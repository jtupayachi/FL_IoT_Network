[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ab66305a-282f-4e3e-8bf3-6d71c0cc9abe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7e784343-22b8-419f-b318-30c8f9c042f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2ee1fa73-9e6e-4512-8bfe-0bda3a72a72a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f5f1e826-2e10-4a18-9544-d59e95092b44
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fc394503-3439-44b4-8526-85845fa35566
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bda39ea1-846d-4ca5-b0e8-9fadcc7262f2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a3776f1b-cda4-44ea-886a-7710b771e00e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 25c39abb-9909-438a-b62d-4bbb67d91d5d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 483388e0-52e4-4e38-8f2d-d2443acab28f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b8682b81-4027-4ff7-ad28-5624e19a927e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 04b1eff5-59a9-402e-99c8-0888276b4e43
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1d6ec10b-3ab9-4313-9cc9-81c0060029b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d11d28da-a8fd-4298-9d6c-ca704b486a07
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 384f1668-9afa-48b3-b304-e21b6371a511
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7f90b107-e82f-4d88-86ed-9c5c21a80191
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c2809287-c44f-43a7-a5a1-8f092fcba426
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f88eb793-27df-4bc8-8c0b-1342f85693c5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c0ce4b49-2380-45f9-9652-276a4e788f0c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8f855d88-80ce-435e-a636-dd0b93d40254
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b18d47a5-aa45-4ccf-9456-2c2905e93146
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: reconnect message e7cab191-7b03-4b00-827e-11ba803d328e
[92mINFO [0m:      Disconnect and shut down
🚀 Starting NASA FL Client: client_23
Algorithm: FEDAVG
Server: localhost:8686
K-Folds: 5
Log Directory: logs
🔄 Using device: cuda
🎯 GPU: NVIDIA A100-SXM4-80GB
💾 Hyperparameters saved to: logs/client_23_hyperparams_20251029_112843.csv
🔍 Looking for data at: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.1/client_23
📊 Loaded 6020 total samples from /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.1/client_23
🔄 Created sequences with length 10
   Final dataset shape: X (6010, 10, 24), y (6010,)
✅ Data split completed:
   Training samples: 3606
   Validation samples: 1202
   Test samples: 1202
   Model type: lstm
✅ Client client_23 ready:
   Model: LSTM
   Training: 3606 samples
   Device: cuda
   Validation: 1202 samples
   Test: 1202 samples
   Algorithm: fedavg
   Total Rounds: 10
   Learning Rate: 0.001
   Batch Size: 32
   Logging to: logs
⏩ Skipping CV for Round 1 (runs every 5 rounds)
Round 1: train_loss=14746.8428, val_loss=13776.1611, val_r2=-0.8313
⏩ Skipping CV for Round 2 (runs every 5 rounds)
Round 2: train_loss=8256.5889, val_loss=7582.0938, val_r2=-0.0079
💾 Training metrics saved to: logs/client_23_training_metrics_20251029_112843.csv
⏩ Skipping CV for Round 3 (runs every 5 rounds)

🎯 Round 3 Training Results:
   Training - Loss: 8307.2324, RMSE: 91.1440, R²: -0.0179
   Validation - Loss: 7623.1362, RMSE: 87.3106, R²: -0.0134
⏩ Skipping CV for Round 4 (runs every 5 rounds)
Round 4: train_loss=8240.7246, val_loss=7569.7441, val_r2=-0.0063
💾 Training metrics saved to: logs/client_23_training_metrics_20251029_112843.csv

🔍 Running 3-fold cross-validation (Round 5)

🔍 Starting 3-fold cross-validation on TRAINING data for client client_23

📊 Fold 1/3
   Fold 1 Results:
     Val Loss: 8086.4849
     Val RMSE: 89.9249, Val R²: -0.0080

📊 Fold 2/3
   Fold 2 Results:
     Val Loss: 8951.4453
     Val RMSE: 94.6121, Val R²: -0.0294

📊 Fold 3/3
   Fold 3 Results:
     Val Loss: 7806.2168
     Val RMSE: 88.3528, Val R²: -0.0089
💾 CV metrics saved to: logs/client_23_cv_metrics_20251029_112843.csv

📈 3-Fold CV Summary (Training Data):
   VAL_LOSS: 8281.3823 ± 487.4258
   RMSE: 90.9633 ± 2.6587
   R2: -0.0154 ± 0.0099

🎯 Round 5 Training Results:
   Training - Loss: 8210.8652, RMSE: 90.6138, R²: -0.0061
   Validation - Loss: 7547.6206, RMSE: 86.8770, R²: -0.0033
💾 Training metrics saved to: logs/client_23_training_metrics_20251029_112843.csv
⏩ Skipping CV for Round 6 (runs every 5 rounds)

🎯 Round 6 Training Results:
   Training - Loss: 8208.0439, RMSE: 90.5983, R²: -0.0058
   Validation - Loss: 7545.6377, RMSE: 86.8656, R²: -0.0031
💾 Training metrics saved to: logs/client_23_training_metrics_20251029_112843.csv
⏩ Skipping CV for Round 7 (runs every 5 rounds)
Round 7: train_loss=8228.1367, val_loss=7560.2026, val_r2=-0.0050
⏩ Skipping CV for Round 8 (runs every 5 rounds)
Round 8: train_loss=8249.2461, val_loss=7576.3374, val_r2=-0.0071
💾 Training metrics saved to: logs/client_23_training_metrics_20251029_112843.csv

🔍 Running 3-fold cross-validation (Round 9)
💾 CV metrics saved to: logs/client_23_cv_metrics_20251029_112843.csv

🎯 Round 9 Training Results:
   Training - Loss: 8216.9883, RMSE: 90.6476, R²: -0.0069
   Validation - Loss: 7552.0000, RMSE: 86.9022, R²: -0.0039
💾 Training metrics saved to: logs/client_23_training_metrics_20251029_112843.csv

🔍 Running 3-fold cross-validation (Round 10)
💾 CV metrics saved to: logs/client_23_cv_metrics_20251029_112843.csv

🎯 Round 10 Training Results:
   Training - Loss: 8250.4531, RMSE: 90.8320, R²: -0.0110
   Validation - Loss: 7577.2803, RMSE: 87.0476, R²: -0.0073
💾 Training metrics saved to: logs/client_23_training_metrics_20251029_112843.csv

================================================================================
🎯 FINAL COMPREHENSIVE REPORT
================================================================================
⚠️ No metrics available for final summary
================================================================================
✅ Client client_23 completed | Algorithm: FEDAVG
