[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 609ee844-40e9-4c65-bf6f-53ee4bf6ad60
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7567854c-4e56-4fa8-899b-f60617ecd579
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 63e7a538-2e10-4413-84c1-cfc000fccfe2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cfe52de3-6b3b-4f92-818e-b1af54756989
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 74363c4d-718a-4f47-88c3-b004088fb13a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9881bb61-76ba-4f17-b6ad-1d22f36da819
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9efd8727-3e23-4d6a-b4a6-090869d2cc24
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8b967fa4-9a86-49ab-a79c-a5f8f37bc505
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 101624fb-1b0c-4807-bd42-0432ad2e6dd9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 27c314a3-63a4-446b-ab77-6f72d56e661c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dad00e8f-a4aa-4d95-9ebf-d4fe64ed1d5d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 02878e42-8a9d-47e8-b77e-2f405dc4bd1a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7bdd3dc5-edb8-4401-8044-7edcdffa1005
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b7ad7d5a-d11d-4e55-b8c8-fbce7cbcb9f8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5994d391-61f0-4383-a0cf-2e2ae7c91da5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 443b83a4-f6b4-4074-80ad-4f11e0b6742a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e56ce28e-4d0f-4d0e-8f09-06f2707649ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1cf96922-c37a-4c44-8a93-517966d27f85
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8ab61ec5-30cf-47dc-9f82-e2614ee05ab9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: reconnect message b39967be-a3be-4ac2-8846-8da6cf110323
[92mINFO [0m:      Disconnect and shut down
🚀 Starting NASA FL Client: client_14
Algorithm: FEDAVG
Server: localhost:8686
K-Folds: 5
Log Directory: logs
🔄 Using device: cuda
🎯 GPU: NVIDIA A100-SXM4-80GB
💾 Hyperparameters saved to: logs/client_14_hyperparams_20251029_120805.csv
🔍 Looking for data at: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.1/client_14
📊 Loaded 6057 total samples from /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.1/client_14
🔄 Created sequences with length 10
   Final dataset shape: X (6047, 10, 24), y (6047,)
✅ Data split completed:
   Training samples: 3627
   Validation samples: 1210
   Test samples: 1210
   Model type: lstm
✅ Client client_14 ready:
   Model: LSTM
   Training: 3627 samples
   Device: cuda
   Validation: 1210 samples
   Test: 1210 samples
   Algorithm: fedavg
   Total Rounds: 10
   Learning Rate: 0.001
   Batch Size: 32
   Logging to: logs

🧪 Round 0 Test Results:
   Test Loss: 16451.0566, RMSE: 128.2617, R²: -0.7987
💾 Test metrics saved to: logs/client_14_test_metrics_20251029_120805.csv
⏩ Skipping CV for Round 2 (runs every 5 rounds)
Round 2: train_loss=9745.7422, val_loss=10135.1484, val_r2=-0.0316
💾 Training metrics saved to: logs/client_14_training_metrics_20251029_120805.csv

🧪 Round 2 Test Results:
   Test Loss: 9314.0889, RMSE: 96.5095, R²: -0.0184
💾 Test metrics saved to: logs/client_14_test_metrics_20251029_120805.csv
⏩ Skipping CV for Round 3 (runs every 5 rounds)

🎯 Round 3 Training Results:
   Training - Loss: 9601.2705, RMSE: 97.9861, R²: -0.0126
   Validation - Loss: 9976.1748, RMSE: 99.8808, R²: -0.0154

🧪 Round 3 Test Results:
   Test Loss: 9296.4727, RMSE: 96.4182, R²: -0.0165
💾 Test metrics saved to: logs/client_14_test_metrics_20251029_120805.csv
⏩ Skipping CV for Round 4 (runs every 5 rounds)
Round 4: train_loss=9576.8779, val_loss=9948.5654, val_r2=-0.0126
💾 Training metrics saved to: logs/client_14_training_metrics_20251029_120805.csv

🧪 Round 4 Test Results:
   Test Loss: 9239.9951, RMSE: 96.1249, R²: -0.0103
💾 Test metrics saved to: logs/client_14_test_metrics_20251029_120805.csv

🔍 Running 3-fold cross-validation (Round 5)

🔍 Starting 3-fold cross-validation on TRAINING data for client client_14

📊 Fold 1/3
   Fold 1 Results:
     Val Loss: 9340.9580
     Val RMSE: 96.6486, Val R²: -0.0094

📊 Fold 2/3
   Fold 2 Results:
     Val Loss: 9650.9492
     Val RMSE: 98.2392, Val R²: -0.0204

📊 Fold 3/3
   Fold 3 Results:
     Val Loss: 9787.4473
     Val RMSE: 98.9315, Val R²: -0.0058
💾 CV metrics saved to: logs/client_14_cv_metrics_20251029_120805.csv

📈 3-Fold CV Summary (Training Data):
   VAL_LOSS: 9593.1182 ± 186.8091
   RMSE: 97.9398 ± 0.9557
   R2: -0.0119 ± 0.0062

🎯 Round 5 Training Results:
   Training - Loss: 9598.9062, RMSE: 97.9740, R²: -0.0124
   Validation - Loss: 9973.5137, RMSE: 99.8675, R²: -0.0151
💾 Training metrics saved to: logs/client_14_training_metrics_20251029_120805.csv

🧪 Round 5 Test Results:
   Test Loss: 9214.4648, RMSE: 95.9920, R²: -0.0075
💾 Test metrics saved to: logs/client_14_test_metrics_20251029_120805.csv
⏩ Skipping CV for Round 6 (runs every 5 rounds)

🎯 Round 6 Training Results:
   Training - Loss: 9645.6953, RMSE: 98.2125, R²: -0.0173
   Validation - Loss: 10025.7051, RMSE: 100.1284, R²: -0.0205
💾 Training metrics saved to: logs/client_14_training_metrics_20251029_120805.csv

🧪 Round 6 Test Results:
   Test Loss: 9223.4727, RMSE: 96.0389, R²: -0.0085
💾 Test metrics saved to: logs/client_14_test_metrics_20251029_120805.csv
⏩ Skipping CV for Round 7 (runs every 5 rounds)
Round 7: train_loss=9651.5244, val_loss=10032.1504, val_r2=-0.0211

🧪 Round 7 Test Results:
   Test Loss: 9222.1777, RMSE: 96.0322, R²: -0.0083
💾 Test metrics saved to: logs/client_14_test_metrics_20251029_120805.csv
⏩ Skipping CV for Round 8 (runs every 5 rounds)
Round 8: train_loss=9640.0010, val_loss=10019.3994, val_r2=-0.0198
💾 Training metrics saved to: logs/client_14_training_metrics_20251029_120805.csv

🧪 Round 8 Test Results:
   Test Loss: 9211.7539, RMSE: 95.9779, R²: -0.0072
💾 Test metrics saved to: logs/client_14_test_metrics_20251029_120805.csv

🔍 Running 3-fold cross-validation (Round 9)
💾 CV metrics saved to: logs/client_14_cv_metrics_20251029_120805.csv

🎯 Round 9 Training Results:
   Training - Loss: 9611.2148, RMSE: 98.0368, R²: -0.0137
   Validation - Loss: 9987.3359, RMSE: 99.9367, R²: -0.0166
💾 Training metrics saved to: logs/client_14_training_metrics_20251029_120805.csv

🧪 Round 9 Test Results:
   Test Loss: 9219.6611, RMSE: 96.0191, R²: -0.0081
💾 Test metrics saved to: logs/client_14_test_metrics_20251029_120805.csv

🔍 Running 3-fold cross-validation (Round 10)
💾 CV metrics saved to: logs/client_14_cv_metrics_20251029_120805.csv

🎯 Round 10 Training Results:
   Training - Loss: 9591.9541, RMSE: 97.9385, R²: -0.0116
   Validation - Loss: 9965.6729, RMSE: 99.8282, R²: -0.0143
💾 Training metrics saved to: logs/client_14_training_metrics_20251029_120805.csv

🧪 Round 10 Test Results:
   Test Loss: 9210.3291, RMSE: 95.9705, R²: -0.0070
💾 Test metrics saved to: logs/client_14_test_metrics_20251029_120805.csv

================================================================================
🎯 FINAL COMPREHENSIVE REPORT
================================================================================
💾 Final summary saved to: logs/client_14_final_summary_20251029_120805.csv

📊 CLIENT: client_14 | ALGORITHM: fedavg | MODEL: LSTM
📈 TOTAL ROUNDS: 10

⚙️  HYPERPARAMETERS:
   Learning Rate: 0.001
   Batch Size: 32
   Local Epochs: 1
   Hidden Dim: 64
   Num Layers: 2
   Sequence Length: 10
   Use Attention: False
   Dropout: 0.3
   Optimizer: adam

🏁 FINAL ROUND PERFORMANCE:
   Training   - Loss:  9591.95 | RMSE:  97.94 | R²: -0.0116
   Validation - Loss:  9965.67 | RMSE:  99.83 | R²: -0.0143
   Test       - Loss:  9210.33 | RMSE:  95.97 | R²: -0.0070

📊 STATISTICS ACROSS ALL ROUNDS (Mean ± Std):
   Training Loss:    9630.06 ±  52.55
   Validation Loss: 10007.91 ±  58.00
   Test Loss:        9960.35 ± 2163.85

   Training RMSE:    98.13 ±  0.27
   Validation RMSE: 100.04 ±  0.29
   Test RMSE:        99.33 ±  9.64

   Training R²:     -0.0157 ± 0.0055
   Validation R²:   -0.0186 ± 0.0059
   Test R²:         -0.0890 ± 0.2366

⭐ BEST PERFORMANCE:
   Best Round: 10 (Test R²: -0.0070)

📋 DATA SUMMARY:
   Training samples:   3627
   Validation samples: 1210
   Test samples:       1210
   Total samples:      6047
================================================================================
✅ Client client_14 completed | Algorithm: FEDAVG
