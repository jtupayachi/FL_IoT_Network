[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2fc1d6cc-4f79-40e5-af7e-5579e709d85b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4fb5fd2b-887d-41c2-af16-b380d1b98dcd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ebcac9ca-b609-4754-a92c-21d31e2c0fbb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5aea4194-69e7-4947-b087-0c66aa5fa9e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f48d1fd7-2f13-440d-a776-78433f8bb592
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ce9b7f9b-cbd1-4dbd-b74d-67652fe7ec76
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 13e33193-5a49-444a-8aef-6397c6919373
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 41940e36-6f4d-44ae-93a4-360fcb798194
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d7d1bbcf-3a4a-404a-a64a-2fddcfc9f378
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 20584039-7e72-4381-b66d-26fe4218b414
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8fd79dc4-415b-4f8c-afe7-5fc2a9a1ee29
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a98b6127-a5f5-4837-9506-8ffbc30a7e21
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b56287b7-4d94-4f3b-a126-0e2319b94469
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bd013fcc-47de-4e1d-87cc-978982931553
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c4932d91-6de6-4999-9cac-5a4eb1e5713c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1af331e2-9840-4b47-ad25-e8b5d779123f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c5f72507-e227-4267-9842-7c47678bb4a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a2a8d976-bb79-4293-91eb-1afcfec4915d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1461adad-d5de-42b3-b5b3-55c5bf49f476
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1b7d7ac0-167d-4860-bd03-dfc7a44290ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: reconnect message bb56ed6a-6b3f-4ed8-b1f5-74e533e60997
[92mINFO [0m:      Disconnect and shut down
ğŸš€ Starting NASA FL Client: client_15
Algorithm: FEDAVG
Server: localhost:8686
K-Folds: 5
Log Directory: logs
ğŸ”„ Using device: cuda
ğŸ¯ GPU: NVIDIA A100-SXM4-80GB
ğŸ’¾ Hyperparameters saved to: logs/client_15_hyperparams_20251029_120807.csv
ğŸ” Looking for data at: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.1/client_15
ğŸ“Š Loaded 6769 total samples from /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.1/client_15
ğŸ”„ Created sequences with length 10
   Final dataset shape: X (6759, 10, 24), y (6759,)
âœ… Data split completed:
   Training samples: 4055
   Validation samples: 1352
   Test samples: 1352
   Model type: lstm
âœ… Client client_15 ready:
   Model: LSTM
   Training: 4055 samples
   Device: cuda
   Validation: 1352 samples
   Test: 1352 samples
   Algorithm: fedavg
   Total Rounds: 10
   Learning Rate: 0.001
   Batch Size: 32
   Logging to: logs
â© Skipping CV for Round 1 (runs every 5 rounds)
Round 1: train_loss=12337.9609, val_loss=12103.7207, val_r2=-0.7560

ğŸ§ª Round 1 Test Results:
   Test Loss: 14454.5547, RMSE: 120.2271, RÂ²: -0.9241
ğŸ’¾ Test metrics saved to: logs/client_15_test_metrics_20251029_120807.csv
â© Skipping CV for Round 2 (runs every 5 rounds)
Round 2: train_loss=7401.9746, val_loss=7215.4268, val_r2=-0.0468
ğŸ’¾ Training metrics saved to: logs/client_15_training_metrics_20251029_120807.csv

ğŸ§ª Round 2 Test Results:
   Test Loss: 7629.3428, RMSE: 87.3461, RÂ²: -0.0156
ğŸ’¾ Test metrics saved to: logs/client_15_test_metrics_20251029_120807.csv
â© Skipping CV for Round 3 (runs every 5 rounds)

ğŸ¯ Round 3 Training Results:
   Training - Loss: 7310.9307, RMSE: 85.5040, RÂ²: -0.0350
   Validation - Loss: 7126.7285, RMSE: 84.4200, RÂ²: -0.0339

ğŸ§ª Round 3 Test Results:
   Test Loss: 7614.7280, RMSE: 87.2624, RÂ²: -0.0136
ğŸ’¾ Test metrics saved to: logs/client_15_test_metrics_20251029_120807.csv
â© Skipping CV for Round 4 (runs every 5 rounds)
Round 4: train_loss=7189.3667, val_loss=7009.1304, val_r2=-0.0169
ğŸ’¾ Training metrics saved to: logs/client_15_training_metrics_20251029_120807.csv

ğŸ§ª Round 4 Test Results:
   Test Loss: 7569.3062, RMSE: 87.0018, RÂ²: -0.0076
ğŸ’¾ Test metrics saved to: logs/client_15_test_metrics_20251029_120807.csv

ğŸ” Running 3-fold cross-validation (Round 5)

ğŸ” Starting 3-fold cross-validation on TRAINING data for client client_15

ğŸ“Š Fold 1/3
   Fold 1 Results:
     Val Loss: 6780.1953
     Val RMSE: 82.3419, Val RÂ²: -0.0070

ğŸ“Š Fold 2/3
   Fold 2 Results:
     Val Loss: 7728.6304
     Val RMSE: 87.9126, Val RÂ²: -0.0415

ğŸ“Š Fold 3/3
   Fold 3 Results:
     Val Loss: 7273.6445
     Val RMSE: 85.2857, Val RÂ²: -0.0418
ğŸ’¾ CV metrics saved to: logs/client_15_cv_metrics_20251029_120807.csv

ğŸ“ˆ 3-Fold CV Summary (Training Data):
   VAL_LOSS: 7260.8234 Â± 387.3031
   RMSE: 85.1801 Â± 2.2754
   R2: -0.0301 Â± 0.0163

ğŸ¯ Round 5 Training Results:
   Training - Loss: 7191.1812, RMSE: 84.8008, RÂ²: -0.0181
   Validation - Loss: 7010.8760, RMSE: 83.7310, RÂ²: -0.0171
ğŸ’¾ Training metrics saved to: logs/client_15_training_metrics_20251029_120807.csv

ğŸ§ª Round 5 Test Results:
   Test Loss: 7549.8818, RMSE: 86.8901, RÂ²: -0.0050
ğŸ’¾ Test metrics saved to: logs/client_15_test_metrics_20251029_120807.csv
â© Skipping CV for Round 6 (runs every 5 rounds)

ğŸ¯ Round 6 Training Results:
   Training - Loss: 7272.5913, RMSE: 85.2795, RÂ²: -0.0296
   Validation - Loss: 7089.5059, RMSE: 84.1992, RÂ²: -0.0285
ğŸ’¾ Training metrics saved to: logs/client_15_training_metrics_20251029_120807.csv

ğŸ§ª Round 6 Test Results:
   Test Loss: 7556.6230, RMSE: 86.9288, RÂ²: -0.0059
ğŸ’¾ Test metrics saved to: logs/client_15_test_metrics_20251029_120807.csv
â© Skipping CV for Round 7 (runs every 5 rounds)
Round 7: train_loss=7276.7349, val_loss=7093.5239, val_r2=-0.0291

ğŸ§ª Round 7 Test Results:
   Test Loss: 7555.6450, RMSE: 86.9232, RÂ²: -0.0058
ğŸ’¾ Test metrics saved to: logs/client_15_test_metrics_20251029_120807.csv
â© Skipping CV for Round 8 (runs every 5 rounds)
Round 8: train_loss=7251.1963, val_loss=7068.7783, val_r2=-0.0255
ğŸ’¾ Training metrics saved to: logs/client_15_training_metrics_20251029_120807.csv

ğŸ§ª Round 8 Test Results:
   Test Loss: 7547.8818, RMSE: 86.8785, RÂ²: -0.0047
ğŸ’¾ Test metrics saved to: logs/client_15_test_metrics_20251029_120807.csv

ğŸ” Running 3-fold cross-validation (Round 9)
ğŸ’¾ CV metrics saved to: logs/client_15_cv_metrics_20251029_120807.csv

ğŸ¯ Round 9 Training Results:
   Training - Loss: 7238.4717, RMSE: 85.0792, RÂ²: -0.0248
   Validation - Loss: 7056.4692, RMSE: 84.0028, RÂ²: -0.0237
ğŸ’¾ Training metrics saved to: logs/client_15_training_metrics_20251029_120807.csv

ğŸ§ª Round 9 Test Results:
   Test Loss: 7553.7529, RMSE: 86.9123, RÂ²: -0.0055
ğŸ’¾ Test metrics saved to: logs/client_15_test_metrics_20251029_120807.csv

ğŸ” Running 3-fold cross-validation (Round 10)
ğŸ’¾ CV metrics saved to: logs/client_15_cv_metrics_20251029_120807.csv

ğŸ¯ Round 10 Training Results:
   Training - Loss: 7185.1333, RMSE: 84.7652, RÂ²: -0.0172
   Validation - Loss: 7005.0649, RMSE: 83.6963, RÂ²: -0.0163
ğŸ’¾ Training metrics saved to: logs/client_15_training_metrics_20251029_120807.csv

ğŸ§ª Round 10 Test Results:
   Test Loss: 7546.8374, RMSE: 86.8725, RÂ²: -0.0046
ğŸ’¾ Test metrics saved to: logs/client_15_test_metrics_20251029_120807.csv

================================================================================
ğŸ¯ FINAL COMPREHENSIVE REPORT
================================================================================
ğŸ’¾ Final summary saved to: logs/client_15_final_summary_20251029_120807.csv

ğŸ“Š CLIENT: client_15 | ALGORITHM: fedavg | MODEL: LSTM
ğŸ“ˆ TOTAL ROUNDS: 10

âš™ï¸  HYPERPARAMETERS:
   Learning Rate: 0.001
   Batch Size: 32
   Local Epochs: 1
   Hidden Dim: 64
   Num Layers: 2
   Sequence Length: 10
   Use Attention: False
   Dropout: 0.3
   Optimizer: adam

ğŸ FINAL ROUND PERFORMANCE:
   Training   - Loss:  7185.13 | RMSE:  84.77 | RÂ²: -0.0172
   Validation - Loss:  7005.06 | RMSE:  83.70 | RÂ²: -0.0163
   Test       - Loss:  7546.84 | RMSE:  86.87 | RÂ²: -0.0046

ğŸ“Š STATISTICS ACROSS ALL ROUNDS (Mean Â± Std):
   Training Loss:    7247.13 Â±  70.74
   Validation Loss:  7065.04 Â±  68.62
   Test Loss:        8257.86 Â± 2065.75

   Training RMSE:    85.13 Â±  0.41
   Validation RMSE:  84.05 Â±  0.41
   Test RMSE:        90.32 Â±  9.97

   Training RÂ²:     -0.0260 Â± 0.0100
   Validation RÂ²:   -0.0250 Â± 0.0100
   Test RÂ²:         -0.0992 Â± 0.2750

â­ BEST PERFORMANCE:
   Best Round: 10 (Test RÂ²: -0.0046)

ğŸ“‹ DATA SUMMARY:
   Training samples:   4055
   Validation samples: 1352
   Test samples:       1352
   Total samples:      6759
================================================================================
âœ… Client client_15 completed | Algorithm: FEDAVG
