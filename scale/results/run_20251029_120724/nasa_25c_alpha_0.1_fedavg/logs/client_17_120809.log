[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a194b5d6-3134-408c-a2fa-6dd7aa0fd8ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 35ea61ad-034b-4f10-85b3-445b41543e8b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6c5ab5aa-fc7c-4c76-82d8-c98733bc1914
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 673983ef-805b-486d-9e72-b076cca84217
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ad281e11-c451-49ee-bd9c-ff318573bd3f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1a578649-041e-45b7-8399-104ed5d03eb3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7e7b81c5-6f10-47be-9bb3-bb9c7b18bcf2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4d9ae213-dadb-4efb-b351-244be0eb5723
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 75cd839a-039f-4db0-b92a-c1477f4167cd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ff27961d-8e28-4946-afce-a6a58d892a8d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6553630c-34b5-4516-bbb8-5c44643b92d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1ac575b8-ce61-4c14-a217-75386e6aa3be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a3644fc4-df7d-4024-9a58-880417ea191c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 53b3867e-a3d5-4139-b7f2-5325f5892221
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2f470eb1-9e14-4d9d-aa0b-f7968b3480d5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 52be5f00-fdc7-4868-896c-f34ef3c29343
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 079cfe61-a6c7-47d9-979c-bfe49d58779b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f606df4e-2274-4a22-953a-e96654044bc0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 106d6ee6-3e7a-48eb-82d9-f5a2845f95ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ab4997f2-ea69-4540-920d-0889f728764b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: reconnect message 87eb1a28-6d89-422b-aa2a-a4041615b8ce
[92mINFO [0m:      Disconnect and shut down
ğŸš€ Starting NASA FL Client: client_17
Algorithm: FEDAVG
Server: localhost:8686
K-Folds: 5
Log Directory: logs
ğŸ”„ Using device: cuda
ğŸ¯ GPU: NVIDIA A100-SXM4-80GB
ğŸ’¾ Hyperparameters saved to: logs/client_17_hyperparams_20251029_120811.csv
ğŸ” Looking for data at: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.1/client_17
ğŸ“Š Loaded 5738 total samples from /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.1/client_17
ğŸ”„ Created sequences with length 10
   Final dataset shape: X (5728, 10, 24), y (5728,)
âœ… Data split completed:
   Training samples: 3436
   Validation samples: 1146
   Test samples: 1146
   Model type: lstm
âœ… Client client_17 ready:
   Model: LSTM
   Training: 3436 samples
   Device: cuda
   Validation: 1146 samples
   Test: 1146 samples
   Algorithm: fedavg
   Total Rounds: 10
   Learning Rate: 0.001
   Batch Size: 32
   Logging to: logs
â© Skipping CV for Round 1 (runs every 5 rounds)
Round 1: train_loss=14125.9805, val_loss=14246.4287, val_r2=-1.2147

ğŸ§ª Round 1 Test Results:
   Test Loss: 13931.8799, RMSE: 118.0334, RÂ²: -1.0968
ğŸ’¾ Test metrics saved to: logs/client_17_test_metrics_20251029_120811.csv
â© Skipping CV for Round 2 (runs every 5 rounds)
Round 2: train_loss=6775.4248, val_loss=6736.5654, val_r2=-0.0473
ğŸ’¾ Training metrics saved to: logs/client_17_training_metrics_20251029_120811.csv

ğŸ§ª Round 2 Test Results:
   Test Loss: 6809.8135, RMSE: 82.5216, RÂ²: -0.0249
ğŸ’¾ Test metrics saved to: logs/client_17_test_metrics_20251029_120811.csv
â© Skipping CV for Round 3 (runs every 5 rounds)

ğŸ¯ Round 3 Training Results:
   Training - Loss: 6645.6367, RMSE: 81.5208, RÂ²: -0.0209
   Validation - Loss: 6596.3672, RMSE: 81.2180, RÂ²: -0.0255

ğŸ§ª Round 3 Test Results:
   Test Loss: 6792.3403, RMSE: 82.4157, RÂ²: -0.0223
ğŸ’¾ Test metrics saved to: logs/client_17_test_metrics_20251029_120811.csv
â© Skipping CV for Round 4 (runs every 5 rounds)
Round 4: train_loss=6695.8540, val_loss=6651.0347, val_r2=-0.0340
ğŸ’¾ Training metrics saved to: logs/client_17_training_metrics_20251029_120811.csv

ğŸ§ª Round 4 Test Results:
   Test Loss: 6736.3921, RMSE: 82.0755, RÂ²: -0.0139
ğŸ’¾ Test metrics saved to: logs/client_17_test_metrics_20251029_120811.csv

ğŸ” Running 3-fold cross-validation (Round 5)

ğŸ” Starting 3-fold cross-validation on TRAINING data for client client_17

ğŸ“Š Fold 1/3
   Fold 1 Results:
     Val Loss: 6302.5103
     Val RMSE: 79.3884, Val RÂ²: -0.0073

ğŸ“Š Fold 2/3
   Fold 2 Results:
     Val Loss: 7088.0532
     Val RMSE: 84.1906, Val RÂ²: -0.0323

ğŸ“Š Fold 3/3
   Fold 3 Results:
     Val Loss: 6445.2324
     Val RMSE: 80.2822, Val RÂ²: -0.0080
ğŸ’¾ CV metrics saved to: logs/client_17_cv_metrics_20251029_120811.csv

ğŸ“ˆ 3-Fold CV Summary (Training Data):
   VAL_LOSS: 6611.9320 Â± 341.6733
   RMSE: 81.2870 Â± 2.0853
   R2: -0.0158 Â± 0.0116

ğŸ¯ Round 5 Training Results:
   Training - Loss: 6631.8208, RMSE: 81.4360, RÂ²: -0.0188
   Validation - Loss: 6581.1875, RMSE: 81.1245, RÂ²: -0.0231
ğŸ’¾ Training metrics saved to: logs/client_17_training_metrics_20251029_120811.csv

ğŸ§ª Round 5 Test Results:
   Test Loss: 6711.1523, RMSE: 81.9216, RÂ²: -0.0101
ğŸ’¾ Test metrics saved to: logs/client_17_test_metrics_20251029_120811.csv
â© Skipping CV for Round 6 (runs every 5 rounds)

ğŸ¯ Round 6 Training Results:
   Training - Loss: 6675.2178, RMSE: 81.7020, RÂ²: -0.0255
   Validation - Loss: 6628.6523, RMSE: 81.4165, RÂ²: -0.0305
ğŸ’¾ Training metrics saved to: logs/client_17_training_metrics_20251029_120811.csv

ğŸ§ª Round 6 Test Results:
   Test Loss: 6720.0527, RMSE: 81.9759, RÂ²: -0.0114
ğŸ’¾ Test metrics saved to: logs/client_17_test_metrics_20251029_120811.csv
â© Skipping CV for Round 7 (runs every 5 rounds)
Round 7: train_loss=6638.7935, val_loss=6588.8579, val_r2=-0.0243

ğŸ§ª Round 7 Test Results:
   Test Loss: 6718.7729, RMSE: 81.9681, RÂ²: -0.0112
ğŸ’¾ Test metrics saved to: logs/client_17_test_metrics_20251029_120811.csv
â© Skipping CV for Round 8 (runs every 5 rounds)
Round 8: train_loss=6626.6499, val_loss=6575.4868, val_r2=-0.0222
ğŸ’¾ Training metrics saved to: logs/client_17_training_metrics_20251029_120811.csv

ğŸ§ª Round 8 Test Results:
   Test Loss: 6708.4756, RMSE: 81.9053, RÂ²: -0.0097
ğŸ’¾ Test metrics saved to: logs/client_17_test_metrics_20251029_120811.csv

ğŸ” Running 3-fold cross-validation (Round 9)
ğŸ’¾ CV metrics saved to: logs/client_17_cv_metrics_20251029_120811.csv

ğŸ¯ Round 9 Training Results:
   Training - Loss: 6633.1895, RMSE: 81.4444, RÂ²: -0.0190
   Validation - Loss: 6582.6938, RMSE: 81.1338, RÂ²: -0.0233
ğŸ’¾ Training metrics saved to: logs/client_17_training_metrics_20251029_120811.csv

ğŸ§ª Round 9 Test Results:
   Test Loss: 6716.2861, RMSE: 81.9530, RÂ²: -0.0108
ğŸ’¾ Test metrics saved to: logs/client_17_test_metrics_20251029_120811.csv

ğŸ” Running 3-fold cross-validation (Round 10)
ğŸ’¾ CV metrics saved to: logs/client_17_cv_metrics_20251029_120811.csv

ğŸ¯ Round 10 Training Results:
   Training - Loss: 6613.1035, RMSE: 81.3210, RÂ²: -0.0159
   Validation - Loss: 6560.4951, RMSE: 80.9969, RÂ²: -0.0199
ğŸ’¾ Training metrics saved to: logs/client_17_training_metrics_20251029_120811.csv

ğŸ§ª Round 10 Test Results:
   Test Loss: 6707.0693, RMSE: 81.8967, RÂ²: -0.0094
ğŸ’¾ Test metrics saved to: logs/client_17_test_metrics_20251029_120811.csv

================================================================================
ğŸ¯ FINAL COMPREHENSIVE REPORT
================================================================================
ğŸ’¾ Final summary saved to: logs/client_17_final_summary_20251029_120811.csv

ğŸ“Š CLIENT: client_17 | ALGORITHM: fedavg | MODEL: LSTM
ğŸ“ˆ TOTAL ROUNDS: 10

âš™ï¸  HYPERPARAMETERS:
   Learning Rate: 0.001
   Batch Size: 32
   Local Epochs: 1
   Hidden Dim: 64
   Num Layers: 2
   Sequence Length: 10
   Use Attention: False
   Dropout: 0.3
   Optimizer: adam

ğŸ FINAL ROUND PERFORMANCE:
   Training   - Loss:  6613.10 | RMSE:  81.32 | RÂ²: -0.0159
   Validation - Loss:  6560.50 | RMSE:  81.00 | RÂ²: -0.0199
   Test       - Loss:  6707.07 | RMSE:  81.90 | RÂ²: -0.0094

ğŸ“Š STATISTICS ACROSS ALL ROUNDS (Mean Â± Std):
   Training Loss:    6664.47 Â±  52.81
   Validation Loss:  6616.59 Â±  57.28
   Test Loss:        7455.22 Â± 2159.16

   Training RMSE:    81.64 Â±  0.32
   Validation RMSE:  81.34 Â±  0.35
   Test RMSE:        85.67 Â± 10.79

   Training RÂ²:     -0.0238 Â± 0.0081
   Validation RÂ²:   -0.0286 Â± 0.0089
   Test RÂ²:         -0.1220 Â± 0.3250

â­ BEST PERFORMANCE:
   Best Round: 10 (Test RÂ²: -0.0094)

ğŸ“‹ DATA SUMMARY:
   Training samples:   3436
   Validation samples: 1146
   Test samples:       1146
   Total samples:      5728
================================================================================
âœ… Client client_17 completed | Algorithm: FEDAVG
