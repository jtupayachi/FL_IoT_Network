[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e7d5490f-fcac-4705-88ee-71b8e21535db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 24924bff-680c-40ca-9af7-c7a2ed8990a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 767693a9-b6df-4745-9bfc-a2e46b684cea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message add0fb23-a504-4159-aac4-061f2c79a104
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3be7b6c9-80ec-4545-8082-e145f3e086eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f03e4c4d-f89f-414f-bb71-6e3c7e261ac1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3391fb7a-d8b2-4703-a3bd-3f8c01832abc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 03fc92c8-c3e5-4761-9f6c-c5e8f109b42b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b0806d66-da7a-4b7a-a743-5ce39e78e65a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message addff32a-f564-4845-8230-39427cca0646
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9fc1db7a-214e-460f-a84b-2e31262747eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 733aa232-d159-45fc-b12a-82e3554edafc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2805c0d9-63f0-49ce-993d-d68d1305ade9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eb8e8118-71c4-45d2-8a38-8605273f4d4d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ba53c0dd-d057-4962-a0ba-c9a084870db5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5a42c163-55be-4929-9731-440e93801628
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c4e671bb-77a6-4104-a9bd-3a192af6929f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2f8debf7-91cd-497f-ba1b-2101d45fd904
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3ea7f0ab-022b-4762-b7a0-438a47cc58d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e9ea1503-e782-4cb3-a6fe-29c9bcc4845b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: reconnect message 2a3b7b5d-64f1-4460-aa66-3473f71c9b3e
[92mINFO [0m:      Disconnect and shut down
ğŸš€ Starting NASA FL Client: client_16
Algorithm: FEDAVG
Server: localhost:8686
K-Folds: 5
Log Directory: logs
ğŸ”„ Using device: cuda
ğŸ¯ GPU: NVIDIA A100-SXM4-80GB
ğŸ’¾ Hyperparameters saved to: logs/client_16_hyperparams_20251029_150431.csv
ğŸ” Looking for data at: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.1/client_16
ğŸ“Š Loaded 8210 total samples from /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.1/client_16
ğŸ”„ Created sequences with length 10
   Final dataset shape: X (8200, 10, 24), y (8200,)
âœ… Data split completed:
   Training samples: 4920
   Validation samples: 1640
   Test samples: 1640
   Model type: lstm
âœ… Client client_16 ready:
   Model: LSTM
   Training: 4920 samples
   Device: cuda
   Validation: 1640 samples
   Test: 1640 samples
   Algorithm: fedavg
   Total Rounds: 10
   Learning Rate: 0.001
   Batch Size: 32
   Logging to: logs
â© Skipping CV for Round 1 (runs every 5 rounds)
Round 1: train_loss=10731.6924, val_loss=9907.0254, val_r2=-0.0200

ğŸ§ª Round 1 Evaluation Results:
   Test Loss: 16369.9563
   RMSE: 127.9451, MAE: 94.7756, RÂ²: -0.6333
ğŸ’¾ Test metrics saved to: logs/client_16_test_metrics_20251029_150431.csv
â© Skipping CV for Round 2 (runs every 5 rounds)
Round 2: train_loss=10650.0908, val_loss=9827.4404, val_r2=-0.0118
ğŸ’¾ Training metrics saved to: logs/client_16_training_metrics_20251029_150431.csv

ğŸ§ª Round 2 Evaluation Results:
   Test Loss: 10743.6845
   RMSE: 103.6518, MAE: 78.5435, RÂ²: -0.0720
ğŸ’¾ Test metrics saved to: logs/client_16_test_metrics_20251029_150431.csv
â© Skipping CV for Round 3 (runs every 5 rounds)

ğŸ¯ Round 3 Training Results:
   Training - Loss: 10642.2969, RMSE: 103.1615, RÂ²: -0.0108
   Validation - Loss: 9819.8730, RMSE: 99.0953, RÂ²: -0.0111

ğŸ§ª Round 3 Evaluation Results:
   Test Loss: 10695.1626
   RMSE: 103.4174, MAE: 78.4527, RÂ²: -0.0671
ğŸ’¾ Test metrics saved to: logs/client_16_test_metrics_20251029_150431.csv
â© Skipping CV for Round 4 (runs every 5 rounds)
Round 4: train_loss=10673.2549, val_loss=9849.9795, val_r2=-0.0142
ğŸ’¾ Training metrics saved to: logs/client_16_training_metrics_20251029_150431.csv

ğŸ§ª Round 4 Evaluation Results:
   Test Loss: 10687.4136
   RMSE: 103.3799, MAE: 78.4384, RÂ²: -0.0663
ğŸ’¾ Test metrics saved to: logs/client_16_test_metrics_20251029_150431.csv

ğŸ” Running 3-fold cross-validation (Round 5)

ğŸ” Starting 3-fold cross-validation on TRAINING data for client client_16

ğŸ“Š Fold 1/3
   Fold 1 Results:
     Val Loss: 10292.4365
     Val RMSE: 101.4516, Val RÂ²: -0.0076

ğŸ“Š Fold 2/3
   Fold 2 Results:
     Val Loss: 11157.6182
     Val RMSE: 105.6296, Val RÂ²: -0.0250

ğŸ“Š Fold 3/3
   Fold 3 Results:
     Val Loss: 10504.5332
     Val RMSE: 102.4916, Val RÂ²: -0.0045
ğŸ’¾ CV metrics saved to: logs/client_16_cv_metrics_20251029_150431.csv

ğŸ“ˆ 3-Fold CV Summary (Training Data):
   VAL_LOSS: 10651.5293 Â± 368.1854
   RMSE: 103.1910 Â± 1.7759
   R2: -0.0124 Â± 0.0090

ğŸ¯ Round 5 Training Results:
   Training - Loss: 10646.0957, RMSE: 103.1799, RÂ²: -0.0112
   Validation - Loss: 9823.5625, RMSE: 99.1139, RÂ²: -0.0115
ğŸ’¾ Training metrics saved to: logs/client_16_training_metrics_20251029_150431.csv

ğŸ§ª Round 5 Evaluation Results:
   Test Loss: 10676.2884
   RMSE: 103.3261, MAE: 78.4186, RÂ²: -0.0652
ğŸ’¾ Test metrics saved to: logs/client_16_test_metrics_20251029_150431.csv
â© Skipping CV for Round 6 (runs every 5 rounds)

ğŸ¯ Round 6 Training Results:
   Training - Loss: 10666.2627, RMSE: 103.2776, RÂ²: -0.0131
   Validation - Loss: 9843.1709, RMSE: 99.2128, RÂ²: -0.0135
ğŸ’¾ Training metrics saved to: logs/client_16_training_metrics_20251029_150431.csv

ğŸ§ª Round 6 Evaluation Results:
   Test Loss: 10672.3523
   RMSE: 103.3071, MAE: 78.4115, RÂ²: -0.0648
ğŸ’¾ Test metrics saved to: logs/client_16_test_metrics_20251029_150431.csv
â© Skipping CV for Round 7 (runs every 5 rounds)
Round 7: train_loss=10686.2080, val_loss=9862.6025, val_r2=-0.0155

ğŸ§ª Round 7 Evaluation Results:
   Test Loss: 10673.3646
   RMSE: 103.3120, MAE: 78.4133, RÂ²: -0.0649
ğŸ’¾ Test metrics saved to: logs/client_16_test_metrics_20251029_150431.csv
â© Skipping CV for Round 8 (runs every 5 rounds)
Round 8: train_loss=10592.2051, val_loss=9771.4590, val_r2=-0.0061
ğŸ’¾ Training metrics saved to: logs/client_16_training_metrics_20251029_150431.csv

ğŸ§ª Round 8 Evaluation Results:
   Test Loss: 10679.8030
   RMSE: 103.3431, MAE: 78.4249, RÂ²: -0.0656
ğŸ’¾ Test metrics saved to: logs/client_16_test_metrics_20251029_150431.csv

ğŸ” Running 3-fold cross-validation (Round 9)
ğŸ’¾ CV metrics saved to: logs/client_16_cv_metrics_20251029_150431.csv

ğŸ¯ Round 9 Training Results:
   Training - Loss: 10606.9932, RMSE: 102.9903, RÂ²: -0.0075
   Validation - Loss: 9785.6992, RMSE: 98.9227, RÂ²: -0.0076
ğŸ’¾ Training metrics saved to: logs/client_16_training_metrics_20251029_150431.csv

ğŸ§ª Round 9 Evaluation Results:
   Test Loss: 10657.4740
   RMSE: 103.2350, MAE: 78.3847, RÂ²: -0.0634
ğŸ’¾ Test metrics saved to: logs/client_16_test_metrics_20251029_150431.csv

ğŸ” Running 3-fold cross-validation (Round 10)
ğŸ’¾ CV metrics saved to: logs/client_16_cv_metrics_20251029_150431.csv

ğŸ¯ Round 10 Training Results:
   Training - Loss: 10631.0498, RMSE: 103.1070, RÂ²: -0.0098
   Validation - Loss: 9808.9648, RMSE: 99.0402, RÂ²: -0.0099
ğŸ’¾ Training metrics saved to: logs/client_16_training_metrics_20251029_150431.csv

ğŸ§ª Round 10 Evaluation Results:
   Test Loss: 10661.5948
   RMSE: 103.2550, MAE: 78.3921, RÂ²: -0.0638
ğŸ’¾ Test metrics saved to: logs/client_16_test_metrics_20251029_150431.csv

================================================================================
ğŸ¯ FINAL COMPREHENSIVE REPORT
================================================================================
ğŸ’¾ Final summary saved to: logs/client_16_final_summary_20251029_150431.csv

ğŸ“Š CLIENT: client_16 | ALGORITHM: fedavg | MODEL: LSTM
ğŸ“ˆ TOTAL ROUNDS: 10

âš™ï¸  HYPERPARAMETERS:
   Learning Rate: 0.001
   Batch Size: 32
   Local Epochs: 1
   Hidden Dim: 64
   Num Layers: 2
   Sequence Length: 10
   Use Attention: False
   Dropout: 0.3
   Optimizer: adam

ğŸ FINAL ROUND PERFORMANCE:
   Training   - Loss: 10631.05 | RMSE: 103.11 | RÂ²: -0.0098
   Validation - Loss:  9808.96 | RMSE:  99.04 | RÂ²: -0.0099
   Test       - Loss: 10661.59 | RMSE: 103.25 | RÂ²: -0.0638

ğŸ“Š STATISTICS ACROSS ALL ROUNDS (Mean Â± Std):
   Training Loss:   10637.99 Â±  27.67
   Validation Loss:  9815.75 Â±  26.81
   Test Loss:       11251.71 Â± 1706.24

   Training RMSE:   103.14 Â±  0.13
   Validation RMSE:  99.07 Â±  0.14
   Test RMSE:       105.82 Â±  7.38

   Training RÂ²:     -0.0104 Â± 0.0026
   Validation RÂ²:   -0.0106 Â± 0.0028
   Test RÂ²:         -0.1227 Â± 0.1702

â­ BEST PERFORMANCE:
   Best Round: 9 (Test RÂ²: -0.0634)

ğŸ“‹ DATA SUMMARY:
   Training samples:   4920
   Validation samples: 1640
   Test samples:       1640
   Total samples:      8200
================================================================================
âœ… Client client_16 completed | Algorithm: FEDAVG
