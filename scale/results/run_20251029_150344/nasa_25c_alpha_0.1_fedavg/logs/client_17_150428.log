[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ee13c237-213f-409b-9907-62f9564e7cbc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6e5a367a-caea-43af-87e9-d9e6177516c5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f33fb2a5-67dd-4014-b9c4-1ffc3cac24f2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d9041328-b400-474e-9f53-9b319a1fdb08
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2a94e463-baf0-435e-a953-4d964d2c2a1e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3a2b617a-b723-487b-b160-e7952073f452
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 63ec8cd9-5c61-412e-9810-8d07ac687521
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a49742d3-fce7-418a-be4d-b2037ca21919
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e7d5f7da-4b68-4cf7-ab41-0e5cf4e695da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a1a12c7e-40ea-49bc-a6bc-b4bb82c5738a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1edfca20-3c90-47cb-bf37-f228133698d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ba22415a-8eae-4f7f-9b31-4a0a7f5c4cd3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6a2afaf8-4cc6-4b11-9bd0-0198048ad745
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a9c9b6d0-f9b6-4196-9942-0f0e690b5385
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a84f07d8-36ee-4b07-bc3c-0e419aedffe9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 475a97ca-6105-4e2d-8f7f-2efa72074f83
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ee894c7c-e2e3-414a-af75-6db808d0655c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2ee4e58c-598e-4779-97ae-3af25940e20c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8b86a9d2-e1a0-4a61-9364-3fb3cf66b7e5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 102b4e4c-9357-4a5c-a116-9703f8a6fcff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: reconnect message 6964299c-2442-4b3a-b224-4989edecf998
[92mINFO [0m:      Disconnect and shut down
ğŸš€ Starting NASA FL Client: client_17
Algorithm: FEDAVG
Server: localhost:8686
K-Folds: 5
Log Directory: logs
ğŸ”„ Using device: cuda
ğŸ¯ GPU: NVIDIA A100-SXM4-80GB
ğŸ’¾ Hyperparameters saved to: logs/client_17_hyperparams_20251029_150433.csv
ğŸ” Looking for data at: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.1/client_17
ğŸ“Š Loaded 5738 total samples from /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.1/client_17
ğŸ”„ Created sequences with length 10
   Final dataset shape: X (5728, 10, 24), y (5728,)
âœ… Data split completed:
   Training samples: 3436
   Validation samples: 1146
   Test samples: 1146
   Model type: lstm
âœ… Client client_17 ready:
   Model: LSTM
   Training: 3436 samples
   Device: cuda
   Validation: 1146 samples
   Test: 1146 samples
   Algorithm: fedavg
   Total Rounds: 10
   Learning Rate: 0.001
   Batch Size: 32
   Logging to: logs
â© Skipping CV for Round 1 (runs every 5 rounds)
Round 1: train_loss=11251.6045, val_loss=11330.7764, val_r2=-0.7615

ğŸ§ª Round 1 Evaluation Results:
   Test Loss: 10376.6854
   RMSE: 101.8660, MAE: 78.6053, RÂ²: -0.5617
ğŸ’¾ Test metrics saved to: logs/client_17_test_metrics_20251029_150433.csv
â© Skipping CV for Round 2 (runs every 5 rounds)
Round 2: train_loss=6617.0669, val_loss=6564.9453, val_r2=-0.0206
ğŸ’¾ Training metrics saved to: logs/client_17_training_metrics_20251029_150433.csv

ğŸ§ª Round 2 Evaluation Results:
   Test Loss: 6712.8384
   RMSE: 81.9319, MAE: 65.4223, RÂ²: -0.0103
ğŸ’¾ Test metrics saved to: logs/client_17_test_metrics_20251029_150433.csv
â© Skipping CV for Round 3 (runs every 5 rounds)

ğŸ¯ Round 3 Training Results:
   Training - Loss: 6641.7910, RMSE: 81.4972, RÂ²: -0.0204
   Validation - Loss: 6592.1719, RMSE: 81.1922, RÂ²: -0.0248

ğŸ§ª Round 3 Evaluation Results:
   Test Loss: 6698.4669
   RMSE: 81.8442, MAE: 65.4127, RÂ²: -0.0081
ğŸ’¾ Test metrics saved to: logs/client_17_test_metrics_20251029_150433.csv
â© Skipping CV for Round 4 (runs every 5 rounds)
Round 4: train_loss=6650.0024, val_loss=6601.1729, val_r2=-0.0262
ğŸ’¾ Training metrics saved to: logs/client_17_training_metrics_20251029_150433.csv

ğŸ§ª Round 4 Evaluation Results:
   Test Loss: 6696.2845
   RMSE: 81.8308, MAE: 65.4123, RÂ²: -0.0078
ğŸ’¾ Test metrics saved to: logs/client_17_test_metrics_20251029_150433.csv

ğŸ” Running 3-fold cross-validation (Round 5)

ğŸ” Starting 3-fold cross-validation on TRAINING data for client client_17

ğŸ“Š Fold 1/3
   Fold 1 Results:
     Val Loss: 6266.8359
     Val RMSE: 79.1633, Val RÂ²: -0.0016

ğŸ“Š Fold 2/3
   Fold 2 Results:
     Val Loss: 6990.9507
     Val RMSE: 83.6119, Val RÂ²: -0.0181

ğŸ“Š Fold 3/3
   Fold 3 Results:
     Val Loss: 6406.4443
     Val RMSE: 80.0403, Val RÂ²: -0.0019
ğŸ’¾ CV metrics saved to: logs/client_17_cv_metrics_20251029_150433.csv

ğŸ“ˆ 3-Fold CV Summary (Training Data):
   VAL_LOSS: 6554.7437 Â± 313.6665
   RMSE: 80.9385 Â± 1.9240
   R2: -0.0072 Â± 0.0077

ğŸ¯ Round 5 Training Results:
   Training - Loss: 6627.8955, RMSE: 81.4119, RÂ²: -0.0182
   Validation - Loss: 6576.8857, RMSE: 81.0980, RÂ²: -0.0224
ğŸ’¾ Training metrics saved to: logs/client_17_training_metrics_20251029_150433.csv

ğŸ§ª Round 5 Evaluation Results:
   Test Loss: 6693.2083
   RMSE: 81.8120, MAE: 65.4138, RÂ²: -0.0074
ğŸ’¾ Test metrics saved to: logs/client_17_test_metrics_20251029_150433.csv
â© Skipping CV for Round 6 (runs every 5 rounds)

ğŸ¯ Round 6 Training Results:
   Training - Loss: 6603.5752, RMSE: 81.2624, RÂ²: -0.0145
   Validation - Loss: 6549.9136, RMSE: 80.9315, RÂ²: -0.0182
ğŸ’¾ Training metrics saved to: logs/client_17_training_metrics_20251029_150433.csv

ğŸ§ª Round 6 Evaluation Results:
   Test Loss: 6692.1365
   RMSE: 81.8055, MAE: 65.4144, RÂ²: -0.0072
ğŸ’¾ Test metrics saved to: logs/client_17_test_metrics_20251029_150433.csv
â© Skipping CV for Round 7 (runs every 5 rounds)
Round 7: train_loss=6643.6460, val_loss=6594.2061, val_r2=-0.0251

ğŸ§ª Round 7 Evaluation Results:
   Test Loss: 6692.4115
   RMSE: 81.8072, MAE: 65.4142, RÂ²: -0.0072
ğŸ’¾ Test metrics saved to: logs/client_17_test_metrics_20251029_150433.csv
â© Skipping CV for Round 8 (runs every 5 rounds)
Round 8: train_loss=6584.8530, val_loss=6528.9058, val_r2=-0.0150
ğŸ’¾ Training metrics saved to: logs/client_17_training_metrics_20251029_150433.csv

ğŸ§ª Round 8 Evaluation Results:
   Test Loss: 6694.1733
   RMSE: 81.8179, MAE: 65.4133, RÂ²: -0.0075
ğŸ’¾ Test metrics saved to: logs/client_17_test_metrics_20251029_150433.csv

ğŸ” Running 3-fold cross-validation (Round 9)
ğŸ’¾ CV metrics saved to: logs/client_17_cv_metrics_20251029_150433.csv

ğŸ¯ Round 9 Training Results:
   Training - Loss: 6610.7671, RMSE: 81.3066, RÂ²: -0.0156
   Validation - Loss: 6557.9199, RMSE: 80.9810, RÂ²: -0.0195
ğŸ’¾ Training metrics saved to: logs/client_17_training_metrics_20251029_150433.csv

ğŸ§ª Round 9 Evaluation Results:
   Test Loss: 6688.1640
   RMSE: 81.7812, MAE: 65.4164, RÂ²: -0.0066
ğŸ’¾ Test metrics saved to: logs/client_17_test_metrics_20251029_150433.csv

ğŸ” Running 3-fold cross-validation (Round 10)
ğŸ’¾ CV metrics saved to: logs/client_17_cv_metrics_20251029_150433.csv

ğŸ¯ Round 10 Training Results:
   Training - Loss: 6648.6387, RMSE: 81.5392, RÂ²: -0.0214
   Validation - Loss: 6599.6743, RMSE: 81.2384, RÂ²: -0.0260
ğŸ’¾ Training metrics saved to: logs/client_17_training_metrics_20251029_150433.csv

ğŸ§ª Round 10 Evaluation Results:
   Test Loss: 6689.2518
   RMSE: 81.7878, MAE: 65.4158, RÂ²: -0.0068
ğŸ’¾ Test metrics saved to: logs/client_17_test_metrics_20251029_150433.csv

================================================================================
ğŸ¯ FINAL COMPREHENSIVE REPORT
================================================================================
ğŸ’¾ Final summary saved to: logs/client_17_final_summary_20251029_150433.csv

ğŸ“Š CLIENT: client_17 | ALGORITHM: fedavg | MODEL: LSTM
ğŸ“ˆ TOTAL ROUNDS: 10

âš™ï¸  HYPERPARAMETERS:
   Learning Rate: 0.001
   Batch Size: 32
   Local Epochs: 1
   Hidden Dim: 64
   Num Layers: 2
   Sequence Length: 10
   Use Attention: False
   Dropout: 0.3
   Optimizer: adam

ğŸ FINAL ROUND PERFORMANCE:
   Training   - Loss:  6648.64 | RMSE:  81.54 | RÂ²: -0.0214
   Validation - Loss:  6599.67 | RMSE:  81.24 | RÂ²: -0.0260
   Test       - Loss:  6689.25 | RMSE:  81.79 | RÂ²: -0.0068

ğŸ“Š STATISTICS ACROSS ALL ROUNDS (Mean Â± Std):
   Training Loss:    6620.40 Â±  21.98
   Validation Loss:  6568.49 Â±  24.34
   Test Loss:        7063.36 Â± 1104.46

   Training RMSE:    81.37 Â±  0.14
   Validation RMSE:  81.05 Â±  0.15
   Test RMSE:        83.83 Â±  6.01

   Training RÂ²:     -0.0171 Â± 0.0034
   Validation RÂ²:   -0.0211 Â± 0.0038
   Test RÂ²:         -0.0631 Â± 0.1662

â­ BEST PERFORMANCE:
   Best Round: 9 (Test RÂ²: -0.0066)

ğŸ“‹ DATA SUMMARY:
   Training samples:   3436
   Validation samples: 1146
   Test samples:       1146
   Total samples:      5728
================================================================================
âœ… Client client_17 completed | Algorithm: FEDAVG
