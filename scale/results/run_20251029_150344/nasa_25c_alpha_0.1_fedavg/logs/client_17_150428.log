[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ee13c237-213f-409b-9907-62f9564e7cbc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6e5a367a-caea-43af-87e9-d9e6177516c5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f33fb2a5-67dd-4014-b9c4-1ffc3cac24f2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d9041328-b400-474e-9f53-9b319a1fdb08
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2a94e463-baf0-435e-a953-4d964d2c2a1e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3a2b617a-b723-487b-b160-e7952073f452
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 63ec8cd9-5c61-412e-9810-8d07ac687521
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a49742d3-fce7-418a-be4d-b2037ca21919
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e7d5f7da-4b68-4cf7-ab41-0e5cf4e695da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a1a12c7e-40ea-49bc-a6bc-b4bb82c5738a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1edfca20-3c90-47cb-bf37-f228133698d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ba22415a-8eae-4f7f-9b31-4a0a7f5c4cd3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6a2afaf8-4cc6-4b11-9bd0-0198048ad745
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a9c9b6d0-f9b6-4196-9942-0f0e690b5385
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a84f07d8-36ee-4b07-bc3c-0e419aedffe9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 475a97ca-6105-4e2d-8f7f-2efa72074f83
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ee894c7c-e2e3-414a-af75-6db808d0655c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2ee4e58c-598e-4779-97ae-3af25940e20c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8b86a9d2-e1a0-4a61-9364-3fb3cf66b7e5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 102b4e4c-9357-4a5c-a116-9703f8a6fcff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: reconnect message 6964299c-2442-4b3a-b224-4989edecf998
[92mINFO [0m:      Disconnect and shut down
🚀 Starting NASA FL Client: client_17
Algorithm: FEDAVG
Server: localhost:8686
K-Folds: 5
Log Directory: logs
🔄 Using device: cuda
🎯 GPU: NVIDIA A100-SXM4-80GB
💾 Hyperparameters saved to: logs/client_17_hyperparams_20251029_150433.csv
🔍 Looking for data at: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.1/client_17
📊 Loaded 5738 total samples from /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.1/client_17
🔄 Created sequences with length 10
   Final dataset shape: X (5728, 10, 24), y (5728,)
✅ Data split completed:
   Training samples: 3436
   Validation samples: 1146
   Test samples: 1146
   Model type: lstm
✅ Client client_17 ready:
   Model: LSTM
   Training: 3436 samples
   Device: cuda
   Validation: 1146 samples
   Test: 1146 samples
   Algorithm: fedavg
   Total Rounds: 10
   Learning Rate: 0.001
   Batch Size: 32
   Logging to: logs
⏩ Skipping CV for Round 1 (runs every 5 rounds)
Round 1: train_loss=11251.6045, val_loss=11330.7764, val_r2=-0.7615

🧪 Round 1 Evaluation Results:
   Test Loss: 10376.6854
   RMSE: 101.8660, MAE: 78.6053, R²: -0.5617
💾 Test metrics saved to: logs/client_17_test_metrics_20251029_150433.csv
⏩ Skipping CV for Round 2 (runs every 5 rounds)
Round 2: train_loss=6617.0669, val_loss=6564.9453, val_r2=-0.0206
💾 Training metrics saved to: logs/client_17_training_metrics_20251029_150433.csv

🧪 Round 2 Evaluation Results:
   Test Loss: 6712.8384
   RMSE: 81.9319, MAE: 65.4223, R²: -0.0103
💾 Test metrics saved to: logs/client_17_test_metrics_20251029_150433.csv
⏩ Skipping CV for Round 3 (runs every 5 rounds)

🎯 Round 3 Training Results:
   Training - Loss: 6641.7910, RMSE: 81.4972, R²: -0.0204
   Validation - Loss: 6592.1719, RMSE: 81.1922, R²: -0.0248

🧪 Round 3 Evaluation Results:
   Test Loss: 6698.4669
   RMSE: 81.8442, MAE: 65.4127, R²: -0.0081
💾 Test metrics saved to: logs/client_17_test_metrics_20251029_150433.csv
⏩ Skipping CV for Round 4 (runs every 5 rounds)
Round 4: train_loss=6650.0024, val_loss=6601.1729, val_r2=-0.0262
💾 Training metrics saved to: logs/client_17_training_metrics_20251029_150433.csv

🧪 Round 4 Evaluation Results:
   Test Loss: 6696.2845
   RMSE: 81.8308, MAE: 65.4123, R²: -0.0078
💾 Test metrics saved to: logs/client_17_test_metrics_20251029_150433.csv

🔍 Running 3-fold cross-validation (Round 5)

🔍 Starting 3-fold cross-validation on TRAINING data for client client_17

📊 Fold 1/3
   Fold 1 Results:
     Val Loss: 6266.8359
     Val RMSE: 79.1633, Val R²: -0.0016

📊 Fold 2/3
   Fold 2 Results:
     Val Loss: 6990.9507
     Val RMSE: 83.6119, Val R²: -0.0181

📊 Fold 3/3
   Fold 3 Results:
     Val Loss: 6406.4443
     Val RMSE: 80.0403, Val R²: -0.0019
💾 CV metrics saved to: logs/client_17_cv_metrics_20251029_150433.csv

📈 3-Fold CV Summary (Training Data):
   VAL_LOSS: 6554.7437 ± 313.6665
   RMSE: 80.9385 ± 1.9240
   R2: -0.0072 ± 0.0077

🎯 Round 5 Training Results:
   Training - Loss: 6627.8955, RMSE: 81.4119, R²: -0.0182
   Validation - Loss: 6576.8857, RMSE: 81.0980, R²: -0.0224
💾 Training metrics saved to: logs/client_17_training_metrics_20251029_150433.csv

🧪 Round 5 Evaluation Results:
   Test Loss: 6693.2083
   RMSE: 81.8120, MAE: 65.4138, R²: -0.0074
💾 Test metrics saved to: logs/client_17_test_metrics_20251029_150433.csv
⏩ Skipping CV for Round 6 (runs every 5 rounds)

🎯 Round 6 Training Results:
   Training - Loss: 6603.5752, RMSE: 81.2624, R²: -0.0145
   Validation - Loss: 6549.9136, RMSE: 80.9315, R²: -0.0182
💾 Training metrics saved to: logs/client_17_training_metrics_20251029_150433.csv

🧪 Round 6 Evaluation Results:
   Test Loss: 6692.1365
   RMSE: 81.8055, MAE: 65.4144, R²: -0.0072
💾 Test metrics saved to: logs/client_17_test_metrics_20251029_150433.csv
⏩ Skipping CV for Round 7 (runs every 5 rounds)
Round 7: train_loss=6643.6460, val_loss=6594.2061, val_r2=-0.0251

🧪 Round 7 Evaluation Results:
   Test Loss: 6692.4115
   RMSE: 81.8072, MAE: 65.4142, R²: -0.0072
💾 Test metrics saved to: logs/client_17_test_metrics_20251029_150433.csv
⏩ Skipping CV for Round 8 (runs every 5 rounds)
Round 8: train_loss=6584.8530, val_loss=6528.9058, val_r2=-0.0150
💾 Training metrics saved to: logs/client_17_training_metrics_20251029_150433.csv

🧪 Round 8 Evaluation Results:
   Test Loss: 6694.1733
   RMSE: 81.8179, MAE: 65.4133, R²: -0.0075
💾 Test metrics saved to: logs/client_17_test_metrics_20251029_150433.csv

🔍 Running 3-fold cross-validation (Round 9)
💾 CV metrics saved to: logs/client_17_cv_metrics_20251029_150433.csv

🎯 Round 9 Training Results:
   Training - Loss: 6610.7671, RMSE: 81.3066, R²: -0.0156
   Validation - Loss: 6557.9199, RMSE: 80.9810, R²: -0.0195
💾 Training metrics saved to: logs/client_17_training_metrics_20251029_150433.csv

🧪 Round 9 Evaluation Results:
   Test Loss: 6688.1640
   RMSE: 81.7812, MAE: 65.4164, R²: -0.0066
💾 Test metrics saved to: logs/client_17_test_metrics_20251029_150433.csv

🔍 Running 3-fold cross-validation (Round 10)
💾 CV metrics saved to: logs/client_17_cv_metrics_20251029_150433.csv

🎯 Round 10 Training Results:
   Training - Loss: 6648.6387, RMSE: 81.5392, R²: -0.0214
   Validation - Loss: 6599.6743, RMSE: 81.2384, R²: -0.0260
💾 Training metrics saved to: logs/client_17_training_metrics_20251029_150433.csv

🧪 Round 10 Evaluation Results:
   Test Loss: 6689.2518
   RMSE: 81.7878, MAE: 65.4158, R²: -0.0068
💾 Test metrics saved to: logs/client_17_test_metrics_20251029_150433.csv

================================================================================
🎯 FINAL COMPREHENSIVE REPORT
================================================================================
💾 Final summary saved to: logs/client_17_final_summary_20251029_150433.csv

📊 CLIENT: client_17 | ALGORITHM: fedavg | MODEL: LSTM
📈 TOTAL ROUNDS: 10

⚙️  HYPERPARAMETERS:
   Learning Rate: 0.001
   Batch Size: 32
   Local Epochs: 1
   Hidden Dim: 64
   Num Layers: 2
   Sequence Length: 10
   Use Attention: False
   Dropout: 0.3
   Optimizer: adam

🏁 FINAL ROUND PERFORMANCE:
   Training   - Loss:  6648.64 | RMSE:  81.54 | R²: -0.0214
   Validation - Loss:  6599.67 | RMSE:  81.24 | R²: -0.0260
   Test       - Loss:  6689.25 | RMSE:  81.79 | R²: -0.0068

📊 STATISTICS ACROSS ALL ROUNDS (Mean ± Std):
   Training Loss:    6620.40 ±  21.98
   Validation Loss:  6568.49 ±  24.34
   Test Loss:        7063.36 ± 1104.46

   Training RMSE:    81.37 ±  0.14
   Validation RMSE:  81.05 ±  0.15
   Test RMSE:        83.83 ±  6.01

   Training R²:     -0.0171 ± 0.0034
   Validation R²:   -0.0211 ± 0.0038
   Test R²:         -0.0631 ± 0.1662

⭐ BEST PERFORMANCE:
   Best Round: 9 (Test R²: -0.0066)

📋 DATA SUMMARY:
   Training samples:   3436
   Validation samples: 1146
   Test samples:       1146
   Total samples:      5728
================================================================================
✅ Client client_17 completed | Algorithm: FEDAVG
