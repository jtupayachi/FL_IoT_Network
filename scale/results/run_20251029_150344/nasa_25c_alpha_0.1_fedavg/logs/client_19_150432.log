[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 191157c2-60ff-4cfd-96c9-eaa3f955effc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8d70ca4c-b406-48bc-b667-3c2b0effa381
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3c41cb29-8720-43eb-bd31-3d6c3b8ebc98
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 96f4bcd8-461a-435e-a31a-3be4d7048e8e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3c5bad67-6ccc-4dc4-842b-e2fec6429a74
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0c638283-5d75-4fb2-a47c-65fee5106ed4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cb00ee2e-8e25-413f-84ad-8310c61eb245
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 68b22574-c1df-4cc5-891b-39d9b931b4cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 30251bbc-96af-4590-95c0-0741269329d1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 509168fe-36f7-40a6-b239-25e72634e848
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8545029c-74c6-4983-9070-dcf984436928
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dd0ebe29-700a-4341-b344-c3a55531a382
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8588e26b-1a11-482c-978d-4e36e770dd68
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 61bc54fe-c9f4-4b07-a972-c4cf5dad6def
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 98332a79-169e-4e34-85a7-c6aebfb70b2e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8be0b089-3381-4090-9412-ae3c00e985ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4768ff9d-1379-4b00-a071-c1fef13e5d80
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 22cf9159-e87a-4285-9b00-7ad933cf52b9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 151ed7fb-4ae7-4755-a3b3-a2fda762a98d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: reconnect message 31f652d0-9328-43a9-aa7e-62975668b741
[92mINFO [0m:      Disconnect and shut down
ğŸš€ Starting NASA FL Client: client_19
Algorithm: FEDAVG
Server: localhost:8686
K-Folds: 5
Log Directory: logs
ğŸ”„ Using device: cuda
ğŸ¯ GPU: NVIDIA A100-SXM4-80GB
ğŸ’¾ Hyperparameters saved to: logs/client_19_hyperparams_20251029_150437.csv
ğŸ” Looking for data at: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.1/client_19
ğŸ“Š Loaded 8316 total samples from /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.1/client_19
ğŸ”„ Created sequences with length 10
   Final dataset shape: X (8306, 10, 24), y (8306,)
âœ… Data split completed:
   Training samples: 4983
   Validation samples: 1661
   Test samples: 1662
   Model type: lstm
âœ… Client client_19 ready:
   Model: LSTM
   Training: 4983 samples
   Device: cuda
   Validation: 1661 samples
   Test: 1662 samples
   Algorithm: fedavg
   Total Rounds: 10
   Learning Rate: 0.001
   Batch Size: 32
   Logging to: logs

ğŸ§ª Round 0 Evaluation Results:
   Test Loss: 12922.4994
   RMSE: 113.6772, MAE: 87.2072, RÂ²: -0.6731
ğŸ’¾ Test metrics saved to: logs/client_19_test_metrics_20251029_150437.csv
â© Skipping CV for Round 2 (runs every 5 rounds)
Round 2: train_loss=8762.9707, val_loss=8874.8613, val_r2=-0.0075
ğŸ’¾ Training metrics saved to: logs/client_19_training_metrics_20251029_150437.csv

ğŸ§ª Round 2 Evaluation Results:
   Test Loss: 8095.7752
   RMSE: 89.9765, MAE: 73.0663, RÂ²: -0.0482
ğŸ’¾ Test metrics saved to: logs/client_19_test_metrics_20251029_150437.csv
â© Skipping CV for Round 3 (runs every 5 rounds)

ğŸ¯ Round 3 Training Results:
   Training - Loss: 8771.0537, RMSE: 93.6539, RÂ²: -0.0100
   Validation - Loss: 8882.2588, RMSE: 94.2457, RÂ²: -0.0083

ğŸ§ª Round 3 Evaluation Results:
   Test Loss: 8061.1689
   RMSE: 89.7840, MAE: 73.0209, RÂ²: -0.0437
ğŸ’¾ Test metrics saved to: logs/client_19_test_metrics_20251029_150437.csv
â© Skipping CV for Round 4 (runs every 5 rounds)
Round 4: train_loss=8785.5264, val_loss=8895.5889, val_r2=-0.0098
ğŸ’¾ Training metrics saved to: logs/client_19_training_metrics_20251029_150437.csv

ğŸ§ª Round 4 Evaluation Results:
   Test Loss: 8055.6882
   RMSE: 89.7535, MAE: 73.0139, RÂ²: -0.0430
ğŸ’¾ Test metrics saved to: logs/client_19_test_metrics_20251029_150437.csv

ğŸ” Running 3-fold cross-validation (Round 5)

ğŸ” Starting 3-fold cross-validation on TRAINING data for client client_19

ğŸ“Š Fold 1/3
   Fold 1 Results:
     Val Loss: 8360.5186
     Val RMSE: 91.4359, Val RÂ²: -0.0134

ğŸ“Š Fold 2/3
   Fold 2 Results:
     Val Loss: 9048.8809
     Val RMSE: 95.1256, Val RÂ²: -0.0049

ğŸ“Š Fold 3/3
   Fold 3 Results:
     Val Loss: 8797.3604
     Val RMSE: 93.7942, Val RÂ²: -0.0006
ğŸ’¾ CV metrics saved to: logs/client_19_cv_metrics_20251029_150437.csv

ğŸ“ˆ 3-Fold CV Summary (Training Data):
   VAL_LOSS: 8735.5866 Â± 284.3972
   RMSE: 93.4519 Â± 1.5257
   R2: -0.0063 Â± 0.0053

ğŸ¯ Round 5 Training Results:
   Training - Loss: 8703.0449, RMSE: 93.2901, RÂ²: -0.0022
   Validation - Loss: 8821.8877, RMSE: 93.9249, RÂ²: -0.0014
ğŸ’¾ Training metrics saved to: logs/client_19_training_metrics_20251029_150437.csv

ğŸ§ª Round 5 Evaluation Results:
   Test Loss: 8047.8416
   RMSE: 89.7098, MAE: 73.0046, RÂ²: -0.0420
ğŸ’¾ Test metrics saved to: logs/client_19_test_metrics_20251029_150437.csv
â© Skipping CV for Round 6 (runs every 5 rounds)

ğŸ¯ Round 6 Training Results:
   Training - Loss: 8768.7100, RMSE: 93.6414, RÂ²: -0.0097
   Validation - Loss: 8880.1133, RMSE: 94.2344, RÂ²: -0.0081
ğŸ’¾ Training metrics saved to: logs/client_19_training_metrics_20251029_150437.csv

ğŸ§ª Round 6 Evaluation Results:
   Test Loss: 8045.0716
   RMSE: 89.6943, MAE: 73.0012, RÂ²: -0.0416
ğŸ’¾ Test metrics saved to: logs/client_19_test_metrics_20251029_150437.csv
â© Skipping CV for Round 7 (runs every 5 rounds)
Round 7: train_loss=8748.2676, val_loss=8861.4932, val_r2=-0.0059

ğŸ§ª Round 7 Evaluation Results:
   Test Loss: 8045.7835
   RMSE: 89.6983, MAE: 73.0021, RÂ²: -0.0417
ğŸ’¾ Test metrics saved to: logs/client_19_test_metrics_20251029_150437.csv
â© Skipping CV for Round 8 (runs every 5 rounds)
Round 8: train_loss=8776.4072, val_loss=8887.1816, val_r2=-0.0089
ğŸ’¾ Training metrics saved to: logs/client_19_training_metrics_20251029_150437.csv

ğŸ§ª Round 8 Evaluation Results:
   Test Loss: 8050.3154
   RMSE: 89.7236, MAE: 73.0075, RÂ²: -0.0423
ğŸ’¾ Test metrics saved to: logs/client_19_test_metrics_20251029_150437.csv

ğŸ” Running 3-fold cross-validation (Round 9)
ğŸ’¾ CV metrics saved to: logs/client_19_cv_metrics_20251029_150437.csv

ğŸ¯ Round 9 Training Results:
   Training - Loss: 8729.5986, RMSE: 93.4323, RÂ²: -0.0052
   Validation - Loss: 8844.7666, RMSE: 94.0466, RÂ²: -0.0040
ğŸ’¾ Training metrics saved to: logs/client_19_training_metrics_20251029_150437.csv

ğŸ§ª Round 9 Evaluation Results:
   Test Loss: 8034.6348
   RMSE: 89.6361, MAE: 72.9885, RÂ²: -0.0402
ğŸ’¾ Test metrics saved to: logs/client_19_test_metrics_20251029_150437.csv

ğŸ” Running 3-fold cross-validation (Round 10)
ğŸ’¾ CV metrics saved to: logs/client_19_cv_metrics_20251029_150437.csv

ğŸ¯ Round 10 Training Results:
   Training - Loss: 8739.8818, RMSE: 93.4873, RÂ²: -0.0064
   Validation - Loss: 8853.9414, RMSE: 94.0954, RÂ²: -0.0051
ğŸ’¾ Training metrics saved to: logs/client_19_training_metrics_20251029_150437.csv

ğŸ§ª Round 10 Evaluation Results:
   Test Loss: 8037.5185
   RMSE: 89.6522, MAE: 72.9921, RÂ²: -0.0406
ğŸ’¾ Test metrics saved to: logs/client_19_test_metrics_20251029_150437.csv

================================================================================
ğŸ¯ FINAL COMPREHENSIVE REPORT
================================================================================
ğŸ’¾ Final summary saved to: logs/client_19_final_summary_20251029_150437.csv

ğŸ“Š CLIENT: client_19 | ALGORITHM: fedavg | MODEL: LSTM
ğŸ“ˆ TOTAL ROUNDS: 10

âš™ï¸  HYPERPARAMETERS:
   Learning Rate: 0.001
   Batch Size: 32
   Local Epochs: 1
   Hidden Dim: 64
   Num Layers: 2
   Sequence Length: 10
   Use Attention: False
   Dropout: 0.3
   Optimizer: adam

ğŸ FINAL ROUND PERFORMANCE:
   Training   - Loss:  8739.88 | RMSE:  93.49 | RÂ²: -0.0064
   Validation - Loss:  8853.94 | RMSE:  94.10 | RÂ²: -0.0051
   Test       - Loss:  8037.52 | RMSE:  89.65 | RÂ²: -0.0406

ğŸ“Š STATISTICS ACROSS ALL ROUNDS (Mean Â± Std):
   Training Loss:    8752.31 Â±  27.16
   Validation Loss:  8865.48 Â±  24.33
   Test Loss:        8539.63 Â± 1461.05

   Training RMSE:    93.55 Â±  0.15
   Validation RMSE:  94.16 Â±  0.13
   Test RMSE:        92.13 Â±  7.18

   Training RÂ²:     -0.0078 Â± 0.0031
   Validation RÂ²:   -0.0064 Â± 0.0028
   Test RÂ²:         -0.1056 Â± 0.1892

â­ BEST PERFORMANCE:
   Best Round: 9 (Test RÂ²: -0.0402)

ğŸ“‹ DATA SUMMARY:
   Training samples:   4983
   Validation samples: 1661
   Test samples:       1662
   Total samples:      8306
================================================================================
âœ… Client client_19 completed | Algorithm: FEDAVG
