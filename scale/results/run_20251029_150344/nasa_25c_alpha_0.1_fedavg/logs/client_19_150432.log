[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 191157c2-60ff-4cfd-96c9-eaa3f955effc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8d70ca4c-b406-48bc-b667-3c2b0effa381
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3c41cb29-8720-43eb-bd31-3d6c3b8ebc98
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 96f4bcd8-461a-435e-a31a-3be4d7048e8e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3c5bad67-6ccc-4dc4-842b-e2fec6429a74
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0c638283-5d75-4fb2-a47c-65fee5106ed4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cb00ee2e-8e25-413f-84ad-8310c61eb245
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 68b22574-c1df-4cc5-891b-39d9b931b4cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 30251bbc-96af-4590-95c0-0741269329d1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 509168fe-36f7-40a6-b239-25e72634e848
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8545029c-74c6-4983-9070-dcf984436928
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dd0ebe29-700a-4341-b344-c3a55531a382
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8588e26b-1a11-482c-978d-4e36e770dd68
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 61bc54fe-c9f4-4b07-a972-c4cf5dad6def
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 98332a79-169e-4e34-85a7-c6aebfb70b2e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8be0b089-3381-4090-9412-ae3c00e985ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4768ff9d-1379-4b00-a071-c1fef13e5d80
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 22cf9159-e87a-4285-9b00-7ad933cf52b9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 151ed7fb-4ae7-4755-a3b3-a2fda762a98d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: reconnect message 31f652d0-9328-43a9-aa7e-62975668b741
[92mINFO [0m:      Disconnect and shut down
🚀 Starting NASA FL Client: client_19
Algorithm: FEDAVG
Server: localhost:8686
K-Folds: 5
Log Directory: logs
🔄 Using device: cuda
🎯 GPU: NVIDIA A100-SXM4-80GB
💾 Hyperparameters saved to: logs/client_19_hyperparams_20251029_150437.csv
🔍 Looking for data at: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.1/client_19
📊 Loaded 8316 total samples from /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.1/client_19
🔄 Created sequences with length 10
   Final dataset shape: X (8306, 10, 24), y (8306,)
✅ Data split completed:
   Training samples: 4983
   Validation samples: 1661
   Test samples: 1662
   Model type: lstm
✅ Client client_19 ready:
   Model: LSTM
   Training: 4983 samples
   Device: cuda
   Validation: 1661 samples
   Test: 1662 samples
   Algorithm: fedavg
   Total Rounds: 10
   Learning Rate: 0.001
   Batch Size: 32
   Logging to: logs

🧪 Round 0 Evaluation Results:
   Test Loss: 12922.4994
   RMSE: 113.6772, MAE: 87.2072, R²: -0.6731
💾 Test metrics saved to: logs/client_19_test_metrics_20251029_150437.csv
⏩ Skipping CV for Round 2 (runs every 5 rounds)
Round 2: train_loss=8762.9707, val_loss=8874.8613, val_r2=-0.0075
💾 Training metrics saved to: logs/client_19_training_metrics_20251029_150437.csv

🧪 Round 2 Evaluation Results:
   Test Loss: 8095.7752
   RMSE: 89.9765, MAE: 73.0663, R²: -0.0482
💾 Test metrics saved to: logs/client_19_test_metrics_20251029_150437.csv
⏩ Skipping CV for Round 3 (runs every 5 rounds)

🎯 Round 3 Training Results:
   Training - Loss: 8771.0537, RMSE: 93.6539, R²: -0.0100
   Validation - Loss: 8882.2588, RMSE: 94.2457, R²: -0.0083

🧪 Round 3 Evaluation Results:
   Test Loss: 8061.1689
   RMSE: 89.7840, MAE: 73.0209, R²: -0.0437
💾 Test metrics saved to: logs/client_19_test_metrics_20251029_150437.csv
⏩ Skipping CV for Round 4 (runs every 5 rounds)
Round 4: train_loss=8785.5264, val_loss=8895.5889, val_r2=-0.0098
💾 Training metrics saved to: logs/client_19_training_metrics_20251029_150437.csv

🧪 Round 4 Evaluation Results:
   Test Loss: 8055.6882
   RMSE: 89.7535, MAE: 73.0139, R²: -0.0430
💾 Test metrics saved to: logs/client_19_test_metrics_20251029_150437.csv

🔍 Running 3-fold cross-validation (Round 5)

🔍 Starting 3-fold cross-validation on TRAINING data for client client_19

📊 Fold 1/3
   Fold 1 Results:
     Val Loss: 8360.5186
     Val RMSE: 91.4359, Val R²: -0.0134

📊 Fold 2/3
   Fold 2 Results:
     Val Loss: 9048.8809
     Val RMSE: 95.1256, Val R²: -0.0049

📊 Fold 3/3
   Fold 3 Results:
     Val Loss: 8797.3604
     Val RMSE: 93.7942, Val R²: -0.0006
💾 CV metrics saved to: logs/client_19_cv_metrics_20251029_150437.csv

📈 3-Fold CV Summary (Training Data):
   VAL_LOSS: 8735.5866 ± 284.3972
   RMSE: 93.4519 ± 1.5257
   R2: -0.0063 ± 0.0053

🎯 Round 5 Training Results:
   Training - Loss: 8703.0449, RMSE: 93.2901, R²: -0.0022
   Validation - Loss: 8821.8877, RMSE: 93.9249, R²: -0.0014
💾 Training metrics saved to: logs/client_19_training_metrics_20251029_150437.csv

🧪 Round 5 Evaluation Results:
   Test Loss: 8047.8416
   RMSE: 89.7098, MAE: 73.0046, R²: -0.0420
💾 Test metrics saved to: logs/client_19_test_metrics_20251029_150437.csv
⏩ Skipping CV for Round 6 (runs every 5 rounds)

🎯 Round 6 Training Results:
   Training - Loss: 8768.7100, RMSE: 93.6414, R²: -0.0097
   Validation - Loss: 8880.1133, RMSE: 94.2344, R²: -0.0081
💾 Training metrics saved to: logs/client_19_training_metrics_20251029_150437.csv

🧪 Round 6 Evaluation Results:
   Test Loss: 8045.0716
   RMSE: 89.6943, MAE: 73.0012, R²: -0.0416
💾 Test metrics saved to: logs/client_19_test_metrics_20251029_150437.csv
⏩ Skipping CV for Round 7 (runs every 5 rounds)
Round 7: train_loss=8748.2676, val_loss=8861.4932, val_r2=-0.0059

🧪 Round 7 Evaluation Results:
   Test Loss: 8045.7835
   RMSE: 89.6983, MAE: 73.0021, R²: -0.0417
💾 Test metrics saved to: logs/client_19_test_metrics_20251029_150437.csv
⏩ Skipping CV for Round 8 (runs every 5 rounds)
Round 8: train_loss=8776.4072, val_loss=8887.1816, val_r2=-0.0089
💾 Training metrics saved to: logs/client_19_training_metrics_20251029_150437.csv

🧪 Round 8 Evaluation Results:
   Test Loss: 8050.3154
   RMSE: 89.7236, MAE: 73.0075, R²: -0.0423
💾 Test metrics saved to: logs/client_19_test_metrics_20251029_150437.csv

🔍 Running 3-fold cross-validation (Round 9)
💾 CV metrics saved to: logs/client_19_cv_metrics_20251029_150437.csv

🎯 Round 9 Training Results:
   Training - Loss: 8729.5986, RMSE: 93.4323, R²: -0.0052
   Validation - Loss: 8844.7666, RMSE: 94.0466, R²: -0.0040
💾 Training metrics saved to: logs/client_19_training_metrics_20251029_150437.csv

🧪 Round 9 Evaluation Results:
   Test Loss: 8034.6348
   RMSE: 89.6361, MAE: 72.9885, R²: -0.0402
💾 Test metrics saved to: logs/client_19_test_metrics_20251029_150437.csv

🔍 Running 3-fold cross-validation (Round 10)
💾 CV metrics saved to: logs/client_19_cv_metrics_20251029_150437.csv

🎯 Round 10 Training Results:
   Training - Loss: 8739.8818, RMSE: 93.4873, R²: -0.0064
   Validation - Loss: 8853.9414, RMSE: 94.0954, R²: -0.0051
💾 Training metrics saved to: logs/client_19_training_metrics_20251029_150437.csv

🧪 Round 10 Evaluation Results:
   Test Loss: 8037.5185
   RMSE: 89.6522, MAE: 72.9921, R²: -0.0406
💾 Test metrics saved to: logs/client_19_test_metrics_20251029_150437.csv

================================================================================
🎯 FINAL COMPREHENSIVE REPORT
================================================================================
💾 Final summary saved to: logs/client_19_final_summary_20251029_150437.csv

📊 CLIENT: client_19 | ALGORITHM: fedavg | MODEL: LSTM
📈 TOTAL ROUNDS: 10

⚙️  HYPERPARAMETERS:
   Learning Rate: 0.001
   Batch Size: 32
   Local Epochs: 1
   Hidden Dim: 64
   Num Layers: 2
   Sequence Length: 10
   Use Attention: False
   Dropout: 0.3
   Optimizer: adam

🏁 FINAL ROUND PERFORMANCE:
   Training   - Loss:  8739.88 | RMSE:  93.49 | R²: -0.0064
   Validation - Loss:  8853.94 | RMSE:  94.10 | R²: -0.0051
   Test       - Loss:  8037.52 | RMSE:  89.65 | R²: -0.0406

📊 STATISTICS ACROSS ALL ROUNDS (Mean ± Std):
   Training Loss:    8752.31 ±  27.16
   Validation Loss:  8865.48 ±  24.33
   Test Loss:        8539.63 ± 1461.05

   Training RMSE:    93.55 ±  0.15
   Validation RMSE:  94.16 ±  0.13
   Test RMSE:        92.13 ±  7.18

   Training R²:     -0.0078 ± 0.0031
   Validation R²:   -0.0064 ± 0.0028
   Test R²:         -0.1056 ± 0.1892

⭐ BEST PERFORMANCE:
   Best Round: 9 (Test R²: -0.0402)

📋 DATA SUMMARY:
   Training samples:   4983
   Validation samples: 1661
   Test samples:       1662
   Total samples:      8306
================================================================================
✅ Client client_19 completed | Algorithm: FEDAVG
