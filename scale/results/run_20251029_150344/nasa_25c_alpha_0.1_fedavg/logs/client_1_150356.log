[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 096542db-0503-48e3-b92f-2a89974fd36f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9dcc75a5-7afd-42e5-94b7-caf68c475fa3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 36b6a8a2-06b4-474b-80e8-11695ec9b411
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8e272dd3-0232-41fd-a879-88fe18025f54
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 813706fa-e1fb-4bcb-89ea-a54f3a3fe78d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d8c34a17-94b2-401e-b9a5-b4d601aa4106
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9ea8a5c8-8a52-4e58-8622-005bab5f931f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3076ae25-24bf-4342-8bf2-938abd0d2315
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b716fab9-2efc-484a-a405-08f0adc934e9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e0930d1e-b864-4812-a805-aeaaffd5b99c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7c2d9667-9961-4ec6-86ea-c0513c062600
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4f091638-6cbb-4a5a-b607-4e73f133d696
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d6a21d9d-3785-4bd4-b974-8d4969feabd5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9bf3ff48-a1a9-4c1d-a63d-16281f6294db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3bedcd7a-fefa-40af-b54f-3b75d223f923
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ce7824d4-0c07-4bb9-9d1a-a331739f3669
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5683ec90-f07c-443a-897a-91228260ad97
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a6539225-769e-423e-9b12-2cde9b473f9b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d04ef913-1250-4d1d-b363-6e309bbcbbda
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 11cc7f01-350b-4cee-9ded-594b78fbd852
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: reconnect message ae386bf5-3e8a-4a2a-b6a7-747d82cab858
[92mINFO [0m:      Disconnect and shut down
ğŸš€ Starting NASA FL Client: client_1
Algorithm: FEDAVG
Server: localhost:8686
K-Folds: 5
Log Directory: logs
ğŸ”„ Using device: cuda
ğŸ¯ GPU: NVIDIA A100-SXM4-80GB
ğŸ’¾ Hyperparameters saved to: logs/client_1_hyperparams_20251029_150409.csv
ğŸ” Looking for data at: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.1/client_1
ğŸ“Š Loaded 5645 total samples from /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.1/client_1
ğŸ”„ Created sequences with length 10
   Final dataset shape: X (5635, 10, 24), y (5635,)
âœ… Data split completed:
   Training samples: 3381
   Validation samples: 1127
   Test samples: 1127
   Model type: lstm
âœ… Client client_1 ready:
   Model: LSTM
   Training: 3381 samples
   Device: cuda
   Validation: 1127 samples
   Test: 1127 samples
   Algorithm: fedavg
   Total Rounds: 10
   Learning Rate: 0.001
   Batch Size: 32
   Logging to: logs
â© Skipping CV for Round 1 (runs every 5 rounds)
Round 1: train_loss=9624.2021, val_loss=9160.9150, val_r2=-0.7743

ğŸ§ª Round 1 Evaluation Results:
   Test Loss: 7462.5688
   RMSE: 86.3862, MAE: 67.3758, RÂ²: -0.4691
ğŸ’¾ Test metrics saved to: logs/client_1_test_metrics_20251029_150409.csv
â© Skipping CV for Round 2 (runs every 5 rounds)
Round 2: train_loss=5339.0181, val_loss=5167.6494, val_r2=-0.0009
ğŸ’¾ Training metrics saved to: logs/client_1_training_metrics_20251029_150409.csv

ğŸ§ª Round 2 Evaluation Results:
   Test Loss: 5095.5800
   RMSE: 71.3833, MAE: 58.1969, RÂ²: -0.0031
ğŸ’¾ Test metrics saved to: logs/client_1_test_metrics_20251029_150409.csv
â© Skipping CV for Round 3 (runs every 5 rounds)

ğŸ¯ Round 3 Training Results:
   Training - Loss: 5330.6504, RMSE: 73.0113, RÂ²: -0.0023
   Validation - Loss: 5164.2886, RMSE: 71.8630, RÂ²: -0.0002

ğŸ§ª Round 3 Evaluation Results:
   Test Loss: 5103.7768
   RMSE: 71.4407, MAE: 58.2515, RÂ²: -0.0048
ğŸ’¾ Test metrics saved to: logs/client_1_test_metrics_20251029_150409.csv
â© Skipping CV for Round 4 (runs every 5 rounds)
Round 4: train_loss=5351.0693, val_loss=5174.0654, val_r2=-0.0021
ğŸ’¾ Training metrics saved to: logs/client_1_training_metrics_20251029_150409.csv

ğŸ§ª Round 4 Evaluation Results:
   Test Loss: 5105.2729
   RMSE: 71.4512, MAE: 58.2611, RÂ²: -0.0051
ğŸ’¾ Test metrics saved to: logs/client_1_test_metrics_20251029_150409.csv

ğŸ” Running 3-fold cross-validation (Round 5)

ğŸ” Starting 3-fold cross-validation on TRAINING data for client client_1

ğŸ“Š Fold 1/3
   Fold 1 Results:
     Val Loss: 5142.2715
     Val RMSE: 71.7096, Val RÂ²: -0.0081

ğŸ“Š Fold 2/3
   Fold 2 Results:
     Val Loss: 5529.3877
     Val RMSE: 74.3599, Val RÂ²: -0.0130

ğŸ“Š Fold 3/3
   Fold 3 Results:
     Val Loss: 5530.8486
     Val RMSE: 74.3697, Val RÂ²: -0.0255
ğŸ’¾ CV metrics saved to: logs/client_1_cv_metrics_20251029_150409.csv

ğŸ“ˆ 3-Fold CV Summary (Training Data):
   VAL_LOSS: 5400.8359 Â± 182.8337
   RMSE: 73.4797 Â± 1.2516
   R2: -0.0155 Â± 0.0073

ğŸ¯ Round 5 Training Results:
   Training - Loss: 5324.8955, RMSE: 72.9719, RÂ²: -0.0012
   Validation - Loss: 5163.1348, RMSE: 71.8550, RÂ²: -0.0000
ğŸ’¾ Training metrics saved to: logs/client_1_training_metrics_20251029_150409.csv

ğŸ§ª Round 5 Evaluation Results:
   Test Loss: 5107.5158
   RMSE: 71.4669, MAE: 58.2763, RÂ²: -0.0055
ğŸ’¾ Test metrics saved to: logs/client_1_test_metrics_20251029_150409.csv
â© Skipping CV for Round 6 (runs every 5 rounds)

ğŸ¯ Round 6 Training Results:
   Training - Loss: 5333.0254, RMSE: 73.0276, RÂ²: -0.0027
   Validation - Loss: 5165.1021, RMSE: 71.8686, RÂ²: -0.0004
ğŸ’¾ Training metrics saved to: logs/client_1_training_metrics_20251029_150409.csv

ğŸ§ª Round 6 Evaluation Results:
   Test Loss: 5108.3367
   RMSE: 71.4726, MAE: 58.2817, RÂ²: -0.0057
ğŸ’¾ Test metrics saved to: logs/client_1_test_metrics_20251029_150409.csv
â© Skipping CV for Round 7 (runs every 5 rounds)
Round 7: train_loss=5325.1860, val_loss=5163.1509, val_r2=-0.0000

ğŸ§ª Round 7 Evaluation Results:
   Test Loss: 5108.1242
   RMSE: 71.4711, MAE: 58.2803, RÂ²: -0.0056
ğŸ’¾ Test metrics saved to: logs/client_1_test_metrics_20251029_150409.csv
â© Skipping CV for Round 8 (runs every 5 rounds)
Round 8: train_loss=5348.4683, val_loss=5172.5776, val_r2=-0.0018
ğŸ’¾ Training metrics saved to: logs/client_1_training_metrics_20251029_150409.csv

ğŸ§ª Round 8 Evaluation Results:
   Test Loss: 5106.7953
   RMSE: 71.4618, MAE: 58.2715, RÂ²: -0.0054
ğŸ’¾ Test metrics saved to: logs/client_1_test_metrics_20251029_150409.csv

ğŸ” Running 3-fold cross-validation (Round 9)
ğŸ’¾ CV metrics saved to: logs/client_1_cv_metrics_20251029_150409.csv

ğŸ¯ Round 9 Training Results:
   Training - Loss: 5347.4985, RMSE: 73.1266, RÂ²: -0.0054
   Validation - Loss: 5172.0356, RMSE: 71.9169, RÂ²: -0.0017
ğŸ’¾ Training metrics saved to: logs/client_1_training_metrics_20251029_150409.csv

ğŸ§ª Round 9 Evaluation Results:
   Test Loss: 5111.5706
   RMSE: 71.4952, MAE: 58.3023, RÂ²: -0.0063
ğŸ’¾ Test metrics saved to: logs/client_1_test_metrics_20251029_150409.csv

ğŸ” Running 3-fold cross-validation (Round 10)
ğŸ’¾ CV metrics saved to: logs/client_1_cv_metrics_20251029_150409.csv

ğŸ¯ Round 10 Training Results:
   Training - Loss: 5330.7563, RMSE: 73.0120, RÂ²: -0.0023
   Validation - Loss: 5164.3218, RMSE: 71.8632, RÂ²: -0.0002
ğŸ’¾ Training metrics saved to: logs/client_1_training_metrics_20251029_150409.csv

ğŸ§ª Round 10 Evaluation Results:
   Test Loss: 5110.6543
   RMSE: 71.4888, MAE: 58.2966, RÂ²: -0.0061
ğŸ’¾ Test metrics saved to: logs/client_1_test_metrics_20251029_150409.csv

================================================================================
ğŸ¯ FINAL COMPREHENSIVE REPORT
================================================================================
ğŸ’¾ Final summary saved to: logs/client_1_final_summary_20251029_150409.csv

ğŸ“Š CLIENT: client_1 | ALGORITHM: fedavg | MODEL: LSTM
ğŸ“ˆ TOTAL ROUNDS: 10

âš™ï¸  HYPERPARAMETERS:
   Learning Rate: 0.001
   Batch Size: 32
   Local Epochs: 1
   Hidden Dim: 64
   Num Layers: 2
   Sequence Length: 10
   Use Attention: False
   Dropout: 0.3
   Optimizer: adam

ğŸ FINAL ROUND PERFORMANCE:
   Training   - Loss:  5330.76 | RMSE:  73.01 | RÂ²: -0.0023
   Validation - Loss:  5164.32 | RMSE:  71.86 | RÂ²: -0.0002
   Test       - Loss:  5110.65 | RMSE:  71.49 | RÂ²: -0.0061

ğŸ“Š STATISTICS ACROSS ALL ROUNDS (Mean Â± Std):
   Training Loss:    5339.25 Â±   9.33
   Validation Loss:  5168.41 Â±   4.12
   Test Loss:        5342.02 Â± 706.86

   Training RMSE:    73.07 Â±  0.06
   Validation RMSE:  71.89 Â±  0.03
   Test RMSE:        72.95 Â±  4.48

   Training RÂ²:     -0.0039 Â± 0.0018
   Validation RÂ²:   -0.0010 Â± 0.0008
   Test RÂ²:         -0.0517 Â± 0.1392

â­ BEST PERFORMANCE:
   Best Round: 2 (Test RÂ²: -0.0031)

ğŸ“‹ DATA SUMMARY:
   Training samples:   3381
   Validation samples: 1127
   Test samples:       1127
   Total samples:      5635
================================================================================
âœ… Client client_1 completed | Algorithm: FEDAVG
