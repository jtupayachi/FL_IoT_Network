[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 096542db-0503-48e3-b92f-2a89974fd36f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9dcc75a5-7afd-42e5-94b7-caf68c475fa3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 36b6a8a2-06b4-474b-80e8-11695ec9b411
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8e272dd3-0232-41fd-a879-88fe18025f54
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 813706fa-e1fb-4bcb-89ea-a54f3a3fe78d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d8c34a17-94b2-401e-b9a5-b4d601aa4106
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9ea8a5c8-8a52-4e58-8622-005bab5f931f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3076ae25-24bf-4342-8bf2-938abd0d2315
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b716fab9-2efc-484a-a405-08f0adc934e9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e0930d1e-b864-4812-a805-aeaaffd5b99c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7c2d9667-9961-4ec6-86ea-c0513c062600
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4f091638-6cbb-4a5a-b607-4e73f133d696
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d6a21d9d-3785-4bd4-b974-8d4969feabd5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9bf3ff48-a1a9-4c1d-a63d-16281f6294db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3bedcd7a-fefa-40af-b54f-3b75d223f923
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ce7824d4-0c07-4bb9-9d1a-a331739f3669
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5683ec90-f07c-443a-897a-91228260ad97
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a6539225-769e-423e-9b12-2cde9b473f9b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d04ef913-1250-4d1d-b363-6e309bbcbbda
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 11cc7f01-350b-4cee-9ded-594b78fbd852
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: reconnect message ae386bf5-3e8a-4a2a-b6a7-747d82cab858
[92mINFO [0m:      Disconnect and shut down
🚀 Starting NASA FL Client: client_1
Algorithm: FEDAVG
Server: localhost:8686
K-Folds: 5
Log Directory: logs
🔄 Using device: cuda
🎯 GPU: NVIDIA A100-SXM4-80GB
💾 Hyperparameters saved to: logs/client_1_hyperparams_20251029_150409.csv
🔍 Looking for data at: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.1/client_1
📊 Loaded 5645 total samples from /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.1/client_1
🔄 Created sequences with length 10
   Final dataset shape: X (5635, 10, 24), y (5635,)
✅ Data split completed:
   Training samples: 3381
   Validation samples: 1127
   Test samples: 1127
   Model type: lstm
✅ Client client_1 ready:
   Model: LSTM
   Training: 3381 samples
   Device: cuda
   Validation: 1127 samples
   Test: 1127 samples
   Algorithm: fedavg
   Total Rounds: 10
   Learning Rate: 0.001
   Batch Size: 32
   Logging to: logs
⏩ Skipping CV for Round 1 (runs every 5 rounds)
Round 1: train_loss=9624.2021, val_loss=9160.9150, val_r2=-0.7743

🧪 Round 1 Evaluation Results:
   Test Loss: 7462.5688
   RMSE: 86.3862, MAE: 67.3758, R²: -0.4691
💾 Test metrics saved to: logs/client_1_test_metrics_20251029_150409.csv
⏩ Skipping CV for Round 2 (runs every 5 rounds)
Round 2: train_loss=5339.0181, val_loss=5167.6494, val_r2=-0.0009
💾 Training metrics saved to: logs/client_1_training_metrics_20251029_150409.csv

🧪 Round 2 Evaluation Results:
   Test Loss: 5095.5800
   RMSE: 71.3833, MAE: 58.1969, R²: -0.0031
💾 Test metrics saved to: logs/client_1_test_metrics_20251029_150409.csv
⏩ Skipping CV for Round 3 (runs every 5 rounds)

🎯 Round 3 Training Results:
   Training - Loss: 5330.6504, RMSE: 73.0113, R²: -0.0023
   Validation - Loss: 5164.2886, RMSE: 71.8630, R²: -0.0002

🧪 Round 3 Evaluation Results:
   Test Loss: 5103.7768
   RMSE: 71.4407, MAE: 58.2515, R²: -0.0048
💾 Test metrics saved to: logs/client_1_test_metrics_20251029_150409.csv
⏩ Skipping CV for Round 4 (runs every 5 rounds)
Round 4: train_loss=5351.0693, val_loss=5174.0654, val_r2=-0.0021
💾 Training metrics saved to: logs/client_1_training_metrics_20251029_150409.csv

🧪 Round 4 Evaluation Results:
   Test Loss: 5105.2729
   RMSE: 71.4512, MAE: 58.2611, R²: -0.0051
💾 Test metrics saved to: logs/client_1_test_metrics_20251029_150409.csv

🔍 Running 3-fold cross-validation (Round 5)

🔍 Starting 3-fold cross-validation on TRAINING data for client client_1

📊 Fold 1/3
   Fold 1 Results:
     Val Loss: 5142.2715
     Val RMSE: 71.7096, Val R²: -0.0081

📊 Fold 2/3
   Fold 2 Results:
     Val Loss: 5529.3877
     Val RMSE: 74.3599, Val R²: -0.0130

📊 Fold 3/3
   Fold 3 Results:
     Val Loss: 5530.8486
     Val RMSE: 74.3697, Val R²: -0.0255
💾 CV metrics saved to: logs/client_1_cv_metrics_20251029_150409.csv

📈 3-Fold CV Summary (Training Data):
   VAL_LOSS: 5400.8359 ± 182.8337
   RMSE: 73.4797 ± 1.2516
   R2: -0.0155 ± 0.0073

🎯 Round 5 Training Results:
   Training - Loss: 5324.8955, RMSE: 72.9719, R²: -0.0012
   Validation - Loss: 5163.1348, RMSE: 71.8550, R²: -0.0000
💾 Training metrics saved to: logs/client_1_training_metrics_20251029_150409.csv

🧪 Round 5 Evaluation Results:
   Test Loss: 5107.5158
   RMSE: 71.4669, MAE: 58.2763, R²: -0.0055
💾 Test metrics saved to: logs/client_1_test_metrics_20251029_150409.csv
⏩ Skipping CV for Round 6 (runs every 5 rounds)

🎯 Round 6 Training Results:
   Training - Loss: 5333.0254, RMSE: 73.0276, R²: -0.0027
   Validation - Loss: 5165.1021, RMSE: 71.8686, R²: -0.0004
💾 Training metrics saved to: logs/client_1_training_metrics_20251029_150409.csv

🧪 Round 6 Evaluation Results:
   Test Loss: 5108.3367
   RMSE: 71.4726, MAE: 58.2817, R²: -0.0057
💾 Test metrics saved to: logs/client_1_test_metrics_20251029_150409.csv
⏩ Skipping CV for Round 7 (runs every 5 rounds)
Round 7: train_loss=5325.1860, val_loss=5163.1509, val_r2=-0.0000

🧪 Round 7 Evaluation Results:
   Test Loss: 5108.1242
   RMSE: 71.4711, MAE: 58.2803, R²: -0.0056
💾 Test metrics saved to: logs/client_1_test_metrics_20251029_150409.csv
⏩ Skipping CV for Round 8 (runs every 5 rounds)
Round 8: train_loss=5348.4683, val_loss=5172.5776, val_r2=-0.0018
💾 Training metrics saved to: logs/client_1_training_metrics_20251029_150409.csv

🧪 Round 8 Evaluation Results:
   Test Loss: 5106.7953
   RMSE: 71.4618, MAE: 58.2715, R²: -0.0054
💾 Test metrics saved to: logs/client_1_test_metrics_20251029_150409.csv

🔍 Running 3-fold cross-validation (Round 9)
💾 CV metrics saved to: logs/client_1_cv_metrics_20251029_150409.csv

🎯 Round 9 Training Results:
   Training - Loss: 5347.4985, RMSE: 73.1266, R²: -0.0054
   Validation - Loss: 5172.0356, RMSE: 71.9169, R²: -0.0017
💾 Training metrics saved to: logs/client_1_training_metrics_20251029_150409.csv

🧪 Round 9 Evaluation Results:
   Test Loss: 5111.5706
   RMSE: 71.4952, MAE: 58.3023, R²: -0.0063
💾 Test metrics saved to: logs/client_1_test_metrics_20251029_150409.csv

🔍 Running 3-fold cross-validation (Round 10)
💾 CV metrics saved to: logs/client_1_cv_metrics_20251029_150409.csv

🎯 Round 10 Training Results:
   Training - Loss: 5330.7563, RMSE: 73.0120, R²: -0.0023
   Validation - Loss: 5164.3218, RMSE: 71.8632, R²: -0.0002
💾 Training metrics saved to: logs/client_1_training_metrics_20251029_150409.csv

🧪 Round 10 Evaluation Results:
   Test Loss: 5110.6543
   RMSE: 71.4888, MAE: 58.2966, R²: -0.0061
💾 Test metrics saved to: logs/client_1_test_metrics_20251029_150409.csv

================================================================================
🎯 FINAL COMPREHENSIVE REPORT
================================================================================
💾 Final summary saved to: logs/client_1_final_summary_20251029_150409.csv

📊 CLIENT: client_1 | ALGORITHM: fedavg | MODEL: LSTM
📈 TOTAL ROUNDS: 10

⚙️  HYPERPARAMETERS:
   Learning Rate: 0.001
   Batch Size: 32
   Local Epochs: 1
   Hidden Dim: 64
   Num Layers: 2
   Sequence Length: 10
   Use Attention: False
   Dropout: 0.3
   Optimizer: adam

🏁 FINAL ROUND PERFORMANCE:
   Training   - Loss:  5330.76 | RMSE:  73.01 | R²: -0.0023
   Validation - Loss:  5164.32 | RMSE:  71.86 | R²: -0.0002
   Test       - Loss:  5110.65 | RMSE:  71.49 | R²: -0.0061

📊 STATISTICS ACROSS ALL ROUNDS (Mean ± Std):
   Training Loss:    5339.25 ±   9.33
   Validation Loss:  5168.41 ±   4.12
   Test Loss:        5342.02 ± 706.86

   Training RMSE:    73.07 ±  0.06
   Validation RMSE:  71.89 ±  0.03
   Test RMSE:        72.95 ±  4.48

   Training R²:     -0.0039 ± 0.0018
   Validation R²:   -0.0010 ± 0.0008
   Test R²:         -0.0517 ± 0.1392

⭐ BEST PERFORMANCE:
   Best Round: 2 (Test R²: -0.0031)

📋 DATA SUMMARY:
   Training samples:   3381
   Validation samples: 1127
   Test samples:       1127
   Total samples:      5635
================================================================================
✅ Client client_1 completed | Algorithm: FEDAVG
