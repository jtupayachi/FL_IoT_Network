[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 277f42ec-a29c-4350-a3cf-010d81a2cf4b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8a132ca4-b4ba-483b-8839-e40e1b3c273c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message df1825f7-5306-470f-8c67-31bab01f06ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 958ff157-0799-4541-81a0-3548e77199f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ce7be07a-95d8-4e12-a5e5-3df5ec347f47
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f23612b8-7a83-410f-b91c-7fe97d16c327
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6496bdf6-2195-4a59-9e43-5257172aba35
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c1097c22-3d59-426b-8ef0-2d886a226c0d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d30c5a1b-e511-4292-982c-67039ea63631
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a082f838-4924-4617-b6cb-a2c85f8f10c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 64602843-1a96-4429-a079-b665dd938f25
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d4ee6407-c291-4e66-a1c5-08584173a741
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 34f3b685-3fc5-4108-89ee-a83163f3d3c4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dbd8f4a8-83ee-4116-9754-5914001d9f29
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f8fe6a93-a87e-4254-b374-ac3e3c1aa307
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 70b7de42-1259-48a3-9d08-ebf801c131fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b2b3fa8f-3805-4ee2-970f-bcc4c554ff85
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 859f4106-a528-4c89-9677-ada96a5f7b38
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d0af1d4e-d74a-4d13-ab2e-69c241cb7062
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: reconnect message 05d011e2-5e02-48d5-8103-66332b695ed9
[92mINFO [0m:      Disconnect and shut down
ğŸš€ Starting NASA FL Client: client_21
Algorithm: FEDAVG
Server: localhost:8686
K-Folds: 5
Log Directory: logs
ğŸ”„ Using device: cuda
ğŸ¯ GPU: NVIDIA A100-SXM4-80GB
ğŸ’¾ Hyperparameters saved to: logs/client_21_hyperparams_20251029_150441.csv
ğŸ” Looking for data at: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.1/client_21
ğŸ“Š Loaded 6210 total samples from /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.1/client_21
ğŸ”„ Created sequences with length 10
   Final dataset shape: X (6200, 10, 24), y (6200,)
âœ… Data split completed:
   Training samples: 3720
   Validation samples: 1240
   Test samples: 1240
   Model type: lstm
âœ… Client client_21 ready:
   Model: LSTM
   Training: 3720 samples
   Device: cuda
   Validation: 1240 samples
   Test: 1240 samples
   Algorithm: fedavg
   Total Rounds: 10
   Learning Rate: 0.001
   Batch Size: 32
   Logging to: logs

ğŸ§ª Round 0 Evaluation Results:
   Test Loss: 8691.1949
   RMSE: 93.2266, MAE: 73.0753, RÂ²: -0.6001
ğŸ’¾ Test metrics saved to: logs/client_21_test_metrics_20251029_150441.csv
â© Skipping CV for Round 2 (runs every 5 rounds)
Round 2: train_loss=5947.9507, val_loss=5517.8550, val_r2=-0.0034
ğŸ’¾ Training metrics saved to: logs/client_21_training_metrics_20251029_150441.csv

ğŸ§ª Round 2 Evaluation Results:
   Test Loss: 5449.8929
   RMSE: 73.8234, MAE: 61.7798, RÂ²: -0.0034
ğŸ’¾ Test metrics saved to: logs/client_21_test_metrics_20251029_150441.csv
â© Skipping CV for Round 3 (runs every 5 rounds)

ğŸ¯ Round 3 Training Results:
   Training - Loss: 5914.6792, RMSE: 76.9070, RÂ²: -0.0053
   Validation - Loss: 5502.5864, RMSE: 74.1794, RÂ²: -0.0007

ğŸ§ª Round 3 Evaluation Results:
   Test Loss: 5442.8753
   RMSE: 73.7758, MAE: 61.8065, RÂ²: -0.0021
ğŸ’¾ Test metrics saved to: logs/client_21_test_metrics_20251029_150441.csv
â© Skipping CV for Round 4 (runs every 5 rounds)
Round 4: train_loss=5924.7637, val_loss=5506.4883, val_r2=-0.0014
ğŸ’¾ Training metrics saved to: logs/client_21_training_metrics_20251029_150441.csv

ğŸ§ª Round 4 Evaluation Results:
   Test Loss: 5441.8916
   RMSE: 73.7692, MAE: 61.8113, RÂ²: -0.0019
ğŸ’¾ Test metrics saved to: logs/client_21_test_metrics_20251029_150441.csv

ğŸ” Running 3-fold cross-validation (Round 5)

ğŸ” Starting 3-fold cross-validation on TRAINING data for client client_21

ğŸ“Š Fold 1/3
   Fold 1 Results:
     Val Loss: 5978.4297
     Val RMSE: 77.3203, Val RÂ²: -0.0000

ğŸ“Š Fold 2/3
   Fold 2 Results:
     Val Loss: 5601.8608
     Val RMSE: 74.8456, Val RÂ²: -0.0105

ğŸ“Š Fold 3/3
   Fold 3 Results:
     Val Loss: 6292.2759
     Val RMSE: 79.3239, Val RÂ²: -0.0310
ğŸ’¾ CV metrics saved to: logs/client_21_cv_metrics_20251029_150441.csv

ğŸ“ˆ 3-Fold CV Summary (Training Data):
   VAL_LOSS: 5957.5221 Â± 282.2482
   RMSE: 77.1633 Â± 1.8316
   R2: -0.0139 Â± 0.0129

ğŸ¯ Round 5 Training Results:
   Training - Loss: 5962.8389, RMSE: 77.2194, RÂ²: -0.0135
   Validation - Loss: 5526.2339, RMSE: 74.3386, RÂ²: -0.0050
ğŸ’¾ Training metrics saved to: logs/client_21_training_metrics_20251029_150441.csv

ğŸ§ª Round 5 Evaluation Results:
   Test Loss: 5440.5484
   RMSE: 73.7601, MAE: 61.8190, RÂ²: -0.0016
ğŸ’¾ Test metrics saved to: logs/client_21_test_metrics_20251029_150441.csv
â© Skipping CV for Round 6 (runs every 5 rounds)

ğŸ¯ Round 6 Training Results:
   Training - Loss: 5958.5410, RMSE: 77.1916, RÂ²: -0.0128
   Validation - Loss: 5523.7378, RMSE: 74.3219, RÂ²: -0.0045
ğŸ’¾ Training metrics saved to: logs/client_21_training_metrics_20251029_150441.csv

ğŸ§ª Round 6 Evaluation Results:
   Test Loss: 5440.0931
   RMSE: 73.7570, MAE: 61.8217, RÂ²: -0.0016
ğŸ’¾ Test metrics saved to: logs/client_21_test_metrics_20251029_150441.csv
â© Skipping CV for Round 7 (runs every 5 rounds)
Round 7: train_loss=5943.8862, val_loss=5515.6675, val_r2=-0.0030

ğŸ§ª Round 7 Evaluation Results:
   Test Loss: 5440.2092
   RMSE: 73.7578, MAE: 61.8210, RÂ²: -0.0016
ğŸ’¾ Test metrics saved to: logs/client_21_test_metrics_20251029_150441.csv
â© Skipping CV for Round 8 (runs every 5 rounds)
Round 8: train_loss=5910.5322, val_loss=5501.2817, val_r2=-0.0004
ğŸ’¾ Training metrics saved to: logs/client_21_training_metrics_20251029_150441.csv

ğŸ§ª Round 8 Evaluation Results:
   Test Loss: 5440.9636
   RMSE: 73.7629, MAE: 61.8165, RÂ²: -0.0017
ğŸ’¾ Test metrics saved to: logs/client_21_test_metrics_20251029_150441.csv

ğŸ” Running 3-fold cross-validation (Round 9)
ğŸ’¾ CV metrics saved to: logs/client_21_cv_metrics_20251029_150441.csv

ğŸ¯ Round 9 Training Results:
   Training - Loss: 5934.4839, RMSE: 77.0356, RÂ²: -0.0087
   Validation - Loss: 5510.9160, RMSE: 74.2355, RÂ²: -0.0022
ğŸ’¾ Training metrics saved to: logs/client_21_training_metrics_20251029_150441.csv

ğŸ§ª Round 9 Evaluation Results:
   Test Loss: 5438.4681
   RMSE: 73.7460, MAE: 61.8321, RÂ²: -0.0013
ğŸ’¾ Test metrics saved to: logs/client_21_test_metrics_20251029_150441.csv

ğŸ” Running 3-fold cross-validation (Round 10)
ğŸ’¾ CV metrics saved to: logs/client_21_cv_metrics_20251029_150441.csv

ğŸ¯ Round 10 Training Results:
   Training - Loss: 5945.4097, RMSE: 77.1065, RÂ²: -0.0106
   Validation - Loss: 5516.4839, RMSE: 74.2730, RÂ²: -0.0032
ğŸ’¾ Training metrics saved to: logs/client_21_training_metrics_20251029_150441.csv

ğŸ§ª Round 10 Evaluation Results:
   Test Loss: 5438.9027
   RMSE: 73.7489, MAE: 61.8292, RÂ²: -0.0013
ğŸ’¾ Test metrics saved to: logs/client_21_test_metrics_20251029_150441.csv

================================================================================
ğŸ¯ FINAL COMPREHENSIVE REPORT
================================================================================
ğŸ’¾ Final summary saved to: logs/client_21_final_summary_20251029_150441.csv

ğŸ“Š CLIENT: client_21 | ALGORITHM: fedavg | MODEL: LSTM
ğŸ“ˆ TOTAL ROUNDS: 10

âš™ï¸  HYPERPARAMETERS:
   Learning Rate: 0.001
   Batch Size: 32
   Local Epochs: 1
   Hidden Dim: 64
   Num Layers: 2
   Sequence Length: 10
   Use Attention: False
   Dropout: 0.3
   Optimizer: adam

ğŸ FINAL ROUND PERFORMANCE:
   Training   - Loss:  5945.41 | RMSE:  77.11 | RÂ²: -0.0106
   Validation - Loss:  5516.48 | RMSE:  74.27 | RÂ²: -0.0032
   Test       - Loss:  5438.90 | RMSE:  73.75 | RÂ²: -0.0013

ğŸ“Š STATISTICS ACROSS ALL ROUNDS (Mean Â± Std):
   Training Loss:    5940.65 Â±  17.26
   Validation Loss:  5514.71 Â±   8.36
   Test Loss:        5766.50 Â± 974.90

   Training RMSE:    77.08 Â±  0.11
   Validation RMSE:  74.26 Â±  0.06
   Test RMSE:        75.71 Â±  5.84

   Training RÂ²:     -0.0098 Â± 0.0029
   Validation RÂ²:   -0.0029 Â± 0.0015
   Test RÂ²:         -0.0617 Â± 0.1795

â­ BEST PERFORMANCE:
   Best Round: 9 (Test RÂ²: -0.0013)

ğŸ“‹ DATA SUMMARY:
   Training samples:   3720
   Validation samples: 1240
   Test samples:       1240
   Total samples:      6200
================================================================================
âœ… Client client_21 completed | Algorithm: FEDAVG
