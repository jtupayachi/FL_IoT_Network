[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 277f42ec-a29c-4350-a3cf-010d81a2cf4b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8a132ca4-b4ba-483b-8839-e40e1b3c273c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message df1825f7-5306-470f-8c67-31bab01f06ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 958ff157-0799-4541-81a0-3548e77199f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ce7be07a-95d8-4e12-a5e5-3df5ec347f47
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f23612b8-7a83-410f-b91c-7fe97d16c327
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6496bdf6-2195-4a59-9e43-5257172aba35
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c1097c22-3d59-426b-8ef0-2d886a226c0d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d30c5a1b-e511-4292-982c-67039ea63631
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a082f838-4924-4617-b6cb-a2c85f8f10c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 64602843-1a96-4429-a079-b665dd938f25
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d4ee6407-c291-4e66-a1c5-08584173a741
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 34f3b685-3fc5-4108-89ee-a83163f3d3c4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dbd8f4a8-83ee-4116-9754-5914001d9f29
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f8fe6a93-a87e-4254-b374-ac3e3c1aa307
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 70b7de42-1259-48a3-9d08-ebf801c131fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b2b3fa8f-3805-4ee2-970f-bcc4c554ff85
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 859f4106-a528-4c89-9677-ada96a5f7b38
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d0af1d4e-d74a-4d13-ab2e-69c241cb7062
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: reconnect message 05d011e2-5e02-48d5-8103-66332b695ed9
[92mINFO [0m:      Disconnect and shut down
🚀 Starting NASA FL Client: client_21
Algorithm: FEDAVG
Server: localhost:8686
K-Folds: 5
Log Directory: logs
🔄 Using device: cuda
🎯 GPU: NVIDIA A100-SXM4-80GB
💾 Hyperparameters saved to: logs/client_21_hyperparams_20251029_150441.csv
🔍 Looking for data at: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.1/client_21
📊 Loaded 6210 total samples from /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.1/client_21
🔄 Created sequences with length 10
   Final dataset shape: X (6200, 10, 24), y (6200,)
✅ Data split completed:
   Training samples: 3720
   Validation samples: 1240
   Test samples: 1240
   Model type: lstm
✅ Client client_21 ready:
   Model: LSTM
   Training: 3720 samples
   Device: cuda
   Validation: 1240 samples
   Test: 1240 samples
   Algorithm: fedavg
   Total Rounds: 10
   Learning Rate: 0.001
   Batch Size: 32
   Logging to: logs

🧪 Round 0 Evaluation Results:
   Test Loss: 8691.1949
   RMSE: 93.2266, MAE: 73.0753, R²: -0.6001
💾 Test metrics saved to: logs/client_21_test_metrics_20251029_150441.csv
⏩ Skipping CV for Round 2 (runs every 5 rounds)
Round 2: train_loss=5947.9507, val_loss=5517.8550, val_r2=-0.0034
💾 Training metrics saved to: logs/client_21_training_metrics_20251029_150441.csv

🧪 Round 2 Evaluation Results:
   Test Loss: 5449.8929
   RMSE: 73.8234, MAE: 61.7798, R²: -0.0034
💾 Test metrics saved to: logs/client_21_test_metrics_20251029_150441.csv
⏩ Skipping CV for Round 3 (runs every 5 rounds)

🎯 Round 3 Training Results:
   Training - Loss: 5914.6792, RMSE: 76.9070, R²: -0.0053
   Validation - Loss: 5502.5864, RMSE: 74.1794, R²: -0.0007

🧪 Round 3 Evaluation Results:
   Test Loss: 5442.8753
   RMSE: 73.7758, MAE: 61.8065, R²: -0.0021
💾 Test metrics saved to: logs/client_21_test_metrics_20251029_150441.csv
⏩ Skipping CV for Round 4 (runs every 5 rounds)
Round 4: train_loss=5924.7637, val_loss=5506.4883, val_r2=-0.0014
💾 Training metrics saved to: logs/client_21_training_metrics_20251029_150441.csv

🧪 Round 4 Evaluation Results:
   Test Loss: 5441.8916
   RMSE: 73.7692, MAE: 61.8113, R²: -0.0019
💾 Test metrics saved to: logs/client_21_test_metrics_20251029_150441.csv

🔍 Running 3-fold cross-validation (Round 5)

🔍 Starting 3-fold cross-validation on TRAINING data for client client_21

📊 Fold 1/3
   Fold 1 Results:
     Val Loss: 5978.4297
     Val RMSE: 77.3203, Val R²: -0.0000

📊 Fold 2/3
   Fold 2 Results:
     Val Loss: 5601.8608
     Val RMSE: 74.8456, Val R²: -0.0105

📊 Fold 3/3
   Fold 3 Results:
     Val Loss: 6292.2759
     Val RMSE: 79.3239, Val R²: -0.0310
💾 CV metrics saved to: logs/client_21_cv_metrics_20251029_150441.csv

📈 3-Fold CV Summary (Training Data):
   VAL_LOSS: 5957.5221 ± 282.2482
   RMSE: 77.1633 ± 1.8316
   R2: -0.0139 ± 0.0129

🎯 Round 5 Training Results:
   Training - Loss: 5962.8389, RMSE: 77.2194, R²: -0.0135
   Validation - Loss: 5526.2339, RMSE: 74.3386, R²: -0.0050
💾 Training metrics saved to: logs/client_21_training_metrics_20251029_150441.csv

🧪 Round 5 Evaluation Results:
   Test Loss: 5440.5484
   RMSE: 73.7601, MAE: 61.8190, R²: -0.0016
💾 Test metrics saved to: logs/client_21_test_metrics_20251029_150441.csv
⏩ Skipping CV for Round 6 (runs every 5 rounds)

🎯 Round 6 Training Results:
   Training - Loss: 5958.5410, RMSE: 77.1916, R²: -0.0128
   Validation - Loss: 5523.7378, RMSE: 74.3219, R²: -0.0045
💾 Training metrics saved to: logs/client_21_training_metrics_20251029_150441.csv

🧪 Round 6 Evaluation Results:
   Test Loss: 5440.0931
   RMSE: 73.7570, MAE: 61.8217, R²: -0.0016
💾 Test metrics saved to: logs/client_21_test_metrics_20251029_150441.csv
⏩ Skipping CV for Round 7 (runs every 5 rounds)
Round 7: train_loss=5943.8862, val_loss=5515.6675, val_r2=-0.0030

🧪 Round 7 Evaluation Results:
   Test Loss: 5440.2092
   RMSE: 73.7578, MAE: 61.8210, R²: -0.0016
💾 Test metrics saved to: logs/client_21_test_metrics_20251029_150441.csv
⏩ Skipping CV for Round 8 (runs every 5 rounds)
Round 8: train_loss=5910.5322, val_loss=5501.2817, val_r2=-0.0004
💾 Training metrics saved to: logs/client_21_training_metrics_20251029_150441.csv

🧪 Round 8 Evaluation Results:
   Test Loss: 5440.9636
   RMSE: 73.7629, MAE: 61.8165, R²: -0.0017
💾 Test metrics saved to: logs/client_21_test_metrics_20251029_150441.csv

🔍 Running 3-fold cross-validation (Round 9)
💾 CV metrics saved to: logs/client_21_cv_metrics_20251029_150441.csv

🎯 Round 9 Training Results:
   Training - Loss: 5934.4839, RMSE: 77.0356, R²: -0.0087
   Validation - Loss: 5510.9160, RMSE: 74.2355, R²: -0.0022
💾 Training metrics saved to: logs/client_21_training_metrics_20251029_150441.csv

🧪 Round 9 Evaluation Results:
   Test Loss: 5438.4681
   RMSE: 73.7460, MAE: 61.8321, R²: -0.0013
💾 Test metrics saved to: logs/client_21_test_metrics_20251029_150441.csv

🔍 Running 3-fold cross-validation (Round 10)
💾 CV metrics saved to: logs/client_21_cv_metrics_20251029_150441.csv

🎯 Round 10 Training Results:
   Training - Loss: 5945.4097, RMSE: 77.1065, R²: -0.0106
   Validation - Loss: 5516.4839, RMSE: 74.2730, R²: -0.0032
💾 Training metrics saved to: logs/client_21_training_metrics_20251029_150441.csv

🧪 Round 10 Evaluation Results:
   Test Loss: 5438.9027
   RMSE: 73.7489, MAE: 61.8292, R²: -0.0013
💾 Test metrics saved to: logs/client_21_test_metrics_20251029_150441.csv

================================================================================
🎯 FINAL COMPREHENSIVE REPORT
================================================================================
💾 Final summary saved to: logs/client_21_final_summary_20251029_150441.csv

📊 CLIENT: client_21 | ALGORITHM: fedavg | MODEL: LSTM
📈 TOTAL ROUNDS: 10

⚙️  HYPERPARAMETERS:
   Learning Rate: 0.001
   Batch Size: 32
   Local Epochs: 1
   Hidden Dim: 64
   Num Layers: 2
   Sequence Length: 10
   Use Attention: False
   Dropout: 0.3
   Optimizer: adam

🏁 FINAL ROUND PERFORMANCE:
   Training   - Loss:  5945.41 | RMSE:  77.11 | R²: -0.0106
   Validation - Loss:  5516.48 | RMSE:  74.27 | R²: -0.0032
   Test       - Loss:  5438.90 | RMSE:  73.75 | R²: -0.0013

📊 STATISTICS ACROSS ALL ROUNDS (Mean ± Std):
   Training Loss:    5940.65 ±  17.26
   Validation Loss:  5514.71 ±   8.36
   Test Loss:        5766.50 ± 974.90

   Training RMSE:    77.08 ±  0.11
   Validation RMSE:  74.26 ±  0.06
   Test RMSE:        75.71 ±  5.84

   Training R²:     -0.0098 ± 0.0029
   Validation R²:   -0.0029 ± 0.0015
   Test R²:         -0.0617 ± 0.1795

⭐ BEST PERFORMANCE:
   Best Round: 9 (Test R²: -0.0013)

📋 DATA SUMMARY:
   Training samples:   3720
   Validation samples: 1240
   Test samples:       1240
   Total samples:      6200
================================================================================
✅ Client client_21 completed | Algorithm: FEDAVG
