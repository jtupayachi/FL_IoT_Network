[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dc5a45cf-5f67-4317-964e-a076b86d8655
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 502bcb7e-2874-44b6-bb48-9fe8cadb6b9f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 586af5de-db75-467c-9f92-116c47bbe1b8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 25440047-cf6c-47cc-8924-ac204698486d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5e91447a-3f11-4d54-b77f-e91a8299bc10
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b0c83299-a598-48c9-bf03-fb5c3671a542
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message df1d50b7-e132-4b1b-abb5-9c8a13f5ec6a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2b970ccb-ceb7-4055-a0d9-df1ae6a0f375
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6159cc4a-c4c4-4f12-b5cb-bd2e6ebd5870
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 987afa57-ee2d-4b29-979a-db0d766f8d8e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e6501200-bfd0-427e-aae1-b6f73992fc16
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b7c33949-65cd-4a84-9ddd-cc06634c2c7b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6753d797-af7a-4f6d-a90c-8b3ebafe5837
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ad6c55bc-16dc-4e83-b826-bc111842a363
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 85778a6f-300d-4f08-890e-64102bf6cbb1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0abda877-1308-49be-8f4b-61e4f9f3feb2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e1633037-82a7-404f-9315-fe4226a11a31
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6e6f0779-16a7-4892-988a-1b9c502180d9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7785cb1f-1f34-4270-ad67-7cebf08442a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: reconnect message 68768642-86b6-4e2b-894b-6f0eda58313b
[92mINFO [0m:      Disconnect and shut down
ğŸš€ Starting NASA FL Client: client_3
Algorithm: FEDAVG
Server: localhost:8686
K-Folds: 5
Log Directory: logs
ğŸ”„ Using device: cuda
ğŸ¯ GPU: NVIDIA A100-SXM4-80GB
ğŸ’¾ Hyperparameters saved to: logs/client_3_hyperparams_20251029_150409.csv
ğŸ” Looking for data at: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.1/client_3
ğŸ“Š Loaded 8574 total samples from /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.1/client_3
ğŸ”„ Created sequences with length 10
   Final dataset shape: X (8564, 10, 24), y (8564,)
âœ… Data split completed:
   Training samples: 5138
   Validation samples: 1713
   Test samples: 1713
   Model type: lstm
âœ… Client client_3 ready:
   Model: LSTM
   Training: 5138 samples
   Device: cuda
   Validation: 1713 samples
   Test: 1713 samples
   Algorithm: fedavg
   Total Rounds: 10
   Learning Rate: 0.001
   Batch Size: 32
   Logging to: logs

ğŸ§ª Round 0 Evaluation Results:
   Test Loss: 10078.2646
   RMSE: 100.3906, MAE: 75.3867, RÂ²: -0.4894
ğŸ’¾ Test metrics saved to: logs/client_3_test_metrics_20251029_150409.csv
â© Skipping CV for Round 2 (runs every 5 rounds)
Round 2: train_loss=6662.4336, val_loss=7118.6069, val_r2=-0.0194
ğŸ’¾ Training metrics saved to: logs/client_3_training_metrics_20251029_150409.csv

ğŸ§ª Round 2 Evaluation Results:
   Test Loss: 6788.8666
   RMSE: 82.3946, MAE: 64.2369, RÂ²: -0.0033
ğŸ’¾ Test metrics saved to: logs/client_3_test_metrics_20251029_150409.csv
â© Skipping CV for Round 3 (runs every 5 rounds)

ğŸ¯ Round 3 Training Results:
   Training - Loss: 6697.0698, RMSE: 81.8356, RÂ²: -0.0147
   Validation - Loss: 7167.8145, RMSE: 84.6629, RÂ²: -0.0264

ğŸ§ª Round 3 Evaluation Results:
   Test Loss: 6781.0116
   RMSE: 82.3469, MAE: 64.2857, RÂ²: -0.0021
ğŸ’¾ Test metrics saved to: logs/client_3_test_metrics_20251029_150409.csv
â© Skipping CV for Round 4 (runs every 5 rounds)
Round 4: train_loss=6667.4438, val_loss=7125.9507, val_r2=-0.0204
ğŸ’¾ Training metrics saved to: logs/client_3_training_metrics_20251029_150409.csv

ğŸ§ª Round 4 Evaluation Results:
   Test Loss: 6779.8913
   RMSE: 82.3401, MAE: 64.2945, RÂ²: -0.0020
ğŸ’¾ Test metrics saved to: logs/client_3_test_metrics_20251029_150409.csv

ğŸ” Running 3-fold cross-validation (Round 5)

ğŸ” Starting 3-fold cross-validation on TRAINING data for client client_3

ğŸ“Š Fold 1/3
   Fold 1 Results:
     Val Loss: 6988.7622
     Val RMSE: 83.5988, Val RÂ²: -0.0433

ğŸ“Š Fold 2/3
   Fold 2 Results:
     Val Loss: 6391.4668
     Val RMSE: 79.9466, Val RÂ²: -0.0120

ğŸ“Š Fold 3/3
   Fold 3 Results:
     Val Loss: 6788.1938
     Val RMSE: 82.3905, Val RÂ²: -0.0015
ğŸ’¾ CV metrics saved to: logs/client_3_cv_metrics_20251029_150409.csv

ğŸ“ˆ 3-Fold CV Summary (Training Data):
   VAL_LOSS: 6722.8076 Â± 248.1894
   RMSE: 81.9787 Â± 1.5192
   R2: -0.0189 Â± 0.0178

ğŸ¯ Round 5 Training Results:
   Training - Loss: 6687.4746, RMSE: 81.7770, RÂ²: -0.0132
   Validation - Loss: 7154.4902, RMSE: 84.5842, RÂ²: -0.0245
ğŸ’¾ Training metrics saved to: logs/client_3_training_metrics_20251029_150409.csv

ğŸ§ª Round 5 Evaluation Results:
   Test Loss: 6778.3506
   RMSE: 82.3307, MAE: 64.3085, RÂ²: -0.0018
ğŸ’¾ Test metrics saved to: logs/client_3_test_metrics_20251029_150409.csv
â© Skipping CV for Round 6 (runs every 5 rounds)

ğŸ¯ Round 6 Training Results:
   Training - Loss: 6699.8809, RMSE: 81.8528, RÂ²: -0.0151
   Validation - Loss: 7171.6777, RMSE: 84.6858, RÂ²: -0.0270
ğŸ’¾ Training metrics saved to: logs/client_3_training_metrics_20251029_150409.csv

ğŸ§ª Round 6 Evaluation Results:
   Test Loss: 6777.8252
   RMSE: 82.3275, MAE: 64.3135, RÂ²: -0.0017
ğŸ’¾ Test metrics saved to: logs/client_3_test_metrics_20251029_150409.csv
â© Skipping CV for Round 7 (runs every 5 rounds)
Round 7: train_loss=6706.7754, val_loss=7181.1074, val_r2=-0.0283

ğŸ§ª Round 7 Evaluation Results:
   Test Loss: 6777.9591
   RMSE: 82.3284, MAE: 64.3122, RÂ²: -0.0017
ğŸ’¾ Test metrics saved to: logs/client_3_test_metrics_20251029_150409.csv
â© Skipping CV for Round 8 (runs every 5 rounds)
Round 8: train_loss=6745.1211, val_loss=7232.2393, val_r2=-0.0356
ğŸ’¾ Training metrics saved to: logs/client_3_training_metrics_20251029_150409.csv

ğŸ§ª Round 8 Evaluation Results:
   Test Loss: 6778.8282
   RMSE: 82.3336, MAE: 64.3041, RÂ²: -0.0018
ğŸ’¾ Test metrics saved to: logs/client_3_test_metrics_20251029_150409.csv

ğŸ” Running 3-fold cross-validation (Round 9)
ğŸ’¾ CV metrics saved to: logs/client_3_cv_metrics_20251029_150409.csv

ğŸ¯ Round 9 Training Results:
   Training - Loss: 6691.9565, RMSE: 81.8044, RÂ²: -0.0139
   Validation - Loss: 7160.7324, RMSE: 84.6211, RÂ²: -0.0254
ğŸ’¾ Training metrics saved to: logs/client_3_training_metrics_20251029_150409.csv

ğŸ§ª Round 9 Evaluation Results:
   Test Loss: 6775.9324
   RMSE: 82.3161, MAE: 64.3325, RÂ²: -0.0014
ğŸ’¾ Test metrics saved to: logs/client_3_test_metrics_20251029_150409.csv

ğŸ” Running 3-fold cross-validation (Round 10)
ğŸ’¾ CV metrics saved to: logs/client_3_cv_metrics_20251029_150409.csv

ğŸ¯ Round 10 Training Results:
   Training - Loss: 6674.8184, RMSE: 81.6996, RÂ²: -0.0113
   Validation - Loss: 7136.5801, RMSE: 84.4783, RÂ²: -0.0219
ğŸ’¾ Training metrics saved to: logs/client_3_training_metrics_20251029_150409.csv

ğŸ§ª Round 10 Evaluation Results:
   Test Loss: 6776.4415
   RMSE: 82.3191, MAE: 64.3272, RÂ²: -0.0015
ğŸ’¾ Test metrics saved to: logs/client_3_test_metrics_20251029_150409.csv

================================================================================
ğŸ¯ FINAL COMPREHENSIVE REPORT
================================================================================
ğŸ’¾ Final summary saved to: logs/client_3_final_summary_20251029_150409.csv

ğŸ“Š CLIENT: client_3 | ALGORITHM: fedavg | MODEL: LSTM
ğŸ“ˆ TOTAL ROUNDS: 10

âš™ï¸  HYPERPARAMETERS:
   Learning Rate: 0.001
   Batch Size: 32
   Local Epochs: 1
   Hidden Dim: 64
   Num Layers: 2
   Sequence Length: 10
   Use Attention: False
   Dropout: 0.3
   Optimizer: adam

ğŸ FINAL ROUND PERFORMANCE:
   Training   - Loss:  6674.82 | RMSE:  81.70 | RÂ²: -0.0113
   Validation - Loss:  7136.58 | RMSE:  84.48 | RÂ²: -0.0219
   Test       - Loss:  6776.44 | RMSE:  82.32 | RÂ²: -0.0015

ğŸ“Š STATISTICS ACROSS ALL ROUNDS (Mean Â± Std):
   Training Loss:    6689.88 Â±  25.76
   Validation Loss:  7157.18 Â±  35.36
   Test Loss:        7109.34 Â± 989.65

   Training RMSE:    81.79 Â±  0.16
   Validation RMSE:  84.60 Â±  0.21
   Test RMSE:        84.14 Â±  5.42

   Training RÂ²:     -0.0136 Â± 0.0039
   Validation RÂ²:   -0.0249 Â± 0.0051
   Test RÂ²:         -0.0507 Â± 0.1463

â­ BEST PERFORMANCE:
   Best Round: 9 (Test RÂ²: -0.0014)

ğŸ“‹ DATA SUMMARY:
   Training samples:   5138
   Validation samples: 1713
   Test samples:       1713
   Total samples:      8564
================================================================================
âœ… Client client_3 completed | Algorithm: FEDAVG
