[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dc5a45cf-5f67-4317-964e-a076b86d8655
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 502bcb7e-2874-44b6-bb48-9fe8cadb6b9f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 586af5de-db75-467c-9f92-116c47bbe1b8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 25440047-cf6c-47cc-8924-ac204698486d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5e91447a-3f11-4d54-b77f-e91a8299bc10
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b0c83299-a598-48c9-bf03-fb5c3671a542
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message df1d50b7-e132-4b1b-abb5-9c8a13f5ec6a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2b970ccb-ceb7-4055-a0d9-df1ae6a0f375
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6159cc4a-c4c4-4f12-b5cb-bd2e6ebd5870
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 987afa57-ee2d-4b29-979a-db0d766f8d8e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e6501200-bfd0-427e-aae1-b6f73992fc16
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b7c33949-65cd-4a84-9ddd-cc06634c2c7b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6753d797-af7a-4f6d-a90c-8b3ebafe5837
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ad6c55bc-16dc-4e83-b826-bc111842a363
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 85778a6f-300d-4f08-890e-64102bf6cbb1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0abda877-1308-49be-8f4b-61e4f9f3feb2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e1633037-82a7-404f-9315-fe4226a11a31
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6e6f0779-16a7-4892-988a-1b9c502180d9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7785cb1f-1f34-4270-ad67-7cebf08442a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: reconnect message 68768642-86b6-4e2b-894b-6f0eda58313b
[92mINFO [0m:      Disconnect and shut down
🚀 Starting NASA FL Client: client_3
Algorithm: FEDAVG
Server: localhost:8686
K-Folds: 5
Log Directory: logs
🔄 Using device: cuda
🎯 GPU: NVIDIA A100-SXM4-80GB
💾 Hyperparameters saved to: logs/client_3_hyperparams_20251029_150409.csv
🔍 Looking for data at: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.1/client_3
📊 Loaded 8574 total samples from /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.1/client_3
🔄 Created sequences with length 10
   Final dataset shape: X (8564, 10, 24), y (8564,)
✅ Data split completed:
   Training samples: 5138
   Validation samples: 1713
   Test samples: 1713
   Model type: lstm
✅ Client client_3 ready:
   Model: LSTM
   Training: 5138 samples
   Device: cuda
   Validation: 1713 samples
   Test: 1713 samples
   Algorithm: fedavg
   Total Rounds: 10
   Learning Rate: 0.001
   Batch Size: 32
   Logging to: logs

🧪 Round 0 Evaluation Results:
   Test Loss: 10078.2646
   RMSE: 100.3906, MAE: 75.3867, R²: -0.4894
💾 Test metrics saved to: logs/client_3_test_metrics_20251029_150409.csv
⏩ Skipping CV for Round 2 (runs every 5 rounds)
Round 2: train_loss=6662.4336, val_loss=7118.6069, val_r2=-0.0194
💾 Training metrics saved to: logs/client_3_training_metrics_20251029_150409.csv

🧪 Round 2 Evaluation Results:
   Test Loss: 6788.8666
   RMSE: 82.3946, MAE: 64.2369, R²: -0.0033
💾 Test metrics saved to: logs/client_3_test_metrics_20251029_150409.csv
⏩ Skipping CV for Round 3 (runs every 5 rounds)

🎯 Round 3 Training Results:
   Training - Loss: 6697.0698, RMSE: 81.8356, R²: -0.0147
   Validation - Loss: 7167.8145, RMSE: 84.6629, R²: -0.0264

🧪 Round 3 Evaluation Results:
   Test Loss: 6781.0116
   RMSE: 82.3469, MAE: 64.2857, R²: -0.0021
💾 Test metrics saved to: logs/client_3_test_metrics_20251029_150409.csv
⏩ Skipping CV for Round 4 (runs every 5 rounds)
Round 4: train_loss=6667.4438, val_loss=7125.9507, val_r2=-0.0204
💾 Training metrics saved to: logs/client_3_training_metrics_20251029_150409.csv

🧪 Round 4 Evaluation Results:
   Test Loss: 6779.8913
   RMSE: 82.3401, MAE: 64.2945, R²: -0.0020
💾 Test metrics saved to: logs/client_3_test_metrics_20251029_150409.csv

🔍 Running 3-fold cross-validation (Round 5)

🔍 Starting 3-fold cross-validation on TRAINING data for client client_3

📊 Fold 1/3
   Fold 1 Results:
     Val Loss: 6988.7622
     Val RMSE: 83.5988, Val R²: -0.0433

📊 Fold 2/3
   Fold 2 Results:
     Val Loss: 6391.4668
     Val RMSE: 79.9466, Val R²: -0.0120

📊 Fold 3/3
   Fold 3 Results:
     Val Loss: 6788.1938
     Val RMSE: 82.3905, Val R²: -0.0015
💾 CV metrics saved to: logs/client_3_cv_metrics_20251029_150409.csv

📈 3-Fold CV Summary (Training Data):
   VAL_LOSS: 6722.8076 ± 248.1894
   RMSE: 81.9787 ± 1.5192
   R2: -0.0189 ± 0.0178

🎯 Round 5 Training Results:
   Training - Loss: 6687.4746, RMSE: 81.7770, R²: -0.0132
   Validation - Loss: 7154.4902, RMSE: 84.5842, R²: -0.0245
💾 Training metrics saved to: logs/client_3_training_metrics_20251029_150409.csv

🧪 Round 5 Evaluation Results:
   Test Loss: 6778.3506
   RMSE: 82.3307, MAE: 64.3085, R²: -0.0018
💾 Test metrics saved to: logs/client_3_test_metrics_20251029_150409.csv
⏩ Skipping CV for Round 6 (runs every 5 rounds)

🎯 Round 6 Training Results:
   Training - Loss: 6699.8809, RMSE: 81.8528, R²: -0.0151
   Validation - Loss: 7171.6777, RMSE: 84.6858, R²: -0.0270
💾 Training metrics saved to: logs/client_3_training_metrics_20251029_150409.csv

🧪 Round 6 Evaluation Results:
   Test Loss: 6777.8252
   RMSE: 82.3275, MAE: 64.3135, R²: -0.0017
💾 Test metrics saved to: logs/client_3_test_metrics_20251029_150409.csv
⏩ Skipping CV for Round 7 (runs every 5 rounds)
Round 7: train_loss=6706.7754, val_loss=7181.1074, val_r2=-0.0283

🧪 Round 7 Evaluation Results:
   Test Loss: 6777.9591
   RMSE: 82.3284, MAE: 64.3122, R²: -0.0017
💾 Test metrics saved to: logs/client_3_test_metrics_20251029_150409.csv
⏩ Skipping CV for Round 8 (runs every 5 rounds)
Round 8: train_loss=6745.1211, val_loss=7232.2393, val_r2=-0.0356
💾 Training metrics saved to: logs/client_3_training_metrics_20251029_150409.csv

🧪 Round 8 Evaluation Results:
   Test Loss: 6778.8282
   RMSE: 82.3336, MAE: 64.3041, R²: -0.0018
💾 Test metrics saved to: logs/client_3_test_metrics_20251029_150409.csv

🔍 Running 3-fold cross-validation (Round 9)
💾 CV metrics saved to: logs/client_3_cv_metrics_20251029_150409.csv

🎯 Round 9 Training Results:
   Training - Loss: 6691.9565, RMSE: 81.8044, R²: -0.0139
   Validation - Loss: 7160.7324, RMSE: 84.6211, R²: -0.0254
💾 Training metrics saved to: logs/client_3_training_metrics_20251029_150409.csv

🧪 Round 9 Evaluation Results:
   Test Loss: 6775.9324
   RMSE: 82.3161, MAE: 64.3325, R²: -0.0014
💾 Test metrics saved to: logs/client_3_test_metrics_20251029_150409.csv

🔍 Running 3-fold cross-validation (Round 10)
💾 CV metrics saved to: logs/client_3_cv_metrics_20251029_150409.csv

🎯 Round 10 Training Results:
   Training - Loss: 6674.8184, RMSE: 81.6996, R²: -0.0113
   Validation - Loss: 7136.5801, RMSE: 84.4783, R²: -0.0219
💾 Training metrics saved to: logs/client_3_training_metrics_20251029_150409.csv

🧪 Round 10 Evaluation Results:
   Test Loss: 6776.4415
   RMSE: 82.3191, MAE: 64.3272, R²: -0.0015
💾 Test metrics saved to: logs/client_3_test_metrics_20251029_150409.csv

================================================================================
🎯 FINAL COMPREHENSIVE REPORT
================================================================================
💾 Final summary saved to: logs/client_3_final_summary_20251029_150409.csv

📊 CLIENT: client_3 | ALGORITHM: fedavg | MODEL: LSTM
📈 TOTAL ROUNDS: 10

⚙️  HYPERPARAMETERS:
   Learning Rate: 0.001
   Batch Size: 32
   Local Epochs: 1
   Hidden Dim: 64
   Num Layers: 2
   Sequence Length: 10
   Use Attention: False
   Dropout: 0.3
   Optimizer: adam

🏁 FINAL ROUND PERFORMANCE:
   Training   - Loss:  6674.82 | RMSE:  81.70 | R²: -0.0113
   Validation - Loss:  7136.58 | RMSE:  84.48 | R²: -0.0219
   Test       - Loss:  6776.44 | RMSE:  82.32 | R²: -0.0015

📊 STATISTICS ACROSS ALL ROUNDS (Mean ± Std):
   Training Loss:    6689.88 ±  25.76
   Validation Loss:  7157.18 ±  35.36
   Test Loss:        7109.34 ± 989.65

   Training RMSE:    81.79 ±  0.16
   Validation RMSE:  84.60 ±  0.21
   Test RMSE:        84.14 ±  5.42

   Training R²:     -0.0136 ± 0.0039
   Validation R²:   -0.0249 ± 0.0051
   Test R²:         -0.0507 ± 0.1463

⭐ BEST PERFORMANCE:
   Best Round: 9 (Test R²: -0.0014)

📋 DATA SUMMARY:
   Training samples:   5138
   Validation samples: 1713
   Test samples:       1713
   Total samples:      8564
================================================================================
✅ Client client_3 completed | Algorithm: FEDAVG
