[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6bf7f7d9-6be7-43e1-93fd-dccde723ca2e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d1061ccc-6ec4-4987-9a50-121756bcd749
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5267a822-1dc2-448f-97a1-b6093432c800
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 92a8e673-84b7-48e1-ae97-d11420eb67e8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 02a8a340-bbb4-44f4-9481-9bd7bd79e2b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9654de8f-0eb8-4dab-9d8e-351f2c764544
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a80f036f-1044-42c0-8ca6-f7e9323aa8da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8f21d278-77b9-4f63-b723-3efe63b04cec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cfe10fad-206f-45aa-a657-380d9a78739b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 42b7f392-e638-4eca-afe7-26f6c05e151b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cd9716b9-e696-4498-b184-92907a7a1821
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 922d81d8-0eca-4088-95b5-6079ef1dcf00
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7498bdcf-0635-46b1-9e98-f4074f3c298f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 09c39fd9-9036-42c0-8444-a0befd86fb6b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d0793543-59c1-4ab1-b1e6-b8eb7cceaf7f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 760ebfc8-b2a2-4a93-9b22-a9c4a47ece72
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 50922c64-d096-4633-8ce2-4414ef243d0d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c4aee212-877b-4aeb-ab75-cf8245da4c8e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a2ca2e12-c855-43f3-a8df-295060471181
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9068ce08-fbac-4fcc-bf27-ee340e7ba0b5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: reconnect message 3e9cd88d-2506-4be2-a93c-a0bcf77aa2bc
[92mINFO [0m:      Disconnect and shut down
🚀 Starting NASA FL Client: client_4
Algorithm: FEDAVG
Server: localhost:8686
K-Folds: 5
Log Directory: logs
🔄 Using device: cuda
🎯 GPU: NVIDIA A100-SXM4-80GB
💾 Hyperparameters saved to: logs/client_4_hyperparams_20251029_150409.csv
🔍 Looking for data at: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.1/client_4
📊 Loaded 5409 total samples from /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.1/client_4
🔄 Created sequences with length 10
   Final dataset shape: X (5399, 10, 24), y (5399,)
✅ Data split completed:
   Training samples: 3239
   Validation samples: 1080
   Test samples: 1080
   Model type: lstm
✅ Client client_4 ready:
   Model: LSTM
   Training: 3239 samples
   Device: cuda
   Validation: 1080 samples
   Test: 1080 samples
   Algorithm: fedavg
   Total Rounds: 10
   Learning Rate: 0.001
   Batch Size: 32
   Logging to: logs
⏩ Skipping CV for Round 1 (runs every 5 rounds)
Round 1: train_loss=9297.1973, val_loss=9853.2959, val_r2=-0.9549

🧪 Round 1 Evaluation Results:
   Test Loss: 7880.7591
   RMSE: 88.7736, MAE: 68.4626, R²: -0.4666
💾 Test metrics saved to: logs/client_4_test_metrics_20251029_150409.csv
⏩ Skipping CV for Round 2 (runs every 5 rounds)
Round 2: train_loss=5056.1309, val_loss=5169.1533, val_r2=-0.0256
💾 Training metrics saved to: logs/client_4_training_metrics_20251029_150409.csv

🧪 Round 2 Evaluation Results:
   Test Loss: 5380.9228
   RMSE: 73.3548, MAE: 59.5702, R²: -0.0014
💾 Test metrics saved to: logs/client_4_test_metrics_20251029_150409.csv
⏩ Skipping CV for Round 3 (runs every 5 rounds)

🎯 Round 3 Training Results:
   Training - Loss: 5031.9990, RMSE: 70.9366, R²: -0.0065
   Validation - Loss: 5131.1064, RMSE: 71.6317, R²: -0.0180

🧪 Round 3 Evaluation Results:
   Test Loss: 5386.8076
   RMSE: 73.3949, MAE: 59.6518, R²: -0.0025
💾 Test metrics saved to: logs/client_4_test_metrics_20251029_150409.csv
⏩ Skipping CV for Round 4 (runs every 5 rounds)
Round 4: train_loss=5048.9336, val_loss=5158.1826, val_r2=-0.0234
💾 Training metrics saved to: logs/client_4_training_metrics_20251029_150409.csv

🧪 Round 4 Evaluation Results:
   Test Loss: 5387.9270
   RMSE: 73.4025, MAE: 59.6656, R²: -0.0027
💾 Test metrics saved to: logs/client_4_test_metrics_20251029_150409.csv

🔍 Running 3-fold cross-validation (Round 5)

🔍 Starting 3-fold cross-validation on TRAINING data for client client_4

📊 Fold 1/3
   Fold 1 Results:
     Val Loss: 5080.9844
     Val RMSE: 71.2810, Val R²: -0.0227

📊 Fold 2/3
   Fold 2 Results:
     Val Loss: 4960.7056
     Val RMSE: 70.4323, Val R²: -0.0152

📊 Fold 3/3
   Fold 3 Results:
     Val Loss: 5171.0000
     Val RMSE: 71.9097, Val R²: -0.0055
💾 CV metrics saved to: logs/client_4_cv_metrics_20251029_150409.csv

📈 3-Fold CV Summary (Training Data):
   VAL_LOSS: 5070.8966 ± 86.1482
   RMSE: 71.2077 ± 0.6054
   R2: -0.0145 ± 0.0070

🎯 Round 5 Training Results:
   Training - Loss: 5067.5391, RMSE: 71.1866, R²: -0.0136
   Validation - Loss: 5186.0757, RMSE: 72.0144, R²: -0.0289
💾 Training metrics saved to: logs/client_4_training_metrics_20251029_150409.csv

🧪 Round 5 Evaluation Results:
   Test Loss: 5389.6254
   RMSE: 73.4141, MAE: 59.6865, R²: -0.0030
💾 Test metrics saved to: logs/client_4_test_metrics_20251029_150409.csv
⏩ Skipping CV for Round 6 (runs every 5 rounds)

🎯 Round 6 Training Results:
   Training - Loss: 5036.6738, RMSE: 70.9695, R²: -0.0075
   Validation - Loss: 5138.8018, RMSE: 71.6854, R²: -0.0195
💾 Training metrics saved to: logs/client_4_training_metrics_20251029_150409.csv

🧪 Round 6 Evaluation Results:
   Test Loss: 5390.2528
   RMSE: 73.4183, MAE: 59.6939, R²: -0.0031
💾 Test metrics saved to: logs/client_4_test_metrics_20251029_150409.csv
⏩ Skipping CV for Round 7 (runs every 5 rounds)
Round 7: train_loss=5039.9458, val_loss=5144.0767, val_r2=-0.0206

🧪 Round 7 Evaluation Results:
   Test Loss: 5390.0904
   RMSE: 73.4172, MAE: 59.6920, R²: -0.0031
💾 Test metrics saved to: logs/client_4_test_metrics_20251029_150409.csv
⏩ Skipping CV for Round 8 (runs every 5 rounds)
Round 8: train_loss=5076.9697, val_loss=5199.7271, val_r2=-0.0316
💾 Training metrics saved to: logs/client_4_training_metrics_20251029_150409.csv

🧪 Round 8 Evaluation Results:
   Test Loss: 5389.0782
   RMSE: 73.4103, MAE: 59.6799, R²: -0.0029
💾 Test metrics saved to: logs/client_4_test_metrics_20251029_150409.csv

🔍 Running 3-fold cross-validation (Round 9)
💾 CV metrics saved to: logs/client_4_cv_metrics_20251029_150409.csv

🎯 Round 9 Training Results:
   Training - Loss: 5040.1562, RMSE: 70.9941, R²: -0.0082
   Validation - Loss: 5144.4126, RMSE: 71.7246, R²: -0.0207
💾 Training metrics saved to: logs/client_4_training_metrics_20251029_150409.csv

🧪 Round 9 Evaluation Results:
   Test Loss: 5392.7494
   RMSE: 73.4353, MAE: 59.7222, R²: -0.0036
💾 Test metrics saved to: logs/client_4_test_metrics_20251029_150409.csv

🔍 Running 3-fold cross-validation (Round 10)
💾 CV metrics saved to: logs/client_4_cv_metrics_20251029_150409.csv

🎯 Round 10 Training Results:
   Training - Loss: 5045.5674, RMSE: 71.0322, R²: -0.0092
   Validation - Loss: 5152.9580, RMSE: 71.7841, R²: -0.0224
💾 Training metrics saved to: logs/client_4_training_metrics_20251029_150409.csv

🧪 Round 10 Evaluation Results:
   Test Loss: 5392.0389
   RMSE: 73.4305, MAE: 59.7143, R²: -0.0035
💾 Test metrics saved to: logs/client_4_test_metrics_20251029_150409.csv

================================================================================
🎯 FINAL COMPREHENSIVE REPORT
================================================================================
💾 Final summary saved to: logs/client_4_final_summary_20251029_150409.csv

📊 CLIENT: client_4 | ALGORITHM: fedavg | MODEL: LSTM
📈 TOTAL ROUNDS: 10

⚙️  HYPERPARAMETERS:
   Learning Rate: 0.001
   Batch Size: 32
   Local Epochs: 1
   Hidden Dim: 64
   Num Layers: 2
   Sequence Length: 10
   Use Attention: False
   Dropout: 0.3
   Optimizer: adam

🏁 FINAL ROUND PERFORMANCE:
   Training   - Loss:  5045.57 | RMSE:  71.03 | R²: -0.0092
   Validation - Loss:  5152.96 | RMSE:  71.78 | R²: -0.0224
   Test       - Loss:  5392.04 | RMSE:  73.43 | R²: -0.0035

📊 STATISTICS ACROSS ALL ROUNDS (Mean ± Std):
   Training Loss:    5053.14 ±  13.62
   Validation Loss:  5164.19 ±  20.58
   Test Loss:        5638.03 ± 747.58

   Training RMSE:    71.09 ±  0.10
   Validation RMSE:  71.86 ±  0.14
   Test RMSE:        74.95 ±  4.61

   Training R²:     -0.0108 ± 0.0027
   Validation R²:   -0.0246 ± 0.0041
   Test R²:         -0.0492 ± 0.1391

⭐ BEST PERFORMANCE:
   Best Round: 2 (Test R²: -0.0014)

📋 DATA SUMMARY:
   Training samples:   3239
   Validation samples: 1080
   Test samples:       1080
   Total samples:      5399
================================================================================
✅ Client client_4 completed | Algorithm: FEDAVG
