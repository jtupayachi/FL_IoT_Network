[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3e19a9dc-c187-4272-8ad8-0c5e87d9f0fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9eae9fa7-8cd4-4652-87e7-12ce5797c013
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5959c27d-7158-4f35-98ec-62cdb7d0226b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cdb8fcc4-ad52-4dba-848c-a7edc004b849
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 68160de3-e0a5-409f-88ab-f1488ba2a026
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fb85b6d7-d0ff-465d-9afa-df2b8808545b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6c16bf40-d598-4941-ba26-62f209ceebff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0ea2cb0d-7ea0-4262-b49b-2b78d2a8c6aa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6b8201a7-8901-4db4-87c5-d6e5351a1250
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 35d92b51-8dd2-413d-a5e8-4ce293aca99f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eb20be3f-00cf-4230-ac8e-f9ab9d6c35d5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 10492374-39d7-4e32-abee-4100cdddaf91
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9da0025b-dd5c-4fbe-93d9-8a303044ab9d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7719aa6d-b70e-4055-8b9e-7f709c6b2518
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ca8f2e63-0a98-45f6-bf1d-18b37029079e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 74ca3746-dade-4a0a-a08d-9058221f1afb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3814a9e1-e7cd-4489-b25e-5380fc99e216
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4be537c1-2be7-43ee-8936-b318ea5bb021
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cd83fb38-a5f7-4f6b-9776-28ba6b197f7b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: reconnect message 293dd141-cca9-491f-9ddd-e276e0c1c11c
[92mINFO [0m:      Disconnect and shut down
🚀 Starting NASA FL Client: client_0
Algorithm: FEDAVG
Server: localhost:8686
K-Folds: 5
Log Directory: logs
🔄 Using device: cuda
🎯 GPU: NVIDIA A100-SXM4-80GB
💾 Hyperparameters saved to: logs/client_0_hyperparams_20251029_151810.csv
🔍 Looking for data at: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.1/client_0
📊 Loaded 5015 total samples from /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.1/client_0
🔄 Created sequences with length 10
   Final dataset shape: X (5005, 10, 24), y (5005,)
✅ Data split completed:
   Training samples: 3003
   Validation samples: 1001
   Test samples: 1001
   Model type: lstm
✅ Client client_0 ready:
   Model: LSTM
   Training: 3003 samples
   Device: cuda
   Validation: 1001 samples
   Test: 1001 samples
   Algorithm: fedavg
   Total Rounds: 10
   Learning Rate: 0.001
   Batch Size: 32
   Logging to: logs

🧪 Round 0 Evaluation Results:
   Test Loss: 8329.1998
   RMSE: 91.2645, MAE: 69.4190, R²: -0.4969
💾 Test metrics saved to: logs/client_0_test_metrics_20251029_151810.csv
⏩ Skipping CV for Round 2 (runs every 5 rounds)
Round 2: train_loss=5932.1328, val_loss=6052.1094, val_r2=-0.0356
💾 Training metrics saved to: logs/client_0_training_metrics_20251029_151810.csv

🧪 Round 2 Evaluation Results:
   Test Loss: 5568.5814
   RMSE: 74.6229, MAE: 59.7885, R²: -0.0008
💾 Test metrics saved to: logs/client_0_test_metrics_20251029_151810.csv
⏩ Skipping CV for Round 3 (runs every 5 rounds)

🎯 Round 3 Training Results:
   Training - Loss: 5858.6333, RMSE: 76.5417, R²: -0.0197
   Validation - Loss: 5974.0488, RMSE: 77.2920, R²: -0.0222

🧪 Round 3 Evaluation Results:
   Test Loss: 5585.4461
   RMSE: 74.7358, MAE: 60.0310, R²: -0.0038
💾 Test metrics saved to: logs/client_0_test_metrics_20251029_151810.csv
⏩ Skipping CV for Round 4 (runs every 5 rounds)
Round 4: train_loss=5840.1211, val_loss=5954.1660, val_r2=-0.0188
💾 Training metrics saved to: logs/client_0_training_metrics_20251029_151810.csv

🧪 Round 4 Evaluation Results:
   Test Loss: 5584.7068
   RMSE: 74.7309, MAE: 60.0222, R²: -0.0037
💾 Test metrics saved to: logs/client_0_test_metrics_20251029_151810.csv

🔍 Running 3-fold cross-validation (Round 5)

🔍 Starting 3-fold cross-validation on TRAINING data for client client_0

📊 Fold 1/3
   Fold 1 Results:
     Val Loss: 6205.1929
     Val RMSE: 78.7730, Val R²: -0.0386

📊 Fold 2/3
   Fold 2 Results:
     Val Loss: 5673.7285
     Val RMSE: 75.3242, Val R²: -0.0076

📊 Fold 3/3
   Fold 3 Results:
     Val Loss: 5628.0269
     Val RMSE: 75.0202, Val R²: -0.0056
💾 CV metrics saved to: logs/client_0_cv_metrics_20251029_151810.csv

📈 3-Fold CV Summary (Training Data):
   VAL_LOSS: 5835.6494 ± 261.9719
   RMSE: 76.3725 ± 1.7020
   R2: -0.0173 ± 0.0151

🎯 Round 5 Training Results:
   Training - Loss: 5845.6855, RMSE: 76.4571, R²: -0.0174
   Validation - Loss: 5960.1558, RMSE: 77.2020, R²: -0.0198
💾 Training metrics saved to: logs/client_0_training_metrics_20251029_151810.csv

🧪 Round 5 Evaluation Results:
   Test Loss: 5591.0694
   RMSE: 74.7735, MAE: 60.0936, R²: -0.0048
💾 Test metrics saved to: logs/client_0_test_metrics_20251029_151810.csv
⏩ Skipping CV for Round 6 (runs every 5 rounds)

🎯 Round 6 Training Results:
   Training - Loss: 5904.6758, RMSE: 76.8419, R²: -0.0277
   Validation - Loss: 6023.0771, RMSE: 77.6085, R²: -0.0306
💾 Training metrics saved to: logs/client_0_training_metrics_20251029_151810.csv

🧪 Round 6 Evaluation Results:
   Test Loss: 5590.1521
   RMSE: 74.7673, MAE: 60.0838, R²: -0.0047
💾 Test metrics saved to: logs/client_0_test_metrics_20251029_151810.csv
⏩ Skipping CV for Round 7 (runs every 5 rounds)
Round 7: train_loss=5863.8574, val_loss=5979.6392, val_r2=-0.0232

🧪 Round 7 Evaluation Results:
   Test Loss: 5595.4262
   RMSE: 74.8026, MAE: 60.1387, R²: -0.0056
💾 Test metrics saved to: logs/client_0_test_metrics_20251029_151810.csv
⏩ Skipping CV for Round 8 (runs every 5 rounds)
Round 8: train_loss=5842.8169, val_loss=5957.0688, val_r2=-0.0193
💾 Training metrics saved to: logs/client_0_training_metrics_20251029_151810.csv

🧪 Round 8 Evaluation Results:
   Test Loss: 5592.2166
   RMSE: 74.7811, MAE: 60.1055, R²: -0.0050
💾 Test metrics saved to: logs/client_0_test_metrics_20251029_151810.csv

🔍 Running 3-fold cross-validation (Round 9)
💾 CV metrics saved to: logs/client_0_cv_metrics_20251029_151810.csv

🎯 Round 9 Training Results:
   Training - Loss: 5874.6387, RMSE: 76.6462, R²: -0.0225
   Validation - Loss: 5991.1509, RMSE: 77.4025, R²: -0.0251
💾 Training metrics saved to: logs/client_0_training_metrics_20251029_151810.csv

🧪 Round 9 Evaluation Results:
   Test Loss: 5586.4866
   RMSE: 74.7428, MAE: 60.0432, R²: -0.0040
💾 Test metrics saved to: logs/client_0_test_metrics_20251029_151810.csv

🔍 Running 3-fold cross-validation (Round 10)
💾 CV metrics saved to: logs/client_0_cv_metrics_20251029_151810.csv

🎯 Round 10 Training Results:
   Training - Loss: 5875.6177, RMSE: 76.6526, R²: -0.0226
   Validation - Loss: 5992.1948, RMSE: 77.4093, R²: -0.0253
💾 Training metrics saved to: logs/client_0_training_metrics_20251029_151810.csv

🧪 Round 10 Evaluation Results:
   Test Loss: 5592.2463
   RMSE: 74.7813, MAE: 60.1058, R²: -0.0050
💾 Test metrics saved to: logs/client_0_test_metrics_20251029_151810.csv

================================================================================
🎯 FINAL COMPREHENSIVE REPORT
================================================================================
💾 Final summary saved to: logs/client_0_final_summary_20251029_151810.csv

📊 CLIENT: client_0 | ALGORITHM: fedavg | MODEL: LSTM
📈 TOTAL ROUNDS: 10

⚙️  HYPERPARAMETERS:
   Learning Rate: 0.001
   Batch Size: 32
   Local Epochs: 1
   Hidden Dim: 64
   Num Layers: 2
   Sequence Length: 10
   Use Attention: False
   Dropout: 0.3
   Optimizer: adam

🏁 FINAL ROUND PERFORMANCE:
   Training   - Loss:  5875.62 | RMSE:  76.65 | R²: -0.0226
   Validation - Loss:  5992.19 | RMSE:  77.41 | R²: -0.0253
   Test       - Loss:  5592.25 | RMSE:  74.78 | R²: -0.0050

📊 STATISTICS ACROSS ALL ROUNDS (Mean ± Std):
   Training Loss:    5873.67 ±  32.17
   Validation Loss:  5989.99 ±  34.26
   Test Loss:        5861.55 ± 822.58

   Training RMSE:    76.64 ±  0.21
   Validation RMSE:  77.39 ±  0.22
   Test RMSE:        76.40 ±  4.95

   Training R²:     -0.0223 ± 0.0056
   Validation R²:   -0.0249 ± 0.0059
   Test R²:         -0.0534 ± 0.1478

⭐ BEST PERFORMANCE:
   Best Round: 2 (Test R²: -0.0008)

📋 DATA SUMMARY:
   Training samples:   3003
   Validation samples: 1001
   Test samples:       1001
   Total samples:      5005
================================================================================
✅ Client client_0 completed | Algorithm: FEDAVG
