[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bfacc557-a881-495a-81f6-e9df29351bd4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 42f7c364-1b1b-4d5f-aa05-bd0189cb045a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2ae4da96-7766-4845-8710-0451b4715d95
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 587bed6b-e872-4b0c-97e8-486cb2b3a137
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a00b7a14-0462-492a-8985-a823c7ab04af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 492a75ed-7974-4904-9013-849436446ed6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4076dfe3-8596-4eff-ab09-8741fc2545ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 89f3a02e-f677-4a22-ad9d-9ff5332b92c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e2ea3682-59dc-455e-876a-9b0adf8bc65b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 07e4ad0f-d852-4bac-b716-19750e5732e8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5dba732f-661a-4b8f-90c4-d556be30811d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8dec97ec-f0d7-4a4a-aa4f-b6fcb8411a14
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b8f814c1-19da-4051-b708-92f89d2e346f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c009e39d-1efc-4105-bb5d-0f8460da419f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4e08dd0d-b4b9-4242-a61a-cc320a34912f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f630395e-d7ea-4e8e-85af-f8bc7ee9e9d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5dae0442-4fa0-4afa-b455-363f4ffbee9d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b6ec3a12-ff79-4b0b-b8a3-1d234831ff3e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 001f6ac3-ecc7-422c-85ff-1fd6034912bd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f765dad4-c7de-4f3b-90ed-5835fcbd55d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: reconnect message 3fb2887a-89ab-47cc-9d86-73ea0807f65c
[92mINFO [0m:      Disconnect and shut down
🚀 Starting NASA FL Client: client_15
Algorithm: FEDAVG
Server: localhost:8686
K-Folds: 5
Log Directory: logs
🔄 Using device: cuda
🎯 GPU: NVIDIA A100-SXM4-80GB
💾 Hyperparameters saved to: logs/client_15_hyperparams_20251029_151832.csv
🔍 Looking for data at: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.1/client_15
📊 Loaded 6769 total samples from /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.1/client_15
🔄 Created sequences with length 10
   Final dataset shape: X (6759, 10, 24), y (6759,)
✅ Data split completed:
   Training samples: 4055
   Validation samples: 1352
   Test samples: 1352
   Model type: lstm
✅ Client client_15 ready:
   Model: LSTM
   Training: 4055 samples
   Device: cuda
   Validation: 1352 samples
   Test: 1352 samples
   Algorithm: fedavg
   Total Rounds: 10
   Learning Rate: 0.001
   Batch Size: 32
   Logging to: logs
⏩ Skipping CV for Round 1 (runs every 5 rounds)
Round 1: train_loss=10277.9307, val_loss=10057.7002, val_r2=-0.4591

🧪 Round 1 Evaluation Results:
   Test Loss: 11394.6307
   RMSE: 106.7456, MAE: 79.5857, R²: -0.5168
💾 Test metrics saved to: logs/client_15_test_metrics_20251029_151832.csv
⏩ Skipping CV for Round 2 (runs every 5 rounds)
Round 2: train_loss=7230.2529, val_loss=7048.5283, val_r2=-0.0226
💾 Training metrics saved to: logs/client_15_training_metrics_20251029_151832.csv

🧪 Round 2 Evaluation Results:
   Test Loss: 7570.6556
   RMSE: 87.0095, MAE: 69.2531, R²: -0.0078
💾 Test metrics saved to: logs/client_15_test_metrics_20251029_151832.csv
⏩ Skipping CV for Round 3 (runs every 5 rounds)

🎯 Round 3 Training Results:
   Training - Loss: 7155.5908, RMSE: 84.5907, R²: -0.0130
   Validation - Loss: 6976.7812, RMSE: 83.5271, R²: -0.0122

🧪 Round 3 Evaluation Results:
   Test Loss: 7538.5247
   RMSE: 86.8247, MAE: 69.4514, R²: -0.0035
💾 Test metrics saved to: logs/client_15_test_metrics_20251029_151832.csv
⏩ Skipping CV for Round 4 (runs every 5 rounds)
Round 4: train_loss=7144.0112, val_loss=6965.7500, val_r2=-0.0106
💾 Training metrics saved to: logs/client_15_training_metrics_20251029_151832.csv

🧪 Round 4 Evaluation Results:
   Test Loss: 7539.3603
   RMSE: 86.8295, MAE: 69.4442, R²: -0.0036
💾 Test metrics saved to: logs/client_15_test_metrics_20251029_151832.csv

🔍 Running 3-fold cross-validation (Round 5)

🔍 Starting 3-fold cross-validation on TRAINING data for client client_15

📊 Fold 1/3
   Fold 1 Results:
     Val Loss: 6757.7681
     Val RMSE: 82.2056, Val R²: -0.0037

📊 Fold 2/3
   Fold 2 Results:
     Val Loss: 7729.8506
     Val RMSE: 87.9196, Val R²: -0.0417

📊 Fold 3/3
   Fold 3 Results:
     Val Loss: 7234.8623
     Val RMSE: 85.0580, Val R²: -0.0363
💾 CV metrics saved to: logs/client_15_cv_metrics_20251029_151832.csv

📈 3-Fold CV Summary (Training Data):
   VAL_LOSS: 7240.8270 ± 396.8734
   RMSE: 85.0611 ± 2.3327
   R2: -0.0272 ± 0.0168

🎯 Round 5 Training Results:
   Training - Loss: 7192.2505, RMSE: 84.8071, R²: -0.0182
   Validation - Loss: 7011.9019, RMSE: 83.7371, R²: -0.0173
💾 Training metrics saved to: logs/client_15_training_metrics_20251029_151832.csv

🧪 Round 5 Evaluation Results:
   Test Loss: 7532.9745
   RMSE: 86.7927, MAE: 69.5024, R²: -0.0027
💾 Test metrics saved to: logs/client_15_test_metrics_20251029_151832.csv
⏩ Skipping CV for Round 6 (runs every 5 rounds)

🎯 Round 6 Training Results:
   Training - Loss: 7200.4854, RMSE: 84.8557, R²: -0.0194
   Validation - Loss: 7019.8228, RMSE: 83.7844, R²: -0.0184
💾 Training metrics saved to: logs/client_15_training_metrics_20251029_151832.csv

🧪 Round 6 Evaluation Results:
   Test Loss: 7533.7941
   RMSE: 86.7974, MAE: 69.4944, R²: -0.0029
💾 Test metrics saved to: logs/client_15_test_metrics_20251029_151832.csv
⏩ Skipping CV for Round 7 (runs every 5 rounds)
Round 7: train_loss=7193.9009, val_loss=7013.4888, val_r2=-0.0175

🧪 Round 7 Evaluation Results:
   Test Loss: 7529.4613
   RMSE: 86.7725, MAE: 69.5391, R²: -0.0023
💾 Test metrics saved to: logs/client_15_test_metrics_20251029_151832.csv
⏩ Skipping CV for Round 8 (runs every 5 rounds)
Round 8: train_loss=7138.6987, val_loss=6960.7026, val_r2=-0.0098
💾 Training metrics saved to: logs/client_15_training_metrics_20251029_151832.csv

🧪 Round 8 Evaluation Results:
   Test Loss: 7531.9908
   RMSE: 86.7870, MAE: 69.5121, R²: -0.0026
💾 Test metrics saved to: logs/client_15_test_metrics_20251029_151832.csv

🔍 Running 3-fold cross-validation (Round 9)
💾 CV metrics saved to: logs/client_15_cv_metrics_20251029_151832.csv

🎯 Round 9 Training Results:
   Training - Loss: 7182.2163, RMSE: 84.7480, R²: -0.0168
   Validation - Loss: 7002.2646, RMSE: 83.6795, R²: -0.0159
💾 Training metrics saved to: logs/client_15_training_metrics_20251029_151832.csv

🧪 Round 9 Evaluation Results:
   Test Loss: 7537.3953
   RMSE: 86.8182, MAE: 69.4613, R²: -0.0033
💾 Test metrics saved to: logs/client_15_test_metrics_20251029_151832.csv

🔍 Running 3-fold cross-validation (Round 10)
💾 CV metrics saved to: logs/client_15_cv_metrics_20251029_151832.csv

🎯 Round 10 Training Results:
   Training - Loss: 7157.1987, RMSE: 84.6002, R²: -0.0133
   Validation - Loss: 6978.3149, RMSE: 83.5363, R²: -0.0124
💾 Training metrics saved to: logs/client_15_training_metrics_20251029_151832.csv

🧪 Round 10 Evaluation Results:
   Test Loss: 7531.9666
   RMSE: 86.7869, MAE: 69.5123, R²: -0.0026
💾 Test metrics saved to: logs/client_15_test_metrics_20251029_151832.csv

================================================================================
🎯 FINAL COMPREHENSIVE REPORT
================================================================================
💾 Final summary saved to: logs/client_15_final_summary_20251029_151832.csv

📊 CLIENT: client_15 | ALGORITHM: fedavg | MODEL: LSTM
📈 TOTAL ROUNDS: 10

⚙️  HYPERPARAMETERS:
   Learning Rate: 0.001
   Batch Size: 32
   Local Epochs: 1
   Hidden Dim: 64
   Num Layers: 2
   Sequence Length: 10
   Use Attention: False
   Dropout: 0.3
   Optimizer: adam

🏁 FINAL ROUND PERFORMANCE:
   Training   - Loss:  7157.20 | RMSE:  84.60 | R²: -0.0133
   Validation - Loss:  6978.31 | RMSE:  83.54 | R²: -0.0124
   Test       - Loss:  7531.97 | RMSE:  86.79 | R²: -0.0026

📊 STATISTICS ACROSS ALL ROUNDS (Mean ± Std):
   Training Loss:    7177.87 ±  30.68
   Validation Loss:  6998.18 ±  29.42
   Test Loss:        7924.08 ± 1156.91

   Training RMSE:    84.72 ±  0.18
   Validation RMSE:  83.65 ±  0.18
   Test RMSE:        88.82 ±  5.98

   Training R²:     -0.0162 ± 0.0043
   Validation R²:   -0.0153 ± 0.0043
   Test R²:         -0.0548 ± 0.1540

⭐ BEST PERFORMANCE:
   Best Round: 7 (Test R²: -0.0023)

📋 DATA SUMMARY:
   Training samples:   4055
   Validation samples: 1352
   Test samples:       1352
   Total samples:      6759
================================================================================
✅ Client client_15 completed | Algorithm: FEDAVG
