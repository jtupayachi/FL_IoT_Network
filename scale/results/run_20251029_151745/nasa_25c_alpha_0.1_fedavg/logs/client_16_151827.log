[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 97990ba3-9184-4436-b6f3-563f6136eda6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3c9e34d5-6201-4714-bd4d-2adaf9920150
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a8f5efd0-eff7-44a6-b20b-67b63896e214
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2368897b-16e7-4c29-91ce-4812e4cc7d4c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fa969f1c-4785-4936-b17a-f2abcdaace77
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8207b7b0-97e2-46b4-b60d-9ce86d1f41dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6d747e9b-5287-40ee-a78d-d77582678698
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0cd3f041-5154-4b23-a78f-5be5a199fd46
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 46263d84-6155-4ca7-b8cb-883c5ec92b78
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 427eecb7-20c1-4fd6-b298-d5e5eccc2e7e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a97e2f9b-a03c-402c-aca7-0f311b47d416
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8c23f4a5-51e7-4c05-a7cb-86dabe837722
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6978811c-40ae-46cc-80e9-c9c3cf012407
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5466a590-d2e8-417f-bfdd-00f7b9944fa3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 47974021-dab5-462b-b8fc-5077cd440a5d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 64ae6f24-28d8-45d5-ba29-002059a7d528
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f196bd8b-30c1-49d4-954a-b88cdd7294da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dc721ece-71f1-4991-9ec4-4d50ef9b9d90
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 79c3c0e1-62bb-4209-a677-8a27b72aca2e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: reconnect message 1899a2c9-4f27-499b-9509-b6443708db6c
[92mINFO [0m:      Disconnect and shut down
🚀 Starting NASA FL Client: client_16
Algorithm: FEDAVG
Server: localhost:8686
K-Folds: 5
Log Directory: logs
🔄 Using device: cuda
🎯 GPU: NVIDIA A100-SXM4-80GB
💾 Hyperparameters saved to: logs/client_16_hyperparams_20251029_151832.csv
🔍 Looking for data at: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.1/client_16
📊 Loaded 8210 total samples from /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.1/client_16
🔄 Created sequences with length 10
   Final dataset shape: X (8200, 10, 24), y (8200,)
✅ Data split completed:
   Training samples: 4920
   Validation samples: 1640
   Test samples: 1640
   Model type: lstm
✅ Client client_16 ready:
   Model: LSTM
   Training: 4920 samples
   Device: cuda
   Validation: 1640 samples
   Test: 1640 samples
   Algorithm: fedavg
   Total Rounds: 10
   Learning Rate: 0.001
   Batch Size: 32
   Logging to: logs

🧪 Round 0 Evaluation Results:
   Test Loss: 16900.4455
   RMSE: 130.0017, MAE: 96.4788, R²: -0.6863
💾 Test metrics saved to: logs/client_16_test_metrics_20251029_151832.csv
⏩ Skipping CV for Round 2 (runs every 5 rounds)
Round 2: train_loss=10774.4434, val_loss=9948.8857, val_r2=-0.0244
💾 Training metrics saved to: logs/client_16_training_metrics_20251029_151832.csv

🧪 Round 2 Evaluation Results:
   Test Loss: 10821.2136
   RMSE: 104.0251, MAE: 78.7038, R²: -0.0797
💾 Test metrics saved to: logs/client_16_test_metrics_20251029_151832.csv
⏩ Skipping CV for Round 3 (runs every 5 rounds)

🎯 Round 3 Training Results:
   Training - Loss: 10620.9863, RMSE: 103.0582, R²: -0.0088
   Validation - Loss: 9799.2207, RMSE: 98.9910, R²: -0.0089

🧪 Round 3 Evaluation Results:
   Test Loss: 10685.1685
   RMSE: 103.3691, MAE: 78.4344, R²: -0.0661
💾 Test metrics saved to: logs/client_16_test_metrics_20251029_151832.csv
⏩ Skipping CV for Round 4 (runs every 5 rounds)
Round 4: train_loss=10636.2871, val_loss=9814.0410, val_r2=-0.0105
💾 Training metrics saved to: logs/client_16_training_metrics_20251029_151832.csv

🧪 Round 4 Evaluation Results:
   Test Loss: 10689.3449
   RMSE: 103.3893, MAE: 78.4418, R²: -0.0665
💾 Test metrics saved to: logs/client_16_test_metrics_20251029_151832.csv

🔍 Running 3-fold cross-validation (Round 5)

🔍 Starting 3-fold cross-validation on TRAINING data for client client_16

📊 Fold 1/3
   Fold 1 Results:
     Val Loss: 10287.4004
     Val RMSE: 101.4268, Val R²: -0.0072

📊 Fold 2/3
   Fold 2 Results:
     Val Loss: 11150.5723
     Val RMSE: 105.5963, Val R²: -0.0243

📊 Fold 3/3
   Fold 3 Results:
     Val Loss: 10508.0527
     Val RMSE: 102.5088, Val R²: -0.0048
💾 CV metrics saved to: logs/client_16_cv_metrics_20251029_151832.csv

📈 3-Fold CV Summary (Training Data):
   VAL_LOSS: 10648.6751 ± 366.1488
   RMSE: 103.1773 ± 1.7666
   R2: -0.0121 ± 0.0087

🎯 Round 5 Training Results:
   Training - Loss: 10636.0645, RMSE: 103.1313, R²: -0.0102
   Validation - Loss: 9813.8271, RMSE: 99.0648, R²: -0.0104
💾 Training metrics saved to: logs/client_16_training_metrics_20251029_151832.csv

🧪 Round 5 Evaluation Results:
   Test Loss: 10655.9211
   RMSE: 103.2275, MAE: 78.3819, R²: -0.0632
💾 Test metrics saved to: logs/client_16_test_metrics_20251029_151832.csv
⏩ Skipping CV for Round 6 (runs every 5 rounds)

🎯 Round 6 Training Results:
   Training - Loss: 10680.1748, RMSE: 103.3449, R²: -0.0144
   Validation - Loss: 9856.7236, RMSE: 99.2810, R²: -0.0149
💾 Training metrics saved to: logs/client_16_training_metrics_20251029_151832.csv

🧪 Round 6 Evaluation Results:
   Test Loss: 10660.4240
   RMSE: 103.2493, MAE: 78.3900, R²: -0.0637
💾 Test metrics saved to: logs/client_16_test_metrics_20251029_151832.csv
⏩ Skipping CV for Round 7 (runs every 5 rounds)
Round 7: train_loss=10597.6455, val_loss=9776.6924, val_r2=-0.0066

🧪 Round 7 Evaluation Results:
   Test Loss: 10635.7161
   RMSE: 103.1296, MAE: 78.3455, R²: -0.0612
💾 Test metrics saved to: logs/client_16_test_metrics_20251029_151832.csv
⏩ Skipping CV for Round 8 (runs every 5 rounds)
Round 8: train_loss=10647.6436, val_loss=9825.0654, val_r2=-0.0116
💾 Training metrics saved to: logs/client_16_training_metrics_20251029_151832.csv

🧪 Round 8 Evaluation Results:
   Test Loss: 10650.4180
   RMSE: 103.2009, MAE: 78.3718, R²: -0.0627
💾 Test metrics saved to: logs/client_16_test_metrics_20251029_151832.csv

🔍 Running 3-fold cross-validation (Round 9)
💾 CV metrics saved to: logs/client_16_cv_metrics_20251029_151832.csv

🎯 Round 9 Training Results:
   Training - Loss: 10643.6172, RMSE: 103.1679, R²: -0.0110
   Validation - Loss: 9821.1582, RMSE: 99.1018, R²: -0.0112
💾 Training metrics saved to: logs/client_16_training_metrics_20251029_151832.csv

🧪 Round 9 Evaluation Results:
   Test Loss: 10679.4371
   RMSE: 103.3414, MAE: 78.4242, R²: -0.0656
💾 Test metrics saved to: logs/client_16_test_metrics_20251029_151832.csv

🔍 Running 3-fold cross-validation (Round 10)
💾 CV metrics saved to: logs/client_16_cv_metrics_20251029_151832.csv

🎯 Round 10 Training Results:
   Training - Loss: 10617.7490, RMSE: 103.0425, R²: -0.0085
   Validation - Loss: 9796.0908, RMSE: 98.9752, R²: -0.0086
💾 Training metrics saved to: logs/client_16_training_metrics_20251029_151832.csv

🧪 Round 10 Evaluation Results:
   Test Loss: 10650.2788
   RMSE: 103.2002, MAE: 78.3716, R²: -0.0626
💾 Test metrics saved to: logs/client_16_test_metrics_20251029_151832.csv

================================================================================
🎯 FINAL COMPREHENSIVE REPORT
================================================================================
💾 Final summary saved to: logs/client_16_final_summary_20251029_151832.csv

📊 CLIENT: client_16 | ALGORITHM: fedavg | MODEL: LSTM
📈 TOTAL ROUNDS: 10

⚙️  HYPERPARAMETERS:
   Learning Rate: 0.001
   Batch Size: 32
   Local Epochs: 1
   Hidden Dim: 64
   Num Layers: 2
   Sequence Length: 10
   Use Attention: False
   Dropout: 0.3
   Optimizer: adam

🏁 FINAL ROUND PERFORMANCE:
   Training   - Loss: 10617.75 | RMSE: 103.04 | R²: -0.0085
   Validation - Loss:  9796.09 | RMSE:  98.98 | R²: -0.0086
   Test       - Loss: 10650.28 | RMSE: 103.20 | R²: -0.0626

📊 STATISTICS ACROSS ALL ROUNDS (Mean ± Std):
   Training Loss:   10662.28 ±  49.00
   Validation Loss:  9839.40 ±  47.81
   Test Loss:       11302.84 ± 1866.53

   Training RMSE:   103.26 ±  0.24
   Validation RMSE:  99.19 ±  0.24
   Test RMSE:       106.01 ±  8.00

   Training R²:     -0.0127 ± 0.0047
   Validation R²:   -0.0131 ± 0.0049
   Test R²:         -0.1278 ± 0.1862

⭐ BEST PERFORMANCE:
   Best Round: 7 (Test R²: -0.0612)

📋 DATA SUMMARY:
   Training samples:   4920
   Validation samples: 1640
   Test samples:       1640
   Total samples:      8200
================================================================================
✅ Client client_16 completed | Algorithm: FEDAVG
