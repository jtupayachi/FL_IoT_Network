[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 97990ba3-9184-4436-b6f3-563f6136eda6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3c9e34d5-6201-4714-bd4d-2adaf9920150
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a8f5efd0-eff7-44a6-b20b-67b63896e214
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2368897b-16e7-4c29-91ce-4812e4cc7d4c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fa969f1c-4785-4936-b17a-f2abcdaace77
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8207b7b0-97e2-46b4-b60d-9ce86d1f41dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6d747e9b-5287-40ee-a78d-d77582678698
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0cd3f041-5154-4b23-a78f-5be5a199fd46
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 46263d84-6155-4ca7-b8cb-883c5ec92b78
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 427eecb7-20c1-4fd6-b298-d5e5eccc2e7e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a97e2f9b-a03c-402c-aca7-0f311b47d416
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8c23f4a5-51e7-4c05-a7cb-86dabe837722
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6978811c-40ae-46cc-80e9-c9c3cf012407
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5466a590-d2e8-417f-bfdd-00f7b9944fa3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 47974021-dab5-462b-b8fc-5077cd440a5d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 64ae6f24-28d8-45d5-ba29-002059a7d528
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f196bd8b-30c1-49d4-954a-b88cdd7294da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dc721ece-71f1-4991-9ec4-4d50ef9b9d90
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 79c3c0e1-62bb-4209-a677-8a27b72aca2e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: reconnect message 1899a2c9-4f27-499b-9509-b6443708db6c
[92mINFO [0m:      Disconnect and shut down
ğŸš€ Starting NASA FL Client: client_16
Algorithm: FEDAVG
Server: localhost:8686
K-Folds: 5
Log Directory: logs
ğŸ”„ Using device: cuda
ğŸ¯ GPU: NVIDIA A100-SXM4-80GB
ğŸ’¾ Hyperparameters saved to: logs/client_16_hyperparams_20251029_151832.csv
ğŸ” Looking for data at: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.1/client_16
ğŸ“Š Loaded 8210 total samples from /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.1/client_16
ğŸ”„ Created sequences with length 10
   Final dataset shape: X (8200, 10, 24), y (8200,)
âœ… Data split completed:
   Training samples: 4920
   Validation samples: 1640
   Test samples: 1640
   Model type: lstm
âœ… Client client_16 ready:
   Model: LSTM
   Training: 4920 samples
   Device: cuda
   Validation: 1640 samples
   Test: 1640 samples
   Algorithm: fedavg
   Total Rounds: 10
   Learning Rate: 0.001
   Batch Size: 32
   Logging to: logs

ğŸ§ª Round 0 Evaluation Results:
   Test Loss: 16900.4455
   RMSE: 130.0017, MAE: 96.4788, RÂ²: -0.6863
ğŸ’¾ Test metrics saved to: logs/client_16_test_metrics_20251029_151832.csv
â© Skipping CV for Round 2 (runs every 5 rounds)
Round 2: train_loss=10774.4434, val_loss=9948.8857, val_r2=-0.0244
ğŸ’¾ Training metrics saved to: logs/client_16_training_metrics_20251029_151832.csv

ğŸ§ª Round 2 Evaluation Results:
   Test Loss: 10821.2136
   RMSE: 104.0251, MAE: 78.7038, RÂ²: -0.0797
ğŸ’¾ Test metrics saved to: logs/client_16_test_metrics_20251029_151832.csv
â© Skipping CV for Round 3 (runs every 5 rounds)

ğŸ¯ Round 3 Training Results:
   Training - Loss: 10620.9863, RMSE: 103.0582, RÂ²: -0.0088
   Validation - Loss: 9799.2207, RMSE: 98.9910, RÂ²: -0.0089

ğŸ§ª Round 3 Evaluation Results:
   Test Loss: 10685.1685
   RMSE: 103.3691, MAE: 78.4344, RÂ²: -0.0661
ğŸ’¾ Test metrics saved to: logs/client_16_test_metrics_20251029_151832.csv
â© Skipping CV for Round 4 (runs every 5 rounds)
Round 4: train_loss=10636.2871, val_loss=9814.0410, val_r2=-0.0105
ğŸ’¾ Training metrics saved to: logs/client_16_training_metrics_20251029_151832.csv

ğŸ§ª Round 4 Evaluation Results:
   Test Loss: 10689.3449
   RMSE: 103.3893, MAE: 78.4418, RÂ²: -0.0665
ğŸ’¾ Test metrics saved to: logs/client_16_test_metrics_20251029_151832.csv

ğŸ” Running 3-fold cross-validation (Round 5)

ğŸ” Starting 3-fold cross-validation on TRAINING data for client client_16

ğŸ“Š Fold 1/3
   Fold 1 Results:
     Val Loss: 10287.4004
     Val RMSE: 101.4268, Val RÂ²: -0.0072

ğŸ“Š Fold 2/3
   Fold 2 Results:
     Val Loss: 11150.5723
     Val RMSE: 105.5963, Val RÂ²: -0.0243

ğŸ“Š Fold 3/3
   Fold 3 Results:
     Val Loss: 10508.0527
     Val RMSE: 102.5088, Val RÂ²: -0.0048
ğŸ’¾ CV metrics saved to: logs/client_16_cv_metrics_20251029_151832.csv

ğŸ“ˆ 3-Fold CV Summary (Training Data):
   VAL_LOSS: 10648.6751 Â± 366.1488
   RMSE: 103.1773 Â± 1.7666
   R2: -0.0121 Â± 0.0087

ğŸ¯ Round 5 Training Results:
   Training - Loss: 10636.0645, RMSE: 103.1313, RÂ²: -0.0102
   Validation - Loss: 9813.8271, RMSE: 99.0648, RÂ²: -0.0104
ğŸ’¾ Training metrics saved to: logs/client_16_training_metrics_20251029_151832.csv

ğŸ§ª Round 5 Evaluation Results:
   Test Loss: 10655.9211
   RMSE: 103.2275, MAE: 78.3819, RÂ²: -0.0632
ğŸ’¾ Test metrics saved to: logs/client_16_test_metrics_20251029_151832.csv
â© Skipping CV for Round 6 (runs every 5 rounds)

ğŸ¯ Round 6 Training Results:
   Training - Loss: 10680.1748, RMSE: 103.3449, RÂ²: -0.0144
   Validation - Loss: 9856.7236, RMSE: 99.2810, RÂ²: -0.0149
ğŸ’¾ Training metrics saved to: logs/client_16_training_metrics_20251029_151832.csv

ğŸ§ª Round 6 Evaluation Results:
   Test Loss: 10660.4240
   RMSE: 103.2493, MAE: 78.3900, RÂ²: -0.0637
ğŸ’¾ Test metrics saved to: logs/client_16_test_metrics_20251029_151832.csv
â© Skipping CV for Round 7 (runs every 5 rounds)
Round 7: train_loss=10597.6455, val_loss=9776.6924, val_r2=-0.0066

ğŸ§ª Round 7 Evaluation Results:
   Test Loss: 10635.7161
   RMSE: 103.1296, MAE: 78.3455, RÂ²: -0.0612
ğŸ’¾ Test metrics saved to: logs/client_16_test_metrics_20251029_151832.csv
â© Skipping CV for Round 8 (runs every 5 rounds)
Round 8: train_loss=10647.6436, val_loss=9825.0654, val_r2=-0.0116
ğŸ’¾ Training metrics saved to: logs/client_16_training_metrics_20251029_151832.csv

ğŸ§ª Round 8 Evaluation Results:
   Test Loss: 10650.4180
   RMSE: 103.2009, MAE: 78.3718, RÂ²: -0.0627
ğŸ’¾ Test metrics saved to: logs/client_16_test_metrics_20251029_151832.csv

ğŸ” Running 3-fold cross-validation (Round 9)
ğŸ’¾ CV metrics saved to: logs/client_16_cv_metrics_20251029_151832.csv

ğŸ¯ Round 9 Training Results:
   Training - Loss: 10643.6172, RMSE: 103.1679, RÂ²: -0.0110
   Validation - Loss: 9821.1582, RMSE: 99.1018, RÂ²: -0.0112
ğŸ’¾ Training metrics saved to: logs/client_16_training_metrics_20251029_151832.csv

ğŸ§ª Round 9 Evaluation Results:
   Test Loss: 10679.4371
   RMSE: 103.3414, MAE: 78.4242, RÂ²: -0.0656
ğŸ’¾ Test metrics saved to: logs/client_16_test_metrics_20251029_151832.csv

ğŸ” Running 3-fold cross-validation (Round 10)
ğŸ’¾ CV metrics saved to: logs/client_16_cv_metrics_20251029_151832.csv

ğŸ¯ Round 10 Training Results:
   Training - Loss: 10617.7490, RMSE: 103.0425, RÂ²: -0.0085
   Validation - Loss: 9796.0908, RMSE: 98.9752, RÂ²: -0.0086
ğŸ’¾ Training metrics saved to: logs/client_16_training_metrics_20251029_151832.csv

ğŸ§ª Round 10 Evaluation Results:
   Test Loss: 10650.2788
   RMSE: 103.2002, MAE: 78.3716, RÂ²: -0.0626
ğŸ’¾ Test metrics saved to: logs/client_16_test_metrics_20251029_151832.csv

================================================================================
ğŸ¯ FINAL COMPREHENSIVE REPORT
================================================================================
ğŸ’¾ Final summary saved to: logs/client_16_final_summary_20251029_151832.csv

ğŸ“Š CLIENT: client_16 | ALGORITHM: fedavg | MODEL: LSTM
ğŸ“ˆ TOTAL ROUNDS: 10

âš™ï¸  HYPERPARAMETERS:
   Learning Rate: 0.001
   Batch Size: 32
   Local Epochs: 1
   Hidden Dim: 64
   Num Layers: 2
   Sequence Length: 10
   Use Attention: False
   Dropout: 0.3
   Optimizer: adam

ğŸ FINAL ROUND PERFORMANCE:
   Training   - Loss: 10617.75 | RMSE: 103.04 | RÂ²: -0.0085
   Validation - Loss:  9796.09 | RMSE:  98.98 | RÂ²: -0.0086
   Test       - Loss: 10650.28 | RMSE: 103.20 | RÂ²: -0.0626

ğŸ“Š STATISTICS ACROSS ALL ROUNDS (Mean Â± Std):
   Training Loss:   10662.28 Â±  49.00
   Validation Loss:  9839.40 Â±  47.81
   Test Loss:       11302.84 Â± 1866.53

   Training RMSE:   103.26 Â±  0.24
   Validation RMSE:  99.19 Â±  0.24
   Test RMSE:       106.01 Â±  8.00

   Training RÂ²:     -0.0127 Â± 0.0047
   Validation RÂ²:   -0.0131 Â± 0.0049
   Test RÂ²:         -0.1278 Â± 0.1862

â­ BEST PERFORMANCE:
   Best Round: 7 (Test RÂ²: -0.0612)

ğŸ“‹ DATA SUMMARY:
   Training samples:   4920
   Validation samples: 1640
   Test samples:       1640
   Total samples:      8200
================================================================================
âœ… Client client_16 completed | Algorithm: FEDAVG
