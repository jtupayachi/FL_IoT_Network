[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 63acbfde-043a-41b1-a8c2-7680df614c9f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 35548171-3069-4c50-9231-f25c70632f61
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f16756a7-46fc-4bc4-a347-96e7ef0064df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3c6a1e22-6778-4dd1-9871-0a2cd94a5acb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4bb6df60-3fa9-45d3-83e8-69bb2c1874a3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 861e904e-7679-4e78-acdc-81c96c0ecfdb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2323b590-b09b-4ec3-9ab9-000a8107a884
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 49d0fa6c-963a-4fd6-9302-00b8435921be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 377d2a52-1599-4191-b404-1fd12ebcd731
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 33c28fb8-16ad-425d-9a54-d71b7d6b4b6b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e5abadbf-5193-4cc1-8d2f-d76f7e3e8df7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 57ff6f99-16ea-445a-9856-d7fbf53d372a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b8930e8d-de02-4c02-b53d-08995e17fda2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message faed298b-9bf8-4285-883b-884722ac5e88
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 52c4f800-c7a1-4790-a25c-d286ff03a654
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5a42b6a0-d3af-41f4-b93d-38fbc896a83c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b1619745-3afa-4eb8-aeaf-c860280f482d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bef0ea81-6dd7-4717-9437-2c8577b86130
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 05a19c89-66f7-4775-ac56-031af073f73d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 04193a4a-7e7b-4215-8f05-a41b887d503a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: reconnect message 79954b0a-9cab-48a0-b6ff-7d65f95cafe6
[92mINFO [0m:      Disconnect and shut down
🚀 Starting NASA FL Client: client_19
Algorithm: FEDAVG
Server: localhost:8686
K-Folds: 5
Log Directory: logs
🔄 Using device: cuda
🎯 GPU: NVIDIA A100-SXM4-80GB
💾 Hyperparameters saved to: logs/client_19_hyperparams_20251029_151838.csv
🔍 Looking for data at: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.1/client_19
📊 Loaded 8316 total samples from /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.1/client_19
🔄 Created sequences with length 10
   Final dataset shape: X (8306, 10, 24), y (8306,)
✅ Data split completed:
   Training samples: 4983
   Validation samples: 1661
   Test samples: 1662
   Model type: lstm
✅ Client client_19 ready:
   Model: LSTM
   Training: 4983 samples
   Device: cuda
   Validation: 1661 samples
   Test: 1662 samples
   Algorithm: fedavg
   Total Rounds: 10
   Learning Rate: 0.001
   Batch Size: 32
   Logging to: logs
⏩ Skipping CV for Round 1 (runs every 5 rounds)
Round 1: train_loss=9536.4746, val_loss=9617.2500, val_r2=-0.0917

🧪 Round 1 Evaluation Results:
   Test Loss: 13403.4742
   RMSE: 115.7734, MAE: 88.8943, R²: -0.7353
💾 Test metrics saved to: logs/client_19_test_metrics_20251029_151838.csv
⏩ Skipping CV for Round 2 (runs every 5 rounds)
Round 2: train_loss=8744.7559, val_loss=8858.3330, val_r2=-0.0056
💾 Training metrics saved to: logs/client_19_training_metrics_20251029_151838.csv

🧪 Round 2 Evaluation Results:
   Test Loss: 8151.9908
   RMSE: 90.2884, MAE: 73.1534, R²: -0.0554
💾 Test metrics saved to: logs/client_19_test_metrics_20251029_151838.csv
⏩ Skipping CV for Round 3 (runs every 5 rounds)

🎯 Round 3 Training Results:
   Training - Loss: 8734.7285, RMSE: 93.4598, R²: -0.0058
   Validation - Loss: 8849.3379, RMSE: 94.0709, R²: -0.0046

🧪 Round 3 Evaluation Results:
   Test Loss: 8054.0854
   RMSE: 89.7446, MAE: 73.0121, R²: -0.0428
💾 Test metrics saved to: logs/client_19_test_metrics_20251029_151838.csv
⏩ Skipping CV for Round 4 (runs every 5 rounds)
Round 4: train_loss=8708.7598, val_loss=8826.6699, val_r2=-0.0020
💾 Training metrics saved to: logs/client_19_training_metrics_20251029_151838.csv

🧪 Round 4 Evaluation Results:
   Test Loss: 8057.0354
   RMSE: 89.7610, MAE: 73.0156, R²: -0.0431
💾 Test metrics saved to: logs/client_19_test_metrics_20251029_151838.csv

🔍 Running 3-fold cross-validation (Round 5)

🔍 Starting 3-fold cross-validation on TRAINING data for client client_19

📊 Fold 1/3
   Fold 1 Results:
     Val Loss: 8408.3838
     Val RMSE: 91.6972, Val R²: -0.0192

📊 Fold 2/3
   Fold 2 Results:
     Val Loss: 9074.4912
     Val RMSE: 95.2601, Val R²: -0.0077

📊 Fold 3/3
   Fold 3 Results:
     Val Loss: 8803.7383
     Val RMSE: 93.8282, Val R²: -0.0013
💾 CV metrics saved to: logs/client_19_cv_metrics_20251029_151838.csv

📈 3-Fold CV Summary (Training Data):
   VAL_LOSS: 8762.2044 ± 273.5185
   RMSE: 93.5952 ± 1.4638
   R2: -0.0094 ± 0.0074

🎯 Round 5 Training Results:
   Training - Loss: 8770.7324, RMSE: 93.6522, R²: -0.0100
   Validation - Loss: 8881.9785, RMSE: 94.2442, R²: -0.0083
💾 Training metrics saved to: logs/client_19_training_metrics_20251029_151838.csv

🧪 Round 5 Evaluation Results:
   Test Loss: 8033.5355
   RMSE: 89.6300, MAE: 72.9872, R²: -0.0401
💾 Test metrics saved to: logs/client_19_test_metrics_20251029_151838.csv
⏩ Skipping CV for Round 6 (runs every 5 rounds)

🎯 Round 6 Training Results:
   Training - Loss: 8731.9443, RMSE: 93.4449, R²: -0.0055
   Validation - Loss: 8846.8574, RMSE: 94.0577, R²: -0.0043
💾 Training metrics saved to: logs/client_19_training_metrics_20251029_151838.csv

🧪 Round 6 Evaluation Results:
   Test Loss: 8036.6864
   RMSE: 89.6476, MAE: 72.9910, R²: -0.0405
💾 Test metrics saved to: logs/client_19_test_metrics_20251029_151838.csv
⏩ Skipping CV for Round 7 (runs every 5 rounds)
Round 7: train_loss=8729.8633, val_loss=8845.0088, val_r2=-0.0041

🧪 Round 7 Evaluation Results:
   Test Loss: 8019.4570
   RMSE: 89.5514, MAE: 72.9701, R²: -0.0383
💾 Test metrics saved to: logs/client_19_test_metrics_20251029_151838.csv
⏩ Skipping CV for Round 8 (runs every 5 rounds)
Round 8: train_loss=8717.5068, val_loss=8834.1650, val_r2=-0.0028
💾 Training metrics saved to: logs/client_19_training_metrics_20251029_151838.csv

🧪 Round 8 Evaluation Results:
   Test Loss: 8029.6912
   RMSE: 89.6085, MAE: 72.9824, R²: -0.0396
💾 Test metrics saved to: logs/client_19_test_metrics_20251029_151838.csv

🔍 Running 3-fold cross-validation (Round 9)
💾 CV metrics saved to: logs/client_19_cv_metrics_20251029_151838.csv

🎯 Round 9 Training Results:
   Training - Loss: 8757.0605, RMSE: 93.5792, R²: -0.0084
   Validation - Loss: 8869.4814, RMSE: 94.1779, R²: -0.0068
💾 Training metrics saved to: logs/client_19_training_metrics_20251029_151838.csv

🧪 Round 9 Evaluation Results:
   Test Loss: 8050.0431
   RMSE: 89.7220, MAE: 73.0072, R²: -0.0422
💾 Test metrics saved to: logs/client_19_test_metrics_20251029_151838.csv

🔍 Running 3-fold cross-validation (Round 10)
💾 CV metrics saved to: logs/client_19_cv_metrics_20251029_151838.csv

🎯 Round 10 Training Results:
   Training - Loss: 8701.3457, RMSE: 93.2810, R²: -0.0020
   Validation - Loss: 8820.5049, RMSE: 93.9175, R²: -0.0013
💾 Training metrics saved to: logs/client_19_training_metrics_20251029_151838.csv

🧪 Round 10 Evaluation Results:
   Test Loss: 8029.5942
   RMSE: 89.6080, MAE: 72.9823, R²: -0.0396
💾 Test metrics saved to: logs/client_19_test_metrics_20251029_151838.csv

================================================================================
🎯 FINAL COMPREHENSIVE REPORT
================================================================================
💾 Final summary saved to: logs/client_19_final_summary_20251029_151838.csv

📊 CLIENT: client_19 | ALGORITHM: fedavg | MODEL: LSTM
📈 TOTAL ROUNDS: 10

⚙️  HYPERPARAMETERS:
   Learning Rate: 0.001
   Batch Size: 32
   Local Epochs: 1
   Hidden Dim: 64
   Num Layers: 2
   Sequence Length: 10
   Use Attention: False
   Dropout: 0.3
   Optimizer: adam

🏁 FINAL ROUND PERFORMANCE:
   Training   - Loss:  8701.35 | RMSE:  93.28 | R²: -0.0020
   Validation - Loss:  8820.50 | RMSE:  93.92 | R²: -0.0013
   Test       - Loss:  8029.59 | RMSE:  89.61 | R²: -0.0396

📊 STATISTICS ACROSS ALL ROUNDS (Mean ± Std):
   Training Loss:    8733.16 ±  23.82
   Validation Loss:  8848.28 ±  21.13
   Test Loss:        8586.56 ± 1606.03

   Training RMSE:    93.45 ±  0.13
   Validation RMSE:  94.07 ±  0.11
   Test RMSE:        92.33 ±  7.82

   Training R²:     -0.0056 ± 0.0027
   Validation R²:   -0.0044 ± 0.0024
   Test R²:         -0.1117 ± 0.2079

⭐ BEST PERFORMANCE:
   Best Round: 7 (Test R²: -0.0383)

📋 DATA SUMMARY:
   Training samples:   4983
   Validation samples: 1661
   Test samples:       1662
   Total samples:      8306
================================================================================
✅ Client client_19 completed | Algorithm: FEDAVG
