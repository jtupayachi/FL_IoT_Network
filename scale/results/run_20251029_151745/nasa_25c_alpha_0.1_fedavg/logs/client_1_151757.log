[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5ff46cf8-fd2b-43b0-8c6a-c0412a841344
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 736cfe43-2aba-4bb5-b139-9fc677c1aa57
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ec3e161d-8748-4365-bacb-9dc0e9e4a130
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message faee946d-ff57-4e5b-b725-708f5d1cd1bc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3b1ca40e-0b00-4437-9dc9-302504b28385
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c838cef7-2cc0-47bc-b523-5d939d2e0918
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 68909a3a-f565-47f4-b7f9-4f3caed36d8b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 95e5fb3f-f94c-4f60-b3fb-86e3fe2c955b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a742bf9c-9bb4-45a8-9dd5-0cac6d751d3f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2cf22cdc-c5c3-4c83-9162-159b17934ee8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message db726d07-ee69-4e19-8176-3f717b056bc4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6e6056b3-4567-496b-98b6-b06ca554ab38
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0db0dbd7-2b51-4f94-9d8a-b2908eb06059
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b6c56dec-1d96-4849-8abf-fbaba5145071
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 61418a67-08e9-43ef-80ea-560d501f4f4a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9d28ec98-c408-4514-8a54-e64faf0f7bef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b0f25940-a562-4aaa-b6cd-6e867e8085b7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bddc26d4-9e45-4a5b-923c-9dd6809c2451
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2deac923-c0ea-4e7b-998a-4310c3c2cc14
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 70af49bd-168d-4750-8bed-f49c5f904494
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: reconnect message ea17fe41-6f15-4073-80e2-a36d9a08a7e0
[92mINFO [0m:      Disconnect and shut down
🚀 Starting NASA FL Client: client_1
Algorithm: FEDAVG
Server: localhost:8686
K-Folds: 5
Log Directory: logs
🔄 Using device: cuda
🎯 GPU: NVIDIA A100-SXM4-80GB
💾 Hyperparameters saved to: logs/client_1_hyperparams_20251029_151810.csv
🔍 Looking for data at: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.1/client_1
📊 Loaded 5645 total samples from /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.1/client_1
🔄 Created sequences with length 10
   Final dataset shape: X (5635, 10, 24), y (5635,)
✅ Data split completed:
   Training samples: 3381
   Validation samples: 1127
   Test samples: 1127
   Model type: lstm
✅ Client client_1 ready:
   Model: LSTM
   Training: 3381 samples
   Device: cuda
   Validation: 1127 samples
   Test: 1127 samples
   Algorithm: fedavg
   Total Rounds: 10
   Learning Rate: 0.001
   Batch Size: 32
   Logging to: logs
⏩ Skipping CV for Round 1 (runs every 5 rounds)
Round 1: train_loss=10011.3906, val_loss=9534.3408, val_r2=-0.8466

🧪 Round 1 Evaluation Results:
   Test Loss: 7791.6786
   RMSE: 88.2705, MAE: 68.7501, R²: -0.5339
💾 Test metrics saved to: logs/client_1_test_metrics_20251029_151810.csv
⏩ Skipping CV for Round 2 (runs every 5 rounds)
Round 2: train_loss=5358.0664, val_loss=5178.2720, val_r2=-0.0029
💾 Training metrics saved to: logs/client_1_training_metrics_20251029_151810.csv

🧪 Round 2 Evaluation Results:
   Test Loss: 5086.3075
   RMSE: 71.3184, MAE: 58.1322, R²: -0.0013
💾 Test metrics saved to: logs/client_1_test_metrics_20251029_151810.csv
⏩ Skipping CV for Round 3 (runs every 5 rounds)

🎯 Round 3 Training Results:
   Training - Loss: 5338.1333, RMSE: 73.0625, R²: -0.0037
   Validation - Loss: 5167.2397, RMSE: 71.8835, R²: -0.0008

🧪 Round 3 Evaluation Results:
   Test Loss: 5105.7178
   RMSE: 71.4543, MAE: 58.2642, R²: -0.0051
💾 Test metrics saved to: logs/client_1_test_metrics_20251029_151810.csv
⏩ Skipping CV for Round 4 (runs every 5 rounds)
Round 4: train_loss=5333.7852, val_loss=5165.3906, val_r2=-0.0004
💾 Training metrics saved to: logs/client_1_training_metrics_20251029_151810.csv

🧪 Round 4 Evaluation Results:
   Test Loss: 5104.8967
   RMSE: 71.4486, MAE: 58.2585, R²: -0.0050
💾 Test metrics saved to: logs/client_1_test_metrics_20251029_151810.csv

🔍 Running 3-fold cross-validation (Round 5)

🔍 Starting 3-fold cross-validation on TRAINING data for client client_1

📊 Fold 1/3
   Fold 1 Results:
     Val Loss: 5167.7197
     Val RMSE: 71.8869, Val R²: -0.0131

📊 Fold 2/3
   Fold 2 Results:
     Val Loss: 5534.8086
     Val RMSE: 74.3963, Val R²: -0.0140

📊 Fold 3/3
   Fold 3 Results:
     Val Loss: 5459.6206
     Val RMSE: 73.8892, Val R²: -0.0123
💾 CV metrics saved to: logs/client_1_cv_metrics_20251029_151810.csv

📈 3-Fold CV Summary (Training Data):
   VAL_LOSS: 5387.3830 ± 158.3293
   RMSE: 73.3908 ± 1.0834
   R2: -0.0131 ± 0.0007

🎯 Round 5 Training Results:
   Training - Loss: 5337.3350, RMSE: 73.0571, R²: -0.0035
   Validation - Loss: 5166.8774, RMSE: 71.8810, R²: -0.0007
💾 Training metrics saved to: logs/client_1_training_metrics_20251029_151810.csv

🧪 Round 5 Evaluation Results:
   Test Loss: 5111.9216
   RMSE: 71.4977, MAE: 58.3044, R²: -0.0064
💾 Test metrics saved to: logs/client_1_test_metrics_20251029_151810.csv
⏩ Skipping CV for Round 6 (runs every 5 rounds)

🎯 Round 6 Training Results:
   Training - Loss: 5331.4780, RMSE: 73.0170, R²: -0.0024
   Validation - Loss: 5164.5566, RMSE: 71.8648, R²: -0.0003
💾 Training metrics saved to: logs/client_1_training_metrics_20251029_151810.csv

🧪 Round 6 Evaluation Results:
   Test Loss: 5110.9140
   RMSE: 71.4907, MAE: 58.2982, R²: -0.0062
💾 Test metrics saved to: logs/client_1_test_metrics_20251029_151810.csv
⏩ Skipping CV for Round 7 (runs every 5 rounds)
Round 7: train_loss=5340.9131, val_loss=5168.5669, val_r2=-0.0011

🧪 Round 7 Evaluation Results:
   Test Loss: 5116.6874
   RMSE: 71.5310, MAE: 58.3341, R²: -0.0073
💾 Test metrics saved to: logs/client_1_test_metrics_20251029_151810.csv
⏩ Skipping CV for Round 8 (runs every 5 rounds)
Round 8: train_loss=5346.5635, val_loss=5171.5200, val_r2=-0.0016
💾 Training metrics saved to: logs/client_1_training_metrics_20251029_151810.csv

🧪 Round 8 Evaluation Results:
   Test Loss: 5113.1794
   RMSE: 71.5065, MAE: 58.3121, R²: -0.0066
💾 Test metrics saved to: logs/client_1_test_metrics_20251029_151810.csv

🔍 Running 3-fold cross-validation (Round 9)
💾 CV metrics saved to: logs/client_1_cv_metrics_20251029_151810.csv

🎯 Round 9 Training Results:
   Training - Loss: 5319.2231, RMSE: 72.9330, R²: -0.0001
   Validation - Loss: 5165.7119, RMSE: 71.8729, R²: -0.0005
💾 Training metrics saved to: logs/client_1_training_metrics_20251029_151810.csv

🧪 Round 9 Evaluation Results:
   Test Loss: 5106.8711
   RMSE: 71.4624, MAE: 58.2720, R²: -0.0054
💾 Test metrics saved to: logs/client_1_test_metrics_20251029_151810.csv

🔍 Running 3-fold cross-validation (Round 10)
💾 CV metrics saved to: logs/client_1_cv_metrics_20251029_151810.csv

🎯 Round 10 Training Results:
   Training - Loss: 5334.8242, RMSE: 73.0399, R²: -0.0030
   Validation - Loss: 5165.8032, RMSE: 71.8735, R²: -0.0005
💾 Training metrics saved to: logs/client_1_training_metrics_20251029_151810.csv

🧪 Round 10 Evaluation Results:
   Test Loss: 5113.2121
   RMSE: 71.5067, MAE: 58.3123, R²: -0.0066
💾 Test metrics saved to: logs/client_1_test_metrics_20251029_151810.csv

================================================================================
🎯 FINAL COMPREHENSIVE REPORT
================================================================================
💾 Final summary saved to: logs/client_1_final_summary_20251029_151810.csv

📊 CLIENT: client_1 | ALGORITHM: fedavg | MODEL: LSTM
📈 TOTAL ROUNDS: 10

⚙️  HYPERPARAMETERS:
   Learning Rate: 0.001
   Batch Size: 32
   Local Epochs: 1
   Hidden Dim: 64
   Num Layers: 2
   Sequence Length: 10
   Use Attention: False
   Dropout: 0.3
   Optimizer: adam

🏁 FINAL ROUND PERFORMANCE:
   Training   - Loss:  5334.82 | RMSE:  73.04 | R²: -0.0030
   Validation - Loss:  5165.80 | RMSE:  71.87 | R²: -0.0005
   Test       - Loss:  5113.21 | RMSE:  71.51 | R²: -0.0066

📊 STATISTICS ACROSS ALL ROUNDS (Mean ± Std):
   Training Loss:    5337.33 ±  11.31
   Validation Loss:  5168.30 ±   4.59
   Test Loss:        5376.14 ± 805.22

   Training RMSE:    73.06 ±  0.08
   Validation RMSE:  71.89 ±  0.03
   Test RMSE:        73.15 ±  5.04

   Training R²:     -0.0035 ± 0.0021
   Validation R²:   -0.0010 ± 0.0009
   Test R²:         -0.0584 ± 0.1585

⭐ BEST PERFORMANCE:
   Best Round: 2 (Test R²: -0.0013)

📋 DATA SUMMARY:
   Training samples:   3381
   Validation samples: 1127
   Test samples:       1127
   Total samples:      5635
================================================================================
✅ Client client_1 completed | Algorithm: FEDAVG
