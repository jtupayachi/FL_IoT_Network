[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 61cac3f9-d1b9-4008-815a-80b78d5da6f2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 86b67d0f-a831-4581-bd17-f1c1cfce37b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ad0d799f-980a-478d-9792-2a4076a127ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bf717178-3d0f-43b9-a1c1-6185d3b1edf1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c761462f-9090-4c72-b474-be6dd180abbf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fb508e69-ad6a-4b8f-aaff-297eadd9edfd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 759cf602-1ebd-45d0-a62e-74116a56496c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a8386a0d-0d54-4c68-87a5-d440196e78a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message da48fcb3-e930-4f8d-8488-4fceae59dd45
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ef45a0f4-a92d-42c8-8ccd-6319b5b8652a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 19a68cef-f735-4f69-a51f-14e0d36f3b0b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4e868526-0724-45b2-802e-08dee96864e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 64b93373-ea5c-4d3b-9cce-c5a86ec8dd7f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7e89b53c-c9a6-4f6f-9535-8c2fa4f32ce4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 977f6280-4ce1-4700-9cca-9433f0e9a019
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dce2e17e-ad1d-49e4-ab67-e1c006a98839
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b44beba1-7c5b-417c-b349-44422826227c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e5fbb8ff-6556-495f-8caf-1c2c5ccaf418
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 011f1ae3-2330-423f-a617-1b319c9e2ce2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: reconnect message a5275f6e-149a-40bc-b707-e4d5af91299a
[92mINFO [0m:      Disconnect and shut down
🚀 Starting NASA FL Client: client_8
Algorithm: FEDAVG
Server: localhost:8686
K-Folds: 5
Log Directory: logs
🔄 Using device: cuda
🎯 GPU: NVIDIA A100-SXM4-80GB
💾 Hyperparameters saved to: logs/client_8_hyperparams_20251029_151818.csv
🔍 Looking for data at: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.1/client_8
📊 Loaded 5083 total samples from /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.1/client_8
🔄 Created sequences with length 10
   Final dataset shape: X (5073, 10, 24), y (5073,)
✅ Data split completed:
   Training samples: 3043
   Validation samples: 1015
   Test samples: 1015
   Model type: lstm
✅ Client client_8 ready:
   Model: LSTM
   Training: 3043 samples
   Device: cuda
   Validation: 1015 samples
   Test: 1015 samples
   Algorithm: fedavg
   Total Rounds: 10
   Learning Rate: 0.001
   Batch Size: 32
   Logging to: logs

🧪 Round 0 Evaluation Results:
   Test Loss: 13192.0517
   RMSE: 114.8567, MAE: 87.0377, R²: -0.6710
💾 Test metrics saved to: logs/client_8_test_metrics_20251029_151818.csv
⏩ Skipping CV for Round 2 (runs every 5 rounds)
Round 2: train_loss=8087.2246, val_loss=7993.6787, val_r2=-0.0161
💾 Training metrics saved to: logs/client_8_training_metrics_20251029_151818.csv

🧪 Round 2 Evaluation Results:
   Test Loss: 8222.7306
   RMSE: 90.6793, MAE: 72.1941, R²: -0.0416
💾 Test metrics saved to: logs/client_8_test_metrics_20251029_151818.csv
⏩ Skipping CV for Round 3 (runs every 5 rounds)

🎯 Round 3 Training Results:
   Training - Loss: 8074.8330, RMSE: 89.8601, R²: -0.0169
   Validation - Loss: 7982.1567, RMSE: 89.3429, R²: -0.0147

🧪 Round 3 Evaluation Results:
   Test Loss: 8137.8262
   RMSE: 90.2099, MAE: 72.0896, R²: -0.0308
💾 Test metrics saved to: logs/client_8_test_metrics_20251029_151818.csv
⏩ Skipping CV for Round 4 (runs every 5 rounds)
Round 4: train_loss=8089.6953, val_loss=7995.9810, val_r2=-0.0164
💾 Training metrics saved to: logs/client_8_training_metrics_20251029_151818.csv

🧪 Round 4 Evaluation Results:
   Test Loss: 8140.3583
   RMSE: 90.2239, MAE: 72.0925, R²: -0.0311
💾 Test metrics saved to: logs/client_8_test_metrics_20251029_151818.csv

🔍 Running 3-fold cross-validation (Round 5)

🔍 Starting 3-fold cross-validation on TRAINING data for client client_8

📊 Fold 1/3
   Fold 1 Results:
     Val Loss: 8529.8115
     Val RMSE: 92.3570, Val R²: -0.0224

📊 Fold 2/3
   Fold 2 Results:
     Val Loss: 8168.7725
     Val RMSE: 90.3813, Val R²: -0.0292

📊 Fold 3/3
   Fold 3 Results:
     Val Loss: 7564.7666
     Val RMSE: 86.9757, Val R²: -0.0059
💾 CV metrics saved to: logs/client_8_cv_metrics_20251029_151818.csv

📈 3-Fold CV Summary (Training Data):
   VAL_LOSS: 8087.7835 ± 398.1183
   RMSE: 89.9046 ± 2.2226
   R2: -0.0192 ± 0.0098

🎯 Round 5 Training Results:
   Training - Loss: 8050.0103, RMSE: 89.7218, R²: -0.0137
   Validation - Loss: 7959.2080, RMSE: 89.2144, R²: -0.0117
💾 Training metrics saved to: logs/client_8_training_metrics_20251029_151818.csv

🧪 Round 5 Evaluation Results:
   Test Loss: 8120.2412
   RMSE: 90.1124, MAE: 72.0686, R²: -0.0286
💾 Test metrics saved to: logs/client_8_test_metrics_20251029_151818.csv
⏩ Skipping CV for Round 6 (runs every 5 rounds)

🎯 Round 6 Training Results:
   Training - Loss: 8049.7603, RMSE: 89.7205, R²: -0.0137
   Validation - Loss: 7958.9775, RMSE: 89.2131, R²: -0.0117
💾 Training metrics saved to: logs/client_8_training_metrics_20251029_151818.csv

🧪 Round 6 Evaluation Results:
   Test Loss: 8122.9314
   RMSE: 90.1273, MAE: 72.0719, R²: -0.0289
💾 Test metrics saved to: logs/client_8_test_metrics_20251029_151818.csv
⏩ Skipping CV for Round 7 (runs every 5 rounds)
Round 7: train_loss=7987.8857, val_loss=7903.0498, val_r2=-0.0046

🧪 Round 7 Evaluation Results:
   Test Loss: 8108.2510
   RMSE: 90.0458, MAE: 72.0549, R²: -0.0271
💾 Test metrics saved to: logs/client_8_test_metrics_20251029_151818.csv
⏩ Skipping CV for Round 8 (runs every 5 rounds)
Round 8: train_loss=8082.0493, val_loss=7988.8633, val_r2=-0.0155
💾 Training metrics saved to: logs/client_8_training_metrics_20251029_151818.csv

🧪 Round 8 Evaluation Results:
   Test Loss: 8116.9621
   RMSE: 90.0942, MAE: 72.0646, R²: -0.0282
💾 Test metrics saved to: logs/client_8_test_metrics_20251029_151818.csv

🔍 Running 3-fold cross-validation (Round 9)
💾 CV metrics saved to: logs/client_8_cv_metrics_20251029_151818.csv

🎯 Round 9 Training Results:
   Training - Loss: 8034.3604, RMSE: 89.6346, R²: -0.0118
   Validation - Loss: 7944.8501, RMSE: 89.1339, R²: -0.0099
💾 Training metrics saved to: logs/client_8_training_metrics_20251029_151818.csv

🧪 Round 9 Evaluation Results:
   Test Loss: 8134.3597
   RMSE: 90.1907, MAE: 72.0855, R²: -0.0304
💾 Test metrics saved to: logs/client_8_test_metrics_20251029_151818.csv

🔍 Running 3-fold cross-validation (Round 10)
💾 CV metrics saved to: logs/client_8_cv_metrics_20251029_151818.csv

🎯 Round 10 Training Results:
   Training - Loss: 8062.5269, RMSE: 89.7916, R²: -0.0153
   Validation - Loss: 7970.7549, RMSE: 89.2791, R²: -0.0132
💾 Training metrics saved to: logs/client_8_training_metrics_20251029_151818.csv

🧪 Round 10 Evaluation Results:
   Test Loss: 8116.8797
   RMSE: 90.0937, MAE: 72.0645, R²: -0.0281
💾 Test metrics saved to: logs/client_8_test_metrics_20251029_151818.csv

================================================================================
🎯 FINAL COMPREHENSIVE REPORT
================================================================================
💾 Final summary saved to: logs/client_8_final_summary_20251029_151818.csv

📊 CLIENT: client_8 | ALGORITHM: fedavg | MODEL: LSTM
📈 TOTAL ROUNDS: 10

⚙️  HYPERPARAMETERS:
   Learning Rate: 0.001
   Batch Size: 32
   Local Epochs: 1
   Hidden Dim: 64
   Num Layers: 2
   Sequence Length: 10
   Use Attention: False
   Dropout: 0.3
   Optimizer: adam

🏁 FINAL ROUND PERFORMANCE:
   Training   - Loss:  8062.53 | RMSE:  89.79 | R²: -0.0153
   Validation - Loss:  7970.75 | RMSE:  89.28 | R²: -0.0132
   Test       - Loss:  8116.88 | RMSE:  90.09 | R²: -0.0281

📊 STATISTICS ACROSS ALL ROUNDS (Mean ± Std):
   Training Loss:    8065.09 ±  19.99
   Validation Loss:  7973.19 ±  18.48
   Test Loss:        8641.26 ± 1517.24

   Training RMSE:    89.81 ±  0.11
   Validation RMSE:  89.29 ±  0.10
   Test RMSE:        92.66 ±  7.40

   Training R²:     -0.0156 ± 0.0025
   Validation R²:   -0.0135 ± 0.0023
   Test R²:         -0.0946 ± 0.1922

⭐ BEST PERFORMANCE:
   Best Round: 7 (Test R²: -0.0271)

📋 DATA SUMMARY:
   Training samples:   3043
   Validation samples: 1015
   Test samples:       1015
   Total samples:      5073
================================================================================
✅ Client client_8 completed | Algorithm: FEDAVG
