[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5830d9ac-c9dc-4828-8911-b20937c0e17e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7be05636-bdee-4f2f-aabd-f3ebd58ddd76
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 714fefed-1367-43c9-ba0a-b9c2d5ec3256
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4cc73e5b-18de-46e8-96e6-2ae7ee280307
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 776daa6e-498b-4b19-b8f1-db5115c93f97
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a5adb230-0b45-46ee-b117-c7b1ed7216bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 009d0144-5cef-4977-bc19-f363d0e23f0f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 12fc0070-ffc4-4e51-a79d-d7f933f615e5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 22439564-7b9f-451c-ab45-ac547cbf299c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7f9c1b56-2cbc-45aa-8a5b-3cc750a56348
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b1e1f2c6-742a-45cf-bd9f-a5e0bc0f00a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4cec04f2-f44a-4686-8c7e-a1b5fb81257d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6d27ee3f-f441-4794-aa7b-98a280a1c399
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message abd9edb3-5476-4360-a990-05a3edef8781
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 818a42d6-b1da-4bd7-9cfc-a181d308be57
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0dac7fe1-01bd-49f0-b08b-7a4a4da38b2f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3ac54612-00f2-4fae-a7b0-d070bee54dfc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bc4f0cb7-02ff-493d-a71e-3ff99c4c751e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5f71caa1-eb0d-46f1-b1fe-1dce25853645
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 47fee210-1767-4cdc-aacc-94bab52272f7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: reconnect message e312b40a-8ac5-4423-8d4e-fdd0d964d186
[92mINFO [0m:      Disconnect and shut down
🚀 Starting NASA FL Client: client_9
Algorithm: FEDAVG
Server: localhost:8686
K-Folds: 5
Log Directory: logs
🔄 Using device: cuda
🎯 GPU: NVIDIA A100-SXM4-80GB
💾 Hyperparameters saved to: logs/client_9_hyperparams_20251029_151823.csv
🔍 Looking for data at: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.1/client_9
📊 Loaded 6423 total samples from /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.1/client_9
🔄 Created sequences with length 10
   Final dataset shape: X (6413, 10, 24), y (6413,)
✅ Data split completed:
   Training samples: 3847
   Validation samples: 1283
   Test samples: 1283
   Model type: lstm
✅ Client client_9 ready:
   Model: LSTM
   Training: 3847 samples
   Device: cuda
   Validation: 1283 samples
   Test: 1283 samples
   Algorithm: fedavg
   Total Rounds: 10
   Learning Rate: 0.001
   Batch Size: 32
   Logging to: logs
⏩ Skipping CV for Round 1 (runs every 5 rounds)
Round 1: train_loss=10835.4004, val_loss=10370.6074, val_r2=-0.6522

🧪 Round 1 Evaluation Results:
   Test Loss: 9974.3534
   RMSE: 99.8717, MAE: 78.0276, R²: -0.6853
💾 Test metrics saved to: logs/client_9_test_metrics_20251029_151823.csv
⏩ Skipping CV for Round 2 (runs every 5 rounds)
Round 2: train_loss=6444.7021, val_loss=6290.5410, val_r2=-0.0022
💾 Training metrics saved to: logs/client_9_training_metrics_20251029_151823.csv

🧪 Round 2 Evaluation Results:
   Test Loss: 5999.6374
   RMSE: 77.4573, MAE: 63.0286, R²: -0.0137
💾 Test metrics saved to: logs/client_9_test_metrics_20251029_151823.csv
⏩ Skipping CV for Round 3 (runs every 5 rounds)

🎯 Round 3 Training Results:
   Training - Loss: 6466.3823, RMSE: 80.4138, R²: -0.0095
   Validation - Loss: 6304.2979, RMSE: 79.3996, R²: -0.0044

🧪 Round 3 Evaluation Results:
   Test Loss: 5960.5608
   RMSE: 77.2047, MAE: 62.9961, R²: -0.0071
💾 Test metrics saved to: logs/client_9_test_metrics_20251029_151823.csv
⏩ Skipping CV for Round 4 (runs every 5 rounds)
Round 4: train_loss=6505.2842, val_loss=6331.9507, val_r2=-0.0088
💾 Training metrics saved to: logs/client_9_training_metrics_20251029_151823.csv

🧪 Round 4 Evaluation Results:
   Test Loss: 5961.6197
   RMSE: 77.2115, MAE: 62.9955, R²: -0.0073
💾 Test metrics saved to: logs/client_9_test_metrics_20251029_151823.csv

🔍 Running 3-fold cross-validation (Round 5)

🔍 Starting 3-fold cross-validation on TRAINING data for client client_9

📊 Fold 1/3
   Fold 1 Results:
     Val Loss: 6344.0859
     Val RMSE: 79.6498, Val R²: -0.0114

📊 Fold 2/3
   Fold 2 Results:
     Val Loss: 6396.1538
     Val RMSE: 79.9760, Val R²: -0.0043

📊 Fold 3/3
   Fold 3 Results:
     Val Loss: 6845.0811
     Val RMSE: 82.7350, Val R²: -0.0421
💾 CV metrics saved to: logs/client_9_cv_metrics_20251029_151823.csv

📈 3-Fold CV Summary (Training Data):
   VAL_LOSS: 6528.4403 ± 224.9056
   RMSE: 80.7869 ± 1.3839
   R2: -0.0193 ± 0.0164

🎯 Round 5 Training Results:
   Training - Loss: 6473.1626, RMSE: 80.4560, R²: -0.0106
   Validation - Loss: 6308.9023, RMSE: 79.4286, R²: -0.0051
💾 Training metrics saved to: logs/client_9_training_metrics_20251029_151823.csv

🧪 Round 5 Evaluation Results:
   Test Loss: 5953.4267
   RMSE: 77.1585, MAE: 63.0001, R²: -0.0059
💾 Test metrics saved to: logs/client_9_test_metrics_20251029_151823.csv
⏩ Skipping CV for Round 6 (runs every 5 rounds)

🎯 Round 6 Training Results:
   Training - Loss: 6479.9541, RMSE: 80.4982, R²: -0.0117
   Validation - Loss: 6313.6221, RMSE: 79.4583, R²: -0.0059
💾 Training metrics saved to: logs/client_9_training_metrics_20251029_151823.csv

🧪 Round 6 Evaluation Results:
   Test Loss: 5954.4923
   RMSE: 77.1654, MAE: 62.9995, R²: -0.0061
💾 Test metrics saved to: logs/client_9_test_metrics_20251029_151823.csv
⏩ Skipping CV for Round 7 (runs every 5 rounds)
Round 7: train_loss=6439.4028, val_loss=6287.4932, val_r2=-0.0017

🧪 Round 7 Evaluation Results:
   Test Loss: 5948.7978
   RMSE: 77.1285, MAE: 63.0044, R²: -0.0051
💾 Test metrics saved to: logs/client_9_test_metrics_20251029_151823.csv
⏩ Skipping CV for Round 8 (runs every 5 rounds)
Round 8: train_loss=6447.3110, val_loss=6292.0967, val_r2=-0.0024
💾 Training metrics saved to: logs/client_9_training_metrics_20251029_151823.csv

🧪 Round 8 Evaluation Results:
   Test Loss: 5952.1410
   RMSE: 77.1501, MAE: 63.0009, R²: -0.0057
💾 Test metrics saved to: logs/client_9_test_metrics_20251029_151823.csv

🔍 Running 3-fold cross-validation (Round 9)
💾 CV metrics saved to: logs/client_9_cv_metrics_20251029_151823.csv

🎯 Round 9 Training Results:
   Training - Loss: 6441.9712, RMSE: 80.2619, R²: -0.0057
   Validation - Loss: 6288.9502, RMSE: 79.3029, R²: -0.0019
💾 Training metrics saved to: logs/client_9_training_metrics_20251029_151823.csv

🧪 Round 9 Evaluation Results:
   Test Loss: 5959.1238
   RMSE: 77.1954, MAE: 62.9969, R²: -0.0069
💾 Test metrics saved to: logs/client_9_test_metrics_20251029_151823.csv

🔍 Running 3-fold cross-validation (Round 10)
💾 CV metrics saved to: logs/client_9_cv_metrics_20251029_151823.csv

🎯 Round 10 Training Results:
   Training - Loss: 6455.6201, RMSE: 80.3469, R²: -0.0079
   Validation - Loss: 6297.2539, RMSE: 79.3552, R²: -0.0033
💾 Training metrics saved to: logs/client_9_training_metrics_20251029_151823.csv

🧪 Round 10 Evaluation Results:
   Test Loss: 5952.1089
   RMSE: 77.1499, MAE: 63.0009, R²: -0.0057
💾 Test metrics saved to: logs/client_9_test_metrics_20251029_151823.csv

================================================================================
🎯 FINAL COMPREHENSIVE REPORT
================================================================================
💾 Final summary saved to: logs/client_9_final_summary_20251029_151823.csv

📊 CLIENT: client_9 | ALGORITHM: fedavg | MODEL: LSTM
📈 TOTAL ROUNDS: 10

⚙️  HYPERPARAMETERS:
   Learning Rate: 0.001
   Batch Size: 32
   Local Epochs: 1
   Hidden Dim: 64
   Num Layers: 2
   Sequence Length: 10
   Use Attention: False
   Dropout: 0.3
   Optimizer: adam

🏁 FINAL ROUND PERFORMANCE:
   Training   - Loss:  6455.62 | RMSE:  80.35 | R²: -0.0079
   Validation - Loss:  6297.25 | RMSE:  79.36 | R²: -0.0033
   Test       - Loss:  5952.11 | RMSE:  77.15 | R²: -0.0057

📊 STATISTICS ACROSS ALL ROUNDS (Mean ± Std):
   Training Loss:    6464.00 ±  21.54
   Validation Loss:  6303.33 ±  14.59
   Test Loss:        6361.63 ± 1204.32

   Training RMSE:    80.40 ±  0.13
   Validation RMSE:  79.39 ±  0.09
   Test RMSE:        79.47 ±  6.80

   Training R²:     -0.0092 ± 0.0034
   Validation R²:   -0.0042 ± 0.0023
   Test R²:         -0.0749 ± 0.2035

⭐ BEST PERFORMANCE:
   Best Round: 7 (Test R²: -0.0051)

📋 DATA SUMMARY:
   Training samples:   3847
   Validation samples: 1283
   Test samples:       1283
   Total samples:      6413
================================================================================
✅ Client client_9 completed | Algorithm: FEDAVG
