[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1e0a85fe-7cdc-4fea-8810-78f733a28627
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 325c3641-c5fb-4783-bf49-c7978cf20ffb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 887ce625-e708-4516-862c-fd4ae6370605
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cf0e5090-6598-40b2-a6e6-24263306b51f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 52ba3a82-f5d3-4a0c-a6eb-cf75510628da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 54b6c873-539f-42fe-84ad-3c1223bd7b66
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 93cd9217-44b7-4df5-a418-a51d90d4f092
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 75ab6d26-f609-428e-9fa7-fee8cde93e19
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 774d2dcc-928e-4e94-8a6b-2feb97df9b21
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 58d26398-63f1-4f34-bcd3-5b8b193e6219
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 73be942d-f080-4b9b-a22a-dcdddcf4acca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 55d93b1e-f7c6-48ab-9419-870d375173b0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c2e4cb03-d4f7-4e5b-b1db-634c9002a570
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 986b4680-b1f1-4c10-b661-bf2828ab3d28
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b56ea938-5a1a-41ec-b97c-78f2331248f7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 129142b1-7561-427e-856b-6df7d99f470c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2a8490b9-89ad-419e-bcd7-0dd97225178a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 32deab6f-78d7-467e-bb8f-02f7bd1b0896
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7953dd33-f1fc-4c38-bf42-2d71f993e48e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c5193273-f7e9-42b7-9f64-fd714346cd0c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: reconnect message 92a709ab-9bd1-4b9b-bf21-45ef17354480
[92mINFO [0m:      Disconnect and shut down
🚀 Starting NASA FL Client: client_14
Algorithm: FEDAVG
Server: localhost:8686
K-Folds: 5
Log Directory: logs
🔄 Using device: cuda
🎯 GPU: NVIDIA A100-SXM4-80GB
💾 Hyperparameters saved to: logs/client_14_hyperparams_20251029_152232.csv
🔍 Looking for data at: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.1/client_14
📊 Loaded 6057 total samples from /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.1/client_14
🔄 Created sequences with length 10
   Final dataset shape: X (6047, 10, 24), y (6047,)
✅ Data split completed:
   Training samples: 3627
   Validation samples: 1210
   Test samples: 1210
   Model type: lstm
✅ Client client_14 ready:
   Model: LSTM
   Training: 3627 samples
   Device: cuda
   Validation: 1210 samples
   Test: 1210 samples
   Algorithm: fedavg
   Total Rounds: 10
   Learning Rate: 0.001
   Batch Size: 32
   Logging to: logs
⏩ Skipping CV for Round 1 (runs every 5 rounds)
Round 1: train_loss=11031.6777, val_loss=11484.1973, val_r2=-0.1689

🧪 Round 1 Evaluation Results:
   Test Loss: 10990.7626
   RMSE: 104.8368, MAE: 74.0079, R²: -0.2017
💾 Test metrics saved to: logs/client_14_test_metrics_20251029_152232.csv
⏩ Skipping CV for Round 2 (runs every 5 rounds)
Round 2: train_loss=9520.1855, val_loss=9882.1885, val_r2=-0.0059
💾 Training metrics saved to: logs/client_14_training_metrics_20251029_152232.csv

🧪 Round 2 Evaluation Results:
   Test Loss: 9189.9905
   RMSE: 95.8644, MAE: 70.5114, R²: -0.0048
💾 Test metrics saved to: logs/client_14_test_metrics_20251029_152232.csv
⏩ Skipping CV for Round 3 (runs every 5 rounds)

🎯 Round 3 Training Results:
   Training - Loss: 9561.6299, RMSE: 97.7836, R²: -0.0084
   Validation - Loss: 9931.0938, RMSE: 99.6549, R²: -0.0108

🧪 Round 3 Evaluation Results:
   Test Loss: 9178.7440
   RMSE: 95.8058, MAE: 70.5784, R²: -0.0036
💾 Test metrics saved to: logs/client_14_test_metrics_20251029_152232.csv
⏩ Skipping CV for Round 4 (runs every 5 rounds)
Round 4: train_loss=9531.3242, val_loss=9895.6182, val_r2=-0.0072
💾 Training metrics saved to: logs/client_14_training_metrics_20251029_152232.csv

🧪 Round 4 Evaluation Results:
   Test Loss: 9180.4135
   RMSE: 95.8145, MAE: 70.5675, R²: -0.0038
💾 Test metrics saved to: logs/client_14_test_metrics_20251029_152232.csv

🔍 Running 3-fold cross-validation (Round 5)

🔍 Starting 3-fold cross-validation on TRAINING data for client client_14

📊 Fold 1/3
   Fold 1 Results:
     Val Loss: 9310.4756
     Val RMSE: 96.4908, Val R²: -0.0061

📊 Fold 2/3
   Fold 2 Results:
     Val Loss: 9530.3408
     Val RMSE: 97.6235, Val R²: -0.0077

📊 Fold 3/3
   Fold 3 Results:
     Val Loss: 9740.7490
     Val RMSE: 98.6952, Val R²: -0.0010
💾 CV metrics saved to: logs/client_14_cv_metrics_20251029_152232.csv

📈 3-Fold CV Summary (Training Data):
   VAL_LOSS: 9527.1885 ± 175.6725
   RMSE: 97.6032 ± 0.9001
   R2: -0.0049 ± 0.0028

🎯 Round 5 Training Results:
   Training - Loss: 9541.4062, RMSE: 97.6801, R²: -0.0063
   Validation - Loss: 9907.5605, RMSE: 99.5367, R²: -0.0084
💾 Training metrics saved to: logs/client_14_training_metrics_20251029_152232.csv

🧪 Round 5 Evaluation Results:
   Test Loss: 9171.5690
   RMSE: 95.7683, MAE: 70.6316, R²: -0.0028
💾 Test metrics saved to: logs/client_14_test_metrics_20251029_152232.csv
⏩ Skipping CV for Round 6 (runs every 5 rounds)

🎯 Round 6 Training Results:
   Training - Loss: 9538.8633, RMSE: 97.6671, R²: -0.0060
   Validation - Loss: 9904.5635, RMSE: 99.5217, R²: -0.0081
💾 Training metrics saved to: logs/client_14_training_metrics_20251029_152232.csv

🧪 Round 6 Evaluation Results:
   Test Loss: 9172.9348
   RMSE: 95.7754, MAE: 70.6204, R²: -0.0030
💾 Test metrics saved to: logs/client_14_test_metrics_20251029_152232.csv
⏩ Skipping CV for Round 7 (runs every 5 rounds)
Round 7: train_loss=9552.0996, val_loss=9920.0645, val_r2=-0.0097

🧪 Round 7 Evaluation Results:
   Test Loss: 9173.8820
   RMSE: 95.7804, MAE: 70.6128, R²: -0.0031
💾 Test metrics saved to: logs/client_14_test_metrics_20251029_152232.csv
⏩ Skipping CV for Round 8 (runs every 5 rounds)
Round 8: train_loss=9547.3857, val_loss=9914.5703, val_r2=-0.0091
💾 Training metrics saved to: logs/client_14_training_metrics_20251029_152232.csv

🧪 Round 8 Evaluation Results:
   Test Loss: 9177.9328
   RMSE: 95.8015, MAE: 70.5838, R²: -0.0035
💾 Test metrics saved to: logs/client_14_test_metrics_20251029_152232.csv

🔍 Running 3-fold cross-validation (Round 9)
💾 CV metrics saved to: logs/client_14_cv_metrics_20251029_152232.csv

🎯 Round 9 Training Results:
   Training - Loss: 9535.3623, RMSE: 97.6492, R²: -0.0057
   Validation - Loss: 9900.4229, RMSE: 99.5009, R²: -0.0077
💾 Training metrics saved to: logs/client_14_training_metrics_20251029_152232.csv

🧪 Round 9 Evaluation Results:
   Test Loss: 9175.3044
   RMSE: 95.7878, MAE: 70.6019, R²: -0.0032
💾 Test metrics saved to: logs/client_14_test_metrics_20251029_152232.csv

🔍 Running 3-fold cross-validation (Round 10)
💾 CV metrics saved to: logs/client_14_cv_metrics_20251029_152232.csv

🎯 Round 10 Training Results:
   Training - Loss: 9529.0283, RMSE: 97.6167, R²: -0.0050
   Validation - Loss: 9892.8730, RMSE: 99.4629, R²: -0.0069
💾 Training metrics saved to: logs/client_14_training_metrics_20251029_152232.csv

🧪 Round 10 Evaluation Results:
   Test Loss: 9173.6646
   RMSE: 95.7792, MAE: 70.6145, R²: -0.0030
💾 Test metrics saved to: logs/client_14_test_metrics_20251029_152232.csv

================================================================================
🎯 FINAL COMPREHENSIVE REPORT
================================================================================
💾 Final summary saved to: logs/client_14_final_summary_20251029_152232.csv

📊 CLIENT: client_14 | ALGORITHM: fedavg | MODEL: LSTM
📈 TOTAL ROUNDS: 10

⚙️  HYPERPARAMETERS:
   Learning Rate: 0.001
   Batch Size: 32
   Local Epochs: 1
   Hidden Dim: 64
   Num Layers: 2
   Sequence Length: 10
   Use Attention: False
   Dropout: 0.3
   Optimizer: adam

🏁 FINAL ROUND PERFORMANCE:
   Training   - Loss:  9529.03 | RMSE:  97.62 | R²: -0.0050
   Validation - Loss:  9892.87 | RMSE:  99.46 | R²: -0.0069
   Test       - Loss:  9173.66 | RMSE:  95.78 | R²: -0.0030

📊 STATISTICS ACROSS ALL ROUNDS (Mean ± Std):
   Training Loss:    9534.79 ±   8.26
   Validation Loss:  9899.69 ±   9.83
   Test Loss:        9358.52 ± 544.10

   Training RMSE:    97.65 ±  0.04
   Validation RMSE:  99.50 ±  0.05
   Test RMSE:        96.70 ±  2.71

   Training R²:     -0.0056 ± 0.0009
   Validation R²:   -0.0076 ± 0.0010
   Test R²:         -0.0232 ± 0.0595

⭐ BEST PERFORMANCE:
   Best Round: 5 (Test R²: -0.0028)

📋 DATA SUMMARY:
   Training samples:   3627
   Validation samples: 1210
   Test samples:       1210
   Total samples:      6047
================================================================================
✅ Client client_14 completed | Algorithm: FEDAVG
