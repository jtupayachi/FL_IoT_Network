[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7c9b5592-dbfa-4f94-a87a-91301f9d22e2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 68603bd3-debd-48c4-871b-c27727209c0f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a71876c8-f264-448e-bc30-10b205e143c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bd818620-13d1-4caa-bfd4-c892fffbd4c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5277e303-6c18-42eb-a600-b672bd7ab9ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c94989d4-4953-4244-bcea-857bf57b993e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 76bf11a9-b3ac-4207-aa0e-58dc8b7257b9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0bc3a5e7-c5fc-41a4-bbd8-24aac71a73d9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 44620920-e731-43ca-909b-e1d673316adf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 822f82a6-5791-4dfc-b89b-50f597896d2d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 07af01ed-f810-4910-8717-15313c4c6ada
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3c3a51ef-cc44-468b-9bfd-417dc5bc2913
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0f6fbc07-9409-432e-9cd5-43ce27e69f84
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 60b48546-1091-4f05-aa95-24ed692ffe1b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message abc0e1cd-0f2b-4498-b453-e4e56e09c3fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fd61ab64-7c42-4db2-96dc-e9e747cefd22
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bc93e31b-8d35-4252-855c-2a92425e2a31
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e7af8adc-5016-480f-b9a3-60179aa97bbd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b5f447d1-6f3a-4092-8b49-e617de3cdc28
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dd27102d-568c-44b1-9f13-9ec742ef45f8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: reconnect message 0f5a178a-6d81-4a4c-90e2-dd36f46ca2f5
[92mINFO [0m:      Disconnect and shut down
ğŸš€ Starting NASA FL Client: client_16
Algorithm: FEDAVG
Server: localhost:8686
K-Folds: 5
Log Directory: logs
ğŸ”„ Using device: cuda
ğŸ¯ GPU: NVIDIA A100-SXM4-80GB
ğŸ’¾ Hyperparameters saved to: logs/client_16_hyperparams_20251029_152232.csv
ğŸ” Looking for data at: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.1/client_16
ğŸ“Š Loaded 8210 total samples from /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.1/client_16
ğŸ”„ Created sequences with length 10
   Final dataset shape: X (8200, 10, 24), y (8200,)
âœ… Data split completed:
   Training samples: 4920
   Validation samples: 1640
   Test samples: 1640
   Model type: lstm
âœ… Client client_16 ready:
   Model: LSTM
   Training: 4920 samples
   Device: cuda
   Validation: 1640 samples
   Test: 1640 samples
   Algorithm: fedavg
   Total Rounds: 10
   Learning Rate: 0.001
   Batch Size: 32
   Logging to: logs
â© Skipping CV for Round 1 (runs every 5 rounds)
Round 1: train_loss=10593.9072, val_loss=9773.0947, val_r2=-0.0063

ğŸ§ª Round 1 Evaluation Results:
   Test Loss: 13795.7196
   RMSE: 117.4552, MAE: 86.9238, RÂ²: -0.3765
ğŸ’¾ Test metrics saved to: logs/client_16_test_metrics_20251029_152232.csv
â© Skipping CV for Round 2 (runs every 5 rounds)
Round 2: train_loss=10606.0137, val_loss=9784.7549, val_r2=-0.0075
ğŸ’¾ Training metrics saved to: logs/client_16_training_metrics_20251029_152232.csv

ğŸ§ª Round 2 Evaluation Results:
   Test Loss: 10653.0764
   RMSE: 103.2137, MAE: 78.3767, RÂ²: -0.0629
ğŸ’¾ Test metrics saved to: logs/client_16_test_metrics_20251029_152232.csv
â© Skipping CV for Round 3 (runs every 5 rounds)

ğŸ¯ Round 3 Training Results:
   Training - Loss: 10570.8906, RMSE: 102.8148, RÂ²: -0.0041
   Validation - Loss: 9751.0625, RMSE: 98.7475, RÂ²: -0.0040

ğŸ§ª Round 3 Evaluation Results:
   Test Loss: 10608.2180
   RMSE: 102.9962, MAE: 78.2983, RÂ²: -0.0584
ğŸ’¾ Test metrics saved to: logs/client_16_test_metrics_20251029_152232.csv
â© Skipping CV for Round 4 (runs every 5 rounds)
Round 4: train_loss=10576.4424, val_loss=9756.3574, val_r2=-0.0045
ğŸ’¾ Training metrics saved to: logs/client_16_training_metrics_20251029_152232.csv

ğŸ§ª Round 4 Evaluation Results:
   Test Loss: 10615.2068
   RMSE: 103.0301, MAE: 78.3104, RÂ²: -0.0591
ğŸ’¾ Test metrics saved to: logs/client_16_test_metrics_20251029_152232.csv

ğŸ” Running 3-fold cross-validation (Round 5)

ğŸ” Starting 3-fold cross-validation on TRAINING data for client client_16

ğŸ“Š Fold 1/3
   Fold 1 Results:
     Val Loss: 10282.9736
     Val RMSE: 101.4050, Val RÂ²: -0.0067

ğŸ“Š Fold 2/3
   Fold 2 Results:
     Val Loss: 11160.4316
     Val RMSE: 105.6429, Val RÂ²: -0.0252

ğŸ“Š Fold 3/3
   Fold 3 Results:
     Val Loss: 10477.2344
     Val RMSE: 102.3584, Val RÂ²: -0.0019
ğŸ’¾ CV metrics saved to: logs/client_16_cv_metrics_20251029_152232.csv

ğŸ“ˆ 3-Fold CV Summary (Training Data):
   VAL_LOSS: 10640.2132 Â± 376.3019
   RMSE: 103.1354 Â± 1.8153
   R2: -0.0113 Â± 0.0101

ğŸ¯ Round 5 Training Results:
   Training - Loss: 10598.1973, RMSE: 102.9475, RÂ²: -0.0066
   Validation - Loss: 9777.2236, RMSE: 98.8798, RÂ²: -0.0067
ğŸ’¾ Training metrics saved to: logs/client_16_training_metrics_20251029_152232.csv

ğŸ§ª Round 5 Evaluation Results:
   Test Loss: 10576.4711
   RMSE: 102.8420, MAE: 78.2462, RÂ²: -0.0553
ğŸ’¾ Test metrics saved to: logs/client_16_test_metrics_20251029_152232.csv
â© Skipping CV for Round 6 (runs every 5 rounds)

ğŸ¯ Round 6 Training Results:
   Training - Loss: 10622.1904, RMSE: 103.0640, RÂ²: -0.0089
   Validation - Loss: 9800.3848, RMSE: 98.9969, RÂ²: -0.0091
ğŸ’¾ Training metrics saved to: logs/client_16_training_metrics_20251029_152232.csv

ğŸ§ª Round 6 Evaluation Results:
   Test Loss: 10582.7555
   RMSE: 102.8725, MAE: 78.2557, RÂ²: -0.0559
ğŸ’¾ Test metrics saved to: logs/client_16_test_metrics_20251029_152232.csv
â© Skipping CV for Round 7 (runs every 5 rounds)
Round 7: train_loss=10592.6611, val_loss=9771.8975, val_r2=-0.0061

ğŸ§ª Round 7 Evaluation Results:
   Test Loss: 10587.0445
   RMSE: 102.8934, MAE: 78.2622, RÂ²: -0.0563
ğŸ’¾ Test metrics saved to: logs/client_16_test_metrics_20251029_152232.csv
â© Skipping CV for Round 8 (runs every 5 rounds)
Round 8: train_loss=10605.6504, val_loss=9784.4033, val_r2=-0.0074
ğŸ’¾ Training metrics saved to: logs/client_16_training_metrics_20251029_152232.csv

ğŸ§ª Round 8 Evaluation Results:
   Test Loss: 10604.7751
   RMSE: 102.9795, MAE: 78.2923, RÂ²: -0.0581
ğŸ’¾ Test metrics saved to: logs/client_16_test_metrics_20251029_152232.csv

ğŸ” Running 3-fold cross-validation (Round 9)
ğŸ’¾ CV metrics saved to: logs/client_16_cv_metrics_20251029_152232.csv

ğŸ¯ Round 9 Training Results:
   Training - Loss: 10596.3379, RMSE: 102.9385, RÂ²: -0.0065
   Validation - Loss: 9775.4346, RMSE: 98.8708, RÂ²: -0.0065
ğŸ’¾ Training metrics saved to: logs/client_16_training_metrics_20251029_152232.csv

ğŸ§ª Round 9 Evaluation Results:
   Test Loss: 10593.3757
   RMSE: 102.9241, MAE: 78.2723, RÂ²: -0.0570
ğŸ’¾ Test metrics saved to: logs/client_16_test_metrics_20251029_152232.csv

ğŸ” Running 3-fold cross-validation (Round 10)
ğŸ’¾ CV metrics saved to: logs/client_16_cv_metrics_20251029_152232.csv

ğŸ¯ Round 10 Training Results:
   Training - Loss: 10598.8838, RMSE: 102.9509, RÂ²: -0.0067
   Validation - Loss: 9777.8838, RMSE: 98.8832, RÂ²: -0.0067
ğŸ’¾ Training metrics saved to: logs/client_16_training_metrics_20251029_152232.csv

ğŸ§ª Round 10 Evaluation Results:
   Test Loss: 10586.0633
   RMSE: 102.8886, MAE: 78.2608, RÂ²: -0.0562
ğŸ’¾ Test metrics saved to: logs/client_16_test_metrics_20251029_152232.csv

================================================================================
ğŸ¯ FINAL COMPREHENSIVE REPORT
================================================================================
ğŸ’¾ Final summary saved to: logs/client_16_final_summary_20251029_152232.csv

ğŸ“Š CLIENT: client_16 | ALGORITHM: fedavg | MODEL: LSTM
ğŸ“ˆ TOTAL ROUNDS: 10

âš™ï¸  HYPERPARAMETERS:
   Learning Rate: 0.001
   Batch Size: 32
   Local Epochs: 1
   Hidden Dim: 64
   Num Layers: 2
   Sequence Length: 10
   Use Attention: False
   Dropout: 0.3
   Optimizer: adam

ğŸ FINAL ROUND PERFORMANCE:
   Training   - Loss: 10598.88 | RMSE: 102.95 | RÂ²: -0.0067
   Validation - Loss:  9777.88 | RMSE:  98.88 | RÂ²: -0.0067
   Test       - Loss: 10586.06 | RMSE: 102.89 | RÂ²: -0.0562

ğŸ“Š STATISTICS ACROSS ALL ROUNDS (Mean Â± Std):
   Training Loss:   10600.53 Â±  12.71
   Validation Loss:  9779.49 Â±  12.23
   Test Loss:       10920.27 Â± 958.71

   Training RMSE:   102.96 Â±  0.06
   Validation RMSE:  98.89 Â±  0.06
   Test RMSE:       104.41 Â±  4.35

   Training RÂ²:     -0.0069 Â± 0.0012
   Validation RÂ²:   -0.0069 Â± 0.0013
   Test RÂ²:         -0.0896 Â± 0.0957

â­ BEST PERFORMANCE:
   Best Round: 5 (Test RÂ²: -0.0553)

ğŸ“‹ DATA SUMMARY:
   Training samples:   4920
   Validation samples: 1640
   Test samples:       1640
   Total samples:      8200
================================================================================
âœ… Client client_16 completed | Algorithm: FEDAVG
