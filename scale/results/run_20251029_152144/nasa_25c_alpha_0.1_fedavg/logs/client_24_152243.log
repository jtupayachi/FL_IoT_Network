[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 95da47e5-cdc8-4b1f-bb0a-97cab83d38f9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2798a5ee-768b-4763-87ed-b17a98f829c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message add220bd-472e-41c7-9d09-f51306c2a4c4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 033b498f-1ac6-44bc-8f00-b57261cc36ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f7dfae44-965b-4645-898b-b4a7a7cbdc7d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cbb0a51c-ff1d-4eaa-8924-0ff8b8a0152e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a4f9555a-7896-4eee-b2b3-5577879f2f78
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5c14bda2-68a8-4d68-b106-06ddd126196e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 48a9260b-b38b-426d-be29-888c46191294
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 481b7088-b82b-4860-92d4-9a3f249dd3e8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 08a2488a-29d9-4018-9e0f-a7689f2365e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 25f6270c-bd49-4c6c-b84b-68d8df606257
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f742b836-f1be-43a8-bf3c-2a45dfe8ac33
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b68994b8-7c91-48cc-b412-611409a44d93
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f1f3a140-1cd8-46fc-a5c5-da61ae004eb4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4dfd5139-4690-4b51-8baa-28c64348b1c5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 60bc3407-68ae-45b2-97f8-6df6d2ada7b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bae8e55f-a3d7-4992-8019-42e19fa361b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f78019e6-40a4-4381-994a-c55732318374
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: reconnect message e7970f27-5ae5-4354-a522-08ec49f9970a
[92mINFO [0m:      Disconnect and shut down
🚀 Starting NASA FL Client: client_24
Algorithm: FEDAVG
Server: localhost:8686
K-Folds: 5
Log Directory: logs
🔄 Using device: cuda
🎯 GPU: NVIDIA A100-SXM4-80GB
💾 Hyperparameters saved to: logs/client_24_hyperparams_20251029_152320.csv
🔍 Looking for data at: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.1/client_24
📊 Loaded 5496 total samples from /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.1/client_24
🔄 Created sequences with length 10
   Final dataset shape: X (5486, 10, 24), y (5486,)
✅ Data split completed:
   Training samples: 3291
   Validation samples: 1097
   Test samples: 1098
   Model type: lstm
✅ Client client_24 ready:
   Model: LSTM
   Training: 3291 samples
   Device: cuda
   Validation: 1097 samples
   Test: 1098 samples
   Algorithm: fedavg
   Total Rounds: 10
   Learning Rate: 0.001
   Batch Size: 32
   Logging to: logs

🧪 Round 0 Evaluation Results:
   Test Loss: 7882.3850
   RMSE: 88.7828, MAE: 69.1091, R²: -0.2430
💾 Test metrics saved to: logs/client_24_test_metrics_20251029_152320.csv
⏩ Skipping CV for Round 2 (runs every 5 rounds)
Round 2: train_loss=6353.2383, val_loss=6091.1870, val_r2=-0.0023
💾 Training metrics saved to: logs/client_24_training_metrics_20251029_152320.csv

🧪 Round 2 Evaluation Results:
   Test Loss: 6350.0096
   RMSE: 79.6869, MAE: 65.1768, R²: -0.0014
💾 Test metrics saved to: logs/client_24_test_metrics_20251029_152320.csv
⏩ Skipping CV for Round 3 (runs every 5 rounds)

🎯 Round 3 Training Results:
   Training - Loss: 6350.2568, RMSE: 79.6885, R²: -0.0048
   Validation - Loss: 6089.2729, RMSE: 78.0338, R²: -0.0020

🧪 Round 3 Evaluation Results:
   Test Loss: 6345.4855
   RMSE: 79.6586, MAE: 65.2232, R²: -0.0007
💾 Test metrics saved to: logs/client_24_test_metrics_20251029_152320.csv
⏩ Skipping CV for Round 4 (runs every 5 rounds)
Round 4: train_loss=6351.6069, val_loss=6090.1328, val_r2=-0.0022
💾 Training metrics saved to: logs/client_24_training_metrics_20251029_152320.csv

🧪 Round 4 Evaluation Results:
   Test Loss: 6346.0910
   RMSE: 79.6624, MAE: 65.2153, R²: -0.0007
💾 Test metrics saved to: logs/client_24_test_metrics_20251029_152320.csv

🔍 Running 3-fold cross-validation (Round 5)

🔍 Starting 3-fold cross-validation on TRAINING data for client client_24

📊 Fold 1/3
   Fold 1 Results:
     Val Loss: 6545.6455
     Val RMSE: 80.9052, Val R²: -0.0191

📊 Fold 2/3
   Fold 2 Results:
     Val Loss: 6504.0620
     Val RMSE: 80.6478, Val R²: -0.0104

📊 Fold 3/3
   Fold 3 Results:
     Val Loss: 6173.7646
     Val RMSE: 78.5733, Val R²: -0.0135
💾 CV metrics saved to: logs/client_24_cv_metrics_20251029_152320.csv

📈 3-Fold CV Summary (Training Data):
   VAL_LOSS: 6407.8241 ± 166.3734
   RMSE: 80.0421 ± 1.0439
   R2: -0.0143 ± 0.0036

🎯 Round 5 Training Results:
   Training - Loss: 6343.1450, RMSE: 79.6439, R²: -0.0037
   Validation - Loss: 6084.9414, RMSE: 78.0060, R²: -0.0013
💾 Training metrics saved to: logs/client_24_training_metrics_20251029_152320.csv

🧪 Round 5 Evaluation Results:
   Test Loss: 6343.2254
   RMSE: 79.6444, MAE: 65.2636, R²: -0.0003
💾 Test metrics saved to: logs/client_24_test_metrics_20251029_152320.csv
⏩ Skipping CV for Round 6 (runs every 5 rounds)

🎯 Round 6 Training Results:
   Training - Loss: 6355.7378, RMSE: 79.7229, R²: -0.0057
   Validation - Loss: 6092.8267, RMSE: 78.0566, R²: -0.0026
💾 Training metrics saved to: logs/client_24_training_metrics_20251029_152320.csv

🧪 Round 6 Evaluation Results:
   Test Loss: 6343.6072
   RMSE: 79.6468, MAE: 65.2546, R²: -0.0004
💾 Test metrics saved to: logs/client_24_test_metrics_20251029_152320.csv
⏩ Skipping CV for Round 7 (runs every 5 rounds)
Round 7: train_loss=6330.0649, val_loss=6078.4351, val_r2=-0.0002

🧪 Round 7 Evaluation Results:
   Test Loss: 6343.8863
   RMSE: 79.6485, MAE: 65.2485, R²: -0.0004
💾 Test metrics saved to: logs/client_24_test_metrics_20251029_152320.csv
⏩ Skipping CV for Round 8 (runs every 5 rounds)
Round 8: train_loss=6327.3716, val_loss=6077.5615, val_r2=-0.0001
💾 Training metrics saved to: logs/client_24_training_metrics_20251029_152320.csv

🧪 Round 8 Evaluation Results:
   Test Loss: 6345.2011
   RMSE: 79.6568, MAE: 65.2271, R²: -0.0006
💾 Test metrics saved to: logs/client_24_test_metrics_20251029_152320.csv

🔍 Running 3-fold cross-validation (Round 9)
💾 CV metrics saved to: logs/client_24_cv_metrics_20251029_152320.csv

🎯 Round 9 Training Results:
   Training - Loss: 6346.6362, RMSE: 79.6658, R²: -0.0043
   Validation - Loss: 6087.0220, RMSE: 78.0194, R²: -0.0016
💾 Training metrics saved to: logs/client_24_training_metrics_20251029_152320.csv

🧪 Round 9 Evaluation Results:
   Test Loss: 6344.3267
   RMSE: 79.6513, MAE: 65.2401, R²: -0.0005
💾 Test metrics saved to: logs/client_24_test_metrics_20251029_152320.csv

🔍 Running 3-fold cross-validation (Round 10)
💾 CV metrics saved to: logs/client_24_cv_metrics_20251029_152320.csv

🎯 Round 10 Training Results:
   Training - Loss: 6349.0332, RMSE: 79.6808, R²: -0.0047
   Validation - Loss: 6088.5029, RMSE: 78.0289, R²: -0.0019
💾 Training metrics saved to: logs/client_24_training_metrics_20251029_152320.csv

🧪 Round 10 Evaluation Results:
   Test Loss: 6343.8213
   RMSE: 79.6481, MAE: 65.2499, R²: -0.0004
💾 Test metrics saved to: logs/client_24_test_metrics_20251029_152320.csv

================================================================================
🎯 FINAL COMPREHENSIVE REPORT
================================================================================
💾 Final summary saved to: logs/client_24_final_summary_20251029_152320.csv

📊 CLIENT: client_24 | ALGORITHM: fedavg | MODEL: LSTM
📈 TOTAL ROUNDS: 10

⚙️  HYPERPARAMETERS:
   Learning Rate: 0.001
   Batch Size: 32
   Local Epochs: 1
   Hidden Dim: 64
   Num Layers: 2
   Sequence Length: 10
   Use Attention: False
   Dropout: 0.3
   Optimizer: adam

🏁 FINAL ROUND PERFORMANCE:
   Training   - Loss:  6349.03 | RMSE:  79.68 | R²: -0.0047
   Validation - Loss:  6088.50 | RMSE:  78.03 | R²: -0.0019
   Test       - Loss:  6343.82 | RMSE:  79.65 | R²: -0.0004

📊 STATISTICS ACROSS ALL ROUNDS (Mean ± Std):
   Training Loss:    6346.68 ±   8.78
   Validation Loss:  6087.45 ±   4.71
   Test Loss:        6498.80 ± 461.20

   Training RMSE:    79.67 ±  0.06
   Validation RMSE:  78.02 ±  0.03
   Test RMSE:        80.57 ±  2.74

   Training R²:     -0.0043 ± 0.0014
   Validation R²:   -0.0017 ± 0.0008
   Test R²:         -0.0248 ± 0.0727

⭐ BEST PERFORMANCE:
   Best Round: 5 (Test R²: -0.0003)

📋 DATA SUMMARY:
   Training samples:   3291
   Validation samples: 1097
   Test samples:       1098
   Total samples:      5486
================================================================================
✅ Client client_24 completed | Algorithm: FEDAVG
