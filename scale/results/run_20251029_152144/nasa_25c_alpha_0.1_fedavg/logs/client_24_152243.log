[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 95da47e5-cdc8-4b1f-bb0a-97cab83d38f9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2798a5ee-768b-4763-87ed-b17a98f829c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message add220bd-472e-41c7-9d09-f51306c2a4c4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 033b498f-1ac6-44bc-8f00-b57261cc36ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f7dfae44-965b-4645-898b-b4a7a7cbdc7d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cbb0a51c-ff1d-4eaa-8924-0ff8b8a0152e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a4f9555a-7896-4eee-b2b3-5577879f2f78
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5c14bda2-68a8-4d68-b106-06ddd126196e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 48a9260b-b38b-426d-be29-888c46191294
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 481b7088-b82b-4860-92d4-9a3f249dd3e8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 08a2488a-29d9-4018-9e0f-a7689f2365e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 25f6270c-bd49-4c6c-b84b-68d8df606257
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f742b836-f1be-43a8-bf3c-2a45dfe8ac33
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b68994b8-7c91-48cc-b412-611409a44d93
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f1f3a140-1cd8-46fc-a5c5-da61ae004eb4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4dfd5139-4690-4b51-8baa-28c64348b1c5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 60bc3407-68ae-45b2-97f8-6df6d2ada7b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bae8e55f-a3d7-4992-8019-42e19fa361b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f78019e6-40a4-4381-994a-c55732318374
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: reconnect message e7970f27-5ae5-4354-a522-08ec49f9970a
[92mINFO [0m:      Disconnect and shut down
ğŸš€ Starting NASA FL Client: client_24
Algorithm: FEDAVG
Server: localhost:8686
K-Folds: 5
Log Directory: logs
ğŸ”„ Using device: cuda
ğŸ¯ GPU: NVIDIA A100-SXM4-80GB
ğŸ’¾ Hyperparameters saved to: logs/client_24_hyperparams_20251029_152320.csv
ğŸ” Looking for data at: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.1/client_24
ğŸ“Š Loaded 5496 total samples from /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.1/client_24
ğŸ”„ Created sequences with length 10
   Final dataset shape: X (5486, 10, 24), y (5486,)
âœ… Data split completed:
   Training samples: 3291
   Validation samples: 1097
   Test samples: 1098
   Model type: lstm
âœ… Client client_24 ready:
   Model: LSTM
   Training: 3291 samples
   Device: cuda
   Validation: 1097 samples
   Test: 1098 samples
   Algorithm: fedavg
   Total Rounds: 10
   Learning Rate: 0.001
   Batch Size: 32
   Logging to: logs

ğŸ§ª Round 0 Evaluation Results:
   Test Loss: 7882.3850
   RMSE: 88.7828, MAE: 69.1091, RÂ²: -0.2430
ğŸ’¾ Test metrics saved to: logs/client_24_test_metrics_20251029_152320.csv
â© Skipping CV for Round 2 (runs every 5 rounds)
Round 2: train_loss=6353.2383, val_loss=6091.1870, val_r2=-0.0023
ğŸ’¾ Training metrics saved to: logs/client_24_training_metrics_20251029_152320.csv

ğŸ§ª Round 2 Evaluation Results:
   Test Loss: 6350.0096
   RMSE: 79.6869, MAE: 65.1768, RÂ²: -0.0014
ğŸ’¾ Test metrics saved to: logs/client_24_test_metrics_20251029_152320.csv
â© Skipping CV for Round 3 (runs every 5 rounds)

ğŸ¯ Round 3 Training Results:
   Training - Loss: 6350.2568, RMSE: 79.6885, RÂ²: -0.0048
   Validation - Loss: 6089.2729, RMSE: 78.0338, RÂ²: -0.0020

ğŸ§ª Round 3 Evaluation Results:
   Test Loss: 6345.4855
   RMSE: 79.6586, MAE: 65.2232, RÂ²: -0.0007
ğŸ’¾ Test metrics saved to: logs/client_24_test_metrics_20251029_152320.csv
â© Skipping CV for Round 4 (runs every 5 rounds)
Round 4: train_loss=6351.6069, val_loss=6090.1328, val_r2=-0.0022
ğŸ’¾ Training metrics saved to: logs/client_24_training_metrics_20251029_152320.csv

ğŸ§ª Round 4 Evaluation Results:
   Test Loss: 6346.0910
   RMSE: 79.6624, MAE: 65.2153, RÂ²: -0.0007
ğŸ’¾ Test metrics saved to: logs/client_24_test_metrics_20251029_152320.csv

ğŸ” Running 3-fold cross-validation (Round 5)

ğŸ” Starting 3-fold cross-validation on TRAINING data for client client_24

ğŸ“Š Fold 1/3
   Fold 1 Results:
     Val Loss: 6545.6455
     Val RMSE: 80.9052, Val RÂ²: -0.0191

ğŸ“Š Fold 2/3
   Fold 2 Results:
     Val Loss: 6504.0620
     Val RMSE: 80.6478, Val RÂ²: -0.0104

ğŸ“Š Fold 3/3
   Fold 3 Results:
     Val Loss: 6173.7646
     Val RMSE: 78.5733, Val RÂ²: -0.0135
ğŸ’¾ CV metrics saved to: logs/client_24_cv_metrics_20251029_152320.csv

ğŸ“ˆ 3-Fold CV Summary (Training Data):
   VAL_LOSS: 6407.8241 Â± 166.3734
   RMSE: 80.0421 Â± 1.0439
   R2: -0.0143 Â± 0.0036

ğŸ¯ Round 5 Training Results:
   Training - Loss: 6343.1450, RMSE: 79.6439, RÂ²: -0.0037
   Validation - Loss: 6084.9414, RMSE: 78.0060, RÂ²: -0.0013
ğŸ’¾ Training metrics saved to: logs/client_24_training_metrics_20251029_152320.csv

ğŸ§ª Round 5 Evaluation Results:
   Test Loss: 6343.2254
   RMSE: 79.6444, MAE: 65.2636, RÂ²: -0.0003
ğŸ’¾ Test metrics saved to: logs/client_24_test_metrics_20251029_152320.csv
â© Skipping CV for Round 6 (runs every 5 rounds)

ğŸ¯ Round 6 Training Results:
   Training - Loss: 6355.7378, RMSE: 79.7229, RÂ²: -0.0057
   Validation - Loss: 6092.8267, RMSE: 78.0566, RÂ²: -0.0026
ğŸ’¾ Training metrics saved to: logs/client_24_training_metrics_20251029_152320.csv

ğŸ§ª Round 6 Evaluation Results:
   Test Loss: 6343.6072
   RMSE: 79.6468, MAE: 65.2546, RÂ²: -0.0004
ğŸ’¾ Test metrics saved to: logs/client_24_test_metrics_20251029_152320.csv
â© Skipping CV for Round 7 (runs every 5 rounds)
Round 7: train_loss=6330.0649, val_loss=6078.4351, val_r2=-0.0002

ğŸ§ª Round 7 Evaluation Results:
   Test Loss: 6343.8863
   RMSE: 79.6485, MAE: 65.2485, RÂ²: -0.0004
ğŸ’¾ Test metrics saved to: logs/client_24_test_metrics_20251029_152320.csv
â© Skipping CV for Round 8 (runs every 5 rounds)
Round 8: train_loss=6327.3716, val_loss=6077.5615, val_r2=-0.0001
ğŸ’¾ Training metrics saved to: logs/client_24_training_metrics_20251029_152320.csv

ğŸ§ª Round 8 Evaluation Results:
   Test Loss: 6345.2011
   RMSE: 79.6568, MAE: 65.2271, RÂ²: -0.0006
ğŸ’¾ Test metrics saved to: logs/client_24_test_metrics_20251029_152320.csv

ğŸ” Running 3-fold cross-validation (Round 9)
ğŸ’¾ CV metrics saved to: logs/client_24_cv_metrics_20251029_152320.csv

ğŸ¯ Round 9 Training Results:
   Training - Loss: 6346.6362, RMSE: 79.6658, RÂ²: -0.0043
   Validation - Loss: 6087.0220, RMSE: 78.0194, RÂ²: -0.0016
ğŸ’¾ Training metrics saved to: logs/client_24_training_metrics_20251029_152320.csv

ğŸ§ª Round 9 Evaluation Results:
   Test Loss: 6344.3267
   RMSE: 79.6513, MAE: 65.2401, RÂ²: -0.0005
ğŸ’¾ Test metrics saved to: logs/client_24_test_metrics_20251029_152320.csv

ğŸ” Running 3-fold cross-validation (Round 10)
ğŸ’¾ CV metrics saved to: logs/client_24_cv_metrics_20251029_152320.csv

ğŸ¯ Round 10 Training Results:
   Training - Loss: 6349.0332, RMSE: 79.6808, RÂ²: -0.0047
   Validation - Loss: 6088.5029, RMSE: 78.0289, RÂ²: -0.0019
ğŸ’¾ Training metrics saved to: logs/client_24_training_metrics_20251029_152320.csv

ğŸ§ª Round 10 Evaluation Results:
   Test Loss: 6343.8213
   RMSE: 79.6481, MAE: 65.2499, RÂ²: -0.0004
ğŸ’¾ Test metrics saved to: logs/client_24_test_metrics_20251029_152320.csv

================================================================================
ğŸ¯ FINAL COMPREHENSIVE REPORT
================================================================================
ğŸ’¾ Final summary saved to: logs/client_24_final_summary_20251029_152320.csv

ğŸ“Š CLIENT: client_24 | ALGORITHM: fedavg | MODEL: LSTM
ğŸ“ˆ TOTAL ROUNDS: 10

âš™ï¸  HYPERPARAMETERS:
   Learning Rate: 0.001
   Batch Size: 32
   Local Epochs: 1
   Hidden Dim: 64
   Num Layers: 2
   Sequence Length: 10
   Use Attention: False
   Dropout: 0.3
   Optimizer: adam

ğŸ FINAL ROUND PERFORMANCE:
   Training   - Loss:  6349.03 | RMSE:  79.68 | RÂ²: -0.0047
   Validation - Loss:  6088.50 | RMSE:  78.03 | RÂ²: -0.0019
   Test       - Loss:  6343.82 | RMSE:  79.65 | RÂ²: -0.0004

ğŸ“Š STATISTICS ACROSS ALL ROUNDS (Mean Â± Std):
   Training Loss:    6346.68 Â±   8.78
   Validation Loss:  6087.45 Â±   4.71
   Test Loss:        6498.80 Â± 461.20

   Training RMSE:    79.67 Â±  0.06
   Validation RMSE:  78.02 Â±  0.03
   Test RMSE:        80.57 Â±  2.74

   Training RÂ²:     -0.0043 Â± 0.0014
   Validation RÂ²:   -0.0017 Â± 0.0008
   Test RÂ²:         -0.0248 Â± 0.0727

â­ BEST PERFORMANCE:
   Best Round: 5 (Test RÂ²: -0.0003)

ğŸ“‹ DATA SUMMARY:
   Training samples:   3291
   Validation samples: 1097
   Test samples:       1098
   Total samples:      5486
================================================================================
âœ… Client client_24 completed | Algorithm: FEDAVG
