[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3c8711e9-0bfd-4136-b1f8-8e58a06461f2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9fc13c4d-1202-4ccf-b3a4-c107d7867394
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ff9e794e-1ff2-4c37-9086-844c6396913f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c5272aa1-484a-4fe0-bb36-d2984fa036c5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3b9b896b-de52-4594-972f-062cf305b35a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 10d2bb7a-6742-412b-9977-c5a8da7fa5f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 79d501f2-3ad6-4f01-96d7-772d5eaf0836
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f52f486b-eaac-48e7-9e2b-7cefd3ec20c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aa0250af-b364-4581-b0ce-d0c1863bba21
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d5265cec-1403-4369-8af4-5ea9fd3058e9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c1209f9a-a9a5-4a3b-bb72-7ebb415a7987
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fe95976b-befd-470c-a8fa-049efa325956
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e33650b7-f815-4a58-96bf-f403f5224c68
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9e753ce3-18be-4013-9614-eb176e3d9a5d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a0325ae9-c290-4373-a357-72a1bd54ddb6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5746556f-7cae-4c25-96a2-ebb1274bcba9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1e595a71-2443-44f9-ba5a-c0b82235bbdb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 20271e28-2703-419b-aef8-e6160d284765
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cbada027-be56-4ebd-8053-5f5ddf10de77
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 38520dea-ca80-4d94-8e8f-c0b2aa502fc6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: reconnect message b717289e-ddbd-4a83-97b5-bca88a4417e3
[92mINFO [0m:      Disconnect and shut down
🚀 Starting NASA FL Client: client_6
Algorithm: FEDAVG
Server: localhost:8686
K-Folds: 5
Log Directory: logs
🔄 Using device: cuda
🎯 GPU: NVIDIA A100-SXM4-80GB
💾 Hyperparameters saved to: logs/client_6_hyperparams_20251029_152216.csv
🔍 Looking for data at: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.1/client_6
📊 Loaded 6613 total samples from /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.1/client_6
🔄 Created sequences with length 10
   Final dataset shape: X (6603, 10, 24), y (6603,)
✅ Data split completed:
   Training samples: 3961
   Validation samples: 1321
   Test samples: 1321
   Model type: lstm
✅ Client client_6 ready:
   Model: LSTM
   Training: 3961 samples
   Device: cuda
   Validation: 1321 samples
   Test: 1321 samples
   Algorithm: fedavg
   Total Rounds: 10
   Learning Rate: 0.001
   Batch Size: 32
   Logging to: logs
⏩ Skipping CV for Round 1 (runs every 5 rounds)
Round 1: train_loss=7989.5884, val_loss=7731.3853, val_r2=-0.0611

🧪 Round 1 Evaluation Results:
   Test Loss: 10963.5728
   RMSE: 104.7071, MAE: 79.9228, R²: -0.3360
💾 Test metrics saved to: logs/client_6_test_metrics_20251029_152216.csv
⏩ Skipping CV for Round 2 (runs every 5 rounds)
Round 2: train_loss=7501.2705, val_loss=7296.5195, val_r2=-0.0014
💾 Training metrics saved to: logs/client_6_training_metrics_20251029_152216.csv

🧪 Round 2 Evaluation Results:
   Test Loss: 8468.4026
   RMSE: 92.0239, MAE: 72.5809, R²: -0.0320
💾 Test metrics saved to: logs/client_6_test_metrics_20251029_152216.csv
⏩ Skipping CV for Round 3 (runs every 5 rounds)

🎯 Round 3 Training Results:
   Training - Loss: 7505.7397, RMSE: 86.6357, R²: -0.0035
   Validation - Loss: 7299.6284, RMSE: 85.4379, R²: -0.0018

🧪 Round 3 Evaluation Results:
   Test Loss: 8439.7623
   RMSE: 91.8682, MAE: 72.5332, R²: -0.0285
💾 Test metrics saved to: logs/client_6_test_metrics_20251029_152216.csv
⏩ Skipping CV for Round 4 (runs every 5 rounds)
Round 4: train_loss=7508.4478, val_loss=7301.5669, val_r2=-0.0021
💾 Training metrics saved to: logs/client_6_training_metrics_20251029_152216.csv

🧪 Round 4 Evaluation Results:
   Test Loss: 8444.1846
   RMSE: 91.8922, MAE: 72.5405, R²: -0.0290
💾 Test metrics saved to: logs/client_6_test_metrics_20251029_152216.csv

🔍 Running 3-fold cross-validation (Round 5)

🔍 Starting 3-fold cross-validation on TRAINING data for client client_6

📊 Fold 1/3
   Fold 1 Results:
     Val Loss: 7719.5127
     Val RMSE: 87.8608, Val R²: -0.0108

📊 Fold 2/3
   Fold 2 Results:
     Val Loss: 7737.3066
     Val RMSE: 87.9620, Val R²: -0.0024

📊 Fold 3/3
   Fold 3 Results:
     Val Loss: 7091.0132
     Val RMSE: 84.2082, Val R²: -0.0024
💾 CV metrics saved to: logs/client_6_cv_metrics_20251029_152216.csv

📈 3-Fold CV Summary (Training Data):
   VAL_LOSS: 7515.9442 ± 300.5594
   RMSE: 86.6770 ± 1.7462
   R2: -0.0052 ± 0.0040

🎯 Round 5 Training Results:
   Training - Loss: 7480.4370, RMSE: 86.4895, R²: -0.0001
   Validation - Loss: 7286.6641, RMSE: 85.3620, R²: -0.0000
💾 Training metrics saved to: logs/client_6_training_metrics_20251029_152216.csv

🧪 Round 5 Evaluation Results:
   Test Loss: 8419.8716
   RMSE: 91.7599, MAE: 72.5009, R²: -0.0261
💾 Test metrics saved to: logs/client_6_test_metrics_20251029_152216.csv
⏩ Skipping CV for Round 6 (runs every 5 rounds)

🎯 Round 6 Training Results:
   Training - Loss: 7502.7124, RMSE: 86.6182, R²: -0.0031
   Validation - Loss: 7297.5078, RMSE: 85.4255, R²: -0.0015
💾 Training metrics saved to: logs/client_6_training_metrics_20251029_152216.csv

🧪 Round 6 Evaluation Results:
   Test Loss: 8423.7826
   RMSE: 91.7812, MAE: 72.5071, R²: -0.0265
💾 Test metrics saved to: logs/client_6_test_metrics_20251029_152216.csv
⏩ Skipping CV for Round 7 (runs every 5 rounds)
Round 7: train_loss=7500.0806, val_loss=7295.7148, val_r2=-0.0013

🧪 Round 7 Evaluation Results:
   Test Loss: 8426.4595
   RMSE: 91.7957, MAE: 72.5112, R²: -0.0269
💾 Test metrics saved to: logs/client_6_test_metrics_20251029_152216.csv
⏩ Skipping CV for Round 8 (runs every 5 rounds)
Round 8: train_loss=7483.1982, val_loss=7286.6104, val_r2=-0.0000
💾 Training metrics saved to: logs/client_6_training_metrics_20251029_152216.csv

🧪 Round 8 Evaluation Results:
   Test Loss: 8437.5893
   RMSE: 91.8564, MAE: 72.5296, R²: -0.0282
💾 Test metrics saved to: logs/client_6_test_metrics_20251029_152216.csv

🔍 Running 3-fold cross-validation (Round 9)
💾 CV metrics saved to: logs/client_6_cv_metrics_20251029_152216.csv

🎯 Round 9 Training Results:
   Training - Loss: 7500.5405, RMSE: 86.6057, R²: -0.0028
   Validation - Loss: 7296.0249, RMSE: 85.4168, R²: -0.0013
💾 Training metrics saved to: logs/client_6_training_metrics_20251029_152216.csv

🧪 Round 9 Evaluation Results:
   Test Loss: 8430.4220
   RMSE: 91.8173, MAE: 72.5176, R²: -0.0273
💾 Test metrics saved to: logs/client_6_test_metrics_20251029_152216.csv

🔍 Running 3-fold cross-validation (Round 10)
💾 CV metrics saved to: logs/client_6_cv_metrics_20251029_152216.csv

🎯 Round 10 Training Results:
   Training - Loss: 7484.7632, RMSE: 86.5145, R²: -0.0007
   Validation - Loss: 7287.0732, RMSE: 85.3644, R²: -0.0001
💾 Training metrics saved to: logs/client_6_training_metrics_20251029_152216.csv

🧪 Round 10 Evaluation Results:
   Test Loss: 8425.8466
   RMSE: 91.7924, MAE: 72.5103, R²: -0.0268
💾 Test metrics saved to: logs/client_6_test_metrics_20251029_152216.csv

================================================================================
🎯 FINAL COMPREHENSIVE REPORT
================================================================================
💾 Final summary saved to: logs/client_6_final_summary_20251029_152216.csv

📊 CLIENT: client_6 | ALGORITHM: fedavg | MODEL: LSTM
📈 TOTAL ROUNDS: 10

⚙️  HYPERPARAMETERS:
   Learning Rate: 0.001
   Batch Size: 32
   Local Epochs: 1
   Hidden Dim: 64
   Num Layers: 2
   Sequence Length: 10
   Use Attention: False
   Dropout: 0.3
   Optimizer: adam

🏁 FINAL ROUND PERFORMANCE:
   Training   - Loss:  7484.76 | RMSE:  86.51 | R²: -0.0007
   Validation - Loss:  7287.07 | RMSE:  85.36 | R²: -0.0001
   Test       - Loss:  8425.85 | RMSE:  91.79 | R²: -0.0268

📊 STATISTICS ACROSS ALL ROUNDS (Mean ± Std):
   Training Loss:    7494.48 ±  10.45
   Validation Loss:  7293.14 ±   5.75
   Test Loss:        8687.99 ± 758.64

   Training RMSE:    86.57 ±  0.06
   Validation RMSE:  85.40 ±  0.03
   Test RMSE:        93.13 ±  3.86

   Training R²:     -0.0020 ± 0.0014
   Validation R²:   -0.0009 ± 0.0008
   Test R²:         -0.0587 ± 0.0924

⭐ BEST PERFORMANCE:
   Best Round: 5 (Test R²: -0.0261)

📋 DATA SUMMARY:
   Training samples:   3961
   Validation samples: 1321
   Test samples:       1321
   Total samples:      6603
================================================================================
✅ Client client_6 completed | Algorithm: FEDAVG
