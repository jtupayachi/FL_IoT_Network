[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d7a02ca7-834f-4fac-98d0-b682c8f32fb1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a57443e5-92a6-4b6f-9d05-06aac4bf75dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f3e15b5b-41ef-44a0-b13d-949b7abe5189
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a81f34ce-e62d-44c1-bd06-e4a15c5ea6ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ea9f8fea-c508-4417-8038-0bb0518c8ff4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 50bb71c6-d3d2-4275-a5bb-02777cae831a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a20579f3-57e8-43be-83ed-1c2e30196a7d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 98acbc2f-a3e9-4653-83be-0bbc3049f744
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3f8e3419-ecd8-4706-82c8-1edf7260ec49
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a33f93cc-f679-49c5-92fa-cddc547e23df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0eca7047-0fb3-4ca8-98b4-6333e0d2392d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f1b55d6a-e6d1-49e4-be45-142b66e88b8e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c4b185ce-6401-48cc-bd79-43e54e84b2d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message be303fca-d99c-4f2e-87ff-0a7c3eb1068e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7109787c-2f2a-418a-a99b-d95d14c83f45
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cd2f2e82-8ba6-457a-a4f6-e1645765f1a9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c716fd7b-2f37-407c-b8cd-be46d99eb31a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9b45fb1e-c682-4e81-a216-1dd91a7169c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6e2ec3fe-6b98-445f-b8dd-03d4d958a5e6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7ce85aef-4210-4bf2-8e79-ddf440c5a605
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: reconnect message f70188e9-b8b4-4de0-a08d-065e8881f51f
[92mINFO [0m:      Disconnect and shut down
🚀 Starting NASA FL Client: client_9
Algorithm: FEDAVG
Server: localhost:8686
K-Folds: 5
Log Directory: logs
🔄 Using device: cuda
🎯 GPU: NVIDIA A100-SXM4-80GB
💾 Hyperparameters saved to: logs/client_9_hyperparams_20251029_152220.csv
🔍 Looking for data at: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.1/client_9
📊 Loaded 6423 total samples from /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.1/client_9
🔄 Created sequences with length 10
   Final dataset shape: X (6413, 10, 24), y (6413,)
✅ Data split completed:
   Training samples: 3847
   Validation samples: 1283
   Test samples: 1283
   Model type: lstm
✅ Client client_9 ready:
   Model: LSTM
   Training: 3847 samples
   Device: cuda
   Validation: 1283 samples
   Test: 1283 samples
   Algorithm: fedavg
   Total Rounds: 10
   Learning Rate: 0.001
   Batch Size: 32
   Logging to: logs
⏩ Skipping CV for Round 1 (runs every 5 rounds)
Round 1: train_loss=7739.6846, val_loss=7429.6445, val_r2=-0.1837

🧪 Round 1 Evaluation Results:
   Test Loss: 7697.5100
   RMSE: 87.7355, MAE: 68.9574, R²: -0.3006
💾 Test metrics saved to: logs/client_9_test_metrics_20251029_152220.csv
⏩ Skipping CV for Round 2 (runs every 5 rounds)
Round 2: train_loss=6446.7822, val_loss=6291.7788, val_r2=-0.0024
💾 Training metrics saved to: logs/client_9_training_metrics_20251029_152220.csv

🧪 Round 2 Evaluation Results:
   Test Loss: 5952.7600
   RMSE: 77.1541, MAE: 63.0005, R²: -0.0058
💾 Test metrics saved to: logs/client_9_test_metrics_20251029_152220.csv
⏩ Skipping CV for Round 3 (runs every 5 rounds)

🎯 Round 3 Training Results:
   Training - Loss: 6443.2861, RMSE: 80.2701, R²: -0.0059
   Validation - Loss: 6289.7114, RMSE: 79.3077, R²: -0.0021

🧪 Round 3 Evaluation Results:
   Test Loss: 5942.9163
   RMSE: 77.0903, MAE: 63.0171, R²: -0.0042
💾 Test metrics saved to: logs/client_9_test_metrics_20251029_152220.csv
⏩ Skipping CV for Round 4 (runs every 5 rounds)
Round 4: train_loss=6450.7661, val_loss=6294.2065, val_r2=-0.0028
💾 Training metrics saved to: logs/client_9_training_metrics_20251029_152220.csv

🧪 Round 4 Evaluation Results:
   Test Loss: 5944.3638
   RMSE: 77.0997, MAE: 63.0138, R²: -0.0044
💾 Test metrics saved to: logs/client_9_test_metrics_20251029_152220.csv

🔍 Running 3-fold cross-validation (Round 5)

🔍 Starting 3-fold cross-validation on TRAINING data for client client_9

📊 Fold 1/3
   Fold 1 Results:
     Val Loss: 6356.0708
     Val RMSE: 79.7250, Val R²: -0.0134

📊 Fold 2/3
   Fold 2 Results:
     Val Loss: 6428.6855
     Val RMSE: 80.1791, Val R²: -0.0094

📊 Fold 3/3
   Fold 3 Results:
     Val Loss: 6796.8237
     Val RMSE: 82.4429, Val R²: -0.0347
💾 CV metrics saved to: logs/client_9_cv_metrics_20251029_152220.csv

📈 3-Fold CV Summary (Training Data):
   VAL_LOSS: 6527.1934 ± 192.9484
   RMSE: 80.7823 ± 1.1887
   R2: -0.0192 ± 0.0111

🎯 Round 5 Training Results:
   Training - Loss: 6429.9028, RMSE: 80.1867, R²: -0.0039
   Validation - Loss: 6282.5215, RMSE: 79.2624, R²: -0.0009
💾 Training metrics saved to: logs/client_9_training_metrics_20251029_152220.csv

🧪 Round 5 Evaluation Results:
   Test Loss: 5936.7671
   RMSE: 77.0504, MAE: 63.0350, R²: -0.0031
💾 Test metrics saved to: logs/client_9_test_metrics_20251029_152220.csv
⏩ Skipping CV for Round 6 (runs every 5 rounds)

🎯 Round 6 Training Results:
   Training - Loss: 6436.8203, RMSE: 80.2298, R²: -0.0049
   Validation - Loss: 6286.0718, RMSE: 79.2848, R²: -0.0015
💾 Training metrics saved to: logs/client_9_training_metrics_20251029_152220.csv

🧪 Round 6 Evaluation Results:
   Test Loss: 5937.9274
   RMSE: 77.0580, MAE: 63.0308, R²: -0.0033
💾 Test metrics saved to: logs/client_9_test_metrics_20251029_152220.csv
⏩ Skipping CV for Round 7 (runs every 5 rounds)
Round 7: train_loss=6443.9019, val_loss=6290.0703, val_r2=-0.0021

🧪 Round 7 Evaluation Results:
   Test Loss: 5938.7355
   RMSE: 77.0632, MAE: 63.0279, R²: -0.0034
💾 Test metrics saved to: logs/client_9_test_metrics_20251029_152220.csv
⏩ Skipping CV for Round 8 (runs every 5 rounds)
Round 8: train_loss=6434.7153, val_loss=6284.9487, val_r2=-0.0013
💾 Training metrics saved to: logs/client_9_training_metrics_20251029_152220.csv

🧪 Round 8 Evaluation Results:
   Test Loss: 5942.2153
   RMSE: 77.0858, MAE: 63.0187, R²: -0.0040
💾 Test metrics saved to: logs/client_9_test_metrics_20251029_152220.csv

🔍 Running 3-fold cross-validation (Round 9)
💾 CV metrics saved to: logs/client_9_cv_metrics_20251029_152220.csv

🎯 Round 9 Training Results:
   Training - Loss: 6435.3711, RMSE: 80.2208, R²: -0.0047
   Validation - Loss: 6285.2944, RMSE: 79.2798, R²: -0.0014
💾 Training metrics saved to: logs/client_9_training_metrics_20251029_152220.csv

🧪 Round 9 Evaluation Results:
   Test Loss: 5939.9529
   RMSE: 77.0711, MAE: 63.0240, R²: -0.0036
💾 Test metrics saved to: logs/client_9_test_metrics_20251029_152220.csv

🔍 Running 3-fold cross-validation (Round 10)
💾 CV metrics saved to: logs/client_9_cv_metrics_20251029_152220.csv

🎯 Round 10 Training Results:
   Training - Loss: 6433.5889, RMSE: 80.2097, R²: -0.0044
   Validation - Loss: 6284.3618, RMSE: 79.2740, R²: -0.0012
💾 Training metrics saved to: logs/client_9_training_metrics_20251029_152220.csv

🧪 Round 10 Evaluation Results:
   Test Loss: 5938.5496
   RMSE: 77.0620, MAE: 63.0286, R²: -0.0034
💾 Test metrics saved to: logs/client_9_test_metrics_20251029_152220.csv

================================================================================
🎯 FINAL COMPREHENSIVE REPORT
================================================================================
💾 Final summary saved to: logs/client_9_final_summary_20251029_152220.csv

📊 CLIENT: client_9 | ALGORITHM: fedavg | MODEL: LSTM
📈 TOTAL ROUNDS: 10

⚙️  HYPERPARAMETERS:
   Learning Rate: 0.001
   Batch Size: 32
   Local Epochs: 1
   Hidden Dim: 64
   Num Layers: 2
   Sequence Length: 10
   Use Attention: False
   Dropout: 0.3
   Optimizer: adam

🏁 FINAL ROUND PERFORMANCE:
   Training   - Loss:  6433.59 | RMSE:  80.21 | R²: -0.0044
   Validation - Loss:  6284.36 | RMSE:  79.27 | R²: -0.0012
   Test       - Loss:  5938.55 | RMSE:  77.06 | R²: -0.0034

📊 STATISTICS ACROSS ALL ROUNDS (Mean ± Std):
   Training Loss:    6438.28 ±   7.01
   Validation Loss:  6287.03 ±   3.96
   Test Loss:        6117.17 ± 526.80

   Training RMSE:    80.24 ±  0.04
   Validation RMSE:  79.29 ±  0.02
   Test RMSE:        78.15 ±  3.20

   Training R²:     -0.0052 ± 0.0011
   Validation R²:   -0.0016 ± 0.0006
   Test R²:         -0.0336 ± 0.0890

⭐ BEST PERFORMANCE:
   Best Round: 5 (Test R²: -0.0031)

📋 DATA SUMMARY:
   Training samples:   3847
   Validation samples: 1283
   Test samples:       1283
   Total samples:      6413
================================================================================
✅ Client client_9 completed | Algorithm: FEDAVG
