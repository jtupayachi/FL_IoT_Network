[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a1a9991c-8455-4c91-a33f-5788d2192d8b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4be7e32e-a954-4570-9fc8-2d28d43a6f2f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 550654b6-9a87-4b58-95c7-13dc88b93b76
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a3aaa346-67df-4130-8218-97a07afaf7a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fa2c792f-9660-4a90-8a9f-da7bef9af272
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 033b5d04-5beb-4e5f-b2c6-cb1f2da92464
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b85093a2-e21c-48cc-a4f1-f0dff7be77bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4d67b8a4-fe1d-4317-9d86-f397f63072fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 27667b47-97e7-4e25-9c94-523064490f73
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 648d30f3-3e25-49bf-ac55-508fb44f6a8e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 86f26ca2-9701-4e3e-8b01-b116adf928b6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 347a0936-0cb6-4c0b-9f8c-bc1be8b5ba3c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cbed7de5-af44-4331-8368-1cf32e6d20d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e74d557e-f969-409e-85cf-de17d9450617
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ef18a2d7-8493-457d-9058-d968438c9c3a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c5db73b2-0183-4dcf-9ab1-bd971b0cc8e8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aa04ecae-0882-45cd-b3c8-aaa69f00cb7f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6071ea44-1321-4485-ac1a-431571f25b6d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 33480197-a472-4bfb-88b6-6c4ea3479d6f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 31864081-0d31-44f4-8e6d-e92165132950
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: reconnect message 98afcc3c-88ab-4c77-a5ec-d1215df57d13
[92mINFO [0m:      Disconnect and shut down
ğŸš€ Starting NASA FL Client: client_0
Algorithm: FEDAVG
Server: localhost:8686
K-Folds: 5
Log Directory: logs
ğŸ”„ Using device: cuda
ğŸ¯ GPU: NVIDIA A100-SXM4-80GB
ğŸ’¾ Hyperparameters saved to: logs/client_0_hyperparams_20251030_013928.csv
ğŸ” Looking for data at: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.1/client_0
ğŸ“Š Loaded 5015 total samples from /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.1/client_0
ğŸ”¢ Original feature dimension: 24
ğŸ” Applying KernelPCA with 5 components, kernel=poly
ğŸ“Š Data shape - Before: (3009, 24), After: (3009, 5)
ğŸ”„ Created sequences with length 10
   Final dataset shape: X (2999, 10, 5), y (2999,)
âœ… Data split completed:
   Training samples: 2999
   Validation samples: 993
   Test samples: 993
   Model type: lstm
   Final input dimension: 5
âœ… Client client_0 ready:
   Model: LSTM
   Training: 2999 samples
   Device: cuda
   Validation: 993 samples
   Test: 993 samples
   Algorithm: fedavg
   Total Rounds: 10
   Learning Rate: 0.001
   Batch Size: 32
   Logging to: logs
â© Skipping CV for Round 1 (runs every 5 rounds)
Round 1: train_loss=13523.5312, val_loss=12278.9082, val_r2=-1.2704

ğŸ§ª Round 1 Evaluation Results:
   Test Loss: 10180.9594
   RMSE: 100.9007, MAE: 77.1893, RÂ²: -0.8119
ğŸ’¾ Test metrics saved to: logs/client_0_test_metrics_20251030_013928.csv
â© Skipping CV for Round 2 (runs every 5 rounds)
Round 2: train_loss=5930.4380, val_loss=5422.5693, val_r2=-0.0026
ğŸ’¾ Training metrics saved to: logs/client_0_training_metrics_20251030_013928.csv

ğŸ§ª Round 2 Evaluation Results:
   Test Loss: 5619.0923
   RMSE: 74.9606, MAE: 59.6282, RÂ²: -0.0000
ğŸ’¾ Test metrics saved to: logs/client_0_test_metrics_20251030_013928.csv
â© Skipping CV for Round 3 (runs every 5 rounds)

ğŸ¯ Round 3 Training Results:
   Training - Loss: 5920.6533, RMSE: 76.9458, RÂ²: -0.0105
   Validation - Loss: 5418.3818, RMSE: 73.6097, RÂ²: -0.0019

ğŸ§ª Round 3 Evaluation Results:
   Test Loss: 5619.1186
   RMSE: 74.9608, MAE: 59.6319, RÂ²: -0.0000
ğŸ’¾ Test metrics saved to: logs/client_0_test_metrics_20251030_013928.csv
â© Skipping CV for Round 4 (runs every 5 rounds)
Round 4: train_loss=5981.9580, val_loss=5449.5078, val_r2=-0.0076
ğŸ’¾ Training metrics saved to: logs/client_0_training_metrics_20251030_013928.csv

ğŸ§ª Round 4 Evaluation Results:
   Test Loss: 5619.1664
   RMSE: 74.9611, MAE: 59.6368, RÂ²: -0.0000
ğŸ’¾ Test metrics saved to: logs/client_0_test_metrics_20251030_013928.csv

ğŸ” Running 3-fold cross-validation (Round 5)

ğŸ” Starting 3-fold cross-validation on TRAINING data for client client_0

ğŸ“Š Fold 1/3
   Fold 1 Results:
     Val Loss: 6204.9316
     Val RMSE: 78.7714, Val RÂ²: -0.0251

ğŸ“Š Fold 2/3
   Fold 2 Results:
     Val Loss: 5669.0425
     Val RMSE: 75.2930, Val RÂ²: -0.0138

ğŸ“Š Fold 3/3
   Fold 3 Results:
     Val Loss: 6009.9370
     Val RMSE: 77.5238, Val RÂ²: -0.0133
ğŸ’¾ CV metrics saved to: logs/client_0_cv_metrics_20251030_013928.csv

ğŸ“ˆ 3-Fold CV Summary (Training Data):
   VAL_LOSS: 5961.3037 Â± 221.4621
   RMSE: 77.1961 Â± 1.4388
   R2: -0.0174 Â± 0.0054

ğŸ¯ Round 5 Training Results:
   Training - Loss: 5945.7510, RMSE: 77.1087, RÂ²: -0.0148
   Validation - Loss: 5429.8447, RMSE: 73.6875, RÂ²: -0.0040
ğŸ’¾ Training metrics saved to: logs/client_0_training_metrics_20251030_013928.csv

ğŸ§ª Round 5 Evaluation Results:
   Test Loss: 5619.1709
   RMSE: 74.9611, MAE: 59.6372, RÂ²: -0.0000
ğŸ’¾ Test metrics saved to: logs/client_0_test_metrics_20251030_013928.csv
â© Skipping CV for Round 6 (runs every 5 rounds)

ğŸ¯ Round 6 Training Results:
   Training - Loss: 5934.1484, RMSE: 77.0334, RÂ²: -0.0128
   Validation - Loss: 5424.2583, RMSE: 73.6496, RÂ²: -0.0030
ğŸ’¾ Training metrics saved to: logs/client_0_training_metrics_20251030_013928.csv

ğŸ§ª Round 6 Evaluation Results:
   Test Loss: 5619.2358
   RMSE: 74.9616, MAE: 59.6422, RÂ²: -0.0000
ğŸ’¾ Test metrics saved to: logs/client_0_test_metrics_20251030_013928.csv
â© Skipping CV for Round 7 (runs every 5 rounds)
Round 7: train_loss=5903.7212, val_loss=5412.3154, val_r2=-0.0008

ğŸ§ª Round 7 Evaluation Results:
   Test Loss: 5620.1288
   RMSE: 74.9675, MAE: 59.6821, RÂ²: -0.0002
ğŸ’¾ Test metrics saved to: logs/client_0_test_metrics_20251030_013928.csv
â© Skipping CV for Round 8 (runs every 5 rounds)
Round 8: train_loss=5941.4077, val_loss=5427.7036, val_r2=-0.0036
ğŸ’¾ Training metrics saved to: logs/client_0_training_metrics_20251030_013928.csv

ğŸ§ª Round 8 Evaluation Results:
   Test Loss: 5619.7802
   RMSE: 74.9652, MAE: 59.6700, RÂ²: -0.0001
ğŸ’¾ Test metrics saved to: logs/client_0_test_metrics_20251030_013928.csv

ğŸ” Running 3-fold cross-validation (Round 9)
ğŸ’¾ CV metrics saved to: logs/client_0_cv_metrics_20251030_013928.csv

ğŸ¯ Round 9 Training Results:
   Training - Loss: 5914.2231, RMSE: 76.9040, RÂ²: -0.0094
   Validation - Loss: 5415.8765, RMSE: 73.5926, RÂ²: -0.0014
ğŸ’¾ Training metrics saved to: logs/client_0_training_metrics_20251030_013928.csv

ğŸ§ª Round 9 Evaluation Results:
   Test Loss: 5620.6159
   RMSE: 74.9708, MAE: 59.6961, RÂ²: -0.0003
ğŸ’¾ Test metrics saved to: logs/client_0_test_metrics_20251030_013928.csv

ğŸ” Running 3-fold cross-validation (Round 10)
ğŸ’¾ CV metrics saved to: logs/client_0_cv_metrics_20251030_013928.csv

ğŸ¯ Round 10 Training Results:
   Training - Loss: 5909.6353, RMSE: 76.8742, RÂ²: -0.0086
   Validation - Loss: 5414.2305, RMSE: 73.5815, RÂ²: -0.0011
ğŸ’¾ Training metrics saved to: logs/client_0_training_metrics_20251030_013928.csv

ğŸ§ª Round 10 Evaluation Results:
   Test Loss: 5619.3700
   RMSE: 74.9625, MAE: 59.6508, RÂ²: -0.0001
ğŸ’¾ Test metrics saved to: logs/client_0_test_metrics_20251030_013928.csv

================================================================================
ğŸ¯ FINAL COMPREHENSIVE REPORT
================================================================================
ğŸ’¾ Final summary saved to: logs/client_0_final_summary_20251030_013928.csv

ğŸ“Š CLIENT: client_0 | ALGORITHM: fedavg | MODEL: LSTM
ğŸ“ˆ TOTAL ROUNDS: 10

âš™ï¸  HYPERPARAMETERS:
   Learning Rate: 0.001
   Batch Size: 32
   Local Epochs: 1
   Hidden Dim: 64
   Num Layers: 2
   Sequence Length: 10
   Use Attention: False
   Dropout: 0.3
   Optimizer: adam

ğŸ FINAL ROUND PERFORMANCE:
   Training   - Loss:  5909.64 | RMSE:  76.87 | RÂ²: -0.0086
   Validation - Loss:  5414.23 | RMSE:  73.58 | RÂ²: -0.0011
   Test       - Loss:  5619.37 | RMSE:  74.96 | RÂ²: -0.0001

ğŸ“Š STATISTICS ACROSS ALL ROUNDS (Mean Â± Std):
   Training Loss:    5936.79 Â±  22.15
   Validation Loss:  5426.28 Â±  10.86
   Test Loss:        6075.66 Â± 1368.43

   Training RMSE:    77.05 Â±  0.14
   Validation RMSE:  73.66 Â±  0.07
   Test RMSE:        77.56 Â±  7.78

   Training RÂ²:     -0.0132 Â± 0.0038
   Validation RÂ²:   -0.0033 Â± 0.0020
   Test RÂ²:         -0.0813 Â± 0.2435

â­ BEST PERFORMANCE:
   Best Round: 2 (Test RÂ²: -0.0000)

ğŸ“‹ DATA SUMMARY:
   Training samples:   2999
   Validation samples: 993
   Test samples:       993
   Total samples:      4985
================================================================================
âœ… Client client_0 completed | Algorithm: FEDAVG
