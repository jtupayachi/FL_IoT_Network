[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message be804458-d3b1-472b-9481-599d9d4099a9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3acf521c-1bb6-4311-8436-f9ce326aa4f3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a4cbe577-bd0b-4078-930a-7f5e7df77112
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5c32ab82-80fc-42d3-b804-88b2678dfd1e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4b013d9b-d1d9-4e41-a1e6-332ce1eb524d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 21b9b826-054f-4a87-a8bd-3e552db0ae3d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 77983bc9-33b0-4441-a8ce-f1e3ec6b7705
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 52fe84ca-450a-4825-a068-bcd65b4177ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8731f4eb-2bca-437e-addb-295a569783f9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2340266c-f7d0-46a4-923a-7b1b41c4bb2d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b7fafef6-a6e5-4fd8-acca-401c914e313d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b9798865-3a1d-495d-81b7-db651732b791
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ada06047-858f-4d8f-a4ef-1a3b7f27161c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4bed3ece-1734-4cb6-bfcd-7979dda379b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e7c6d6a1-6ed8-4a39-b5ad-8384035580c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9552c227-3c20-4888-8daf-07de93762ab2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 12977a30-bb5e-4043-91e0-24020fda3732
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f9937960-beef-4f93-8b2b-b9076bc28b89
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7e757acf-4846-4e84-bc22-0661360de57f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: reconnect message d14ee2e8-040a-49f5-9dd9-f515be9dd71d
[92mINFO [0m:      Disconnect and shut down
🚀 Starting NASA FL Client: client_19
Algorithm: FEDAVG
Server: localhost:8686
K-Folds: 5
Log Directory: logs
🔄 Using device: cuda
🎯 GPU: NVIDIA A100-SXM4-80GB
💾 Hyperparameters saved to: logs/client_19_hyperparams_20251030_013953.csv
🔍 Looking for data at: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.1/client_19
📊 Loaded 8316 total samples from /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.1/client_19
🔢 Original feature dimension: 24
🔍 Applying KernelPCA with 5 components, kernel=poly
📊 Data shape - Before: (4989, 24), After: (4989, 5)
🔄 Created sequences with length 10
   Final dataset shape: X (4979, 10, 5), y (4979,)
✅ Data split completed:
   Training samples: 4979
   Validation samples: 1653
   Test samples: 1654
   Model type: lstm
   Final input dimension: 5
✅ Client client_19 ready:
   Model: LSTM
   Training: 4979 samples
   Device: cuda
   Validation: 1653 samples
   Test: 1654 samples
   Algorithm: fedavg
   Total Rounds: 10
   Learning Rate: 0.001
   Batch Size: 32
   Logging to: logs

🧪 Round 0 Evaluation Results:
   Test Loss: 16975.2275
   RMSE: 130.2890, MAE: 101.2720, R²: -1.0448
💾 Test metrics saved to: logs/client_19_test_metrics_20251030_013953.csv
⏩ Skipping CV for Round 2 (runs every 5 rounds)
Round 2: train_loss=8796.3975, val_loss=8617.8799, val_r2=-0.0128
💾 Training metrics saved to: logs/client_19_training_metrics_20251030_013953.csv

🧪 Round 2 Evaluation Results:
   Test Loss: 8947.7911
   RMSE: 94.5928, MAE: 75.2435, R²: -0.0778
💾 Test metrics saved to: logs/client_19_test_metrics_20251030_013953.csv
⏩ Skipping CV for Round 3 (runs every 5 rounds)

🎯 Round 3 Training Results:
   Training - Loss: 8816.8311, RMSE: 93.8980, R²: -0.0229
   Validation - Loss: 8634.0205, RMSE: 92.9194, R²: -0.0147

🧪 Round 3 Evaluation Results:
   Test Loss: 8944.5163
   RMSE: 94.5755, MAE: 75.2373, R²: -0.0774
💾 Test metrics saved to: logs/client_19_test_metrics_20251030_013953.csv
⏩ Skipping CV for Round 4 (runs every 5 rounds)
Round 4: train_loss=8720.8936, val_loss=8560.9473, val_r2=-0.0061
💾 Training metrics saved to: logs/client_19_training_metrics_20251030_013953.csv

🧪 Round 4 Evaluation Results:
   Test Loss: 8940.1683
   RMSE: 94.5525, MAE: 75.2291, R²: -0.0769
💾 Test metrics saved to: logs/client_19_test_metrics_20251030_013953.csv

🔍 Running 3-fold cross-validation (Round 5)

🔍 Starting 3-fold cross-validation on TRAINING data for client client_19

📊 Fold 1/3
   Fold 1 Results:
     Val Loss: 8614.8506
     Val RMSE: 92.8162, Val R²: -0.0186

📊 Fold 2/3
   Fold 2 Results:
     Val Loss: 8725.4004
     Val RMSE: 93.4099, Val R²: -0.0159

📊 Fold 3/3
   Fold 3 Results:
     Val Loss: 9018.7354
     Val RMSE: 94.9670, Val R²: -0.0234
💾 CV metrics saved to: logs/client_19_cv_metrics_20251030_013953.csv

📈 3-Fold CV Summary (Training Data):
   VAL_LOSS: 8786.3288 ± 170.4209
   RMSE: 93.7310 ± 0.9070
   R2: -0.0193 ± 0.0031

🎯 Round 5 Training Results:
   Training - Loss: 8790.0078, RMSE: 93.7550, R²: -0.0198
   Validation - Loss: 8612.8838, RMSE: 92.8056, R²: -0.0122
💾 Training metrics saved to: logs/client_19_training_metrics_20251030_013953.csv

🧪 Round 5 Evaluation Results:
   Test Loss: 8939.8210
   RMSE: 94.5506, MAE: 75.2285, R²: -0.0769
💾 Test metrics saved to: logs/client_19_test_metrics_20251030_013953.csv
⏩ Skipping CV for Round 6 (runs every 5 rounds)

🎯 Round 6 Training Results:
   Training - Loss: 8806.7529, RMSE: 93.8443, R²: -0.0217
   Validation - Loss: 8626.0312, RMSE: 92.8764, R²: -0.0137
💾 Training metrics saved to: logs/client_19_training_metrics_20251030_013953.csv

🧪 Round 6 Evaluation Results:
   Test Loss: 8935.4203
   RMSE: 94.5274, MAE: 75.2201, R²: -0.0763
💾 Test metrics saved to: logs/client_19_test_metrics_20251030_013953.csv
⏩ Skipping CV for Round 7 (runs every 5 rounds)
Round 7: train_loss=8799.6748, val_loss=8620.4531, val_r2=-0.0131

🧪 Round 7 Evaluation Results:
   Test Loss: 8904.7573
   RMSE: 94.3650, MAE: 75.1639, R²: -0.0726
💾 Test metrics saved to: logs/client_19_test_metrics_20251030_013953.csv
⏩ Skipping CV for Round 8 (runs every 5 rounds)
Round 8: train_loss=8782.4219, val_loss=8606.9873, val_r2=-0.0115
💾 Training metrics saved to: logs/client_19_training_metrics_20251030_013953.csv

🧪 Round 8 Evaluation Results:
   Test Loss: 8913.9027
   RMSE: 94.4135, MAE: 75.1808, R²: -0.0737
💾 Test metrics saved to: logs/client_19_test_metrics_20251030_013953.csv

🔍 Running 3-fold cross-validation (Round 9)
💾 CV metrics saved to: logs/client_19_cv_metrics_20251030_013953.csv

🎯 Round 9 Training Results:
   Training - Loss: 8740.6367, RMSE: 93.4914, R²: -0.0140
   Validation - Loss: 8575.3057, RMSE: 92.6029, R²: -0.0078
💾 Training metrics saved to: logs/client_19_training_metrics_20251030_013953.csv

🧪 Round 9 Evaluation Results:
   Test Loss: 8894.3003
   RMSE: 94.3096, MAE: 75.1445, R²: -0.0714
💾 Test metrics saved to: logs/client_19_test_metrics_20251030_013953.csv

🔍 Running 3-fold cross-validation (Round 10)
💾 CV metrics saved to: logs/client_19_cv_metrics_20251030_013953.csv

🎯 Round 10 Training Results:
   Training - Loss: 8749.7539, RMSE: 93.5401, R²: -0.0151
   Validation - Loss: 8582.0840, RMSE: 92.6395, R²: -0.0086
💾 Training metrics saved to: logs/client_19_training_metrics_20251030_013953.csv

🧪 Round 10 Evaluation Results:
   Test Loss: 8928.4715
   RMSE: 94.4906, MAE: 75.2073, R²: -0.0755
💾 Test metrics saved to: logs/client_19_test_metrics_20251030_013953.csv

================================================================================
🎯 FINAL COMPREHENSIVE REPORT
================================================================================
💾 Final summary saved to: logs/client_19_final_summary_20251030_013953.csv

📊 CLIENT: client_19 | ALGORITHM: fedavg | MODEL: LSTM
📈 TOTAL ROUNDS: 10

⚙️  HYPERPARAMETERS:
   Learning Rate: 0.001
   Batch Size: 32
   Local Epochs: 1
   Hidden Dim: 64
   Num Layers: 2
   Sequence Length: 10
   Use Attention: False
   Dropout: 0.3
   Optimizer: adam

🏁 FINAL ROUND PERFORMANCE:
   Training   - Loss:  8749.75 | RMSE:  93.54 | R²: -0.0151
   Validation - Loss:  8582.08 | RMSE:  92.64 | R²: -0.0086
   Test       - Loss:  8928.47 | RMSE:  94.49 | R²: -0.0755

📊 STATISTICS ACROSS ALL ROUNDS (Mean ± Std):
   Training Loss:    8769.55 ±  29.96
   Validation Loss:  8597.45 ±  22.75
   Test Loss:        9732.44 ± 2414.32

   Training RMSE:    93.65 ±  0.16
   Validation RMSE:  92.72 ±  0.12
   Test RMSE:        98.07 ± 10.74

   Training R²:     -0.0174 ± 0.0035
   Validation R²:   -0.0104 ± 0.0027
   Test R²:         -0.1723 ± 0.2908

⭐ BEST PERFORMANCE:
   Best Round: 9 (Test R²: -0.0714)

📋 DATA SUMMARY:
   Training samples:   4979
   Validation samples: 1653
   Test samples:       1654
   Total samples:      8286
================================================================================
✅ Client client_19 completed | Algorithm: FEDAVG
