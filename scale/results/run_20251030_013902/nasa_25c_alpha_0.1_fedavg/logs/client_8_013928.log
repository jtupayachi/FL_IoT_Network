[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a6a8f76d-a357-4e26-ad2a-10b6f14e1457
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7b44c0f4-496b-4277-aab5-8629022bf3dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0f1f6bd2-be7c-473b-b91a-5625bbedfc84
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a0ba0d4e-91b8-4837-aa7f-cc05f72a3873
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8b4f3eb5-7190-4ea3-99d9-ba5579dceca0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8884c077-0080-4307-a1f7-dc6d6f70fd8b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7fac58ef-e3d8-480a-805d-0bbedbbde4c5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dfe8d8d9-d761-43fa-a1c5-bb8aff278908
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4e4f088a-6139-4d97-b95d-68ad8569d404
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 12913133-df70-472c-9857-ad74342e963e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b9f0f6da-6fb6-4fe5-978a-a33884b6c967
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9fe701da-01b1-476d-8902-4728f34c0472
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8dab7e35-7eed-448d-990c-ef3136274570
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7e834915-bc7c-4e55-a03a-8c6498e1f25d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9bb89f4b-0e3b-4bbb-b7f8-176144e51a93
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 934aa3d5-68ca-4bad-998e-46468aa7cebe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 52f8d190-a4b8-4faf-a1d4-fe39b999d8df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 91bfc895-b1ad-4b08-bc26-e1d88702bfd5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bef06118-3bbb-4f6b-8063-66e177d62bb2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9d23691d-b155-49ad-9492-34ccd770cfb4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: reconnect message e523fedd-cbb2-4837-8b77-49e92a2b1976
[92mINFO [0m:      Disconnect and shut down
ğŸš€ Starting NASA FL Client: client_8
Algorithm: FEDAVG
Server: localhost:8686
K-Folds: 5
Log Directory: logs
ğŸ”„ Using device: cuda
ğŸ¯ GPU: NVIDIA A100-SXM4-80GB
ğŸ’¾ Hyperparameters saved to: logs/client_8_hyperparams_20251030_013932.csv
ğŸ” Looking for data at: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.1/client_8
ğŸ“Š Loaded 5083 total samples from /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.1/client_8
ğŸ”¢ Original feature dimension: 24
ğŸ” Applying KernelPCA with 5 components, kernel=poly
ğŸ“Š Data shape - Before: (3049, 24), After: (3049, 5)
ğŸ”„ Created sequences with length 10
   Final dataset shape: X (3039, 10, 5), y (3039,)
âœ… Data split completed:
   Training samples: 3039
   Validation samples: 1007
   Test samples: 1007
   Model type: lstm
   Final input dimension: 5
âœ… Client client_8 ready:
   Model: LSTM
   Training: 3039 samples
   Device: cuda
   Validation: 1007 samples
   Test: 1007 samples
   Algorithm: fedavg
   Total Rounds: 10
   Learning Rate: 0.001
   Batch Size: 32
   Logging to: logs
â© Skipping CV for Round 1 (runs every 5 rounds)
Round 1: train_loss=18955.1836, val_loss=19215.3281, val_r2=-1.3989

ğŸ§ª Round 1 Evaluation Results:
   Test Loss: 15024.5443
   RMSE: 122.5746, MAE: 93.6479, RÂ²: -0.9242
ğŸ’¾ Test metrics saved to: logs/client_8_test_metrics_20251030_013932.csv
â© Skipping CV for Round 2 (runs every 5 rounds)
Round 2: train_loss=8089.1289, val_loss=8222.5684, val_r2=-0.0265
ğŸ’¾ Training metrics saved to: logs/client_8_training_metrics_20251030_013932.csv

ğŸ§ª Round 2 Evaluation Results:
   Test Loss: 8105.3397
   RMSE: 90.0297, MAE: 71.8717, RÂ²: -0.0380
ğŸ’¾ Test metrics saved to: logs/client_8_test_metrics_20251030_013932.csv
â© Skipping CV for Round 3 (runs every 5 rounds)

ğŸ¯ Round 3 Training Results:
   Training - Loss: 8255.6865, RMSE: 90.8608, RÂ²: -0.0455
   Validation - Loss: 8396.1670, RMSE: 91.6306, RÂ²: -0.0482

ğŸ§ª Round 3 Evaluation Results:
   Test Loss: 8103.1204
   RMSE: 90.0173, MAE: 71.8686, RÂ²: -0.0378
ğŸ’¾ Test metrics saved to: logs/client_8_test_metrics_20251030_013932.csv
â© Skipping CV for Round 4 (runs every 5 rounds)
Round 4: train_loss=8253.9873, val_loss=8394.4053, val_r2=-0.0480
ğŸ’¾ Training metrics saved to: logs/client_8_training_metrics_20251030_013932.csv

ğŸ§ª Round 4 Evaluation Results:
   Test Loss: 8100.1782
   RMSE: 90.0010, MAE: 71.8644, RÂ²: -0.0374
ğŸ’¾ Test metrics saved to: logs/client_8_test_metrics_20251030_013932.csv

ğŸ” Running 3-fold cross-validation (Round 5)

ğŸ” Starting 3-fold cross-validation on TRAINING data for client client_8

ğŸ“Š Fold 1/3
   Fold 1 Results:
     Val Loss: 8437.1631
     Val RMSE: 91.8540, Val RÂ²: -0.0274

ğŸ“Š Fold 2/3
   Fold 2 Results:
     Val Loss: 7721.7808
     Val RMSE: 87.8737, Val RÂ²: -0.0026

ğŸ“Š Fold 3/3
   Fold 3 Results:
     Val Loss: 7832.1396
     Val RMSE: 88.4994, Val RÂ²: -0.0101
ğŸ’¾ CV metrics saved to: logs/client_8_cv_metrics_20251030_013932.csv

ğŸ“ˆ 3-Fold CV Summary (Training Data):
   VAL_LOSS: 7997.0278 Â± 314.4668
   RMSE: 89.4090 Â± 1.7477
   R2: -0.0134 Â± 0.0104

ğŸ¯ Round 5 Training Results:
   Training - Loss: 8185.4561, RMSE: 90.4735, RÂ²: -0.0366
   Validation - Loss: 8323.2246, RMSE: 91.2317, RÂ²: -0.0391
ğŸ’¾ Training metrics saved to: logs/client_8_training_metrics_20251030_013932.csv

ğŸ§ª Round 5 Evaluation Results:
   Test Loss: 8099.9434
   RMSE: 89.9997, MAE: 71.8640, RÂ²: -0.0374
ğŸ’¾ Test metrics saved to: logs/client_8_test_metrics_20251030_013932.csv
â© Skipping CV for Round 6 (runs every 5 rounds)

ğŸ¯ Round 6 Training Results:
   Training - Loss: 8321.2998, RMSE: 91.2212, RÂ²: -0.0538
   Validation - Loss: 8464.0811, RMSE: 92.0004, RÂ²: -0.0567
ğŸ’¾ Training metrics saved to: logs/client_8_training_metrics_20251030_013932.csv

ğŸ§ª Round 6 Evaluation Results:
   Test Loss: 8096.9707
   RMSE: 89.9832, MAE: 71.8598, RÂ²: -0.0370
ğŸ’¾ Test metrics saved to: logs/client_8_test_metrics_20251030_013932.csv
â© Skipping CV for Round 7 (runs every 5 rounds)
Round 7: train_loss=8200.2900, val_loss=8338.6562, val_r2=-0.0410

ğŸ§ª Round 7 Evaluation Results:
   Test Loss: 8076.3986
   RMSE: 89.8688, MAE: 71.8331, RÂ²: -0.0343
ğŸ’¾ Test metrics saved to: logs/client_8_test_metrics_20251030_013932.csv
â© Skipping CV for Round 8 (runs every 5 rounds)
Round 8: train_loss=8238.8066, val_loss=8378.6611, val_r2=-0.0460
ğŸ’¾ Training metrics saved to: logs/client_8_training_metrics_20251030_013932.csv

ğŸ§ª Round 8 Evaluation Results:
   Test Loss: 8082.5081
   RMSE: 89.9028, MAE: 71.8410, RÂ²: -0.0351
ğŸ’¾ Test metrics saved to: logs/client_8_test_metrics_20251030_013932.csv

ğŸ” Running 3-fold cross-validation (Round 9)
ğŸ’¾ CV metrics saved to: logs/client_8_cv_metrics_20251030_013932.csv

ğŸ¯ Round 9 Training Results:
   Training - Loss: 8152.3423, RMSE: 90.2903, RÂ²: -0.0324
   Validation - Loss: 8288.7168, RMSE: 91.0424, RÂ²: -0.0348
ğŸ’¾ Training metrics saved to: logs/client_8_training_metrics_20251030_013932.csv

ğŸ§ª Round 9 Evaluation Results:
   Test Loss: 8069.4414
   RMSE: 89.8301, MAE: 71.8240, RÂ²: -0.0334
ğŸ’¾ Test metrics saved to: logs/client_8_test_metrics_20251030_013932.csv

ğŸ” Running 3-fold cross-validation (Round 10)
ğŸ’¾ CV metrics saved to: logs/client_8_cv_metrics_20251030_013932.csv

ğŸ¯ Round 10 Training Results:
   Training - Loss: 8206.7549, RMSE: 90.5911, RÂ²: -0.0393
   Validation - Loss: 8345.3770, RMSE: 91.3530, RÂ²: -0.0418
ğŸ’¾ Training metrics saved to: logs/client_8_training_metrics_20251030_013932.csv

ğŸ§ª Round 10 Evaluation Results:
   Test Loss: 8092.2868
   RMSE: 89.9571, MAE: 71.8535, RÂ²: -0.0364
ğŸ’¾ Test metrics saved to: logs/client_8_test_metrics_20251030_013932.csv

================================================================================
ğŸ¯ FINAL COMPREHENSIVE REPORT
================================================================================
ğŸ’¾ Final summary saved to: logs/client_8_final_summary_20251030_013932.csv

ğŸ“Š CLIENT: client_8 | ALGORITHM: fedavg | MODEL: LSTM
ğŸ“ˆ TOTAL ROUNDS: 10

âš™ï¸  HYPERPARAMETERS:
   Learning Rate: 0.001
   Batch Size: 32
   Local Epochs: 1
   Hidden Dim: 64
   Num Layers: 2
   Sequence Length: 10
   Use Attention: False
   Dropout: 0.3
   Optimizer: adam

ğŸ FINAL ROUND PERFORMANCE:
   Training   - Loss:  8206.75 | RMSE:  90.59 | RÂ²: -0.0393
   Validation - Loss:  8345.38 | RMSE:  91.35 | RÂ²: -0.0418
   Test       - Loss:  8092.29 | RMSE:  89.96 | RÂ²: -0.0364

ğŸ“Š STATISTICS ACROSS ALL ROUNDS (Mean Â± Std):
   Training Loss:    8206.83 Â±  69.31
   Validation Loss:  8345.29 Â±  72.10
   Test Loss:        8785.07 Â± 2079.85

   Training RMSE:    90.59 Â±  0.38
   Validation RMSE:  91.35 Â±  0.39
   Test RMSE:        93.22 Â±  9.79

   Training RÂ²:     -0.0393 Â± 0.0088
   Validation RÂ²:   -0.0418 Â± 0.0090
   Test RÂ²:         -0.1251 Â± 0.2664

â­ BEST PERFORMANCE:
   Best Round: 9 (Test RÂ²: -0.0334)

ğŸ“‹ DATA SUMMARY:
   Training samples:   3039
   Validation samples: 1007
   Test samples:       1007
   Total samples:      5053
================================================================================
âœ… Client client_8 completed | Algorithm: FEDAVG
