[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cc8cb96f-2de2-4ace-8e72-b6e34086195b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e6c424f1-e89f-46cc-a3e9-06bb94d7165c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0b9ba938-fcb0-4398-a363-cc775dc0a13c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 87d802d9-e98e-460c-ace7-4b6029d3c2cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ceb5a693-a89c-4e96-97c4-996e284b7829
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4fae8cc7-4761-4f34-8252-e446d9b72ae3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c7f33429-5b4d-4ee4-996a-c6c4774a1d31
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d885bf0d-5817-4873-93f0-dac50f71d1ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f95135c2-876a-4265-91b4-eaeb63ff4f7d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f31e0b39-5abd-40ce-b3c4-b8e62ea5270c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 73f770ec-0c9a-4e1a-b4a3-5f0bb80d9210
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e68891cd-f787-4b1c-acf6-de966637f5e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 879c260f-3f9a-44df-8e70-8e18cedd91da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 16f23b45-a5d0-4d90-832d-fce775f148c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 62e3ebb1-ed96-49cc-a980-41832173a774
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a119bb00-9f30-4fea-ac6b-4d6e0e548db2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fe05cb8e-e6d9-49b8-b3aa-39355a09f7d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 677ef96c-398e-4ecf-b2af-4fe3831f988f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 94f3b1ad-8e6c-434f-a9cd-de1d90429600
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: reconnect message b32f5a35-b61e-469d-b198-66b450d409ce
[92mINFO [0m:      Disconnect and shut down
🚀 Starting NASA FL Client: client_11
Algorithm: FEDAVG
Server: localhost:8686
K-Folds: 5
Log Directory: logs
🔄 Using device: cuda
🎯 GPU: NVIDIA A100-SXM4-80GB
💾 Hyperparameters saved to: logs/client_11_hyperparams_20251030_014939.csv
🔍 Looking for data at: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.1/client_11
📊 Loaded 6122 total samples from /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.1/client_11
🔢 Original feature dimension: 24
🔍 Applying KernelPCA with 5 components, kernel=poly
📊 Data shape - Before: (3672, 24), After: (3672, 5)
🔄 Created sequences with length 10
   Final dataset shape: X (3662, 10, 5), y (3662,)
✅ Data split completed:
   Training samples: 3662
   Validation samples: 1215
   Test samples: 1215
   Model type: lstm
   Final input dimension: 5
✅ Client client_11 ready:
   Model: LSTM
   Training: 3662 samples
   Device: cuda
   Validation: 1215 samples
   Test: 1215 samples
   Algorithm: fedavg
   Total Rounds: 10
   Learning Rate: 0.001
   Batch Size: 32
   Logging to: logs

🧪 Round 0 Evaluation Results:
   Test Loss: 19056.5430
   RMSE: 138.0454, MAE: 106.0524, R²: -1.1865
💾 Test metrics saved to: logs/client_11_test_metrics_20251030_014939.csv
⏩ Skipping CV for Round 2 (runs every 5 rounds)
Round 2: train_loss=8855.5010, val_loss=8444.2178, val_r2=-0.0070
💾 Training metrics saved to: logs/client_11_training_metrics_20251030_014939.csv

🧪 Round 2 Evaluation Results:
   Test Loss: 9158.8835
   RMSE: 95.7021, MAE: 72.5586, R²: -0.0509
💾 Test metrics saved to: logs/client_11_test_metrics_20251030_014939.csv
⏩ Skipping CV for Round 3 (runs every 5 rounds)

🎯 Round 3 Training Results:
   Training - Loss: 8730.5938, RMSE: 93.4377, R²: -0.0115
   Validation - Loss: 8392.6211, RMSE: 91.6112, R²: -0.0008

🧪 Round 3 Evaluation Results:
   Test Loss: 9111.4356
   RMSE: 95.4538, MAE: 72.4782, R²: -0.0454
💾 Test metrics saved to: logs/client_11_test_metrics_20251030_014939.csv
⏩ Skipping CV for Round 4 (runs every 5 rounds)
Round 4: train_loss=8717.8936, val_loss=8389.5615, val_r2=-0.0005
💾 Training metrics saved to: logs/client_11_training_metrics_20251030_014939.csv

🧪 Round 4 Evaluation Results:
   Test Loss: 9106.5199
   RMSE: 95.4281, MAE: 72.4700, R²: -0.0448
💾 Test metrics saved to: logs/client_11_test_metrics_20251030_014939.csv

🔍 Running 3-fold cross-validation (Round 5)

🔍 Starting 3-fold cross-validation on TRAINING data for client client_11

📊 Fold 1/3
   Fold 1 Results:
     Val Loss: 8523.3975
     Val RMSE: 92.3222, Val R²: -0.0191

📊 Fold 2/3
   Fold 2 Results:
     Val Loss: 9215.4111
     Val RMSE: 95.9969, Val R²: -0.0205

📊 Fold 3/3
   Fold 3 Results:
     Val Loss: 8502.2393
     Val RMSE: 92.2076, Val R²: -0.0028
💾 CV metrics saved to: logs/client_11_cv_metrics_20251030_014939.csv

📈 3-Fold CV Summary (Training Data):
   VAL_LOSS: 8747.0160 ± 331.3180
   RMSE: 93.5089 ± 1.7599
   R2: -0.0142 ± 0.0080

🎯 Round 5 Training Results:
   Training - Loss: 8697.8799, RMSE: 93.2624, R²: -0.0078
   Validation - Loss: 8386.3027, RMSE: 91.5768, R²: -0.0001
💾 Training metrics saved to: logs/client_11_training_metrics_20251030_014939.csv

🧪 Round 5 Evaluation Results:
   Test Loss: 9049.6169
   RMSE: 95.1295, MAE: 72.3904, R²: -0.0383
💾 Test metrics saved to: logs/client_11_test_metrics_20251030_014939.csv
⏩ Skipping CV for Round 6 (runs every 5 rounds)

🎯 Round 6 Training Results:
   Training - Loss: 8701.7734, RMSE: 93.2833, R²: -0.0082
   Validation - Loss: 8386.7578, RMSE: 91.5792, R²: -0.0001
💾 Training metrics saved to: logs/client_11_training_metrics_20251030_014939.csv

🧪 Round 6 Evaluation Results:
   Test Loss: 9065.6934
   RMSE: 95.2139, MAE: 72.4093, R²: -0.0402
💾 Test metrics saved to: logs/client_11_test_metrics_20251030_014939.csv
⏩ Skipping CV for Round 7 (runs every 5 rounds)
Round 7: train_loss=8697.9453, val_loss=8386.3096, val_r2=-0.0001

🧪 Round 7 Evaluation Results:
   Test Loss: 9021.9529
   RMSE: 94.9840, MAE: 72.3605, R²: -0.0351
💾 Test metrics saved to: logs/client_11_test_metrics_20251030_014939.csv
⏩ Skipping CV for Round 8 (runs every 5 rounds)
Round 8: train_loss=8687.6055, val_loss=8385.6143, val_r2=-0.0000
💾 Training metrics saved to: logs/client_11_training_metrics_20251030_014939.csv

🧪 Round 8 Evaluation Results:
   Test Loss: 9031.2942
   RMSE: 95.0331, MAE: 72.3686, R²: -0.0362
💾 Test metrics saved to: logs/client_11_test_metrics_20251030_014939.csv

🔍 Running 3-fold cross-validation (Round 9)
💾 CV metrics saved to: logs/client_11_cv_metrics_20251030_014939.csv

🎯 Round 9 Training Results:
   Training - Loss: 8667.4268, RMSE: 93.0990, R²: -0.0042
   Validation - Loss: 8387.2363, RMSE: 91.5819, R²: -0.0002
💾 Training metrics saved to: logs/client_11_training_metrics_20251030_014939.csv

🧪 Round 9 Evaluation Results:
   Test Loss: 9042.0298
   RMSE: 95.0896, MAE: 72.3813, R²: -0.0374
💾 Test metrics saved to: logs/client_11_test_metrics_20251030_014939.csv

🔍 Running 3-fold cross-validation (Round 10)
💾 CV metrics saved to: logs/client_11_cv_metrics_20251030_014939.csv

🎯 Round 10 Training Results:
   Training - Loss: 8676.2520, RMSE: 93.1464, R²: -0.0052
   Validation - Loss: 8385.9316, RMSE: 91.5747, R²: -0.0000
💾 Training metrics saved to: logs/client_11_training_metrics_20251030_014939.csv

🧪 Round 10 Evaluation Results:
   Test Loss: 9030.8235
   RMSE: 95.0306, MAE: 72.3682, R²: -0.0362
💾 Test metrics saved to: logs/client_11_test_metrics_20251030_014939.csv

================================================================================
🎯 FINAL COMPREHENSIVE REPORT
================================================================================
💾 Final summary saved to: logs/client_11_final_summary_20251030_014939.csv

📊 CLIENT: client_11 | ALGORITHM: fedavg | MODEL: LSTM
📈 TOTAL ROUNDS: 10

⚙️  HYPERPARAMETERS:
   Learning Rate: 0.001
   Batch Size: 32
   Local Epochs: 1
   Hidden Dim: 64
   Num Layers: 2
   Sequence Length: 10
   Use Attention: False
   Dropout: 0.3
   Optimizer: adam

🏁 FINAL ROUND PERFORMANCE:
   Training   - Loss:  8676.25 | RMSE:  93.15 | R²: -0.0052
   Validation - Loss:  8385.93 | RMSE:  91.57 | R²: -0.0000
   Test       - Loss:  9030.82 | RMSE:  95.03 | R²: -0.0362

📊 STATISTICS ACROSS ALL ROUNDS (Mean ± Std):
   Training Loss:    8714.90 ±  59.44
   Validation Loss:  8395.09 ±  20.09
   Test Loss:       10067.48 ± 2996.65

   Training RMSE:    93.35 ±  0.32
   Validation RMSE:  91.62 ±  0.11
   Test RMSE:        99.51 ± 12.85

   Training R²:     -0.0097 ± 0.0069
   Validation R²:   -0.0011 ± 0.0024
   Test R²:         -0.1551 ± 0.3438

⭐ BEST PERFORMANCE:
   Best Round: 7 (Test R²: -0.0351)

📋 DATA SUMMARY:
   Training samples:   3662
   Validation samples: 1215
   Test samples:       1215
   Total samples:      6092
================================================================================
✅ Client client_11 completed | Algorithm: FEDAVG
