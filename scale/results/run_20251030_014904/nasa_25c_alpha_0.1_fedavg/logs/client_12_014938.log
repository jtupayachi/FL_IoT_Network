[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e757eb8f-e338-4b9e-9109-4f55fc3d788f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fdf8a788-e05b-4f9f-888c-c91c7baa6bf3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0b76b7d0-f814-4916-bcd5-9188e6c81865
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0af51d45-fd74-411b-8b3e-55b1eef13ad5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a1c8c87a-512e-4d9a-9209-90efa449ec5f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 969dd507-afff-457a-b1cb-581dec5f5562
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6d5f9bad-f177-4a1a-9969-1902139f7df1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fd796e33-b770-48e4-ba32-ddd0af34dc9f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ac6c353d-007a-43ef-a8b3-85b311c82b0e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e2bca953-a4ea-4962-aaa0-083351088cad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 862d3b8f-c032-4e0d-a5f1-4bb09c5ab0e8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6df2602d-2e1e-456d-8a04-708fa03f8824
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 96d93c8b-4f37-49b7-92b1-b1fd1cba0c9c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fc3da079-2923-49b9-ae56-e1322f8913be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7f359d34-9b5c-4ee9-9994-28f29e5dbc27
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d5697171-8921-446e-a724-7edb3afdb4b8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eb8b84a9-7c06-4efe-9501-9f2a5df19389
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f1c9b538-6faa-404e-bcf3-952b6752f45b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 07e17b18-e197-455d-b57c-b5b851727d57
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: reconnect message fe7e6242-e594-4aba-9f49-73324643ae17
[92mINFO [0m:      Disconnect and shut down
🚀 Starting NASA FL Client: client_12
Algorithm: FEDAVG
Server: localhost:8686
K-Folds: 5
Log Directory: logs
🔄 Using device: cuda
🎯 GPU: NVIDIA A100-SXM4-80GB
💾 Hyperparameters saved to: logs/client_12_hyperparams_20251030_014944.csv
🔍 Looking for data at: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.1/client_12
📊 Loaded 6688 total samples from /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.1/client_12
🔢 Original feature dimension: 24
🔍 Applying KernelPCA with 5 components, kernel=poly
📊 Data shape - Before: (4012, 24), After: (4012, 5)
🔄 Created sequences with length 10
   Final dataset shape: X (4002, 10, 5), y (4002,)
✅ Data split completed:
   Training samples: 4002
   Validation samples: 1328
   Test samples: 1328
   Model type: lstm
   Final input dimension: 5
✅ Client client_12 ready:
   Model: LSTM
   Training: 4002 samples
   Device: cuda
   Validation: 1328 samples
   Test: 1328 samples
   Algorithm: fedavg
   Total Rounds: 10
   Learning Rate: 0.001
   Batch Size: 32
   Logging to: logs

🧪 Round 0 Evaluation Results:
   Test Loss: 14637.6132
   RMSE: 120.9860, MAE: 95.3461, R²: -1.2985
💾 Test metrics saved to: logs/client_12_test_metrics_20251030_014944.csv
⏩ Skipping CV for Round 2 (runs every 5 rounds)
Round 2: train_loss=6019.3921, val_loss=6215.7012, val_r2=-0.0142
💾 Training metrics saved to: logs/client_12_training_metrics_20251030_014944.csv

🧪 Round 2 Evaluation Results:
   Test Loss: 6474.3930
   RMSE: 80.4636, MAE: 65.3066, R²: -0.0167
💾 Test metrics saved to: logs/client_12_test_metrics_20251030_014944.csv
⏩ Skipping CV for Round 3 (runs every 5 rounds)

🎯 Round 3 Training Results:
   Training - Loss: 6041.8101, RMSE: 77.7291, R²: -0.0180
   Validation - Loss: 6238.4346, RMSE: 78.9838, R²: -0.0179

🧪 Round 3 Evaluation Results:
   Test Loss: 6451.8697
   RMSE: 80.3235, MAE: 65.2807, R²: -0.0131
💾 Test metrics saved to: logs/client_12_test_metrics_20251030_014944.csv
⏩ Skipping CV for Round 4 (runs every 5 rounds)
Round 4: train_loss=6019.4614, val_loss=6215.7715, val_r2=-0.0142
💾 Training metrics saved to: logs/client_12_training_metrics_20251030_014944.csv

🧪 Round 4 Evaluation Results:
   Test Loss: 6449.6195
   RMSE: 80.3095, MAE: 65.2782, R²: -0.0128
💾 Test metrics saved to: logs/client_12_test_metrics_20251030_014944.csv

🔍 Running 3-fold cross-validation (Round 5)

🔍 Starting 3-fold cross-validation on TRAINING data for client client_12

📊 Fold 1/3
   Fold 1 Results:
     Val Loss: 5628.9873
     Val RMSE: 75.0266, Val R²: -0.0049

📊 Fold 2/3
   Fold 2 Results:
     Val Loss: 6203.2832
     Val RMSE: 78.7609, Val R²: -0.0171

📊 Fold 3/3
   Fold 3 Results:
     Val Loss: 6416.4170
     Val RMSE: 80.1025, Val R²: -0.0553
💾 CV metrics saved to: logs/client_12_cv_metrics_20251030_014944.csv

📈 3-Fold CV Summary (Training Data):
   VAL_LOSS: 6082.8958 ± 332.5470
   RMSE: 77.9633 ± 2.1476
   R2: -0.0258 ± 0.0215

🎯 Round 5 Training Results:
   Training - Loss: 5995.6743, RMSE: 77.4317, R²: -0.0103
   Validation - Loss: 6191.6001, RMSE: 78.6867, R²: -0.0103
💾 Training metrics saved to: logs/client_12_training_metrics_20251030_014944.csv

🧪 Round 5 Evaluation Results:
   Test Loss: 6424.8883
   RMSE: 80.1554, MAE: 65.2589, R²: -0.0089
💾 Test metrics saved to: logs/client_12_test_metrics_20251030_014944.csv
⏩ Skipping CV for Round 6 (runs every 5 rounds)

🎯 Round 6 Training Results:
   Training - Loss: 6024.4907, RMSE: 77.6176, R²: -0.0151
   Validation - Loss: 6220.8750, RMSE: 78.8725, R²: -0.0151
💾 Training metrics saved to: logs/client_12_training_metrics_20251030_014944.csv

🧪 Round 6 Evaluation Results:
   Test Loss: 6431.6147
   RMSE: 80.1973, MAE: 65.2615, R²: -0.0099
💾 Test metrics saved to: logs/client_12_test_metrics_20251030_014944.csv
⏩ Skipping CV for Round 7 (runs every 5 rounds)
Round 7: train_loss=5977.8833, val_loss=6173.4683, val_r2=-0.0073

🧪 Round 7 Evaluation Results:
   Test Loss: 6413.8569
   RMSE: 80.0866, MAE: 65.2569, R²: -0.0071
💾 Test metrics saved to: logs/client_12_test_metrics_20251030_014944.csv
⏩ Skipping CV for Round 8 (runs every 5 rounds)
Round 8: train_loss=5941.0654, val_loss=6135.5376, val_r2=-0.0012
💾 Training metrics saved to: logs/client_12_training_metrics_20251030_014944.csv

🧪 Round 8 Evaluation Results:
   Test Loss: 6417.5010
   RMSE: 80.1093, MAE: 65.2561, R²: -0.0077
💾 Test metrics saved to: logs/client_12_test_metrics_20251030_014944.csv

🔍 Running 3-fold cross-validation (Round 9)
💾 CV metrics saved to: logs/client_12_cv_metrics_20251030_014944.csv

🎯 Round 9 Training Results:
   Training - Loss: 5977.0112, RMSE: 77.3111, R²: -0.0071
   Validation - Loss: 6172.5786, RMSE: 78.5658, R²: -0.0072
💾 Training metrics saved to: logs/client_12_training_metrics_20251030_014944.csv

🧪 Round 9 Evaluation Results:
   Test Loss: 6421.7921
   RMSE: 80.1361, MAE: 65.2576, R²: -0.0084
💾 Test metrics saved to: logs/client_12_test_metrics_20251030_014944.csv

🔍 Running 3-fold cross-validation (Round 10)
💾 CV metrics saved to: logs/client_12_cv_metrics_20251030_014944.csv

🎯 Round 10 Training Results:
   Training - Loss: 5974.1079, RMSE: 77.2924, R²: -0.0066
   Validation - Loss: 6169.6128, RMSE: 78.5469, R²: -0.0067
💾 Training metrics saved to: logs/client_12_training_metrics_20251030_014944.csv

🧪 Round 10 Evaluation Results:
   Test Loss: 6417.3153
   RMSE: 80.1081, MAE: 65.2562, R²: -0.0077
💾 Test metrics saved to: logs/client_12_test_metrics_20251030_014944.csv

================================================================================
🎯 FINAL COMPREHENSIVE REPORT
================================================================================
💾 Final summary saved to: logs/client_12_final_summary_20251030_014944.csv

📊 CLIENT: client_12 | ALGORITHM: fedavg | MODEL: LSTM
📈 TOTAL ROUNDS: 10

⚙️  HYPERPARAMETERS:
   Learning Rate: 0.001
   Batch Size: 32
   Local Epochs: 1
   Hidden Dim: 64
   Num Layers: 2
   Sequence Length: 10
   Use Attention: False
   Dropout: 0.3
   Optimizer: adam

🏁 FINAL ROUND PERFORMANCE:
   Training   - Loss:  5974.11 | RMSE:  77.29 | R²: -0.0066
   Validation - Loss:  6169.61 | RMSE:  78.55 | R²: -0.0067
   Test       - Loss:  6417.32 | RMSE:  80.11 | R²: -0.0077

📊 STATISTICS ACROSS ALL ROUNDS (Mean ± Std):
   Training Loss:    5993.03 ±  28.55
   Validation Loss:  6188.81 ±  29.17
   Test Loss:        7254.05 ± 2461.26

   Training RMSE:    77.41 ±  0.18
   Validation RMSE:  78.67 ±  0.19
   Test RMSE:        84.29 ± 12.23

   Training R²:     -0.0098 ± 0.0048
   Validation R²:   -0.0098 ± 0.0048
   Test R²:         -0.1391 ± 0.3865

⭐ BEST PERFORMANCE:
   Best Round: 7 (Test R²: -0.0071)

📋 DATA SUMMARY:
   Training samples:   4002
   Validation samples: 1328
   Test samples:       1328
   Total samples:      6658
================================================================================
✅ Client client_12 completed | Algorithm: FEDAVG
