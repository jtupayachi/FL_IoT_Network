[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 245fff3e-568e-4f96-a29e-aa5f7cf44140
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1dac1d92-fe9d-4693-b741-f58c1c8f30fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a76ace0a-5c45-4456-9fe0-2c16b0f4dded
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7eddcb5a-da72-459c-b618-ae48c4ba474b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b01aa6e3-0445-4d5c-b00e-ba4fd8fb2419
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 130a9654-b774-415a-8753-7d115f445074
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d9df46a7-ce3e-46af-b512-ad0423681b7f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b3377696-284b-4457-8375-1429662b11ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c9360e66-f90e-45cb-b236-62fc0901e551
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0d78ab4c-7030-4568-b102-60a02d17d1cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 23b2f12f-c5bf-42a0-9022-0d136f20a060
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6963947b-c4fe-4a16-9f78-c9bcc20e7630
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1380e37d-0b5a-48b5-adc2-cd1a0d0016fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 62a08c11-754b-4b36-aae8-b39c6ee70d79
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7dce85d5-aa5a-4ebc-b250-ee4de9407537
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8968edb3-2233-4811-924c-77392e813d68
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 73676176-d50d-401f-82bd-cadc761e3f98
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 51ee73ef-75a1-48be-a243-d3e4e2d0e8ce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 05edba67-1685-41a8-96e2-9aec7fe328da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: reconnect message 7ccae84f-22d2-4aaa-bb41-2b7dd5a49296
[92mINFO [0m:      Disconnect and shut down
🚀 Starting NASA FL Client: client_13
Algorithm: FEDAVG
Server: localhost:8686
K-Folds: 5
Log Directory: logs
🔄 Using device: cuda
🎯 GPU: NVIDIA A100-SXM4-80GB
💾 Hyperparameters saved to: logs/client_13_hyperparams_20251030_014944.csv
🔍 Looking for data at: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.1/client_13
📊 Loaded 6596 total samples from /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.1/client_13
🔢 Original feature dimension: 24
🔍 Applying KernelPCA with 5 components, kernel=poly
📊 Data shape - Before: (3957, 24), After: (3957, 5)
🔄 Created sequences with length 10
   Final dataset shape: X (3947, 10, 5), y (3947,)
✅ Data split completed:
   Training samples: 3947
   Validation samples: 1309
   Test samples: 1310
   Model type: lstm
   Final input dimension: 5
✅ Client client_13 ready:
   Model: LSTM
   Training: 3947 samples
   Device: cuda
   Validation: 1309 samples
   Test: 1310 samples
   Algorithm: fedavg
   Total Rounds: 10
   Learning Rate: 0.001
   Batch Size: 32
   Logging to: logs

🧪 Round 0 Evaluation Results:
   Test Loss: 23643.5798
   RMSE: 153.7647, MAE: 118.3631, R²: -1.2411
💾 Test metrics saved to: logs/client_13_test_metrics_20251030_014944.csv
⏩ Skipping CV for Round 2 (runs every 5 rounds)
Round 2: train_loss=10412.9062, val_loss=10892.4951, val_r2=-0.0645
💾 Training metrics saved to: logs/client_13_training_metrics_20251030_014944.csv

🧪 Round 2 Evaluation Results:
   Test Loss: 11691.7795
   RMSE: 108.1285, MAE: 81.0238, R²: -0.1082
💾 Test metrics saved to: logs/client_13_test_metrics_20251030_014944.csv
⏩ Skipping CV for Round 3 (runs every 5 rounds)

🎯 Round 3 Training Results:
   Training - Loss: 10139.5381, RMSE: 100.6953, R²: -0.0208
   Validation - Loss: 10562.1816, RMSE: 102.7725, R²: -0.0322

🧪 Round 3 Evaluation Results:
   Test Loss: 11614.8130
   RMSE: 107.7720, MAE: 80.8475, R²: -0.1009
💾 Test metrics saved to: logs/client_13_test_metrics_20251030_014944.csv
⏩ Skipping CV for Round 4 (runs every 5 rounds)
Round 4: train_loss=10230.9639, val_loss=10675.4453, val_r2=-0.0433
💾 Training metrics saved to: logs/client_13_training_metrics_20251030_014944.csv

🧪 Round 4 Evaluation Results:
   Test Loss: 11606.7402
   RMSE: 107.7346, MAE: 80.8290, R²: -0.1002
💾 Test metrics saved to: logs/client_13_test_metrics_20251030_014944.csv

🔍 Running 3-fold cross-validation (Round 5)

🔍 Starting 3-fold cross-validation on TRAINING data for client client_13

📊 Fold 1/3
   Fold 1 Results:
     Val Loss: 10125.9590
     Val RMSE: 100.6278, Val R²: -0.0118

📊 Fold 2/3
   Fold 2 Results:
     Val Loss: 9883.2812
     Val RMSE: 99.4147, Val R²: -0.0158

📊 Fold 3/3
   Fold 3 Results:
     Val Loss: 10289.0557
     Val RMSE: 101.4350, Val R²: -0.0231
💾 CV metrics saved to: logs/client_13_cv_metrics_20251030_014944.csv

📈 3-Fold CV Summary (Training Data):
   VAL_LOSS: 10099.4320 ± 166.7153
   RMSE: 100.4925 ± 0.8303
   R2: -0.0169 ± 0.0047

🎯 Round 5 Training Results:
   Training - Loss: 10128.5654, RMSE: 100.6408, R²: -0.0197
   Validation - Loss: 10548.2832, RMSE: 102.7048, R²: -0.0309
💾 Training metrics saved to: logs/client_13_training_metrics_20251030_014944.csv

🧪 Round 5 Evaluation Results:
   Test Loss: 11511.7353
   RMSE: 107.2928, MAE: 80.6230, R²: -0.0912
💾 Test metrics saved to: logs/client_13_test_metrics_20251030_014944.csv
⏩ Skipping CV for Round 6 (runs every 5 rounds)

🎯 Round 6 Training Results:
   Training - Loss: 10173.6055, RMSE: 100.8643, R²: -0.0242
   Validation - Loss: 10604.8633, RMSE: 102.9799, R²: -0.0364
💾 Training metrics saved to: logs/client_13_training_metrics_20251030_014944.csv

🧪 Round 6 Evaluation Results:
   Test Loss: 11538.8851
   RMSE: 107.4192, MAE: 80.6794, R²: -0.0937
💾 Test metrics saved to: logs/client_13_test_metrics_20251030_014944.csv
⏩ Skipping CV for Round 7 (runs every 5 rounds)
Round 7: train_loss=10138.9424, val_loss=10561.4287, val_r2=-0.0322

🧪 Round 7 Evaluation Results:
   Test Loss: 11464.3728
   RMSE: 107.0718, MAE: 80.5254, R²: -0.0867
💾 Test metrics saved to: logs/client_13_test_metrics_20251030_014944.csv
⏩ Skipping CV for Round 8 (runs every 5 rounds)
Round 8: train_loss=10146.7490, val_loss=10571.2715, val_r2=-0.0331
💾 Training metrics saved to: logs/client_13_training_metrics_20251030_014944.csv

🧪 Round 8 Evaluation Results:
   Test Loss: 11480.4619
   RMSE: 107.1469, MAE: 80.5573, R²: -0.0882
💾 Test metrics saved to: logs/client_13_test_metrics_20251030_014944.csv

🔍 Running 3-fold cross-validation (Round 9)
💾 CV metrics saved to: logs/client_13_cv_metrics_20251030_014944.csv

🎯 Round 9 Training Results:
   Training - Loss: 10161.9873, RMSE: 100.8067, R²: -0.0231
   Validation - Loss: 10590.3799, RMSE: 102.9096, R²: -0.0350
💾 Training metrics saved to: logs/client_13_training_metrics_20251030_014944.csv

🧪 Round 9 Evaluation Results:
   Test Loss: 11498.8297
   RMSE: 107.2326, MAE: 80.5959, R²: -0.0899
💾 Test metrics saved to: logs/client_13_test_metrics_20251030_014944.csv

🔍 Running 3-fold cross-validation (Round 10)
💾 CV metrics saved to: logs/client_13_cv_metrics_20251030_014944.csv

🎯 Round 10 Training Results:
   Training - Loss: 10114.3135, RMSE: 100.5699, R²: -0.0183
   Validation - Loss: 10530.1084, RMSE: 102.6163, R²: -0.0291
💾 Training metrics saved to: logs/client_13_training_metrics_20251030_014944.csv

🧪 Round 10 Evaluation Results:
   Test Loss: 11479.6534
   RMSE: 107.1431, MAE: 80.5557, R²: -0.0881
💾 Test metrics saved to: logs/client_13_test_metrics_20251030_014944.csv

================================================================================
🎯 FINAL COMPREHENSIVE REPORT
================================================================================
💾 Final summary saved to: logs/client_13_final_summary_20251030_014944.csv

📊 CLIENT: client_13 | ALGORITHM: fedavg | MODEL: LSTM
📈 TOTAL ROUNDS: 10

⚙️  HYPERPARAMETERS:
   Learning Rate: 0.001
   Batch Size: 32
   Local Epochs: 1
   Hidden Dim: 64
   Num Layers: 2
   Sequence Length: 10
   Use Attention: False
   Dropout: 0.3
   Optimizer: adam

🏁 FINAL ROUND PERFORMANCE:
   Training   - Loss: 10114.31 | RMSE: 100.57 | R²: -0.0183
   Validation - Loss: 10530.11 | RMSE: 102.62 | R²: -0.0291
   Test       - Loss: 11479.65 | RMSE: 107.14 | R²: -0.0881

📊 STATISTICS ACROSS ALL ROUNDS (Mean ± Std):
   Training Loss:   10195.58 ±  95.30
   Validation Loss: 10630.41 ± 115.43
   Test Loss:       12753.09 ± 3630.83

   Training RMSE:   100.97 ±  0.47
   Validation RMSE: 103.10 ±  0.56
   Test RMSE:       112.07 ± 13.90

   Training R²:     -0.0265 ± 0.0096
   Validation R²:   -0.0389 ± 0.0113
   Test R²:         -0.2088 ± 0.3442

⭐ BEST PERFORMANCE:
   Best Round: 7 (Test R²: -0.0867)

📋 DATA SUMMARY:
   Training samples:   3947
   Validation samples: 1309
   Test samples:       1310
   Total samples:      6566
================================================================================
✅ Client client_13 completed | Algorithm: FEDAVG
