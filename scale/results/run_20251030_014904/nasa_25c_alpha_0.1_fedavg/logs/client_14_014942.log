[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 17aff445-be9f-4a41-89d2-95e0d8e8b0cd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c2bffe67-458f-4d6a-8aa7-a24a64eaf6b0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bd91ecf1-96ae-4da9-8cde-31e535a3f594
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 180ff620-7f27-4080-811f-22b8455c9de7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8b2015c1-a827-4156-b2b5-f59269273e65
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0dc03491-9a2e-4181-b9d3-628dfa5c3821
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dd6fdb37-e49e-4559-93d9-e18c2256d7a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 92b48041-ad6f-4a4d-ab61-cc2ac81a432c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 114a40df-3d7f-4b8a-bb72-3c66942497bc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 016121c2-dbef-46d9-9104-3e8b075c2d9e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 33abca6e-1037-4606-a32d-7428bf2e8c3c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 710b03da-2d6b-4b8b-8a51-f34017fc92f3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 82f10923-a3a7-4aa8-b7e8-6907d5afbd7a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0e9fd18c-b88a-4409-9ca5-2c1143846831
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 39068331-7ea3-4f60-b82b-2b4346616d52
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9ff392c5-3979-4822-bb18-82cc48865ce3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 50876bf9-4a08-4ce4-a67a-a50b2e2195aa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 320f5602-2f5e-4ac8-b117-a99a7e7cae59
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0d3f8c0c-95a4-4580-b481-cce3b17dd568
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: reconnect message 0e8fde5a-f75e-4bb5-a18a-8cb9905793e9
[92mINFO [0m:      Disconnect and shut down
🚀 Starting NASA FL Client: client_14
Algorithm: FEDAVG
Server: localhost:8686
K-Folds: 5
Log Directory: logs
🔄 Using device: cuda
🎯 GPU: NVIDIA A100-SXM4-80GB
💾 Hyperparameters saved to: logs/client_14_hyperparams_20251030_014946.csv
🔍 Looking for data at: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.1/client_14
📊 Loaded 6057 total samples from /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.1/client_14
🔢 Original feature dimension: 24
🔍 Applying KernelPCA with 5 components, kernel=poly
📊 Data shape - Before: (3633, 24), After: (3633, 5)
🔄 Created sequences with length 10
   Final dataset shape: X (3623, 10, 5), y (3623,)
✅ Data split completed:
   Training samples: 3623
   Validation samples: 1202
   Test samples: 1202
   Model type: lstm
   Final input dimension: 5
✅ Client client_14 ready:
   Model: LSTM
   Training: 3623 samples
   Device: cuda
   Validation: 1202 samples
   Test: 1202 samples
   Algorithm: fedavg
   Total Rounds: 10
   Learning Rate: 0.001
   Batch Size: 32
   Logging to: logs

🧪 Round 0 Evaluation Results:
   Test Loss: 17515.1507
   RMSE: 132.3448, MAE: 96.9935, R²: -0.9610
💾 Test metrics saved to: logs/client_14_test_metrics_20251030_014946.csv
⏩ Skipping CV for Round 2 (runs every 5 rounds)
Round 2: train_loss=9944.9609, val_loss=9397.2812, val_r2=-0.0315
💾 Training metrics saved to: logs/client_14_training_metrics_20251030_014946.csv

🧪 Round 2 Evaluation Results:
   Test Loss: 9075.8926
   RMSE: 95.2675, MAE: 70.1756, R²: -0.0161
💾 Test metrics saved to: logs/client_14_test_metrics_20251030_014946.csv
⏩ Skipping CV for Round 3 (runs every 5 rounds)

🎯 Round 3 Training Results:
   Training - Loss: 9904.1279, RMSE: 99.5195, R²: -0.0211
   Validation - Loss: 9352.9795, RMSE: 96.7108, R²: -0.0266

🧪 Round 3 Evaluation Results:
   Test Loss: 9049.4027
   RMSE: 95.1283, MAE: 70.1807, R²: -0.0132
💾 Test metrics saved to: logs/client_14_test_metrics_20251030_014946.csv
⏩ Skipping CV for Round 4 (runs every 5 rounds)
Round 4: train_loss=9891.3652, val_loss=9339.0635, val_r2=-0.0251
💾 Training metrics saved to: logs/client_14_training_metrics_20251030_014946.csv

🧪 Round 4 Evaluation Results:
   Test Loss: 9046.7283
   RMSE: 95.1143, MAE: 70.1818, R²: -0.0129
💾 Test metrics saved to: logs/client_14_test_metrics_20251030_014946.csv

🔍 Running 3-fold cross-validation (Round 5)

🔍 Starting 3-fold cross-validation on TRAINING data for client client_14

📊 Fold 1/3
   Fold 1 Results:
     Val Loss: 10302.6436
     Val RMSE: 101.5019, Val R²: -0.0127

📊 Fold 2/3
   Fold 2 Results:
     Val Loss: 9805.3184
     Val RMSE: 99.0218, Val R²: -0.0120

📊 Fold 3/3
   Fold 3 Results:
     Val Loss: 9317.8223
     Val RMSE: 96.5289, Val R²: -0.0090
💾 CV metrics saved to: logs/client_14_cv_metrics_20251030_014946.csv

📈 3-Fold CV Summary (Training Data):
   VAL_LOSS: 9808.5947 ± 402.0583
   RMSE: 99.0175 ± 2.0303
   R2: -0.0112 ± 0.0016

🎯 Round 5 Training Results:
   Training - Loss: 9875.5684, RMSE: 99.3759, R²: -0.0181
   Validation - Loss: 9321.7832, RMSE: 96.5494, R²: -0.0232
💾 Training metrics saved to: logs/client_14_training_metrics_20251030_014946.csv

🧪 Round 5 Evaluation Results:
   Test Loss: 9016.8770
   RMSE: 94.9572, MAE: 70.2103, R²: -0.0095
💾 Test metrics saved to: logs/client_14_test_metrics_20251030_014946.csv
⏩ Skipping CV for Round 6 (runs every 5 rounds)

🎯 Round 6 Training Results:
   Training - Loss: 9877.7637, RMSE: 99.3869, R²: -0.0183
   Validation - Loss: 9324.1885, RMSE: 96.5618, R²: -0.0234
💾 Training metrics saved to: logs/client_14_training_metrics_20251030_014946.csv

🧪 Round 6 Evaluation Results:
   Test Loss: 9025.0912
   RMSE: 95.0005, MAE: 70.1987, R²: -0.0105
💾 Test metrics saved to: logs/client_14_test_metrics_20251030_014946.csv
⏩ Skipping CV for Round 7 (runs every 5 rounds)
Round 7: train_loss=9830.7598, val_loss=9272.3604, val_r2=-0.0178

🧪 Round 7 Evaluation Results:
   Test Loss: 9003.1986
   RMSE: 94.8852, MAE: 70.2333, R²: -0.0080
💾 Test metrics saved to: logs/client_14_test_metrics_20251030_014946.csv
⏩ Skipping CV for Round 8 (runs every 5 rounds)
Round 8: train_loss=9815.3516, val_loss=9255.1855, val_r2=-0.0159
💾 Training metrics saved to: logs/client_14_training_metrics_20251030_014946.csv

🧪 Round 8 Evaluation Results:
   Test Loss: 9007.7491
   RMSE: 94.9092, MAE: 70.2241, R²: -0.0085
💾 Test metrics saved to: logs/client_14_test_metrics_20251030_014946.csv

🔍 Running 3-fold cross-validation (Round 9)
💾 CV metrics saved to: logs/client_14_cv_metrics_20251030_014946.csv

🎯 Round 9 Training Results:
   Training - Loss: 9905.5273, RMSE: 99.5265, R²: -0.0212
   Validation - Loss: 9354.5029, RMSE: 96.7187, R²: -0.0268
💾 Training metrics saved to: logs/client_14_training_metrics_20251030_014946.csv

🧪 Round 9 Evaluation Results:
   Test Loss: 9013.0657
   RMSE: 94.9372, MAE: 70.2158, R²: -0.0091
💾 Test metrics saved to: logs/client_14_test_metrics_20251030_014946.csv

🔍 Running 3-fold cross-validation (Round 10)
💾 CV metrics saved to: logs/client_14_cv_metrics_20251030_014946.csv

🎯 Round 10 Training Results:
   Training - Loss: 9885.3760, RMSE: 99.4252, R²: -0.0191
   Validation - Loss: 9332.5186, RMSE: 96.6050, R²: -0.0244
💾 Training metrics saved to: logs/client_14_training_metrics_20251030_014946.csv

🧪 Round 10 Evaluation Results:
   Test Loss: 9007.5179
   RMSE: 94.9079, MAE: 70.2245, R²: -0.0085
💾 Test metrics saved to: logs/client_14_test_metrics_20251030_014946.csv

================================================================================
🎯 FINAL COMPREHENSIVE REPORT
================================================================================
💾 Final summary saved to: logs/client_14_final_summary_20251030_014946.csv

📊 CLIENT: client_14 | ALGORITHM: fedavg | MODEL: LSTM
📈 TOTAL ROUNDS: 10

⚙️  HYPERPARAMETERS:
   Learning Rate: 0.001
   Batch Size: 32
   Local Epochs: 1
   Hidden Dim: 64
   Num Layers: 2
   Sequence Length: 10
   Use Attention: False
   Dropout: 0.3
   Optimizer: adam

🏁 FINAL ROUND PERFORMANCE:
   Training   - Loss:  9885.38 | RMSE:  99.43 | R²: -0.0191
   Validation - Loss:  9332.52 | RMSE:  96.60 | R²: -0.0244
   Test       - Loss:  9007.52 | RMSE:  94.91 | R²: -0.0085

📊 STATISTICS ACROSS ALL ROUNDS (Mean ± Std):
   Training Loss:    9885.13 ±  35.96
   Validation Loss:  9332.07 ±  39.43
   Test Loss:        9876.07 ± 2546.46

   Training RMSE:    99.42 ±  0.18
   Validation RMSE:  96.60 ±  0.20
   Test RMSE:        98.75 ± 11.20

   Training R²:     -0.0191 ± 0.0037
   Validation R²:   -0.0243 ± 0.0043
   Test R²:         -0.1057 ± 0.2851

⭐ BEST PERFORMANCE:
   Best Round: 7 (Test R²: -0.0080)

📋 DATA SUMMARY:
   Training samples:   3623
   Validation samples: 1202
   Test samples:       1202
   Total samples:      6027
================================================================================
✅ Client client_14 completed | Algorithm: FEDAVG
