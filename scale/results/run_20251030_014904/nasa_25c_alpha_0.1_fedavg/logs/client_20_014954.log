[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message acf7b680-c16c-4d44-8bc5-15791b61f6d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8d65be93-5817-4984-b032-3588dba8e98b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6a8c66ae-b02d-408f-a828-0498c4ac0d61
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 992ef73c-db1b-45a4-a7a8-50ce83a82dde
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a31206da-b12d-4fa7-9a66-1b5fee1c9bf2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b7be43cd-6632-4a88-8511-874adc77dd12
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 95e52ad8-e516-4dc7-af20-90584cb89026
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 76eff07c-6d7b-4bfd-b243-340050330505
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9d45ff99-6bb9-48f3-a8e0-4676a83c8f3b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ea481431-5dce-4992-b476-aadcde7a2c95
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 96559a22-09d9-4824-af54-01f9feff8ae5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 80359316-f14f-4393-bc8a-5f3be69c9d25
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 14ac9152-2419-47da-a979-a3474ddac55c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6058e092-da6d-493f-a395-a3c615645aa2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 31baf177-d9f3-4ef2-8ea3-8a7f4853a005
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c5a0cf4d-34f4-483d-b7ff-3df22ad45558
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8352f7fe-e251-4b46-85ac-75c82b3b49f3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3cdbb474-c687-487b-a626-eb21b0a71c47
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 83f9279b-197a-4501-8db7-5e026eb0e798
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: reconnect message d50f9ecd-e199-4979-8ad6-599ce3ed60d5
[92mINFO [0m:      Disconnect and shut down
🚀 Starting NASA FL Client: client_20
Algorithm: FEDAVG
Server: localhost:8686
K-Folds: 5
Log Directory: logs
🔄 Using device: cuda
🎯 GPU: NVIDIA A100-SXM4-80GB
💾 Hyperparameters saved to: logs/client_20_hyperparams_20251030_014957.csv
🔍 Looking for data at: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.1/client_20
📊 Loaded 7643 total samples from /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.1/client_20
🔢 Original feature dimension: 24
🔍 Applying KernelPCA with 5 components, kernel=poly
📊 Data shape - Before: (4585, 24), After: (4585, 5)
🔄 Created sequences with length 10
   Final dataset shape: X (4575, 10, 5), y (4575,)
✅ Data split completed:
   Training samples: 4575
   Validation samples: 1519
   Test samples: 1519
   Model type: lstm
   Final input dimension: 5
✅ Client client_20 ready:
   Model: LSTM
   Training: 4575 samples
   Device: cuda
   Validation: 1519 samples
   Test: 1519 samples
   Algorithm: fedavg
   Total Rounds: 10
   Learning Rate: 0.001
   Batch Size: 32
   Logging to: logs

🧪 Round 0 Evaluation Results:
   Test Loss: 17665.3254
   RMSE: 132.9110, MAE: 106.3819, R²: -1.4605
💾 Test metrics saved to: logs/client_20_test_metrics_20251030_014957.csv
⏩ Skipping CV for Round 2 (runs every 5 rounds)
Round 2: train_loss=6984.8647, val_loss=7107.8794, val_r2=-0.0297
💾 Training metrics saved to: logs/client_20_training_metrics_20251030_014957.csv

🧪 Round 2 Evaluation Results:
   Test Loss: 7653.1270
   RMSE: 87.4822, MAE: 70.1994, R²: -0.0660
💾 Test metrics saved to: logs/client_20_test_metrics_20251030_014957.csv
⏩ Skipping CV for Round 3 (runs every 5 rounds)

🎯 Round 3 Training Results:
   Training - Loss: 6933.9541, RMSE: 83.2704, R²: -0.0275
   Validation - Loss: 7060.6396, RMSE: 84.0276, R²: -0.0229

🧪 Round 3 Evaluation Results:
   Test Loss: 7604.0331
   RMSE: 87.2011, MAE: 70.0650, R²: -0.0591
💾 Test metrics saved to: logs/client_20_test_metrics_20251030_014957.csv
⏩ Skipping CV for Round 4 (runs every 5 rounds)
Round 4: train_loss=6978.8848, val_loss=7102.3081, val_r2=-0.0289
💾 Training metrics saved to: logs/client_20_training_metrics_20251030_014957.csv

🧪 Round 4 Evaluation Results:
   Test Loss: 7598.9414
   RMSE: 87.1719, MAE: 70.0513, R²: -0.0584
💾 Test metrics saved to: logs/client_20_test_metrics_20251030_014957.csv

🔍 Running 3-fold cross-validation (Round 5)

🔍 Starting 3-fold cross-validation on TRAINING data for client client_20

📊 Fold 1/3
   Fold 1 Results:
     Val Loss: 6854.8628
     Val RMSE: 82.7941, Val R²: -0.0195

📊 Fold 2/3
   Fold 2 Results:
     Val Loss: 6748.9688
     Val RMSE: 82.1521, Val R²: -0.0165

📊 Fold 3/3
   Fold 3 Results:
     Val Loss: 7251.5952
     Val RMSE: 85.1563, Val R²: -0.0543
💾 CV metrics saved to: logs/client_20_cv_metrics_20251030_014957.csv

📈 3-Fold CV Summary (Training Data):
   VAL_LOSS: 6951.8089 ± 216.3443
   RMSE: 83.3675 ± 1.2917
   R2: -0.0301 ± 0.0172

🎯 Round 5 Training Results:
   Training - Loss: 6927.1328, RMSE: 83.2294, R²: -0.0264
   Validation - Loss: 7054.3477, RMSE: 83.9902, R²: -0.0220
💾 Training metrics saved to: logs/client_20_training_metrics_20251030_014957.csv

🧪 Round 5 Evaluation Results:
   Test Loss: 7539.9139
   RMSE: 86.8327, MAE: 69.9040, R²: -0.0502
💾 Test metrics saved to: logs/client_20_test_metrics_20251030_014957.csv
⏩ Skipping CV for Round 6 (runs every 5 rounds)

🎯 Round 6 Training Results:
   Training - Loss: 6898.5303, RMSE: 83.0574, R²: -0.0222
   Validation - Loss: 7028.0801, RMSE: 83.8336, R²: -0.0182
💾 Training metrics saved to: logs/client_20_training_metrics_20251030_014957.csv

🧪 Round 6 Evaluation Results:
   Test Loss: 7556.6077
   RMSE: 86.9287, MAE: 69.9450, R²: -0.0525
💾 Test metrics saved to: logs/client_20_test_metrics_20251030_014957.csv
⏩ Skipping CV for Round 7 (runs every 5 rounds)
Round 7: train_loss=6945.9482, val_loss=7071.7271, val_r2=-0.0245

🧪 Round 7 Evaluation Results:
   Test Loss: 7511.1515
   RMSE: 86.6669, MAE: 69.8324, R²: -0.0462
💾 Test metrics saved to: logs/client_20_test_metrics_20251030_014957.csv
⏩ Skipping CV for Round 8 (runs every 5 rounds)
Round 8: train_loss=6910.4175, val_loss=7038.9717, val_r2=-0.0197
💾 Training metrics saved to: logs/client_20_training_metrics_20251030_014957.csv

🧪 Round 8 Evaluation Results:
   Test Loss: 7520.8690
   RMSE: 86.7229, MAE: 69.8563, R²: -0.0475
💾 Test metrics saved to: logs/client_20_test_metrics_20251030_014957.csv

🔍 Running 3-fold cross-validation (Round 9)
💾 CV metrics saved to: logs/client_20_cv_metrics_20251030_014957.csv

🎯 Round 9 Training Results:
   Training - Loss: 6921.5620, RMSE: 83.1959, R²: -0.0256
   Validation - Loss: 7049.2158, RMSE: 83.9596, R²: -0.0212
💾 Training metrics saved to: logs/client_20_training_metrics_20251030_014957.csv

🧪 Round 9 Evaluation Results:
   Test Loss: 7532.0302
   RMSE: 86.7873, MAE: 69.8844, R²: -0.0491
💾 Test metrics saved to: logs/client_20_test_metrics_20251030_014957.csv

🔍 Running 3-fold cross-validation (Round 10)
💾 CV metrics saved to: logs/client_20_cv_metrics_20251030_014957.csv

🎯 Round 10 Training Results:
   Training - Loss: 6906.2671, RMSE: 83.1040, R²: -0.0234
   Validation - Loss: 7035.1646, RMSE: 83.8759, R²: -0.0192
💾 Training metrics saved to: logs/client_20_training_metrics_20251030_014957.csv

🧪 Round 10 Evaluation Results:
   Test Loss: 7520.3794
   RMSE: 86.7201, MAE: 69.8551, R²: -0.0475
💾 Test metrics saved to: logs/client_20_test_metrics_20251030_014957.csv

================================================================================
🎯 FINAL COMPREHENSIVE REPORT
================================================================================
💾 Final summary saved to: logs/client_20_final_summary_20251030_014957.csv

📊 CLIENT: client_20 | ALGORITHM: fedavg | MODEL: LSTM
📈 TOTAL ROUNDS: 10

⚙️  HYPERPARAMETERS:
   Learning Rate: 0.001
   Batch Size: 32
   Local Epochs: 1
   Hidden Dim: 64
   Num Layers: 2
   Sequence Length: 10
   Use Attention: False
   Dropout: 0.3
   Optimizer: adam

🏁 FINAL ROUND PERFORMANCE:
   Training   - Loss:  6906.27 | RMSE:  83.10 | R²: -0.0234
   Validation - Loss:  7035.16 | RMSE:  83.88 | R²: -0.0192
   Test       - Loss:  7520.38 | RMSE:  86.72 | R²: -0.0475

📊 STATISTICS ACROSS ALL ROUNDS (Mean ± Std):
   Training Loss:    6932.52 ±  32.45
   Validation Loss:  7059.42 ±  30.01
   Test Loss:        8570.24 ± 3032.01

   Training RMSE:    83.26 ±  0.19
   Validation RMSE:  84.02 ±  0.18
   Test RMSE:        91.54 ± 13.79

   Training R²:     -0.0272 ± 0.0048
   Validation R²:   -0.0227 ± 0.0043
   Test R²:         -0.1937 ± 0.4223

⭐ BEST PERFORMANCE:
   Best Round: 7 (Test R²: -0.0462)

📋 DATA SUMMARY:
   Training samples:   4575
   Validation samples: 1519
   Test samples:       1519
   Total samples:      7613
================================================================================
✅ Client client_20 completed | Algorithm: FEDAVG
