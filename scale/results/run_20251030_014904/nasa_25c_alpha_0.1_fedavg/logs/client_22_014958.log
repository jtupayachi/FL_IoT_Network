[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 12e2194f-b93f-4605-8914-a2bfdfc1cd0e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 376f1f3c-a11a-4cee-92f2-195eee005eaf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6d088bec-8db9-4c24-bacd-9b15df9a82fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f2464b90-3baa-48db-b747-c4f5211cbfec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3dccf537-a28f-49a5-a1b2-e8745efdffee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 300e4623-efcf-4f61-acd4-97aedefef669
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7363e779-c9b1-41c5-ab18-27bb0d3c1222
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f706f036-e1e1-4a0c-826b-c4f0dab90b55
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message edc7dad3-cee0-4aa4-9753-a1e23792f58e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7c0b8b0b-1be9-423f-8413-81cc92fa2d9a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2d68a2fb-1050-46e9-9f8f-d952aaa6ee53
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 29dcfea3-988a-45a3-9d17-aefde436d808
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 77215a58-50ca-45b8-b6ed-0cf543e629c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d0b49464-7b35-4703-9121-2b4b26a971d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 689a9ad6-169a-478f-b9f8-4e827d7b3867
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7e72ae76-7083-4a0f-96c3-9d1ad8df40a3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message af158b58-c459-473f-b9f6-66308fcc5532
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b4ed31b9-1212-45af-be7d-d69bd9ff851c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0b98b483-ff35-43b9-b59e-a7988aabc18e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: reconnect message 62618a92-b29a-43d1-81a2-76c379ad2de2
[92mINFO [0m:      Disconnect and shut down
🚀 Starting NASA FL Client: client_22
Algorithm: FEDAVG
Server: localhost:8686
K-Folds: 5
Log Directory: logs
🔄 Using device: cuda
🎯 GPU: NVIDIA A100-SXM4-80GB
💾 Hyperparameters saved to: logs/client_22_hyperparams_20251030_015001.csv
🔍 Looking for data at: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.1/client_22
📊 Loaded 5251 total samples from /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.1/client_22
🔢 Original feature dimension: 24
🔍 Applying KernelPCA with 5 components, kernel=poly
📊 Data shape - Before: (3150, 24), After: (3150, 5)
🔄 Created sequences with length 10
   Final dataset shape: X (3140, 10, 5), y (3140,)
✅ Data split completed:
   Training samples: 3140
   Validation samples: 1040
   Test samples: 1041
   Model type: lstm
   Final input dimension: 5
✅ Client client_22 ready:
   Model: LSTM
   Training: 3140 samples
   Device: cuda
   Validation: 1040 samples
   Test: 1041 samples
   Algorithm: fedavg
   Total Rounds: 10
   Learning Rate: 0.001
   Batch Size: 32
   Logging to: logs

🧪 Round 0 Evaluation Results:
   Test Loss: 9292.7984
   RMSE: 96.3992, MAE: 77.9649, R²: -1.3510
💾 Test metrics saved to: logs/client_22_test_metrics_20251030_015001.csv
⏩ Skipping CV for Round 2 (runs every 5 rounds)
Round 2: train_loss=4408.6719, val_loss=4184.2969, val_r2=-0.0240
💾 Training metrics saved to: logs/client_22_training_metrics_20251030_015001.csv

🧪 Round 2 Evaluation Results:
   Test Loss: 4009.8959
   RMSE: 63.3237, MAE: 53.1179, R²: -0.0145
💾 Test metrics saved to: logs/client_22_test_metrics_20251030_015001.csv
⏩ Skipping CV for Round 3 (runs every 5 rounds)

🎯 Round 3 Training Results:
   Training - Loss: 4311.3643, RMSE: 65.6610, R²: -0.0145
   Validation - Loss: 4112.7778, RMSE: 64.1309, R²: -0.0065

🧪 Round 3 Evaluation Results:
   Test Loss: 4028.7636
   RMSE: 63.4725, MAE: 53.2340, R²: -0.0192
💾 Test metrics saved to: logs/client_22_test_metrics_20251030_015001.csv
⏩ Skipping CV for Round 4 (runs every 5 rounds)
Round 4: train_loss=4323.1279, val_loss=4120.6567, val_r2=-0.0084
💾 Training metrics saved to: logs/client_22_training_metrics_20251030_015001.csv

🧪 Round 4 Evaluation Results:
   Test Loss: 4030.9405
   RMSE: 63.4897, MAE: 53.2471, R²: -0.0198
💾 Test metrics saved to: logs/client_22_test_metrics_20251030_015001.csv

🔍 Running 3-fold cross-validation (Round 5)

🔍 Starting 3-fold cross-validation on TRAINING data for client client_22

📊 Fold 1/3
   Fold 1 Results:
     Val Loss: 4214.1328
     Val RMSE: 64.9164, Val R²: -0.0328

📊 Fold 2/3
   Fold 2 Results:
     Val Loss: 4447.3975
     Val RMSE: 66.6888, Val R²: -0.0263

📊 Fold 3/3
   Fold 3 Results:
     Val Loss: 4595.9839
     Val RMSE: 67.7937, Val R²: -0.0618
💾 CV metrics saved to: logs/client_22_cv_metrics_20251030_015001.csv

📈 3-Fold CV Summary (Training Data):
   VAL_LOSS: 4419.1714 ± 157.1625
   RMSE: 66.4663 ± 1.1852
   R2: -0.0403 ± 0.0154

🎯 Round 5 Training Results:
   Training - Loss: 4348.2783, RMSE: 65.9415, R²: -0.0232
   Validation - Loss: 4138.4336, RMSE: 64.3307, R²: -0.0127
💾 Training metrics saved to: logs/client_22_training_metrics_20251030_015001.csv

🧪 Round 5 Evaluation Results:
   Test Loss: 4059.6355
   RMSE: 63.7153, MAE: 53.4241, R²: -0.0270
💾 Test metrics saved to: logs/client_22_test_metrics_20251030_015001.csv
⏩ Skipping CV for Round 6 (runs every 5 rounds)

🎯 Round 6 Training Results:
   Training - Loss: 4357.5381, RMSE: 66.0117, R²: -0.0254
   Validation - Loss: 4145.2222, RMSE: 64.3834, R²: -0.0144
💾 Training metrics saved to: logs/client_22_training_metrics_20251030_015001.csv

🧪 Round 6 Evaluation Results:
   Test Loss: 4050.8348
   RMSE: 63.6462, MAE: 53.3694, R²: -0.0248
💾 Test metrics saved to: logs/client_22_test_metrics_20251030_015001.csv
⏩ Skipping CV for Round 7 (runs every 5 rounds)
Round 7: train_loss=4306.2725, val_loss=4109.4829, val_r2=-0.0057

🧪 Round 7 Evaluation Results:
   Test Loss: 4076.2253
   RMSE: 63.8453, MAE: 53.5248, R²: -0.0312
💾 Test metrics saved to: logs/client_22_test_metrics_20251030_015001.csv
⏩ Skipping CV for Round 8 (runs every 5 rounds)
Round 8: train_loss=4327.5186, val_loss=4123.6772, val_r2=-0.0091
💾 Training metrics saved to: logs/client_22_training_metrics_20251030_015001.csv

🧪 Round 8 Evaluation Results:
   Test Loss: 4070.4081
   RMSE: 63.7998, MAE: 53.4884, R²: -0.0298
💾 Test metrics saved to: logs/client_22_test_metrics_20251030_015001.csv

🔍 Running 3-fold cross-validation (Round 9)
💾 CV metrics saved to: logs/client_22_cv_metrics_20251030_015001.csv

🎯 Round 9 Training Results:
   Training - Loss: 4314.2129, RMSE: 65.6827, R²: -0.0152
   Validation - Loss: 4114.6538, RMSE: 64.1456, R²: -0.0069
💾 Training metrics saved to: logs/client_22_training_metrics_20251030_015001.csv

🧪 Round 9 Evaluation Results:
   Test Loss: 4063.9969
   RMSE: 63.7495, MAE: 53.4504, R²: -0.0282
💾 Test metrics saved to: logs/client_22_test_metrics_20251030_015001.csv

🔍 Running 3-fold cross-validation (Round 10)
💾 CV metrics saved to: logs/client_22_cv_metrics_20251030_015001.csv

🎯 Round 10 Training Results:
   Training - Loss: 4307.1113, RMSE: 65.6286, R²: -0.0135
   Validation - Loss: 4110.0200, RMSE: 64.1094, R²: -0.0058
💾 Training metrics saved to: logs/client_22_training_metrics_20251030_015001.csv

🧪 Round 10 Evaluation Results:
   Test Loss: 4070.6959
   RMSE: 63.8020, MAE: 53.4902, R²: -0.0298
💾 Test metrics saved to: logs/client_22_test_metrics_20251030_015001.csv

================================================================================
🎯 FINAL COMPREHENSIVE REPORT
================================================================================
💾 Final summary saved to: logs/client_22_final_summary_20251030_015001.csv

📊 CLIENT: client_22 | ALGORITHM: fedavg | MODEL: LSTM
📈 TOTAL ROUNDS: 10

⚙️  HYPERPARAMETERS:
   Learning Rate: 0.001
   Batch Size: 32
   Local Epochs: 1
   Hidden Dim: 64
   Num Layers: 2
   Sequence Length: 10
   Use Attention: False
   Dropout: 0.3
   Optimizer: adam

🏁 FINAL ROUND PERFORMANCE:
   Training   - Loss:  4307.11 | RMSE:  65.63 | R²: -0.0135
   Validation - Loss:  4110.02 | RMSE:  64.11 | R²: -0.0058
   Test       - Loss:  4070.70 | RMSE:  63.80 | R²: -0.0298

📊 STATISTICS ACROSS ALL ROUNDS (Mean ± Std):
   Training Loss:    4340.92 ±  32.23
   Validation Loss:  4133.85 ±  23.63
   Test Loss:        4575.42 ± 1572.59

   Training RMSE:    65.89 ±  0.24
   Validation RMSE:  64.29 ±  0.18
   Test RMSE:        66.92 ±  9.83

   Training R²:     -0.0214 ± 0.0076
   Validation R²:   -0.0116 ± 0.0058
   Test R²:         -0.1575 ± 0.3979

⭐ BEST PERFORMANCE:
   Best Round: 2 (Test R²: -0.0145)

📋 DATA SUMMARY:
   Training samples:   3140
   Validation samples: 1040
   Test samples:       1041
   Total samples:      5221
================================================================================
✅ Client client_22 completed | Algorithm: FEDAVG
