[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8ec2aa18-a9d8-4470-8bf7-36055c0acee4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 676e84ed-268e-42d9-bfd8-93601ac04431
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 20b5defe-886a-493b-ac44-18d9b18b2dd5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3323591b-3e05-4816-bab8-1203a19f35ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b7a656e0-11b7-4ee8-a93a-936c095c060b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 54042ff9-a48e-40ec-96e0-8af1ff648203
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c18b44cd-60dd-44a9-b94e-5669966c966e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d2185493-91f8-4459-95b7-d77f51c21fc5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f1d2ec84-39e8-460b-b1e4-86dafba5cc51
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e3670894-84e7-4c02-8d81-6c4fd4969901
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f8a61ee6-20d4-41ce-908e-acc5d7f7c86c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 567e5902-308b-4424-b5df-984b99731d2d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b609204d-a2a3-4b8f-a8bd-a0c313308d6e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 38712d72-229f-4de3-b777-39ab45e285ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b70b6bf1-123a-49f4-a213-222b5e6766fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 36bc5948-7a8e-488c-a38c-9af00ca99327
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5d2822ac-9435-48b8-a1a2-198377e3380a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b28f7ee8-6837-45d7-bc11-39004677d7fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ccdb365d-c829-4c06-b91e-0e0dc857e1bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: reconnect message 0e222cc8-6b11-4567-a76f-f7a7aed00444
[92mINFO [0m:      Disconnect and shut down
🚀 Starting NASA FL Client: client_2
Algorithm: FEDAVG
Server: localhost:8686
K-Folds: 5
Log Directory: logs
🔄 Using device: cuda
🎯 GPU: NVIDIA A100-SXM4-80GB
💾 Hyperparameters saved to: logs/client_2_hyperparams_20251030_014929.csv
🔍 Looking for data at: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.1/client_2
📊 Loaded 7847 total samples from /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.1/client_2
🔢 Original feature dimension: 24
🔍 Applying KernelPCA with 5 components, kernel=poly
📊 Data shape - Before: (4707, 24), After: (4707, 5)
🔄 Created sequences with length 10
   Final dataset shape: X (4697, 10, 5), y (4697,)
✅ Data split completed:
   Training samples: 4697
   Validation samples: 1560
   Test samples: 1560
   Model type: lstm
   Final input dimension: 5
✅ Client client_2 ready:
   Model: LSTM
   Training: 4697 samples
   Device: cuda
   Validation: 1560 samples
   Test: 1560 samples
   Algorithm: fedavg
   Total Rounds: 10
   Learning Rate: 0.001
   Batch Size: 32
   Logging to: logs

🧪 Round 0 Evaluation Results:
   Test Loss: 14486.7195
   RMSE: 120.3608, MAE: 96.6179, R²: -1.4433
💾 Test metrics saved to: logs/client_2_test_metrics_20251030_014929.csv
⏩ Skipping CV for Round 2 (runs every 5 rounds)
Round 2: train_loss=6404.1128, val_loss=6484.9048, val_r2=-0.0175
💾 Training metrics saved to: logs/client_2_training_metrics_20251030_014929.csv

🧪 Round 2 Evaluation Results:
   Test Loss: 6069.9814
   RMSE: 77.9101, MAE: 62.9323, R²: -0.0238
💾 Test metrics saved to: logs/client_2_test_metrics_20251030_014929.csv
⏩ Skipping CV for Round 3 (runs every 5 rounds)

🎯 Round 3 Training Results:
   Training - Loss: 6404.2925, RMSE: 80.0268, R²: -0.0142
   Validation - Loss: 6485.1055, RMSE: 80.5301, R²: -0.0176

🧪 Round 3 Evaluation Results:
   Test Loss: 6043.8148
   RMSE: 77.7420, MAE: 62.8810, R²: -0.0193
💾 Test metrics saved to: logs/client_2_test_metrics_20251030_014929.csv
⏩ Skipping CV for Round 4 (runs every 5 rounds)
Round 4: train_loss=6453.1660, val_loss=6539.0615, val_r2=-0.0260
💾 Training metrics saved to: logs/client_2_training_metrics_20251030_014929.csv

🧪 Round 4 Evaluation Results:
   Test Loss: 6041.1753
   RMSE: 77.7250, MAE: 62.8761, R²: -0.0189
💾 Test metrics saved to: logs/client_2_test_metrics_20251030_014929.csv

🔍 Running 3-fold cross-validation (Round 5)

🔍 Starting 3-fold cross-validation on TRAINING data for client client_2

📊 Fold 1/3
   Fold 1 Results:
     Val Loss: 6528.7744
     Val RMSE: 80.8008, Val R²: -0.0160

📊 Fold 2/3
   Fold 2 Results:
     Val Loss: 6492.0664
     Val RMSE: 80.5734, Val R²: -0.0150

📊 Fold 3/3
   Fold 3 Results:
     Val Loss: 6292.9678
     Val RMSE: 79.3282, Val R²: -0.0282
💾 CV metrics saved to: logs/client_2_cv_metrics_20251030_014929.csv

📈 3-Fold CV Summary (Training Data):
   VAL_LOSS: 6437.9362 ± 103.5978
   RMSE: 80.2341 ± 0.6473
   R2: -0.0197 ± 0.0060

🎯 Round 5 Training Results:
   Training - Loss: 6401.0581, RMSE: 80.0066, R²: -0.0137
   Validation - Loss: 6481.4897, RMSE: 80.5077, R²: -0.0170
💾 Training metrics saved to: logs/client_2_training_metrics_20251030_014929.csv

🧪 Round 5 Evaluation Results:
   Test Loss: 6011.7415
   RMSE: 77.5354, MAE: 62.8315, R²: -0.0139
💾 Test metrics saved to: logs/client_2_test_metrics_20251030_014929.csv
⏩ Skipping CV for Round 6 (runs every 5 rounds)

🎯 Round 6 Training Results:
   Training - Loss: 6392.6318, RMSE: 79.9539, R²: -0.0124
   Validation - Loss: 6472.0376, RMSE: 80.4490, R²: -0.0155
💾 Training metrics saved to: logs/client_2_training_metrics_20251030_014929.csv

🧪 Round 6 Evaluation Results:
   Test Loss: 6019.8346
   RMSE: 77.5876, MAE: 62.8426, R²: -0.0153
💾 Test metrics saved to: logs/client_2_test_metrics_20251030_014929.csv
⏩ Skipping CV for Round 7 (runs every 5 rounds)
Round 7: train_loss=6397.3506, val_loss=6477.3374, val_r2=-0.0164

🧪 Round 7 Evaluation Results:
   Test Loss: 5998.2791
   RMSE: 77.4486, MAE: 62.8143, R²: -0.0117
💾 Test metrics saved to: logs/client_2_test_metrics_20251030_014929.csv
⏩ Skipping CV for Round 8 (runs every 5 rounds)
Round 8: train_loss=6385.9883, val_loss=6464.5439, val_r2=-0.0144
💾 Training metrics saved to: logs/client_2_training_metrics_20251030_014929.csv

🧪 Round 8 Evaluation Results:
   Test Loss: 6002.7558
   RMSE: 77.4775, MAE: 62.8187, R²: -0.0124
💾 Test metrics saved to: logs/client_2_test_metrics_20251030_014929.csv

🔍 Running 3-fold cross-validation (Round 9)
💾 CV metrics saved to: logs/client_2_cv_metrics_20251030_014929.csv

🎯 Round 9 Training Results:
   Training - Loss: 6364.6665, RMSE: 79.7789, R²: -0.0080
   Validation - Loss: 6440.1899, RMSE: 80.2508, R²: -0.0105
💾 Training metrics saved to: logs/client_2_training_metrics_20251030_014929.csv

🧪 Round 9 Evaluation Results:
   Test Loss: 6007.9889
   RMSE: 77.5112, MAE: 62.8261, R²: -0.0133
💾 Test metrics saved to: logs/client_2_test_metrics_20251030_014929.csv

🔍 Running 3-fold cross-validation (Round 10)
💾 CV metrics saved to: logs/client_2_cv_metrics_20251030_014929.csv

🎯 Round 10 Training Results:
   Training - Loss: 6374.9741, RMSE: 79.8434, R²: -0.0096
   Validation - Loss: 6452.0308, RMSE: 80.3245, R²: -0.0124
💾 Training metrics saved to: logs/client_2_training_metrics_20251030_014929.csv

🧪 Round 10 Evaluation Results:
   Test Loss: 6002.5285
   RMSE: 77.4760, MAE: 62.8185, R²: -0.0124
💾 Test metrics saved to: logs/client_2_test_metrics_20251030_014929.csv

================================================================================
🎯 FINAL COMPREHENSIVE REPORT
================================================================================
💾 Final summary saved to: logs/client_2_final_summary_20251030_014929.csv

📊 CLIENT: client_2 | ALGORITHM: fedavg | MODEL: LSTM
📈 TOTAL ROUNDS: 10

⚙️  HYPERPARAMETERS:
   Learning Rate: 0.001
   Batch Size: 32
   Local Epochs: 1
   Hidden Dim: 64
   Num Layers: 2
   Sequence Length: 10
   Use Attention: False
   Dropout: 0.3
   Optimizer: adam

🏁 FINAL ROUND PERFORMANCE:
   Training   - Loss:  6374.97 | RMSE:  79.84 | R²: -0.0096
   Validation - Loss:  6452.03 | RMSE:  80.32 | R²: -0.0124
   Test       - Loss:  6002.53 | RMSE:  77.48 | R²: -0.0124

📊 STATISTICS ACROSS ALL ROUNDS (Mean ± Std):
   Training Loss:    6396.66 ±  26.44
   Validation Loss:  6476.32 ±  29.49
   Test Loss:        6868.48 ± 2539.51

   Training RMSE:    79.98 ±  0.17
   Validation RMSE:  80.48 ±  0.18
   Test RMSE:        81.88 ± 12.83

   Training R²:     -0.0130 ± 0.0042
   Validation R²:   -0.0162 ± 0.0046
   Test R²:         -0.1584 ± 0.4283

⭐ BEST PERFORMANCE:
   Best Round: 7 (Test R²: -0.0117)

📋 DATA SUMMARY:
   Training samples:   4697
   Validation samples: 1560
   Test samples:       1560
   Total samples:      7817
================================================================================
✅ Client client_2 completed | Algorithm: FEDAVG
