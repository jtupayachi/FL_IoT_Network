[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0d7b497f-e9bd-42b0-b33c-fc2b9585247b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 89628fbe-ce16-459d-91e8-e7e9041097e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 77902be1-56d1-476c-bd19-ca83ac2b242a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d747fe9c-2493-4a4d-9ecc-0bca1ba77630
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 000f6b44-d28b-4a41-85d6-4a57d40ea1c4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7c0b736f-f33b-42a9-94c1-15894a7a863c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d4cd968b-fb63-4dfc-97d6-829a20e621ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 791e0bb2-efe9-4df2-a679-062705b73a36
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 10bf1e61-8bd9-4d0f-b9e9-958024bc6640
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7d09645d-a591-43df-ad37-0c4bbe10518b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5808a216-ad8f-4ff5-8571-ed0d132ea820
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 013c83cc-c097-4713-ad57-251b440a2692
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 82d74853-89b6-4863-97d4-9e91e2333474
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a4ec9e88-7a4d-4600-8614-bad830fe3700
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bb993929-723b-46c7-af54-dbb5c9d29fd3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a9cf2158-dd54-43b3-9247-b03242d3a8a7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c6a62ccf-4a51-4677-92b9-cbd26122ab08
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9618b8a3-0eaf-4502-875e-572e5a795c17
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4e6c3abe-4552-45ea-857d-10d02717ca4a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: reconnect message 59a922c9-bc51-42d1-8588-122fadcb7298
[92mINFO [0m:      Disconnect and shut down
🚀 Starting NASA FL Client: client_14
Algorithm: FEDAVG
Server: localhost:8686
K-Folds: 5
Log Directory: logs
🔄 Using device: cuda
🎯 GPU: NVIDIA A100-SXM4-80GB
💾 Hyperparameters saved to: logs/client_14_hyperparams_20251030_015841.csv
🔍 Looking for data at: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.1/client_14
📊 Loaded 6057 total samples from /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.1/client_14
🔢 Original feature dimension: 24
🔍 Applying KernelPCA with 5 components, kernel=poly
📊 Data shape - Before: (3633, 24), After: (3633, 5)
🔄 Created sequences with length 10
   Final dataset shape: X (3623, 10, 5), y (3623,)
✅ Data split completed:
   Training samples: 3623
   Validation samples: 1202
   Test samples: 1202
   Model type: lstm
   Final input dimension: 5
✅ Client client_14 ready:
   Model: LSTM
   Training: 3623 samples
   Device: cuda
   Validation: 1202 samples
   Test: 1202 samples
   Algorithm: fedavg
   Total Rounds: 10
   Learning Rate: 0.001
   Batch Size: 32
   Logging to: logs

🧪 Round 0 Evaluation Results:
   Test Loss: 14985.8924
   RMSE: 122.4169, MAE: 87.6448, R²: -0.6778
💾 Test metrics saved to: logs/client_14_test_metrics_20251030_015841.csv
⏩ Skipping CV for Round 2 (runs every 5 rounds)
Round 2: train_loss=9785.0469, val_loss=9221.0205, val_r2=-0.0121
💾 Training metrics saved to: logs/client_14_training_metrics_20251030_015841.csv

🧪 Round 2 Evaluation Results:
   Test Loss: 8994.2588
   RMSE: 94.8381, MAE: 70.2524, R²: -0.0070
💾 Test metrics saved to: logs/client_14_test_metrics_20251030_015841.csv
⏩ Skipping CV for Round 3 (runs every 5 rounds)

🎯 Round 3 Training Results:
   Training - Loss: 9826.9219, RMSE: 99.1308, R²: -0.0131
   Validation - Loss: 9268.0918, RMSE: 96.2709, R²: -0.0173

🧪 Round 3 Evaluation Results:
   Test Loss: 9000.9598
   RMSE: 94.8734, MAE: 70.2380, R²: -0.0078
💾 Test metrics saved to: logs/client_14_test_metrics_20251030_015841.csv
⏩ Skipping CV for Round 4 (runs every 5 rounds)
Round 4: train_loss=9810.8301, val_loss=9250.1230, val_r2=-0.0153
💾 Training metrics saved to: logs/client_14_training_metrics_20251030_015841.csv

🧪 Round 4 Evaluation Results:
   Test Loss: 9003.8974
   RMSE: 94.8889, MAE: 70.2319, R²: -0.0081
💾 Test metrics saved to: logs/client_14_test_metrics_20251030_015841.csv

🔍 Running 3-fold cross-validation (Round 5)

🔍 Starting 3-fold cross-validation on TRAINING data for client client_14

📊 Fold 1/3
   Fold 1 Results:
     Val Loss: 10247.8232
     Val RMSE: 101.2315, Val R²: -0.0073

📊 Fold 2/3
   Fold 2 Results:
     Val Loss: 9753.0693
     Val RMSE: 98.7576, Val R²: -0.0066

📊 Fold 3/3
   Fold 3 Results:
     Val Loss: 9312.6270
     Val RMSE: 96.5020, Val R²: -0.0085
💾 CV metrics saved to: logs/client_14_cv_metrics_20251030_015841.csv

📈 3-Fold CV Summary (Training Data):
   VAL_LOSS: 9771.1732 ± 382.0068
   RMSE: 98.8304 ± 1.9315
   R2: -0.0075 ± 0.0008

🎯 Round 5 Training Results:
   Training - Loss: 9849.7646, RMSE: 99.2460, R²: -0.0155
   Validation - Loss: 9293.4053, RMSE: 96.4023, R²: -0.0201
💾 Training metrics saved to: logs/client_14_training_metrics_20251030_015841.csv

🧪 Round 5 Evaluation Results:
   Test Loss: 8991.9841
   RMSE: 94.8261, MAE: 70.2575, R²: -0.0068
💾 Test metrics saved to: logs/client_14_test_metrics_20251030_015841.csv
⏩ Skipping CV for Round 6 (runs every 5 rounds)

🎯 Round 6 Training Results:
   Training - Loss: 9824.0996, RMSE: 99.1166, R²: -0.0128
   Validation - Loss: 9264.9492, RMSE: 96.2546, R²: -0.0169
💾 Training metrics saved to: logs/client_14_training_metrics_20251030_015841.csv

🧪 Round 6 Evaluation Results:
   Test Loss: 8977.2662
   RMSE: 94.7484, MAE: 70.3045, R²: -0.0051
💾 Test metrics saved to: logs/client_14_test_metrics_20251030_015841.csv
⏩ Skipping CV for Round 7 (runs every 5 rounds)
Round 7: train_loss=9912.1523, val_loss=9361.7129, val_r2=-0.0276

🧪 Round 7 Evaluation Results:
   Test Loss: 8973.5654
   RMSE: 94.7289, MAE: 70.3194, R²: -0.0047
💾 Test metrics saved to: logs/client_14_test_metrics_20251030_015841.csv
⏩ Skipping CV for Round 8 (runs every 5 rounds)
Round 8: train_loss=9844.1484, val_loss=9287.1992, val_r2=-0.0194
💾 Training metrics saved to: logs/client_14_training_metrics_20251030_015841.csv

🧪 Round 8 Evaluation Results:
   Test Loss: 8964.0880
   RMSE: 94.6789, MAE: 70.3614, R²: -0.0036
💾 Test metrics saved to: logs/client_14_test_metrics_20251030_015841.csv

🔍 Running 3-fold cross-validation (Round 9)
💾 CV metrics saved to: logs/client_14_cv_metrics_20251030_015841.csv

🎯 Round 9 Training Results:
   Training - Loss: 9894.6240, RMSE: 99.4717, R²: -0.0201
   Validation - Loss: 9342.6211, RMSE: 96.6572, R²: -0.0255
💾 Training metrics saved to: logs/client_14_training_metrics_20251030_015841.csv

🧪 Round 9 Evaluation Results:
   Test Loss: 8972.3062
   RMSE: 94.7223, MAE: 70.3247, R²: -0.0046
💾 Test metrics saved to: logs/client_14_test_metrics_20251030_015841.csv

🔍 Running 3-fold cross-validation (Round 10)
💾 CV metrics saved to: logs/client_14_cv_metrics_20251030_015841.csv

🎯 Round 10 Training Results:
   Training - Loss: 9868.4961, RMSE: 99.3403, R²: -0.0174
   Validation - Loss: 9314.0244, RMSE: 96.5092, R²: -0.0223
💾 Training metrics saved to: logs/client_14_training_metrics_20251030_015841.csv

🧪 Round 10 Evaluation Results:
   Test Loss: 8968.3304
   RMSE: 94.7013, MAE: 70.3417, R²: -0.0041
💾 Test metrics saved to: logs/client_14_test_metrics_20251030_015841.csv

================================================================================
🎯 FINAL COMPREHENSIVE REPORT
================================================================================
💾 Final summary saved to: logs/client_14_final_summary_20251030_015841.csv

📊 CLIENT: client_14 | ALGORITHM: fedavg | MODEL: LSTM
📈 TOTAL ROUNDS: 10

⚙️  HYPERPARAMETERS:
   Learning Rate: 0.001
   Batch Size: 32
   Local Epochs: 1
   Hidden Dim: 64
   Num Layers: 2
   Sequence Length: 10
   Use Attention: False
   Dropout: 0.3
   Optimizer: adam

🏁 FINAL ROUND PERFORMANCE:
   Training   - Loss:  9868.50 | RMSE:  99.34 | R²: -0.0174
   Validation - Loss:  9314.02 | RMSE:  96.51 | R²: -0.0223
   Test       - Loss:  8968.33 | RMSE:  94.70 | R²: -0.0041

📊 STATISTICS ACROSS ALL ROUNDS (Mean ± Std):
   Training Loss:    9839.57 ±  33.87
   Validation Loss:  9281.91 ±  37.57
   Test Loss:        9583.25 ± 1800.93

   Training RMSE:    99.19 ±  0.17
   Validation RMSE:  96.34 ±  0.20
   Test RMSE:        97.54 ±  8.29

   Training R²:     -0.0144 ± 0.0035
   Validation R²:   -0.0188 ± 0.0041
   Test R²:         -0.0730 ± 0.2016

⭐ BEST PERFORMANCE:
   Best Round: 8 (Test R²: -0.0036)

📋 DATA SUMMARY:
   Training samples:   3623
   Validation samples: 1202
   Test samples:       1202
   Total samples:      6027
================================================================================
✅ Client client_14 completed | Algorithm: FEDAVG
