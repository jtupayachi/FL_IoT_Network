[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c899fa31-440e-45e0-97c3-179360577415
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9873d412-5a06-419f-a8f0-224f49869406
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3907f820-18da-4055-80fa-747a5fc1c729
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 64adeb5f-1048-4a27-94c2-5aa260a8c2c4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4d64c86f-008d-4fe4-8446-c0daad5f0c71
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f4bd1865-587f-4909-a7e7-21f8eb53302f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 31d5706f-4f4a-4a1b-8dd4-82f1daa39cdb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5731b824-b987-4d53-873c-b2a1e2b94f64
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 086d94e8-f639-494c-b73e-fb3d24041b73
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 10fb6268-e2ca-4fe8-9205-99cf660ff3ea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2ffb797c-c813-4e27-9b1e-c49574a203a3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0be3ed93-0b42-415d-96f0-581255121888
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7aacafca-131a-4978-bcf5-6ab3df5bced4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0479d842-52be-42c8-858d-664e480875e5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bc18b4eb-aabc-43c9-bb0c-e867bf0181d1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 82dca5e4-f8cf-49c9-80a2-640636cf0f41
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ea94c3ed-971c-4768-a1dc-4006477df71d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c20bcbdb-b771-41fc-9611-bae8afa3babc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 53677ca0-57ae-4253-99de-d9f182828bb7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 09b551a9-b1d2-4fff-be6d-81ef64d3272d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: reconnect message c5ab4024-b98b-4e5f-b833-da2aa9fcc092
[92mINFO [0m:      Disconnect and shut down
ğŸš€ Starting NASA FL Client: client_21
Algorithm: FEDAVG
Server: localhost:8686
K-Folds: 5
Log Directory: logs
ğŸ”„ Using device: cuda
ğŸ¯ GPU: NVIDIA A100-SXM4-80GB
ğŸ’¾ Hyperparameters saved to: logs/client_21_hyperparams_20251030_015855.csv
ğŸ” Looking for data at: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.1/client_21
ğŸ“Š Loaded 6210 total samples from /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.1/client_21
ğŸ”¢ Original feature dimension: 24
ğŸ” Applying KernelPCA with 5 components, kernel=poly
ğŸ“Š Data shape - Before: (3726, 24), After: (3726, 5)
ğŸ”„ Created sequences with length 10
   Final dataset shape: X (3716, 10, 5), y (3716,)
âœ… Data split completed:
   Training samples: 3716
   Validation samples: 1232
   Test samples: 1232
   Model type: lstm
   Final input dimension: 5
âœ… Client client_21 ready:
   Model: LSTM
   Training: 3716 samples
   Device: cuda
   Validation: 1232 samples
   Test: 1232 samples
   Algorithm: fedavg
   Total Rounds: 10
   Learning Rate: 0.001
   Batch Size: 32
   Logging to: logs
â© Skipping CV for Round 1 (runs every 5 rounds)
Round 1: train_loss=10359.1279, val_loss=10148.4053, val_r2=-0.8042

ğŸ§ª Round 1 Evaluation Results:
   Test Loss: 10973.9129
   RMSE: 104.7564, MAE: 82.2962, RÂ²: -0.9558
ğŸ’¾ Test metrics saved to: logs/client_21_test_metrics_20251030_015855.csv
â© Skipping CV for Round 2 (runs every 5 rounds)
Round 2: train_loss=6048.6919, val_loss=5822.8379, val_r2=-0.0352
ğŸ’¾ Training metrics saved to: logs/client_21_training_metrics_20251030_015855.csv

ğŸ§ª Round 2 Evaluation Results:
   Test Loss: 5622.0003
   RMSE: 74.9800, MAE: 62.1635, RÂ²: -0.0020
ğŸ’¾ Test metrics saved to: logs/client_21_test_metrics_20251030_015855.csv
â© Skipping CV for Round 3 (runs every 5 rounds)

ğŸ¯ Round 3 Training Results:
   Training - Loss: 6022.8892, RMSE: 77.6073, RÂ²: -0.0287
   Validation - Loss: 5796.7622, RMSE: 76.1365, RÂ²: -0.0305

ğŸ§ª Round 3 Evaluation Results:
   Test Loss: 5624.9239
   RMSE: 74.9995, MAE: 62.1474, RÂ²: -0.0025
ğŸ’¾ Test metrics saved to: logs/client_21_test_metrics_20251030_015855.csv
â© Skipping CV for Round 4 (runs every 5 rounds)
Round 4: train_loss=6062.8975, val_loss=5837.1860, val_r2=-0.0377
ğŸ’¾ Training metrics saved to: logs/client_21_training_metrics_20251030_015855.csv

ğŸ§ª Round 4 Evaluation Results:
   Test Loss: 5626.2634
   RMSE: 75.0084, MAE: 62.1406, RÂ²: -0.0027
ğŸ’¾ Test metrics saved to: logs/client_21_test_metrics_20251030_015855.csv

ğŸ” Running 3-fold cross-validation (Round 5)

ğŸ” Starting 3-fold cross-validation on TRAINING data for client client_21

ğŸ“Š Fold 1/3
   Fold 1 Results:
     Val Loss: 5968.6338
     Val RMSE: 77.2569, Val RÂ²: -0.0119

ğŸ“Š Fold 2/3
   Fold 2 Results:
     Val Loss: 5867.4624
     Val RMSE: 76.5994, Val RÂ²: -0.0137

ğŸ“Š Fold 3/3
   Fold 3 Results:
     Val Loss: 6065.0732
     Val RMSE: 77.8786, Val RÂ²: -0.0326
ğŸ’¾ CV metrics saved to: logs/client_21_cv_metrics_20251030_015855.csv

ğŸ“ˆ 3-Fold CV Summary (Training Data):
   VAL_LOSS: 5967.0565 Â± 80.6820
   RMSE: 77.2450 Â± 0.5223
   R2: -0.0194 Â± 0.0094

ğŸ¯ Round 5 Training Results:
   Training - Loss: 6002.3560, RMSE: 77.4749, RÂ²: -0.0252
   Validation - Loss: 5775.9966, RMSE: 76.0000, RÂ²: -0.0269
ğŸ’¾ Training metrics saved to: logs/client_21_training_metrics_20251030_015855.csv

ğŸ§ª Round 5 Evaluation Results:
   Test Loss: 5621.0534
   RMSE: 74.9737, MAE: 62.1691, RÂ²: -0.0018
ğŸ’¾ Test metrics saved to: logs/client_21_test_metrics_20251030_015855.csv
â© Skipping CV for Round 6 (runs every 5 rounds)

ğŸ¯ Round 6 Training Results:
   Training - Loss: 5973.5698, RMSE: 77.2889, RÂ²: -0.0203
   Validation - Loss: 5746.8550, RMSE: 75.8080, RÂ²: -0.0217
ğŸ’¾ Training metrics saved to: logs/client_21_training_metrics_20251030_015855.csv

ğŸ§ª Round 6 Evaluation Results:
   Test Loss: 5615.6125
   RMSE: 74.9374, MAE: 62.2135, RÂ²: -0.0008
ğŸ’¾ Test metrics saved to: logs/client_21_test_metrics_20251030_015855.csv
â© Skipping CV for Round 7 (runs every 5 rounds)
Round 7: train_loss=6017.6182, val_loss=5791.4341, val_r2=-0.0296

ğŸ§ª Round 7 Evaluation Results:
   Test Loss: 5614.4727
   RMSE: 74.9298, MAE: 62.2285, RÂ²: -0.0006
ğŸ’¾ Test metrics saved to: logs/client_21_test_metrics_20251030_015855.csv
â© Skipping CV for Round 8 (runs every 5 rounds)
Round 8: train_loss=6012.4585, val_loss=5786.2153, val_r2=-0.0287
ğŸ’¾ Training metrics saved to: logs/client_21_training_metrics_20251030_015855.csv

ğŸ§ª Round 8 Evaluation Results:
   Test Loss: 5612.1239
   RMSE: 74.9141, MAE: 62.2708, RÂ²: -0.0002
ğŸ’¾ Test metrics saved to: logs/client_21_test_metrics_20251030_015855.csv

ğŸ” Running 3-fold cross-validation (Round 9)
ğŸ’¾ CV metrics saved to: logs/client_21_cv_metrics_20251030_015855.csv

ğŸ¯ Round 9 Training Results:
   Training - Loss: 5934.7974, RMSE: 77.0376, RÂ²: -0.0137
   Validation - Loss: 5707.5269, RMSE: 75.5482, RÂ²: -0.0147
ğŸ’¾ Training metrics saved to: logs/client_21_training_metrics_20251030_015855.csv

ğŸ§ª Round 9 Evaluation Results:
   Test Loss: 5614.1104
   RMSE: 74.9274, MAE: 62.2338, RÂ²: -0.0006
ğŸ’¾ Test metrics saved to: logs/client_21_test_metrics_20251030_015855.csv

ğŸ” Running 3-fold cross-validation (Round 10)
ğŸ’¾ CV metrics saved to: logs/client_21_cv_metrics_20251030_015855.csv

ğŸ¯ Round 10 Training Results:
   Training - Loss: 6001.4458, RMSE: 77.4690, RÂ²: -0.0250
   Validation - Loss: 5775.0762, RMSE: 75.9939, RÂ²: -0.0267
ğŸ’¾ Training metrics saved to: logs/client_21_training_metrics_20251030_015855.csv

ğŸ§ª Round 10 Evaluation Results:
   Test Loss: 5613.0618
   RMSE: 74.9204, MAE: 62.2509, RÂ²: -0.0004
ğŸ’¾ Test metrics saved to: logs/client_21_test_metrics_20251030_015855.csv

================================================================================
ğŸ¯ FINAL COMPREHENSIVE REPORT
================================================================================
ğŸ’¾ Final summary saved to: logs/client_21_final_summary_20251030_015855.csv

ğŸ“Š CLIENT: client_21 | ALGORITHM: fedavg | MODEL: LSTM
ğŸ“ˆ TOTAL ROUNDS: 10

âš™ï¸  HYPERPARAMETERS:
   Learning Rate: 0.001
   Batch Size: 32
   Local Epochs: 1
   Hidden Dim: 64
   Num Layers: 2
   Sequence Length: 10
   Use Attention: False
   Dropout: 0.3
   Optimizer: adam

ğŸ FINAL ROUND PERFORMANCE:
   Training   - Loss:  6001.45 | RMSE:  77.47 | RÂ²: -0.0250
   Validation - Loss:  5775.08 | RMSE:  75.99 | RÂ²: -0.0267
   Test       - Loss:  5613.06 | RMSE:  74.92 | RÂ²: -0.0004

ğŸ“Š STATISTICS ACROSS ALL ROUNDS (Mean Â± Std):
   Training Loss:    6005.17 Â±  40.09
   Validation Loss:  5778.81 Â±  40.58
   Test Loss:        6153.75 Â± 1606.73

   Training RMSE:    77.49 Â±  0.26
   Validation RMSE:  76.02 Â±  0.27
   Test RMSE:        77.93 Â±  8.94

   Training RÂ²:     -0.0257 Â± 0.0068
   Validation RÂ²:   -0.0274 Â± 0.0072
   Test RÂ²:         -0.0968 Â± 0.2864

â­ BEST PERFORMANCE:
   Best Round: 8 (Test RÂ²: -0.0002)

ğŸ“‹ DATA SUMMARY:
   Training samples:   3716
   Validation samples: 1232
   Test samples:       1232
   Total samples:      6180
================================================================================
âœ… Client client_21 completed | Algorithm: FEDAVG
