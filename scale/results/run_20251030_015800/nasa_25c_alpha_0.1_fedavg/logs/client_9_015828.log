[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 970f38de-cb0e-4bbb-968a-310e1828c69d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c8cfb966-d1fd-447d-981d-506f411a6678
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7b90142c-dd91-4786-af74-be414c51163b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fa3140c2-1998-4c33-b52f-f9ca040cb2bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c0321d32-6c04-4e67-81d8-acd6f621d44c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7cca15c6-1c82-4865-810f-84be46116f83
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ff4d53af-02ef-4f70-817e-6467b6cb1460
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c3433861-63ce-4837-82eb-2a4d0dc77f54
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0fdb7f48-683c-4a83-b6fe-ea26473351a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fb4c16f1-6b6e-45db-a43b-7a23b49e362b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f43bf14a-2118-4246-92e7-36c1800eecf1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 75e398ac-5c74-44c0-b27d-9d8fae9433ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c67a2021-bb17-459e-b0d0-9f5f75f6b3b6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message daf6cf82-b626-4e00-a411-20a053037b83
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b6167c91-3307-4d4a-b402-0de3ca475738
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ce692f29-233a-4459-8e6c-45957af589b9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 03e5bac8-9629-42c5-bb0f-fe587917ccb4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4bb7bdc4-b68b-4aca-9a8e-ee3859ce165c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 27dcab77-668a-4138-af57-44accb7fcdd6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: reconnect message 31a9eeec-f082-45ea-a2a5-ea66bd05ce1b
[92mINFO [0m:      Disconnect and shut down
🚀 Starting NASA FL Client: client_9
Algorithm: FEDAVG
Server: localhost:8686
K-Folds: 5
Log Directory: logs
🔄 Using device: cuda
🎯 GPU: NVIDIA A100-SXM4-80GB
💾 Hyperparameters saved to: logs/client_9_hyperparams_20251030_015831.csv
🔍 Looking for data at: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.1/client_9
📊 Loaded 6423 total samples from /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.1/client_9
🔢 Original feature dimension: 24
🔍 Applying KernelPCA with 5 components, kernel=poly
📊 Data shape - Before: (3853, 24), After: (3853, 5)
🔄 Created sequences with length 10
   Final dataset shape: X (3843, 10, 5), y (3843,)
✅ Data split completed:
   Training samples: 3843
   Validation samples: 1275
   Test samples: 1275
   Model type: lstm
   Final input dimension: 5
✅ Client client_9 ready:
   Model: LSTM
   Training: 3843 samples
   Device: cuda
   Validation: 1275 samples
   Test: 1275 samples
   Algorithm: fedavg
   Total Rounds: 10
   Learning Rate: 0.001
   Batch Size: 32
   Logging to: logs

🧪 Round 0 Evaluation Results:
   Test Loss: 13036.0320
   RMSE: 114.1754, MAE: 90.1068, R²: -1.0335
💾 Test metrics saved to: logs/client_9_test_metrics_20251030_015831.csv
⏩ Skipping CV for Round 2 (runs every 5 rounds)
Round 2: train_loss=6295.3931, val_loss=6217.7905, val_r2=-0.0093
💾 Training metrics saved to: logs/client_9_training_metrics_20251030_015831.csv

🧪 Round 2 Evaluation Results:
   Test Loss: 6542.9088
   RMSE: 80.8883, MAE: 66.0553, R²: -0.0206
💾 Test metrics saved to: logs/client_9_test_metrics_20251030_015831.csv
⏩ Skipping CV for Round 3 (runs every 5 rounds)

🎯 Round 3 Training Results:
   Training - Loss: 6294.2407, RMSE: 79.3363, R²: -0.0041
   Validation - Loss: 6216.1011, RMSE: 78.8423, R²: -0.0090

🧪 Round 3 Evaluation Results:
   Test Loss: 6552.5706
   RMSE: 80.9479, MAE: 66.0686, R²: -0.0221
💾 Test metrics saved to: logs/client_9_test_metrics_20251030_015831.csv
⏩ Skipping CV for Round 4 (runs every 5 rounds)
Round 4: train_loss=6291.9976, val_loss=6212.7744, val_r2=-0.0085
💾 Training metrics saved to: logs/client_9_training_metrics_20251030_015831.csv

🧪 Round 4 Evaluation Results:
   Test Loss: 6556.7610
   RMSE: 80.9738, MAE: 66.0742, R²: -0.0228
💾 Test metrics saved to: logs/client_9_test_metrics_20251030_015831.csv

🔍 Running 3-fold cross-validation (Round 5)

🔍 Starting 3-fold cross-validation on TRAINING data for client client_9

📊 Fold 1/3
   Fold 1 Results:
     Val Loss: 6366.9824
     Val RMSE: 79.7934, Val R²: -0.0026

📊 Fold 2/3
   Fold 2 Results:
     Val Loss: 6386.1797
     Val RMSE: 79.9136, Val R²: -0.0159

📊 Fold 3/3
   Fold 3 Results:
     Val Loss: 6205.9771
     Val RMSE: 78.7780, Val R²: -0.0064
💾 CV metrics saved to: logs/client_9_cv_metrics_20251030_015831.csv

📈 3-Fold CV Summary (Training Data):
   VAL_LOSS: 6319.7131 ± 80.8045
   RMSE: 79.4950 ± 0.5093
   R2: -0.0083 ± 0.0056

🎯 Round 5 Training Results:
   Training - Loss: 6287.0566, RMSE: 79.2910, R²: -0.0029
   Validation - Loss: 6205.2471, RMSE: 78.7734, R²: -0.0073
💾 Training metrics saved to: logs/client_9_training_metrics_20251030_015831.csv

🧪 Round 5 Evaluation Results:
   Test Loss: 6539.5932
   RMSE: 80.8677, MAE: 66.0506, R²: -0.0201
💾 Test metrics saved to: logs/client_9_test_metrics_20251030_015831.csv
⏩ Skipping CV for Round 6 (runs every 5 rounds)

🎯 Round 6 Training Results:
   Training - Loss: 6292.4683, RMSE: 79.3251, R²: -0.0038
   Validation - Loss: 6213.4756, RMSE: 78.8256, R²: -0.0086
💾 Training metrics saved to: logs/client_9_training_metrics_20251030_015831.csv

🧪 Round 6 Evaluation Results:
   Test Loss: 6517.6021
   RMSE: 80.7317, MAE: 66.0243, R²: -0.0167
💾 Test metrics saved to: logs/client_9_test_metrics_20251030_015831.csv
⏩ Skipping CV for Round 7 (runs every 5 rounds)
Round 7: train_loss=6307.9946, val_loss=6235.6533, val_r2=-0.0122

🧪 Round 7 Evaluation Results:
   Test Loss: 6511.8940
   RMSE: 80.6963, MAE: 66.0215, R²: -0.0158
💾 Test metrics saved to: logs/client_9_test_metrics_20251030_015831.csv
⏩ Skipping CV for Round 8 (runs every 5 rounds)
Round 8: train_loss=6278.7930, val_loss=6191.7036, val_r2=-0.0051
💾 Training metrics saved to: logs/client_9_training_metrics_20251030_015831.csv

🧪 Round 8 Evaluation Results:
   Test Loss: 6496.8278
   RMSE: 80.6029, MAE: 66.0137, R²: -0.0134
💾 Test metrics saved to: logs/client_9_test_metrics_20251030_015831.csv

🔍 Running 3-fold cross-validation (Round 9)
💾 CV metrics saved to: logs/client_9_cv_metrics_20251030_015831.csv

🎯 Round 9 Training Results:
   Training - Loss: 6282.8999, RMSE: 79.2647, R²: -0.0023
   Validation - Loss: 6198.6279, RMSE: 78.7314, R²: -0.0062
💾 Training metrics saved to: logs/client_9_training_metrics_20251030_015831.csv

🧪 Round 9 Evaluation Results:
   Test Loss: 6509.9318
   RMSE: 80.6841, MAE: 66.0205, R²: -0.0155
💾 Test metrics saved to: logs/client_9_test_metrics_20251030_015831.csv

🔍 Running 3-fold cross-validation (Round 10)
💾 CV metrics saved to: logs/client_9_cv_metrics_20251030_015831.csv

🎯 Round 10 Training Results:
   Training - Loss: 6278.0698, RMSE: 79.2343, R²: -0.0015
   Validation - Loss: 6190.4282, RMSE: 78.6793, R²: -0.0048
💾 Training metrics saved to: logs/client_9_training_metrics_20251030_015831.csv

🧪 Round 10 Evaluation Results:
   Test Loss: 6503.6609
   RMSE: 80.6453, MAE: 66.0172, R²: -0.0145
💾 Test metrics saved to: logs/client_9_test_metrics_20251030_015831.csv

================================================================================
🎯 FINAL COMPREHENSIVE REPORT
================================================================================
💾 Final summary saved to: logs/client_9_final_summary_20251030_015831.csv

📊 CLIENT: client_9 | ALGORITHM: fedavg | MODEL: LSTM
📈 TOTAL ROUNDS: 10

⚙️  HYPERPARAMETERS:
   Learning Rate: 0.001
   Batch Size: 32
   Local Epochs: 1
   Hidden Dim: 64
   Num Layers: 2
   Sequence Length: 10
   Use Attention: False
   Dropout: 0.3
   Optimizer: adam

🏁 FINAL ROUND PERFORMANCE:
   Training   - Loss:  6278.07 | RMSE:  79.23 | R²: -0.0015
   Validation - Loss:  6190.43 | RMSE:  78.68 | R²: -0.0048
   Test       - Loss:  6503.66 | RMSE:  80.65 | R²: -0.0145

📊 STATISTICS ACROSS ALL ROUNDS (Mean ± Std):
   Training Loss:    6286.67 ±   6.42
   Validation Loss:  6204.29 ±  10.16
   Test Loss:        7176.78 ± 1953.19

   Training RMSE:    79.29 ±  0.04
   Validation RMSE:  78.77 ±  0.06
   Test RMSE:        84.12 ± 10.02

   Training R²:     -0.0029 ± 0.0010
   Validation R²:   -0.0071 ± 0.0016
   Test R²:         -0.1195 ± 0.3047

⭐ BEST PERFORMANCE:
   Best Round: 8 (Test R²: -0.0134)

📋 DATA SUMMARY:
   Training samples:   3843
   Validation samples: 1275
   Test samples:       1275
   Total samples:      6393
================================================================================
✅ Client client_9 completed | Algorithm: FEDAVG
