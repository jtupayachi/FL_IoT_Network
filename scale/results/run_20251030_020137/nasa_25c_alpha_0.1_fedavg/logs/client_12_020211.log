[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 026ada66-b4c8-4388-9b62-46a3d064c8e5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 16f74ed7-5efd-45f4-bcd8-e17f02a9ca3a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 18d0191c-ac8a-4837-a883-5d96dfaaeb8a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 11344c83-06b7-4137-90a7-47773a987f68
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6b65d708-5fa8-452b-ba3e-23841e69b452
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2740916e-aef2-45c9-b578-c284f89bae69
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bfa628e1-4ecb-4bfc-a291-c9236fb51b5e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e8e72a8a-399b-42c9-8446-a9c5dbd7001c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8ee2f8dc-2672-4177-91db-14777a10409d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 47f1fdce-3659-4be2-88b5-9186c64a8514
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6c88acdd-9e91-42ae-893f-57fd6447c89f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bbcb132d-70ef-463e-8c27-484cc68291ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ac8a09e9-e93a-4cdf-819f-17ee9adbd5b6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3e254807-13bc-4560-9baa-b9a6dd56bba5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 04184d78-b2c3-4fa0-add7-b79361672b15
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 70d9524f-e920-4106-8d88-26a15139241d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c1c4e51b-ca61-4080-a152-a4175ff43514
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 64c388bb-0b57-4e23-bacc-196f617e02fb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 580dbbfc-82be-4849-adb5-ab4cd5cba37d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7778b21e-c64b-4457-9d23-a5b2e5d66878
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: reconnect message 652d28be-45b6-4e0c-8ada-a25511defcbe
[92mINFO [0m:      Disconnect and shut down
ğŸš€ Starting NASA FL Client: client_12
Algorithm: FEDAVG
Server: localhost:8686
K-Folds: 5
Log Directory: logs
ğŸ”„ Using device: cuda
ğŸ¯ GPU: NVIDIA A100-SXM4-80GB
ğŸ’¾ Hyperparameters saved to: logs/client_12_hyperparams_20251030_020214.csv
ğŸ” Looking for data at: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.1/client_12
ğŸ“Š Loaded 6688 total samples from /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.1/client_12
ğŸ”¢ Original feature dimension: 24
ğŸ” Applying KernelPCA with 5 components, kernel=poly
ğŸ“Š Data shape - Before: (4012, 24), After: (4012, 5)
ğŸ”„ Created sequences with length 10
   Final dataset shape: X (4002, 10, 5), y (4002,)
âœ… Data split completed:
   Training samples: 4002
   Validation samples: 1328
   Test samples: 1328
   Model type: lstm
   Final input dimension: 5
âœ… Client client_12 ready:
   Model: LSTM
   Training: 4002 samples
   Device: cuda
   Validation: 1328 samples
   Test: 1328 samples
   Algorithm: fedavg
   Total Rounds: 10
   Learning Rate: 0.001
   Batch Size: 32
   Logging to: logs
â© Skipping CV for Round 1 (runs every 5 rounds)
Round 1: train_loss=10225.6182, val_loss=10437.4150, val_r2=-0.7031

ğŸ§ª Round 1 Evaluation Results:
   Test Loss: 12292.0627
   RMSE: 110.8696, MAE: 86.0129, RÂ²: -0.9302
ğŸ’¾ Test metrics saved to: logs/client_12_test_metrics_20251030_020214.csv
â© Skipping CV for Round 2 (runs every 5 rounds)
Round 2: train_loss=6000.5410, val_loss=6196.5493, val_r2=-0.0111
ğŸ’¾ Training metrics saved to: logs/client_12_training_metrics_20251030_020214.csv

ğŸ§ª Round 2 Evaluation Results:
   Test Loss: 6436.8607
   RMSE: 80.2300, MAE: 65.2659, RÂ²: -0.0108
ğŸ’¾ Test metrics saved to: logs/client_12_test_metrics_20251030_020214.csv
â© Skipping CV for Round 3 (runs every 5 rounds)

ğŸ¯ Round 3 Training Results:
   Training - Loss: 5995.9688, RMSE: 77.4336, RÂ²: -0.0103
   Validation - Loss: 6191.8994, RMSE: 78.6886, RÂ²: -0.0103

ğŸ§ª Round 3 Evaluation Results:
   Test Loss: 6418.0046
   RMSE: 80.1124, MAE: 65.2561, RÂ²: -0.0078
ğŸ’¾ Test metrics saved to: logs/client_12_test_metrics_20251030_020214.csv
â© Skipping CV for Round 4 (runs every 5 rounds)
Round 4: train_loss=5974.2671, val_loss=6169.7749, val_r2=-0.0067
ğŸ’¾ Training metrics saved to: logs/client_12_training_metrics_20251030_020214.csv

ğŸ§ª Round 4 Evaluation Results:
   Test Loss: 6414.5898
   RMSE: 80.0911, MAE: 65.2568, RÂ²: -0.0073
ğŸ’¾ Test metrics saved to: logs/client_12_test_metrics_20251030_020214.csv

ğŸ” Running 3-fold cross-validation (Round 5)

ğŸ” Starting 3-fold cross-validation on TRAINING data for client client_12

ğŸ“Š Fold 1/3
   Fold 1 Results:
     Val Loss: 5601.3081
     Val RMSE: 74.8419, Val RÂ²: -0.0000

ğŸ“Š Fold 2/3
   Fold 2 Results:
     Val Loss: 6168.6333
     Val RMSE: 78.5406, Val RÂ²: -0.0114

ğŸ“Š Fold 3/3
   Fold 3 Results:
     Val Loss: 6342.6709
     Val RMSE: 79.6409, Val RÂ²: -0.0432
ğŸ’¾ CV metrics saved to: logs/client_12_cv_metrics_20251030_020214.csv

ğŸ“ˆ 3-Fold CV Summary (Training Data):
   VAL_LOSS: 6037.5374 Â± 316.5378
   RMSE: 77.6745 Â± 2.0527
   R2: -0.0182 Â± 0.0183

ğŸ¯ Round 5 Training Results:
   Training - Loss: 5962.1260, RMSE: 77.2148, RÂ²: -0.0046
   Validation - Loss: 6157.3452, RMSE: 78.4688, RÂ²: -0.0047
ğŸ’¾ Training metrics saved to: logs/client_12_training_metrics_20251030_020214.csv

ğŸ§ª Round 5 Evaluation Results:
   Test Loss: 6408.3639
   RMSE: 80.0523, MAE: 65.2582, RÂ²: -0.0063
ğŸ’¾ Test metrics saved to: logs/client_12_test_metrics_20251030_020214.csv
â© Skipping CV for Round 6 (runs every 5 rounds)

ğŸ¯ Round 6 Training Results:
   Training - Loss: 5982.3169, RMSE: 77.3454, RÂ²: -0.0080
   Validation - Loss: 6177.9922, RMSE: 78.6002, RÂ²: -0.0081
ğŸ’¾ Training metrics saved to: logs/client_12_training_metrics_20251030_020214.csv

ğŸ§ª Round 6 Evaluation Results:
   Test Loss: 6409.6435
   RMSE: 80.0602, MAE: 65.2579, RÂ²: -0.0065
ğŸ’¾ Test metrics saved to: logs/client_12_test_metrics_20251030_020214.csv
â© Skipping CV for Round 7 (runs every 5 rounds)
Round 7: train_loss=6013.3813, val_loss=6209.5991, val_r2=-0.0132

ğŸ§ª Round 7 Evaluation Results:
   Test Loss: 6419.6613
   RMSE: 80.1228, MAE: 65.2568, RÂ²: -0.0081
ğŸ’¾ Test metrics saved to: logs/client_12_test_metrics_20251030_020214.csv
â© Skipping CV for Round 8 (runs every 5 rounds)
Round 8: train_loss=5959.4087, val_loss=6154.5527, val_r2=-0.0043
ğŸ’¾ Training metrics saved to: logs/client_12_training_metrics_20251030_020214.csv

ğŸ§ª Round 8 Evaluation Results:
   Test Loss: 6411.4696
   RMSE: 80.0717, MAE: 65.2575, RÂ²: -0.0068
ğŸ’¾ Test metrics saved to: logs/client_12_test_metrics_20251030_020214.csv

ğŸ” Running 3-fold cross-validation (Round 9)
ğŸ’¾ CV metrics saved to: logs/client_12_cv_metrics_20251030_020214.csv

ğŸ¯ Round 9 Training Results:
   Training - Loss: 5991.2407, RMSE: 77.4031, RÂ²: -0.0095
   Validation - Loss: 6187.0869, RMSE: 78.6580, RÂ²: -0.0096
ğŸ’¾ Training metrics saved to: logs/client_12_training_metrics_20251030_020214.csv

ğŸ§ª Round 9 Evaluation Results:
   Test Loss: 6415.7627
   RMSE: 80.0985, MAE: 65.2565, RÂ²: -0.0074
ğŸ’¾ Test metrics saved to: logs/client_12_test_metrics_20251030_020214.csv

ğŸ” Running 3-fold cross-validation (Round 10)
ğŸ’¾ CV metrics saved to: logs/client_12_cv_metrics_20251030_020214.csv

ğŸ¯ Round 10 Training Results:
   Training - Loss: 5973.0566, RMSE: 77.2856, RÂ²: -0.0065
   Validation - Loss: 6168.5376, RMSE: 78.5400, RÂ²: -0.0065
ğŸ’¾ Training metrics saved to: logs/client_12_training_metrics_20251030_020214.csv

ğŸ§ª Round 10 Evaluation Results:
   Test Loss: 6413.3961
   RMSE: 80.0837, MAE: 65.2570, RÂ²: -0.0071
ğŸ’¾ Test metrics saved to: logs/client_12_test_metrics_20251030_020214.csv

================================================================================
ğŸ¯ FINAL COMPREHENSIVE REPORT
================================================================================
ğŸ’¾ Final summary saved to: logs/client_12_final_summary_20251030_020214.csv

ğŸ“Š CLIENT: client_12 | ALGORITHM: fedavg | MODEL: LSTM
ğŸ“ˆ TOTAL ROUNDS: 10

âš™ï¸  HYPERPARAMETERS:
   Learning Rate: 0.001
   Batch Size: 32
   Local Epochs: 1
   Hidden Dim: 64
   Num Layers: 2
   Sequence Length: 10
   Use Attention: False
   Dropout: 0.3
   Optimizer: adam

ğŸ FINAL ROUND PERFORMANCE:
   Training   - Loss:  5973.06 | RMSE:  77.29 | RÂ²: -0.0065
   Validation - Loss:  6168.54 | RMSE:  78.54 | RÂ²: -0.0065
   Test       - Loss:  6413.40 | RMSE:  80.08 | RÂ²: -0.0071

ğŸ“Š STATISTICS ACROSS ALL ROUNDS (Mean Â± Std):
   Training Loss:    5977.57 Â±  13.82
   Validation Loss:  6173.12 Â±  14.11
   Test Loss:        7003.98 Â± 1762.71

   Training RMSE:    77.31 Â±  0.09
   Validation RMSE:  78.57 Â±  0.09
   Test RMSE:        83.18 Â±  9.23

   Training RÂ²:     -0.0072 Â± 0.0023
   Validation RÂ²:   -0.0073 Â± 0.0023
   Test RÂ²:         -0.0998 Â± 0.2768

â­ BEST PERFORMANCE:
   Best Round: 5 (Test RÂ²: -0.0063)

ğŸ“‹ DATA SUMMARY:
   Training samples:   4002
   Validation samples: 1328
   Test samples:       1328
   Total samples:      6658
================================================================================
âœ… Client client_12 completed | Algorithm: FEDAVG
