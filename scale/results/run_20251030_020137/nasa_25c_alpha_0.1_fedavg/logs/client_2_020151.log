[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 72559109-1050-4b1b-8bbc-000843b643ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e080c7c7-a0fb-4a32-b3d4-5d2d5c472580
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a2fd0ba8-9472-4317-93cf-af6f275ba479
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b0c13e50-8dd0-4e71-9769-4be12410b9a7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message da004ca2-cfc5-4f52-99d8-c2168cee5b73
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c12a05d7-a957-476f-a35f-37493a06bd79
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 31cada5b-bbd4-40ed-a7e5-3b1c31580a3d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0c516d4f-e3e1-4f3d-9066-cbcc0069c534
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3adeb96d-9d13-4093-9f17-047de780e8e2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7a89307e-ad50-4ebc-8b27-389f180326f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 95a05eec-46a8-460c-97af-c862af296941
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 27b651ea-484e-4df4-a561-696efc069d63
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4bcafde0-dc73-4c41-9e28-c49763889e87
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 99571bd9-bb0b-47b4-9952-87f3357708e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a67e6c2b-6c1f-4bff-b9ae-e849869519d5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d7ec7694-e158-4e7b-b8a0-20f30832a7b5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ccdffbee-efce-4ffb-86c7-13f25c139745
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d001b947-9947-45ac-b77c-8ee4e4cf892b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f77f8a9e-2774-4668-808c-288c6fa560e0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: reconnect message d6f34cd6-752d-44dc-979e-2f380627758c
[92mINFO [0m:      Disconnect and shut down
🚀 Starting NASA FL Client: client_2
Algorithm: FEDAVG
Server: localhost:8686
K-Folds: 5
Log Directory: logs
🔄 Using device: cuda
🎯 GPU: NVIDIA A100-SXM4-80GB
💾 Hyperparameters saved to: logs/client_2_hyperparams_20251030_020154.csv
🔍 Looking for data at: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.1/client_2
📊 Loaded 7847 total samples from /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.1/client_2
🔢 Original feature dimension: 24
🔍 Applying KernelPCA with 5 components, kernel=poly
📊 Data shape - Before: (4707, 24), After: (4707, 5)
🔄 Created sequences with length 10
   Final dataset shape: X (4697, 10, 5), y (4697,)
✅ Data split completed:
   Training samples: 4697
   Validation samples: 1560
   Test samples: 1560
   Model type: lstm
   Final input dimension: 5
✅ Client client_2 ready:
   Model: LSTM
   Training: 4697 samples
   Device: cuda
   Validation: 1560 samples
   Test: 1560 samples
   Algorithm: fedavg
   Total Rounds: 10
   Learning Rate: 0.001
   Batch Size: 32
   Logging to: logs

🧪 Round 0 Evaluation Results:
   Test Loss: 12097.2491
   RMSE: 109.9875, MAE: 86.8070, R²: -1.0403
💾 Test metrics saved to: logs/client_2_test_metrics_20251030_020154.csv
⏩ Skipping CV for Round 2 (runs every 5 rounds)
Round 2: train_loss=6404.8696, val_loss=6485.7490, val_r2=-0.0177
💾 Training metrics saved to: logs/client_2_training_metrics_20251030_020154.csv

🧪 Round 2 Evaluation Results:
   Test Loss: 6026.0968
   RMSE: 77.6279, MAE: 62.8524, R²: -0.0164
💾 Test metrics saved to: logs/client_2_test_metrics_20251030_020154.csv
⏩ Skipping CV for Round 3 (runs every 5 rounds)

🎯 Round 3 Training Results:
   Training - Loss: 6361.4980, RMSE: 79.7590, R²: -0.0075
   Validation - Loss: 6436.5195, RMSE: 80.2279, R²: -0.0100

🧪 Round 3 Evaluation Results:
   Test Loss: 6003.3721
   RMSE: 77.4814, MAE: 62.8194, R²: -0.0125
💾 Test metrics saved to: logs/client_2_test_metrics_20251030_020154.csv
⏩ Skipping CV for Round 4 (runs every 5 rounds)
Round 4: train_loss=6427.1108, val_loss=6510.4351, val_r2=-0.0216
💾 Training metrics saved to: logs/client_2_training_metrics_20251030_020154.csv

🧪 Round 4 Evaluation Results:
   Test Loss: 5999.1820
   RMSE: 77.4544, MAE: 62.8152, R²: -0.0118
💾 Test metrics saved to: logs/client_2_test_metrics_20251030_020154.csv

🔍 Running 3-fold cross-validation (Round 5)

🔍 Starting 3-fold cross-validation on TRAINING data for client client_2

📊 Fold 1/3
   Fold 1 Results:
     Val Loss: 6482.5962
     Val RMSE: 80.5146, Val R²: -0.0088

📊 Fold 2/3
   Fold 2 Results:
     Val Loss: 6426.4448
     Val RMSE: 80.1651, Val R²: -0.0047

📊 Fold 3/3
   Fold 3 Results:
     Val Loss: 6218.5513
     Val RMSE: 78.8578, Val R²: -0.0161
💾 CV metrics saved to: logs/client_2_cv_metrics_20251030_020154.csv

📈 3-Fold CV Summary (Training Data):
   VAL_LOSS: 6375.8641 ± 113.5745
   RMSE: 79.8458 ± 0.7131
   R2: -0.0099 ± 0.0047

🎯 Round 5 Training Results:
   Training - Loss: 6376.3145, RMSE: 79.8518, R²: -0.0098
   Validation - Loss: 6453.5591, RMSE: 80.3340, R²: -0.0126
💾 Training metrics saved to: logs/client_2_training_metrics_20251030_020154.csv

🧪 Round 5 Evaluation Results:
   Test Loss: 5991.4650
   RMSE: 77.4046, MAE: 62.8073, R²: -0.0105
💾 Test metrics saved to: logs/client_2_test_metrics_20251030_020154.csv
⏩ Skipping CV for Round 6 (runs every 5 rounds)

🎯 Round 6 Training Results:
   Training - Loss: 6383.7793, RMSE: 79.8986, R²: -0.0110
   Validation - Loss: 6462.0449, RMSE: 80.3868, R²: -0.0140
💾 Training metrics saved to: logs/client_2_training_metrics_20251030_020154.csv

🧪 Round 6 Evaluation Results:
   Test Loss: 5993.0601
   RMSE: 77.4149, MAE: 62.8090, R²: -0.0108
💾 Test metrics saved to: logs/client_2_test_metrics_20251030_020154.csv
⏩ Skipping CV for Round 7 (runs every 5 rounds)
Round 7: train_loss=6367.1807, val_loss=6443.0918, val_r2=-0.0110

🧪 Round 7 Evaluation Results:
   Test Loss: 6005.3954
   RMSE: 77.4945, MAE: 62.8223, R²: -0.0129
💾 Test metrics saved to: logs/client_2_test_metrics_20251030_020154.csv
⏩ Skipping CV for Round 8 (runs every 5 rounds)
Round 8: train_loss=6373.4858, val_loss=6450.3291, val_r2=-0.0121
💾 Training metrics saved to: logs/client_2_training_metrics_20251030_020154.csv

🧪 Round 8 Evaluation Results:
   Test Loss: 5995.3280
   RMSE: 77.4295, MAE: 62.8113, R²: -0.0112
💾 Test metrics saved to: logs/client_2_test_metrics_20251030_020154.csv

🔍 Running 3-fold cross-validation (Round 9)
💾 CV metrics saved to: logs/client_2_cv_metrics_20251030_020154.csv

🎯 Round 9 Training Results:
   Training - Loss: 6403.5264, RMSE: 80.0220, R²: -0.0141
   Validation - Loss: 6484.2490, RMSE: 80.5248, R²: -0.0174
💾 Training metrics saved to: logs/client_2_training_metrics_20251030_020154.csv

🧪 Round 9 Evaluation Results:
   Test Loss: 6000.6242
   RMSE: 77.4637, MAE: 62.8166, R²: -0.0121
💾 Test metrics saved to: logs/client_2_test_metrics_20251030_020154.csv

🔍 Running 3-fold cross-validation (Round 10)
💾 CV metrics saved to: logs/client_2_cv_metrics_20251030_020154.csv

🎯 Round 10 Training Results:
   Training - Loss: 6482.5278, RMSE: 80.5141, R²: -0.0266
   Validation - Loss: 6571.0479, RMSE: 81.0620, R²: -0.0311
💾 Training metrics saved to: logs/client_2_training_metrics_20251030_020154.csv

🧪 Round 10 Evaluation Results:
   Test Loss: 5997.7107
   RMSE: 77.4449, MAE: 62.8137, R²: -0.0116
💾 Test metrics saved to: logs/client_2_test_metrics_20251030_020154.csv

================================================================================
🎯 FINAL COMPREHENSIVE REPORT
================================================================================
💾 Final summary saved to: logs/client_2_final_summary_20251030_020154.csv

📊 CLIENT: client_2 | ALGORITHM: fedavg | MODEL: LSTM
📈 TOTAL ROUNDS: 10

⚙️  HYPERPARAMETERS:
   Learning Rate: 0.001
   Batch Size: 32
   Local Epochs: 1
   Hidden Dim: 64
   Num Layers: 2
   Sequence Length: 10
   Use Attention: False
   Dropout: 0.3
   Optimizer: adam

🏁 FINAL ROUND PERFORMANCE:
   Training   - Loss:  6482.53 | RMSE:  80.51 | R²: -0.0266
   Validation - Loss:  6571.05 | RMSE:  81.06 | R²: -0.0311
   Test       - Loss:  5997.71 | RMSE:  77.44 | R²: -0.0116

📊 STATISTICS ACROSS ALL ROUNDS (Mean ± Std):
   Training Loss:    6407.37 ±  35.31
   Validation Loss:  6488.20 ±  39.09
   Test Loss:        6610.95 ± 1828.79

   Training RMSE:    80.05 ±  0.22
   Validation RMSE:  80.55 ±  0.24
   Test RMSE:        80.72 ±  9.76

   Training R²:     -0.0147 ± 0.0056
   Validation R²:   -0.0181 ± 0.0061
   Test R²:         -0.1150 ± 0.3084

⭐ BEST PERFORMANCE:
   Best Round: 5 (Test R²: -0.0105)

📋 DATA SUMMARY:
   Training samples:   4697
   Validation samples: 1560
   Test samples:       1560
   Total samples:      7817
================================================================================
✅ Client client_2 completed | Algorithm: FEDAVG
