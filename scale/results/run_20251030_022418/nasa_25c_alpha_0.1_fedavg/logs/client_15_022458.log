[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4d4d56c4-6b39-4a38-8ee7-fe4bde5a7fe5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d76223f2-ac64-4f51-9962-eb3dc1a40616
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b5c64f31-6427-4dc4-88f5-850061ee8d39
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cfbb147b-95ef-47ed-8f11-db73c2902725
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cc639e30-bbbc-4faa-b6e7-a3cf08dc197b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7719d3a4-c0a8-4e88-a54a-2968b1969c18
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ce07d70c-ca97-4ec7-a266-b432ff882f0e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6ea2a700-b357-4416-965b-d7b3a4ef6ef9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 90e3c159-bd1c-4987-8cd9-1045cb654868
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message faa2ee95-2b39-405f-be13-08832f4cfe55
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d11576a9-cbec-40fc-b877-70adbbfb72e6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message db1ae6cb-bf1b-4c4c-8733-150b1b7fe00e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 538c4d9a-9fee-4372-8afd-893589b2f86f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9f8ef714-ab0b-46ab-bc1d-9a7dde4c1c99
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e17e66f0-d2b0-45da-b7c5-5eed1aa3f8bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 00f2a092-1147-4043-9635-668b30c17579
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4c0c2cc2-d5fc-48a6-91f8-0417cde6dd02
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 60cde52b-77a6-478c-9e75-4e93de313de8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1c7cffdb-d21b-4ca6-8bc4-bb8915471260
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: reconnect message ba1f9c6c-8889-424a-8d24-85f1b085596f
[92mINFO [0m:      Disconnect and shut down
🚀 Starting NASA FL Client: client_15
Algorithm: FEDAVG
Server: localhost:8686
K-Folds: 5
Log Directory: logs
🔄 Using device: cuda
🎯 GPU: NVIDIA A100-SXM4-80GB
💾 Hyperparameters saved to: logs/client_15_hyperparams_20251030_022501.csv
🔍 Looking for data at: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.1/client_15
📊 Loaded 6769 total samples from /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.1/client_15
🔢 Original feature dimension: 24
🔍 Applying KernelPCA with 5 components, kernel=poly
📊 Data shape - Before: (4061, 24), After: (4061, 5)
🔄 Created sequences with length 10
   Final dataset shape: X (4051, 10, 5), y (4051,)
✅ Data split completed:
   Training samples: 4051
   Validation samples: 1344
   Test samples: 1344
   Model type: lstm
   Final input dimension: 5
✅ Client client_15 ready:
   Model: LSTM
   Training: 4051 samples
   Device: cuda
   Validation: 1344 samples
   Test: 1344 samples
   Algorithm: fedavg
   Total Rounds: 10
   Learning Rate: 0.001
   Batch Size: 32
   Logging to: logs

🧪 Round 0 Evaluation Results:
   Test Loss: 10970.4683
   RMSE: 104.7400, MAE: 78.4990, R²: -0.5045
💾 Test metrics saved to: logs/client_15_test_metrics_20251030_022501.csv
⏩ Skipping CV for Round 2 (runs every 5 rounds)
Round 2: train_loss=7229.5044, val_loss=6631.9346, val_r2=-0.0000
💾 Training metrics saved to: logs/client_15_training_metrics_20251030_022501.csv

🧪 Round 2 Evaluation Results:
   Test Loss: 7356.3339
   RMSE: 85.7691, MAE: 68.5131, R²: -0.0089
💾 Test metrics saved to: logs/client_15_test_metrics_20251030_022501.csv
⏩ Skipping CV for Round 3 (runs every 5 rounds)

🎯 Round 3 Training Results:
   Training - Loss: 7228.5376, RMSE: 85.0208, R²: -0.0042
   Validation - Loss: 6631.9448, RMSE: 81.4368, R²: -0.0000

🧪 Round 3 Evaluation Results:
   Test Loss: 7358.8285
   RMSE: 85.7836, MAE: 68.5067, R²: -0.0092
💾 Test metrics saved to: logs/client_15_test_metrics_20251030_022501.csv
⏩ Skipping CV for Round 4 (runs every 5 rounds)
Round 4: train_loss=7221.4834, val_loss=6632.5469, val_r2=-0.0001
💾 Training metrics saved to: logs/client_15_training_metrics_20251030_022501.csv

🧪 Round 4 Evaluation Results:
   Test Loss: 7346.6201
   RMSE: 85.7124, MAE: 68.5393, R²: -0.0075
💾 Test metrics saved to: logs/client_15_test_metrics_20251030_022501.csv

🔍 Running 3-fold cross-validation (Round 5)

🔍 Starting 3-fold cross-validation on TRAINING data for client client_15

📊 Fold 1/3
   Fold 1 Results:
     Val Loss: 7018.2720
     Val RMSE: 83.7751, Val R²: -0.0146

📊 Fold 2/3
   Fold 2 Results:
     Val Loss: 7137.3599
     Val RMSE: 84.4829, Val R²: -0.0000

📊 Fold 3/3
   Fold 3 Results:
     Val Loss: 7791.9609
     Val RMSE: 88.2721, Val R²: -0.0404
💾 CV metrics saved to: logs/client_15_cv_metrics_20251030_022501.csv

📈 3-Fold CV Summary (Training Data):
   VAL_LOSS: 7315.8643 ± 340.1436
   RMSE: 85.5100 ± 1.9743
   R2: -0.0183 ± 0.0167

🎯 Round 5 Training Results:
   Training - Loss: 7255.0967, RMSE: 85.1769, R²: -0.0079
   Validation - Loss: 6635.6606, RMSE: 81.4596, R²: -0.0006
💾 Training metrics saved to: logs/client_15_training_metrics_20251030_022501.csv

🧪 Round 5 Evaluation Results:
   Test Loss: 7354.0099
   RMSE: 85.7555, MAE: 68.5192, R²: -0.0085
💾 Test metrics saved to: logs/client_15_test_metrics_20251030_022501.csv
⏩ Skipping CV for Round 6 (runs every 5 rounds)

🎯 Round 6 Training Results:
   Training - Loss: 7218.5181, RMSE: 84.9619, R²: -0.0028
   Validation - Loss: 6633.1431, RMSE: 81.4441, R²: -0.0002
💾 Training metrics saved to: logs/client_15_training_metrics_20251030_022501.csv

🧪 Round 6 Evaluation Results:
   Test Loss: 7341.8573
   RMSE: 85.6846, MAE: 68.5547, R²: -0.0069
💾 Test metrics saved to: logs/client_15_test_metrics_20251030_022501.csv
⏩ Skipping CV for Round 7 (runs every 5 rounds)
Round 7: train_loss=7233.4673, val_loss=6632.0420, val_r2=-0.0000

🧪 Round 7 Evaluation Results:
   Test Loss: 7345.5169
   RMSE: 85.7060, MAE: 68.5424, R²: -0.0074
💾 Test metrics saved to: logs/client_15_test_metrics_20251030_022501.csv
⏩ Skipping CV for Round 8 (runs every 5 rounds)
Round 8: train_loss=7235.0073, val_loss=6632.1431, val_r2=-0.0000
💾 Training metrics saved to: logs/client_15_training_metrics_20251030_022501.csv

🧪 Round 8 Evaluation Results:
   Test Loss: 7333.5150
   RMSE: 85.6359, MAE: 68.5850, R²: -0.0057
💾 Test metrics saved to: logs/client_15_test_metrics_20251030_022501.csv

🔍 Running 3-fold cross-validation (Round 9)
💾 CV metrics saved to: logs/client_15_cv_metrics_20251030_022501.csv

🎯 Round 9 Training Results:
   Training - Loss: 7220.8594, RMSE: 84.9756, R²: -0.0032
   Validation - Loss: 6632.6533, RMSE: 81.4411, R²: -0.0001
💾 Training metrics saved to: logs/client_15_training_metrics_20251030_022501.csv

🧪 Round 9 Evaluation Results:
   Test Loss: 7348.1626
   RMSE: 85.7214, MAE: 68.5350, R²: -0.0077
💾 Test metrics saved to: logs/client_15_test_metrics_20251030_022501.csv

🔍 Running 3-fold cross-validation (Round 10)
💾 CV metrics saved to: logs/client_15_cv_metrics_20251030_022501.csv

🎯 Round 10 Training Results:
   Training - Loss: 7232.8071, RMSE: 85.0459, R²: -0.0048
   Validation - Loss: 6632.0093, RMSE: 81.4371, R²: -0.0000
💾 Training metrics saved to: logs/client_15_training_metrics_20251030_022501.csv

🧪 Round 10 Evaluation Results:
   Test Loss: 7337.7495
   RMSE: 85.6607, MAE: 68.5693, R²: -0.0063
💾 Test metrics saved to: logs/client_15_test_metrics_20251030_022501.csv

================================================================================
🎯 FINAL COMPREHENSIVE REPORT
================================================================================
💾 Final summary saved to: logs/client_15_final_summary_20251030_022501.csv

📊 CLIENT: client_15 | ALGORITHM: fedavg | MODEL: LSTM
📈 TOTAL ROUNDS: 10

⚙️  HYPERPARAMETERS:
   Learning Rate: 0.001
   Batch Size: 32
   Local Epochs: 1
   Hidden Dim: 64
   Num Layers: 2
   Sequence Length: 10
   Use Attention: False
   Dropout: 0.3
   Optimizer: adam

🏁 FINAL ROUND PERFORMANCE:
   Training   - Loss:  7232.81 | RMSE:  85.05 | R²: -0.0048
   Validation - Loss:  6632.01 | RMSE:  81.44 | R²: -0.0000
   Test       - Loss:  7337.75 | RMSE:  85.66 | R²: -0.0063

📊 STATISTICS ACROSS ALL ROUNDS (Mean ± Std):
   Training Loss:    7230.47 ±  11.65
   Validation Loss:  6632.87 ±   1.20
   Test Loss:        7709.31 ± 1087.08

   Training RMSE:    85.03 ±  0.07
   Validation RMSE:  81.44 ±  0.01
   Test RMSE:        87.62 ±  5.71

   Training R²:     -0.0045 ± 0.0016
   Validation R²:   -0.0001 ± 0.0002
   Test R²:         -0.0573 ± 0.1491

⭐ BEST PERFORMANCE:
   Best Round: 8 (Test R²: -0.0057)

📋 DATA SUMMARY:
   Training samples:   4051
   Validation samples: 1344
   Test samples:       1344
   Total samples:      6739
================================================================================
✅ Client client_15 completed | Algorithm: FEDAVG
