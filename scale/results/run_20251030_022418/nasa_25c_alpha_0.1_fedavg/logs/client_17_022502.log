[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 49c7b713-956c-4fe4-a276-7e7dfcd829b0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b1047cef-4004-4ba2-85f6-f15b43d23ee9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1a508e77-0768-4ed2-94f1-2a585572fea4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7403d6fb-0da1-438c-a88a-f4d0abbd003d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 49cf44ad-19fd-487b-8de2-265bcc297eaa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 85227894-8c11-404e-83cf-256c75c772c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message af3486c0-105a-481a-9309-56901c904fe9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fce20f04-69d8-4ffe-998d-c9100f30ed7a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 66a83e22-c8d8-4b36-a8c2-4fdeaa62c16a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5b0e2d42-8bc8-479b-9d2d-de8d162831d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 32a210a4-f9cf-4bcc-9dd5-d260bd333256
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6b7dc687-e3c7-4dc7-88f3-ac6324fea054
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8505d59d-6381-4654-bf9d-8bbcc007aedb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0c8f789e-b2f1-409a-98a6-ade783408d4c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 19de23e5-479d-4774-a929-c23c153941fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9328c565-6d6a-4505-8814-c040f1fb42f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6da62d25-388c-47ca-b908-0c3f0d759413
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2c16d3cb-2dd3-48c8-b56c-874d4544a181
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e0854fa4-6d08-4928-9f0a-ff8a4f50add2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: reconnect message 98541be4-24c5-4d84-ac28-6a0d0b7fa99f
[92mINFO [0m:      Disconnect and shut down
🚀 Starting NASA FL Client: client_17
Algorithm: FEDAVG
Server: localhost:8686
K-Folds: 5
Log Directory: logs
🔄 Using device: cuda
🎯 GPU: NVIDIA A100-SXM4-80GB
💾 Hyperparameters saved to: logs/client_17_hyperparams_20251030_022505.csv
🔍 Looking for data at: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.1/client_17
📊 Loaded 5738 total samples from /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.1/client_17
🔢 Original feature dimension: 24
🔍 Applying KernelPCA with 5 components, kernel=poly
📊 Data shape - Before: (3442, 24), After: (3442, 5)
🔄 Created sequences with length 10
   Final dataset shape: X (3432, 10, 5), y (3432,)
✅ Data split completed:
   Training samples: 3432
   Validation samples: 1138
   Test samples: 1138
   Model type: lstm
   Final input dimension: 5
✅ Client client_17 ready:
   Model: LSTM
   Training: 3432 samples
   Device: cuda
   Validation: 1138 samples
   Test: 1138 samples
   Algorithm: fedavg
   Total Rounds: 10
   Learning Rate: 0.001
   Batch Size: 32
   Logging to: logs

🧪 Round 0 Evaluation Results:
   Test Loss: 10044.2435
   RMSE: 100.2210, MAE: 77.4509, R²: -0.5489
💾 Test metrics saved to: logs/client_17_test_metrics_20251030_022505.csv
⏩ Skipping CV for Round 2 (runs every 5 rounds)
Round 2: train_loss=6614.1479, val_loss=7189.6123, val_r2=-0.0617
💾 Training metrics saved to: logs/client_17_training_metrics_20251030_022505.csv

🧪 Round 2 Evaluation Results:
   Test Loss: 6534.2856
   RMSE: 80.8349, MAE: 64.4624, R²: -0.0077
💾 Test metrics saved to: logs/client_17_test_metrics_20251030_022505.csv
⏩ Skipping CV for Round 3 (runs every 5 rounds)

🎯 Round 3 Training Results:
   Training - Loss: 6546.1323, RMSE: 80.9082, R²: -0.0159
   Validation - Loss: 7078.2803, RMSE: 84.1325, R²: -0.0453

🧪 Round 3 Evaluation Results:
   Test Loss: 6536.4760
   RMSE: 80.8485, MAE: 64.4613, R²: -0.0080
💾 Test metrics saved to: logs/client_17_test_metrics_20251030_022505.csv
⏩ Skipping CV for Round 4 (runs every 5 rounds)
Round 4: train_loss=6527.7603, val_loss=7045.8511, val_r2=-0.0405
💾 Training metrics saved to: logs/client_17_training_metrics_20251030_022505.csv

🧪 Round 4 Evaluation Results:
   Test Loss: 6525.8165
   RMSE: 80.7825, MAE: 64.4668, R²: -0.0064
💾 Test metrics saved to: logs/client_17_test_metrics_20251030_022505.csv

🔍 Running 3-fold cross-validation (Round 5)

🔍 Starting 3-fold cross-validation on TRAINING data for client client_17

📊 Fold 1/3
   Fold 1 Results:
     Val Loss: 6724.2559
     Val RMSE: 82.0016, Val R²: -0.0198

📊 Fold 2/3
   Fold 2 Results:
     Val Loss: 6128.7446
     Val RMSE: 78.2863, Val R²: -0.0089

📊 Fold 3/3
   Fold 3 Results:
     Val Loss: 6753.0698
     Val RMSE: 82.1771, Val R²: -0.0140
💾 CV metrics saved to: logs/client_17_cv_metrics_20251030_022505.csv

📈 3-Fold CV Summary (Training Data):
   VAL_LOSS: 6535.3568 ± 287.7587
   RMSE: 80.8216 ± 1.7942
   R2: -0.0142 ± 0.0045

🎯 Round 5 Training Results:
   Training - Loss: 6546.0063, RMSE: 80.9074, R²: -0.0159
   Validation - Loss: 7078.0625, RMSE: 84.1312, R²: -0.0452
💾 Training metrics saved to: logs/client_17_training_metrics_20251030_022505.csv

🧪 Round 5 Evaluation Results:
   Test Loss: 6532.2505
   RMSE: 80.8223, MAE: 64.4634, R²: -0.0074
💾 Test metrics saved to: logs/client_17_test_metrics_20251030_022505.csv
⏩ Skipping CV for Round 6 (runs every 5 rounds)

🎯 Round 6 Training Results:
   Training - Loss: 6579.2939, RMSE: 81.1128, R²: -0.0211
   Validation - Loss: 7133.9292, RMSE: 84.4626, R²: -0.0535
💾 Training metrics saved to: logs/client_17_training_metrics_20251030_022505.csv

🧪 Round 6 Evaluation Results:
   Test Loss: 6521.7043
   RMSE: 80.7571, MAE: 64.4708, R²: -0.0057
💾 Test metrics saved to: logs/client_17_test_metrics_20251030_022505.csv
⏩ Skipping CV for Round 7 (runs every 5 rounds)
Round 7: train_loss=6582.2061, val_loss=7138.6777, val_r2=-0.0542

🧪 Round 7 Evaluation Results:
   Test Loss: 6524.8616
   RMSE: 80.7766, MAE: 64.4674, R²: -0.0062
💾 Test metrics saved to: logs/client_17_test_metrics_20251030_022505.csv
⏩ Skipping CV for Round 8 (runs every 5 rounds)
Round 8: train_loss=6608.4160, val_loss=7180.6123, val_r2=-0.0604
💾 Training metrics saved to: logs/client_17_training_metrics_20251030_022505.csv

🧪 Round 8 Evaluation Results:
   Test Loss: 6514.5810
   RMSE: 80.7130, MAE: 64.4795, R²: -0.0046
💾 Test metrics saved to: logs/client_17_test_metrics_20251030_022505.csv

🔍 Running 3-fold cross-validation (Round 9)
💾 CV metrics saved to: logs/client_17_cv_metrics_20251030_022505.csv

🎯 Round 9 Training Results:
   Training - Loss: 6582.7217, RMSE: 81.1340, R²: -0.0216
   Validation - Loss: 7139.5166, RMSE: 84.4957, R²: -0.0543
💾 Training metrics saved to: logs/client_17_training_metrics_20251030_022505.csv

🧪 Round 9 Evaluation Results:
   Test Loss: 6527.1547
   RMSE: 80.7908, MAE: 64.4661, R²: -0.0066
💾 Test metrics saved to: logs/client_17_test_metrics_20251030_022505.csv

🔍 Running 3-fold cross-validation (Round 10)
💾 CV metrics saved to: logs/client_17_cv_metrics_20251030_022505.csv

🎯 Round 10 Training Results:
   Training - Loss: 6593.7773, RMSE: 81.2021, R²: -0.0233
   Validation - Loss: 7157.3604, RMSE: 84.6012, R²: -0.0569
💾 Training metrics saved to: logs/client_17_training_metrics_20251030_022505.csv

🧪 Round 10 Evaluation Results:
   Test Loss: 6518.1831
   RMSE: 80.7353, MAE: 64.4750, R²: -0.0052
💾 Test metrics saved to: logs/client_17_test_metrics_20251030_022505.csv

================================================================================
🎯 FINAL COMPREHENSIVE REPORT
================================================================================
💾 Final summary saved to: logs/client_17_final_summary_20251030_022505.csv

📊 CLIENT: client_17 | ALGORITHM: fedavg | MODEL: LSTM
📈 TOTAL ROUNDS: 10

⚙️  HYPERPARAMETERS:
   Learning Rate: 0.001
   Batch Size: 32
   Local Epochs: 1
   Hidden Dim: 64
   Num Layers: 2
   Sequence Length: 10
   Use Attention: False
   Dropout: 0.3
   Optimizer: adam

🏁 FINAL ROUND PERFORMANCE:
   Training   - Loss:  6593.78 | RMSE:  81.20 | R²: -0.0233
   Validation - Loss:  7157.36 | RMSE:  84.60 | R²: -0.0569
   Test       - Loss:  6518.18 | RMSE:  80.74 | R²: -0.0052

📊 STATISTICS ACROSS ALL ROUNDS (Mean ± Std):
   Training Loss:    6578.87 ±  29.39
   Validation Loss:  7132.13 ±  48.87
   Test Loss:        6877.96 ± 1055.45

   Training RMSE:    81.11 ±  0.18
   Validation RMSE:  84.45 ±  0.29
   Test RMSE:        82.73 ±  5.83

   Training R²:     -0.0210 ± 0.0046
   Validation R²:   -0.0532 ± 0.0072
   Test R²:         -0.0607 ± 0.1628

⭐ BEST PERFORMANCE:
   Best Round: 8 (Test R²: -0.0046)

📋 DATA SUMMARY:
   Training samples:   3432
   Validation samples: 1138
   Test samples:       1138
   Total samples:      5708
================================================================================
✅ Client client_17 completed | Algorithm: FEDAVG
