[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d45a278f-2b84-4f56-b2cf-c6e739f75a8c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 631f4e6e-a7de-4a9e-b389-2b11c28297a9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3395c854-950e-412f-ad41-1ad43c1c4756
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bf965aff-8c40-4bfb-87e9-018e799ba5d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ee80415c-faf1-4e48-bfbc-238bff35966a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4d4f8a28-17b9-40f1-8aac-a19019283c66
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5cbc70a1-d654-4dca-a655-fc7e80c75bb4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message faaedd81-955f-4712-98be-119f08c2d15f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3ae62f99-48c9-47b7-937e-e6ff220547f9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0a811f66-9d7d-4dba-920e-cbcb2136fe46
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 79b8bfdc-d4db-4ccf-bd5d-250ad6808ce5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fcd7def1-5a55-4c95-a44f-de2b6a2b1422
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8d0b9406-3330-491f-a0ad-bb0b92dd9070
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 292eb747-5265-4eb3-a704-2986ba6d2859
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d7c9852a-0d13-4f9b-85f3-24faa344e17d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2e002b90-85a6-46f7-9bfb-007cb1bb56af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b22267b1-c608-4713-ac8d-07bc2747a483
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e24f0154-3245-4158-ab19-2fb57ff3b24c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b398f78e-238a-426d-9cd9-9a79fa62cea2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 09e536cf-1c1d-4fca-9197-a5b67682765b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: reconnect message 408cdfc6-6b2d-46ef-83f7-7b166cc0ec46
[92mINFO [0m:      Disconnect and shut down
🚀 Starting NASA FL Client: client_24
Algorithm: FEDAVG
Server: localhost:8686
K-Folds: 5
Log Directory: logs
🔄 Using device: cuda
🎯 GPU: NVIDIA A100-SXM4-80GB
💾 Hyperparameters saved to: logs/client_24_hyperparams_20251030_022518.csv
🔍 Looking for data at: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.1/client_24
📊 Loaded 5496 total samples from /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.1/client_24
🔢 Original feature dimension: 24
🔍 Applying KernelPCA with 5 components, kernel=poly
📊 Data shape - Before: (3297, 24), After: (3297, 5)
🔄 Created sequences with length 10
   Final dataset shape: X (3287, 10, 5), y (3287,)
✅ Data split completed:
   Training samples: 3287
   Validation samples: 1089
   Test samples: 1090
   Model type: lstm
   Final input dimension: 5
✅ Client client_24 ready:
   Model: LSTM
   Training: 3287 samples
   Device: cuda
   Validation: 1089 samples
   Test: 1090 samples
   Algorithm: fedavg
   Total Rounds: 10
   Learning Rate: 0.001
   Batch Size: 32
   Logging to: logs
⏩ Skipping CV for Round 1 (runs every 5 rounds)
Round 1: train_loss=11030.7490, val_loss=11273.7480, val_r2=-0.8250

🧪 Round 1 Evaluation Results:
   Test Loss: 9159.8491
   RMSE: 95.7071, MAE: 73.9178, R²: -0.5105
💾 Test metrics saved to: logs/client_24_test_metrics_20251030_022518.csv
⏩ Skipping CV for Round 2 (runs every 5 rounds)
Round 2: train_loss=6474.9985, val_loss=6261.1396, val_r2=-0.0136
💾 Training metrics saved to: logs/client_24_training_metrics_20251030_022518.csv

🧪 Round 2 Evaluation Results:
   Test Loss: 6073.1297
   RMSE: 77.9303, MAE: 64.0540, R²: -0.0015
💾 Test metrics saved to: logs/client_24_test_metrics_20251030_022518.csv
⏩ Skipping CV for Round 3 (runs every 5 rounds)

🎯 Round 3 Training Results:
   Training - Loss: 6488.5132, RMSE: 80.5513, R²: -0.0068
   Validation - Loss: 6282.8677, RMSE: 79.2645, R²: -0.0171

🧪 Round 3 Evaluation Results:
   Test Loss: 6074.0840
   RMSE: 77.9364, MAE: 64.0495, R²: -0.0017
💾 Test metrics saved to: logs/client_24_test_metrics_20251030_022518.csv
⏩ Skipping CV for Round 4 (runs every 5 rounds)
Round 4: train_loss=6475.2378, val_loss=6261.5415, val_r2=-0.0136
💾 Training metrics saved to: logs/client_24_training_metrics_20251030_022518.csv

🧪 Round 4 Evaluation Results:
   Test Loss: 6069.7179
   RMSE: 77.9084, MAE: 64.0725, R²: -0.0009
💾 Test metrics saved to: logs/client_24_test_metrics_20251030_022518.csv

🔍 Running 3-fold cross-validation (Round 5)

🔍 Starting 3-fold cross-validation on TRAINING data for client client_24

📊 Fold 1/3
   Fold 1 Results:
     Val Loss: 5975.6572
     Val RMSE: 77.3024, Val R²: -0.0007

📊 Fold 2/3
   Fold 2 Results:
     Val Loss: 6969.7524
     Val RMSE: 83.4850, Val R²: -0.0194

📊 Fold 3/3
   Fold 3 Results:
     Val Loss: 6587.7524
     Val RMSE: 81.1650, Val R²: -0.0163
💾 CV metrics saved to: logs/client_24_cv_metrics_20251030_022518.csv

📈 3-Fold CV Summary (Training Data):
   VAL_LOSS: 6511.0540 ± 409.4454
   RMSE: 80.6508 ± 2.5501
   R2: -0.0121 ± 0.0082

🎯 Round 5 Training Results:
   Training - Loss: 6476.0156, RMSE: 80.4737, R²: -0.0048
   Validation - Loss: 6262.8345, RMSE: 79.1381, R²: -0.0138
💾 Training metrics saved to: logs/client_24_training_metrics_20251030_022518.csv

🧪 Round 5 Evaluation Results:
   Test Loss: 6072.2677
   RMSE: 77.9248, MAE: 64.0583, R²: -0.0014
💾 Test metrics saved to: logs/client_24_test_metrics_20251030_022518.csv
⏩ Skipping CV for Round 6 (runs every 5 rounds)

🎯 Round 6 Training Results:
   Training - Loss: 6457.8057, RMSE: 80.3605, R²: -0.0020
   Validation - Loss: 6230.0337, RMSE: 78.9306, R²: -0.0085
💾 Training metrics saved to: logs/client_24_training_metrics_20251030_022518.csv

🧪 Round 6 Evaluation Results:
   Test Loss: 6068.2489
   RMSE: 77.8990, MAE: 64.0852, R²: -0.0007
💾 Test metrics saved to: logs/client_24_test_metrics_20251030_022518.csv
⏩ Skipping CV for Round 7 (runs every 5 rounds)
Round 7: train_loss=6499.0122, val_loss=6298.8901, val_r2=-0.0197

🧪 Round 7 Evaluation Results:
   Test Loss: 6069.3645
   RMSE: 77.9061, MAE: 64.0747, R²: -0.0009
💾 Test metrics saved to: logs/client_24_test_metrics_20251030_022518.csv
⏩ Skipping CV for Round 8 (runs every 5 rounds)
Round 8: train_loss=6477.8540, val_loss=6265.8657, val_r2=-0.0143
💾 Training metrics saved to: logs/client_24_training_metrics_20251030_022518.csv

🧪 Round 8 Evaluation Results:
   Test Loss: 6066.0783
   RMSE: 77.8850, MAE: 64.1112, R²: -0.0003
💾 Test metrics saved to: logs/client_24_test_metrics_20251030_022518.csv

🔍 Running 3-fold cross-validation (Round 9)
💾 CV metrics saved to: logs/client_24_cv_metrics_20251030_022518.csv

🎯 Round 9 Training Results:
   Training - Loss: 6466.5054, RMSE: 80.4146, R²: -0.0033
   Validation - Loss: 6246.4932, RMSE: 79.0348, R²: -0.0112
💾 Training metrics saved to: logs/client_24_training_metrics_20251030_022518.csv

🧪 Round 9 Evaluation Results:
   Test Loss: 6070.2245
   RMSE: 77.9116, MAE: 64.0695, R²: -0.0010
💾 Test metrics saved to: logs/client_24_test_metrics_20251030_022518.csv

🔍 Running 3-fold cross-validation (Round 10)
💾 CV metrics saved to: logs/client_24_cv_metrics_20251030_022518.csv

🎯 Round 10 Training Results:
   Training - Loss: 6452.8867, RMSE: 80.3299, R²: -0.0012
   Validation - Loss: 6219.4756, RMSE: 78.8637, R²: -0.0068
💾 Training metrics saved to: logs/client_24_training_metrics_20251030_022518.csv

🧪 Round 10 Evaluation Results:
   Test Loss: 6067.1103
   RMSE: 77.8917, MAE: 64.0977, R²: -0.0005
💾 Test metrics saved to: logs/client_24_test_metrics_20251030_022518.csv

================================================================================
🎯 FINAL COMPREHENSIVE REPORT
================================================================================
💾 Final summary saved to: logs/client_24_final_summary_20251030_022518.csv

📊 CLIENT: client_24 | ALGORITHM: fedavg | MODEL: LSTM
📈 TOTAL ROUNDS: 10

⚙️  HYPERPARAMETERS:
   Learning Rate: 0.001
   Batch Size: 32
   Local Epochs: 1
   Hidden Dim: 64
   Num Layers: 2
   Sequence Length: 10
   Use Attention: False
   Dropout: 0.3
   Optimizer: adam

🏁 FINAL ROUND PERFORMANCE:
   Training   - Loss:  6452.89 | RMSE:  80.33 | R²: -0.0012
   Validation - Loss:  6219.48 | RMSE:  78.86 | R²: -0.0068
   Test       - Loss:  6067.11 | RMSE:  77.89 | R²: -0.0005

📊 STATISTICS ACROSS ALL ROUNDS (Mean ± Std):
   Training Loss:    6468.76 ±   9.21
   Validation Loss:  6249.63 ±  16.97
   Test Loss:        6379.01 ± 926.95

   Training RMSE:    80.43 ±  0.06
   Validation RMSE:  79.05 ±  0.11
   Test RMSE:        79.69 ±  5.34

   Training R²:     -0.0037 ± 0.0014
   Validation R²:   -0.0117 ± 0.0027
   Test R²:         -0.0520 ± 0.1529

⭐ BEST PERFORMANCE:
   Best Round: 8 (Test R²: -0.0003)

📋 DATA SUMMARY:
   Training samples:   3287
   Validation samples: 1089
   Test samples:       1090
   Total samples:      5466
================================================================================
✅ Client client_24 completed | Algorithm: FEDAVG
