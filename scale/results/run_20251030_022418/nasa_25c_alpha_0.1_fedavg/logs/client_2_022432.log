[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: get_parameters message 93bb8c74-6776-4841-9f3b-b69e0ffe8bae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7fb02bee-ea47-4fc2-9ef4-b60fd89e18d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7c8d8961-2001-4dc1-922b-a42896584d98
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0067371f-6516-4b82-924d-6a59ee5f65d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dbadcbb6-0f3a-4aae-8886-dcb92d755598
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 833ad8a9-4d57-4c14-b27f-2118e23f197a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f22b9560-c43b-4550-8d27-0858fe962358
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 932b50d7-7d60-4efc-a1e2-96d4d3c22f84
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6d02c8d9-fb6f-4252-b55e-174a1d9eb60f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 16dbc943-96ff-4a95-b023-e7f9c502e60c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8a3d449e-a6b5-4c18-96ba-d4fe22ecfe65
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 92069815-cd89-4916-96bb-2c6505768ccd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a448e989-6ac1-4429-8d41-f900a48df725
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e3f31c2b-6e68-48c2-bce3-37e4d052e26e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 380823b1-eaa8-461b-8ca9-998be88af150
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 213dad1f-caae-4061-8a59-0cda03ba1e35
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1d97a6d0-6635-4d95-9402-cdc4e65ff149
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ffe4fc54-5a84-474b-9c77-f72d148e1bde
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4ec3525c-67e0-449e-9df1-d26d01675a4f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message db9a7c60-760d-4304-9a7a-0baf1087880a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: reconnect message 17498590-fba8-4e3c-92f8-ee35fd26c2df
[92mINFO [0m:      Disconnect and shut down
ğŸš€ Starting NASA FL Client: client_2
Algorithm: FEDAVG
Server: localhost:8686
K-Folds: 5
Log Directory: logs
ğŸ”„ Using device: cuda
ğŸ¯ GPU: NVIDIA A100-SXM4-80GB
ğŸ’¾ Hyperparameters saved to: logs/client_2_hyperparams_20251030_022435.csv
ğŸ” Looking for data at: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.1/client_2
ğŸ“Š Loaded 7847 total samples from /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.1/client_2
ğŸ”¢ Original feature dimension: 24
ğŸ” Applying KernelPCA with 5 components, kernel=poly
ğŸ“Š Data shape - Before: (4707, 24), After: (4707, 5)
ğŸ”„ Created sequences with length 10
   Final dataset shape: X (4697, 10, 5), y (4697,)
âœ… Data split completed:
   Training samples: 4697
   Validation samples: 1560
   Test samples: 1560
   Model type: lstm
   Final input dimension: 5
âœ… Client client_2 ready:
   Model: LSTM
   Training: 4697 samples
   Device: cuda
   Validation: 1560 samples
   Test: 1560 samples
   Algorithm: fedavg
   Total Rounds: 10
   Learning Rate: 0.001
   Batch Size: 32
   Logging to: logs

ğŸ§ª Round 0 Evaluation Results:
   Test Loss: 9522.9199
   RMSE: 97.5854, MAE: 76.0813, RÂ²: -0.6061
ğŸ’¾ Test metrics saved to: logs/client_2_test_metrics_20251030_022435.csv
â© Skipping CV for Round 2 (runs every 5 rounds)
Round 2: train_loss=6372.2842, val_loss=6448.9541, val_r2=-0.0119
ğŸ’¾ Training metrics saved to: logs/client_2_training_metrics_20251030_022435.csv

ğŸ§ª Round 2 Evaluation Results:
   Test Loss: 5982.9004
   RMSE: 77.3492, MAE: 62.8011, RÂ²: -0.0091
ğŸ’¾ Test metrics saved to: logs/client_2_test_metrics_20251030_022435.csv
â© Skipping CV for Round 3 (runs every 5 rounds)

ğŸ¯ Round 3 Training Results:
   Training - Loss: 6406.1553, RMSE: 80.0385, RÂ²: -0.0145
   Validation - Loss: 6487.1836, RMSE: 80.5431, RÂ²: -0.0179

ğŸ§ª Round 3 Evaluation Results:
   Test Loss: 5985.1786
   RMSE: 77.3639, MAE: 62.8019, RÂ²: -0.0095
ğŸ’¾ Test metrics saved to: logs/client_2_test_metrics_20251030_022435.csv
â© Skipping CV for Round 4 (runs every 5 rounds)
Round 4: train_loss=6354.1401, val_loss=6427.9243, val_r2=-0.0086
ğŸ’¾ Training metrics saved to: logs/client_2_training_metrics_20251030_022435.csv

ğŸ§ª Round 4 Evaluation Results:
   Test Loss: 5974.0723
   RMSE: 77.2921, MAE: 62.7979, RÂ²: -0.0076
ğŸ’¾ Test metrics saved to: logs/client_2_test_metrics_20251030_022435.csv

ğŸ” Running 3-fold cross-validation (Round 5)

ğŸ” Starting 3-fold cross-validation on TRAINING data for client client_2

ğŸ“Š Fold 1/3
   Fold 1 Results:
     Val Loss: 6464.9419
     Val RMSE: 80.4049, Val RÂ²: -0.0060

ğŸ“Š Fold 2/3
   Fold 2 Results:
     Val Loss: 6425.9731
     Val RMSE: 80.1622, Val RÂ²: -0.0047

ğŸ“Š Fold 3/3
   Fold 3 Results:
     Val Loss: 6188.4180
     Val RMSE: 78.6665, Val RÂ²: -0.0112
ğŸ’¾ CV metrics saved to: logs/client_2_cv_metrics_20251030_022435.csv

ğŸ“ˆ 3-Fold CV Summary (Training Data):
   VAL_LOSS: 6359.7777 Â± 122.2095
   RMSE: 79.7445 Â± 0.7687
   R2: -0.0073 Â± 0.0028

ğŸ¯ Round 5 Training Results:
   Training - Loss: 6389.6167, RMSE: 79.9351, RÂ²: -0.0119
   Validation - Loss: 6468.6411, RMSE: 80.4279, RÂ²: -0.0150
ğŸ’¾ Training metrics saved to: logs/client_2_training_metrics_20251030_022435.csv

ğŸ§ª Round 5 Evaluation Results:
   Test Loss: 5980.7818
   RMSE: 77.3355, MAE: 62.8004, RÂ²: -0.0087
ğŸ’¾ Test metrics saved to: logs/client_2_test_metrics_20251030_022435.csv
â© Skipping CV for Round 6 (runs every 5 rounds)

ğŸ¯ Round 6 Training Results:
   Training - Loss: 6346.1558, RMSE: 79.6628, RÂ²: -0.0050
   Validation - Loss: 6418.4619, RMSE: 80.1153, RÂ²: -0.0071
ğŸ’¾ Training metrics saved to: logs/client_2_training_metrics_20251030_022435.csv

ğŸ§ª Round 6 Evaluation Results:
   Test Loss: 5969.7724
   RMSE: 77.2643, MAE: 62.7983, RÂ²: -0.0069
ğŸ’¾ Test metrics saved to: logs/client_2_test_metrics_20251030_022435.csv
â© Skipping CV for Round 7 (runs every 5 rounds)
Round 7: train_loss=6366.6748, val_loss=6442.5078, val_r2=-0.0109

ğŸ§ª Round 7 Evaluation Results:
   Test Loss: 5973.0743
   RMSE: 77.2857, MAE: 62.7975, RÂ²: -0.0074
ğŸ’¾ Test metrics saved to: logs/client_2_test_metrics_20251030_022435.csv
â© Skipping CV for Round 8 (runs every 5 rounds)
Round 8: train_loss=6346.8945, val_loss=6419.3442, val_r2=-0.0073
ğŸ’¾ Training metrics saved to: logs/client_2_training_metrics_20251030_022435.csv

ğŸ§ª Round 8 Evaluation Results:
   Test Loss: 5962.2974
   RMSE: 77.2159, MAE: 62.8007, RÂ²: -0.0056
ğŸ’¾ Test metrics saved to: logs/client_2_test_metrics_20251030_022435.csv

ğŸ” Running 3-fold cross-validation (Round 9)
ğŸ’¾ CV metrics saved to: logs/client_2_cv_metrics_20251030_022435.csv

ğŸ¯ Round 9 Training Results:
   Training - Loss: 6375.4941, RMSE: 79.8467, RÂ²: -0.0097
   Validation - Loss: 6452.6245, RMSE: 80.3282, RÂ²: -0.0125
ğŸ’¾ Training metrics saved to: logs/client_2_training_metrics_20251030_022435.csv

ğŸ§ª Round 9 Evaluation Results:
   Test Loss: 5975.4692
   RMSE: 77.3012, MAE: 62.7984, RÂ²: -0.0078
ğŸ’¾ Test metrics saved to: logs/client_2_test_metrics_20251030_022435.csv

ğŸ” Running 3-fold cross-validation (Round 10)
ğŸ’¾ CV metrics saved to: logs/client_2_cv_metrics_20251030_022435.csv

ğŸ¯ Round 10 Training Results:
   Training - Loss: 6333.4683, RMSE: 79.5831, RÂ²: -0.0030
   Validation - Loss: 6402.9668, RMSE: 80.0185, RÂ²: -0.0047
ğŸ’¾ Training metrics saved to: logs/client_2_training_metrics_20251030_022435.csv

ğŸ§ª Round 10 Evaluation Results:
   Test Loss: 5966.0818
   RMSE: 77.2404, MAE: 62.7995, RÂ²: -0.0062
ğŸ’¾ Test metrics saved to: logs/client_2_test_metrics_20251030_022435.csv

================================================================================
ğŸ¯ FINAL COMPREHENSIVE REPORT
================================================================================
ğŸ’¾ Final summary saved to: logs/client_2_final_summary_20251030_022435.csv

ğŸ“Š CLIENT: client_2 | ALGORITHM: fedavg | MODEL: LSTM
ğŸ“ˆ TOTAL ROUNDS: 10

âš™ï¸  HYPERPARAMETERS:
   Learning Rate: 0.001
   Batch Size: 32
   Local Epochs: 1
   Hidden Dim: 64
   Num Layers: 2
   Sequence Length: 10
   Use Attention: False
   Dropout: 0.3
   Optimizer: adam

ğŸ FINAL ROUND PERFORMANCE:
   Training   - Loss:  6333.47 | RMSE:  79.58 | RÂ²: -0.0030
   Validation - Loss:  6402.97 | RMSE:  80.02 | RÂ²: -0.0047
   Test       - Loss:  5966.08 | RMSE:  77.24 | RÂ²: -0.0062

ğŸ“Š STATISTICS ACROSS ALL ROUNDS (Mean Â± Std):
   Training Loss:    6359.72 Â±  18.40
   Validation Loss:  6434.13 Â±  21.47
   Test Loss:        6329.25 Â± 1064.58

   Training RMSE:    79.75 Â±  0.12
   Validation RMSE:  80.21 Â±  0.13
   Test RMSE:        79.32 Â±  6.09

   Training RÂ²:     -0.0072 Â± 0.0029
   Validation RÂ²:   -0.0096 Â± 0.0034
   Test RÂ²:         -0.0675 Â± 0.1796

â­ BEST PERFORMANCE:
   Best Round: 8 (Test RÂ²: -0.0056)

ğŸ“‹ DATA SUMMARY:
   Training samples:   4697
   Validation samples: 1560
   Test samples:       1560
   Total samples:      7817
================================================================================
âœ… Client client_2 completed | Algorithm: FEDAVG
