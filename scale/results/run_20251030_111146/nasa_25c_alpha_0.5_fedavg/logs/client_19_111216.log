[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 983ab25a-70dd-47d8-9daa-d4faba2a1bea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 16f4484b-ce2f-424f-b9de-d9ff8195e9f7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a06c1b6e-ef68-4d17-8b70-efe684b2afb8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f178092a-0ba7-4648-85b2-40c0866567cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message acc2373c-06f3-450f-9b74-061840d92bf0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 13676511-df0c-48a0-bb01-addb29a0eae5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5308e3b2-6936-4cb7-8e6b-361172302673
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dccb97b8-d382-474c-9f67-09d6b194c94e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a8c8eea5-cf66-4ddb-b36b-502838e15328
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8e7cd647-1505-41ac-aa76-e6e1f454ecac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6c7be040-319e-4863-8c6a-faab898d6717
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b8c194be-9807-4aaf-8b9e-43348822b229
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 08b42432-4e0f-4cde-87dd-6b480793fc45
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0ceb3bcd-f6e2-4711-8561-27aa5eefd8f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 53a0f663-b1a0-4fca-bf72-338f1ecfc58d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d9f1272b-2b6c-4617-a0eb-7b4cc1fc5c42
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 91d4f77a-cd5d-4347-abd3-4567e1ea2c61
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e69a6e7f-e127-4e91-9563-3818ad1553c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6aebc5cd-629b-4d3f-8f1d-6e6c1b723b34
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: reconnect message 52d2ca4a-7b34-4a39-be56-291b9acd1caa
[92mINFO [0m:      Disconnect and shut down
🚀 Starting NASA FL Client: client_19
Algorithm: FEDAVG
Server: localhost:8686
K-Folds: 5
Log Directory: logs
🔄 Using device: cuda
🎯 GPU: NVIDIA A100-SXM4-80GB
🛑 Early stopping enabled:
   Patience: 3 epochs
   Min delta: 0.001
💾 Hyperparameters saved to: logs/client_19_hyperparams_20251030_111221.csv
🔍 Looking for data at: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.5/client_19
📊 Loaded 5558 total samples from /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.5/client_19
🔢 Original feature dimension: 24
🔍 Applying KernelPCA with 5 components, kernel=poly
📊 Data shape - Before: (3334, 24), After: (3334, 5)
🔄 Created sequences with length 10
   Final dataset shape: X (3324, 10, 5), y (3324,)
✅ Data split completed:
   Training samples: 3324
   Validation samples: 1102
   Test samples: 1102
   Model type: lstm
   Final input dimension: 5
✅ Client client_19 ready:
   Model: LSTM
   Training: 3324 samples
   Device: cuda
   Validation: 1102 samples
   Test: 1102 samples
   Algorithm: fedavg
   Total Rounds: 10
   Learning Rate: 0.001
   Batch Size: 32
   Logging to: logs

🧪 Round 0 Evaluation Results:
   Test Loss: 14253.9306
   RMSE: 119.3898, MAE: 89.9398, R²: -0.6862
💾 Test metrics saved to: logs/client_19_test_metrics_20251030_111221.csv
⏩ Skipping CV for Round 2

🔄 Starting local training (Round 2)...
   Epoch 1/1: train_loss=12064.8608, val_rmse=94.2049 ⭐ (improved by inf)
   ✅ Completed 1 epochs, using best model (val_rmse=94.2049)
Round 2: epochs=1, train_loss=9605.9609, val_rmse=94.2049, val_r2=-0.0283
💾 Training metrics saved to: logs/client_19_training_metrics_20251030_111221.csv

🧪 Round 2 Evaluation Results:
   Test Loss: 9064.3730
   RMSE: 95.2070, MAE: 73.6106, R²: -0.0723
💾 Test metrics saved to: logs/client_19_test_metrics_20251030_111221.csv
⏩ Skipping CV for Round 3

🔄 Starting local training (Round 3)...
   Epoch 1/1: train_loss=10821.6649, val_rmse=94.6511 ⭐ (improved by inf)
   ✅ Completed 1 epochs, using best model (val_rmse=94.6511)

🎯 Round 3 Training Summary:
   Epochs trained: 1/1
   Total early stops so far: 0
   Training   - Loss: 9696.4150, RMSE: 98.4704, R²: -0.0402
   Validation - Loss: 8958.8271, RMSE: 94.6511, R²: -0.0381

🧪 Round 3 Evaluation Results:
   Test Loss: 9047.9333
   RMSE: 95.1206, MAE: 73.5735, R²: -0.0703
💾 Test metrics saved to: logs/client_19_test_metrics_20251030_111221.csv
⏩ Skipping CV for Round 4

🔄 Starting local training (Round 4)...
   Epoch 1/1: train_loss=10851.9069, val_rmse=94.5213 ⭐ (improved by inf)
   ✅ Completed 1 epochs, using best model (val_rmse=94.5213)
Round 4: epochs=1, train_loss=9670.1475, val_rmse=94.5213, val_r2=-0.0352
💾 Training metrics saved to: logs/client_19_training_metrics_20251030_111221.csv

🧪 Round 4 Evaluation Results:
   Test Loss: 9014.3195
   RMSE: 94.9438, MAE: 73.5024, R²: -0.0664
💾 Test metrics saved to: logs/client_19_test_metrics_20251030_111221.csv

🔍 Running 3-fold cross-validation (Round 5)

🔍 Starting 3-fold cross-validation on TRAINING data for client client_19

📊 Fold 1/3
   Fold 1 Results:
     Val Loss: 8886.2979
     Val RMSE: 94.2672, Val R²: -0.0160

📊 Fold 2/3
   Fold 2 Results:
     Val Loss: 9783.0156
     Val RMSE: 98.9091, Val R²: -0.0143

📊 Fold 3/3
   Fold 3 Results:
     Val Loss: 9744.0352
     Val RMSE: 98.7119, Val R²: -0.0183
💾 CV metrics saved to: logs/client_19_cv_metrics_20251030_111221.csv

📈 3-Fold CV Summary (Training Data):
   VAL_LOSS: 9471.1162 ± 413.8351
   RMSE: 97.2961 ± 2.1433
   R2: -0.0162 ± 0.0017

🔄 Starting local training (Round 5)...
   Epoch 1/1: train_loss=10771.0290, val_rmse=94.2736 ⭐ (improved by inf)
   ✅ Completed 1 epochs, using best model (val_rmse=94.2736)

🎯 Round 5 Training Summary:
   Epochs trained: 1/1
   Total early stops so far: 0
   Training   - Loss: 9619.9121, RMSE: 98.0812, R²: -0.0320
   Validation - Loss: 8887.5078, RMSE: 94.2736, R²: -0.0298
💾 Training metrics saved to: logs/client_19_training_metrics_20251030_111221.csv

🧪 Round 5 Evaluation Results:
   Test Loss: 9028.1527
   RMSE: 95.0166, MAE: 73.5319, R²: -0.0680
💾 Test metrics saved to: logs/client_19_test_metrics_20251030_111221.csv
⏩ Skipping CV for Round 6

🔄 Starting local training (Round 6)...
   Epoch 1/1: train_loss=10823.4115, val_rmse=94.3365 ⭐ (improved by inf)
   ✅ Completed 1 epochs, using best model (val_rmse=94.3365)

🎯 Round 6 Training Summary:
   Epochs trained: 1/1
   Total early stops so far: 0
   Training   - Loss: 9632.6895, RMSE: 98.1463, R²: -0.0334
   Validation - Loss: 8899.3779, RMSE: 94.3365, R²: -0.0312
💾 Training metrics saved to: logs/client_19_training_metrics_20251030_111221.csv

🧪 Round 6 Evaluation Results:
   Test Loss: 9010.1291
   RMSE: 94.9217, MAE: 73.4934, R²: -0.0659
💾 Test metrics saved to: logs/client_19_test_metrics_20251030_111221.csv
⏩ Skipping CV for Round 7

🔄 Starting local training (Round 7)...
   Epoch 1/1: train_loss=10881.5613, val_rmse=94.2660 ⭐ (improved by inf)
   ✅ Completed 1 epochs, using best model (val_rmse=94.2660)
Round 7: epochs=1, train_loss=9618.3682, val_rmse=94.2660, val_r2=-0.0296

🧪 Round 7 Evaluation Results:
   Test Loss: 9039.8323
   RMSE: 95.0780, MAE: 73.5565, R²: -0.0694
💾 Test metrics saved to: logs/client_19_test_metrics_20251030_111221.csv
⏩ Skipping CV for Round 8

🔄 Starting local training (Round 8)...
   Epoch 1/1: train_loss=10789.1064, val_rmse=94.3794 ⭐ (improved by inf)
   ✅ Completed 1 epochs, using best model (val_rmse=94.3794)
Round 8: epochs=1, train_loss=9641.3838, val_rmse=94.3794, val_r2=-0.0321
💾 Training metrics saved to: logs/client_19_training_metrics_20251030_111221.csv

🧪 Round 8 Evaluation Results:
   Test Loss: 9036.7963
   RMSE: 95.0621, MAE: 73.5502, R²: -0.0690
💾 Test metrics saved to: logs/client_19_test_metrics_20251030_111221.csv

🔍 Running 3-fold cross-validation (Round 9)
💾 CV metrics saved to: logs/client_19_cv_metrics_20251030_111221.csv

🔄 Starting local training (Round 9)...
   Epoch 1/1: train_loss=10366.2233, val_rmse=93.8806 ⭐ (improved by inf)
   ✅ Completed 1 epochs, using best model (val_rmse=93.8806)

🎯 Round 9 Training Summary:
   Epochs trained: 1/1
   Total early stops so far: 0
   Training   - Loss: 9539.7666, RMSE: 97.6717, R²: -0.0234
   Validation - Loss: 8813.5703, RMSE: 93.8806, R²: -0.0212
💾 Training metrics saved to: logs/client_19_training_metrics_20251030_111221.csv

🧪 Round 9 Evaluation Results:
   Test Loss: 9023.6169
   RMSE: 94.9927, MAE: 73.5223, R²: -0.0675
💾 Test metrics saved to: logs/client_19_test_metrics_20251030_111221.csv

🔍 Running 3-fold cross-validation (Round 10)
💾 CV metrics saved to: logs/client_19_cv_metrics_20251030_111221.csv

🔄 Starting local training (Round 10)...
   Epoch 1/1: train_loss=11008.1863, val_rmse=94.3402 ⭐ (improved by inf)
   ✅ Completed 1 epochs, using best model (val_rmse=94.3402)

🎯 Round 10 Training Summary:
   Epochs trained: 1/1
   Total early stops so far: 0
   Training   - Loss: 9633.4434, RMSE: 98.1501, R²: -0.0335
   Validation - Loss: 8900.0762, RMSE: 94.3402, R²: -0.0313
💾 Training metrics saved to: logs/client_19_training_metrics_20251030_111221.csv

🧪 Round 10 Evaluation Results:
   Test Loss: 9006.7646
   RMSE: 94.9040, MAE: 73.4862, R²: -0.0655
💾 Test metrics saved to: logs/client_19_test_metrics_20251030_111221.csv

================================================================================
🎯 FINAL COMPREHENSIVE REPORT
================================================================================
💾 Final summary saved to: logs/client_19_final_summary_20251030_111221.csv

📊 CLIENT: client_19 | ALGORITHM: fedavg | MODEL: LSTM
📈 TOTAL ROUNDS: 10

⚙️  HYPERPARAMETERS:
   Learning Rate: 0.001
   Batch Size: 32
   Local Epochs: 1
   Hidden Dim: 64
   Num Layers: 2
   Sequence Length: 10
   Use Attention: False
   Dropout: 0.3
   Optimizer: adam

🛑 EARLY STOPPING SUMMARY:
   Enabled: Yes
   Patience: 3 epochs
   Min delta: 0.001
   Total early stops: 0/10 rounds
   Early stop rate: 0.0%

🏁 FINAL ROUND PERFORMANCE:
   Training   - Loss:  9633.44 | RMSE:  98.15 | R²: -0.0335
   Validation - Loss:  8900.08 | RMSE:  94.34 | R²: -0.0313
   Test       - Loss:  9006.76 | RMSE:  94.90 | R²: -0.0655

📊 STATISTICS ACROSS ALL ROUNDS (Mean ± Std):
   Training Loss:    9620.47 ±  37.70
   Validation Loss:  8888.12 ±  34.88
   Test Loss:        9552.58 ± 1567.21

   Training RMSE:    98.08 ±  0.19
   Validation RMSE:  94.28 ±  0.19
   Test RMSE:        97.46 ±  7.31

   Training R²:     -0.0321 ± 0.0040
   Validation R²:   -0.0299 ± 0.0040
   Test R²:         -0.1300 ± 0.1854

⭐ BEST PERFORMANCE:
   Best Round: 10 (Test R²: -0.0655)

📋 DATA SUMMARY:
   Training samples:   3324
   Validation samples: 1102
   Test samples:       1102
   Total samples:      5528
================================================================================
✅ Client client_19 completed | Algorithm: FEDAVG
