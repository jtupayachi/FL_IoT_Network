[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 78a0ea10-be31-4412-9994-7a7f3f147616
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5112f69c-cfb2-4fb0-8af4-1fa0b09f586e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eabb30a9-b647-4e5e-94a6-f335d529b76b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ac7eed7c-e604-4f15-8640-3bad5b0d103d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9a662eb0-0926-4d6d-a64d-d9ad0c0cc5b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5d08209c-a7a4-42f9-aae6-5f3311fca6d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e2d5baa1-1a9a-49de-9338-993006ed689c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 516c788c-1e1a-4c82-95b2-063f90f67ae1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 048e846b-d980-4051-b4dc-a7f301975c46
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 41e0783a-e895-4868-b903-7b503f1f6f1c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f05e3f23-5564-4169-8a2a-a5883ab060a3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ce482470-7c23-4cc0-b7d5-3a4fa5376a95
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 996d2faa-b83d-4d30-a50f-24be21c21539
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b5a53960-c242-471b-b03c-4be2f6d0b03f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 253f40e7-ac5c-47df-845c-5d27cccf8de3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4cdb526f-74b4-4efd-9af7-5166c8089b70
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 85c2b7e1-f587-45d9-8886-b5e202e75f47
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8dec4c0b-490e-4fde-a5ee-e44d9ce86887
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ecddb79c-3dee-4887-b70d-f07fd744385d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: reconnect message c34f9fb3-126b-463b-91e4-5201cc60d8fc
[92mINFO [0m:      Disconnect and shut down
🚀 Starting NASA FL Client: client_21
Algorithm: FEDAVG
Server: localhost:8686
K-Folds: 5
Log Directory: logs
🔄 Using device: cuda
🎯 GPU: NVIDIA A100-SXM4-80GB
🛑 Early stopping enabled:
   Patience: 3 epochs
   Min delta: 0.001
💾 Hyperparameters saved to: logs/client_21_hyperparams_20251030_111222.csv
🔍 Looking for data at: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.5/client_21
📊 Loaded 6245 total samples from /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.5/client_21
🔢 Original feature dimension: 24
🔍 Applying KernelPCA with 5 components, kernel=poly
📊 Data shape - Before: (3747, 24), After: (3747, 5)
🔄 Created sequences with length 10
   Final dataset shape: X (3737, 10, 5), y (3737,)
✅ Data split completed:
   Training samples: 3737
   Validation samples: 1239
   Test samples: 1239
   Model type: lstm
   Final input dimension: 5
✅ Client client_21 ready:
   Model: LSTM
   Training: 3737 samples
   Device: cuda
   Validation: 1239 samples
   Test: 1239 samples
   Algorithm: fedavg
   Total Rounds: 10
   Learning Rate: 0.001
   Batch Size: 32
   Logging to: logs

🧪 Round 0 Evaluation Results:
   Test Loss: 9566.0576
   RMSE: 97.8062, MAE: 74.4721, R²: -0.5644
💾 Test metrics saved to: logs/client_21_test_metrics_20251030_111222.csv
⏩ Skipping CV for Round 2

🔄 Starting local training (Round 2)...
   Epoch 1/1: train_loss=7894.2683, val_rmse=81.3982 ⭐ (improved by inf)
   ✅ Completed 1 epochs, using best model (val_rmse=81.3982)
Round 2: epochs=1, train_loss=6399.1128, val_rmse=81.3982, val_r2=-0.0270
💾 Training metrics saved to: logs/client_21_training_metrics_20251030_111222.csv

🧪 Round 2 Evaluation Results:
   Test Loss: 6168.2832
   RMSE: 78.5384, MAE: 62.7368, R²: -0.0087
💾 Test metrics saved to: logs/client_21_test_metrics_20251030_111222.csv
⏩ Skipping CV for Round 3

🔄 Starting local training (Round 3)...
   Epoch 1/1: train_loss=7670.0888, val_rmse=81.9385 ⭐ (improved by inf)
   ✅ Completed 1 epochs, using best model (val_rmse=81.9385)

🎯 Round 3 Training Summary:
   Epochs trained: 1/1
   Total early stops so far: 0
   Training   - Loss: 6460.6655, RMSE: 80.3783, R²: -0.0219
   Validation - Loss: 6713.9150, RMSE: 81.9385, R²: -0.0407

🧪 Round 3 Evaluation Results:
   Test Loss: 6163.5042
   RMSE: 78.5080, MAE: 62.7444, R²: -0.0079
💾 Test metrics saved to: logs/client_21_test_metrics_20251030_111222.csv
⏩ Skipping CV for Round 4

🔄 Starting local training (Round 4)...
   Epoch 1/1: train_loss=7507.6406, val_rmse=81.1341 ⭐ (improved by inf)
   ✅ Completed 1 epochs, using best model (val_rmse=81.1341)
Round 4: epochs=1, train_loss=6371.6641, val_rmse=81.1341, val_r2=-0.0203
💾 Training metrics saved to: logs/client_21_training_metrics_20251030_111222.csv

🧪 Round 4 Evaluation Results:
   Test Loss: 6154.2455
   RMSE: 78.4490, MAE: 62.7653, R²: -0.0064
💾 Test metrics saved to: logs/client_21_test_metrics_20251030_111222.csv

🔍 Running 3-fold cross-validation (Round 5)

🔍 Starting 3-fold cross-validation on TRAINING data for client client_21

📊 Fold 1/3
   Fold 1 Results:
     Val Loss: 6612.9663
     Val RMSE: 81.3201, Val R²: -0.0106

📊 Fold 2/3
   Fold 2 Results:
     Val Loss: 5899.9126
     Val RMSE: 76.8109, Val R²: -0.0009

📊 Fold 3/3
   Fold 3 Results:
     Val Loss: 6639.9126
     Val RMSE: 81.4857, Val R²: -0.0184
💾 CV metrics saved to: logs/client_21_cv_metrics_20251030_111222.csv

📈 3-Fold CV Summary (Training Data):
   VAL_LOSS: 6384.2638 ± 342.6647
   RMSE: 79.8722 ± 2.1657
   R2: -0.0100 ± 0.0071

🔄 Starting local training (Round 5)...
   Epoch 1/1: train_loss=7426.9788, val_rmse=81.4577 ⭐ (improved by inf)
   ✅ Completed 1 epochs, using best model (val_rmse=81.4577)

🎯 Round 5 Training Summary:
   Epochs trained: 1/1
   Total early stops so far: 0
   Training   - Loss: 6405.5781, RMSE: 80.0349, R²: -0.0131
   Validation - Loss: 6635.3574, RMSE: 81.4577, R²: -0.0285
💾 Training metrics saved to: logs/client_21_training_metrics_20251030_111222.csv

🧪 Round 5 Evaluation Results:
   Test Loss: 6157.9698
   RMSE: 78.4727, MAE: 62.7566, R²: -0.0070
💾 Test metrics saved to: logs/client_21_test_metrics_20251030_111222.csv
⏩ Skipping CV for Round 6

🔄 Starting local training (Round 6)...
   Epoch 1/1: train_loss=7400.0808, val_rmse=81.2320 ⭐ (improved by inf)
   ✅ Completed 1 epochs, using best model (val_rmse=81.2320)

🎯 Round 6 Training Summary:
   Epochs trained: 1/1
   Total early stops so far: 0
   Training   - Loss: 6381.5615, RMSE: 79.8847, R²: -0.0093
   Validation - Loss: 6598.6304, RMSE: 81.2320, R²: -0.0228
💾 Training metrics saved to: logs/client_21_training_metrics_20251030_111222.csv

🧪 Round 6 Evaluation Results:
   Test Loss: 6153.1420
   RMSE: 78.4420, MAE: 62.7679, R²: -0.0063
💾 Test metrics saved to: logs/client_21_test_metrics_20251030_111222.csv
⏩ Skipping CV for Round 7

🔄 Starting local training (Round 7)...
   Epoch 1/1: train_loss=7550.9325, val_rmse=81.7917 ⭐ (improved by inf)
   ✅ Completed 1 epochs, using best model (val_rmse=81.7917)
Round 7: epochs=1, train_loss=6443.3896, val_rmse=81.7917, val_r2=-0.0370

🧪 Round 7 Evaluation Results:
   Test Loss: 6161.2085
   RMSE: 78.4934, MAE: 62.7494, R²: -0.0076
💾 Test metrics saved to: logs/client_21_test_metrics_20251030_111222.csv
⏩ Skipping CV for Round 8

🔄 Starting local training (Round 8)...
   Epoch 1/1: train_loss=7522.5170, val_rmse=81.2665 ⭐ (improved by inf)
   ✅ Completed 1 epochs, using best model (val_rmse=81.2665)
Round 8: epochs=1, train_loss=6385.1357, val_rmse=81.2665, val_r2=-0.0237
💾 Training metrics saved to: logs/client_21_training_metrics_20251030_111222.csv

🧪 Round 8 Evaluation Results:
   Test Loss: 6160.3585
   RMSE: 78.4880, MAE: 62.7512, R²: -0.0074
💾 Test metrics saved to: logs/client_21_test_metrics_20251030_111222.csv

🔍 Running 3-fold cross-validation (Round 9)
💾 CV metrics saved to: logs/client_21_cv_metrics_20251030_111222.csv

🔄 Starting local training (Round 9)...
   Epoch 1/1: train_loss=7361.8859, val_rmse=81.7906 ⭐ (improved by inf)
   ✅ Completed 1 epochs, using best model (val_rmse=81.7906)

🎯 Round 9 Training Summary:
   Epochs trained: 1/1
   Total early stops so far: 0
   Training   - Loss: 6443.2593, RMSE: 80.2699, R²: -0.0191
   Validation - Loss: 6689.7026, RMSE: 81.7906, R²: -0.0369
💾 Training metrics saved to: logs/client_21_training_metrics_20251030_111222.csv

🧪 Round 9 Evaluation Results:
   Test Loss: 6156.7351
   RMSE: 78.4649, MAE: 62.7594, R²: -0.0068
💾 Test metrics saved to: logs/client_21_test_metrics_20251030_111222.csv

🔍 Running 3-fold cross-validation (Round 10)
💾 CV metrics saved to: logs/client_21_cv_metrics_20251030_111222.csv

🔄 Starting local training (Round 10)...
   Epoch 1/1: train_loss=7430.2953, val_rmse=81.1629 ⭐ (improved by inf)
   ✅ Completed 1 epochs, using best model (val_rmse=81.1629)

🎯 Round 10 Training Summary:
   Epochs trained: 1/1
   Total early stops so far: 0
   Training   - Loss: 6374.5376, RMSE: 79.8407, R²: -0.0082
   Validation - Loss: 6587.4141, RMSE: 81.1629, R²: -0.0211
💾 Training metrics saved to: logs/client_21_training_metrics_20251030_111222.csv

🧪 Round 10 Evaluation Results:
   Test Loss: 6152.2642
   RMSE: 78.4364, MAE: 62.7701, R²: -0.0061
💾 Test metrics saved to: logs/client_21_test_metrics_20251030_111222.csv

================================================================================
🎯 FINAL COMPREHENSIVE REPORT
================================================================================
💾 Final summary saved to: logs/client_21_final_summary_20251030_111222.csv

📊 CLIENT: client_21 | ALGORITHM: fedavg | MODEL: LSTM
📈 TOTAL ROUNDS: 10

⚙️  HYPERPARAMETERS:
   Learning Rate: 0.001
   Batch Size: 32
   Local Epochs: 1
   Hidden Dim: 64
   Num Layers: 2
   Sequence Length: 10
   Use Attention: False
   Dropout: 0.3
   Optimizer: adam

🛑 EARLY STOPPING SUMMARY:
   Enabled: Yes
   Patience: 3 epochs
   Min delta: 0.001
   Total early stops: 0/10 rounds
   Early stop rate: 0.0%

🏁 FINAL ROUND PERFORMANCE:
   Training   - Loss:  6374.54 | RMSE:  79.84 | R²: -0.0082
   Validation - Loss:  6587.41 | RMSE:  81.16 | R²: -0.0211
   Test       - Loss:  6152.26 | RMSE:  78.44 | R²: -0.0061

📊 STATISTICS ACROSS ALL ROUNDS (Mean ± Std):
   Training Loss:    6394.41 ±  22.98
   Validation Loss:  6617.68 ±  34.32
   Test Loss:        6499.38 ± 1022.24

   Training RMSE:    79.96 ±  0.14
   Validation RMSE:  81.35 ±  0.21
   Test RMSE:        80.41 ±  5.80

   Training R²:     -0.0114 ± 0.0036
   Validation R²:   -0.0258 ± 0.0053
   Test R²:         -0.0629 ± 0.1672

⭐ BEST PERFORMANCE:
   Best Round: 10 (Test R²: -0.0061)

📋 DATA SUMMARY:
   Training samples:   3737
   Validation samples: 1239
   Test samples:       1239
   Total samples:      6215
================================================================================
✅ Client client_21 completed | Algorithm: FEDAVG
