[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 34d89ed9-8642-42a9-a51d-15b0848a5c1a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dba396e2-b587-4b1e-8b6b-af87d4d7a70a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a0601f0d-795e-4189-83b4-5727de193029
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 33c996f5-ffbe-4ded-88c8-1b48f7c3f91c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c8ff0bad-fff5-4caf-b3fa-8712cc4e0b19
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9080e243-7594-43a1-a0e1-ec91f9704665
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c4847e7f-b0d9-4e72-9dd0-d64d250ee8af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e14d7cbd-c99f-4871-acc3-921695cda92b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1169df79-88b8-487c-856d-c003351fe520
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e2dd06b8-b315-49cb-a62e-5ce6c0b661f7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9d94f99d-21fb-48ac-b5da-299984b3b038
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 99c139e5-a7f5-4535-af8b-2d58f1fdddcf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4c560324-7337-4c35-a501-b73fef37a00d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 45dbb2c0-8760-4e0a-8dd2-bde93a40c062
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4e56f8cf-a791-429c-ab47-18e34e226aec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9a1f4fb8-b85c-4321-a511-81cb96818419
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 68498251-2b0a-4d29-bd9e-28e77c9aafb7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 71fb341f-6984-4f50-9b82-e0be10ab6015
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d7e34cb2-84c0-429a-b0be-5a0c489dd1df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 27aced41-8446-4e43-ad22-2ea670b04978
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: reconnect message 957062e6-3dce-4cd5-811a-0bb9c161b882
[92mINFO [0m:      Disconnect and shut down
ğŸš€ Starting NASA FL Client: client_4
Algorithm: FEDAVG
Server: localhost:8686
K-Folds: 5
Log Directory: logs
ğŸ”„ Using device: cuda
ğŸ¯ GPU: NVIDIA A100-SXM4-80GB
ğŸ›‘ Early stopping enabled:
   Patience: 3 epochs
   Min delta: 0.001
ğŸ’¾ Hyperparameters saved to: logs/client_4_hyperparams_20251030_111205.csv
ğŸ” Looking for data at: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.5/client_4
ğŸ“Š Loaded 7615 total samples from /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.5/client_4
ğŸ”¢ Original feature dimension: 24
ğŸ” Applying KernelPCA with 5 components, kernel=poly
ğŸ“Š Data shape - Before: (4569, 24), After: (4569, 5)
ğŸ”„ Created sequences with length 10
   Final dataset shape: X (4559, 10, 5), y (4559,)
âœ… Data split completed:
   Training samples: 4559
   Validation samples: 1513
   Test samples: 1513
   Model type: lstm
   Final input dimension: 5
âœ… Client client_4 ready:
   Model: LSTM
   Training: 4559 samples
   Device: cuda
   Validation: 1513 samples
   Test: 1513 samples
   Algorithm: fedavg
   Total Rounds: 10
   Learning Rate: 0.001
   Batch Size: 32
   Logging to: logs
â© Skipping CV for Round 1

ğŸ”„ Starting local training (Round 1)...
   Epoch 1/1: train_loss=26242.8305, val_rmse=118.9591 â­ (improved by inf)
   âœ… Completed 1 epochs, using best model (val_rmse=118.9591)
Round 1: epochs=1, train_loss=13415.8340, val_rmse=118.9591, val_r2=-0.3195

ğŸ§ª Round 1 Evaluation Results:
   Test Loss: 18167.2959
   RMSE: 134.7861, MAE: 101.2454, RÂ²: -0.7299
ğŸ’¾ Test metrics saved to: logs/client_4_test_metrics_20251030_111205.csv
â© Skipping CV for Round 2

ğŸ”„ Starting local training (Round 2)...
   Epoch 1/1: train_loss=13076.8329, val_rmse=104.5864 â­ (improved by inf)
   âœ… Completed 1 epochs, using best model (val_rmse=104.5864)
Round 2: epochs=1, train_loss=10542.6064, val_rmse=104.5864, val_r2=-0.0199
ğŸ’¾ Training metrics saved to: logs/client_4_training_metrics_20251030_111205.csv

ğŸ§ª Round 2 Evaluation Results:
   Test Loss: 11806.0625
   RMSE: 108.6557, MAE: 82.6395, RÂ²: -0.1242
ğŸ’¾ Test metrics saved to: logs/client_4_test_metrics_20251030_111205.csv
â© Skipping CV for Round 3

ğŸ”„ Starting local training (Round 3)...
   Epoch 1/1: train_loss=12184.9833, val_rmse=104.5167 â­ (improved by inf)
   âœ… Completed 1 epochs, using best model (val_rmse=104.5167)

ğŸ¯ Round 3 Training Summary:
   Epochs trained: 1/1
   Total early stops so far: 0
   Training   - Loss: 10531.9512, RMSE: 102.6253, RÂ²: -0.0101
   Validation - Loss: 10923.7402, RMSE: 104.5167, RÂ²: -0.0186

ğŸ§ª Round 3 Evaluation Results:
   Test Loss: 11781.9978
   RMSE: 108.5449, MAE: 82.5831, RÂ²: -0.1219
ğŸ’¾ Test metrics saved to: logs/client_4_test_metrics_20251030_111205.csv
â© Skipping CV for Round 4

ğŸ”„ Starting local training (Round 4)...
   Epoch 1/1: train_loss=12293.9551, val_rmse=104.4060 â­ (improved by inf)
   âœ… Completed 1 epochs, using best model (val_rmse=104.4060)
Round 4: epochs=1, train_loss=10515.3496, val_rmse=104.4060, val_r2=-0.0164
ğŸ’¾ Training metrics saved to: logs/client_4_training_metrics_20251030_111205.csv

ğŸ§ª Round 4 Evaluation Results:
   Test Loss: 11732.4576
   RMSE: 108.3165, MAE: 82.4708, RÂ²: -0.1171
ğŸ’¾ Test metrics saved to: logs/client_4_test_metrics_20251030_111205.csv

ğŸ” Running 3-fold cross-validation (Round 5)

ğŸ” Starting 3-fold cross-validation on TRAINING data for client client_4

ğŸ“Š Fold 1/3
   Fold 1 Results:
     Val Loss: 10631.4209
     Val RMSE: 103.1088, Val RÂ²: -0.0025

ğŸ“Š Fold 2/3
   Fold 2 Results:
     Val Loss: 10884.1768
     Val RMSE: 104.3273, Val RÂ²: -0.0377

ğŸ“Š Fold 3/3
   Fold 3 Results:
     Val Loss: 10247.3311
     Val RMSE: 101.2291, Val RÂ²: -0.0085
ğŸ’¾ CV metrics saved to: logs/client_4_cv_metrics_20251030_111205.csv

ğŸ“ˆ 3-Fold CV Summary (Training Data):
   VAL_LOSS: 10587.6429 Â± 261.8275
   RMSE: 102.8884 Â± 1.2744
   R2: -0.0162 Â± 0.0154

ğŸ”„ Starting local training (Round 5)...
   Epoch 1/1: train_loss=12197.2937, val_rmse=104.8777 â­ (improved by inf)
   âœ… Completed 1 epochs, using best model (val_rmse=104.8777)

ğŸ¯ Round 5 Training Summary:
   Epochs trained: 1/1
   Total early stops so far: 0
   Training   - Loss: 10588.4902, RMSE: 102.9004, RÂ²: -0.0155
   Validation - Loss: 10999.3301, RMSE: 104.8777, RÂ²: -0.0256
ğŸ’¾ Training metrics saved to: logs/client_4_training_metrics_20251030_111205.csv

ğŸ§ª Round 5 Evaluation Results:
   Test Loss: 11752.9016
   RMSE: 108.4108, MAE: 82.5174, RÂ²: -0.1191
ğŸ’¾ Test metrics saved to: logs/client_4_test_metrics_20251030_111205.csv
â© Skipping CV for Round 6

ğŸ”„ Starting local training (Round 6)...
   Epoch 1/1: train_loss=12313.8980, val_rmse=104.4098 â­ (improved by inf)
   âœ… Completed 1 epochs, using best model (val_rmse=104.4098)

ğŸ¯ Round 6 Training Summary:
   Epochs trained: 1/1
   Total early stops so far: 0
   Training   - Loss: 10515.9160, RMSE: 102.5471, RÂ²: -0.0085
   Validation - Loss: 10901.4053, RMSE: 104.4098, RÂ²: -0.0165
ğŸ’¾ Training metrics saved to: logs/client_4_training_metrics_20251030_111205.csv

ğŸ§ª Round 6 Evaluation Results:
   Test Loss: 11726.2483
   RMSE: 108.2878, MAE: 82.4566, RÂ²: -0.1166
ğŸ’¾ Test metrics saved to: logs/client_4_test_metrics_20251030_111205.csv
â© Skipping CV for Round 7

ğŸ”„ Starting local training (Round 7)...
   Epoch 1/1: train_loss=12298.0673, val_rmse=104.3871 â­ (improved by inf)
   âœ… Completed 1 epochs, using best model (val_rmse=104.3871)
Round 7: epochs=1, train_loss=10512.5586, val_rmse=104.3871, val_r2=-0.0161

ğŸ§ª Round 7 Evaluation Results:
   Test Loss: 11770.1003
   RMSE: 108.4901, MAE: 82.5564, RÂ²: -0.1207
ğŸ’¾ Test metrics saved to: logs/client_4_test_metrics_20251030_111205.csv
â© Skipping CV for Round 8

ğŸ”„ Starting local training (Round 8)...
   Epoch 1/1: train_loss=12302.9253, val_rmse=104.5351 â­ (improved by inf)
   âœ… Completed 1 epochs, using best model (val_rmse=104.5351)
Round 8: epochs=1, train_loss=10534.7451, val_rmse=104.5351, val_r2=-0.0189
ğŸ’¾ Training metrics saved to: logs/client_4_training_metrics_20251030_111205.csv

ğŸ§ª Round 8 Evaluation Results:
   Test Loss: 11765.6351
   RMSE: 108.4695, MAE: 82.5463, RÂ²: -0.1203
ğŸ’¾ Test metrics saved to: logs/client_4_test_metrics_20251030_111205.csv

ğŸ” Running 3-fold cross-validation (Round 9)
ğŸ’¾ CV metrics saved to: logs/client_4_cv_metrics_20251030_111205.csv

ğŸ”„ Starting local training (Round 9)...
   Epoch 1/1: train_loss=12081.9374, val_rmse=104.4931 â­ (improved by inf)
   âœ… Completed 1 epochs, using best model (val_rmse=104.4931)

ğŸ¯ Round 9 Training Summary:
   Epochs trained: 1/1
   Total early stops so far: 0
   Training   - Loss: 10528.3701, RMSE: 102.6079, RÂ²: -0.0097
   Validation - Loss: 10918.7988, RMSE: 104.4931, RÂ²: -0.0181
ğŸ’¾ Training metrics saved to: logs/client_4_training_metrics_20251030_111205.csv

ğŸ§ª Round 9 Evaluation Results:
   Test Loss: 11746.2070
   RMSE: 108.3799, MAE: 82.5022, RÂ²: -0.1185
ğŸ’¾ Test metrics saved to: logs/client_4_test_metrics_20251030_111205.csv

ğŸ” Running 3-fold cross-validation (Round 10)
ğŸ’¾ CV metrics saved to: logs/client_4_cv_metrics_20251030_111205.csv

ğŸ”„ Starting local training (Round 10)...
   Epoch 1/1: train_loss=12192.9669, val_rmse=104.3035 â­ (improved by inf)
   âœ… Completed 1 epochs, using best model (val_rmse=104.3035)

ğŸ¯ Round 10 Training Summary:
   Epochs trained: 1/1
   Total early stops so far: 0
   Training   - Loss: 10500.3916, RMSE: 102.4714, RÂ²: -0.0070
   Validation - Loss: 10879.2119, RMSE: 104.3035, RÂ²: -0.0144
ğŸ’¾ Training metrics saved to: logs/client_4_training_metrics_20251030_111205.csv

ğŸ§ª Round 10 Evaluation Results:
   Test Loss: 11721.2583
   RMSE: 108.2648, MAE: 82.4451, RÂ²: -0.1161
ğŸ’¾ Test metrics saved to: logs/client_4_test_metrics_20251030_111205.csv

================================================================================
ğŸ¯ FINAL COMPREHENSIVE REPORT
================================================================================
ğŸ’¾ Final summary saved to: logs/client_4_final_summary_20251030_111205.csv

ğŸ“Š CLIENT: client_4 | ALGORITHM: fedavg | MODEL: LSTM
ğŸ“ˆ TOTAL ROUNDS: 10

âš™ï¸  HYPERPARAMETERS:
   Learning Rate: 0.001
   Batch Size: 32
   Local Epochs: 1
   Hidden Dim: 64
   Num Layers: 2
   Sequence Length: 10
   Use Attention: False
   Dropout: 0.3
   Optimizer: adam

ğŸ›‘ EARLY STOPPING SUMMARY:
   Enabled: Yes
   Patience: 3 epochs
   Min delta: 0.001
   Total early stops: 0/10 rounds
   Early stop rate: 0.0%

ğŸ FINAL ROUND PERFORMANCE:
   Training   - Loss: 10500.39 | RMSE: 102.47 | RÂ²: -0.0070
   Validation - Loss: 10879.21 | RMSE: 104.30 | RÂ²: -0.0144
   Test       - Loss: 11721.26 | RMSE: 108.26 | RÂ²: -0.1161

ğŸ“Š STATISTICS ACROSS ALL ROUNDS (Mean Â± Std):
   Training Loss:   10532.27 Â±  26.35
   Validation Loss: 10923.61 Â±  35.82
   Test Loss:       12397.02 Â± 1923.59

   Training RMSE:   102.63 Â±  0.13
   Validation RMSE: 104.52 Â±  0.17
   Test RMSE:       111.06 Â±  7.91

   Training RÂ²:     -0.0101 Â± 0.0025
   Validation RÂ²:   -0.0186 Â± 0.0033
   Test RÂ²:         -0.1804 Â± 0.1832

â­ BEST PERFORMANCE:
   Best Round: 10 (Test RÂ²: -0.1161)

ğŸ“‹ DATA SUMMARY:
   Training samples:   4559
   Validation samples: 1513
   Test samples:       1513
   Total samples:      7585
================================================================================
âœ… Client client_4 completed | Algorithm: FEDAVG
