[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 34d89ed9-8642-42a9-a51d-15b0848a5c1a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dba396e2-b587-4b1e-8b6b-af87d4d7a70a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a0601f0d-795e-4189-83b4-5727de193029
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 33c996f5-ffbe-4ded-88c8-1b48f7c3f91c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c8ff0bad-fff5-4caf-b3fa-8712cc4e0b19
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9080e243-7594-43a1-a0e1-ec91f9704665
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c4847e7f-b0d9-4e72-9dd0-d64d250ee8af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e14d7cbd-c99f-4871-acc3-921695cda92b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1169df79-88b8-487c-856d-c003351fe520
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e2dd06b8-b315-49cb-a62e-5ce6c0b661f7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9d94f99d-21fb-48ac-b5da-299984b3b038
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 99c139e5-a7f5-4535-af8b-2d58f1fdddcf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4c560324-7337-4c35-a501-b73fef37a00d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 45dbb2c0-8760-4e0a-8dd2-bde93a40c062
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4e56f8cf-a791-429c-ab47-18e34e226aec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9a1f4fb8-b85c-4321-a511-81cb96818419
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 68498251-2b0a-4d29-bd9e-28e77c9aafb7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 71fb341f-6984-4f50-9b82-e0be10ab6015
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d7e34cb2-84c0-429a-b0be-5a0c489dd1df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 27aced41-8446-4e43-ad22-2ea670b04978
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: reconnect message 957062e6-3dce-4cd5-811a-0bb9c161b882
[92mINFO [0m:      Disconnect and shut down
🚀 Starting NASA FL Client: client_4
Algorithm: FEDAVG
Server: localhost:8686
K-Folds: 5
Log Directory: logs
🔄 Using device: cuda
🎯 GPU: NVIDIA A100-SXM4-80GB
🛑 Early stopping enabled:
   Patience: 3 epochs
   Min delta: 0.001
💾 Hyperparameters saved to: logs/client_4_hyperparams_20251030_111205.csv
🔍 Looking for data at: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.5/client_4
📊 Loaded 7615 total samples from /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.5/client_4
🔢 Original feature dimension: 24
🔍 Applying KernelPCA with 5 components, kernel=poly
📊 Data shape - Before: (4569, 24), After: (4569, 5)
🔄 Created sequences with length 10
   Final dataset shape: X (4559, 10, 5), y (4559,)
✅ Data split completed:
   Training samples: 4559
   Validation samples: 1513
   Test samples: 1513
   Model type: lstm
   Final input dimension: 5
✅ Client client_4 ready:
   Model: LSTM
   Training: 4559 samples
   Device: cuda
   Validation: 1513 samples
   Test: 1513 samples
   Algorithm: fedavg
   Total Rounds: 10
   Learning Rate: 0.001
   Batch Size: 32
   Logging to: logs
⏩ Skipping CV for Round 1

🔄 Starting local training (Round 1)...
   Epoch 1/1: train_loss=26242.8305, val_rmse=118.9591 ⭐ (improved by inf)
   ✅ Completed 1 epochs, using best model (val_rmse=118.9591)
Round 1: epochs=1, train_loss=13415.8340, val_rmse=118.9591, val_r2=-0.3195

🧪 Round 1 Evaluation Results:
   Test Loss: 18167.2959
   RMSE: 134.7861, MAE: 101.2454, R²: -0.7299
💾 Test metrics saved to: logs/client_4_test_metrics_20251030_111205.csv
⏩ Skipping CV for Round 2

🔄 Starting local training (Round 2)...
   Epoch 1/1: train_loss=13076.8329, val_rmse=104.5864 ⭐ (improved by inf)
   ✅ Completed 1 epochs, using best model (val_rmse=104.5864)
Round 2: epochs=1, train_loss=10542.6064, val_rmse=104.5864, val_r2=-0.0199
💾 Training metrics saved to: logs/client_4_training_metrics_20251030_111205.csv

🧪 Round 2 Evaluation Results:
   Test Loss: 11806.0625
   RMSE: 108.6557, MAE: 82.6395, R²: -0.1242
💾 Test metrics saved to: logs/client_4_test_metrics_20251030_111205.csv
⏩ Skipping CV for Round 3

🔄 Starting local training (Round 3)...
   Epoch 1/1: train_loss=12184.9833, val_rmse=104.5167 ⭐ (improved by inf)
   ✅ Completed 1 epochs, using best model (val_rmse=104.5167)

🎯 Round 3 Training Summary:
   Epochs trained: 1/1
   Total early stops so far: 0
   Training   - Loss: 10531.9512, RMSE: 102.6253, R²: -0.0101
   Validation - Loss: 10923.7402, RMSE: 104.5167, R²: -0.0186

🧪 Round 3 Evaluation Results:
   Test Loss: 11781.9978
   RMSE: 108.5449, MAE: 82.5831, R²: -0.1219
💾 Test metrics saved to: logs/client_4_test_metrics_20251030_111205.csv
⏩ Skipping CV for Round 4

🔄 Starting local training (Round 4)...
   Epoch 1/1: train_loss=12293.9551, val_rmse=104.4060 ⭐ (improved by inf)
   ✅ Completed 1 epochs, using best model (val_rmse=104.4060)
Round 4: epochs=1, train_loss=10515.3496, val_rmse=104.4060, val_r2=-0.0164
💾 Training metrics saved to: logs/client_4_training_metrics_20251030_111205.csv

🧪 Round 4 Evaluation Results:
   Test Loss: 11732.4576
   RMSE: 108.3165, MAE: 82.4708, R²: -0.1171
💾 Test metrics saved to: logs/client_4_test_metrics_20251030_111205.csv

🔍 Running 3-fold cross-validation (Round 5)

🔍 Starting 3-fold cross-validation on TRAINING data for client client_4

📊 Fold 1/3
   Fold 1 Results:
     Val Loss: 10631.4209
     Val RMSE: 103.1088, Val R²: -0.0025

📊 Fold 2/3
   Fold 2 Results:
     Val Loss: 10884.1768
     Val RMSE: 104.3273, Val R²: -0.0377

📊 Fold 3/3
   Fold 3 Results:
     Val Loss: 10247.3311
     Val RMSE: 101.2291, Val R²: -0.0085
💾 CV metrics saved to: logs/client_4_cv_metrics_20251030_111205.csv

📈 3-Fold CV Summary (Training Data):
   VAL_LOSS: 10587.6429 ± 261.8275
   RMSE: 102.8884 ± 1.2744
   R2: -0.0162 ± 0.0154

🔄 Starting local training (Round 5)...
   Epoch 1/1: train_loss=12197.2937, val_rmse=104.8777 ⭐ (improved by inf)
   ✅ Completed 1 epochs, using best model (val_rmse=104.8777)

🎯 Round 5 Training Summary:
   Epochs trained: 1/1
   Total early stops so far: 0
   Training   - Loss: 10588.4902, RMSE: 102.9004, R²: -0.0155
   Validation - Loss: 10999.3301, RMSE: 104.8777, R²: -0.0256
💾 Training metrics saved to: logs/client_4_training_metrics_20251030_111205.csv

🧪 Round 5 Evaluation Results:
   Test Loss: 11752.9016
   RMSE: 108.4108, MAE: 82.5174, R²: -0.1191
💾 Test metrics saved to: logs/client_4_test_metrics_20251030_111205.csv
⏩ Skipping CV for Round 6

🔄 Starting local training (Round 6)...
   Epoch 1/1: train_loss=12313.8980, val_rmse=104.4098 ⭐ (improved by inf)
   ✅ Completed 1 epochs, using best model (val_rmse=104.4098)

🎯 Round 6 Training Summary:
   Epochs trained: 1/1
   Total early stops so far: 0
   Training   - Loss: 10515.9160, RMSE: 102.5471, R²: -0.0085
   Validation - Loss: 10901.4053, RMSE: 104.4098, R²: -0.0165
💾 Training metrics saved to: logs/client_4_training_metrics_20251030_111205.csv

🧪 Round 6 Evaluation Results:
   Test Loss: 11726.2483
   RMSE: 108.2878, MAE: 82.4566, R²: -0.1166
💾 Test metrics saved to: logs/client_4_test_metrics_20251030_111205.csv
⏩ Skipping CV for Round 7

🔄 Starting local training (Round 7)...
   Epoch 1/1: train_loss=12298.0673, val_rmse=104.3871 ⭐ (improved by inf)
   ✅ Completed 1 epochs, using best model (val_rmse=104.3871)
Round 7: epochs=1, train_loss=10512.5586, val_rmse=104.3871, val_r2=-0.0161

🧪 Round 7 Evaluation Results:
   Test Loss: 11770.1003
   RMSE: 108.4901, MAE: 82.5564, R²: -0.1207
💾 Test metrics saved to: logs/client_4_test_metrics_20251030_111205.csv
⏩ Skipping CV for Round 8

🔄 Starting local training (Round 8)...
   Epoch 1/1: train_loss=12302.9253, val_rmse=104.5351 ⭐ (improved by inf)
   ✅ Completed 1 epochs, using best model (val_rmse=104.5351)
Round 8: epochs=1, train_loss=10534.7451, val_rmse=104.5351, val_r2=-0.0189
💾 Training metrics saved to: logs/client_4_training_metrics_20251030_111205.csv

🧪 Round 8 Evaluation Results:
   Test Loss: 11765.6351
   RMSE: 108.4695, MAE: 82.5463, R²: -0.1203
💾 Test metrics saved to: logs/client_4_test_metrics_20251030_111205.csv

🔍 Running 3-fold cross-validation (Round 9)
💾 CV metrics saved to: logs/client_4_cv_metrics_20251030_111205.csv

🔄 Starting local training (Round 9)...
   Epoch 1/1: train_loss=12081.9374, val_rmse=104.4931 ⭐ (improved by inf)
   ✅ Completed 1 epochs, using best model (val_rmse=104.4931)

🎯 Round 9 Training Summary:
   Epochs trained: 1/1
   Total early stops so far: 0
   Training   - Loss: 10528.3701, RMSE: 102.6079, R²: -0.0097
   Validation - Loss: 10918.7988, RMSE: 104.4931, R²: -0.0181
💾 Training metrics saved to: logs/client_4_training_metrics_20251030_111205.csv

🧪 Round 9 Evaluation Results:
   Test Loss: 11746.2070
   RMSE: 108.3799, MAE: 82.5022, R²: -0.1185
💾 Test metrics saved to: logs/client_4_test_metrics_20251030_111205.csv

🔍 Running 3-fold cross-validation (Round 10)
💾 CV metrics saved to: logs/client_4_cv_metrics_20251030_111205.csv

🔄 Starting local training (Round 10)...
   Epoch 1/1: train_loss=12192.9669, val_rmse=104.3035 ⭐ (improved by inf)
   ✅ Completed 1 epochs, using best model (val_rmse=104.3035)

🎯 Round 10 Training Summary:
   Epochs trained: 1/1
   Total early stops so far: 0
   Training   - Loss: 10500.3916, RMSE: 102.4714, R²: -0.0070
   Validation - Loss: 10879.2119, RMSE: 104.3035, R²: -0.0144
💾 Training metrics saved to: logs/client_4_training_metrics_20251030_111205.csv

🧪 Round 10 Evaluation Results:
   Test Loss: 11721.2583
   RMSE: 108.2648, MAE: 82.4451, R²: -0.1161
💾 Test metrics saved to: logs/client_4_test_metrics_20251030_111205.csv

================================================================================
🎯 FINAL COMPREHENSIVE REPORT
================================================================================
💾 Final summary saved to: logs/client_4_final_summary_20251030_111205.csv

📊 CLIENT: client_4 | ALGORITHM: fedavg | MODEL: LSTM
📈 TOTAL ROUNDS: 10

⚙️  HYPERPARAMETERS:
   Learning Rate: 0.001
   Batch Size: 32
   Local Epochs: 1
   Hidden Dim: 64
   Num Layers: 2
   Sequence Length: 10
   Use Attention: False
   Dropout: 0.3
   Optimizer: adam

🛑 EARLY STOPPING SUMMARY:
   Enabled: Yes
   Patience: 3 epochs
   Min delta: 0.001
   Total early stops: 0/10 rounds
   Early stop rate: 0.0%

🏁 FINAL ROUND PERFORMANCE:
   Training   - Loss: 10500.39 | RMSE: 102.47 | R²: -0.0070
   Validation - Loss: 10879.21 | RMSE: 104.30 | R²: -0.0144
   Test       - Loss: 11721.26 | RMSE: 108.26 | R²: -0.1161

📊 STATISTICS ACROSS ALL ROUNDS (Mean ± Std):
   Training Loss:   10532.27 ±  26.35
   Validation Loss: 10923.61 ±  35.82
   Test Loss:       12397.02 ± 1923.59

   Training RMSE:   102.63 ±  0.13
   Validation RMSE: 104.52 ±  0.17
   Test RMSE:       111.06 ±  7.91

   Training R²:     -0.0101 ± 0.0025
   Validation R²:   -0.0186 ± 0.0033
   Test R²:         -0.1804 ± 0.1832

⭐ BEST PERFORMANCE:
   Best Round: 10 (Test R²: -0.1161)

📋 DATA SUMMARY:
   Training samples:   4559
   Validation samples: 1513
   Test samples:       1513
   Total samples:      7585
================================================================================
✅ Client client_4 completed | Algorithm: FEDAVG
