[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 04273710-69c8-4571-8c9f-9c3b9e283ee1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fade7782-7d51-4069-bda1-9522e27e5791
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d17898e3-498e-4d8b-92c5-a48608e708be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 951231a5-5783-48de-a85b-2df42fa41438
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 86ed272b-2c7c-4fe4-8063-4e0e08f83dcc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3a449aac-a04d-4d3d-af58-324cf381557c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c642762d-b89d-4a97-95e6-67ebe42e6de8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 367edb2d-c4c7-4cab-b083-2aac3d71149d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 32864109-f3c0-48d6-ac9a-fe5591f0a8b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 54f841e5-20c6-4d3b-a40d-42bbda878fc3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 400551a3-3fbc-4d5f-b7cc-62e547037f84
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 609f8469-9469-4986-a7ed-e23749645930
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 01b91cb1-05c2-415c-b6ed-dd5d8e2422da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fbeb0997-6999-45d4-96ca-bd503f6d3e2b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 897d2ea6-c80a-4e0e-8fd4-40777246e34f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7a31f86b-7fcf-4569-87e9-ca5cf3a802d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c7812130-865d-49c7-a76e-54d5e28637bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e0a07e1c-8376-4352-8686-611f0a47b022
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6c72a11c-b06b-4784-b5e8-df72291a2ec6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 78b2ade1-78de-44fa-834b-dba151612a7d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: reconnect message 8b9dbee3-b797-49f5-8d59-3b5b1197dd29
[92mINFO [0m:      Disconnect and shut down
ğŸš€ Starting NASA FL Client: client_10
Algorithm: FEDAVGM
Server: localhost:8687
K-Folds: 5
Log Directory: logs
ğŸ”„ Using device: cuda
ğŸ¯ GPU: NVIDIA A100-SXM4-80GB
ğŸ›‘ Early stopping enabled:
   Patience: 3 epochs
   Min delta: 0.001
ğŸ’¾ Hyperparameters saved to: logs/client_10_hyperparams_20251030_111334.csv
ğŸ” Looking for data at: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.5/client_10
ğŸ“Š Loaded 7021 total samples from /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.5/client_10
ğŸ”¢ Original feature dimension: 24
ğŸ” Applying KernelPCA with 5 components, kernel=poly
ğŸ“Š Data shape - Before: (4212, 24), After: (4212, 5)
ğŸ”„ Created sequences with length 10
   Final dataset shape: X (4202, 10, 5), y (4202,)
âœ… Data split completed:
   Training samples: 4202
   Validation samples: 1394
   Test samples: 1395
   Model type: lstm
   Final input dimension: 5
âœ… Client client_10 ready:
   Model: LSTM
   Training: 4202 samples
   Device: cuda
   Validation: 1394 samples
   Test: 1395 samples
   Algorithm: fedavgm
   Total Rounds: 10
   Learning Rate: 0.001
   Batch Size: 32
   Logging to: logs
â© Skipping CV for Round 1

ğŸ”„ Starting local training (Round 1)...
   Epoch 1/1: train_loss=15164.3381, val_rmse=83.4224 â­ (improved by inf)
   âœ… Completed 1 epochs, using best model (val_rmse=83.4224)
Round 1: epochs=1, train_loss=6674.1250, val_rmse=83.4224, val_r2=-0.2117

ğŸ§ª Round 1 Evaluation Results:
   Test Loss: 10625.9435
   RMSE: 103.0822, MAE: 80.6410, RÂ²: -0.8248
ğŸ’¾ Test metrics saved to: logs/client_10_test_metrics_20251030_111334.csv
â© Skipping CV for Round 2

ğŸ”„ Starting local training (Round 2)...
   Epoch 1/1: train_loss=6905.0388, val_rmse=76.3461 â­ (improved by inf)
   âœ… Completed 1 epochs, using best model (val_rmse=76.3461)
Round 2: epochs=1, train_loss=5633.4155, val_rmse=76.3461, val_r2=-0.0148
ğŸ’¾ Training metrics saved to: logs/client_10_training_metrics_20251030_111334.csv

ğŸ§ª Round 2 Evaluation Results:
   Test Loss: 23604.5642
   RMSE: 153.6378, MAE: 137.2144, RÂ²: -3.0537
ğŸ’¾ Test metrics saved to: logs/client_10_test_metrics_20251030_111334.csv
â© Skipping CV for Round 3

ğŸ”„ Starting local training (Round 3)...
   Epoch 1/1: train_loss=8390.6027, val_rmse=76.3677 â­ (improved by inf)
   âœ… Completed 1 epochs, using best model (val_rmse=76.3677)

ğŸ¯ Round 3 Training Summary:
   Epochs trained: 1/1
   Total early stops so far: 0
   Training   - Loss: 5636.0991, RMSE: 75.0740, RÂ²: -0.0105
   Validation - Loss: 5832.0317, RMSE: 76.3677, RÂ²: -0.0154

ğŸ§ª Round 3 Evaluation Results:
   Test Loss: 18704.5390
   RMSE: 136.7645, MAE: 120.4835, RÂ²: -2.2122
ğŸ’¾ Test metrics saved to: logs/client_10_test_metrics_20251030_111334.csv
â© Skipping CV for Round 4

ğŸ”„ Starting local training (Round 4)...
   Epoch 1/1: train_loss=8470.1321, val_rmse=76.4869 â­ (improved by inf)
   âœ… Completed 1 epochs, using best model (val_rmse=76.4869)
Round 4: epochs=1, train_loss=5651.0811, val_rmse=76.4869, val_r2=-0.0186
ğŸ’¾ Training metrics saved to: logs/client_10_training_metrics_20251030_111334.csv

ğŸ§ª Round 4 Evaluation Results:
   Test Loss: 5993.1678
   RMSE: 77.4156, MAE: 62.6074, RÂ²: -0.0292
ğŸ’¾ Test metrics saved to: logs/client_10_test_metrics_20251030_111334.csv

ğŸ” Running 3-fold cross-validation (Round 5)

ğŸ” Starting 3-fold cross-validation on TRAINING data for client client_10

ğŸ“Š Fold 1/3
   Fold 1 Results:
     Val Loss: 5975.9863
     Val RMSE: 77.3045, Val RÂ²: -0.0099

ğŸ“Š Fold 2/3
   Fold 2 Results:
     Val Loss: 5511.8594
     Val RMSE: 74.2419, Val RÂ²: -0.0142

ğŸ“Š Fold 3/3
   Fold 3 Results:
     Val Loss: 5415.5771
     Val RMSE: 73.5906, Val RÂ²: -0.0068
ğŸ’¾ CV metrics saved to: logs/client_10_cv_metrics_20251030_111334.csv

ğŸ“ˆ 3-Fold CV Summary (Training Data):
   VAL_LOSS: 5634.4743 Â± 244.6636
   RMSE: 75.0457 Â± 1.6192
   R2: -0.0103 Â± 0.0030

ğŸ”„ Starting local training (Round 5)...
   Epoch 1/1: train_loss=6713.6734, val_rmse=76.3909 â­ (improved by inf)
   âœ… Completed 1 epochs, using best model (val_rmse=76.3909)

ğŸ¯ Round 5 Training Summary:
   Epochs trained: 1/1
   Total early stops so far: 0
   Training   - Loss: 5638.9893, RMSE: 75.0932, RÂ²: -0.0110
   Validation - Loss: 5835.5752, RMSE: 76.3909, RÂ²: -0.0160
ğŸ’¾ Training metrics saved to: logs/client_10_training_metrics_20251030_111334.csv

ğŸ§ª Round 5 Evaluation Results:
   Test Loss: 8336.9734
   RMSE: 91.3070, MAE: 71.2014, RÂ²: -0.4317
ğŸ’¾ Test metrics saved to: logs/client_10_test_metrics_20251030_111334.csv
â© Skipping CV for Round 6

ğŸ”„ Starting local training (Round 6)...
   Epoch 1/1: train_loss=6966.3147, val_rmse=76.4416 â­ (improved by inf)
   âœ… Completed 1 epochs, using best model (val_rmse=76.4416)

ğŸ¯ Round 6 Training Summary:
   Epochs trained: 1/1
   Total early stops so far: 0
   Training   - Loss: 5645.3462, RMSE: 75.1355, RÂ²: -0.0122
   Validation - Loss: 5843.3184, RMSE: 76.4416, RÂ²: -0.0174
ğŸ’¾ Training metrics saved to: logs/client_10_training_metrics_20251030_111334.csv

ğŸ§ª Round 6 Evaluation Results:
   Test Loss: 6580.7388
   RMSE: 81.1217, MAE: 64.4132, RÂ²: -0.1301
ğŸ’¾ Test metrics saved to: logs/client_10_test_metrics_20251030_111334.csv
â© Skipping CV for Round 7

ğŸ”„ Starting local training (Round 7)...
   Epoch 1/1: train_loss=6561.3689, val_rmse=76.4052 â­ (improved by inf)
   âœ… Completed 1 epochs, using best model (val_rmse=76.4052)
Round 7: epochs=1, train_loss=5640.7739, val_rmse=76.4052, val_r2=-0.0164

ğŸ§ª Round 7 Evaluation Results:
   Test Loss: 5901.1924
   RMSE: 76.8192, MAE: 63.4859, RÂ²: -0.0134
ğŸ’¾ Test metrics saved to: logs/client_10_test_metrics_20251030_111334.csv
â© Skipping CV for Round 8

ğŸ”„ Starting local training (Round 8)...
   Epoch 1/1: train_loss=6710.5329, val_rmse=76.3413 â­ (improved by inf)
   âœ… Completed 1 epochs, using best model (val_rmse=76.3413)
Round 8: epochs=1, train_loss=5632.8223, val_rmse=76.3413, val_r2=-0.0147
ğŸ’¾ Training metrics saved to: logs/client_10_training_metrics_20251030_111334.csv

ğŸ§ª Round 8 Evaluation Results:
   Test Loss: 6017.3655
   RMSE: 77.5717, MAE: 64.2385, RÂ²: -0.0334
ğŸ’¾ Test metrics saved to: logs/client_10_test_metrics_20251030_111334.csv

ğŸ” Running 3-fold cross-validation (Round 9)
ğŸ’¾ CV metrics saved to: logs/client_10_cv_metrics_20251030_111334.csv

ğŸ”„ Starting local training (Round 9)...
   Epoch 1/1: train_loss=6618.6537, val_rmse=76.5186 â­ (improved by inf)
   âœ… Completed 1 epochs, using best model (val_rmse=76.5186)

ğŸ¯ Round 9 Training Summary:
   Epochs trained: 1/1
   Total early stops so far: 0
   Training   - Loss: 5655.1162, RMSE: 75.2005, RÂ²: -0.0139
   Validation - Loss: 5855.0972, RMSE: 76.5186, RÂ²: -0.0194
ğŸ’¾ Training metrics saved to: logs/client_10_training_metrics_20251030_111334.csv

ğŸ§ª Round 9 Evaluation Results:
   Test Loss: 5835.0300
   RMSE: 76.3874, MAE: 62.5608, RÂ²: -0.0021
ğŸ’¾ Test metrics saved to: logs/client_10_test_metrics_20251030_111334.csv

ğŸ” Running 3-fold cross-validation (Round 10)
ğŸ’¾ CV metrics saved to: logs/client_10_cv_metrics_20251030_111334.csv

ğŸ”„ Starting local training (Round 10)...
   Epoch 1/1: train_loss=6505.8943, val_rmse=76.3420 â­ (improved by inf)
   âœ… Completed 1 epochs, using best model (val_rmse=76.3420)

ğŸ¯ Round 10 Training Summary:
   Epochs trained: 1/1
   Total early stops so far: 0
   Training   - Loss: 5632.9087, RMSE: 75.0527, RÂ²: -0.0099
   Validation - Loss: 5828.1006, RMSE: 76.3420, RÂ²: -0.0147
ğŸ’¾ Training metrics saved to: logs/client_10_training_metrics_20251030_111334.csv

ğŸ§ª Round 10 Evaluation Results:
   Test Loss: 6014.0917
   RMSE: 77.5506, MAE: 62.6505, RÂ²: -0.0328
ğŸ’¾ Test metrics saved to: logs/client_10_test_metrics_20251030_111334.csv

================================================================================
ğŸ¯ FINAL COMPREHENSIVE REPORT
================================================================================
ğŸ’¾ Final summary saved to: logs/client_10_final_summary_20251030_111334.csv

ğŸ“Š CLIENT: client_10 | ALGORITHM: fedavgm | MODEL: LSTM
ğŸ“ˆ TOTAL ROUNDS: 10

âš™ï¸  HYPERPARAMETERS:
   Learning Rate: 0.001
   Batch Size: 32
   Local Epochs: 1
   Hidden Dim: 64
   Num Layers: 2
   Sequence Length: 10
   Use Attention: False
   Dropout: 0.3
   Optimizer: adam

ğŸ›‘ EARLY STOPPING SUMMARY:
   Enabled: Yes
   Patience: 3 epochs
   Min delta: 0.001
   Total early stops: 0/10 rounds
   Early stop rate: 0.0%

ğŸ FINAL ROUND PERFORMANCE:
   Training   - Loss:  5632.91 | RMSE:  75.05 | RÂ²: -0.0099
   Validation - Loss:  5828.10 | RMSE:  76.34 | RÂ²: -0.0147
   Test       - Loss:  6014.09 | RMSE:  77.55 | RÂ²: -0.0328

ğŸ“Š STATISTICS ACROSS ALL ROUNDS (Mean Â± Std):
   Training Loss:    5641.38 Â±   8.56
   Validation Loss:  5838.44 Â±  10.41
   Test Loss:        9761.36 Â± 5975.64

   Training RMSE:    75.11 Â±  0.06
   Validation RMSE:  76.41 Â±  0.07
   Test RMSE:        95.17 Â± 26.55

   Training RÂ²:     -0.0115 Â± 0.0015
   Validation RÂ²:   -0.0165 Â± 0.0018
   Test RÂ²:         -0.6763 Â± 1.0262

â­ BEST PERFORMANCE:
   Best Round: 9 (Test RÂ²: -0.0021)

ğŸ“‹ DATA SUMMARY:
   Training samples:   4202
   Validation samples: 1394
   Test samples:       1395
   Total samples:      6991
================================================================================
âœ… Client client_10 completed | Algorithm: FEDAVGM
