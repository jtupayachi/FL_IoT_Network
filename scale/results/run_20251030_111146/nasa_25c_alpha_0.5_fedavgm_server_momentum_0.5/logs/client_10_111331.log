[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 04273710-69c8-4571-8c9f-9c3b9e283ee1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fade7782-7d51-4069-bda1-9522e27e5791
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d17898e3-498e-4d8b-92c5-a48608e708be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 951231a5-5783-48de-a85b-2df42fa41438
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 86ed272b-2c7c-4fe4-8063-4e0e08f83dcc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3a449aac-a04d-4d3d-af58-324cf381557c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c642762d-b89d-4a97-95e6-67ebe42e6de8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 367edb2d-c4c7-4cab-b083-2aac3d71149d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 32864109-f3c0-48d6-ac9a-fe5591f0a8b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 54f841e5-20c6-4d3b-a40d-42bbda878fc3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 400551a3-3fbc-4d5f-b7cc-62e547037f84
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 609f8469-9469-4986-a7ed-e23749645930
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 01b91cb1-05c2-415c-b6ed-dd5d8e2422da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fbeb0997-6999-45d4-96ca-bd503f6d3e2b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 897d2ea6-c80a-4e0e-8fd4-40777246e34f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7a31f86b-7fcf-4569-87e9-ca5cf3a802d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c7812130-865d-49c7-a76e-54d5e28637bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e0a07e1c-8376-4352-8686-611f0a47b022
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6c72a11c-b06b-4784-b5e8-df72291a2ec6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 78b2ade1-78de-44fa-834b-dba151612a7d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: reconnect message 8b9dbee3-b797-49f5-8d59-3b5b1197dd29
[92mINFO [0m:      Disconnect and shut down
🚀 Starting NASA FL Client: client_10
Algorithm: FEDAVGM
Server: localhost:8687
K-Folds: 5
Log Directory: logs
🔄 Using device: cuda
🎯 GPU: NVIDIA A100-SXM4-80GB
🛑 Early stopping enabled:
   Patience: 3 epochs
   Min delta: 0.001
💾 Hyperparameters saved to: logs/client_10_hyperparams_20251030_111334.csv
🔍 Looking for data at: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.5/client_10
📊 Loaded 7021 total samples from /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.5/client_10
🔢 Original feature dimension: 24
🔍 Applying KernelPCA with 5 components, kernel=poly
📊 Data shape - Before: (4212, 24), After: (4212, 5)
🔄 Created sequences with length 10
   Final dataset shape: X (4202, 10, 5), y (4202,)
✅ Data split completed:
   Training samples: 4202
   Validation samples: 1394
   Test samples: 1395
   Model type: lstm
   Final input dimension: 5
✅ Client client_10 ready:
   Model: LSTM
   Training: 4202 samples
   Device: cuda
   Validation: 1394 samples
   Test: 1395 samples
   Algorithm: fedavgm
   Total Rounds: 10
   Learning Rate: 0.001
   Batch Size: 32
   Logging to: logs
⏩ Skipping CV for Round 1

🔄 Starting local training (Round 1)...
   Epoch 1/1: train_loss=15164.3381, val_rmse=83.4224 ⭐ (improved by inf)
   ✅ Completed 1 epochs, using best model (val_rmse=83.4224)
Round 1: epochs=1, train_loss=6674.1250, val_rmse=83.4224, val_r2=-0.2117

🧪 Round 1 Evaluation Results:
   Test Loss: 10625.9435
   RMSE: 103.0822, MAE: 80.6410, R²: -0.8248
💾 Test metrics saved to: logs/client_10_test_metrics_20251030_111334.csv
⏩ Skipping CV for Round 2

🔄 Starting local training (Round 2)...
   Epoch 1/1: train_loss=6905.0388, val_rmse=76.3461 ⭐ (improved by inf)
   ✅ Completed 1 epochs, using best model (val_rmse=76.3461)
Round 2: epochs=1, train_loss=5633.4155, val_rmse=76.3461, val_r2=-0.0148
💾 Training metrics saved to: logs/client_10_training_metrics_20251030_111334.csv

🧪 Round 2 Evaluation Results:
   Test Loss: 23604.5642
   RMSE: 153.6378, MAE: 137.2144, R²: -3.0537
💾 Test metrics saved to: logs/client_10_test_metrics_20251030_111334.csv
⏩ Skipping CV for Round 3

🔄 Starting local training (Round 3)...
   Epoch 1/1: train_loss=8390.6027, val_rmse=76.3677 ⭐ (improved by inf)
   ✅ Completed 1 epochs, using best model (val_rmse=76.3677)

🎯 Round 3 Training Summary:
   Epochs trained: 1/1
   Total early stops so far: 0
   Training   - Loss: 5636.0991, RMSE: 75.0740, R²: -0.0105
   Validation - Loss: 5832.0317, RMSE: 76.3677, R²: -0.0154

🧪 Round 3 Evaluation Results:
   Test Loss: 18704.5390
   RMSE: 136.7645, MAE: 120.4835, R²: -2.2122
💾 Test metrics saved to: logs/client_10_test_metrics_20251030_111334.csv
⏩ Skipping CV for Round 4

🔄 Starting local training (Round 4)...
   Epoch 1/1: train_loss=8470.1321, val_rmse=76.4869 ⭐ (improved by inf)
   ✅ Completed 1 epochs, using best model (val_rmse=76.4869)
Round 4: epochs=1, train_loss=5651.0811, val_rmse=76.4869, val_r2=-0.0186
💾 Training metrics saved to: logs/client_10_training_metrics_20251030_111334.csv

🧪 Round 4 Evaluation Results:
   Test Loss: 5993.1678
   RMSE: 77.4156, MAE: 62.6074, R²: -0.0292
💾 Test metrics saved to: logs/client_10_test_metrics_20251030_111334.csv

🔍 Running 3-fold cross-validation (Round 5)

🔍 Starting 3-fold cross-validation on TRAINING data for client client_10

📊 Fold 1/3
   Fold 1 Results:
     Val Loss: 5975.9863
     Val RMSE: 77.3045, Val R²: -0.0099

📊 Fold 2/3
   Fold 2 Results:
     Val Loss: 5511.8594
     Val RMSE: 74.2419, Val R²: -0.0142

📊 Fold 3/3
   Fold 3 Results:
     Val Loss: 5415.5771
     Val RMSE: 73.5906, Val R²: -0.0068
💾 CV metrics saved to: logs/client_10_cv_metrics_20251030_111334.csv

📈 3-Fold CV Summary (Training Data):
   VAL_LOSS: 5634.4743 ± 244.6636
   RMSE: 75.0457 ± 1.6192
   R2: -0.0103 ± 0.0030

🔄 Starting local training (Round 5)...
   Epoch 1/1: train_loss=6713.6734, val_rmse=76.3909 ⭐ (improved by inf)
   ✅ Completed 1 epochs, using best model (val_rmse=76.3909)

🎯 Round 5 Training Summary:
   Epochs trained: 1/1
   Total early stops so far: 0
   Training   - Loss: 5638.9893, RMSE: 75.0932, R²: -0.0110
   Validation - Loss: 5835.5752, RMSE: 76.3909, R²: -0.0160
💾 Training metrics saved to: logs/client_10_training_metrics_20251030_111334.csv

🧪 Round 5 Evaluation Results:
   Test Loss: 8336.9734
   RMSE: 91.3070, MAE: 71.2014, R²: -0.4317
💾 Test metrics saved to: logs/client_10_test_metrics_20251030_111334.csv
⏩ Skipping CV for Round 6

🔄 Starting local training (Round 6)...
   Epoch 1/1: train_loss=6966.3147, val_rmse=76.4416 ⭐ (improved by inf)
   ✅ Completed 1 epochs, using best model (val_rmse=76.4416)

🎯 Round 6 Training Summary:
   Epochs trained: 1/1
   Total early stops so far: 0
   Training   - Loss: 5645.3462, RMSE: 75.1355, R²: -0.0122
   Validation - Loss: 5843.3184, RMSE: 76.4416, R²: -0.0174
💾 Training metrics saved to: logs/client_10_training_metrics_20251030_111334.csv

🧪 Round 6 Evaluation Results:
   Test Loss: 6580.7388
   RMSE: 81.1217, MAE: 64.4132, R²: -0.1301
💾 Test metrics saved to: logs/client_10_test_metrics_20251030_111334.csv
⏩ Skipping CV for Round 7

🔄 Starting local training (Round 7)...
   Epoch 1/1: train_loss=6561.3689, val_rmse=76.4052 ⭐ (improved by inf)
   ✅ Completed 1 epochs, using best model (val_rmse=76.4052)
Round 7: epochs=1, train_loss=5640.7739, val_rmse=76.4052, val_r2=-0.0164

🧪 Round 7 Evaluation Results:
   Test Loss: 5901.1924
   RMSE: 76.8192, MAE: 63.4859, R²: -0.0134
💾 Test metrics saved to: logs/client_10_test_metrics_20251030_111334.csv
⏩ Skipping CV for Round 8

🔄 Starting local training (Round 8)...
   Epoch 1/1: train_loss=6710.5329, val_rmse=76.3413 ⭐ (improved by inf)
   ✅ Completed 1 epochs, using best model (val_rmse=76.3413)
Round 8: epochs=1, train_loss=5632.8223, val_rmse=76.3413, val_r2=-0.0147
💾 Training metrics saved to: logs/client_10_training_metrics_20251030_111334.csv

🧪 Round 8 Evaluation Results:
   Test Loss: 6017.3655
   RMSE: 77.5717, MAE: 64.2385, R²: -0.0334
💾 Test metrics saved to: logs/client_10_test_metrics_20251030_111334.csv

🔍 Running 3-fold cross-validation (Round 9)
💾 CV metrics saved to: logs/client_10_cv_metrics_20251030_111334.csv

🔄 Starting local training (Round 9)...
   Epoch 1/1: train_loss=6618.6537, val_rmse=76.5186 ⭐ (improved by inf)
   ✅ Completed 1 epochs, using best model (val_rmse=76.5186)

🎯 Round 9 Training Summary:
   Epochs trained: 1/1
   Total early stops so far: 0
   Training   - Loss: 5655.1162, RMSE: 75.2005, R²: -0.0139
   Validation - Loss: 5855.0972, RMSE: 76.5186, R²: -0.0194
💾 Training metrics saved to: logs/client_10_training_metrics_20251030_111334.csv

🧪 Round 9 Evaluation Results:
   Test Loss: 5835.0300
   RMSE: 76.3874, MAE: 62.5608, R²: -0.0021
💾 Test metrics saved to: logs/client_10_test_metrics_20251030_111334.csv

🔍 Running 3-fold cross-validation (Round 10)
💾 CV metrics saved to: logs/client_10_cv_metrics_20251030_111334.csv

🔄 Starting local training (Round 10)...
   Epoch 1/1: train_loss=6505.8943, val_rmse=76.3420 ⭐ (improved by inf)
   ✅ Completed 1 epochs, using best model (val_rmse=76.3420)

🎯 Round 10 Training Summary:
   Epochs trained: 1/1
   Total early stops so far: 0
   Training   - Loss: 5632.9087, RMSE: 75.0527, R²: -0.0099
   Validation - Loss: 5828.1006, RMSE: 76.3420, R²: -0.0147
💾 Training metrics saved to: logs/client_10_training_metrics_20251030_111334.csv

🧪 Round 10 Evaluation Results:
   Test Loss: 6014.0917
   RMSE: 77.5506, MAE: 62.6505, R²: -0.0328
💾 Test metrics saved to: logs/client_10_test_metrics_20251030_111334.csv

================================================================================
🎯 FINAL COMPREHENSIVE REPORT
================================================================================
💾 Final summary saved to: logs/client_10_final_summary_20251030_111334.csv

📊 CLIENT: client_10 | ALGORITHM: fedavgm | MODEL: LSTM
📈 TOTAL ROUNDS: 10

⚙️  HYPERPARAMETERS:
   Learning Rate: 0.001
   Batch Size: 32
   Local Epochs: 1
   Hidden Dim: 64
   Num Layers: 2
   Sequence Length: 10
   Use Attention: False
   Dropout: 0.3
   Optimizer: adam

🛑 EARLY STOPPING SUMMARY:
   Enabled: Yes
   Patience: 3 epochs
   Min delta: 0.001
   Total early stops: 0/10 rounds
   Early stop rate: 0.0%

🏁 FINAL ROUND PERFORMANCE:
   Training   - Loss:  5632.91 | RMSE:  75.05 | R²: -0.0099
   Validation - Loss:  5828.10 | RMSE:  76.34 | R²: -0.0147
   Test       - Loss:  6014.09 | RMSE:  77.55 | R²: -0.0328

📊 STATISTICS ACROSS ALL ROUNDS (Mean ± Std):
   Training Loss:    5641.38 ±   8.56
   Validation Loss:  5838.44 ±  10.41
   Test Loss:        9761.36 ± 5975.64

   Training RMSE:    75.11 ±  0.06
   Validation RMSE:  76.41 ±  0.07
   Test RMSE:        95.17 ± 26.55

   Training R²:     -0.0115 ± 0.0015
   Validation R²:   -0.0165 ± 0.0018
   Test R²:         -0.6763 ± 1.0262

⭐ BEST PERFORMANCE:
   Best Round: 9 (Test R²: -0.0021)

📋 DATA SUMMARY:
   Training samples:   4202
   Validation samples: 1394
   Test samples:       1395
   Total samples:      6991
================================================================================
✅ Client client_10 completed | Algorithm: FEDAVGM
