[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7a02d6ca-3c27-4049-9440-ef4f410ec328
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 32fb89b0-e9c3-4b62-8a40-19053d0bfd6e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a839d86f-a59b-4858-8598-a7b78abd2222
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c5e2ad5a-a02a-402b-bd59-9e2e27090dde
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 339477f9-6f16-4914-84d0-93c1a017ef19
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 45c08a45-6b9f-4b06-8a84-8a3e7652a222
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ac847591-a395-4812-9612-72c2c58d4fa9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b1847fec-c7e9-4175-af9d-7ec3ad071258
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 016d44c6-8259-4366-b497-ee5dbfef5562
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1af550a6-f53a-485f-847b-53730b1aba26
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message af994c21-870f-47e7-a5fc-b4dc313ca8a9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5fceed79-a36a-4af3-8b0e-274f747988c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5c0d0406-de86-4f03-8053-b2d03740ad56
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6c0adb1e-1d43-4c07-804b-f1295813a2a7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 66238cd0-3084-49da-a4fc-2e9d0fb9e11a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d04a0fe8-4a08-4f6b-a68f-9d108b6eb4dd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ef4b2fe8-8249-4a93-9890-a69b546e2fac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 36a32edd-5369-4041-8485-c40556600743
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 96ef65e5-4531-4890-8e1f-17a81b59c8e5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 97ddd208-698b-43b4-97ea-9c3a96a4f10e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: reconnect message c26623aa-0f3b-4af9-b088-be9ef9b2b29d
[92mINFO [0m:      Disconnect and shut down
🚀 Starting NASA FL Client: client_11
Algorithm: FEDAVGM
Server: localhost:8687
K-Folds: 5
Log Directory: logs
🔄 Using device: cuda
🎯 GPU: NVIDIA A100-SXM4-80GB
🛑 Early stopping enabled:
   Patience: 3 epochs
   Min delta: 0.001
💾 Hyperparameters saved to: logs/client_11_hyperparams_20251030_111335.csv
🔍 Looking for data at: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.5/client_11
📊 Loaded 5713 total samples from /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.5/client_11
🔢 Original feature dimension: 24
🔍 Applying KernelPCA with 5 components, kernel=poly
📊 Data shape - Before: (3427, 24), After: (3427, 5)
🔄 Created sequences with length 10
   Final dataset shape: X (3417, 10, 5), y (3417,)
✅ Data split completed:
   Training samples: 3417
   Validation samples: 1133
   Test samples: 1133
   Model type: lstm
   Final input dimension: 5
✅ Client client_11 ready:
   Model: LSTM
   Training: 3417 samples
   Device: cuda
   Validation: 1133 samples
   Test: 1133 samples
   Algorithm: fedavgm
   Total Rounds: 10
   Learning Rate: 0.001
   Batch Size: 32
   Logging to: logs
⏩ Skipping CV for Round 1

🔄 Starting local training (Round 1)...
   Epoch 1/1: train_loss=18947.5508, val_rmse=113.5949 ⭐ (improved by inf)
   ✅ Completed 1 epochs, using best model (val_rmse=113.5949)
Round 1: epochs=1, train_loss=12272.0791, val_rmse=113.5949, val_r2=-0.6545

🧪 Round 1 Evaluation Results:
   Test Loss: 11618.5585
   RMSE: 107.7894, MAE: 78.2853, R²: -0.5705
💾 Test metrics saved to: logs/client_11_test_metrics_20251030_111335.csv
⏩ Skipping CV for Round 2

🔄 Starting local training (Round 2)...
   Epoch 1/1: train_loss=8712.2365, val_rmse=88.9510 ⭐ (improved by inf)
   ✅ Completed 1 epochs, using best model (val_rmse=88.9510)
Round 2: epochs=1, train_loss=7467.0161, val_rmse=88.9510, val_r2=-0.0145
💾 Training metrics saved to: logs/client_11_training_metrics_20251030_111335.csv

🧪 Round 2 Evaluation Results:
   Test Loss: 26355.6327
   RMSE: 162.3442, MAE: 149.1887, R²: -2.5625
💾 Test metrics saved to: logs/client_11_test_metrics_20251030_111335.csv
⏩ Skipping CV for Round 3

🔄 Starting local training (Round 3)...
   Epoch 1/1: train_loss=10915.4846, val_rmse=88.8027 ⭐ (improved by inf)
   ✅ Completed 1 epochs, using best model (val_rmse=88.8027)

🎯 Round 3 Training Summary:
   Epochs trained: 1/1
   Total early stops so far: 0
   Training   - Loss: 7444.7085, RMSE: 86.2827, R²: -0.0082
   Validation - Loss: 7885.9204, RMSE: 88.8027, R²: -0.0111

🧪 Round 3 Evaluation Results:
   Test Loss: 21283.3566
   RMSE: 145.8882, MAE: 132.2857, R²: -1.8768
💾 Test metrics saved to: logs/client_11_test_metrics_20251030_111335.csv
⏩ Skipping CV for Round 4

🔄 Starting local training (Round 4)...
   Epoch 1/1: train_loss=10816.1042, val_rmse=88.9481 ⭐ (improved by inf)
   ✅ Completed 1 epochs, using best model (val_rmse=88.9481)
Round 4: epochs=1, train_loss=7466.5728, val_rmse=88.9481, val_r2=-0.0144
💾 Training metrics saved to: logs/client_11_training_metrics_20251030_111335.csv

🧪 Round 4 Evaluation Results:
   Test Loss: 7473.9482
   RMSE: 86.4520, MAE: 65.0659, R²: -0.0102
💾 Test metrics saved to: logs/client_11_test_metrics_20251030_111335.csv

🔍 Running 3-fold cross-validation (Round 5)

🔍 Starting 3-fold cross-validation on TRAINING data for client client_11

📊 Fold 1/3
   Fold 1 Results:
     Val Loss: 7396.1382
     Val RMSE: 86.0008, Val R²: -0.0006

📊 Fold 2/3
   Fold 2 Results:
     Val Loss: 7509.0757
     Val RMSE: 86.6549, Val R²: -0.0103

📊 Fold 3/3
   Fold 3 Results:
     Val Loss: 7406.4814
     Val RMSE: 86.0609, Val R²: -0.0116
💾 CV metrics saved to: logs/client_11_cv_metrics_20251030_111335.csv

📈 3-Fold CV Summary (Training Data):
   VAL_LOSS: 7437.2318 ± 50.9765
   RMSE: 86.2389 ± 0.2952
   R2: -0.0075 ± 0.0049

🔄 Starting local training (Round 5)...
   Epoch 1/1: train_loss=8350.4506, val_rmse=88.7979 ⭐ (improved by inf)
   ✅ Completed 1 epochs, using best model (val_rmse=88.7979)

🎯 Round 5 Training Summary:
   Epochs trained: 1/1
   Total early stops so far: 0
   Training   - Loss: 7443.9990, RMSE: 86.2786, R²: -0.0081
   Validation - Loss: 7885.0708, RMSE: 88.7979, R²: -0.0110
💾 Training metrics saved to: logs/client_11_training_metrics_20251030_111335.csv

🧪 Round 5 Evaluation Results:
   Test Loss: 9495.8687
   RMSE: 97.4468, MAE: 70.5968, R²: -0.2835
💾 Test metrics saved to: logs/client_11_test_metrics_20251030_111335.csv
⏩ Skipping CV for Round 6

🔄 Starting local training (Round 6)...
   Epoch 1/1: train_loss=8835.6716, val_rmse=88.8329 ⭐ (improved by inf)
   ✅ Completed 1 epochs, using best model (val_rmse=88.8329)

🎯 Round 6 Training Summary:
   Epochs trained: 1/1
   Total early stops so far: 0
   Training   - Loss: 7449.1987, RMSE: 86.3087, R²: -0.0088
   Validation - Loss: 7891.2798, RMSE: 88.8329, R²: -0.0118
💾 Training metrics saved to: logs/client_11_training_metrics_20251030_111335.csv

🧪 Round 6 Evaluation Results:
   Test Loss: 7935.8502
   RMSE: 89.0834, MAE: 65.6278, R²: -0.0727
💾 Test metrics saved to: logs/client_11_test_metrics_20251030_111335.csv
⏩ Skipping CV for Round 7

🔄 Starting local training (Round 7)...
   Epoch 1/1: train_loss=8440.5854, val_rmse=88.7585 ⭐ (improved by inf)
   ✅ Completed 1 epochs, using best model (val_rmse=88.7585)
Round 7: epochs=1, train_loss=7438.1875, val_rmse=88.7585, val_r2=-0.0101

🧪 Round 7 Evaluation Results:
   Test Loss: 7571.8862
   RMSE: 87.0166, MAE: 68.4667, R²: -0.0235
💾 Test metrics saved to: logs/client_11_test_metrics_20251030_111335.csv
⏩ Skipping CV for Round 8

🔄 Starting local training (Round 8)...
   Epoch 1/1: train_loss=8359.9361, val_rmse=88.9379 ⭐ (improved by inf)
   ✅ Completed 1 epochs, using best model (val_rmse=88.9379)
Round 8: epochs=1, train_loss=7465.0205, val_rmse=88.9379, val_r2=-0.0142
💾 Training metrics saved to: logs/client_11_training_metrics_20251030_111335.csv

🧪 Round 8 Evaluation Results:
   Test Loss: 7732.3063
   RMSE: 87.9335, MAE: 69.9077, R²: -0.0452
💾 Test metrics saved to: logs/client_11_test_metrics_20251030_111335.csv

🔍 Running 3-fold cross-validation (Round 9)
💾 CV metrics saved to: logs/client_11_cv_metrics_20251030_111335.csv

🔄 Starting local training (Round 9)...
   Epoch 1/1: train_loss=8550.7106, val_rmse=88.8337 ⭐ (improved by inf)
   ✅ Completed 1 epochs, using best model (val_rmse=88.8337)

🎯 Round 9 Training Summary:
   Epochs trained: 1/1
   Total early stops so far: 0
   Training   - Loss: 7449.3140, RMSE: 86.3094, R²: -0.0088
   Validation - Loss: 7891.4185, RMSE: 88.8337, R²: -0.0118
💾 Training metrics saved to: logs/client_11_training_metrics_20251030_111335.csv

🧪 Round 9 Evaluation Results:
   Test Loss: 7398.9205
   RMSE: 86.0170, MAE: 65.9615, R²: -0.0001
💾 Test metrics saved to: logs/client_11_test_metrics_20251030_111335.csv

🔍 Running 3-fold cross-validation (Round 10)
💾 CV metrics saved to: logs/client_11_cv_metrics_20251030_111335.csv

🔄 Starting local training (Round 10)...
   Epoch 1/1: train_loss=8397.7509, val_rmse=88.9130 ⭐ (improved by inf)
   ✅ Completed 1 epochs, using best model (val_rmse=88.9130)

🎯 Round 10 Training Summary:
   Epochs trained: 1/1
   Total early stops so far: 0
   Training   - Loss: 7461.2397, RMSE: 86.3785, R²: -0.0104
   Validation - Loss: 7905.5166, RMSE: 88.9130, R²: -0.0136
💾 Training metrics saved to: logs/client_11_training_metrics_20251030_111335.csv

🧪 Round 10 Evaluation Results:
   Test Loss: 7488.1145
   RMSE: 86.5339, MAE: 65.0351, R²: -0.0122
💾 Test metrics saved to: logs/client_11_test_metrics_20251030_111335.csv

================================================================================
🎯 FINAL COMPREHENSIVE REPORT
================================================================================
💾 Final summary saved to: logs/client_11_final_summary_20251030_111335.csv

📊 CLIENT: client_11 | ALGORITHM: fedavgm | MODEL: LSTM
📈 TOTAL ROUNDS: 10

⚙️  HYPERPARAMETERS:
   Learning Rate: 0.001
   Batch Size: 32
   Local Epochs: 1
   Hidden Dim: 64
   Num Layers: 2
   Sequence Length: 10
   Use Attention: False
   Dropout: 0.3
   Optimizer: adam

🛑 EARLY STOPPING SUMMARY:
   Enabled: Yes
   Patience: 3 epochs
   Min delta: 0.001
   Total early stops: 0/10 rounds
   Early stop rate: 0.0%

🏁 FINAL ROUND PERFORMANCE:
   Training   - Loss:  7461.24 | RMSE:  86.38 | R²: -0.0104
   Validation - Loss:  7905.52 | RMSE:  88.91 | R²: -0.0136
   Test       - Loss:  7488.11 | RMSE:  86.53 | R²: -0.0122

📊 STATISTICS ACROSS ALL ROUNDS (Mean ± Std):
   Training Loss:    7457.48 ±   8.96
   Validation Loss:  7901.04 ±  10.58
   Test Loss:       11435.44 ± 6417.51

   Training RMSE:    86.36 ±  0.05
   Validation RMSE:  88.89 ±  0.06
   Test RMSE:       103.65 ± 26.31

   Training R²:     -0.0099 ± 0.0012
   Validation R²:   -0.0130 ± 0.0014
   Test R²:         -0.5457 ± 0.8674

⭐ BEST PERFORMANCE:
   Best Round: 9 (Test R²: -0.0001)

📋 DATA SUMMARY:
   Training samples:   3417
   Validation samples: 1133
   Test samples:       1133
   Total samples:      5683
================================================================================
✅ Client client_11 completed | Algorithm: FEDAVGM
