[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7a02d6ca-3c27-4049-9440-ef4f410ec328
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 32fb89b0-e9c3-4b62-8a40-19053d0bfd6e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a839d86f-a59b-4858-8598-a7b78abd2222
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c5e2ad5a-a02a-402b-bd59-9e2e27090dde
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 339477f9-6f16-4914-84d0-93c1a017ef19
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 45c08a45-6b9f-4b06-8a84-8a3e7652a222
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ac847591-a395-4812-9612-72c2c58d4fa9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b1847fec-c7e9-4175-af9d-7ec3ad071258
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 016d44c6-8259-4366-b497-ee5dbfef5562
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1af550a6-f53a-485f-847b-53730b1aba26
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message af994c21-870f-47e7-a5fc-b4dc313ca8a9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5fceed79-a36a-4af3-8b0e-274f747988c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5c0d0406-de86-4f03-8053-b2d03740ad56
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6c0adb1e-1d43-4c07-804b-f1295813a2a7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 66238cd0-3084-49da-a4fc-2e9d0fb9e11a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d04a0fe8-4a08-4f6b-a68f-9d108b6eb4dd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ef4b2fe8-8249-4a93-9890-a69b546e2fac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 36a32edd-5369-4041-8485-c40556600743
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 96ef65e5-4531-4890-8e1f-17a81b59c8e5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 97ddd208-698b-43b4-97ea-9c3a96a4f10e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: reconnect message c26623aa-0f3b-4af9-b088-be9ef9b2b29d
[92mINFO [0m:      Disconnect and shut down
ğŸš€ Starting NASA FL Client: client_11
Algorithm: FEDAVGM
Server: localhost:8687
K-Folds: 5
Log Directory: logs
ğŸ”„ Using device: cuda
ğŸ¯ GPU: NVIDIA A100-SXM4-80GB
ğŸ›‘ Early stopping enabled:
   Patience: 3 epochs
   Min delta: 0.001
ğŸ’¾ Hyperparameters saved to: logs/client_11_hyperparams_20251030_111335.csv
ğŸ” Looking for data at: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.5/client_11
ğŸ“Š Loaded 5713 total samples from /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.5/client_11
ğŸ”¢ Original feature dimension: 24
ğŸ” Applying KernelPCA with 5 components, kernel=poly
ğŸ“Š Data shape - Before: (3427, 24), After: (3427, 5)
ğŸ”„ Created sequences with length 10
   Final dataset shape: X (3417, 10, 5), y (3417,)
âœ… Data split completed:
   Training samples: 3417
   Validation samples: 1133
   Test samples: 1133
   Model type: lstm
   Final input dimension: 5
âœ… Client client_11 ready:
   Model: LSTM
   Training: 3417 samples
   Device: cuda
   Validation: 1133 samples
   Test: 1133 samples
   Algorithm: fedavgm
   Total Rounds: 10
   Learning Rate: 0.001
   Batch Size: 32
   Logging to: logs
â© Skipping CV for Round 1

ğŸ”„ Starting local training (Round 1)...
   Epoch 1/1: train_loss=18947.5508, val_rmse=113.5949 â­ (improved by inf)
   âœ… Completed 1 epochs, using best model (val_rmse=113.5949)
Round 1: epochs=1, train_loss=12272.0791, val_rmse=113.5949, val_r2=-0.6545

ğŸ§ª Round 1 Evaluation Results:
   Test Loss: 11618.5585
   RMSE: 107.7894, MAE: 78.2853, RÂ²: -0.5705
ğŸ’¾ Test metrics saved to: logs/client_11_test_metrics_20251030_111335.csv
â© Skipping CV for Round 2

ğŸ”„ Starting local training (Round 2)...
   Epoch 1/1: train_loss=8712.2365, val_rmse=88.9510 â­ (improved by inf)
   âœ… Completed 1 epochs, using best model (val_rmse=88.9510)
Round 2: epochs=1, train_loss=7467.0161, val_rmse=88.9510, val_r2=-0.0145
ğŸ’¾ Training metrics saved to: logs/client_11_training_metrics_20251030_111335.csv

ğŸ§ª Round 2 Evaluation Results:
   Test Loss: 26355.6327
   RMSE: 162.3442, MAE: 149.1887, RÂ²: -2.5625
ğŸ’¾ Test metrics saved to: logs/client_11_test_metrics_20251030_111335.csv
â© Skipping CV for Round 3

ğŸ”„ Starting local training (Round 3)...
   Epoch 1/1: train_loss=10915.4846, val_rmse=88.8027 â­ (improved by inf)
   âœ… Completed 1 epochs, using best model (val_rmse=88.8027)

ğŸ¯ Round 3 Training Summary:
   Epochs trained: 1/1
   Total early stops so far: 0
   Training   - Loss: 7444.7085, RMSE: 86.2827, RÂ²: -0.0082
   Validation - Loss: 7885.9204, RMSE: 88.8027, RÂ²: -0.0111

ğŸ§ª Round 3 Evaluation Results:
   Test Loss: 21283.3566
   RMSE: 145.8882, MAE: 132.2857, RÂ²: -1.8768
ğŸ’¾ Test metrics saved to: logs/client_11_test_metrics_20251030_111335.csv
â© Skipping CV for Round 4

ğŸ”„ Starting local training (Round 4)...
   Epoch 1/1: train_loss=10816.1042, val_rmse=88.9481 â­ (improved by inf)
   âœ… Completed 1 epochs, using best model (val_rmse=88.9481)
Round 4: epochs=1, train_loss=7466.5728, val_rmse=88.9481, val_r2=-0.0144
ğŸ’¾ Training metrics saved to: logs/client_11_training_metrics_20251030_111335.csv

ğŸ§ª Round 4 Evaluation Results:
   Test Loss: 7473.9482
   RMSE: 86.4520, MAE: 65.0659, RÂ²: -0.0102
ğŸ’¾ Test metrics saved to: logs/client_11_test_metrics_20251030_111335.csv

ğŸ” Running 3-fold cross-validation (Round 5)

ğŸ” Starting 3-fold cross-validation on TRAINING data for client client_11

ğŸ“Š Fold 1/3
   Fold 1 Results:
     Val Loss: 7396.1382
     Val RMSE: 86.0008, Val RÂ²: -0.0006

ğŸ“Š Fold 2/3
   Fold 2 Results:
     Val Loss: 7509.0757
     Val RMSE: 86.6549, Val RÂ²: -0.0103

ğŸ“Š Fold 3/3
   Fold 3 Results:
     Val Loss: 7406.4814
     Val RMSE: 86.0609, Val RÂ²: -0.0116
ğŸ’¾ CV metrics saved to: logs/client_11_cv_metrics_20251030_111335.csv

ğŸ“ˆ 3-Fold CV Summary (Training Data):
   VAL_LOSS: 7437.2318 Â± 50.9765
   RMSE: 86.2389 Â± 0.2952
   R2: -0.0075 Â± 0.0049

ğŸ”„ Starting local training (Round 5)...
   Epoch 1/1: train_loss=8350.4506, val_rmse=88.7979 â­ (improved by inf)
   âœ… Completed 1 epochs, using best model (val_rmse=88.7979)

ğŸ¯ Round 5 Training Summary:
   Epochs trained: 1/1
   Total early stops so far: 0
   Training   - Loss: 7443.9990, RMSE: 86.2786, RÂ²: -0.0081
   Validation - Loss: 7885.0708, RMSE: 88.7979, RÂ²: -0.0110
ğŸ’¾ Training metrics saved to: logs/client_11_training_metrics_20251030_111335.csv

ğŸ§ª Round 5 Evaluation Results:
   Test Loss: 9495.8687
   RMSE: 97.4468, MAE: 70.5968, RÂ²: -0.2835
ğŸ’¾ Test metrics saved to: logs/client_11_test_metrics_20251030_111335.csv
â© Skipping CV for Round 6

ğŸ”„ Starting local training (Round 6)...
   Epoch 1/1: train_loss=8835.6716, val_rmse=88.8329 â­ (improved by inf)
   âœ… Completed 1 epochs, using best model (val_rmse=88.8329)

ğŸ¯ Round 6 Training Summary:
   Epochs trained: 1/1
   Total early stops so far: 0
   Training   - Loss: 7449.1987, RMSE: 86.3087, RÂ²: -0.0088
   Validation - Loss: 7891.2798, RMSE: 88.8329, RÂ²: -0.0118
ğŸ’¾ Training metrics saved to: logs/client_11_training_metrics_20251030_111335.csv

ğŸ§ª Round 6 Evaluation Results:
   Test Loss: 7935.8502
   RMSE: 89.0834, MAE: 65.6278, RÂ²: -0.0727
ğŸ’¾ Test metrics saved to: logs/client_11_test_metrics_20251030_111335.csv
â© Skipping CV for Round 7

ğŸ”„ Starting local training (Round 7)...
   Epoch 1/1: train_loss=8440.5854, val_rmse=88.7585 â­ (improved by inf)
   âœ… Completed 1 epochs, using best model (val_rmse=88.7585)
Round 7: epochs=1, train_loss=7438.1875, val_rmse=88.7585, val_r2=-0.0101

ğŸ§ª Round 7 Evaluation Results:
   Test Loss: 7571.8862
   RMSE: 87.0166, MAE: 68.4667, RÂ²: -0.0235
ğŸ’¾ Test metrics saved to: logs/client_11_test_metrics_20251030_111335.csv
â© Skipping CV for Round 8

ğŸ”„ Starting local training (Round 8)...
   Epoch 1/1: train_loss=8359.9361, val_rmse=88.9379 â­ (improved by inf)
   âœ… Completed 1 epochs, using best model (val_rmse=88.9379)
Round 8: epochs=1, train_loss=7465.0205, val_rmse=88.9379, val_r2=-0.0142
ğŸ’¾ Training metrics saved to: logs/client_11_training_metrics_20251030_111335.csv

ğŸ§ª Round 8 Evaluation Results:
   Test Loss: 7732.3063
   RMSE: 87.9335, MAE: 69.9077, RÂ²: -0.0452
ğŸ’¾ Test metrics saved to: logs/client_11_test_metrics_20251030_111335.csv

ğŸ” Running 3-fold cross-validation (Round 9)
ğŸ’¾ CV metrics saved to: logs/client_11_cv_metrics_20251030_111335.csv

ğŸ”„ Starting local training (Round 9)...
   Epoch 1/1: train_loss=8550.7106, val_rmse=88.8337 â­ (improved by inf)
   âœ… Completed 1 epochs, using best model (val_rmse=88.8337)

ğŸ¯ Round 9 Training Summary:
   Epochs trained: 1/1
   Total early stops so far: 0
   Training   - Loss: 7449.3140, RMSE: 86.3094, RÂ²: -0.0088
   Validation - Loss: 7891.4185, RMSE: 88.8337, RÂ²: -0.0118
ğŸ’¾ Training metrics saved to: logs/client_11_training_metrics_20251030_111335.csv

ğŸ§ª Round 9 Evaluation Results:
   Test Loss: 7398.9205
   RMSE: 86.0170, MAE: 65.9615, RÂ²: -0.0001
ğŸ’¾ Test metrics saved to: logs/client_11_test_metrics_20251030_111335.csv

ğŸ” Running 3-fold cross-validation (Round 10)
ğŸ’¾ CV metrics saved to: logs/client_11_cv_metrics_20251030_111335.csv

ğŸ”„ Starting local training (Round 10)...
   Epoch 1/1: train_loss=8397.7509, val_rmse=88.9130 â­ (improved by inf)
   âœ… Completed 1 epochs, using best model (val_rmse=88.9130)

ğŸ¯ Round 10 Training Summary:
   Epochs trained: 1/1
   Total early stops so far: 0
   Training   - Loss: 7461.2397, RMSE: 86.3785, RÂ²: -0.0104
   Validation - Loss: 7905.5166, RMSE: 88.9130, RÂ²: -0.0136
ğŸ’¾ Training metrics saved to: logs/client_11_training_metrics_20251030_111335.csv

ğŸ§ª Round 10 Evaluation Results:
   Test Loss: 7488.1145
   RMSE: 86.5339, MAE: 65.0351, RÂ²: -0.0122
ğŸ’¾ Test metrics saved to: logs/client_11_test_metrics_20251030_111335.csv

================================================================================
ğŸ¯ FINAL COMPREHENSIVE REPORT
================================================================================
ğŸ’¾ Final summary saved to: logs/client_11_final_summary_20251030_111335.csv

ğŸ“Š CLIENT: client_11 | ALGORITHM: fedavgm | MODEL: LSTM
ğŸ“ˆ TOTAL ROUNDS: 10

âš™ï¸  HYPERPARAMETERS:
   Learning Rate: 0.001
   Batch Size: 32
   Local Epochs: 1
   Hidden Dim: 64
   Num Layers: 2
   Sequence Length: 10
   Use Attention: False
   Dropout: 0.3
   Optimizer: adam

ğŸ›‘ EARLY STOPPING SUMMARY:
   Enabled: Yes
   Patience: 3 epochs
   Min delta: 0.001
   Total early stops: 0/10 rounds
   Early stop rate: 0.0%

ğŸ FINAL ROUND PERFORMANCE:
   Training   - Loss:  7461.24 | RMSE:  86.38 | RÂ²: -0.0104
   Validation - Loss:  7905.52 | RMSE:  88.91 | RÂ²: -0.0136
   Test       - Loss:  7488.11 | RMSE:  86.53 | RÂ²: -0.0122

ğŸ“Š STATISTICS ACROSS ALL ROUNDS (Mean Â± Std):
   Training Loss:    7457.48 Â±   8.96
   Validation Loss:  7901.04 Â±  10.58
   Test Loss:       11435.44 Â± 6417.51

   Training RMSE:    86.36 Â±  0.05
   Validation RMSE:  88.89 Â±  0.06
   Test RMSE:       103.65 Â± 26.31

   Training RÂ²:     -0.0099 Â± 0.0012
   Validation RÂ²:   -0.0130 Â± 0.0014
   Test RÂ²:         -0.5457 Â± 0.8674

â­ BEST PERFORMANCE:
   Best Round: 9 (Test RÂ²: -0.0001)

ğŸ“‹ DATA SUMMARY:
   Training samples:   3417
   Validation samples: 1133
   Test samples:       1133
   Total samples:      5683
================================================================================
âœ… Client client_11 completed | Algorithm: FEDAVGM
