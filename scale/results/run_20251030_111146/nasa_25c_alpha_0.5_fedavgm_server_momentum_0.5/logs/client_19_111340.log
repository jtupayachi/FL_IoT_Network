[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a57338f2-1a47-4014-88d9-133e2789428d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 68f17306-7c79-494a-89c7-d932bad0abec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e7a0aa2d-b4d5-485e-864a-35fbf04aceb6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f3ea4f2c-517d-478d-bf9c-feb8a9bbd622
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 23731d5d-a34e-476e-ad63-7a2fa9767d2d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4e773b9f-92b5-453f-ba99-6bfebbbff880
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 775661f7-35f9-4849-8db3-d47c9ac8ae12
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8a4944e2-e3ab-4367-96ac-d5ce59346740
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bbccf556-1a5f-47f0-bde3-d6d5bc156cdf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 32a5d5e0-a7c9-4c26-8c9e-a375fb7f9e0b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 21dda63f-9d26-4ede-ad6c-ca9fa56a39b6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0f73c055-6437-469f-8500-ca98977ee196
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6921796c-5eec-47ec-af88-b6be07ed4c98
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ef61e0d7-1471-44cf-b069-d1eb40800956
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 36065fdf-d3f3-4512-9d99-281c25bcc79b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8533e14f-6e0c-436d-b05a-60ca6da8f8e1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4fd029d3-b035-4c7a-93a3-bbb5508b7bef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a318d37a-ab52-4372-870e-87ae81e1a6c4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b2f7e68e-8a1b-43f8-bc48-2a0687f61580
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 89371972-9200-4154-83ef-b89222eb59bc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: reconnect message 0433fb34-be2f-49c5-b1a7-c604de57d8ba
[92mINFO [0m:      Disconnect and shut down
🚀 Starting NASA FL Client: client_19
Algorithm: FEDAVGM
Server: localhost:8687
K-Folds: 5
Log Directory: logs
🔄 Using device: cuda
🎯 GPU: NVIDIA A100-SXM4-80GB
🛑 Early stopping enabled:
   Patience: 3 epochs
   Min delta: 0.001
💾 Hyperparameters saved to: logs/client_19_hyperparams_20251030_111343.csv
🔍 Looking for data at: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.5/client_19
📊 Loaded 5558 total samples from /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.5/client_19
🔢 Original feature dimension: 24
🔍 Applying KernelPCA with 5 components, kernel=poly
📊 Data shape - Before: (3334, 24), After: (3334, 5)
🔄 Created sequences with length 10
   Final dataset shape: X (3324, 10, 5), y (3324,)
✅ Data split completed:
   Training samples: 3324
   Validation samples: 1102
   Test samples: 1102
   Model type: lstm
   Final input dimension: 5
✅ Client client_19 ready:
   Model: LSTM
   Training: 3324 samples
   Device: cuda
   Validation: 1102 samples
   Test: 1102 samples
   Algorithm: fedavgm
   Total Rounds: 10
   Learning Rate: 0.001
   Batch Size: 32
   Logging to: logs
⏩ Skipping CV for Round 1

🔄 Starting local training (Round 1)...
   Epoch 1/1: train_loss=25113.7105, val_rmse=132.2030 ⭐ (improved by inf)
   ✅ Completed 1 epochs, using best model (val_rmse=132.2030)
Round 1: epochs=1, train_loss=18403.7793, val_rmse=132.2030, val_r2=-1.0252

🧪 Round 1 Evaluation Results:
   Test Loss: 15717.6979
   RMSE: 125.3702, MAE: 95.0840, R²: -0.8594
💾 Test metrics saved to: logs/client_19_test_metrics_20251030_111343.csv
⏩ Skipping CV for Round 2

🔄 Starting local training (Round 2)...
   Epoch 1/1: train_loss=11498.5384, val_rmse=94.0157 ⭐ (improved by inf)
   ✅ Completed 1 epochs, using best model (val_rmse=94.0157)
Round 2: epochs=1, train_loss=9567.4033, val_rmse=94.0157, val_r2=-0.0242
💾 Training metrics saved to: logs/client_19_training_metrics_20251030_111343.csv

🧪 Round 2 Evaluation Results:
   Test Loss: 22240.4623
   RMSE: 149.1324, MAE: 131.3752, R²: -1.6310
💾 Test metrics saved to: logs/client_19_test_metrics_20251030_111343.csv
⏩ Skipping CV for Round 3

🔄 Starting local training (Round 3)...
   Epoch 1/1: train_loss=12354.2699, val_rmse=93.7715 ⭐ (improved by inf)
   ✅ Completed 1 epochs, using best model (val_rmse=93.7715)

🎯 Round 3 Training Summary:
   Epochs trained: 1/1
   Total early stops so far: 0
   Training   - Loss: 9517.3555, RMSE: 97.5569, R²: -0.0210
   Validation - Loss: 8793.0928, RMSE: 93.7715, R²: -0.0189

🧪 Round 3 Evaluation Results:
   Test Loss: 17972.8209
   RMSE: 134.0627, MAE: 116.6098, R²: -1.1261
💾 Test metrics saved to: logs/client_19_test_metrics_20251030_111343.csv
⏩ Skipping CV for Round 4

🔄 Starting local training (Round 4)...
   Epoch 1/1: train_loss=12405.0977, val_rmse=93.9354 ⭐ (improved by inf)
   ✅ Completed 1 epochs, using best model (val_rmse=93.9354)
Round 4: epochs=1, train_loss=9550.9805, val_rmse=93.9354, val_r2=-0.0224
💾 Training metrics saved to: logs/client_19_training_metrics_20251030_111343.csv

🧪 Round 4 Evaluation Results:
   Test Loss: 9292.6823
   RMSE: 96.3986, MAE: 74.1639, R²: -0.0993
💾 Test metrics saved to: logs/client_19_test_metrics_20251030_111343.csv

🔍 Running 3-fold cross-validation (Round 5)

🔍 Starting 3-fold cross-validation on TRAINING data for client client_19

📊 Fold 1/3
   Fold 1 Results:
     Val Loss: 8862.4707
     Val RMSE: 94.1407, Val R²: -0.0132

📊 Fold 2/3
   Fold 2 Results:
     Val Loss: 9793.8984
     Val RMSE: 98.9641, Val R²: -0.0154

📊 Fold 3/3
   Fold 3 Results:
     Val Loss: 9611.4961
     Val RMSE: 98.0382, Val R²: -0.0045
💾 CV metrics saved to: logs/client_19_cv_metrics_20251030_111343.csv

📈 3-Fold CV Summary (Training Data):
   VAL_LOSS: 9422.6217 ± 403.0257
   RMSE: 97.0477 ± 2.0900
   R2: -0.0110 ± 0.0047

🔄 Starting local training (Round 5)...
   Epoch 1/1: train_loss=10782.6224, val_rmse=93.7180 ⭐ (improved by inf)
   ✅ Completed 1 epochs, using best model (val_rmse=93.7180)

🎯 Round 5 Training Summary:
   Epochs trained: 1/1
   Total early stops so far: 0
   Training   - Loss: 9506.3262, RMSE: 97.5004, R²: -0.0198
   Validation - Loss: 8783.0557, RMSE: 93.7180, R²: -0.0177
💾 Training metrics saved to: logs/client_19_training_metrics_20251030_111343.csv

🧪 Round 5 Evaluation Results:
   Test Loss: 12818.2294
   RMSE: 113.2176, MAE: 85.0664, R²: -0.5164
💾 Test metrics saved to: logs/client_19_test_metrics_20251030_111343.csv
⏩ Skipping CV for Round 6

🔄 Starting local training (Round 6)...
   Epoch 1/1: train_loss=11555.3339, val_rmse=93.6371 ⭐ (improved by inf)
   ✅ Completed 1 epochs, using best model (val_rmse=93.6371)

🎯 Round 6 Training Summary:
   Epochs trained: 1/1
   Total early stops so far: 0
   Training   - Loss: 9489.6250, RMSE: 97.4147, R²: -0.0181
   Validation - Loss: 8767.9131, RMSE: 93.6371, R²: -0.0159
💾 Training metrics saved to: logs/client_19_training_metrics_20251030_111343.csv

🧪 Round 6 Evaluation Results:
   Test Loss: 10341.6229
   RMSE: 101.6938, MAE: 77.1470, R²: -0.2234
💾 Test metrics saved to: logs/client_19_test_metrics_20251030_111343.csv
⏩ Skipping CV for Round 7

🔄 Starting local training (Round 7)...
   Epoch 1/1: train_loss=10888.1016, val_rmse=93.7368 ⭐ (improved by inf)
   ✅ Completed 1 epochs, using best model (val_rmse=93.7368)
Round 7: epochs=1, train_loss=9510.2080, val_rmse=93.7368, val_r2=-0.0181

🧪 Round 7 Evaluation Results:
   Test Loss: 8503.4755
   RMSE: 92.2143, MAE: 73.0738, R²: -0.0059
💾 Test metrics saved to: logs/client_19_test_metrics_20251030_111343.csv
⏩ Skipping CV for Round 8

🔄 Starting local training (Round 8)...
   Epoch 1/1: train_loss=10415.5450, val_rmse=93.8357 ⭐ (improved by inf)
   ✅ Completed 1 epochs, using best model (val_rmse=93.8357)
Round 8: epochs=1, train_loss=9530.5469, val_rmse=93.8357, val_r2=-0.0203
💾 Training metrics saved to: logs/client_19_training_metrics_20251030_111343.csv

🧪 Round 8 Evaluation Results:
   Test Loss: 8457.2051
   RMSE: 91.9631, MAE: 73.4525, R²: -0.0005
💾 Test metrics saved to: logs/client_19_test_metrics_20251030_111343.csv

🔍 Running 3-fold cross-validation (Round 9)
💾 CV metrics saved to: logs/client_19_cv_metrics_20251030_111343.csv

🔄 Starting local training (Round 9)...
   Epoch 1/1: train_loss=10298.4458, val_rmse=93.7042 ⭐ (improved by inf)
   ✅ Completed 1 epochs, using best model (val_rmse=93.7042)

🎯 Round 9 Training Summary:
   Epochs trained: 1/1
   Total early stops so far: 0
   Training   - Loss: 9503.4980, RMSE: 97.4859, R²: -0.0195
   Validation - Loss: 8780.4844, RMSE: 93.7042, R²: -0.0174
💾 Training metrics saved to: logs/client_19_training_metrics_20251030_111343.csv

🧪 Round 9 Evaluation Results:
   Test Loss: 8829.4226
   RMSE: 93.9650, MAE: 73.1564, R²: -0.0445
💾 Test metrics saved to: logs/client_19_test_metrics_20251030_111343.csv

🔍 Running 3-fold cross-validation (Round 10)
💾 CV metrics saved to: logs/client_19_cv_metrics_20251030_111343.csv

🔄 Starting local training (Round 10)...
   Epoch 1/1: train_loss=10459.7401, val_rmse=93.8006 ⭐ (improved by inf)
   ✅ Completed 1 epochs, using best model (val_rmse=93.8006)

🎯 Round 10 Training Summary:
   Epochs trained: 1/1
   Total early stops so far: 0
   Training   - Loss: 9523.3477, RMSE: 97.5876, R²: -0.0217
   Validation - Loss: 8798.5576, RMSE: 93.8006, R²: -0.0195
💾 Training metrics saved to: logs/client_19_training_metrics_20251030_111343.csv

🧪 Round 10 Evaluation Results:
   Test Loss: 9338.4155
   RMSE: 96.6355, MAE: 74.2775, R²: -0.1047
💾 Test metrics saved to: logs/client_19_test_metrics_20251030_111343.csv

================================================================================
🎯 FINAL COMPREHENSIVE REPORT
================================================================================
💾 Final summary saved to: logs/client_19_final_summary_20251030_111343.csv

📊 CLIENT: client_19 | ALGORITHM: fedavgm | MODEL: LSTM
📈 TOTAL ROUNDS: 10

⚙️  HYPERPARAMETERS:
   Learning Rate: 0.001
   Batch Size: 32
   Local Epochs: 1
   Hidden Dim: 64
   Num Layers: 2
   Sequence Length: 10
   Use Attention: False
   Dropout: 0.3
   Optimizer: adam

🛑 EARLY STOPPING SUMMARY:
   Enabled: Yes
   Patience: 3 epochs
   Min delta: 0.001
   Total early stops: 0/10 rounds
   Early stop rate: 0.0%

🏁 FINAL ROUND PERFORMANCE:
   Training   - Loss:  9523.35 | RMSE:  97.59 | R²: -0.0217
   Validation - Loss:  8798.56 | RMSE:  93.80 | R²: -0.0195
   Test       - Loss:  9338.42 | RMSE:  96.64 | R²: -0.1047

📊 STATISTICS ACROSS ALL ROUNDS (Mean ± Std):
   Training Loss:    9524.53 ±  25.54
   Validation Loss:  8799.71 ±  23.34
   Test Loss:       12351.20 ± 4536.44

   Training RMSE:    97.59 ±  0.13
   Validation RMSE:  93.81 ±  0.12
   Test RMSE:       109.47 ± 19.20

   Training R²:     -0.0218 ± 0.0027
   Validation R²:   -0.0196 ± 0.0027
   Test R²:         -0.4611 ± 0.5366

⭐ BEST PERFORMANCE:
   Best Round: 8 (Test R²: -0.0005)

📋 DATA SUMMARY:
   Training samples:   3324
   Validation samples: 1102
   Test samples:       1102
   Total samples:      5528
================================================================================
✅ Client client_19 completed | Algorithm: FEDAVGM
