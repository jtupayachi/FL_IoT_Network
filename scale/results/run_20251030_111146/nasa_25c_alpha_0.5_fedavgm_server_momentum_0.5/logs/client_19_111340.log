[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a57338f2-1a47-4014-88d9-133e2789428d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 68f17306-7c79-494a-89c7-d932bad0abec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e7a0aa2d-b4d5-485e-864a-35fbf04aceb6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f3ea4f2c-517d-478d-bf9c-feb8a9bbd622
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 23731d5d-a34e-476e-ad63-7a2fa9767d2d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4e773b9f-92b5-453f-ba99-6bfebbbff880
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 775661f7-35f9-4849-8db3-d47c9ac8ae12
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8a4944e2-e3ab-4367-96ac-d5ce59346740
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bbccf556-1a5f-47f0-bde3-d6d5bc156cdf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 32a5d5e0-a7c9-4c26-8c9e-a375fb7f9e0b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 21dda63f-9d26-4ede-ad6c-ca9fa56a39b6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0f73c055-6437-469f-8500-ca98977ee196
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6921796c-5eec-47ec-af88-b6be07ed4c98
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ef61e0d7-1471-44cf-b069-d1eb40800956
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 36065fdf-d3f3-4512-9d99-281c25bcc79b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8533e14f-6e0c-436d-b05a-60ca6da8f8e1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4fd029d3-b035-4c7a-93a3-bbb5508b7bef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a318d37a-ab52-4372-870e-87ae81e1a6c4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b2f7e68e-8a1b-43f8-bc48-2a0687f61580
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 89371972-9200-4154-83ef-b89222eb59bc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: reconnect message 0433fb34-be2f-49c5-b1a7-c604de57d8ba
[92mINFO [0m:      Disconnect and shut down
ğŸš€ Starting NASA FL Client: client_19
Algorithm: FEDAVGM
Server: localhost:8687
K-Folds: 5
Log Directory: logs
ğŸ”„ Using device: cuda
ğŸ¯ GPU: NVIDIA A100-SXM4-80GB
ğŸ›‘ Early stopping enabled:
   Patience: 3 epochs
   Min delta: 0.001
ğŸ’¾ Hyperparameters saved to: logs/client_19_hyperparams_20251030_111343.csv
ğŸ” Looking for data at: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.5/client_19
ğŸ“Š Loaded 5558 total samples from /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.5/client_19
ğŸ”¢ Original feature dimension: 24
ğŸ” Applying KernelPCA with 5 components, kernel=poly
ğŸ“Š Data shape - Before: (3334, 24), After: (3334, 5)
ğŸ”„ Created sequences with length 10
   Final dataset shape: X (3324, 10, 5), y (3324,)
âœ… Data split completed:
   Training samples: 3324
   Validation samples: 1102
   Test samples: 1102
   Model type: lstm
   Final input dimension: 5
âœ… Client client_19 ready:
   Model: LSTM
   Training: 3324 samples
   Device: cuda
   Validation: 1102 samples
   Test: 1102 samples
   Algorithm: fedavgm
   Total Rounds: 10
   Learning Rate: 0.001
   Batch Size: 32
   Logging to: logs
â© Skipping CV for Round 1

ğŸ”„ Starting local training (Round 1)...
   Epoch 1/1: train_loss=25113.7105, val_rmse=132.2030 â­ (improved by inf)
   âœ… Completed 1 epochs, using best model (val_rmse=132.2030)
Round 1: epochs=1, train_loss=18403.7793, val_rmse=132.2030, val_r2=-1.0252

ğŸ§ª Round 1 Evaluation Results:
   Test Loss: 15717.6979
   RMSE: 125.3702, MAE: 95.0840, RÂ²: -0.8594
ğŸ’¾ Test metrics saved to: logs/client_19_test_metrics_20251030_111343.csv
â© Skipping CV for Round 2

ğŸ”„ Starting local training (Round 2)...
   Epoch 1/1: train_loss=11498.5384, val_rmse=94.0157 â­ (improved by inf)
   âœ… Completed 1 epochs, using best model (val_rmse=94.0157)
Round 2: epochs=1, train_loss=9567.4033, val_rmse=94.0157, val_r2=-0.0242
ğŸ’¾ Training metrics saved to: logs/client_19_training_metrics_20251030_111343.csv

ğŸ§ª Round 2 Evaluation Results:
   Test Loss: 22240.4623
   RMSE: 149.1324, MAE: 131.3752, RÂ²: -1.6310
ğŸ’¾ Test metrics saved to: logs/client_19_test_metrics_20251030_111343.csv
â© Skipping CV for Round 3

ğŸ”„ Starting local training (Round 3)...
   Epoch 1/1: train_loss=12354.2699, val_rmse=93.7715 â­ (improved by inf)
   âœ… Completed 1 epochs, using best model (val_rmse=93.7715)

ğŸ¯ Round 3 Training Summary:
   Epochs trained: 1/1
   Total early stops so far: 0
   Training   - Loss: 9517.3555, RMSE: 97.5569, RÂ²: -0.0210
   Validation - Loss: 8793.0928, RMSE: 93.7715, RÂ²: -0.0189

ğŸ§ª Round 3 Evaluation Results:
   Test Loss: 17972.8209
   RMSE: 134.0627, MAE: 116.6098, RÂ²: -1.1261
ğŸ’¾ Test metrics saved to: logs/client_19_test_metrics_20251030_111343.csv
â© Skipping CV for Round 4

ğŸ”„ Starting local training (Round 4)...
   Epoch 1/1: train_loss=12405.0977, val_rmse=93.9354 â­ (improved by inf)
   âœ… Completed 1 epochs, using best model (val_rmse=93.9354)
Round 4: epochs=1, train_loss=9550.9805, val_rmse=93.9354, val_r2=-0.0224
ğŸ’¾ Training metrics saved to: logs/client_19_training_metrics_20251030_111343.csv

ğŸ§ª Round 4 Evaluation Results:
   Test Loss: 9292.6823
   RMSE: 96.3986, MAE: 74.1639, RÂ²: -0.0993
ğŸ’¾ Test metrics saved to: logs/client_19_test_metrics_20251030_111343.csv

ğŸ” Running 3-fold cross-validation (Round 5)

ğŸ” Starting 3-fold cross-validation on TRAINING data for client client_19

ğŸ“Š Fold 1/3
   Fold 1 Results:
     Val Loss: 8862.4707
     Val RMSE: 94.1407, Val RÂ²: -0.0132

ğŸ“Š Fold 2/3
   Fold 2 Results:
     Val Loss: 9793.8984
     Val RMSE: 98.9641, Val RÂ²: -0.0154

ğŸ“Š Fold 3/3
   Fold 3 Results:
     Val Loss: 9611.4961
     Val RMSE: 98.0382, Val RÂ²: -0.0045
ğŸ’¾ CV metrics saved to: logs/client_19_cv_metrics_20251030_111343.csv

ğŸ“ˆ 3-Fold CV Summary (Training Data):
   VAL_LOSS: 9422.6217 Â± 403.0257
   RMSE: 97.0477 Â± 2.0900
   R2: -0.0110 Â± 0.0047

ğŸ”„ Starting local training (Round 5)...
   Epoch 1/1: train_loss=10782.6224, val_rmse=93.7180 â­ (improved by inf)
   âœ… Completed 1 epochs, using best model (val_rmse=93.7180)

ğŸ¯ Round 5 Training Summary:
   Epochs trained: 1/1
   Total early stops so far: 0
   Training   - Loss: 9506.3262, RMSE: 97.5004, RÂ²: -0.0198
   Validation - Loss: 8783.0557, RMSE: 93.7180, RÂ²: -0.0177
ğŸ’¾ Training metrics saved to: logs/client_19_training_metrics_20251030_111343.csv

ğŸ§ª Round 5 Evaluation Results:
   Test Loss: 12818.2294
   RMSE: 113.2176, MAE: 85.0664, RÂ²: -0.5164
ğŸ’¾ Test metrics saved to: logs/client_19_test_metrics_20251030_111343.csv
â© Skipping CV for Round 6

ğŸ”„ Starting local training (Round 6)...
   Epoch 1/1: train_loss=11555.3339, val_rmse=93.6371 â­ (improved by inf)
   âœ… Completed 1 epochs, using best model (val_rmse=93.6371)

ğŸ¯ Round 6 Training Summary:
   Epochs trained: 1/1
   Total early stops so far: 0
   Training   - Loss: 9489.6250, RMSE: 97.4147, RÂ²: -0.0181
   Validation - Loss: 8767.9131, RMSE: 93.6371, RÂ²: -0.0159
ğŸ’¾ Training metrics saved to: logs/client_19_training_metrics_20251030_111343.csv

ğŸ§ª Round 6 Evaluation Results:
   Test Loss: 10341.6229
   RMSE: 101.6938, MAE: 77.1470, RÂ²: -0.2234
ğŸ’¾ Test metrics saved to: logs/client_19_test_metrics_20251030_111343.csv
â© Skipping CV for Round 7

ğŸ”„ Starting local training (Round 7)...
   Epoch 1/1: train_loss=10888.1016, val_rmse=93.7368 â­ (improved by inf)
   âœ… Completed 1 epochs, using best model (val_rmse=93.7368)
Round 7: epochs=1, train_loss=9510.2080, val_rmse=93.7368, val_r2=-0.0181

ğŸ§ª Round 7 Evaluation Results:
   Test Loss: 8503.4755
   RMSE: 92.2143, MAE: 73.0738, RÂ²: -0.0059
ğŸ’¾ Test metrics saved to: logs/client_19_test_metrics_20251030_111343.csv
â© Skipping CV for Round 8

ğŸ”„ Starting local training (Round 8)...
   Epoch 1/1: train_loss=10415.5450, val_rmse=93.8357 â­ (improved by inf)
   âœ… Completed 1 epochs, using best model (val_rmse=93.8357)
Round 8: epochs=1, train_loss=9530.5469, val_rmse=93.8357, val_r2=-0.0203
ğŸ’¾ Training metrics saved to: logs/client_19_training_metrics_20251030_111343.csv

ğŸ§ª Round 8 Evaluation Results:
   Test Loss: 8457.2051
   RMSE: 91.9631, MAE: 73.4525, RÂ²: -0.0005
ğŸ’¾ Test metrics saved to: logs/client_19_test_metrics_20251030_111343.csv

ğŸ” Running 3-fold cross-validation (Round 9)
ğŸ’¾ CV metrics saved to: logs/client_19_cv_metrics_20251030_111343.csv

ğŸ”„ Starting local training (Round 9)...
   Epoch 1/1: train_loss=10298.4458, val_rmse=93.7042 â­ (improved by inf)
   âœ… Completed 1 epochs, using best model (val_rmse=93.7042)

ğŸ¯ Round 9 Training Summary:
   Epochs trained: 1/1
   Total early stops so far: 0
   Training   - Loss: 9503.4980, RMSE: 97.4859, RÂ²: -0.0195
   Validation - Loss: 8780.4844, RMSE: 93.7042, RÂ²: -0.0174
ğŸ’¾ Training metrics saved to: logs/client_19_training_metrics_20251030_111343.csv

ğŸ§ª Round 9 Evaluation Results:
   Test Loss: 8829.4226
   RMSE: 93.9650, MAE: 73.1564, RÂ²: -0.0445
ğŸ’¾ Test metrics saved to: logs/client_19_test_metrics_20251030_111343.csv

ğŸ” Running 3-fold cross-validation (Round 10)
ğŸ’¾ CV metrics saved to: logs/client_19_cv_metrics_20251030_111343.csv

ğŸ”„ Starting local training (Round 10)...
   Epoch 1/1: train_loss=10459.7401, val_rmse=93.8006 â­ (improved by inf)
   âœ… Completed 1 epochs, using best model (val_rmse=93.8006)

ğŸ¯ Round 10 Training Summary:
   Epochs trained: 1/1
   Total early stops so far: 0
   Training   - Loss: 9523.3477, RMSE: 97.5876, RÂ²: -0.0217
   Validation - Loss: 8798.5576, RMSE: 93.8006, RÂ²: -0.0195
ğŸ’¾ Training metrics saved to: logs/client_19_training_metrics_20251030_111343.csv

ğŸ§ª Round 10 Evaluation Results:
   Test Loss: 9338.4155
   RMSE: 96.6355, MAE: 74.2775, RÂ²: -0.1047
ğŸ’¾ Test metrics saved to: logs/client_19_test_metrics_20251030_111343.csv

================================================================================
ğŸ¯ FINAL COMPREHENSIVE REPORT
================================================================================
ğŸ’¾ Final summary saved to: logs/client_19_final_summary_20251030_111343.csv

ğŸ“Š CLIENT: client_19 | ALGORITHM: fedavgm | MODEL: LSTM
ğŸ“ˆ TOTAL ROUNDS: 10

âš™ï¸  HYPERPARAMETERS:
   Learning Rate: 0.001
   Batch Size: 32
   Local Epochs: 1
   Hidden Dim: 64
   Num Layers: 2
   Sequence Length: 10
   Use Attention: False
   Dropout: 0.3
   Optimizer: adam

ğŸ›‘ EARLY STOPPING SUMMARY:
   Enabled: Yes
   Patience: 3 epochs
   Min delta: 0.001
   Total early stops: 0/10 rounds
   Early stop rate: 0.0%

ğŸ FINAL ROUND PERFORMANCE:
   Training   - Loss:  9523.35 | RMSE:  97.59 | RÂ²: -0.0217
   Validation - Loss:  8798.56 | RMSE:  93.80 | RÂ²: -0.0195
   Test       - Loss:  9338.42 | RMSE:  96.64 | RÂ²: -0.1047

ğŸ“Š STATISTICS ACROSS ALL ROUNDS (Mean Â± Std):
   Training Loss:    9524.53 Â±  25.54
   Validation Loss:  8799.71 Â±  23.34
   Test Loss:       12351.20 Â± 4536.44

   Training RMSE:    97.59 Â±  0.13
   Validation RMSE:  93.81 Â±  0.12
   Test RMSE:       109.47 Â± 19.20

   Training RÂ²:     -0.0218 Â± 0.0027
   Validation RÂ²:   -0.0196 Â± 0.0027
   Test RÂ²:         -0.4611 Â± 0.5366

â­ BEST PERFORMANCE:
   Best Round: 8 (Test RÂ²: -0.0005)

ğŸ“‹ DATA SUMMARY:
   Training samples:   3324
   Validation samples: 1102
   Test samples:       1102
   Total samples:      5528
================================================================================
âœ… Client client_19 completed | Algorithm: FEDAVGM
