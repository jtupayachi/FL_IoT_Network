[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 70f6b3a5-9e12-466b-b683-b8ff76750cab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message be02ba06-f4e3-4989-bc79-5077c3c2bba6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2dee05f7-8fd7-43ae-b453-7014ef2f7ff4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b330deb5-4dba-4c96-b02c-a3f4189b6c78
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b91d41f7-1d94-41d4-b3a4-c10352c83d83
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3981a6a6-e2ab-499c-8bca-45f6c43651d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message da2ef337-cc3d-4dff-850d-85e112d631c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2077a34d-8b84-4ec9-91fd-292e7bcae914
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1d9877fa-8acd-4da8-8d56-06b46c38a3d9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ca347f78-7b38-4de0-8234-63820edf5b5e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cb635313-b52b-4a9d-b6b3-6746b4e8f877
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dd736bf7-a86f-4a78-a8d5-7f19ee8e1c89
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f37eb0d4-f2ea-4724-adad-2471b07d8edd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8e7c1645-38e4-44a5-a55e-720a8a52cff6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a2bbdee5-acb4-44b7-b1e1-5f933ea8851b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b5e6f5ec-c395-4337-9008-1a0193c9b3f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ace97936-a109-4034-b613-589aad5676fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ff4cdd20-d4d2-4d9d-ab98-182a32d57166
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 100ae66b-97ef-4ac1-ac02-142450dbbd21
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 934c4308-4a80-4e1f-93a2-619b80afb715
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: reconnect message f6cafaf6-3d04-4b1e-9d85-aba106335cdb
[92mINFO [0m:      Disconnect and shut down
🚀 Starting NASA FL Client: client_22
Algorithm: FEDAVGM
Server: localhost:8687
K-Folds: 5
Log Directory: logs
🔄 Using device: cuda
🎯 GPU: NVIDIA A100-SXM4-80GB
🛑 Early stopping enabled:
   Patience: 3 epochs
   Min delta: 0.001
💾 Hyperparameters saved to: logs/client_22_hyperparams_20251030_111346.csv
🔍 Looking for data at: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.5/client_22
📊 Loaded 6778 total samples from /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.5/client_22
🔢 Original feature dimension: 24
🔍 Applying KernelPCA with 5 components, kernel=poly
📊 Data shape - Before: (4066, 24), After: (4066, 5)
🔄 Created sequences with length 10
   Final dataset shape: X (4056, 10, 5), y (4056,)
✅ Data split completed:
   Training samples: 4056
   Validation samples: 1346
   Test samples: 1346
   Model type: lstm
   Final input dimension: 5
✅ Client client_22 ready:
   Model: LSTM
   Training: 4056 samples
   Device: cuda
   Validation: 1346 samples
   Test: 1346 samples
   Algorithm: fedavgm
   Total Rounds: 10
   Learning Rate: 0.001
   Batch Size: 32
   Logging to: logs
⏩ Skipping CV for Round 1

🔄 Starting local training (Round 1)...
   Epoch 1/1: train_loss=21481.8775, val_rmse=106.8948 ⭐ (improved by inf)
   ✅ Completed 1 epochs, using best model (val_rmse=106.8948)
Round 1: epochs=1, train_loss=11023.5625, val_rmse=106.8948, val_r2=-0.3578

🧪 Round 1 Evaluation Results:
   Test Loss: 15875.3258
   RMSE: 125.9973, MAE: 95.1751, R²: -0.7944
💾 Test metrics saved to: logs/client_22_test_metrics_20251030_111346.csv
⏩ Skipping CV for Round 2

🔄 Starting local training (Round 2)...
   Epoch 1/1: train_loss=10226.8581, val_rmse=93.0408 ⭐ (improved by inf)
   ✅ Completed 1 epochs, using best model (val_rmse=93.0408)
Round 2: epochs=1, train_loss=8584.1660, val_rmse=93.0408, val_r2=-0.0287
💾 Training metrics saved to: logs/client_22_training_metrics_20251030_111346.csv

🧪 Round 2 Evaluation Results:
   Test Loss: 22964.4971
   RMSE: 151.5404, MAE: 133.3855, R²: -1.5957
💾 Test metrics saved to: logs/client_22_test_metrics_20251030_111346.csv
⏩ Skipping CV for Round 3

🔄 Starting local training (Round 3)...
   Epoch 1/1: train_loss=11254.9060, val_rmse=92.6254 ⭐ (improved by inf)
   ✅ Completed 1 epochs, using best model (val_rmse=92.6254)

🎯 Round 3 Training Summary:
   Epochs trained: 1/1
   Total early stops so far: 0
   Training   - Loss: 8529.9023, RMSE: 92.3575, R²: -0.0088
   Validation - Loss: 8579.4570, RMSE: 92.6254, R²: -0.0195

🧪 Round 3 Evaluation Results:
   Test Loss: 18641.3740
   RMSE: 136.5334, MAE: 118.5430, R²: -1.1070
💾 Test metrics saved to: logs/client_22_test_metrics_20251030_111346.csv
⏩ Skipping CV for Round 4

🔄 Starting local training (Round 4)...
   Epoch 1/1: train_loss=10916.1645, val_rmse=92.6999 ⭐ (improved by inf)
   ✅ Completed 1 epochs, using best model (val_rmse=92.6999)
Round 4: epochs=1, train_loss=8539.2822, val_rmse=92.6999, val_r2=-0.0211
💾 Training metrics saved to: logs/client_22_training_metrics_20251030_111346.csv

🧪 Round 4 Evaluation Results:
   Test Loss: 9607.5556
   RMSE: 98.0181, MAE: 75.6616, R²: -0.0859
💾 Test metrics saved to: logs/client_22_test_metrics_20251030_111346.csv

🔍 Running 3-fold cross-validation (Round 5)

🔍 Starting 3-fold cross-validation on TRAINING data for client client_22

📊 Fold 1/3
   Fold 1 Results:
     Val Loss: 8307.7334
     Val RMSE: 91.1468, Val R²: -0.0105

📊 Fold 2/3
   Fold 2 Results:
     Val Loss: 8378.4043
     Val RMSE: 91.5336, Val R²: -0.0062

📊 Fold 3/3
   Fold 3 Results:
     Val Loss: 8863.8994
     Val RMSE: 94.1483, Val R²: -0.0055
💾 CV metrics saved to: logs/client_22_cv_metrics_20251030_111346.csv

📈 3-Fold CV Summary (Training Data):
   VAL_LOSS: 8516.6790 ± 247.2112
   RMSE: 92.2762 ± 1.3331
   R2: -0.0074 ± 0.0022

🔄 Starting local training (Round 5)...
   Epoch 1/1: train_loss=9880.6934, val_rmse=92.7803 ⭐ (improved by inf)
   ✅ Completed 1 epochs, using best model (val_rmse=92.7803)

🎯 Round 5 Training Summary:
   Epochs trained: 1/1
   Total early stops so far: 0
   Training   - Loss: 8549.5938, RMSE: 92.4640, R²: -0.0111
   Validation - Loss: 8608.1914, RMSE: 92.7803, R²: -0.0229
💾 Training metrics saved to: logs/client_22_training_metrics_20251030_111346.csv

🧪 Round 5 Evaluation Results:
   Test Loss: 13029.4226
   RMSE: 114.1465, MAE: 85.6208, R²: -0.4727
💾 Test metrics saved to: logs/client_22_test_metrics_20251030_111346.csv
⏩ Skipping CV for Round 6

🔄 Starting local training (Round 6)...
   Epoch 1/1: train_loss=10225.0996, val_rmse=92.6317 ⭐ (improved by inf)
   ✅ Completed 1 epochs, using best model (val_rmse=92.6317)

🎯 Round 6 Training Summary:
   Epochs trained: 1/1
   Total early stops so far: 0
   Training   - Loss: 8530.6865, RMSE: 92.3617, R²: -0.0089
   Validation - Loss: 8580.6240, RMSE: 92.6317, R²: -0.0196
💾 Training metrics saved to: logs/client_22_training_metrics_20251030_111346.csv

🧪 Round 6 Evaluation Results:
   Test Loss: 10616.0178
   RMSE: 103.0341, MAE: 78.2785, R²: -0.1999
💾 Test metrics saved to: logs/client_22_test_metrics_20251030_111346.csv
⏩ Skipping CV for Round 7

🔄 Starting local training (Round 7)...
   Epoch 1/1: train_loss=9825.7032, val_rmse=92.7492 ⭐ (improved by inf)
   ✅ Completed 1 epochs, using best model (val_rmse=92.7492)
Round 7: epochs=1, train_loss=8545.5762, val_rmse=92.7492, val_r2=-0.0222

🧪 Round 7 Evaluation Results:
   Test Loss: 8879.5201
   RMSE: 94.2312, MAE: 74.8788, R²: -0.0037
💾 Test metrics saved to: logs/client_22_test_metrics_20251030_111346.csv
⏩ Skipping CV for Round 8

🔄 Starting local training (Round 8)...
   Epoch 1/1: train_loss=9466.2217, val_rmse=92.4647 ⭐ (improved by inf)
   ✅ Completed 1 epochs, using best model (val_rmse=92.4647)
Round 8: epochs=1, train_loss=8510.4023, val_rmse=92.4647, val_r2=-0.0160
💾 Training metrics saved to: logs/client_22_training_metrics_20251030_111346.csv

🧪 Round 8 Evaluation Results:
   Test Loss: 8847.5018
   RMSE: 94.0612, MAE: 75.2930, R²: -0.0000
💾 Test metrics saved to: logs/client_22_test_metrics_20251030_111346.csv

🔍 Running 3-fold cross-validation (Round 9)
💾 CV metrics saved to: logs/client_22_cv_metrics_20251030_111346.csv

🔄 Starting local training (Round 9)...
   Epoch 1/1: train_loss=9511.4876, val_rmse=92.6385 ⭐ (improved by inf)
   ✅ Completed 1 epochs, using best model (val_rmse=92.6385)

🎯 Round 9 Training Summary:
   Epochs trained: 1/1
   Total early stops so far: 0
   Training   - Loss: 8531.5371, RMSE: 92.3663, R²: -0.0090
   Validation - Loss: 8581.8877, RMSE: 92.6385, R²: -0.0198
💾 Training metrics saved to: logs/client_22_training_metrics_20251030_111346.csv

🧪 Round 9 Evaluation Results:
   Test Loss: 9171.0655
   RMSE: 95.7657, MAE: 74.8070, R²: -0.0366
💾 Test metrics saved to: logs/client_22_test_metrics_20251030_111346.csv

🔍 Running 3-fold cross-validation (Round 10)
💾 CV metrics saved to: logs/client_22_cv_metrics_20251030_111346.csv

🔄 Starting local training (Round 10)...
   Epoch 1/1: train_loss=9498.0043, val_rmse=92.7403 ⭐ (improved by inf)
   ✅ Completed 1 epochs, using best model (val_rmse=92.7403)

🎯 Round 10 Training Summary:
   Epochs trained: 1/1
   Total early stops so far: 0
   Training   - Loss: 8544.4404, RMSE: 92.4361, R²: -0.0105
   Validation - Loss: 8600.7715, RMSE: 92.7403, R²: -0.0220
💾 Training metrics saved to: logs/client_22_training_metrics_20251030_111346.csv

🧪 Round 10 Evaluation Results:
   Test Loss: 9651.1121
   RMSE: 98.2401, MAE: 75.7636, R²: -0.0909
💾 Test metrics saved to: logs/client_22_test_metrics_20251030_111346.csv

================================================================================
🎯 FINAL COMPREHENSIVE REPORT
================================================================================
💾 Final summary saved to: logs/client_22_final_summary_20251030_111346.csv

📊 CLIENT: client_22 | ALGORITHM: fedavgm | MODEL: LSTM
📈 TOTAL ROUNDS: 10

⚙️  HYPERPARAMETERS:
   Learning Rate: 0.001
   Batch Size: 32
   Local Epochs: 1
   Hidden Dim: 64
   Num Layers: 2
   Sequence Length: 10
   Use Attention: False
   Dropout: 0.3
   Optimizer: adam

🛑 EARLY STOPPING SUMMARY:
   Enabled: Yes
   Patience: 3 epochs
   Min delta: 0.001
   Total early stops: 0/10 rounds
   Early stop rate: 0.0%

🏁 FINAL ROUND PERFORMANCE:
   Training   - Loss:  8544.44 | RMSE:  92.44 | R²: -0.0105
   Validation - Loss:  8600.77 | RMSE:  92.74 | R²: -0.0220
   Test       - Loss:  9651.11 | RMSE:  98.24 | R²: -0.0909

📊 STATISTICS ACROSS ALL ROUNDS (Mean ± Std):
   Training Loss:    8541.44 ±  20.99
   Validation Loss:  8595.87 ±  30.30
   Test Loss:       12728.34 ± 4646.89

   Training RMSE:    92.42 ±  0.11
   Validation RMSE:  92.71 ±  0.16
   Test RMSE:       111.16 ± 19.30

   Training R²:     -0.0101 ± 0.0025
   Validation R²:   -0.0214 ± 0.0036
   Test R²:         -0.4387 ± 0.5252

⭐ BEST PERFORMANCE:
   Best Round: 8 (Test R²: -0.0000)

📋 DATA SUMMARY:
   Training samples:   4056
   Validation samples: 1346
   Test samples:       1346
   Total samples:      6748
================================================================================
✅ Client client_22 completed | Algorithm: FEDAVGM
