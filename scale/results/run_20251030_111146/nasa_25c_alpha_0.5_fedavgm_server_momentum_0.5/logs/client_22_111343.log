[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 70f6b3a5-9e12-466b-b683-b8ff76750cab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message be02ba06-f4e3-4989-bc79-5077c3c2bba6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2dee05f7-8fd7-43ae-b453-7014ef2f7ff4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b330deb5-4dba-4c96-b02c-a3f4189b6c78
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b91d41f7-1d94-41d4-b3a4-c10352c83d83
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3981a6a6-e2ab-499c-8bca-45f6c43651d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message da2ef337-cc3d-4dff-850d-85e112d631c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2077a34d-8b84-4ec9-91fd-292e7bcae914
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1d9877fa-8acd-4da8-8d56-06b46c38a3d9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ca347f78-7b38-4de0-8234-63820edf5b5e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cb635313-b52b-4a9d-b6b3-6746b4e8f877
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dd736bf7-a86f-4a78-a8d5-7f19ee8e1c89
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f37eb0d4-f2ea-4724-adad-2471b07d8edd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8e7c1645-38e4-44a5-a55e-720a8a52cff6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a2bbdee5-acb4-44b7-b1e1-5f933ea8851b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b5e6f5ec-c395-4337-9008-1a0193c9b3f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ace97936-a109-4034-b613-589aad5676fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ff4cdd20-d4d2-4d9d-ab98-182a32d57166
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 100ae66b-97ef-4ac1-ac02-142450dbbd21
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 934c4308-4a80-4e1f-93a2-619b80afb715
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: reconnect message f6cafaf6-3d04-4b1e-9d85-aba106335cdb
[92mINFO [0m:      Disconnect and shut down
ğŸš€ Starting NASA FL Client: client_22
Algorithm: FEDAVGM
Server: localhost:8687
K-Folds: 5
Log Directory: logs
ğŸ”„ Using device: cuda
ğŸ¯ GPU: NVIDIA A100-SXM4-80GB
ğŸ›‘ Early stopping enabled:
   Patience: 3 epochs
   Min delta: 0.001
ğŸ’¾ Hyperparameters saved to: logs/client_22_hyperparams_20251030_111346.csv
ğŸ” Looking for data at: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.5/client_22
ğŸ“Š Loaded 6778 total samples from /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.5/client_22
ğŸ”¢ Original feature dimension: 24
ğŸ” Applying KernelPCA with 5 components, kernel=poly
ğŸ“Š Data shape - Before: (4066, 24), After: (4066, 5)
ğŸ”„ Created sequences with length 10
   Final dataset shape: X (4056, 10, 5), y (4056,)
âœ… Data split completed:
   Training samples: 4056
   Validation samples: 1346
   Test samples: 1346
   Model type: lstm
   Final input dimension: 5
âœ… Client client_22 ready:
   Model: LSTM
   Training: 4056 samples
   Device: cuda
   Validation: 1346 samples
   Test: 1346 samples
   Algorithm: fedavgm
   Total Rounds: 10
   Learning Rate: 0.001
   Batch Size: 32
   Logging to: logs
â© Skipping CV for Round 1

ğŸ”„ Starting local training (Round 1)...
   Epoch 1/1: train_loss=21481.8775, val_rmse=106.8948 â­ (improved by inf)
   âœ… Completed 1 epochs, using best model (val_rmse=106.8948)
Round 1: epochs=1, train_loss=11023.5625, val_rmse=106.8948, val_r2=-0.3578

ğŸ§ª Round 1 Evaluation Results:
   Test Loss: 15875.3258
   RMSE: 125.9973, MAE: 95.1751, RÂ²: -0.7944
ğŸ’¾ Test metrics saved to: logs/client_22_test_metrics_20251030_111346.csv
â© Skipping CV for Round 2

ğŸ”„ Starting local training (Round 2)...
   Epoch 1/1: train_loss=10226.8581, val_rmse=93.0408 â­ (improved by inf)
   âœ… Completed 1 epochs, using best model (val_rmse=93.0408)
Round 2: epochs=1, train_loss=8584.1660, val_rmse=93.0408, val_r2=-0.0287
ğŸ’¾ Training metrics saved to: logs/client_22_training_metrics_20251030_111346.csv

ğŸ§ª Round 2 Evaluation Results:
   Test Loss: 22964.4971
   RMSE: 151.5404, MAE: 133.3855, RÂ²: -1.5957
ğŸ’¾ Test metrics saved to: logs/client_22_test_metrics_20251030_111346.csv
â© Skipping CV for Round 3

ğŸ”„ Starting local training (Round 3)...
   Epoch 1/1: train_loss=11254.9060, val_rmse=92.6254 â­ (improved by inf)
   âœ… Completed 1 epochs, using best model (val_rmse=92.6254)

ğŸ¯ Round 3 Training Summary:
   Epochs trained: 1/1
   Total early stops so far: 0
   Training   - Loss: 8529.9023, RMSE: 92.3575, RÂ²: -0.0088
   Validation - Loss: 8579.4570, RMSE: 92.6254, RÂ²: -0.0195

ğŸ§ª Round 3 Evaluation Results:
   Test Loss: 18641.3740
   RMSE: 136.5334, MAE: 118.5430, RÂ²: -1.1070
ğŸ’¾ Test metrics saved to: logs/client_22_test_metrics_20251030_111346.csv
â© Skipping CV for Round 4

ğŸ”„ Starting local training (Round 4)...
   Epoch 1/1: train_loss=10916.1645, val_rmse=92.6999 â­ (improved by inf)
   âœ… Completed 1 epochs, using best model (val_rmse=92.6999)
Round 4: epochs=1, train_loss=8539.2822, val_rmse=92.6999, val_r2=-0.0211
ğŸ’¾ Training metrics saved to: logs/client_22_training_metrics_20251030_111346.csv

ğŸ§ª Round 4 Evaluation Results:
   Test Loss: 9607.5556
   RMSE: 98.0181, MAE: 75.6616, RÂ²: -0.0859
ğŸ’¾ Test metrics saved to: logs/client_22_test_metrics_20251030_111346.csv

ğŸ” Running 3-fold cross-validation (Round 5)

ğŸ” Starting 3-fold cross-validation on TRAINING data for client client_22

ğŸ“Š Fold 1/3
   Fold 1 Results:
     Val Loss: 8307.7334
     Val RMSE: 91.1468, Val RÂ²: -0.0105

ğŸ“Š Fold 2/3
   Fold 2 Results:
     Val Loss: 8378.4043
     Val RMSE: 91.5336, Val RÂ²: -0.0062

ğŸ“Š Fold 3/3
   Fold 3 Results:
     Val Loss: 8863.8994
     Val RMSE: 94.1483, Val RÂ²: -0.0055
ğŸ’¾ CV metrics saved to: logs/client_22_cv_metrics_20251030_111346.csv

ğŸ“ˆ 3-Fold CV Summary (Training Data):
   VAL_LOSS: 8516.6790 Â± 247.2112
   RMSE: 92.2762 Â± 1.3331
   R2: -0.0074 Â± 0.0022

ğŸ”„ Starting local training (Round 5)...
   Epoch 1/1: train_loss=9880.6934, val_rmse=92.7803 â­ (improved by inf)
   âœ… Completed 1 epochs, using best model (val_rmse=92.7803)

ğŸ¯ Round 5 Training Summary:
   Epochs trained: 1/1
   Total early stops so far: 0
   Training   - Loss: 8549.5938, RMSE: 92.4640, RÂ²: -0.0111
   Validation - Loss: 8608.1914, RMSE: 92.7803, RÂ²: -0.0229
ğŸ’¾ Training metrics saved to: logs/client_22_training_metrics_20251030_111346.csv

ğŸ§ª Round 5 Evaluation Results:
   Test Loss: 13029.4226
   RMSE: 114.1465, MAE: 85.6208, RÂ²: -0.4727
ğŸ’¾ Test metrics saved to: logs/client_22_test_metrics_20251030_111346.csv
â© Skipping CV for Round 6

ğŸ”„ Starting local training (Round 6)...
   Epoch 1/1: train_loss=10225.0996, val_rmse=92.6317 â­ (improved by inf)
   âœ… Completed 1 epochs, using best model (val_rmse=92.6317)

ğŸ¯ Round 6 Training Summary:
   Epochs trained: 1/1
   Total early stops so far: 0
   Training   - Loss: 8530.6865, RMSE: 92.3617, RÂ²: -0.0089
   Validation - Loss: 8580.6240, RMSE: 92.6317, RÂ²: -0.0196
ğŸ’¾ Training metrics saved to: logs/client_22_training_metrics_20251030_111346.csv

ğŸ§ª Round 6 Evaluation Results:
   Test Loss: 10616.0178
   RMSE: 103.0341, MAE: 78.2785, RÂ²: -0.1999
ğŸ’¾ Test metrics saved to: logs/client_22_test_metrics_20251030_111346.csv
â© Skipping CV for Round 7

ğŸ”„ Starting local training (Round 7)...
   Epoch 1/1: train_loss=9825.7032, val_rmse=92.7492 â­ (improved by inf)
   âœ… Completed 1 epochs, using best model (val_rmse=92.7492)
Round 7: epochs=1, train_loss=8545.5762, val_rmse=92.7492, val_r2=-0.0222

ğŸ§ª Round 7 Evaluation Results:
   Test Loss: 8879.5201
   RMSE: 94.2312, MAE: 74.8788, RÂ²: -0.0037
ğŸ’¾ Test metrics saved to: logs/client_22_test_metrics_20251030_111346.csv
â© Skipping CV for Round 8

ğŸ”„ Starting local training (Round 8)...
   Epoch 1/1: train_loss=9466.2217, val_rmse=92.4647 â­ (improved by inf)
   âœ… Completed 1 epochs, using best model (val_rmse=92.4647)
Round 8: epochs=1, train_loss=8510.4023, val_rmse=92.4647, val_r2=-0.0160
ğŸ’¾ Training metrics saved to: logs/client_22_training_metrics_20251030_111346.csv

ğŸ§ª Round 8 Evaluation Results:
   Test Loss: 8847.5018
   RMSE: 94.0612, MAE: 75.2930, RÂ²: -0.0000
ğŸ’¾ Test metrics saved to: logs/client_22_test_metrics_20251030_111346.csv

ğŸ” Running 3-fold cross-validation (Round 9)
ğŸ’¾ CV metrics saved to: logs/client_22_cv_metrics_20251030_111346.csv

ğŸ”„ Starting local training (Round 9)...
   Epoch 1/1: train_loss=9511.4876, val_rmse=92.6385 â­ (improved by inf)
   âœ… Completed 1 epochs, using best model (val_rmse=92.6385)

ğŸ¯ Round 9 Training Summary:
   Epochs trained: 1/1
   Total early stops so far: 0
   Training   - Loss: 8531.5371, RMSE: 92.3663, RÂ²: -0.0090
   Validation - Loss: 8581.8877, RMSE: 92.6385, RÂ²: -0.0198
ğŸ’¾ Training metrics saved to: logs/client_22_training_metrics_20251030_111346.csv

ğŸ§ª Round 9 Evaluation Results:
   Test Loss: 9171.0655
   RMSE: 95.7657, MAE: 74.8070, RÂ²: -0.0366
ğŸ’¾ Test metrics saved to: logs/client_22_test_metrics_20251030_111346.csv

ğŸ” Running 3-fold cross-validation (Round 10)
ğŸ’¾ CV metrics saved to: logs/client_22_cv_metrics_20251030_111346.csv

ğŸ”„ Starting local training (Round 10)...
   Epoch 1/1: train_loss=9498.0043, val_rmse=92.7403 â­ (improved by inf)
   âœ… Completed 1 epochs, using best model (val_rmse=92.7403)

ğŸ¯ Round 10 Training Summary:
   Epochs trained: 1/1
   Total early stops so far: 0
   Training   - Loss: 8544.4404, RMSE: 92.4361, RÂ²: -0.0105
   Validation - Loss: 8600.7715, RMSE: 92.7403, RÂ²: -0.0220
ğŸ’¾ Training metrics saved to: logs/client_22_training_metrics_20251030_111346.csv

ğŸ§ª Round 10 Evaluation Results:
   Test Loss: 9651.1121
   RMSE: 98.2401, MAE: 75.7636, RÂ²: -0.0909
ğŸ’¾ Test metrics saved to: logs/client_22_test_metrics_20251030_111346.csv

================================================================================
ğŸ¯ FINAL COMPREHENSIVE REPORT
================================================================================
ğŸ’¾ Final summary saved to: logs/client_22_final_summary_20251030_111346.csv

ğŸ“Š CLIENT: client_22 | ALGORITHM: fedavgm | MODEL: LSTM
ğŸ“ˆ TOTAL ROUNDS: 10

âš™ï¸  HYPERPARAMETERS:
   Learning Rate: 0.001
   Batch Size: 32
   Local Epochs: 1
   Hidden Dim: 64
   Num Layers: 2
   Sequence Length: 10
   Use Attention: False
   Dropout: 0.3
   Optimizer: adam

ğŸ›‘ EARLY STOPPING SUMMARY:
   Enabled: Yes
   Patience: 3 epochs
   Min delta: 0.001
   Total early stops: 0/10 rounds
   Early stop rate: 0.0%

ğŸ FINAL ROUND PERFORMANCE:
   Training   - Loss:  8544.44 | RMSE:  92.44 | RÂ²: -0.0105
   Validation - Loss:  8600.77 | RMSE:  92.74 | RÂ²: -0.0220
   Test       - Loss:  9651.11 | RMSE:  98.24 | RÂ²: -0.0909

ğŸ“Š STATISTICS ACROSS ALL ROUNDS (Mean Â± Std):
   Training Loss:    8541.44 Â±  20.99
   Validation Loss:  8595.87 Â±  30.30
   Test Loss:       12728.34 Â± 4646.89

   Training RMSE:    92.42 Â±  0.11
   Validation RMSE:  92.71 Â±  0.16
   Test RMSE:       111.16 Â± 19.30

   Training RÂ²:     -0.0101 Â± 0.0025
   Validation RÂ²:   -0.0214 Â± 0.0036
   Test RÂ²:         -0.4387 Â± 0.5252

â­ BEST PERFORMANCE:
   Best Round: 8 (Test RÂ²: -0.0000)

ğŸ“‹ DATA SUMMARY:
   Training samples:   4056
   Validation samples: 1346
   Test samples:       1346
   Total samples:      6748
================================================================================
âœ… Client client_22 completed | Algorithm: FEDAVGM
