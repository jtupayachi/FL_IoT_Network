[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3d0824b1-a176-446c-b257-6c47b387cb84
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 823f9ce1-a2bb-44a6-9de6-f59c234e0e20
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e1c457c8-d51f-462c-a959-a249ae2fcafb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bc63b8f9-8ae8-45d0-a769-f447ee1b0e0a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b5a70cf5-6fb4-49c3-bcb1-be1100b2c104
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7c011334-931b-4cc9-a391-d7ea229f5d45
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c7f206e6-5a4b-4535-90f7-1bf92caf463b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b9200a60-ac21-469c-86ae-443b7b733d49
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 042f8346-946b-4e22-98c7-ca7925dfacc2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7c20248a-ae4d-4fe6-98fa-329ec735a56d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 952643c3-99cd-417a-8f88-50bfca1c4d75
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9e402d9f-1997-4061-b648-7a8b95e9c037
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4fa639b8-26e8-4fbb-83c0-44ca34b8e685
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5aa74b03-cffe-4b39-b14a-c406e70f0304
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 479bdb42-efc9-42e8-9a4a-e3af66faf961
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e65a748a-1faf-46e2-8008-e86f3db8acb7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 49a847d7-3d1a-4455-ac29-00b211647644
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a558f06b-de2e-4bfe-baa5-c59aa8d4a08b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e1bff6d7-eb3e-48ef-86d6-7c34cd2adc9d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f29d15be-f071-40fc-b590-e9f72270a407
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: reconnect message 1f11b40f-e96f-45cd-abf0-76ce890fd03f
[92mINFO [0m:      Disconnect and shut down
ğŸš€ Starting NASA FL Client: client_2
Algorithm: FEDAVGM
Server: localhost:8687
K-Folds: 5
Log Directory: logs
ğŸ”„ Using device: cuda
ğŸ¯ GPU: NVIDIA A100-SXM4-80GB
ğŸ›‘ Early stopping enabled:
   Patience: 3 epochs
   Min delta: 0.001
ğŸ’¾ Hyperparameters saved to: logs/client_2_hyperparams_20251030_111326.csv
ğŸ” Looking for data at: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.5/client_2
ğŸ“Š Loaded 6296 total samples from /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.5/client_2
ğŸ”¢ Original feature dimension: 24
ğŸ” Applying KernelPCA with 5 components, kernel=poly
ğŸ“Š Data shape - Before: (3777, 24), After: (3777, 5)
ğŸ”„ Created sequences with length 10
   Final dataset shape: X (3767, 10, 5), y (3767,)
âœ… Data split completed:
   Training samples: 3767
   Validation samples: 1249
   Test samples: 1250
   Model type: lstm
   Final input dimension: 5
âœ… Client client_2 ready:
   Model: LSTM
   Training: 3767 samples
   Device: cuda
   Validation: 1249 samples
   Test: 1250 samples
   Algorithm: fedavgm
   Total Rounds: 10
   Learning Rate: 0.001
   Batch Size: 32
   Logging to: logs
â© Skipping CV for Round 1

ğŸ”„ Starting local training (Round 1)...
   Epoch 1/1: train_loss=20171.5667, val_rmse=110.3833 â­ (improved by inf)
   âœ… Completed 1 epochs, using best model (val_rmse=110.3833)
Round 1: epochs=1, train_loss=11547.3213, val_rmse=110.3833, val_r2=-0.5914

ğŸ§ª Round 1 Evaluation Results:
   Test Loss: 13511.7519
   RMSE: 116.2401, MAE: 89.4818, RÂ²: -0.8850
ğŸ’¾ Test metrics saved to: logs/client_2_test_metrics_20251030_111326.csv
â© Skipping CV for Round 2

ğŸ”„ Starting local training (Round 2)...
   Epoch 1/1: train_loss=9263.0776, val_rmse=88.4063 â­ (improved by inf)
   âœ… Completed 1 epochs, using best model (val_rmse=88.4063)
Round 2: epochs=1, train_loss=7566.0640, val_rmse=88.4063, val_r2=-0.0208
ğŸ’¾ Training metrics saved to: logs/client_2_training_metrics_20251030_111326.csv

ğŸ§ª Round 2 Evaluation Results:
   Test Loss: 22297.5154
   RMSE: 149.3235, MAE: 132.3853, RÂ²: -2.1107
ğŸ’¾ Test metrics saved to: logs/client_2_test_metrics_20251030_111326.csv
â© Skipping CV for Round 3

ğŸ”„ Starting local training (Round 3)...
   Epoch 1/1: train_loss=10648.2207, val_rmse=88.4873 â­ (improved by inf)
   âœ… Completed 1 epochs, using best model (val_rmse=88.4873)

ğŸ¯ Round 3 Training Summary:
   Epochs trained: 1/1
   Total early stops so far: 0
   Training   - Loss: 7576.4502, RMSE: 87.0428, RÂ²: -0.0124
   Validation - Loss: 7829.9951, RMSE: 88.4873, RÂ²: -0.0227

ğŸ§ª Round 3 Evaluation Results:
   Test Loss: 17808.2015
   RMSE: 133.4474, MAE: 117.0315, RÂ²: -1.4844
ğŸ’¾ Test metrics saved to: logs/client_2_test_metrics_20251030_111326.csv
â© Skipping CV for Round 4

ğŸ”„ Starting local training (Round 4)...
   Epoch 1/1: train_loss=10374.8191, val_rmse=88.5822 â­ (improved by inf)
   âœ… Completed 1 epochs, using best model (val_rmse=88.5822)
Round 4: epochs=1, train_loss=7588.8462, val_rmse=88.5822, val_r2=-0.0249
ğŸ’¾ Training metrics saved to: logs/client_2_training_metrics_20251030_111326.csv

ğŸ§ª Round 4 Evaluation Results:
   Test Loss: 7714.9785
   RMSE: 87.8350, MAE: 69.1333, RÂ²: -0.0763
ğŸ’¾ Test metrics saved to: logs/client_2_test_metrics_20251030_111326.csv

ğŸ” Running 3-fold cross-validation (Round 5)

ğŸ” Starting 3-fold cross-validation on TRAINING data for client client_2

ğŸ“Š Fold 1/3
   Fold 1 Results:
     Val Loss: 7690.0000
     Val RMSE: 87.6927, Val RÂ²: -0.0103

ğŸ“Š Fold 2/3
   Fold 2 Results:
     Val Loss: 7360.6611
     Val RMSE: 85.7943, Val RÂ²: -0.0050

ğŸ“Š Fold 3/3
   Fold 3 Results:
     Val Loss: 7556.3389
     Val RMSE: 86.9272, Val RÂ²: -0.0057
ğŸ’¾ CV metrics saved to: logs/client_2_cv_metrics_20251030_111326.csv

ğŸ“ˆ 3-Fold CV Summary (Training Data):
   VAL_LOSS: 7535.6667 Â± 135.2443
   RMSE: 86.8047 Â± 0.7798
   R2: -0.0070 Â± 0.0023

ğŸ”„ Starting local training (Round 5)...
   Epoch 1/1: train_loss=8695.7006, val_rmse=88.4229 â­ (improved by inf)
   âœ… Completed 1 epochs, using best model (val_rmse=88.4229)

ğŸ¯ Round 5 Training Summary:
   Epochs trained: 1/1
   Total early stops so far: 0
   Training   - Loss: 7568.1821, RMSE: 86.9953, RÂ²: -0.0113
   Validation - Loss: 7818.6133, RMSE: 88.4229, RÂ²: -0.0212
ğŸ’¾ Training metrics saved to: logs/client_2_training_metrics_20251030_111326.csv

ğŸ§ª Round 5 Evaluation Results:
   Test Loss: 10826.2848
   RMSE: 104.0494, MAE: 79.5255, RÂ²: -0.5104
ğŸ’¾ Test metrics saved to: logs/client_2_test_metrics_20251030_111326.csv
â© Skipping CV for Round 6

ğŸ”„ Starting local training (Round 6)...
   Epoch 1/1: train_loss=9003.1393, val_rmse=88.5185 â­ (improved by inf)
   âœ… Completed 1 epochs, using best model (val_rmse=88.5185)

ğŸ¯ Round 6 Training Summary:
   Epochs trained: 1/1
   Total early stops so far: 0
   Training   - Loss: 7580.5073, RMSE: 87.0661, RÂ²: -0.0129
   Validation - Loss: 7835.5293, RMSE: 88.5185, RÂ²: -0.0234
ğŸ’¾ Training metrics saved to: logs/client_2_training_metrics_20251030_111326.csv

ğŸ§ª Round 6 Evaluation Results:
   Test Loss: 8602.1931
   RMSE: 92.7480, MAE: 71.8376, RÂ²: -0.2001
ğŸ’¾ Test metrics saved to: logs/client_2_test_metrics_20251030_111326.csv
â© Skipping CV for Round 7

ğŸ”„ Starting local training (Round 7)...
   Epoch 1/1: train_loss=8563.3665, val_rmse=88.4601 â­ (improved by inf)
   âœ… Completed 1 epochs, using best model (val_rmse=88.4601)
Round 7: epochs=1, train_loss=7572.9438, val_rmse=88.4601, val_r2=-0.0220

ğŸ§ª Round 7 Evaluation Results:
   Test Loss: 7170.1751
   RMSE: 84.6769, MAE: 68.4035, RÂ²: -0.0003
ğŸ’¾ Test metrics saved to: logs/client_2_test_metrics_20251030_111326.csv
â© Skipping CV for Round 8

ğŸ”„ Starting local training (Round 8)...
   Epoch 1/1: train_loss=8646.7475, val_rmse=88.3920 â­ (improved by inf)
   âœ… Completed 1 epochs, using best model (val_rmse=88.3920)
Round 8: epochs=1, train_loss=7564.2495, val_rmse=88.3920, val_r2=-0.0205
ğŸ’¾ Training metrics saved to: logs/client_2_training_metrics_20251030_111326.csv

ğŸ§ª Round 8 Evaluation Results:
   Test Loss: 7180.8466
   RMSE: 84.7399, MAE: 68.9081, RÂ²: -0.0018
ğŸ’¾ Test metrics saved to: logs/client_2_test_metrics_20251030_111326.csv

ğŸ” Running 3-fold cross-validation (Round 9)
ğŸ’¾ CV metrics saved to: logs/client_2_cv_metrics_20251030_111326.csv

ğŸ”„ Starting local training (Round 9)...
   Epoch 1/1: train_loss=8828.2477, val_rmse=88.4343 â­ (improved by inf)
   âœ… Completed 1 epochs, using best model (val_rmse=88.4343)

ğŸ¯ Round 9 Training Summary:
   Epochs trained: 1/1
   Total early stops so far: 0
   Training   - Loss: 7569.6328, RMSE: 87.0036, RÂ²: -0.0115
   Validation - Loss: 7820.6211, RMSE: 88.4343, RÂ²: -0.0214
ğŸ’¾ Training metrics saved to: logs/client_2_training_metrics_20251030_111326.csv

ğŸ§ª Round 9 Evaluation Results:
   Test Loss: 7358.6742
   RMSE: 85.7827, MAE: 68.2533, RÂ²: -0.0266
ğŸ’¾ Test metrics saved to: logs/client_2_test_metrics_20251030_111326.csv

ğŸ” Running 3-fold cross-validation (Round 10)
ğŸ’¾ CV metrics saved to: logs/client_2_cv_metrics_20251030_111326.csv

ğŸ”„ Starting local training (Round 10)...
   Epoch 1/1: train_loss=8535.6787, val_rmse=88.5361 â­ (improved by inf)
   âœ… Completed 1 epochs, using best model (val_rmse=88.5361)

ğŸ¯ Round 10 Training Summary:
   Epochs trained: 1/1
   Total early stops so far: 0
   Training   - Loss: 7582.7998, RMSE: 87.0793, RÂ²: -0.0132
   Validation - Loss: 7838.6426, RMSE: 88.5361, RÂ²: -0.0238
ğŸ’¾ Training metrics saved to: logs/client_2_training_metrics_20251030_111326.csv

ğŸ§ª Round 10 Evaluation Results:
   Test Loss: 7752.0152
   RMSE: 88.0455, MAE: 69.2343, RÂ²: -0.0815
ğŸ’¾ Test metrics saved to: logs/client_2_test_metrics_20251030_111326.csv

================================================================================
ğŸ¯ FINAL COMPREHENSIVE REPORT
================================================================================
ğŸ’¾ Final summary saved to: logs/client_2_final_summary_20251030_111326.csv

ğŸ“Š CLIENT: client_2 | ALGORITHM: fedavgm | MODEL: LSTM
ğŸ“ˆ TOTAL ROUNDS: 10

âš™ï¸  HYPERPARAMETERS:
   Learning Rate: 0.001
   Batch Size: 32
   Local Epochs: 1
   Hidden Dim: 64
   Num Layers: 2
   Sequence Length: 10
   Use Attention: False
   Dropout: 0.3
   Optimizer: adam

ğŸ›‘ EARLY STOPPING SUMMARY:
   Enabled: Yes
   Patience: 3 epochs
   Min delta: 0.001
   Total early stops: 0/10 rounds
   Early stop rate: 0.0%

ğŸ FINAL ROUND PERFORMANCE:
   Training   - Loss:  7582.80 | RMSE:  87.08 | RÂ²: -0.0132
   Validation - Loss:  7838.64 | RMSE:  88.54 | RÂ²: -0.0238
   Test       - Loss:  7752.02 | RMSE:  88.05 | RÂ²: -0.0815

ğŸ“Š STATISTICS ACROSS ALL ROUNDS (Mean Â± Std):
   Training Loss:    7574.33 Â±   8.87
   Validation Loss:  7827.01 Â±  12.14
   Test Loss:       11022.26 Â± 4999.23

   Training RMSE:    87.03 Â±  0.05
   Validation RMSE:  88.47 Â±  0.07
   Test RMSE:       102.69 Â± 21.85

   Training RÂ²:     -0.0121 Â± 0.0012
   Validation RÂ²:   -0.0223 Â± 0.0016
   Test RÂ²:         -0.5377 Â± 0.6974

â­ BEST PERFORMANCE:
   Best Round: 7 (Test RÂ²: -0.0003)

ğŸ“‹ DATA SUMMARY:
   Training samples:   3767
   Validation samples: 1249
   Test samples:       1250
   Total samples:      6266
================================================================================
âœ… Client client_2 completed | Algorithm: FEDAVGM
