[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3d0824b1-a176-446c-b257-6c47b387cb84
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 823f9ce1-a2bb-44a6-9de6-f59c234e0e20
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e1c457c8-d51f-462c-a959-a249ae2fcafb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bc63b8f9-8ae8-45d0-a769-f447ee1b0e0a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b5a70cf5-6fb4-49c3-bcb1-be1100b2c104
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7c011334-931b-4cc9-a391-d7ea229f5d45
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c7f206e6-5a4b-4535-90f7-1bf92caf463b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b9200a60-ac21-469c-86ae-443b7b733d49
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 042f8346-946b-4e22-98c7-ca7925dfacc2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7c20248a-ae4d-4fe6-98fa-329ec735a56d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 952643c3-99cd-417a-8f88-50bfca1c4d75
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9e402d9f-1997-4061-b648-7a8b95e9c037
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4fa639b8-26e8-4fbb-83c0-44ca34b8e685
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5aa74b03-cffe-4b39-b14a-c406e70f0304
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 479bdb42-efc9-42e8-9a4a-e3af66faf961
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e65a748a-1faf-46e2-8008-e86f3db8acb7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 49a847d7-3d1a-4455-ac29-00b211647644
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a558f06b-de2e-4bfe-baa5-c59aa8d4a08b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e1bff6d7-eb3e-48ef-86d6-7c34cd2adc9d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f29d15be-f071-40fc-b590-e9f72270a407
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: reconnect message 1f11b40f-e96f-45cd-abf0-76ce890fd03f
[92mINFO [0m:      Disconnect and shut down
🚀 Starting NASA FL Client: client_2
Algorithm: FEDAVGM
Server: localhost:8687
K-Folds: 5
Log Directory: logs
🔄 Using device: cuda
🎯 GPU: NVIDIA A100-SXM4-80GB
🛑 Early stopping enabled:
   Patience: 3 epochs
   Min delta: 0.001
💾 Hyperparameters saved to: logs/client_2_hyperparams_20251030_111326.csv
🔍 Looking for data at: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.5/client_2
📊 Loaded 6296 total samples from /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.5/client_2
🔢 Original feature dimension: 24
🔍 Applying KernelPCA with 5 components, kernel=poly
📊 Data shape - Before: (3777, 24), After: (3777, 5)
🔄 Created sequences with length 10
   Final dataset shape: X (3767, 10, 5), y (3767,)
✅ Data split completed:
   Training samples: 3767
   Validation samples: 1249
   Test samples: 1250
   Model type: lstm
   Final input dimension: 5
✅ Client client_2 ready:
   Model: LSTM
   Training: 3767 samples
   Device: cuda
   Validation: 1249 samples
   Test: 1250 samples
   Algorithm: fedavgm
   Total Rounds: 10
   Learning Rate: 0.001
   Batch Size: 32
   Logging to: logs
⏩ Skipping CV for Round 1

🔄 Starting local training (Round 1)...
   Epoch 1/1: train_loss=20171.5667, val_rmse=110.3833 ⭐ (improved by inf)
   ✅ Completed 1 epochs, using best model (val_rmse=110.3833)
Round 1: epochs=1, train_loss=11547.3213, val_rmse=110.3833, val_r2=-0.5914

🧪 Round 1 Evaluation Results:
   Test Loss: 13511.7519
   RMSE: 116.2401, MAE: 89.4818, R²: -0.8850
💾 Test metrics saved to: logs/client_2_test_metrics_20251030_111326.csv
⏩ Skipping CV for Round 2

🔄 Starting local training (Round 2)...
   Epoch 1/1: train_loss=9263.0776, val_rmse=88.4063 ⭐ (improved by inf)
   ✅ Completed 1 epochs, using best model (val_rmse=88.4063)
Round 2: epochs=1, train_loss=7566.0640, val_rmse=88.4063, val_r2=-0.0208
💾 Training metrics saved to: logs/client_2_training_metrics_20251030_111326.csv

🧪 Round 2 Evaluation Results:
   Test Loss: 22297.5154
   RMSE: 149.3235, MAE: 132.3853, R²: -2.1107
💾 Test metrics saved to: logs/client_2_test_metrics_20251030_111326.csv
⏩ Skipping CV for Round 3

🔄 Starting local training (Round 3)...
   Epoch 1/1: train_loss=10648.2207, val_rmse=88.4873 ⭐ (improved by inf)
   ✅ Completed 1 epochs, using best model (val_rmse=88.4873)

🎯 Round 3 Training Summary:
   Epochs trained: 1/1
   Total early stops so far: 0
   Training   - Loss: 7576.4502, RMSE: 87.0428, R²: -0.0124
   Validation - Loss: 7829.9951, RMSE: 88.4873, R²: -0.0227

🧪 Round 3 Evaluation Results:
   Test Loss: 17808.2015
   RMSE: 133.4474, MAE: 117.0315, R²: -1.4844
💾 Test metrics saved to: logs/client_2_test_metrics_20251030_111326.csv
⏩ Skipping CV for Round 4

🔄 Starting local training (Round 4)...
   Epoch 1/1: train_loss=10374.8191, val_rmse=88.5822 ⭐ (improved by inf)
   ✅ Completed 1 epochs, using best model (val_rmse=88.5822)
Round 4: epochs=1, train_loss=7588.8462, val_rmse=88.5822, val_r2=-0.0249
💾 Training metrics saved to: logs/client_2_training_metrics_20251030_111326.csv

🧪 Round 4 Evaluation Results:
   Test Loss: 7714.9785
   RMSE: 87.8350, MAE: 69.1333, R²: -0.0763
💾 Test metrics saved to: logs/client_2_test_metrics_20251030_111326.csv

🔍 Running 3-fold cross-validation (Round 5)

🔍 Starting 3-fold cross-validation on TRAINING data for client client_2

📊 Fold 1/3
   Fold 1 Results:
     Val Loss: 7690.0000
     Val RMSE: 87.6927, Val R²: -0.0103

📊 Fold 2/3
   Fold 2 Results:
     Val Loss: 7360.6611
     Val RMSE: 85.7943, Val R²: -0.0050

📊 Fold 3/3
   Fold 3 Results:
     Val Loss: 7556.3389
     Val RMSE: 86.9272, Val R²: -0.0057
💾 CV metrics saved to: logs/client_2_cv_metrics_20251030_111326.csv

📈 3-Fold CV Summary (Training Data):
   VAL_LOSS: 7535.6667 ± 135.2443
   RMSE: 86.8047 ± 0.7798
   R2: -0.0070 ± 0.0023

🔄 Starting local training (Round 5)...
   Epoch 1/1: train_loss=8695.7006, val_rmse=88.4229 ⭐ (improved by inf)
   ✅ Completed 1 epochs, using best model (val_rmse=88.4229)

🎯 Round 5 Training Summary:
   Epochs trained: 1/1
   Total early stops so far: 0
   Training   - Loss: 7568.1821, RMSE: 86.9953, R²: -0.0113
   Validation - Loss: 7818.6133, RMSE: 88.4229, R²: -0.0212
💾 Training metrics saved to: logs/client_2_training_metrics_20251030_111326.csv

🧪 Round 5 Evaluation Results:
   Test Loss: 10826.2848
   RMSE: 104.0494, MAE: 79.5255, R²: -0.5104
💾 Test metrics saved to: logs/client_2_test_metrics_20251030_111326.csv
⏩ Skipping CV for Round 6

🔄 Starting local training (Round 6)...
   Epoch 1/1: train_loss=9003.1393, val_rmse=88.5185 ⭐ (improved by inf)
   ✅ Completed 1 epochs, using best model (val_rmse=88.5185)

🎯 Round 6 Training Summary:
   Epochs trained: 1/1
   Total early stops so far: 0
   Training   - Loss: 7580.5073, RMSE: 87.0661, R²: -0.0129
   Validation - Loss: 7835.5293, RMSE: 88.5185, R²: -0.0234
💾 Training metrics saved to: logs/client_2_training_metrics_20251030_111326.csv

🧪 Round 6 Evaluation Results:
   Test Loss: 8602.1931
   RMSE: 92.7480, MAE: 71.8376, R²: -0.2001
💾 Test metrics saved to: logs/client_2_test_metrics_20251030_111326.csv
⏩ Skipping CV for Round 7

🔄 Starting local training (Round 7)...
   Epoch 1/1: train_loss=8563.3665, val_rmse=88.4601 ⭐ (improved by inf)
   ✅ Completed 1 epochs, using best model (val_rmse=88.4601)
Round 7: epochs=1, train_loss=7572.9438, val_rmse=88.4601, val_r2=-0.0220

🧪 Round 7 Evaluation Results:
   Test Loss: 7170.1751
   RMSE: 84.6769, MAE: 68.4035, R²: -0.0003
💾 Test metrics saved to: logs/client_2_test_metrics_20251030_111326.csv
⏩ Skipping CV for Round 8

🔄 Starting local training (Round 8)...
   Epoch 1/1: train_loss=8646.7475, val_rmse=88.3920 ⭐ (improved by inf)
   ✅ Completed 1 epochs, using best model (val_rmse=88.3920)
Round 8: epochs=1, train_loss=7564.2495, val_rmse=88.3920, val_r2=-0.0205
💾 Training metrics saved to: logs/client_2_training_metrics_20251030_111326.csv

🧪 Round 8 Evaluation Results:
   Test Loss: 7180.8466
   RMSE: 84.7399, MAE: 68.9081, R²: -0.0018
💾 Test metrics saved to: logs/client_2_test_metrics_20251030_111326.csv

🔍 Running 3-fold cross-validation (Round 9)
💾 CV metrics saved to: logs/client_2_cv_metrics_20251030_111326.csv

🔄 Starting local training (Round 9)...
   Epoch 1/1: train_loss=8828.2477, val_rmse=88.4343 ⭐ (improved by inf)
   ✅ Completed 1 epochs, using best model (val_rmse=88.4343)

🎯 Round 9 Training Summary:
   Epochs trained: 1/1
   Total early stops so far: 0
   Training   - Loss: 7569.6328, RMSE: 87.0036, R²: -0.0115
   Validation - Loss: 7820.6211, RMSE: 88.4343, R²: -0.0214
💾 Training metrics saved to: logs/client_2_training_metrics_20251030_111326.csv

🧪 Round 9 Evaluation Results:
   Test Loss: 7358.6742
   RMSE: 85.7827, MAE: 68.2533, R²: -0.0266
💾 Test metrics saved to: logs/client_2_test_metrics_20251030_111326.csv

🔍 Running 3-fold cross-validation (Round 10)
💾 CV metrics saved to: logs/client_2_cv_metrics_20251030_111326.csv

🔄 Starting local training (Round 10)...
   Epoch 1/1: train_loss=8535.6787, val_rmse=88.5361 ⭐ (improved by inf)
   ✅ Completed 1 epochs, using best model (val_rmse=88.5361)

🎯 Round 10 Training Summary:
   Epochs trained: 1/1
   Total early stops so far: 0
   Training   - Loss: 7582.7998, RMSE: 87.0793, R²: -0.0132
   Validation - Loss: 7838.6426, RMSE: 88.5361, R²: -0.0238
💾 Training metrics saved to: logs/client_2_training_metrics_20251030_111326.csv

🧪 Round 10 Evaluation Results:
   Test Loss: 7752.0152
   RMSE: 88.0455, MAE: 69.2343, R²: -0.0815
💾 Test metrics saved to: logs/client_2_test_metrics_20251030_111326.csv

================================================================================
🎯 FINAL COMPREHENSIVE REPORT
================================================================================
💾 Final summary saved to: logs/client_2_final_summary_20251030_111326.csv

📊 CLIENT: client_2 | ALGORITHM: fedavgm | MODEL: LSTM
📈 TOTAL ROUNDS: 10

⚙️  HYPERPARAMETERS:
   Learning Rate: 0.001
   Batch Size: 32
   Local Epochs: 1
   Hidden Dim: 64
   Num Layers: 2
   Sequence Length: 10
   Use Attention: False
   Dropout: 0.3
   Optimizer: adam

🛑 EARLY STOPPING SUMMARY:
   Enabled: Yes
   Patience: 3 epochs
   Min delta: 0.001
   Total early stops: 0/10 rounds
   Early stop rate: 0.0%

🏁 FINAL ROUND PERFORMANCE:
   Training   - Loss:  7582.80 | RMSE:  87.08 | R²: -0.0132
   Validation - Loss:  7838.64 | RMSE:  88.54 | R²: -0.0238
   Test       - Loss:  7752.02 | RMSE:  88.05 | R²: -0.0815

📊 STATISTICS ACROSS ALL ROUNDS (Mean ± Std):
   Training Loss:    7574.33 ±   8.87
   Validation Loss:  7827.01 ±  12.14
   Test Loss:       11022.26 ± 4999.23

   Training RMSE:    87.03 ±  0.05
   Validation RMSE:  88.47 ±  0.07
   Test RMSE:       102.69 ± 21.85

   Training R²:     -0.0121 ± 0.0012
   Validation R²:   -0.0223 ± 0.0016
   Test R²:         -0.5377 ± 0.6974

⭐ BEST PERFORMANCE:
   Best Round: 7 (Test R²: -0.0003)

📋 DATA SUMMARY:
   Training samples:   3767
   Validation samples: 1249
   Test samples:       1250
   Total samples:      6266
================================================================================
✅ Client client_2 completed | Algorithm: FEDAVGM
