[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 71ecb48d-a32d-466d-b457-91a38b909acb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b610e6d4-2982-4d73-ab24-bd3c025fd6b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 75d5db65-5c16-4aaa-8e83-1574e57c97ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ff18b018-1b08-4d4a-92be-ddf8122d486b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 769b8cdb-9666-483d-ba68-cf7940482a58
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4bfd61c4-3ffc-4b9f-9695-1c6b9f0abdfe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 14e65c8f-ac9d-458b-a1f8-42c0ec17baba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f1135984-ad5f-4cae-952c-ea28ff14275e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c8ec72ad-7580-424a-8d53-6d7b7259a5ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ad09c4e7-790b-4d9a-93bb-703b1085831a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 53f9a228-fa46-4956-89d4-3cb1f8183c9b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message efd52b96-7fd4-41ea-b8bd-c4638cc8b1ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0344a8cd-8755-4a2a-90bc-716233772074
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c88e9175-fa06-4542-8f82-29ba3c319ed8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 44583be8-dedd-4ff4-b96a-9a394a213987
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f184f337-3584-47f8-91e3-afc24341aa57
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 07cf0082-c2b4-480b-a5ab-00769984613f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 62be0599-be9a-402b-8bb4-ece91857d327
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 217e6fd5-577a-4a6b-a5cd-df3f0d481c5e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: reconnect message c533d820-14e2-476b-aefb-49189315a4b3
[92mINFO [0m:      Disconnect and shut down
ğŸš€ Starting NASA FL Client: client_12
Algorithm: FEDAVGM
Server: localhost:8688
K-Folds: 5
Log Directory: logs
ğŸ”„ Using device: cuda
ğŸ¯ GPU: NVIDIA A100-SXM4-80GB
ğŸ›‘ Early stopping enabled:
   Patience: 3 epochs
   Min delta: 0.001
ğŸ’¾ Hyperparameters saved to: logs/client_12_hyperparams_20251030_111500.csv
ğŸ” Looking for data at: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.5/client_12
ğŸ“Š Loaded 7920 total samples from /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.5/client_12
ğŸ”¢ Original feature dimension: 24
ğŸ” Applying KernelPCA with 5 components, kernel=poly
ğŸ“Š Data shape - Before: (4752, 24), After: (4752, 5)
ğŸ”„ Created sequences with length 10
   Final dataset shape: X (4742, 10, 5), y (4742,)
âœ… Data split completed:
   Training samples: 4742
   Validation samples: 1574
   Test samples: 1574
   Model type: lstm
   Final input dimension: 5
âœ… Client client_12 ready:
   Model: LSTM
   Training: 4742 samples
   Device: cuda
   Validation: 1574 samples
   Test: 1574 samples
   Algorithm: fedavgm
   Total Rounds: 10
   Learning Rate: 0.001
   Batch Size: 32
   Logging to: logs

ğŸ§ª Round 0 Evaluation Results:
   Test Loss: 7115.4521
   RMSE: 84.3531, MAE: 68.3202, RÂ²: -0.3346
ğŸ’¾ Test metrics saved to: logs/client_12_test_metrics_20251030_111500.csv
â© Skipping CV for Round 2

ğŸ”„ Starting local training (Round 2)...
   Epoch 1/1: train_loss=6260.1632, val_rmse=72.1126 â­ (improved by inf)
   âœ… Completed 1 epochs, using best model (val_rmse=72.1126)
Round 2: epochs=1, train_loss=5322.8237, val_rmse=72.1126, val_r2=-0.0213
ğŸ’¾ Training metrics saved to: logs/client_12_training_metrics_20251030_111500.csv

ğŸ§ª Round 2 Evaluation Results:
   Test Loss: 140901.3433
   RMSE: 375.3683, MAE: 368.1981, RÂ²: -25.4280
ğŸ’¾ Test metrics saved to: logs/client_12_test_metrics_20251030_111500.csv
â© Skipping CV for Round 3

ğŸ”„ Starting local training (Round 3)...
   Epoch 1/1: train_loss=27128.7557, val_rmse=72.2523 â­ (improved by inf)
   âœ… Completed 1 epochs, using best model (val_rmse=72.2523)

ğŸ¯ Round 3 Training Summary:
   Epochs trained: 1/1
   Total early stops so far: 0
   Training   - Loss: 5342.7388, RMSE: 73.0940, RÂ²: -0.0241
   Validation - Loss: 5220.3872, RMSE: 72.2523, RÂ²: -0.0253

ğŸ§ª Round 3 Evaluation Results:
   Test Loss: 299252.4951
   RMSE: 547.0398, MAE: 542.1448, RÂ²: -55.1291
ğŸ’¾ Test metrics saved to: logs/client_12_test_metrics_20251030_111500.csv
â© Skipping CV for Round 4

ğŸ”„ Starting local training (Round 4)...
   Epoch 1/1: train_loss=64653.3362, val_rmse=94.7198 â­ (improved by inf)
   âœ… Completed 1 epochs, using best model (val_rmse=94.7198)
Round 4: epochs=1, train_loss=9114.0088, val_rmse=94.7198, val_r2=-0.7621
ğŸ’¾ Training metrics saved to: logs/client_12_training_metrics_20251030_111500.csv

ğŸ§ª Round 4 Evaluation Results:
   Test Loss: 33880.4952
   RMSE: 184.0666, MAE: 169.7967, RÂ²: -5.3548
ğŸ’¾ Test metrics saved to: logs/client_12_test_metrics_20251030_111500.csv

ğŸ” Running 3-fold cross-validation (Round 5)

ğŸ” Starting 3-fold cross-validation on TRAINING data for client client_12

ğŸ“Š Fold 1/3
   Fold 1 Results:
     Val Loss: 8485.3379
     Val RMSE: 92.1159, Val RÂ²: -0.5957

ğŸ“Š Fold 2/3
   Fold 2 Results:
     Val Loss: 8283.2803
     Val RMSE: 91.0125, Val RÂ²: -0.6211

ğŸ“Š Fold 3/3
   Fold 3 Results:
     Val Loss: 8296.4971
     Val RMSE: 91.0851, Val RÂ²: -0.5887
ğŸ’¾ CV metrics saved to: logs/client_12_cv_metrics_20251030_111500.csv

ğŸ“ˆ 3-Fold CV Summary (Training Data):
   VAL_LOSS: 8355.0384 Â± 92.2935
   RMSE: 91.4045 Â± 0.5039
   R2: -0.6019 Â± 0.0139

ğŸ”„ Starting local training (Round 5)...
   Epoch 1/1: train_loss=16683.8765, val_rmse=79.3865 â­ (improved by inf)
   âœ… Completed 1 epochs, using best model (val_rmse=79.3865)

ğŸ¯ Round 5 Training Summary:
   Epochs trained: 1/1
   Total early stops so far: 0
   Training   - Loss: 6436.9736, RMSE: 80.2308, RÂ²: -0.2338
   Validation - Loss: 6302.2100, RMSE: 79.3865, RÂ²: -0.2378
ğŸ’¾ Training metrics saved to: logs/client_12_training_metrics_20251030_111500.csv

ğŸ§ª Round 5 Evaluation Results:
   Test Loss: 10280.8499
   RMSE: 101.3945, MAE: 80.9373, RÂ²: -0.9283
ğŸ’¾ Test metrics saved to: logs/client_12_test_metrics_20251030_111500.csv
â© Skipping CV for Round 6

ğŸ”„ Starting local training (Round 6)...
   Epoch 1/1: train_loss=9336.2629, val_rmse=88.8787 â­ (improved by inf)
   âœ… Completed 1 epochs, using best model (val_rmse=88.8787)

ğŸ¯ Round 6 Training Summary:
   Epochs trained: 1/1
   Total early stops so far: 0
   Training   - Loss: 8010.5659, RMSE: 89.5018, RÂ²: -0.5355
   Validation - Loss: 7899.4150, RMSE: 88.8787, RÂ²: -0.5514
ğŸ’¾ Training metrics saved to: logs/client_12_training_metrics_20251030_111500.csv

ğŸ§ª Round 6 Evaluation Results:
   Test Loss: 18842.0665
   RMSE: 137.2664, MAE: 116.2540, RÂ²: -2.5341
ğŸ’¾ Test metrics saved to: logs/client_12_test_metrics_20251030_111500.csv
â© Skipping CV for Round 7

ğŸ”„ Starting local training (Round 7)...
   Epoch 1/1: train_loss=18192.9157, val_rmse=133.5052 â­ (improved by inf)
   âœ… Completed 1 epochs, using best model (val_rmse=133.5052)
Round 7: epochs=1, train_loss=17918.6934, val_rmse=133.5052, val_r2=-2.5006

ğŸ§ª Round 7 Evaluation Results:
   Test Loss: 19219.0566
   RMSE: 138.6328, MAE: 117.8454, RÂ²: -2.6048
ğŸ’¾ Test metrics saved to: logs/client_12_test_metrics_20251030_111500.csv
â© Skipping CV for Round 8

ğŸ”„ Starting local training (Round 8)...
   Epoch 1/1: train_loss=18779.1968, val_rmse=136.4937 â­ (improved by inf)
   âœ… Completed 1 epochs, using best model (val_rmse=136.4937)
Round 8: epochs=1, train_loss=18724.6309, val_rmse=136.4937, val_r2=-2.6590
ğŸ’¾ Training metrics saved to: logs/client_12_training_metrics_20251030_111500.csv

ğŸ§ª Round 8 Evaluation Results:
   Test Loss: 19185.4177
   RMSE: 138.5114, MAE: 117.7029, RÂ²: -2.5985
ğŸ’¾ Test metrics saved to: logs/client_12_test_metrics_20251030_111500.csv

ğŸ” Running 3-fold cross-validation (Round 9)
ğŸ’¾ CV metrics saved to: logs/client_12_cv_metrics_20251030_111500.csv

ğŸ”„ Starting local training (Round 9)...
   Epoch 1/1: train_loss=18745.7814, val_rmse=136.3710 â­ (improved by inf)
   âœ… Completed 1 epochs, using best model (val_rmse=136.3710)

ğŸ¯ Round 9 Training Summary:
   Epochs trained: 1/1
   Total early stops so far: 0
   Training   - Loss: 18691.1875, RMSE: 136.7157, RÂ²: -2.5827
   Validation - Loss: 18597.0449, RMSE: 136.3710, RÂ²: -2.6525
ğŸ’¾ Training metrics saved to: logs/client_12_training_metrics_20251030_111500.csv

ğŸ§ª Round 9 Evaluation Results:
   Test Loss: 19126.6787
   RMSE: 138.2992, MAE: 117.4553, RÂ²: -2.5875
ğŸ’¾ Test metrics saved to: logs/client_12_test_metrics_20251030_111500.csv

ğŸ” Running 3-fold cross-validation (Round 10)
ğŸ’¾ CV metrics saved to: logs/client_12_cv_metrics_20251030_111500.csv

ğŸ”„ Starting local training (Round 10)...
   Epoch 1/1: train_loss=18687.6552, val_rmse=136.1577 â­ (improved by inf)
   âœ… Completed 1 epochs, using best model (val_rmse=136.1577)

ğŸ¯ Round 10 Training Summary:
   Epochs trained: 1/1
   Total early stops so far: 0
   Training   - Loss: 18633.1328, RMSE: 136.5032, RÂ²: -2.5716
   Validation - Loss: 18538.9219, RMSE: 136.1577, RÂ²: -2.6410
ğŸ’¾ Training metrics saved to: logs/client_12_training_metrics_20251030_111500.csv

ğŸ§ª Round 10 Evaluation Results:
   Test Loss: 19045.5667
   RMSE: 138.0057, MAE: 117.1126, RÂ²: -2.5723
ğŸ’¾ Test metrics saved to: logs/client_12_test_metrics_20251030_111500.csv

================================================================================
ğŸ¯ FINAL COMPREHENSIVE REPORT
================================================================================
ğŸ’¾ Final summary saved to: logs/client_12_final_summary_20251030_111500.csv

ğŸ“Š CLIENT: client_12 | ALGORITHM: fedavgm | MODEL: LSTM
ğŸ“ˆ TOTAL ROUNDS: 10

âš™ï¸  HYPERPARAMETERS:
   Learning Rate: 0.001
   Batch Size: 32
   Local Epochs: 1
   Hidden Dim: 64
   Num Layers: 2
   Sequence Length: 10
   Use Attention: False
   Dropout: 0.3
   Optimizer: adam

ğŸ›‘ EARLY STOPPING SUMMARY:
   Enabled: Yes
   Patience: 3 epochs
   Min delta: 0.001
   Total early stops: 0/10 rounds
   Early stop rate: 0.0%

ğŸ FINAL ROUND PERFORMANCE:
   Training   - Loss: 18633.13 | RMSE: 136.50 | RÂ²: -2.5716
   Validation - Loss: 18538.92 | RMSE: 136.16 | RÂ²: -2.6410
   Test       - Loss: 19045.57 | RMSE: 138.01 | RÂ²: -2.5723

ğŸ“Š STATISTICS ACROSS ALL ROUNDS (Mean Â± Std):
   Training Loss:   12133.33 Â± 5777.33
   Validation Loss: 12020.03 Â± 5793.17
   Test Loss:       58684.94 Â± 88369.27

   Training RMSE:   106.89 Â± 26.61
   Validation RMSE: 106.30 Â± 26.83
   Test RMSE:       198.29 Â± 139.16

   Training RÂ²:     -1.3257 Â± 1.1074
   Validation RÂ²:   -1.3607 Â± 1.1378
   Test RÂ²:         -10.0072 Â± 16.5749

â­ BEST PERFORMANCE:
   Best Round: 0 (Test RÂ²: -0.3346)

ğŸ“‹ DATA SUMMARY:
   Training samples:   4742
   Validation samples: 1574
   Test samples:       1574
   Total samples:      7890
================================================================================
âœ… Client client_12 completed | Algorithm: FEDAVGM
