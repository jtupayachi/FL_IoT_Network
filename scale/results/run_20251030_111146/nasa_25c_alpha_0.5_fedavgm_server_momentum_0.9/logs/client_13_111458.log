[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6d54ca49-cf23-47d1-89ea-2939bf1d6572
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0f5a3fe6-3b61-4d8a-bd0a-21cf2469781a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 791e81fc-ab09-4690-a669-9f7eb5e7a001
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c763d816-3e06-494a-87c0-2783f0718a5c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 081118eb-0a47-4e16-924f-817c34a71cc8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4b62646e-c8e1-4fff-a753-63a960bfa3b9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ecb4457b-b541-4945-ad02-26992830ceee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7cefe638-9008-4217-bfaa-1939c9d577f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9ab14b85-754c-44aa-9288-25dab4487517
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e3a03f73-ccf2-4284-9890-e88d90c3251d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 496017d6-559c-42c0-bd06-fd18f4c009ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 968255d8-58be-4128-8a51-1884568c1220
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d4824750-788c-479c-8ee8-da36d3ebb48d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 056ed5db-b9f0-44c0-b3fc-967263372c86
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dfc33f4f-97aa-4f89-9cb5-e3dba20f0ee3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4c2b6f6a-26ba-4025-8f4f-e9df656d092d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7df936a7-7af3-4d64-8dbf-772a22a2b423
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0e67416d-f99b-449d-8765-5bdc937cdfce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3d360c95-8124-43b1-a545-4623bfbe95bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6cc1f945-583d-4885-8fad-9d4a17900a20
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: reconnect message 39011499-ae38-4bf2-bd44-6a4140cf45d6
[92mINFO [0m:      Disconnect and shut down
ğŸš€ Starting NASA FL Client: client_13
Algorithm: FEDAVGM
Server: localhost:8688
K-Folds: 5
Log Directory: logs
ğŸ”„ Using device: cuda
ğŸ¯ GPU: NVIDIA A100-SXM4-80GB
ğŸ›‘ Early stopping enabled:
   Patience: 3 epochs
   Min delta: 0.001
ğŸ’¾ Hyperparameters saved to: logs/client_13_hyperparams_20251030_111501.csv
ğŸ” Looking for data at: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.5/client_13
ğŸ“Š Loaded 8239 total samples from /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.5/client_13
ğŸ”¢ Original feature dimension: 24
ğŸ” Applying KernelPCA with 5 components, kernel=poly
ğŸ“Š Data shape - Before: (4943, 24), After: (4943, 5)
ğŸ”„ Created sequences with length 10
   Final dataset shape: X (4933, 10, 5), y (4933,)
âœ… Data split completed:
   Training samples: 4933
   Validation samples: 1638
   Test samples: 1638
   Model type: lstm
   Final input dimension: 5
âœ… Client client_13 ready:
   Model: LSTM
   Training: 4933 samples
   Device: cuda
   Validation: 1638 samples
   Test: 1638 samples
   Algorithm: fedavgm
   Total Rounds: 10
   Learning Rate: 0.001
   Batch Size: 32
   Logging to: logs
â© Skipping CV for Round 1

ğŸ”„ Starting local training (Round 1)...
   Epoch 1/1: train_loss=19778.9227, val_rmse=89.9470 â­ (improved by inf)
   âœ… Completed 1 epochs, using best model (val_rmse=89.9470)
Round 1: epochs=1, train_loss=8786.3271, val_rmse=89.9470, val_r2=-0.0245

ğŸ§ª Round 1 Evaluation Results:
   Test Loss: 11394.1198
   RMSE: 106.7432, MAE: 80.3706, RÂ²: -0.4210
ğŸ’¾ Test metrics saved to: logs/client_13_test_metrics_20251030_111501.csv
â© Skipping CV for Round 2

ğŸ”„ Starting local training (Round 2)...
   Epoch 1/1: train_loss=10041.2476, val_rmse=88.9847 â­ (improved by inf)
   âœ… Completed 1 epochs, using best model (val_rmse=88.9847)
Round 2: epochs=1, train_loss=8558.5596, val_rmse=88.9847, val_r2=-0.0027
ğŸ’¾ Training metrics saved to: logs/client_13_training_metrics_20251030_111501.csv

ğŸ§ª Round 2 Evaluation Results:
   Test Loss: 132159.3848
   RMSE: 363.5373, MAE: 352.3361, RÂ²: -15.4815
ğŸ’¾ Test metrics saved to: logs/client_13_test_metrics_20251030_111501.csv
â© Skipping CV for Round 3

ğŸ”„ Starting local training (Round 3)...
   Epoch 1/1: train_loss=22360.2308, val_rmse=88.8742 â­ (improved by inf)
   âœ… Completed 1 epochs, using best model (val_rmse=88.8742)

ğŸ¯ Round 3 Training Summary:
   Epochs trained: 1/1
   Total early stops so far: 0
   Training   - Loss: 8504.2334, RMSE: 92.2184, RÂ²: -0.0004
   Validation - Loss: 7898.6230, RMSE: 88.8742, RÂ²: -0.0002

ğŸ§ª Round 3 Evaluation Results:
   Test Loss: 284992.1941
   RMSE: 533.8466, MAE: 526.2827, RÂ²: -34.5411
ğŸ’¾ Test metrics saved to: logs/client_13_test_metrics_20251030_111501.csv
â© Skipping CV for Round 4

ğŸ”„ Starting local training (Round 4)...
   Epoch 1/1: train_loss=48414.4693, val_rmse=93.8029 â­ (improved by inf)
   âœ… Completed 1 epochs, using best model (val_rmse=93.8029)
Round 4: epochs=1, train_loss=9232.4326, val_rmse=93.8029, val_r2=-0.1142
ğŸ’¾ Training metrics saved to: logs/client_13_training_metrics_20251030_111501.csv

ğŸ§ª Round 4 Evaluation Results:
   Test Loss: 31459.0909
   RMSE: 177.3671, MAE: 160.4371, RÂ²: -2.9232
ğŸ’¾ Test metrics saved to: logs/client_13_test_metrics_20251030_111501.csv

ğŸ” Running 3-fold cross-validation (Round 5)

ğŸ” Starting 3-fold cross-validation on TRAINING data for client client_13

ğŸ“Š Fold 1/3
   Fold 1 Results:
     Val Loss: 9790.2070
     Val RMSE: 98.9455, Val RÂ²: -0.1305

ğŸ“Š Fold 2/3
   Fold 2 Results:
     Val Loss: 9896.6143
     Val RMSE: 99.4817, Val RÂ²: -0.1485

ğŸ“Š Fold 3/3
   Fold 3 Results:
     Val Loss: 9702.7734
     Val RMSE: 98.5027, Val RÂ²: -0.1810
ğŸ’¾ CV metrics saved to: logs/client_13_cv_metrics_20251030_111501.csv

ğŸ“ˆ 3-Fold CV Summary (Training Data):
   VAL_LOSS: 9796.5316 Â± 79.2614
   RMSE: 98.9766 Â± 0.4003
   R2: -0.1533 Â± 0.0209

ğŸ”„ Starting local training (Round 5)...
   Epoch 1/1: train_loss=15276.0112, val_rmse=90.0677 â­ (improved by inf)
   âœ… Completed 1 epochs, using best model (val_rmse=90.0677)

ğŸ¯ Round 5 Training Summary:
   Epochs trained: 1/1
   Total early stops so far: 0
   Training   - Loss: 8637.4277, RMSE: 92.9378, RÂ²: -0.0160
   Validation - Loss: 8112.1890, RMSE: 90.0677, RÂ²: -0.0272
ğŸ’¾ Training metrics saved to: logs/client_13_training_metrics_20251030_111501.csv

ğŸ§ª Round 5 Evaluation Results:
   Test Loss: 15452.7822
   RMSE: 124.3092, MAE: 94.7841, RÂ²: -0.9271
ğŸ’¾ Test metrics saved to: logs/client_13_test_metrics_20251030_111501.csv
â© Skipping CV for Round 6

ğŸ”„ Starting local training (Round 6)...
   Epoch 1/1: train_loss=14249.7454, val_rmse=104.1036 â­ (improved by inf)
   âœ… Completed 1 epochs, using best model (val_rmse=104.1036)

ğŸ¯ Round 6 Training Summary:
   Epochs trained: 1/1
   Total early stops so far: 0
   Training   - Loss: 11774.2695, RMSE: 108.5093, RÂ²: -0.3850
   Validation - Loss: 10837.5674, RMSE: 104.1036, RÂ²: -0.3723
ğŸ’¾ Training metrics saved to: logs/client_13_training_metrics_20251030_111501.csv

ğŸ§ª Round 6 Evaluation Results:
   Test Loss: 25468.2606
   RMSE: 159.5878, MAE: 132.1073, RÂ²: -2.1761
ğŸ’¾ Test metrics saved to: logs/client_13_test_metrics_20251030_111501.csv
â© Skipping CV for Round 7

ğŸ”„ Starting local training (Round 7)...
   Epoch 1/1: train_loss=25673.8937, val_rmse=154.5295 â­ (improved by inf)
   âœ… Completed 1 epochs, using best model (val_rmse=154.5295)
Round 7: epochs=1, train_loss=25247.2793, val_rmse=154.5295, val_r2=-2.0238

ğŸ§ª Round 7 Evaluation Results:
   Test Loss: 25896.3408
   RMSE: 160.9234, MAE: 133.7074, RÂ²: -2.2295
ğŸ’¾ Test metrics saved to: logs/client_13_test_metrics_20251030_111501.csv
â© Skipping CV for Round 8

ğŸ”„ Starting local training (Round 8)...
   Epoch 1/1: train_loss=26513.7117, val_rmse=158.5864 â­ (improved by inf)
   âœ… Completed 1 epochs, using best model (val_rmse=158.5864)
Round 8: epochs=1, train_loss=26546.9980, val_rmse=158.5864, val_r2=-2.1846
ğŸ’¾ Training metrics saved to: logs/client_13_training_metrics_20251030_111501.csv

ğŸ§ª Round 8 Evaluation Results:
   Test Loss: 25858.1708
   RMSE: 160.8048, MAE: 133.5648, RÂ²: -2.2247
ğŸ’¾ Test metrics saved to: logs/client_13_test_metrics_20251030_111501.csv

ğŸ” Running 3-fold cross-validation (Round 9)
ğŸ’¾ CV metrics saved to: logs/client_13_cv_metrics_20251030_111501.csv

ğŸ”„ Starting local training (Round 9)...
   Epoch 1/1: train_loss=26476.3856, val_rmse=158.4743 â­ (improved by inf)
   âœ… Completed 1 epochs, using best model (val_rmse=158.4743)

ğŸ¯ Round 9 Training Summary:
   Epochs trained: 1/1
   Total early stops so far: 0
   Training   - Loss: 26510.6465, RMSE: 162.8209, RÂ²: -2.1185
   Validation - Loss: 25114.1055, RMSE: 158.4743, RÂ²: -2.1801
ğŸ’¾ Training metrics saved to: logs/client_13_training_metrics_20251030_111501.csv

ğŸ§ª Round 9 Evaluation Results:
   Test Loss: 25791.5081
   RMSE: 160.5974, MAE: 133.3162, RÂ²: -2.2164
ğŸ’¾ Test metrics saved to: logs/client_13_test_metrics_20251030_111501.csv

ğŸ” Running 3-fold cross-validation (Round 10)
ğŸ’¾ CV metrics saved to: logs/client_13_cv_metrics_20251030_111501.csv

ğŸ”„ Starting local training (Round 10)...
   Epoch 1/1: train_loss=26410.1968, val_rmse=158.2721 â­ (improved by inf)
   âœ… Completed 1 epochs, using best model (val_rmse=158.2721)

ğŸ¯ Round 10 Training Summary:
   Epochs trained: 1/1
   Total early stops so far: 0
   Training   - Loss: 26445.1348, RMSE: 162.6196, RÂ²: -2.1108
   Validation - Loss: 25050.0566, RMSE: 158.2721, RÂ²: -2.1720
ğŸ’¾ Training metrics saved to: logs/client_13_training_metrics_20251030_111501.csv

ğŸ§ª Round 10 Evaluation Results:
   Test Loss: 25699.4259
   RMSE: 160.3104, MAE: 132.9721, RÂ²: -2.2050
ğŸ’¾ Test metrics saved to: logs/client_13_test_metrics_20251030_111501.csv

================================================================================
ğŸ¯ FINAL COMPREHENSIVE REPORT
================================================================================
ğŸ’¾ Final summary saved to: logs/client_13_final_summary_20251030_111501.csv

ğŸ“Š CLIENT: client_13 | ALGORITHM: fedavgm | MODEL: LSTM
ğŸ“ˆ TOTAL ROUNDS: 10

âš™ï¸  HYPERPARAMETERS:
   Learning Rate: 0.001
   Batch Size: 32
   Local Epochs: 1
   Hidden Dim: 64
   Num Layers: 2
   Sequence Length: 10
   Use Attention: False
   Dropout: 0.3
   Optimizer: adam

ğŸ›‘ EARLY STOPPING SUMMARY:
   Enabled: Yes
   Patience: 3 epochs
   Min delta: 0.001
   Total early stops: 0/10 rounds
   Early stop rate: 0.0%

ğŸ FINAL ROUND PERFORMANCE:
   Training   - Loss: 26445.13 | RMSE: 162.62 | RÂ²: -2.1108
   Validation - Loss: 25050.06 | RMSE: 158.27 | RÂ²: -2.1720
   Test       - Loss: 25699.43 | RMSE: 160.31 | RÂ²: -2.2050

ğŸ“Š STATISTICS ACROSS ALL ROUNDS (Mean Â± Std):
   Training Loss:   16815.07 Â± 8446.49
   Validation Loss: 15854.40 Â± 8058.49
   Test Loss:       60417.13 Â± 81765.65

   Training RMSE:   125.49 Â± 32.68
   Validation RMSE: 121.76 Â± 32.09
   Test RMSE:       210.80 Â± 126.41

   Training RÂ²:     -0.9780 Â± 0.9936
   Validation RÂ²:   -1.0076 Â± 1.0204
   Test RÂ²:         -6.5346 Â± 10.1969

â­ BEST PERFORMANCE:
   Best Round: 1 (Test RÂ²: -0.4210)

ğŸ“‹ DATA SUMMARY:
   Training samples:   4933
   Validation samples: 1638
   Test samples:       1638
   Total samples:      8209
================================================================================
âœ… Client client_13 completed | Algorithm: FEDAVGM
