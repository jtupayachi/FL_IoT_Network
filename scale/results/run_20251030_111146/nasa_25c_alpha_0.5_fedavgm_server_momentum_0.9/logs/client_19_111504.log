[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b34b6329-dae3-4c3d-9886-6ac3e0a5682b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e2252582-49d6-4c45-a60c-3fffa387f677
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 78ab4b89-cfa9-4b44-8b39-f856c74c2726
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ac6396c2-db87-4ff1-9906-4da3b87394f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message badfa8cf-1846-492b-ba4b-73d2365304ce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4b4e15ea-8efc-42b0-b2c8-beee6f4d3e78
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1309641b-c663-45e2-8449-777fe276dc69
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 67a4d4fb-4e5e-4f67-9813-3dc9db64183b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ad712e5e-a2c8-4130-8f31-2ff9cf04d4be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a81b5c8e-6984-443b-8d2e-679418199008
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5c69616a-179e-4073-8c6c-35e761e5609a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dfede05a-6750-410e-8474-1aa65cfe3694
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b2c4513e-e914-4235-bd65-69f2bf44ab99
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1fa9fdd9-c9f6-4466-b549-a4e1d29a0d4b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8a8530cf-3b13-42e1-8f1a-f92024cf3862
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4eae99d9-7175-42e2-b545-2a0861758cdd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7571f0d6-eceb-4221-aeb9-9db2c7196483
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6fc4cfc3-d1f5-4c5e-9966-ece90942ae43
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e3127e55-9495-4d69-9788-070feb41c848
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7f7c3a0c-519c-4cf0-85a9-4bee38868576
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: reconnect message abf05251-e37d-47e6-9043-3bc6ed679ec6
[92mINFO [0m:      Disconnect and shut down
🚀 Starting NASA FL Client: client_19
Algorithm: FEDAVGM
Server: localhost:8688
K-Folds: 5
Log Directory: logs
🔄 Using device: cuda
🎯 GPU: NVIDIA A100-SXM4-80GB
🛑 Early stopping enabled:
   Patience: 3 epochs
   Min delta: 0.001
💾 Hyperparameters saved to: logs/client_19_hyperparams_20251030_111507.csv
🔍 Looking for data at: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.5/client_19
📊 Loaded 5558 total samples from /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.5/client_19
🔢 Original feature dimension: 24
🔍 Applying KernelPCA with 5 components, kernel=poly
📊 Data shape - Before: (3334, 24), After: (3334, 5)
🔄 Created sequences with length 10
   Final dataset shape: X (3324, 10, 5), y (3324,)
✅ Data split completed:
   Training samples: 3324
   Validation samples: 1102
   Test samples: 1102
   Model type: lstm
   Final input dimension: 5
✅ Client client_19 ready:
   Model: LSTM
   Training: 3324 samples
   Device: cuda
   Validation: 1102 samples
   Test: 1102 samples
   Algorithm: fedavgm
   Total Rounds: 10
   Learning Rate: 0.001
   Batch Size: 32
   Logging to: logs
⏩ Skipping CV for Round 1

🔄 Starting local training (Round 1)...
   Epoch 1/1: train_loss=24825.7414, val_rmse=129.7279 ⭐ (improved by inf)
   ✅ Completed 1 epochs, using best model (val_rmse=129.7279)
Round 1: epochs=1, train_loss=17746.7539, val_rmse=129.7279, val_r2=-0.9500

🧪 Round 1 Evaluation Results:
   Test Loss: 12294.4245
   RMSE: 110.8802, MAE: 83.3618, R²: -0.4544
💾 Test metrics saved to: logs/client_19_test_metrics_20251030_111507.csv
⏩ Skipping CV for Round 2

🔄 Starting local training (Round 2)...
   Epoch 1/1: train_loss=11007.3812, val_rmse=94.1583 ⭐ (improved by inf)
   ✅ Completed 1 epochs, using best model (val_rmse=94.1583)
Round 2: epochs=1, train_loss=9596.4697, val_rmse=94.1583, val_r2=-0.0273
💾 Training metrics saved to: logs/client_19_training_metrics_20251030_111507.csv

🧪 Round 2 Evaluation Results:
   Test Loss: 129875.9963
   RMSE: 360.3831, MAE: 348.4576, R²: -14.3640
💾 Test metrics saved to: logs/client_19_test_metrics_20251030_111507.csv
⏩ Skipping CV for Round 3

🔄 Starting local training (Round 3)...
   Epoch 1/1: train_loss=33886.4169, val_rmse=95.3312 ⭐ (improved by inf)
   ✅ Completed 1 epochs, using best model (val_rmse=95.3312)

🎯 Round 3 Training Summary:
   Epochs trained: 1/1
   Total early stops so far: 0
   Training   - Loss: 9727.4961, RMSE: 98.6281, R²: -0.0436
   Validation - Loss: 9088.0449, RMSE: 95.3312, R²: -0.0530

🧪 Round 3 Evaluation Results:
   Test Loss: 281359.6848
   RMSE: 530.4335, MAE: 522.4045, R²: -32.2842
💾 Test metrics saved to: logs/client_19_test_metrics_20251030_111507.csv
⏩ Skipping CV for Round 4

🔄 Starting local training (Round 4)...
   Epoch 1/1: train_loss=74366.7107, val_rmse=116.2938 ⭐ (improved by inf)
   ✅ Completed 1 epochs, using best model (val_rmse=116.2938)
Round 4: epochs=1, train_loss=14043.1123, val_rmse=116.2938, val_r2=-0.5671
💾 Training metrics saved to: logs/client_19_training_metrics_20251030_111507.csv

🧪 Round 4 Evaluation Results:
   Test Loss: 30721.0259
   RMSE: 175.2741, MAE: 157.6062, R²: -2.6342
💾 Test metrics saved to: logs/client_19_test_metrics_20251030_111507.csv

🔍 Running 3-fold cross-validation (Round 5)

🔍 Starting 3-fold cross-validation on TRAINING data for client client_19

📊 Fold 1/3
   Fold 1 Results:
     Val Loss: 12204.7021
     Val RMSE: 110.4749, Val R²: -0.3954

📊 Fold 2/3
   Fold 2 Results:
     Val Loss: 13219.4570
     Val RMSE: 114.9759, Val R²: -0.3706

📊 Fold 3/3
   Fold 3 Results:
     Val Loss: 13269.6719
     Val RMSE: 115.1941, Val R²: -0.3868
💾 CV metrics saved to: logs/client_19_cv_metrics_20251030_111507.csv

📈 3-Fold CV Summary (Training Data):
   VAL_LOSS: 12897.9437 ± 490.6243
   RMSE: 113.5483 ± 2.1750
   R2: -0.3842 ± 0.0103

🔄 Starting local training (Round 5)...
   Epoch 1/1: train_loss=18896.5296, val_rmse=99.8984 ⭐ (improved by inf)
   ✅ Completed 1 epochs, using best model (val_rmse=99.8984)

🎯 Round 5 Training Summary:
   Epochs trained: 1/1
   Total early stops so far: 0
   Training   - Loss: 10581.0449, RMSE: 102.8642, R²: -0.1351
   Validation - Loss: 9979.6797, RMSE: 99.8984, R²: -0.1564
💾 Training metrics saved to: logs/client_19_training_metrics_20251030_111507.csv

🧪 Round 5 Evaluation Results:
   Test Loss: 16569.2913
   RMSE: 128.7218, MAE: 98.1149, R²: -0.9601
💾 Test metrics saved to: logs/client_19_test_metrics_20251030_111507.csv
⏩ Skipping CV for Round 6

🔄 Starting local training (Round 6)...
   Epoch 1/1: train_loss=16055.8244, val_rmse=117.1903 ⭐ (improved by inf)
   ✅ Completed 1 epochs, using best model (val_rmse=117.1903)

🎯 Round 6 Training Summary:
   Epochs trained: 1/1
   Total early stops so far: 0
   Training   - Loss: 14603.5332, RMSE: 120.8451, R²: -0.5667
   Validation - Loss: 13733.5674, RMSE: 117.1903, R²: -0.5913
💾 Training metrics saved to: logs/client_19_training_metrics_20251030_111507.csv

🧪 Round 6 Evaluation Results:
   Test Loss: 26942.5460
   RMSE: 164.1418, MAE: 135.9835, R²: -2.1872
💾 Test metrics saved to: logs/client_19_test_metrics_20251030_111507.csv
⏩ Skipping CV for Round 7

🔄 Starting local training (Round 7)...
   Epoch 1/1: train_loss=26836.8784, val_rmse=159.9515 ⭐ (improved by inf)
   ✅ Completed 1 epochs, using best model (val_rmse=159.9515)
Round 7: epochs=1, train_loss=26600.3711, val_rmse=159.9515, val_r2=-1.9645

🧪 Round 7 Evaluation Results:
   Test Loss: 27383.1269
   RMSE: 165.4785, MAE: 137.5859, R²: -2.2394
💾 Test metrics saved to: logs/client_19_test_metrics_20251030_111507.csv
⏩ Skipping CV for Round 8

🔄 Starting local training (Round 8)...
   Epoch 1/1: train_loss=27486.3909, val_rmse=162.6032 ⭐ (improved by inf)
   ✅ Completed 1 epochs, using best model (val_rmse=162.6032)
Round 8: epochs=1, train_loss=27463.7676, val_rmse=162.6032, val_r2=-2.0636
💾 Training metrics saved to: logs/client_19_training_metrics_20251030_111507.csv

🧪 Round 8 Evaluation Results:
   Test Loss: 27343.8490
   RMSE: 165.3598, MAE: 137.4432, R²: -2.2347
💾 Test metrics saved to: logs/client_19_test_metrics_20251030_111507.csv

🔍 Running 3-fold cross-validation (Round 9)
💾 CV metrics saved to: logs/client_19_cv_metrics_20251030_111507.csv

🔄 Starting local training (Round 9)...
   Epoch 1/1: train_loss=27447.9630, val_rmse=162.4864 ⭐ (improved by inf)
   ✅ Completed 1 epochs, using best model (val_rmse=162.4864)

🎯 Round 9 Training Summary:
   Epochs trained: 1/1
   Total early stops so far: 0
   Training   - Loss: 27425.4473, RMSE: 165.6063, R²: -1.9422
   Validation - Loss: 26401.8418, RMSE: 162.4864, R²: -2.0592
💾 Training metrics saved to: logs/client_19_training_metrics_20251030_111507.csv

🧪 Round 9 Evaluation Results:
   Test Loss: 27275.2486
   RMSE: 165.1522, MAE: 137.1943, R²: -2.2266
💾 Test metrics saved to: logs/client_19_test_metrics_20251030_111507.csv

🔍 Running 3-fold cross-validation (Round 10)
💾 CV metrics saved to: logs/client_19_cv_metrics_20251030_111507.csv

🔄 Starting local training (Round 10)...
   Epoch 1/1: train_loss=27380.8568, val_rmse=162.2821 ⭐ (improved by inf)
   ✅ Completed 1 epochs, using best model (val_rmse=162.2821)

🎯 Round 10 Training Summary:
   Epochs trained: 1/1
   Total early stops so far: 0
   Training   - Loss: 27358.4551, RMSE: 165.4039, R²: -1.9350
   Validation - Loss: 26335.4727, RMSE: 162.2821, R²: -2.0515
💾 Training metrics saved to: logs/client_19_training_metrics_20251030_111507.csv

🧪 Round 10 Evaluation Results:
   Test Loss: 27180.4842
   RMSE: 164.8650, MAE: 136.8497, R²: -2.2154
💾 Test metrics saved to: logs/client_19_test_metrics_20251030_111507.csv

================================================================================
🎯 FINAL COMPREHENSIVE REPORT
================================================================================
💾 Final summary saved to: logs/client_19_final_summary_20251030_111507.csv

📊 CLIENT: client_19 | ALGORITHM: fedavgm | MODEL: LSTM
📈 TOTAL ROUNDS: 10

⚙️  HYPERPARAMETERS:
   Learning Rate: 0.001
   Batch Size: 32
   Local Epochs: 1
   Hidden Dim: 64
   Num Layers: 2
   Sequence Length: 10
   Use Attention: False
   Dropout: 0.3
   Optimizer: adam

🛑 EARLY STOPPING SUMMARY:
   Enabled: Yes
   Patience: 3 epochs
   Min delta: 0.001
   Total early stops: 0/10 rounds
   Early stop rate: 0.0%

🏁 FINAL ROUND PERFORMANCE:
   Training   - Loss: 27358.46 | RMSE: 165.40 | R²: -1.9350
   Validation - Loss: 26335.47 | RMSE: 162.28 | R²: -2.0515
   Test       - Loss: 27180.48 | RMSE: 164.87 | R²: -2.2154

📊 STATISTICS ACROSS ALL ROUNDS (Mean ± Std):
   Training Loss:   18724.55 ± 7701.22
   Validation Loss: 17897.20 ± 7532.99
   Test Loss:       60694.57 ± 80167.55

   Training RMSE:   133.84 ± 28.47
   Validation RMSE: 130.70 ± 28.53
   Test RMSE:       213.07 ± 123.68

   Training R²:     -1.0088 ± 0.8262
   Validation R²:   -1.0738 ± 0.8729
   Test R²:         -6.1800 ± 9.4836

⭐ BEST PERFORMANCE:
   Best Round: 1 (Test R²: -0.4544)

📋 DATA SUMMARY:
   Training samples:   3324
   Validation samples: 1102
   Test samples:       1102
   Total samples:      5528
================================================================================
✅ Client client_19 completed | Algorithm: FEDAVGM
