[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b34b6329-dae3-4c3d-9886-6ac3e0a5682b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e2252582-49d6-4c45-a60c-3fffa387f677
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 78ab4b89-cfa9-4b44-8b39-f856c74c2726
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ac6396c2-db87-4ff1-9906-4da3b87394f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message badfa8cf-1846-492b-ba4b-73d2365304ce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4b4e15ea-8efc-42b0-b2c8-beee6f4d3e78
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1309641b-c663-45e2-8449-777fe276dc69
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 67a4d4fb-4e5e-4f67-9813-3dc9db64183b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ad712e5e-a2c8-4130-8f31-2ff9cf04d4be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a81b5c8e-6984-443b-8d2e-679418199008
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5c69616a-179e-4073-8c6c-35e761e5609a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dfede05a-6750-410e-8474-1aa65cfe3694
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b2c4513e-e914-4235-bd65-69f2bf44ab99
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1fa9fdd9-c9f6-4466-b549-a4e1d29a0d4b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8a8530cf-3b13-42e1-8f1a-f92024cf3862
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4eae99d9-7175-42e2-b545-2a0861758cdd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7571f0d6-eceb-4221-aeb9-9db2c7196483
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6fc4cfc3-d1f5-4c5e-9966-ece90942ae43
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e3127e55-9495-4d69-9788-070feb41c848
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7f7c3a0c-519c-4cf0-85a9-4bee38868576
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: reconnect message abf05251-e37d-47e6-9043-3bc6ed679ec6
[92mINFO [0m:      Disconnect and shut down
ğŸš€ Starting NASA FL Client: client_19
Algorithm: FEDAVGM
Server: localhost:8688
K-Folds: 5
Log Directory: logs
ğŸ”„ Using device: cuda
ğŸ¯ GPU: NVIDIA A100-SXM4-80GB
ğŸ›‘ Early stopping enabled:
   Patience: 3 epochs
   Min delta: 0.001
ğŸ’¾ Hyperparameters saved to: logs/client_19_hyperparams_20251030_111507.csv
ğŸ” Looking for data at: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.5/client_19
ğŸ“Š Loaded 5558 total samples from /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.5/client_19
ğŸ”¢ Original feature dimension: 24
ğŸ” Applying KernelPCA with 5 components, kernel=poly
ğŸ“Š Data shape - Before: (3334, 24), After: (3334, 5)
ğŸ”„ Created sequences with length 10
   Final dataset shape: X (3324, 10, 5), y (3324,)
âœ… Data split completed:
   Training samples: 3324
   Validation samples: 1102
   Test samples: 1102
   Model type: lstm
   Final input dimension: 5
âœ… Client client_19 ready:
   Model: LSTM
   Training: 3324 samples
   Device: cuda
   Validation: 1102 samples
   Test: 1102 samples
   Algorithm: fedavgm
   Total Rounds: 10
   Learning Rate: 0.001
   Batch Size: 32
   Logging to: logs
â© Skipping CV for Round 1

ğŸ”„ Starting local training (Round 1)...
   Epoch 1/1: train_loss=24825.7414, val_rmse=129.7279 â­ (improved by inf)
   âœ… Completed 1 epochs, using best model (val_rmse=129.7279)
Round 1: epochs=1, train_loss=17746.7539, val_rmse=129.7279, val_r2=-0.9500

ğŸ§ª Round 1 Evaluation Results:
   Test Loss: 12294.4245
   RMSE: 110.8802, MAE: 83.3618, RÂ²: -0.4544
ğŸ’¾ Test metrics saved to: logs/client_19_test_metrics_20251030_111507.csv
â© Skipping CV for Round 2

ğŸ”„ Starting local training (Round 2)...
   Epoch 1/1: train_loss=11007.3812, val_rmse=94.1583 â­ (improved by inf)
   âœ… Completed 1 epochs, using best model (val_rmse=94.1583)
Round 2: epochs=1, train_loss=9596.4697, val_rmse=94.1583, val_r2=-0.0273
ğŸ’¾ Training metrics saved to: logs/client_19_training_metrics_20251030_111507.csv

ğŸ§ª Round 2 Evaluation Results:
   Test Loss: 129875.9963
   RMSE: 360.3831, MAE: 348.4576, RÂ²: -14.3640
ğŸ’¾ Test metrics saved to: logs/client_19_test_metrics_20251030_111507.csv
â© Skipping CV for Round 3

ğŸ”„ Starting local training (Round 3)...
   Epoch 1/1: train_loss=33886.4169, val_rmse=95.3312 â­ (improved by inf)
   âœ… Completed 1 epochs, using best model (val_rmse=95.3312)

ğŸ¯ Round 3 Training Summary:
   Epochs trained: 1/1
   Total early stops so far: 0
   Training   - Loss: 9727.4961, RMSE: 98.6281, RÂ²: -0.0436
   Validation - Loss: 9088.0449, RMSE: 95.3312, RÂ²: -0.0530

ğŸ§ª Round 3 Evaluation Results:
   Test Loss: 281359.6848
   RMSE: 530.4335, MAE: 522.4045, RÂ²: -32.2842
ğŸ’¾ Test metrics saved to: logs/client_19_test_metrics_20251030_111507.csv
â© Skipping CV for Round 4

ğŸ”„ Starting local training (Round 4)...
   Epoch 1/1: train_loss=74366.7107, val_rmse=116.2938 â­ (improved by inf)
   âœ… Completed 1 epochs, using best model (val_rmse=116.2938)
Round 4: epochs=1, train_loss=14043.1123, val_rmse=116.2938, val_r2=-0.5671
ğŸ’¾ Training metrics saved to: logs/client_19_training_metrics_20251030_111507.csv

ğŸ§ª Round 4 Evaluation Results:
   Test Loss: 30721.0259
   RMSE: 175.2741, MAE: 157.6062, RÂ²: -2.6342
ğŸ’¾ Test metrics saved to: logs/client_19_test_metrics_20251030_111507.csv

ğŸ” Running 3-fold cross-validation (Round 5)

ğŸ” Starting 3-fold cross-validation on TRAINING data for client client_19

ğŸ“Š Fold 1/3
   Fold 1 Results:
     Val Loss: 12204.7021
     Val RMSE: 110.4749, Val RÂ²: -0.3954

ğŸ“Š Fold 2/3
   Fold 2 Results:
     Val Loss: 13219.4570
     Val RMSE: 114.9759, Val RÂ²: -0.3706

ğŸ“Š Fold 3/3
   Fold 3 Results:
     Val Loss: 13269.6719
     Val RMSE: 115.1941, Val RÂ²: -0.3868
ğŸ’¾ CV metrics saved to: logs/client_19_cv_metrics_20251030_111507.csv

ğŸ“ˆ 3-Fold CV Summary (Training Data):
   VAL_LOSS: 12897.9437 Â± 490.6243
   RMSE: 113.5483 Â± 2.1750
   R2: -0.3842 Â± 0.0103

ğŸ”„ Starting local training (Round 5)...
   Epoch 1/1: train_loss=18896.5296, val_rmse=99.8984 â­ (improved by inf)
   âœ… Completed 1 epochs, using best model (val_rmse=99.8984)

ğŸ¯ Round 5 Training Summary:
   Epochs trained: 1/1
   Total early stops so far: 0
   Training   - Loss: 10581.0449, RMSE: 102.8642, RÂ²: -0.1351
   Validation - Loss: 9979.6797, RMSE: 99.8984, RÂ²: -0.1564
ğŸ’¾ Training metrics saved to: logs/client_19_training_metrics_20251030_111507.csv

ğŸ§ª Round 5 Evaluation Results:
   Test Loss: 16569.2913
   RMSE: 128.7218, MAE: 98.1149, RÂ²: -0.9601
ğŸ’¾ Test metrics saved to: logs/client_19_test_metrics_20251030_111507.csv
â© Skipping CV for Round 6

ğŸ”„ Starting local training (Round 6)...
   Epoch 1/1: train_loss=16055.8244, val_rmse=117.1903 â­ (improved by inf)
   âœ… Completed 1 epochs, using best model (val_rmse=117.1903)

ğŸ¯ Round 6 Training Summary:
   Epochs trained: 1/1
   Total early stops so far: 0
   Training   - Loss: 14603.5332, RMSE: 120.8451, RÂ²: -0.5667
   Validation - Loss: 13733.5674, RMSE: 117.1903, RÂ²: -0.5913
ğŸ’¾ Training metrics saved to: logs/client_19_training_metrics_20251030_111507.csv

ğŸ§ª Round 6 Evaluation Results:
   Test Loss: 26942.5460
   RMSE: 164.1418, MAE: 135.9835, RÂ²: -2.1872
ğŸ’¾ Test metrics saved to: logs/client_19_test_metrics_20251030_111507.csv
â© Skipping CV for Round 7

ğŸ”„ Starting local training (Round 7)...
   Epoch 1/1: train_loss=26836.8784, val_rmse=159.9515 â­ (improved by inf)
   âœ… Completed 1 epochs, using best model (val_rmse=159.9515)
Round 7: epochs=1, train_loss=26600.3711, val_rmse=159.9515, val_r2=-1.9645

ğŸ§ª Round 7 Evaluation Results:
   Test Loss: 27383.1269
   RMSE: 165.4785, MAE: 137.5859, RÂ²: -2.2394
ğŸ’¾ Test metrics saved to: logs/client_19_test_metrics_20251030_111507.csv
â© Skipping CV for Round 8

ğŸ”„ Starting local training (Round 8)...
   Epoch 1/1: train_loss=27486.3909, val_rmse=162.6032 â­ (improved by inf)
   âœ… Completed 1 epochs, using best model (val_rmse=162.6032)
Round 8: epochs=1, train_loss=27463.7676, val_rmse=162.6032, val_r2=-2.0636
ğŸ’¾ Training metrics saved to: logs/client_19_training_metrics_20251030_111507.csv

ğŸ§ª Round 8 Evaluation Results:
   Test Loss: 27343.8490
   RMSE: 165.3598, MAE: 137.4432, RÂ²: -2.2347
ğŸ’¾ Test metrics saved to: logs/client_19_test_metrics_20251030_111507.csv

ğŸ” Running 3-fold cross-validation (Round 9)
ğŸ’¾ CV metrics saved to: logs/client_19_cv_metrics_20251030_111507.csv

ğŸ”„ Starting local training (Round 9)...
   Epoch 1/1: train_loss=27447.9630, val_rmse=162.4864 â­ (improved by inf)
   âœ… Completed 1 epochs, using best model (val_rmse=162.4864)

ğŸ¯ Round 9 Training Summary:
   Epochs trained: 1/1
   Total early stops so far: 0
   Training   - Loss: 27425.4473, RMSE: 165.6063, RÂ²: -1.9422
   Validation - Loss: 26401.8418, RMSE: 162.4864, RÂ²: -2.0592
ğŸ’¾ Training metrics saved to: logs/client_19_training_metrics_20251030_111507.csv

ğŸ§ª Round 9 Evaluation Results:
   Test Loss: 27275.2486
   RMSE: 165.1522, MAE: 137.1943, RÂ²: -2.2266
ğŸ’¾ Test metrics saved to: logs/client_19_test_metrics_20251030_111507.csv

ğŸ” Running 3-fold cross-validation (Round 10)
ğŸ’¾ CV metrics saved to: logs/client_19_cv_metrics_20251030_111507.csv

ğŸ”„ Starting local training (Round 10)...
   Epoch 1/1: train_loss=27380.8568, val_rmse=162.2821 â­ (improved by inf)
   âœ… Completed 1 epochs, using best model (val_rmse=162.2821)

ğŸ¯ Round 10 Training Summary:
   Epochs trained: 1/1
   Total early stops so far: 0
   Training   - Loss: 27358.4551, RMSE: 165.4039, RÂ²: -1.9350
   Validation - Loss: 26335.4727, RMSE: 162.2821, RÂ²: -2.0515
ğŸ’¾ Training metrics saved to: logs/client_19_training_metrics_20251030_111507.csv

ğŸ§ª Round 10 Evaluation Results:
   Test Loss: 27180.4842
   RMSE: 164.8650, MAE: 136.8497, RÂ²: -2.2154
ğŸ’¾ Test metrics saved to: logs/client_19_test_metrics_20251030_111507.csv

================================================================================
ğŸ¯ FINAL COMPREHENSIVE REPORT
================================================================================
ğŸ’¾ Final summary saved to: logs/client_19_final_summary_20251030_111507.csv

ğŸ“Š CLIENT: client_19 | ALGORITHM: fedavgm | MODEL: LSTM
ğŸ“ˆ TOTAL ROUNDS: 10

âš™ï¸  HYPERPARAMETERS:
   Learning Rate: 0.001
   Batch Size: 32
   Local Epochs: 1
   Hidden Dim: 64
   Num Layers: 2
   Sequence Length: 10
   Use Attention: False
   Dropout: 0.3
   Optimizer: adam

ğŸ›‘ EARLY STOPPING SUMMARY:
   Enabled: Yes
   Patience: 3 epochs
   Min delta: 0.001
   Total early stops: 0/10 rounds
   Early stop rate: 0.0%

ğŸ FINAL ROUND PERFORMANCE:
   Training   - Loss: 27358.46 | RMSE: 165.40 | RÂ²: -1.9350
   Validation - Loss: 26335.47 | RMSE: 162.28 | RÂ²: -2.0515
   Test       - Loss: 27180.48 | RMSE: 164.87 | RÂ²: -2.2154

ğŸ“Š STATISTICS ACROSS ALL ROUNDS (Mean Â± Std):
   Training Loss:   18724.55 Â± 7701.22
   Validation Loss: 17897.20 Â± 7532.99
   Test Loss:       60694.57 Â± 80167.55

   Training RMSE:   133.84 Â± 28.47
   Validation RMSE: 130.70 Â± 28.53
   Test RMSE:       213.07 Â± 123.68

   Training RÂ²:     -1.0088 Â± 0.8262
   Validation RÂ²:   -1.0738 Â± 0.8729
   Test RÂ²:         -6.1800 Â± 9.4836

â­ BEST PERFORMANCE:
   Best Round: 1 (Test RÂ²: -0.4544)

ğŸ“‹ DATA SUMMARY:
   Training samples:   3324
   Validation samples: 1102
   Test samples:       1102
   Total samples:      5528
================================================================================
âœ… Client client_19 completed | Algorithm: FEDAVGM
