[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eaf0ef02-a4a8-4afc-a7b5-40c136318884
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message af2a6e84-21ba-4a4f-aacb-883ed7d30522
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0a0f0784-7f13-4b7b-8196-e682794bbf0b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2774ca92-cc75-434f-818b-b43eb8def50b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 588438e8-a3c6-460c-8b6c-fa0fcea2910d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b717b953-ea7b-4483-9584-2e1adea11a8d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0b28a7c5-2ad3-485e-8bb2-444350a06469
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b99967b1-fa19-44b0-a710-c4c6d3840c70
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e7274386-79e0-42b1-b2f2-41f1fb47f04b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a67a9323-2df3-410d-a1d6-bbbc74666c2b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 423944ea-ab69-4312-88a2-e2b084d13211
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f3f241c3-77df-46fe-a072-1ffdf2eb879c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7e6b1870-2871-4206-8227-b4758d6673dd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9bcecdbd-9589-4561-b87e-40be9b9a3d0f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f15583e4-65a5-425f-afbe-76b93bb9ee7d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f81e67d2-9300-425d-b52d-9d032c57aaf2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ecbb95d0-260c-4225-938f-e5d19b61a642
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a8ae1008-9cfa-4cfb-9c81-ce9937223739
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a251cd50-6c55-4a5b-a1df-a0c3d8436df2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d94e8c65-ace1-491e-981f-c309a9c3f48e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: reconnect message e11fa495-5a39-4fdd-896f-3bbaf57c2920
[92mINFO [0m:      Disconnect and shut down
ğŸš€ Starting NASA FL Client: client_4
Algorithm: FEDAVGM
Server: localhost:8688
K-Folds: 5
Log Directory: logs
ğŸ”„ Using device: cuda
ğŸ¯ GPU: NVIDIA A100-SXM4-80GB
ğŸ›‘ Early stopping enabled:
   Patience: 3 epochs
   Min delta: 0.001
ğŸ’¾ Hyperparameters saved to: logs/client_4_hyperparams_20251030_111452.csv
ğŸ” Looking for data at: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.5/client_4
ğŸ“Š Loaded 7615 total samples from /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.5/client_4
ğŸ”¢ Original feature dimension: 24
ğŸ” Applying KernelPCA with 5 components, kernel=poly
ğŸ“Š Data shape - Before: (4569, 24), After: (4569, 5)
ğŸ”„ Created sequences with length 10
   Final dataset shape: X (4559, 10, 5), y (4559,)
âœ… Data split completed:
   Training samples: 4559
   Validation samples: 1513
   Test samples: 1513
   Model type: lstm
   Final input dimension: 5
âœ… Client client_4 ready:
   Model: LSTM
   Training: 4559 samples
   Device: cuda
   Validation: 1513 samples
   Test: 1513 samples
   Algorithm: fedavgm
   Total Rounds: 10
   Learning Rate: 0.001
   Batch Size: 32
   Logging to: logs
â© Skipping CV for Round 1

ğŸ”„ Starting local training (Round 1)...
   Epoch 1/1: train_loss=24635.3156, val_rmse=108.1893 â­ (improved by inf)
   âœ… Completed 1 epochs, using best model (val_rmse=108.1893)
Round 1: epochs=1, train_loss=11180.1201, val_rmse=108.1893, val_r2=-0.0914

ğŸ§ª Round 1 Evaluation Results:
   Test Loss: 15884.7005
   RMSE: 126.0345, MAE: 94.1842, RÂ²: -0.5125
ğŸ’¾ Test metrics saved to: logs/client_4_test_metrics_20251030_111452.csv
â© Skipping CV for Round 2

ğŸ”„ Starting local training (Round 2)...
   Epoch 1/1: train_loss=12676.5885, val_rmse=104.4724 â­ (improved by inf)
   âœ… Completed 1 epochs, using best model (val_rmse=104.4724)
Round 2: epochs=1, train_loss=10525.2549, val_rmse=104.4724, val_r2=-0.0177
ğŸ’¾ Training metrics saved to: logs/client_4_training_metrics_20251030_111452.csv

ğŸ§ª Round 2 Evaluation Results:
   Test Loss: 124117.9132
   RMSE: 352.3037, MAE: 337.1993, RÂ²: -10.8183
ğŸ’¾ Test metrics saved to: logs/client_4_test_metrics_20251030_111452.csv
â© Skipping CV for Round 3

ğŸ”„ Starting local training (Round 3)...
   Epoch 1/1: train_loss=25406.9332, val_rmse=103.6852 â­ (improved by inf)
   âœ… Completed 1 epochs, using best model (val_rmse=103.6852)

ğŸ¯ Round 3 Training Summary:
   Epochs trained: 1/1
   Total early stops so far: 0
   Training   - Loss: 10428.4570, RMSE: 102.1198, RÂ²: -0.0002
   Validation - Loss: 10750.6318, RMSE: 103.6852, RÂ²: -0.0024

ğŸ§ª Round 3 Evaluation Results:
   Test Loss: 271639.4355
   RMSE: 521.1904, MAE: 511.0159, RÂ²: -24.8650
ğŸ’¾ Test metrics saved to: logs/client_4_test_metrics_20251030_111452.csv
â© Skipping CV for Round 4

ğŸ”„ Starting local training (Round 4)...
   Epoch 1/1: train_loss=52709.3029, val_rmse=106.4588 â­ (improved by inf)
   âœ… Completed 1 epochs, using best model (val_rmse=106.4588)
Round 4: epochs=1, train_loss=11241.8340, val_rmse=106.4588, val_r2=-0.0568
ğŸ’¾ Training metrics saved to: logs/client_4_training_metrics_20251030_111452.csv

ğŸ§ª Round 4 Evaluation Results:
   Test Loss: 29500.8352
   RMSE: 171.7581, MAE: 152.4953, RÂ²: -1.8090
ğŸ’¾ Test metrics saved to: logs/client_4_test_metrics_20251030_111452.csv

ğŸ” Running 3-fold cross-validation (Round 5)

ğŸ” Starting 3-fold cross-validation on TRAINING data for client client_4

ğŸ“Š Fold 1/3
   Fold 1 Results:
     Val Loss: 11671.5596
     Val RMSE: 108.0350, Val RÂ²: -0.1005

ğŸ“Š Fold 2/3
   Fold 2 Results:
     Val Loss: 11184.3740
     Val RMSE: 105.7562, Val RÂ²: -0.0663

ğŸ“Š Fold 3/3
   Fold 3 Results:
     Val Loss: 11255.5625
     Val RMSE: 106.0922, Val RÂ²: -0.1078
ğŸ’¾ CV metrics saved to: logs/client_4_cv_metrics_20251030_111452.csv

ğŸ“ˆ 3-Fold CV Summary (Training Data):
   VAL_LOSS: 11370.4987 Â± 214.8568
   RMSE: 106.6278 Â± 1.0044
   R2: -0.0915 Â± 0.0181

ğŸ”„ Starting local training (Round 5)...
   Epoch 1/1: train_loss=16874.7408, val_rmse=103.5616 â­ (improved by inf)
   âœ… Completed 1 epochs, using best model (val_rmse=103.5616)

ğŸ¯ Round 5 Training Summary:
   Epochs trained: 1/1
   Total early stops so far: 0
   Training   - Loss: 10448.2627, RMSE: 102.2167, RÂ²: -0.0020
   Validation - Loss: 10724.9971, RMSE: 103.5616, RÂ²: -0.0001
ğŸ’¾ Training metrics saved to: logs/client_4_training_metrics_20251030_111452.csv

ğŸ§ª Round 5 Evaluation Results:
   Test Loss: 20799.7800
   RMSE: 144.2213, MAE: 109.6999, RÂ²: -0.9805
ğŸ’¾ Test metrics saved to: logs/client_4_test_metrics_20251030_111452.csv
â© Skipping CV for Round 6

ğŸ”„ Starting local training (Round 6)...
   Epoch 1/1: train_loss=18030.4012, val_rmse=125.8662 â­ (improved by inf)
   âœ… Completed 1 epochs, using best model (val_rmse=125.8662)

ğŸ¯ Round 6 Training Summary:
   Epochs trained: 1/1
   Total early stops so far: 0
   Training   - Loss: 15006.2939, RMSE: 122.5002, RÂ²: -0.4392
   Validation - Loss: 15842.3057, RMSE: 125.8662, RÂ²: -0.4772
ğŸ’¾ Training metrics saved to: logs/client_4_training_metrics_20251030_111452.csv

ğŸ§ª Round 6 Evaluation Results:
   Test Loss: 32218.2506
   RMSE: 179.4944, MAE: 147.3862, RÂ²: -2.0678
ğŸ’¾ Test metrics saved to: logs/client_4_test_metrics_20251030_111452.csv
â© Skipping CV for Round 7

ğŸ”„ Starting local training (Round 7)...
   Epoch 1/1: train_loss=31029.9969, val_rmse=178.7083 â­ (improved by inf)
   âœ… Completed 1 epochs, using best model (val_rmse=178.7083)
Round 7: epochs=1, train_loss=30527.3750, val_rmse=178.7083, val_r2=-1.9779

ğŸ§ª Round 7 Evaluation Results:
   Test Loss: 32695.5096
   RMSE: 180.8190, MAE: 148.9742, RÂ²: -2.1132
ğŸ’¾ Test metrics saved to: logs/client_4_test_metrics_20251030_111452.csv
â© Skipping CV for Round 8

ğŸ”„ Starting local training (Round 8)...
   Epoch 1/1: train_loss=31942.5803, val_rmse=182.6970 â­ (improved by inf)
   âœ… Completed 1 epochs, using best model (val_rmse=182.6970)
Round 8: epochs=1, train_loss=31931.2539, val_rmse=182.6970, val_r2=-2.1124
ğŸ’¾ Training metrics saved to: logs/client_4_training_metrics_20251030_111452.csv

ğŸ§ª Round 8 Evaluation Results:
   Test Loss: 32652.9789
   RMSE: 180.7014, MAE: 148.8318, RÂ²: -2.1092
ğŸ’¾ Test metrics saved to: logs/client_4_test_metrics_20251030_111452.csv

ğŸ” Running 3-fold cross-validation (Round 9)
ğŸ’¾ CV metrics saved to: logs/client_4_cv_metrics_20251030_111452.csv

ğŸ”„ Starting local training (Round 9)...
   Epoch 1/1: train_loss=31901.9047, val_rmse=182.5859 â­ (improved by inf)
   âœ… Completed 1 epochs, using best model (val_rmse=182.5859)

ğŸ¯ Round 9 Training Summary:
   Epochs trained: 1/1
   Total early stops so far: 0
   Training   - Loss: 31891.7090, RMSE: 178.5825, RÂ²: -2.0586
   Validation - Loss: 33337.6211, RMSE: 182.5859, RÂ²: -2.1086
ğŸ’¾ Training metrics saved to: logs/client_4_training_metrics_20251030_111452.csv

ğŸ§ª Round 9 Evaluation Results:
   Test Loss: 32578.6891
   RMSE: 180.4957, MAE: 148.5850, RÂ²: -2.1021
ğŸ’¾ Test metrics saved to: logs/client_4_test_metrics_20251030_111452.csv

ğŸ” Running 3-fold cross-validation (Round 10)
ğŸ’¾ CV metrics saved to: logs/client_4_cv_metrics_20251030_111452.csv

ğŸ”„ Starting local training (Round 10)...
   Epoch 1/1: train_loss=31829.6518, val_rmse=182.3850 â­ (improved by inf)
   âœ… Completed 1 epochs, using best model (val_rmse=182.3850)

ğŸ¯ Round 10 Training Summary:
   Epochs trained: 1/1
   Total early stops so far: 0
   Training   - Loss: 31820.2539, RMSE: 178.3823, RÂ²: -2.0517
   Validation - Loss: 33264.2773, RMSE: 182.3850, RÂ²: -2.1017
ğŸ’¾ Training metrics saved to: logs/client_4_training_metrics_20251030_111452.csv

ğŸ§ª Round 10 Evaluation Results:
   Test Loss: 32476.0490
   RMSE: 180.2111, MAE: 148.2433, RÂ²: -2.0923
ğŸ’¾ Test metrics saved to: logs/client_4_test_metrics_20251030_111452.csv

================================================================================
ğŸ¯ FINAL COMPREHENSIVE REPORT
================================================================================
ğŸ’¾ Final summary saved to: logs/client_4_final_summary_20251030_111452.csv

ğŸ“Š CLIENT: client_4 | ALGORITHM: fedavgm | MODEL: LSTM
ğŸ“ˆ TOTAL ROUNDS: 10

âš™ï¸  HYPERPARAMETERS:
   Learning Rate: 0.001
   Batch Size: 32
   Local Epochs: 1
   Hidden Dim: 64
   Num Layers: 2
   Sequence Length: 10
   Use Attention: False
   Dropout: 0.3
   Optimizer: adam

ğŸ›‘ EARLY STOPPING SUMMARY:
   Enabled: Yes
   Patience: 3 epochs
   Min delta: 0.001
   Total early stops: 0/10 rounds
   Early stop rate: 0.0%

ğŸ FINAL ROUND PERFORMANCE:
   Training   - Loss: 31820.25 | RMSE: 178.38 | RÂ²: -2.0517
   Validation - Loss: 33264.28 | RMSE: 182.38 | RÂ²: -2.1017
   Test       - Loss: 32476.05 | RMSE: 180.21 | RÂ²: -2.0923

ğŸ“Š STATISTICS ACROSS ALL ROUNDS (Mean Â± Std):
   Training Loss:   20409.27 Â± 10035.38
   Validation Loss: 21256.48 Â± 10574.40
   Test Loss:       62456.41 Â± 75518.04

   Training RMSE:   138.43 Â± 35.31
   Validation RMSE: 141.15 Â± 36.53
   Test RMSE:       221.72 Â± 115.31

   Training RÂ²:     -0.9574 Â± 0.9625
   Validation RÂ²:   -0.9821 Â± 0.9860
   Test RÂ²:         -4.9470 Â± 7.1907

â­ BEST PERFORMANCE:
   Best Round: 1 (Test RÂ²: -0.5125)

ğŸ“‹ DATA SUMMARY:
   Training samples:   4559
   Validation samples: 1513
   Test samples:       1513
   Total samples:      7585
================================================================================
âœ… Client client_4 completed | Algorithm: FEDAVGM
