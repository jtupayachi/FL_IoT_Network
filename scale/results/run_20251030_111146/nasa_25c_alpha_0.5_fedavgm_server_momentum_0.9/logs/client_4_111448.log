[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eaf0ef02-a4a8-4afc-a7b5-40c136318884
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message af2a6e84-21ba-4a4f-aacb-883ed7d30522
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0a0f0784-7f13-4b7b-8196-e682794bbf0b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2774ca92-cc75-434f-818b-b43eb8def50b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 588438e8-a3c6-460c-8b6c-fa0fcea2910d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b717b953-ea7b-4483-9584-2e1adea11a8d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0b28a7c5-2ad3-485e-8bb2-444350a06469
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b99967b1-fa19-44b0-a710-c4c6d3840c70
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e7274386-79e0-42b1-b2f2-41f1fb47f04b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a67a9323-2df3-410d-a1d6-bbbc74666c2b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 423944ea-ab69-4312-88a2-e2b084d13211
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f3f241c3-77df-46fe-a072-1ffdf2eb879c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7e6b1870-2871-4206-8227-b4758d6673dd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9bcecdbd-9589-4561-b87e-40be9b9a3d0f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f15583e4-65a5-425f-afbe-76b93bb9ee7d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f81e67d2-9300-425d-b52d-9d032c57aaf2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ecbb95d0-260c-4225-938f-e5d19b61a642
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a8ae1008-9cfa-4cfb-9c81-ce9937223739
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a251cd50-6c55-4a5b-a1df-a0c3d8436df2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d94e8c65-ace1-491e-981f-c309a9c3f48e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: reconnect message e11fa495-5a39-4fdd-896f-3bbaf57c2920
[92mINFO [0m:      Disconnect and shut down
🚀 Starting NASA FL Client: client_4
Algorithm: FEDAVGM
Server: localhost:8688
K-Folds: 5
Log Directory: logs
🔄 Using device: cuda
🎯 GPU: NVIDIA A100-SXM4-80GB
🛑 Early stopping enabled:
   Patience: 3 epochs
   Min delta: 0.001
💾 Hyperparameters saved to: logs/client_4_hyperparams_20251030_111452.csv
🔍 Looking for data at: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.5/client_4
📊 Loaded 7615 total samples from /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.5/client_4
🔢 Original feature dimension: 24
🔍 Applying KernelPCA with 5 components, kernel=poly
📊 Data shape - Before: (4569, 24), After: (4569, 5)
🔄 Created sequences with length 10
   Final dataset shape: X (4559, 10, 5), y (4559,)
✅ Data split completed:
   Training samples: 4559
   Validation samples: 1513
   Test samples: 1513
   Model type: lstm
   Final input dimension: 5
✅ Client client_4 ready:
   Model: LSTM
   Training: 4559 samples
   Device: cuda
   Validation: 1513 samples
   Test: 1513 samples
   Algorithm: fedavgm
   Total Rounds: 10
   Learning Rate: 0.001
   Batch Size: 32
   Logging to: logs
⏩ Skipping CV for Round 1

🔄 Starting local training (Round 1)...
   Epoch 1/1: train_loss=24635.3156, val_rmse=108.1893 ⭐ (improved by inf)
   ✅ Completed 1 epochs, using best model (val_rmse=108.1893)
Round 1: epochs=1, train_loss=11180.1201, val_rmse=108.1893, val_r2=-0.0914

🧪 Round 1 Evaluation Results:
   Test Loss: 15884.7005
   RMSE: 126.0345, MAE: 94.1842, R²: -0.5125
💾 Test metrics saved to: logs/client_4_test_metrics_20251030_111452.csv
⏩ Skipping CV for Round 2

🔄 Starting local training (Round 2)...
   Epoch 1/1: train_loss=12676.5885, val_rmse=104.4724 ⭐ (improved by inf)
   ✅ Completed 1 epochs, using best model (val_rmse=104.4724)
Round 2: epochs=1, train_loss=10525.2549, val_rmse=104.4724, val_r2=-0.0177
💾 Training metrics saved to: logs/client_4_training_metrics_20251030_111452.csv

🧪 Round 2 Evaluation Results:
   Test Loss: 124117.9132
   RMSE: 352.3037, MAE: 337.1993, R²: -10.8183
💾 Test metrics saved to: logs/client_4_test_metrics_20251030_111452.csv
⏩ Skipping CV for Round 3

🔄 Starting local training (Round 3)...
   Epoch 1/1: train_loss=25406.9332, val_rmse=103.6852 ⭐ (improved by inf)
   ✅ Completed 1 epochs, using best model (val_rmse=103.6852)

🎯 Round 3 Training Summary:
   Epochs trained: 1/1
   Total early stops so far: 0
   Training   - Loss: 10428.4570, RMSE: 102.1198, R²: -0.0002
   Validation - Loss: 10750.6318, RMSE: 103.6852, R²: -0.0024

🧪 Round 3 Evaluation Results:
   Test Loss: 271639.4355
   RMSE: 521.1904, MAE: 511.0159, R²: -24.8650
💾 Test metrics saved to: logs/client_4_test_metrics_20251030_111452.csv
⏩ Skipping CV for Round 4

🔄 Starting local training (Round 4)...
   Epoch 1/1: train_loss=52709.3029, val_rmse=106.4588 ⭐ (improved by inf)
   ✅ Completed 1 epochs, using best model (val_rmse=106.4588)
Round 4: epochs=1, train_loss=11241.8340, val_rmse=106.4588, val_r2=-0.0568
💾 Training metrics saved to: logs/client_4_training_metrics_20251030_111452.csv

🧪 Round 4 Evaluation Results:
   Test Loss: 29500.8352
   RMSE: 171.7581, MAE: 152.4953, R²: -1.8090
💾 Test metrics saved to: logs/client_4_test_metrics_20251030_111452.csv

🔍 Running 3-fold cross-validation (Round 5)

🔍 Starting 3-fold cross-validation on TRAINING data for client client_4

📊 Fold 1/3
   Fold 1 Results:
     Val Loss: 11671.5596
     Val RMSE: 108.0350, Val R²: -0.1005

📊 Fold 2/3
   Fold 2 Results:
     Val Loss: 11184.3740
     Val RMSE: 105.7562, Val R²: -0.0663

📊 Fold 3/3
   Fold 3 Results:
     Val Loss: 11255.5625
     Val RMSE: 106.0922, Val R²: -0.1078
💾 CV metrics saved to: logs/client_4_cv_metrics_20251030_111452.csv

📈 3-Fold CV Summary (Training Data):
   VAL_LOSS: 11370.4987 ± 214.8568
   RMSE: 106.6278 ± 1.0044
   R2: -0.0915 ± 0.0181

🔄 Starting local training (Round 5)...
   Epoch 1/1: train_loss=16874.7408, val_rmse=103.5616 ⭐ (improved by inf)
   ✅ Completed 1 epochs, using best model (val_rmse=103.5616)

🎯 Round 5 Training Summary:
   Epochs trained: 1/1
   Total early stops so far: 0
   Training   - Loss: 10448.2627, RMSE: 102.2167, R²: -0.0020
   Validation - Loss: 10724.9971, RMSE: 103.5616, R²: -0.0001
💾 Training metrics saved to: logs/client_4_training_metrics_20251030_111452.csv

🧪 Round 5 Evaluation Results:
   Test Loss: 20799.7800
   RMSE: 144.2213, MAE: 109.6999, R²: -0.9805
💾 Test metrics saved to: logs/client_4_test_metrics_20251030_111452.csv
⏩ Skipping CV for Round 6

🔄 Starting local training (Round 6)...
   Epoch 1/1: train_loss=18030.4012, val_rmse=125.8662 ⭐ (improved by inf)
   ✅ Completed 1 epochs, using best model (val_rmse=125.8662)

🎯 Round 6 Training Summary:
   Epochs trained: 1/1
   Total early stops so far: 0
   Training   - Loss: 15006.2939, RMSE: 122.5002, R²: -0.4392
   Validation - Loss: 15842.3057, RMSE: 125.8662, R²: -0.4772
💾 Training metrics saved to: logs/client_4_training_metrics_20251030_111452.csv

🧪 Round 6 Evaluation Results:
   Test Loss: 32218.2506
   RMSE: 179.4944, MAE: 147.3862, R²: -2.0678
💾 Test metrics saved to: logs/client_4_test_metrics_20251030_111452.csv
⏩ Skipping CV for Round 7

🔄 Starting local training (Round 7)...
   Epoch 1/1: train_loss=31029.9969, val_rmse=178.7083 ⭐ (improved by inf)
   ✅ Completed 1 epochs, using best model (val_rmse=178.7083)
Round 7: epochs=1, train_loss=30527.3750, val_rmse=178.7083, val_r2=-1.9779

🧪 Round 7 Evaluation Results:
   Test Loss: 32695.5096
   RMSE: 180.8190, MAE: 148.9742, R²: -2.1132
💾 Test metrics saved to: logs/client_4_test_metrics_20251030_111452.csv
⏩ Skipping CV for Round 8

🔄 Starting local training (Round 8)...
   Epoch 1/1: train_loss=31942.5803, val_rmse=182.6970 ⭐ (improved by inf)
   ✅ Completed 1 epochs, using best model (val_rmse=182.6970)
Round 8: epochs=1, train_loss=31931.2539, val_rmse=182.6970, val_r2=-2.1124
💾 Training metrics saved to: logs/client_4_training_metrics_20251030_111452.csv

🧪 Round 8 Evaluation Results:
   Test Loss: 32652.9789
   RMSE: 180.7014, MAE: 148.8318, R²: -2.1092
💾 Test metrics saved to: logs/client_4_test_metrics_20251030_111452.csv

🔍 Running 3-fold cross-validation (Round 9)
💾 CV metrics saved to: logs/client_4_cv_metrics_20251030_111452.csv

🔄 Starting local training (Round 9)...
   Epoch 1/1: train_loss=31901.9047, val_rmse=182.5859 ⭐ (improved by inf)
   ✅ Completed 1 epochs, using best model (val_rmse=182.5859)

🎯 Round 9 Training Summary:
   Epochs trained: 1/1
   Total early stops so far: 0
   Training   - Loss: 31891.7090, RMSE: 178.5825, R²: -2.0586
   Validation - Loss: 33337.6211, RMSE: 182.5859, R²: -2.1086
💾 Training metrics saved to: logs/client_4_training_metrics_20251030_111452.csv

🧪 Round 9 Evaluation Results:
   Test Loss: 32578.6891
   RMSE: 180.4957, MAE: 148.5850, R²: -2.1021
💾 Test metrics saved to: logs/client_4_test_metrics_20251030_111452.csv

🔍 Running 3-fold cross-validation (Round 10)
💾 CV metrics saved to: logs/client_4_cv_metrics_20251030_111452.csv

🔄 Starting local training (Round 10)...
   Epoch 1/1: train_loss=31829.6518, val_rmse=182.3850 ⭐ (improved by inf)
   ✅ Completed 1 epochs, using best model (val_rmse=182.3850)

🎯 Round 10 Training Summary:
   Epochs trained: 1/1
   Total early stops so far: 0
   Training   - Loss: 31820.2539, RMSE: 178.3823, R²: -2.0517
   Validation - Loss: 33264.2773, RMSE: 182.3850, R²: -2.1017
💾 Training metrics saved to: logs/client_4_training_metrics_20251030_111452.csv

🧪 Round 10 Evaluation Results:
   Test Loss: 32476.0490
   RMSE: 180.2111, MAE: 148.2433, R²: -2.0923
💾 Test metrics saved to: logs/client_4_test_metrics_20251030_111452.csv

================================================================================
🎯 FINAL COMPREHENSIVE REPORT
================================================================================
💾 Final summary saved to: logs/client_4_final_summary_20251030_111452.csv

📊 CLIENT: client_4 | ALGORITHM: fedavgm | MODEL: LSTM
📈 TOTAL ROUNDS: 10

⚙️  HYPERPARAMETERS:
   Learning Rate: 0.001
   Batch Size: 32
   Local Epochs: 1
   Hidden Dim: 64
   Num Layers: 2
   Sequence Length: 10
   Use Attention: False
   Dropout: 0.3
   Optimizer: adam

🛑 EARLY STOPPING SUMMARY:
   Enabled: Yes
   Patience: 3 epochs
   Min delta: 0.001
   Total early stops: 0/10 rounds
   Early stop rate: 0.0%

🏁 FINAL ROUND PERFORMANCE:
   Training   - Loss: 31820.25 | RMSE: 178.38 | R²: -2.0517
   Validation - Loss: 33264.28 | RMSE: 182.38 | R²: -2.1017
   Test       - Loss: 32476.05 | RMSE: 180.21 | R²: -2.0923

📊 STATISTICS ACROSS ALL ROUNDS (Mean ± Std):
   Training Loss:   20409.27 ± 10035.38
   Validation Loss: 21256.48 ± 10574.40
   Test Loss:       62456.41 ± 75518.04

   Training RMSE:   138.43 ± 35.31
   Validation RMSE: 141.15 ± 36.53
   Test RMSE:       221.72 ± 115.31

   Training R²:     -0.9574 ± 0.9625
   Validation R²:   -0.9821 ± 0.9860
   Test R²:         -4.9470 ± 7.1907

⭐ BEST PERFORMANCE:
   Best Round: 1 (Test R²: -0.5125)

📋 DATA SUMMARY:
   Training samples:   4559
   Validation samples: 1513
   Test samples:       1513
   Total samples:      7585
================================================================================
✅ Client client_4 completed | Algorithm: FEDAVGM
