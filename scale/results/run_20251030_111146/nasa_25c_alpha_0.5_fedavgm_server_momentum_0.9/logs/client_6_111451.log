[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c8cb4f55-9bf2-4a26-91d2-f9d63049fb5c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eb8926fc-0ab0-4916-ae3d-e7cc617ae502
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fd37668b-82aa-4cc5-b6f2-16fe88303ba1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c045da1e-59f2-4dd6-a632-d9dc5058f999
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6965a7e2-b4b2-4aed-9e57-484934946f4d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3b8fdb8c-6943-47c1-a59e-80118c362a0c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cc629a7a-0fca-4a86-8892-738f59ca637a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e46ed065-5e59-41ee-83e5-4b2165c3a368
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a8914fce-7ee9-4fc8-acb3-2faac0f178e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 21653f63-bd25-40b3-8f15-ab504616822d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b3c6cc74-1d4a-462b-92d4-d4d8215171de
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a11d3c60-28fc-42b1-940e-ecfdec0ac4f4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1088e59b-a644-4469-97a8-b69c099ef303
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 657ff89a-7da1-4563-bfe9-ec25c97ddb0c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 65d7dece-51d9-4f29-8e36-3c48e2189fac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2daf7575-5c31-429c-938b-fb7681f9e8fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2f2e5607-5645-4854-87f9-63b7f01cee59
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f0d6cbf3-a662-4dec-b697-f610d50041ce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 89dfb7b6-d964-4303-b28e-b0d890562e46
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6851cf4c-1bf9-4bf6-a919-ac03394c6440
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: reconnect message 4a4044c1-2051-4209-a385-b36a747a03f1
[92mINFO [0m:      Disconnect and shut down
ğŸš€ Starting NASA FL Client: client_6
Algorithm: FEDAVGM
Server: localhost:8688
K-Folds: 5
Log Directory: logs
ğŸ”„ Using device: cuda
ğŸ¯ GPU: NVIDIA A100-SXM4-80GB
ğŸ›‘ Early stopping enabled:
   Patience: 3 epochs
   Min delta: 0.001
ğŸ’¾ Hyperparameters saved to: logs/client_6_hyperparams_20251030_111455.csv
ğŸ” Looking for data at: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.5/client_6
ğŸ“Š Loaded 7595 total samples from /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.5/client_6
ğŸ”¢ Original feature dimension: 24
ğŸ” Applying KernelPCA with 5 components, kernel=poly
ğŸ“Š Data shape - Before: (4557, 24), After: (4557, 5)
ğŸ”„ Created sequences with length 10
   Final dataset shape: X (4547, 10, 5), y (4547,)
âœ… Data split completed:
   Training samples: 4547
   Validation samples: 1509
   Test samples: 1509
   Model type: lstm
   Final input dimension: 5
âœ… Client client_6 ready:
   Model: LSTM
   Training: 4547 samples
   Device: cuda
   Validation: 1509 samples
   Test: 1509 samples
   Algorithm: fedavgm
   Total Rounds: 10
   Learning Rate: 0.001
   Batch Size: 32
   Logging to: logs
â© Skipping CV for Round 1

ğŸ”„ Starting local training (Round 1)...
   Epoch 1/1: train_loss=14635.6190, val_rmse=78.7701 â­ (improved by inf)
   âœ… Completed 1 epochs, using best model (val_rmse=78.7701)
Round 1: epochs=1, train_loss=6065.4849, val_rmse=78.7701, val_r2=-0.0288

ğŸ§ª Round 1 Evaluation Results:
   Test Loss: 7721.0950
   RMSE: 87.8698, MAE: 67.5947, RÂ²: -0.3283
ğŸ’¾ Test metrics saved to: logs/client_6_test_metrics_20251030_111455.csv
â© Skipping CV for Round 2

ğŸ”„ Starting local training (Round 2)...
   Epoch 1/1: train_loss=6908.0817, val_rmse=77.8279 â­ (improved by inf)
   âœ… Completed 1 epochs, using best model (val_rmse=77.8279)
Round 2: epochs=1, train_loss=5912.7603, val_rmse=77.8279, val_r2=-0.0043
ğŸ’¾ Training metrics saved to: logs/client_6_training_metrics_20251030_111455.csv

ğŸ§ª Round 2 Evaluation Results:
   Test Loss: 140319.5960
   RMSE: 374.5926, MAE: 366.7516, RÂ²: -23.1395
ğŸ’¾ Test metrics saved to: logs/client_6_test_metrics_20251030_111455.csv
â© Skipping CV for Round 3

ğŸ”„ Starting local training (Round 3)...
   Epoch 1/1: train_loss=23904.4774, val_rmse=78.2085 â­ (improved by inf)
   âœ… Completed 1 epochs, using best model (val_rmse=78.2085)

ğŸ¯ Round 3 Training Summary:
   Epochs trained: 1/1
   Total early stops so far: 0
   Training   - Loss: 5962.9595, RMSE: 77.2202, RÂ²: -0.0135
   Validation - Loss: 6116.5762, RMSE: 78.2085, RÂ²: -0.0142

ğŸ§ª Round 3 Evaluation Results:
   Test Loss: 298167.4959
   RMSE: 546.0472, MAE: 540.6982, RÂ²: -50.2944
ğŸ’¾ Test metrics saved to: logs/client_6_test_metrics_20251030_111455.csv
â© Skipping CV for Round 4

ğŸ”„ Starting local training (Round 4)...
   Epoch 1/1: train_loss=54819.1420, val_rmse=90.2165 â­ (improved by inf)
   âœ… Completed 1 epochs, using best model (val_rmse=90.2165)
Round 4: epochs=1, train_loss=7961.9053, val_rmse=90.2165, val_r2=-0.3495
ğŸ’¾ Training metrics saved to: logs/client_6_training_metrics_20251030_111455.csv

ğŸ§ª Round 4 Evaluation Results:
   Test Loss: 33875.1323
   RMSE: 184.0520, MAE: 170.1861, RÂ²: -4.8276
ğŸ’¾ Test metrics saved to: logs/client_6_test_metrics_20251030_111455.csv

ğŸ” Running 3-fold cross-validation (Round 5)

ğŸ” Starting 3-fold cross-validation on TRAINING data for client client_6

ğŸ“Š Fold 1/3
   Fold 1 Results:
     Val Loss: 8556.5322
     Val RMSE: 92.5015, Val RÂ²: -0.5618

ğŸ“Š Fold 2/3
   Fold 2 Results:
     Val Loss: 9294.5430
     Val RMSE: 96.4082, Val RÂ²: -0.5305

ğŸ“Š Fold 3/3
   Fold 3 Results:
     Val Loss: 9364.5596
     Val RMSE: 96.7706, Val RÂ²: -0.5356
ğŸ’¾ CV metrics saved to: logs/client_6_cv_metrics_20251030_111455.csv

ğŸ“ˆ 3-Fold CV Summary (Training Data):
   VAL_LOSS: 9071.8783 Â± 365.5240
   RMSE: 95.2268 Â± 1.9327
   R2: -0.5427 Â± 0.0137

ğŸ”„ Starting local training (Round 5)...
   Epoch 1/1: train_loss=14045.2970, val_rmse=79.7196 â­ (improved by inf)
   âœ… Completed 1 epochs, using best model (val_rmse=79.7196)

ğŸ¯ Round 5 Training Summary:
   Epochs trained: 1/1
   Total early stops so far: 0
   Training   - Loss: 6195.9873, RMSE: 78.7146, RÂ²: -0.0531
   Validation - Loss: 6355.2158, RMSE: 79.7196, RÂ²: -0.0537
ğŸ’¾ Training metrics saved to: logs/client_6_training_metrics_20251030_111455.csv

ğŸ§ª Round 5 Evaluation Results:
   Test Loss: 10967.9283
   RMSE: 104.7279, MAE: 81.0931, RÂ²: -0.8868
ğŸ’¾ Test metrics saved to: logs/client_6_test_metrics_20251030_111455.csv
â© Skipping CV for Round 6

ğŸ”„ Starting local training (Round 6)...
   Epoch 1/1: train_loss=9910.2222, val_rmse=92.6769 â­ (improved by inf)
   âœ… Completed 1 epochs, using best model (val_rmse=92.6769)

ğŸ¯ Round 6 Training Summary:
   Epochs trained: 1/1
   Total early stops so far: 0
   Training   - Loss: 8473.7148, RMSE: 92.0528, RÂ²: -0.4403
   Validation - Loss: 8589.0039, RMSE: 92.6769, RÂ²: -0.4241
ğŸ’¾ Training metrics saved to: logs/client_6_training_metrics_20251030_111455.csv

ğŸ§ª Round 6 Evaluation Results:
   Test Loss: 19661.7873
   RMSE: 140.2205, MAE: 117.7073, RÂ²: -2.3825
ğŸ’¾ Test metrics saved to: logs/client_6_test_metrics_20251030_111455.csv
â© Skipping CV for Round 7

ğŸ”„ Starting local training (Round 7)...
   Epoch 1/1: train_loss=19102.5069, val_rmse=137.4375 â­ (improved by inf)
   âœ… Completed 1 epochs, using best model (val_rmse=137.4375)
Round 7: epochs=1, train_loss=18814.0371, val_rmse=137.4375, val_r2=-2.1319

ğŸ§ª Round 7 Evaluation Results:
   Test Loss: 20043.4383
   RMSE: 141.5748, MAE: 119.2919, RÂ²: -2.4481
ğŸ’¾ Test metrics saved to: logs/client_6_test_metrics_20251030_111455.csv
â© Skipping CV for Round 8

ğŸ”„ Starting local training (Round 8)...
   Epoch 1/1: train_loss=19727.0954, val_rmse=140.6173 â­ (improved by inf)
   âœ… Completed 1 epochs, using best model (val_rmse=140.6173)
Round 8: epochs=1, train_loss=19700.6445, val_rmse=140.6173, val_r2=-2.2785
ğŸ’¾ Training metrics saved to: logs/client_6_training_metrics_20251030_111455.csv

ğŸ§ª Round 8 Evaluation Results:
   Test Loss: 20009.3863
   RMSE: 141.4545, MAE: 119.1496, RÂ²: -2.4423
ğŸ’¾ Test metrics saved to: logs/client_6_test_metrics_20251030_111455.csv

ğŸ” Running 3-fold cross-validation (Round 9)
ğŸ’¾ CV metrics saved to: logs/client_6_cv_metrics_20251030_111455.csv

ğŸ”„ Starting local training (Round 9)...
   Epoch 1/1: train_loss=19693.6436, val_rmse=140.4997 â­ (improved by inf)
   âœ… Completed 1 epochs, using best model (val_rmse=140.4997)

ğŸ¯ Round 9 Training Summary:
   Epochs trained: 1/1
   Total early stops so far: 0
   Training   - Loss: 19667.4805, RMSE: 140.2408, RÂ²: -2.3429
   Validation - Loss: 19740.1562, RMSE: 140.4997, RÂ²: -2.2731
ğŸ’¾ Training metrics saved to: logs/client_6_training_metrics_20251030_111455.csv

ğŸ§ª Round 9 Evaluation Results:
   Test Loss: 19949.9252
   RMSE: 141.2442, MAE: 118.9035, RÂ²: -2.4320
ğŸ’¾ Test metrics saved to: logs/client_6_test_metrics_20251030_111455.csv

ğŸ” Running 3-fold cross-validation (Round 10)
ğŸ’¾ CV metrics saved to: logs/client_6_cv_metrics_20251030_111455.csv

ğŸ”„ Starting local training (Round 10)...
   Epoch 1/1: train_loss=19635.1223, val_rmse=140.2929 â­ (improved by inf)
   âœ… Completed 1 epochs, using best model (val_rmse=140.2929)

ğŸ¯ Round 10 Training Summary:
   Epochs trained: 1/1
   Total early stops so far: 0
   Training   - Loss: 19609.2578, RMSE: 140.0331, RÂ²: -2.3330
   Validation - Loss: 19682.0938, RMSE: 140.2929, RÂ²: -2.2634
ğŸ’¾ Training metrics saved to: logs/client_6_training_metrics_20251030_111455.csv

ğŸ§ª Round 10 Evaluation Results:
   Test Loss: 19867.8128
   RMSE: 140.9532, MAE: 118.5627, RÂ²: -2.4179
ğŸ’¾ Test metrics saved to: logs/client_6_test_metrics_20251030_111455.csv

================================================================================
ğŸ¯ FINAL COMPREHENSIVE REPORT
================================================================================
ğŸ’¾ Final summary saved to: logs/client_6_final_summary_20251030_111455.csv

ğŸ“Š CLIENT: client_6 | ALGORITHM: fedavgm | MODEL: LSTM
ğŸ“ˆ TOTAL ROUNDS: 10

âš™ï¸  HYPERPARAMETERS:
   Learning Rate: 0.001
   Batch Size: 32
   Local Epochs: 1
   Hidden Dim: 64
   Num Layers: 2
   Sequence Length: 10
   Use Attention: False
   Dropout: 0.3
   Optimizer: adam

ğŸ›‘ EARLY STOPPING SUMMARY:
   Enabled: Yes
   Patience: 3 epochs
   Min delta: 0.001
   Total early stops: 0/10 rounds
   Early stop rate: 0.0%

ğŸ FINAL ROUND PERFORMANCE:
   Training   - Loss: 19609.26 | RMSE: 140.03 | RÂ²: -2.3330
   Validation - Loss: 19682.09 | RMSE: 140.29 | RÂ²: -2.2634
   Test       - Loss: 19867.81 | RMSE: 140.95 | RÂ²: -2.4179

ğŸ“Š STATISTICS ACROSS ALL ROUNDS (Mean Â± Std):
   Training Loss:   12503.11 Â± 6253.01
   Validation Loss: 12619.41 Â± 6215.01
   Test Loss:       59058.36 Â± 87762.98

   Training RMSE:   108.22 Â± 28.14
   Validation RMSE: 108.84 Â± 27.82
   Test RMSE:       200.27 Â± 137.65

   Training RÂ²:     -1.1252 Â± 1.0628
   Validation RÂ²:   -1.0924 Â± 1.0305
   Test RÂ²:         -9.1599 Â± 15.0980

â­ BEST PERFORMANCE:
   Best Round: 1 (Test RÂ²: -0.3283)

ğŸ“‹ DATA SUMMARY:
   Training samples:   4547
   Validation samples: 1509
   Test samples:       1509
   Total samples:      7565
================================================================================
âœ… Client client_6 completed | Algorithm: FEDAVGM
