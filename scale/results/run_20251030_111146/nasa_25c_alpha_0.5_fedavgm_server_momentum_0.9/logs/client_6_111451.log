[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c8cb4f55-9bf2-4a26-91d2-f9d63049fb5c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eb8926fc-0ab0-4916-ae3d-e7cc617ae502
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fd37668b-82aa-4cc5-b6f2-16fe88303ba1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c045da1e-59f2-4dd6-a632-d9dc5058f999
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6965a7e2-b4b2-4aed-9e57-484934946f4d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3b8fdb8c-6943-47c1-a59e-80118c362a0c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cc629a7a-0fca-4a86-8892-738f59ca637a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e46ed065-5e59-41ee-83e5-4b2165c3a368
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a8914fce-7ee9-4fc8-acb3-2faac0f178e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 21653f63-bd25-40b3-8f15-ab504616822d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b3c6cc74-1d4a-462b-92d4-d4d8215171de
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a11d3c60-28fc-42b1-940e-ecfdec0ac4f4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1088e59b-a644-4469-97a8-b69c099ef303
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 657ff89a-7da1-4563-bfe9-ec25c97ddb0c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 65d7dece-51d9-4f29-8e36-3c48e2189fac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2daf7575-5c31-429c-938b-fb7681f9e8fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2f2e5607-5645-4854-87f9-63b7f01cee59
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f0d6cbf3-a662-4dec-b697-f610d50041ce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 89dfb7b6-d964-4303-b28e-b0d890562e46
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6851cf4c-1bf9-4bf6-a919-ac03394c6440
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: reconnect message 4a4044c1-2051-4209-a385-b36a747a03f1
[92mINFO [0m:      Disconnect and shut down
🚀 Starting NASA FL Client: client_6
Algorithm: FEDAVGM
Server: localhost:8688
K-Folds: 5
Log Directory: logs
🔄 Using device: cuda
🎯 GPU: NVIDIA A100-SXM4-80GB
🛑 Early stopping enabled:
   Patience: 3 epochs
   Min delta: 0.001
💾 Hyperparameters saved to: logs/client_6_hyperparams_20251030_111455.csv
🔍 Looking for data at: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.5/client_6
📊 Loaded 7595 total samples from /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/25_clients/alpha_0.5/client_6
🔢 Original feature dimension: 24
🔍 Applying KernelPCA with 5 components, kernel=poly
📊 Data shape - Before: (4557, 24), After: (4557, 5)
🔄 Created sequences with length 10
   Final dataset shape: X (4547, 10, 5), y (4547,)
✅ Data split completed:
   Training samples: 4547
   Validation samples: 1509
   Test samples: 1509
   Model type: lstm
   Final input dimension: 5
✅ Client client_6 ready:
   Model: LSTM
   Training: 4547 samples
   Device: cuda
   Validation: 1509 samples
   Test: 1509 samples
   Algorithm: fedavgm
   Total Rounds: 10
   Learning Rate: 0.001
   Batch Size: 32
   Logging to: logs
⏩ Skipping CV for Round 1

🔄 Starting local training (Round 1)...
   Epoch 1/1: train_loss=14635.6190, val_rmse=78.7701 ⭐ (improved by inf)
   ✅ Completed 1 epochs, using best model (val_rmse=78.7701)
Round 1: epochs=1, train_loss=6065.4849, val_rmse=78.7701, val_r2=-0.0288

🧪 Round 1 Evaluation Results:
   Test Loss: 7721.0950
   RMSE: 87.8698, MAE: 67.5947, R²: -0.3283
💾 Test metrics saved to: logs/client_6_test_metrics_20251030_111455.csv
⏩ Skipping CV for Round 2

🔄 Starting local training (Round 2)...
   Epoch 1/1: train_loss=6908.0817, val_rmse=77.8279 ⭐ (improved by inf)
   ✅ Completed 1 epochs, using best model (val_rmse=77.8279)
Round 2: epochs=1, train_loss=5912.7603, val_rmse=77.8279, val_r2=-0.0043
💾 Training metrics saved to: logs/client_6_training_metrics_20251030_111455.csv

🧪 Round 2 Evaluation Results:
   Test Loss: 140319.5960
   RMSE: 374.5926, MAE: 366.7516, R²: -23.1395
💾 Test metrics saved to: logs/client_6_test_metrics_20251030_111455.csv
⏩ Skipping CV for Round 3

🔄 Starting local training (Round 3)...
   Epoch 1/1: train_loss=23904.4774, val_rmse=78.2085 ⭐ (improved by inf)
   ✅ Completed 1 epochs, using best model (val_rmse=78.2085)

🎯 Round 3 Training Summary:
   Epochs trained: 1/1
   Total early stops so far: 0
   Training   - Loss: 5962.9595, RMSE: 77.2202, R²: -0.0135
   Validation - Loss: 6116.5762, RMSE: 78.2085, R²: -0.0142

🧪 Round 3 Evaluation Results:
   Test Loss: 298167.4959
   RMSE: 546.0472, MAE: 540.6982, R²: -50.2944
💾 Test metrics saved to: logs/client_6_test_metrics_20251030_111455.csv
⏩ Skipping CV for Round 4

🔄 Starting local training (Round 4)...
   Epoch 1/1: train_loss=54819.1420, val_rmse=90.2165 ⭐ (improved by inf)
   ✅ Completed 1 epochs, using best model (val_rmse=90.2165)
Round 4: epochs=1, train_loss=7961.9053, val_rmse=90.2165, val_r2=-0.3495
💾 Training metrics saved to: logs/client_6_training_metrics_20251030_111455.csv

🧪 Round 4 Evaluation Results:
   Test Loss: 33875.1323
   RMSE: 184.0520, MAE: 170.1861, R²: -4.8276
💾 Test metrics saved to: logs/client_6_test_metrics_20251030_111455.csv

🔍 Running 3-fold cross-validation (Round 5)

🔍 Starting 3-fold cross-validation on TRAINING data for client client_6

📊 Fold 1/3
   Fold 1 Results:
     Val Loss: 8556.5322
     Val RMSE: 92.5015, Val R²: -0.5618

📊 Fold 2/3
   Fold 2 Results:
     Val Loss: 9294.5430
     Val RMSE: 96.4082, Val R²: -0.5305

📊 Fold 3/3
   Fold 3 Results:
     Val Loss: 9364.5596
     Val RMSE: 96.7706, Val R²: -0.5356
💾 CV metrics saved to: logs/client_6_cv_metrics_20251030_111455.csv

📈 3-Fold CV Summary (Training Data):
   VAL_LOSS: 9071.8783 ± 365.5240
   RMSE: 95.2268 ± 1.9327
   R2: -0.5427 ± 0.0137

🔄 Starting local training (Round 5)...
   Epoch 1/1: train_loss=14045.2970, val_rmse=79.7196 ⭐ (improved by inf)
   ✅ Completed 1 epochs, using best model (val_rmse=79.7196)

🎯 Round 5 Training Summary:
   Epochs trained: 1/1
   Total early stops so far: 0
   Training   - Loss: 6195.9873, RMSE: 78.7146, R²: -0.0531
   Validation - Loss: 6355.2158, RMSE: 79.7196, R²: -0.0537
💾 Training metrics saved to: logs/client_6_training_metrics_20251030_111455.csv

🧪 Round 5 Evaluation Results:
   Test Loss: 10967.9283
   RMSE: 104.7279, MAE: 81.0931, R²: -0.8868
💾 Test metrics saved to: logs/client_6_test_metrics_20251030_111455.csv
⏩ Skipping CV for Round 6

🔄 Starting local training (Round 6)...
   Epoch 1/1: train_loss=9910.2222, val_rmse=92.6769 ⭐ (improved by inf)
   ✅ Completed 1 epochs, using best model (val_rmse=92.6769)

🎯 Round 6 Training Summary:
   Epochs trained: 1/1
   Total early stops so far: 0
   Training   - Loss: 8473.7148, RMSE: 92.0528, R²: -0.4403
   Validation - Loss: 8589.0039, RMSE: 92.6769, R²: -0.4241
💾 Training metrics saved to: logs/client_6_training_metrics_20251030_111455.csv

🧪 Round 6 Evaluation Results:
   Test Loss: 19661.7873
   RMSE: 140.2205, MAE: 117.7073, R²: -2.3825
💾 Test metrics saved to: logs/client_6_test_metrics_20251030_111455.csv
⏩ Skipping CV for Round 7

🔄 Starting local training (Round 7)...
   Epoch 1/1: train_loss=19102.5069, val_rmse=137.4375 ⭐ (improved by inf)
   ✅ Completed 1 epochs, using best model (val_rmse=137.4375)
Round 7: epochs=1, train_loss=18814.0371, val_rmse=137.4375, val_r2=-2.1319

🧪 Round 7 Evaluation Results:
   Test Loss: 20043.4383
   RMSE: 141.5748, MAE: 119.2919, R²: -2.4481
💾 Test metrics saved to: logs/client_6_test_metrics_20251030_111455.csv
⏩ Skipping CV for Round 8

🔄 Starting local training (Round 8)...
   Epoch 1/1: train_loss=19727.0954, val_rmse=140.6173 ⭐ (improved by inf)
   ✅ Completed 1 epochs, using best model (val_rmse=140.6173)
Round 8: epochs=1, train_loss=19700.6445, val_rmse=140.6173, val_r2=-2.2785
💾 Training metrics saved to: logs/client_6_training_metrics_20251030_111455.csv

🧪 Round 8 Evaluation Results:
   Test Loss: 20009.3863
   RMSE: 141.4545, MAE: 119.1496, R²: -2.4423
💾 Test metrics saved to: logs/client_6_test_metrics_20251030_111455.csv

🔍 Running 3-fold cross-validation (Round 9)
💾 CV metrics saved to: logs/client_6_cv_metrics_20251030_111455.csv

🔄 Starting local training (Round 9)...
   Epoch 1/1: train_loss=19693.6436, val_rmse=140.4997 ⭐ (improved by inf)
   ✅ Completed 1 epochs, using best model (val_rmse=140.4997)

🎯 Round 9 Training Summary:
   Epochs trained: 1/1
   Total early stops so far: 0
   Training   - Loss: 19667.4805, RMSE: 140.2408, R²: -2.3429
   Validation - Loss: 19740.1562, RMSE: 140.4997, R²: -2.2731
💾 Training metrics saved to: logs/client_6_training_metrics_20251030_111455.csv

🧪 Round 9 Evaluation Results:
   Test Loss: 19949.9252
   RMSE: 141.2442, MAE: 118.9035, R²: -2.4320
💾 Test metrics saved to: logs/client_6_test_metrics_20251030_111455.csv

🔍 Running 3-fold cross-validation (Round 10)
💾 CV metrics saved to: logs/client_6_cv_metrics_20251030_111455.csv

🔄 Starting local training (Round 10)...
   Epoch 1/1: train_loss=19635.1223, val_rmse=140.2929 ⭐ (improved by inf)
   ✅ Completed 1 epochs, using best model (val_rmse=140.2929)

🎯 Round 10 Training Summary:
   Epochs trained: 1/1
   Total early stops so far: 0
   Training   - Loss: 19609.2578, RMSE: 140.0331, R²: -2.3330
   Validation - Loss: 19682.0938, RMSE: 140.2929, R²: -2.2634
💾 Training metrics saved to: logs/client_6_training_metrics_20251030_111455.csv

🧪 Round 10 Evaluation Results:
   Test Loss: 19867.8128
   RMSE: 140.9532, MAE: 118.5627, R²: -2.4179
💾 Test metrics saved to: logs/client_6_test_metrics_20251030_111455.csv

================================================================================
🎯 FINAL COMPREHENSIVE REPORT
================================================================================
💾 Final summary saved to: logs/client_6_final_summary_20251030_111455.csv

📊 CLIENT: client_6 | ALGORITHM: fedavgm | MODEL: LSTM
📈 TOTAL ROUNDS: 10

⚙️  HYPERPARAMETERS:
   Learning Rate: 0.001
   Batch Size: 32
   Local Epochs: 1
   Hidden Dim: 64
   Num Layers: 2
   Sequence Length: 10
   Use Attention: False
   Dropout: 0.3
   Optimizer: adam

🛑 EARLY STOPPING SUMMARY:
   Enabled: Yes
   Patience: 3 epochs
   Min delta: 0.001
   Total early stops: 0/10 rounds
   Early stop rate: 0.0%

🏁 FINAL ROUND PERFORMANCE:
   Training   - Loss: 19609.26 | RMSE: 140.03 | R²: -2.3330
   Validation - Loss: 19682.09 | RMSE: 140.29 | R²: -2.2634
   Test       - Loss: 19867.81 | RMSE: 140.95 | R²: -2.4179

📊 STATISTICS ACROSS ALL ROUNDS (Mean ± Std):
   Training Loss:   12503.11 ± 6253.01
   Validation Loss: 12619.41 ± 6215.01
   Test Loss:       59058.36 ± 87762.98

   Training RMSE:   108.22 ± 28.14
   Validation RMSE: 108.84 ± 27.82
   Test RMSE:       200.27 ± 137.65

   Training R²:     -1.1252 ± 1.0628
   Validation R²:   -1.0924 ± 1.0305
   Test R²:         -9.1599 ± 15.0980

⭐ BEST PERFORMANCE:
   Best Round: 1 (Test R²: -0.3283)

📋 DATA SUMMARY:
   Training samples:   4547
   Validation samples: 1509
   Test samples:       1509
   Total samples:      7565
================================================================================
✅ Client client_6 completed | Algorithm: FEDAVGM
