[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aa4d7235-2f32-4a3a-b089-2ce5d373fe70
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a944c11c-c8f1-4128-bf5d-3eb556a7d68c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6815da3e-b7d7-413b-8cb4-b5360f093637
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fc377493-2e32-4bee-8e69-ee1fe1df68a9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e7416175-8ded-4aba-a85a-b87a91d049c7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7385ec7a-1f69-475c-9887-a693e1537715
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6cf9601f-2b7c-47aa-b738-3af687ad68e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 83576524-68ea-49d2-9685-c5fdf2f68cb6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6d84617d-4d4c-4d11-9a02-b7da240e851a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0be60aee-888c-4471-b48e-ca4fc6c39a68
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8dae7dd0-6c83-4ad9-becc-d5f3be971adf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 57cedd69-cfdc-4d66-8d00-f7f66f1f85da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b9dd9695-3376-4745-b534-53c01ee8f8e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4cbbe400-44ef-4289-8a22-b65687a39301
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e52c28ec-1cfd-437b-b05e-e17b5415c190
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8f9106e6-766d-4d00-a898-2b59387af1df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 72217974-8233-493f-aa44-9254f7a42ec8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 59b3428c-123f-4653-b96d-37f54b5d344f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4948f39d-5874-4f3d-b58d-e654ff4c876b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a9bdbc8b-5e49-407c-886f-9c4200e2903b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 38a803b5-50a0-4cbf-90cd-63676acb4241
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3d8b9723-cd21-435d-8977-c67907cbfc3d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3ba4586d-5b8a-40a3-afcc-775fe2b99919
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message db60f17a-d25c-4b92-8e5a-88a4b8683465
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2c794c8b-7379-448b-93d3-9ba466d96a21
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 24cd49bb-00b2-45e5-a1c7-d087b1c50cb6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 529cf693-51b3-4325-9b96-7d126e8262bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8e86fc1f-52fe-4734-bd36-2118f9696da4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d3272c4a-dfac-4025-9354-148edebcdf7d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 74db891b-509f-4392-bc87-43021a017977
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6a92a266-e927-4495-adfe-2008aa0b2003
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5829b39a-f213-4332-bf5e-fb7dff3ed506
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0a162557-3046-4b95-844d-aae199c023f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0542d253-3fd1-4210-b927-af8cf3172562
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cec05d81-a2b3-4235-bfee-3ea611642c04
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 15b2a4fe-155c-46aa-be46-e6381aa7fb74
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b054d02f-3a16-4415-8f4c-05ca8f632490
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7240c089-7960-4c39-b8a7-8cc188646d2a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9a344690-6871-4e67-b613-67b77496cdf5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 17fe8587-5f9b-453b-aaf3-95e6fba53385
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 10e8f13d-ecf2-456d-be5b-79a4a5349d19
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4add89e4-9785-4d26-90b7-aaf9aca771f7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a3b4d128-a6d1-44b8-a065-a36fa4ae2611
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 155c1127-1fd3-46dd-9aee-9995c26aa8d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7ce4c84a-9a9c-4266-b197-de4993646817
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cfab62be-0c8b-4e99-b260-3df0d6ef82a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5910a773-fa46-46eb-932a-5e87eb7c1fc1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e0edbed9-1cff-4d06-82e1-aac20770b4c6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8a99fe1c-6f26-44ca-aae5-07c4551a7917
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7d4313ae-3ba3-48d9-bc80-d46b83934440
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fe0f0c5f-4853-44d3-9ffe-23bc8a13fc96
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 62405463-6dc1-40a6-b24c-d6d6450efc4c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 275b1666-7b0f-4e30-9459-ba8da24188d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c010b5ce-32c4-4ef3-9932-55e2d9eecf75
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8a21389b-e296-4778-93a5-edbfe07b8c3d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 08709fd3-48e1-4957-bb8d-d3347a033997
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 22f57422-b973-4551-8b66-441ab40bb045
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fd824f64-4ab9-406a-bd9f-811602f8c1ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ecd54c9d-e52c-4a86-a65e-e73790c3a5d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d6102f2a-5119-485d-b817-775166349ce5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4fcf57a6-3ec4-4598-ba33-257c87693329
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b26002eb-6e58-45ed-b7c1-0d217145000e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dd043c20-3ae6-4699-9b61-13519a14590c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 05dbf87b-4318-44d0-b60e-f26a6f4b99ce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fa4f4dc0-704e-422e-a5d0-5ee3efc2897e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 72d21474-feb6-4de1-9d0c-5028135c6bc8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5d73cdcd-1d8a-48a6-a4ca-856c13d477c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d95f3538-27de-434f-abe5-26c7825d8360
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0feb5ea3-7263-4233-ae04-55c402341eb7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 09ca34ae-084a-43f2-9997-25a090932ead
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 52d1478f-9104-49e3-9dce-3de5372ae4c4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ccb640d0-839f-45ee-af61-c9a02215d579
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d43119b6-55db-4467-8c09-524addddbe7f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f0df18fe-1c5a-4d66-8a56-6e8f297b85f8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 231ee6c5-1ff1-4686-a5fb-e81d602768eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 91a7cdb6-6ea6-4a17-b7f7-39bc95c304b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dbf8bc19-5096-47d4-804f-3934a8fefeef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 53953d3d-7d52-4d09-9136-d241d7ae2828
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d41f1a80-87f8-45af-9d8d-14c3126d50d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3be6d55b-90c6-4937-b7a1-bec9c1f9a11e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8fc38d43-847f-42ef-a5b1-02bd3aad2414
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 29a4e42f-3d0d-4fbc-b35c-23d39a45ef7a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 33bf357c-bbe6-4084-b7fe-33302a40b825
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 66a4c9dc-fc88-4f82-ba23-5dac628efe4d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a705f51c-8031-4f10-a9c6-3cb06468f21b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f86f70a1-4009-43a3-9a80-0b1938b281d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7ebfe5b3-c353-4a61-b8b3-e513989b6611
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a8cc69a1-3898-40da-a03b-c5701200ad86
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2a8b4055-110d-41af-b989-b26393a1fe3e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 68757c17-5ffb-4ee8-a8fd-bed498cdf70d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9d4cac3b-f266-4684-9a39-6ebc4509c067
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c08a03ed-2f11-471a-a588-92ae28451a1c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a240c2c8-9a79-4b36-b5f0-7535d08e71e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7bb0d621-2e7d-4b4c-a00c-fd1d721d8be1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6a87877d-8c6a-4f1c-bce2-fec6ee4bf682
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 42fab016-10c1-4584-86e1-0d7987e4de00
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 30250cdc-070c-450f-9cbd-4007dbe6e698
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e06e5ab3-1d7a-4822-b1d6-9a93258710b8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9c050d55-d597-4de7-aff3-0c2c3f000460
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 40269a9d-05e9-45f3-92ea-9798e930223a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6fcd4178-ae14-4c37-885b-133086a4662a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d868156a-646f-446f-ae3a-d9cb6b54e730
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 88e1ab67-26fe-4638-8852-4109315fe124
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 20d0845f-4068-44ce-8e30-db5dc002273b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0dfe66c5-d004-43d0-91c2-571c3cea977f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 045cd686-9d55-42ee-959e-fdadabf3a2e2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ae1687ea-923a-4960-8b46-6adbd9f08e45
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3f82ef42-d1e0-4f95-95be-c9b4853543ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6fda85ee-9a21-4e0d-b634-f71739dbfa83
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 01744dd7-fcb6-44ca-86f6-83e2124db70e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d1dc0f34-7988-4d56-965f-ec83cbf93b3f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2af6b03b-f5fc-4134-bb96-57cd4e40a062
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 10740ab0-f7c3-49d8-a53f-eaf811ac3569
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f3561275-26da-4ed3-85c2-b55e1f30a071
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cb95d73e-d5b1-488b-ae23-07348ebebea9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 16b65307-a03d-4dab-be65-d68b57a0d42f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9f738d20-c310-47be-86e2-ee7467378e25
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1cd34e87-109f-46a9-8404-b2559a142846
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5ea9c099-3bf5-4a0d-b235-36d9e78a1ce3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cf7a340b-23b6-4817-81b3-548d909ee09a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ef919d69-5804-4868-902b-4c1e05209ea2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e8577762-fb19-4f61-9d25-bc7baa69233b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0457b632-d5d5-4c3b-a0c8-ad4c7b905880
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fc3f863f-6e9d-49fc-8561-83fa65819fee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1bce849f-679a-4fa9-834f-967634cf7eeb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 78ac116f-c116-4e58-ba96-44b1fba8fedd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5b21bb7f-d1d1-4e7b-a917-b0250d1e08f6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 019fbbe2-478f-47e9-a5e3-c8dc2cc8c213
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5baa9693-ed52-4da3-900e-02eb2567747c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b3d9a55e-61c6-4f8a-af4d-f3abb70dbaa7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ce7bfec4-2fa9-4559-966e-3983c77e9dac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d61303b6-5e65-4541-95ee-4324dd8a5c43
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d1c67284-0423-4793-8648-f1732fd61437
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 65255328-8208-4635-a97d-b880c1cb0276
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b54acf4a-90e5-4da9-9981-9c4d3d76e1a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 758894bc-7317-42bc-a83f-7b721b2cbfd6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3c0e34af-3c9c-4944-9d97-97148d84e1b8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 88bfe460-cac6-4f88-b28f-94f53674c318
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 17a247e5-054f-4b43-9167-68f62e02c72f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2c72f0b6-c345-48ab-9d97-6877ac7d9807
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 093a5d62-a462-489e-92fd-7e4610ba75bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f97383dd-0cc7-4609-a8a5-6101f5b02c6f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5d977b85-29ad-4ced-9a37-6739efd5a59a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e3895639-7b3a-4432-9606-9e805a783843
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8c48432d-b709-48b8-944c-1432df097889
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0f84725a-c816-4582-aa3b-4df3ae843f3a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 57f4af0b-52b6-463a-8275-70a5f48c4a4f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b1cf913f-5ac9-482d-a9c9-9cd662e3a0b0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 39c404b9-7d3a-4e57-bf21-322457dff44b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message af8eac8f-e179-46dd-acc9-8e29980bdaa3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 100abdd4-2376-4c21-9ebb-d01b446d88a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8d14c44d-0815-4b66-93c6-7e29eb03ef90
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 181eafd4-778d-4428-a368-ac9ce1fe4690
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7e896b84-b2af-4c1a-8f49-8014d5dca978
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 65289103-c7b8-423c-8c0c-2ced081d8303
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 35966ccd-161a-4b7f-a4b7-595491cfb026
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7501cb4e-8373-4296-bebe-38f6f28c10f8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8455a7b0-8fa4-427e-bfdf-7f326c058a40
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 41cc1174-31cf-4596-82e8-73eedcf20d33
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message feabd5ad-f2f4-4e0f-a8a8-f063dee4623b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d8b905dc-bcfb-42af-9dca-ea254cc81c24
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 258d53fa-bd02-4aea-854b-14a83b8eda53
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 75488eda-79f3-496d-b124-83c99ab547bd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 208f5218-7444-40e3-bc0c-87424aea8e37
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8f279177-8c8a-4814-9a33-7afa992e1748
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b4acc1f2-d5e1-4493-80e6-ef3429d8c376
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message da33099e-bca9-4d4c-88fa-2591241c3dbf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f2fe348b-c2bf-4146-b8e1-a993c22b04d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 69192c5d-2114-4a45-940e-52d63b4be47c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8958745b-b19f-40da-be19-d220532ab8ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 960c16ff-350a-4cde-9375-5157283f8e63
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message de3e1a35-c26c-4c51-b159-64e39181c07d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 29f9bf06-a09c-43f7-ada9-2fde7138d835
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c081d1b8-ba63-4044-a176-818fb2cc2939
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 045b42cf-0123-4197-811a-1e4e5cbe4ac0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0c6529c9-8441-406a-8215-9b4ce58ddaa8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e1b15b10-dc16-4415-bbab-28d1963f70bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2c3904cf-f3c8-4ef3-a5e7-8adf6092e0f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 31a44f70-18c3-49ce-b285-607b18be7494
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7f050cf4-40e8-4a1e-b71a-692224243c2d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cb79ded2-b27f-44f0-a718-3dc06152c545
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eede0db4-caa0-4302-98ff-64bc8e16a5fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 662b274c-2962-440e-bb36-2773b3883127
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5a61a24c-3213-4814-8f0e-967be9d53ee3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 641d8061-8fea-42a7-86f0-14f2ee7d8365
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 36efc64a-e926-4279-86be-2e3d7215ffff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5b1c3746-9e7b-4485-9b75-fc8d8e6ea2ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 084f89c8-aa7b-40a1-a552-21680d7cbbef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message be2e16f1-ba78-4629-b777-181d9b6fd3b3
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8687 {grpc_message:"Socket closed", grpc_status:14}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_10
Server: localhost:8687
Algorithm: FEDAVG
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_10
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_10/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_10/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_10/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_10/test_labels.txt

📊 Raw data loaded:
   Train: X=(424, 24), y=(424,)
   Test:  X=(106, 24), y=(106,)

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 415 samples, 5 features
   Test:  97 samples, 5 features
✅ Client client_10 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

============================================================
🔄 Round 1 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.3191, val=0.1983 (↓), lr=0.001000
   ✓ Epoch   2/100: train=0.1255, val=0.1076 (↓), lr=0.001000
   ✓ Epoch   3/100: train=0.0923, val=0.0837 (↓), lr=0.001000
   ✓ Epoch   4/100: train=0.0837, val=0.0769 (↓), lr=0.001000
   ✓ Epoch   5/100: train=0.0811, val=0.0758 (↓), lr=0.001000
   • Epoch  11/100: train=0.0766, val=0.0772, patience=6/15, lr=0.001000
   📉 Epoch 12: LR reduced 0.001000 → 0.000500
   📉 Epoch 20: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0758)

============================================================
📊 Round 1 Summary - Client client_10
   Epochs: 20/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0791, RMSE=0.2812, R²=0.0313
   Val:   Loss=0.0758, RMSE=0.2753, R²=-0.0141
============================================================


============================================================
🔄 Round 2 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0756 (↓), lr=0.000250
   • Epoch   2/100: train=0.0808, val=0.0801, patience=1/15, lr=0.000250
   • Epoch   3/100: train=0.0808, val=0.0808, patience=2/15, lr=0.000250
   • Epoch   4/100: train=0.0803, val=0.0804, patience=3/15, lr=0.000250
   • Epoch   5/100: train=0.0796, val=0.0813, patience=4/15, lr=0.000250
   📉 Epoch 8: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0778, val=0.0831, patience=10/15, lr=0.000125
   📉 Epoch 16: LR reduced 0.000125 → 0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0756)

============================================================
📊 Round 2 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000250 → 0.000063 (2 reductions)
   Train: Loss=0.0807, RMSE=0.2840, R²=0.0121
   Val:   Loss=0.0756, RMSE=0.2750, R²=-0.0968
============================================================


📊 Round 2 Test Metrics:
   Loss: 0.0886, RMSE: 0.2977, MAE: 0.2561, R²: -0.0020

============================================================
🔄 Round 4 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0731, val=0.1097 (↓), lr=0.000063
   • Epoch   2/100: train=0.0730, val=0.1098, patience=1/15, lr=0.000063
   • Epoch   3/100: train=0.0728, val=0.1096, patience=2/15, lr=0.000063
   • Epoch   4/100: train=0.0726, val=0.1095, patience=3/15, lr=0.000063
   • Epoch   5/100: train=0.0725, val=0.1095, patience=4/15, lr=0.000063
   📉 Epoch 8: LR reduced 0.000063 → 0.000031
   • Epoch  11/100: train=0.0719, val=0.1097, patience=10/15, lr=0.000031
   📉 Epoch 16: LR reduced 0.000031 → 0.000016

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.1097)

============================================================
📊 Round 4 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000063 → 0.000016 (2 reductions)
   Train: Loss=0.0725, RMSE=0.2693, R²=0.0188
   Val:   Loss=0.1097, RMSE=0.3313, R²=-0.0827
============================================================


============================================================
🔄 Round 5 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000016
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0761 (↓), lr=0.000016
   • Epoch   2/100: train=0.0796, val=0.0760, patience=1/15, lr=0.000016
   • Epoch   3/100: train=0.0793, val=0.0759, patience=2/15, lr=0.000016
   • Epoch   4/100: train=0.0792, val=0.0759, patience=3/15, lr=0.000016
   • Epoch   5/100: train=0.0790, val=0.0759, patience=4/15, lr=0.000016
   📉 Epoch 8: LR reduced 0.000016 → 0.000008
   • Epoch  11/100: train=0.0787, val=0.0760, patience=10/15, lr=0.000008
   📉 Epoch 16: LR reduced 0.000008 → 0.000004

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0761)

============================================================
📊 Round 5 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000016 → 0.000004 (2 reductions)
   Train: Loss=0.0811, RMSE=0.2847, R²=0.0051
   Val:   Loss=0.0761, RMSE=0.2758, R²=-0.0126
============================================================


📊 Round 5 Test Metrics:
   Loss: 0.0906, RMSE: 0.3009, MAE: 0.2578, R²: -0.0243

📊 Round 5 Test Metrics:
   Loss: 0.0904, RMSE: 0.3006, MAE: 0.2576, R²: -0.0218

============================================================
🔄 Round 11 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000004
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0820 (↓), lr=0.000004
   • Epoch   2/100: train=0.0798, val=0.0820, patience=1/15, lr=0.000004
   • Epoch   3/100: train=0.0798, val=0.0820, patience=2/15, lr=0.000004
   • Epoch   4/100: train=0.0797, val=0.0820, patience=3/15, lr=0.000004
   • Epoch   5/100: train=0.0796, val=0.0820, patience=4/15, lr=0.000004
   📉 Epoch 8: LR reduced 0.000004 → 0.000002
   • Epoch  11/100: train=0.0794, val=0.0819, patience=10/15, lr=0.000002
   📉 Epoch 16: LR reduced 0.000002 → 0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 11 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000004 → 0.000001 (2 reductions)
   Train: Loss=0.0803, RMSE=0.2833, R²=-0.0015
   Val:   Loss=0.0820, RMSE=0.2864, R²=-0.0176
============================================================


📊 Round 11 Test Metrics:
   Loss: 0.0906, RMSE: 0.3009, MAE: 0.2584, R²: -0.0241

📊 Round 11 Test Metrics:
   Loss: 0.0905, RMSE: 0.3009, MAE: 0.2584, R²: -0.0240

============================================================
🔄 Round 13 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 13 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2836, R²=0.0009
   Val:   Loss=0.0812, RMSE=0.2849, R²=-0.0290
============================================================


📊 Round 13 Test Metrics:
   Loss: 0.0905, RMSE: 0.3009, MAE: 0.2584, R²: -0.0237

📊 Round 13 Test Metrics:
   Loss: 0.0912, RMSE: 0.3020, MAE: 0.2593, R²: -0.0314

============================================================
🔄 Round 16 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0732 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0732, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0732, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0731, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0731, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0731, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0732)

============================================================
📊 Round 16 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=-0.0077
   Val:   Loss=0.0732, RMSE=0.2705, R²=-0.0236
============================================================


📊 Round 16 Test Metrics:
   Loss: 0.0913, RMSE: 0.3022, MAE: 0.2594, R²: -0.0326

============================================================
🔄 Round 17 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 17 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2852, R²=-0.0068
   Val:   Loss=0.0787, RMSE=0.2806, R²=-0.0097
============================================================


📊 Round 17 Test Metrics:
   Loss: 0.0913, RMSE: 0.3021, MAE: 0.2594, R²: -0.0324

📊 Round 17 Test Metrics:
   Loss: 0.0916, RMSE: 0.3026, MAE: 0.2598, R²: -0.0356

============================================================
🔄 Round 21 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 21 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=-0.0051
   Val:   Loss=0.0793, RMSE=0.2816, R²=-0.0276
============================================================


============================================================
🔄 Round 23 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 23 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=-0.0088
   Val:   Loss=0.0831, RMSE=0.2882, R²=-0.0039
============================================================


📊 Round 23 Test Metrics:
   Loss: 0.0920, RMSE: 0.3033, MAE: 0.2602, R²: -0.0401

============================================================
🔄 Round 26 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 26 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2826, R²=0.0001
   Val:   Loss=0.0845, RMSE=0.2906, R²=-0.0323
============================================================


📊 Round 26 Test Metrics:
   Loss: 0.0920, RMSE: 0.3033, MAE: 0.2602, R²: -0.0401

============================================================
🔄 Round 27 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 27 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=-0.0195
   Val:   Loss=0.0831, RMSE=0.2882, R²=0.0414
============================================================


📊 Round 27 Test Metrics:
   Loss: 0.0920, RMSE: 0.3033, MAE: 0.2602, R²: -0.0402

📊 Round 27 Test Metrics:
   Loss: 0.0920, RMSE: 0.3033, MAE: 0.2602, R²: -0.0402

📊 Round 27 Test Metrics:
   Loss: 0.0920, RMSE: 0.3033, MAE: 0.2602, R²: -0.0402

============================================================
🔄 Round 33 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 33 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2826, R²=-0.0034
   Val:   Loss=0.0844, RMSE=0.2904, R²=-0.0298
============================================================


📊 Round 33 Test Metrics:
   Loss: 0.0920, RMSE: 0.3033, MAE: 0.2602, R²: -0.0401

============================================================
🔄 Round 34 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0754 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0754, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0755, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0755, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0755, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0755, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0754)

============================================================
📊 Round 34 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=-0.0221
   Val:   Loss=0.0754, RMSE=0.2747, R²=0.0327
============================================================


============================================================
🔄 Round 39 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0767, val=0.0953 (↓), lr=0.000001
   • Epoch   2/100: train=0.0767, val=0.0953, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0767, val=0.0953, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0767, val=0.0953, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0766, val=0.0953, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0766, val=0.0953, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0953)

============================================================
📊 Round 39 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0771, RMSE=0.2777, R²=0.0085
   Val:   Loss=0.0953, RMSE=0.3088, R²=-0.0698
============================================================


📊 Round 39 Test Metrics:
   Loss: 0.0920, RMSE: 0.3033, MAE: 0.2602, R²: -0.0401

📊 Round 39 Test Metrics:
   Loss: 0.0920, RMSE: 0.3033, MAE: 0.2602, R²: -0.0401

============================================================
🔄 Round 41 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0705 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0705, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0705, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0705, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0705, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0705, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0705)

============================================================
📊 Round 41 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2887, R²=-0.0085
   Val:   Loss=0.0705, RMSE=0.2656, R²=0.0023
============================================================


============================================================
🔄 Round 42 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0777 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0777, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0777, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0777, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0777, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0777, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 42 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=-0.0130
   Val:   Loss=0.0777, RMSE=0.2787, R²=0.0201
============================================================


============================================================
🔄 Round 43 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0752 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0752, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0752, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0752, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0752, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0753, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0752)

============================================================
📊 Round 43 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2866, R²=-0.0098
   Val:   Loss=0.0752, RMSE=0.2742, R²=-0.0281
============================================================


📊 Round 43 Test Metrics:
   Loss: 0.0920, RMSE: 0.3033, MAE: 0.2602, R²: -0.0402

📊 Round 43 Test Metrics:
   Loss: 0.0920, RMSE: 0.3033, MAE: 0.2602, R²: -0.0403

============================================================
🔄 Round 48 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 48 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=-0.0046
   Val:   Loss=0.0808, RMSE=0.2842, R²=-0.0213
============================================================


📊 Round 48 Test Metrics:
   Loss: 0.0920, RMSE: 0.3033, MAE: 0.2602, R²: -0.0402

============================================================
🔄 Round 53 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 53 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=-0.0086
   Val:   Loss=0.0790, RMSE=0.2810, R²=0.0019
============================================================


📊 Round 53 Test Metrics:
   Loss: 0.0920, RMSE: 0.3033, MAE: 0.2602, R²: -0.0403

============================================================
🔄 Round 58 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0712 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0712, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0712, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0712, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0712, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0712, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0712)

============================================================
📊 Round 58 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=-0.0114
   Val:   Loss=0.0712, RMSE=0.2668, R²=0.0123
============================================================


📊 Round 58 Test Metrics:
   Loss: 0.0920, RMSE: 0.3033, MAE: 0.2602, R²: -0.0405

📊 Round 58 Test Metrics:
   Loss: 0.0920, RMSE: 0.3033, MAE: 0.2602, R²: -0.0405

📊 Round 58 Test Metrics:
   Loss: 0.0920, RMSE: 0.3033, MAE: 0.2602, R²: -0.0404

📊 Round 58 Test Metrics:
   Loss: 0.0920, RMSE: 0.3033, MAE: 0.2602, R²: -0.0403

============================================================
🔄 Round 66 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0751 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0751, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0751, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0751, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0750, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0750, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0751)

============================================================
📊 Round 66 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=-0.0036
   Val:   Loss=0.0751, RMSE=0.2740, R²=-0.0498
============================================================


📊 Round 66 Test Metrics:
   Loss: 0.0920, RMSE: 0.3033, MAE: 0.2602, R²: -0.0403

============================================================
🔄 Round 67 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0780, val=0.0884 (↓), lr=0.000001
   • Epoch   2/100: train=0.0780, val=0.0884, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0780, val=0.0884, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0780, val=0.0884, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0780, val=0.0884, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0780, val=0.0884, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0884)

============================================================
📊 Round 67 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2808, R²=0.0034
   Val:   Loss=0.0884, RMSE=0.2974, R²=-0.0516
============================================================


📊 Round 67 Test Metrics:
   Loss: 0.0920, RMSE: 0.3033, MAE: 0.2602, R²: -0.0402

============================================================
🔄 Round 68 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 68 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2854, R²=-0.0130
   Val:   Loss=0.0781, RMSE=0.2794, R²=0.0104
============================================================


📊 Round 68 Test Metrics:
   Loss: 0.0920, RMSE: 0.3033, MAE: 0.2602, R²: -0.0402

============================================================
🔄 Round 69 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0777 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0777, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0776, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0776, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0776, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 69 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=-0.0117
   Val:   Loss=0.0777, RMSE=0.2787, R²=-0.0018
============================================================


📊 Round 69 Test Metrics:
   Loss: 0.0920, RMSE: 0.3033, MAE: 0.2602, R²: -0.0402

📊 Round 69 Test Metrics:
   Loss: 0.0920, RMSE: 0.3033, MAE: 0.2602, R²: -0.0402

============================================================
🔄 Round 71 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 71 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2829, R²=-0.0105
   Val:   Loss=0.0838, RMSE=0.2894, R²=-0.0030
============================================================


📊 Round 71 Test Metrics:
   Loss: 0.0920, RMSE: 0.3033, MAE: 0.2602, R²: -0.0402

============================================================
🔄 Round 72 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 72 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=-0.0126
   Val:   Loss=0.0842, RMSE=0.2902, R²=0.0080
============================================================


📊 Round 72 Test Metrics:
   Loss: 0.0920, RMSE: 0.3033, MAE: 0.2602, R²: -0.0402

============================================================
🔄 Round 73 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0776, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0776, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0776, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0776, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0776, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0775, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 73 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2819, R²=-0.0064
   Val:   Loss=0.0861, RMSE=0.2934, R²=-0.0160
============================================================


============================================================
🔄 Round 74 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0774, val=0.0892 (↓), lr=0.000001
   • Epoch   2/100: train=0.0774, val=0.0892, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0774, val=0.0892, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0774, val=0.0892, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0774, val=0.0892, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0774, val=0.0891, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0892)

============================================================
📊 Round 74 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2805, R²=-0.0008
   Val:   Loss=0.0892, RMSE=0.2986, R²=-0.0606
============================================================


📊 Round 74 Test Metrics:
   Loss: 0.0920, RMSE: 0.3033, MAE: 0.2602, R²: -0.0403

============================================================
🔄 Round 75 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0767 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0767, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0767, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0767, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0766, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0766, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0767)

============================================================
📊 Round 75 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=-0.0030
   Val:   Loss=0.0767, RMSE=0.2769, R²=-0.0226
============================================================


============================================================
🔄 Round 76 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0760, val=0.0965 (↓), lr=0.000001
   • Epoch   2/100: train=0.0760, val=0.0965, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0760, val=0.0965, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0760, val=0.0964, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0759, val=0.0964, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0759, val=0.0964, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0965)

============================================================
📊 Round 76 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0769, RMSE=0.2772, R²=-0.0150
   Val:   Loss=0.0965, RMSE=0.3106, R²=0.0191
============================================================


📊 Round 76 Test Metrics:
   Loss: 0.0920, RMSE: 0.3033, MAE: 0.2602, R²: -0.0402

📊 Round 76 Test Metrics:
   Loss: 0.0920, RMSE: 0.3033, MAE: 0.2602, R²: -0.0402

============================================================
🔄 Round 78 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0777 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0777, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0777, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0777, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0777, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0777, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 78 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=-0.0060
   Val:   Loss=0.0777, RMSE=0.2788, R²=-0.0096
============================================================


📊 Round 78 Test Metrics:
   Loss: 0.0920, RMSE: 0.3033, MAE: 0.2602, R²: -0.0402

📊 Round 78 Test Metrics:
   Loss: 0.0920, RMSE: 0.3033, MAE: 0.2602, R²: -0.0401

============================================================
🔄 Round 82 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0732 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0732, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0732, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0732, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0732, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0734, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0732)

============================================================
📊 Round 82 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=-0.0133
   Val:   Loss=0.0732, RMSE=0.2705, R²=-0.0353
============================================================


============================================================
🔄 Round 83 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 83 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=0.0033
   Val:   Loss=0.0805, RMSE=0.2837, R²=-0.0745
============================================================


📊 Round 83 Test Metrics:
   Loss: 0.0920, RMSE: 0.3033, MAE: 0.2602, R²: -0.0402

============================================================
🔄 Round 84 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0757 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0757, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0757, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0757, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0757, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0757, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0757)

============================================================
📊 Round 84 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=0.0027
   Val:   Loss=0.0757, RMSE=0.2752, R²=-0.0503
============================================================


📊 Round 84 Test Metrics:
   Loss: 0.0920, RMSE: 0.3033, MAE: 0.2602, R²: -0.0401

============================================================
🔄 Round 85 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 85 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2819, R²=-0.0009
   Val:   Loss=0.0861, RMSE=0.2934, R²=-0.0494
============================================================


📊 Round 85 Test Metrics:
   Loss: 0.0920, RMSE: 0.3033, MAE: 0.2602, R²: -0.0401

============================================================
🔄 Round 89 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0907 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0907, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0907, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0906, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0906, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0906, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0907)

============================================================
📊 Round 89 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0783, RMSE=0.2799, R²=-0.0027
   Val:   Loss=0.0907, RMSE=0.3011, R²=-0.0624
============================================================


============================================================
🔄 Round 91 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0765 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0765, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0765, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0765, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0765, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0766, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0765)

============================================================
📊 Round 91 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2861, R²=-0.0184
   Val:   Loss=0.0765, RMSE=0.2765, R²=0.0290
============================================================


📊 Round 91 Test Metrics:
   Loss: 0.0920, RMSE: 0.3033, MAE: 0.2602, R²: -0.0401

============================================================
🔄 Round 95 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0743 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0743, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0743, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0743, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0743, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0743, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0743)

============================================================
📊 Round 95 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=-0.0064
   Val:   Loss=0.0743, RMSE=0.2726, R²=-0.0193
============================================================


============================================================
🔄 Round 96 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0694 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0694, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0694, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0694, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0694, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0694, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0694)

============================================================
📊 Round 96 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2892, R²=-0.0043
   Val:   Loss=0.0694, RMSE=0.2635, R²=-0.0195
============================================================


📊 Round 96 Test Metrics:
   Loss: 0.0920, RMSE: 0.3032, MAE: 0.2602, R²: -0.0399

============================================================
🔄 Round 99 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0773, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0773, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0773, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0773, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0773, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0772, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 99 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2822, R²=-0.0128
   Val:   Loss=0.0856, RMSE=0.2925, R²=0.0111
============================================================


📊 Round 99 Test Metrics:
   Loss: 0.0919, RMSE: 0.3032, MAE: 0.2602, R²: -0.0399

============================================================
🔄 Round 104 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 104 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2852, R²=-0.0087
   Val:   Loss=0.0786, RMSE=0.2803, R²=-0.0212
============================================================


📊 Round 104 Test Metrics:
   Loss: 0.0919, RMSE: 0.3032, MAE: 0.2602, R²: -0.0399

============================================================
🔄 Round 105 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0776, val=0.0929 (↓), lr=0.000001
   • Epoch   2/100: train=0.0776, val=0.0929, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0776, val=0.0929, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0776, val=0.0929, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0776, val=0.0929, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0775, val=0.0929, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0929)

============================================================
📊 Round 105 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0778, RMSE=0.2789, R²=-0.0070
   Val:   Loss=0.0929, RMSE=0.3049, R²=-0.0144
============================================================


============================================================
🔄 Round 107 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 107 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=-0.0163
   Val:   Loss=0.0828, RMSE=0.2877, R²=0.0195
============================================================


📊 Round 107 Test Metrics:
   Loss: 0.0919, RMSE: 0.3032, MAE: 0.2602, R²: -0.0398

📊 Round 107 Test Metrics:
   Loss: 0.0919, RMSE: 0.3032, MAE: 0.2602, R²: -0.0398

📊 Round 107 Test Metrics:
   Loss: 0.0919, RMSE: 0.3032, MAE: 0.2602, R²: -0.0398

============================================================
🔄 Round 114 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0752 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0752, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0752, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0752, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0752, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0751, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0752)

============================================================
📊 Round 114 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2868, R²=-0.0000
   Val:   Loss=0.0752, RMSE=0.2742, R²=-0.1095
============================================================


📊 Round 114 Test Metrics:
   Loss: 0.0919, RMSE: 0.3032, MAE: 0.2602, R²: -0.0398

============================================================
🔄 Round 117 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0749 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0749, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0749, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0749, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0749, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0750, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0749)

============================================================
📊 Round 117 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=-0.0186
   Val:   Loss=0.0749, RMSE=0.2736, R²=0.0142
============================================================


📊 Round 117 Test Metrics:
   Loss: 0.0919, RMSE: 0.3032, MAE: 0.2602, R²: -0.0397

📊 Round 117 Test Metrics:
   Loss: 0.0919, RMSE: 0.3032, MAE: 0.2602, R²: -0.0397

============================================================
🔄 Round 119 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0713 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0713, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0713, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0713, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0713, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0712, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0713)

============================================================
📊 Round 119 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=-0.0123
   Val:   Loss=0.0713, RMSE=0.2670, R²=0.0152
============================================================


📊 Round 119 Test Metrics:
   Loss: 0.0919, RMSE: 0.3032, MAE: 0.2602, R²: -0.0397

============================================================
🔄 Round 123 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0720 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0720, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0720, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0720, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0720, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0719, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0720)

============================================================
📊 Round 123 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2882, R²=-0.0187
   Val:   Loss=0.0720, RMSE=0.2683, R²=0.0415
============================================================


============================================================
🔄 Round 124 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 124 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=-0.0099
   Val:   Loss=0.0845, RMSE=0.2907, R²=0.0013
============================================================


📊 Round 124 Test Metrics:
   Loss: 0.0919, RMSE: 0.3032, MAE: 0.2602, R²: -0.0396

============================================================
🔄 Round 128 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0720 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0720, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0720, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0720, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0720, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0719, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0720)

============================================================
📊 Round 128 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2882, R²=-0.0128
   Val:   Loss=0.0720, RMSE=0.2683, R²=0.0083
============================================================


📊 Round 128 Test Metrics:
   Loss: 0.0919, RMSE: 0.3032, MAE: 0.2602, R²: -0.0398

📊 Round 128 Test Metrics:
   Loss: 0.0919, RMSE: 0.3032, MAE: 0.2602, R²: -0.0399

============================================================
🔄 Round 131 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 131 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=-0.0052
   Val:   Loss=0.0775, RMSE=0.2784, R²=-0.0339
============================================================


📊 Round 131 Test Metrics:
   Loss: 0.0920, RMSE: 0.3032, MAE: 0.2602, R²: -0.0399

📊 Round 131 Test Metrics:
   Loss: 0.0919, RMSE: 0.3032, MAE: 0.2602, R²: -0.0399

============================================================
🔄 Round 135 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0750 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0750, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0751, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0751, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0751, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0752, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0750)

============================================================
📊 Round 135 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2868, R²=-0.0169
   Val:   Loss=0.0750, RMSE=0.2739, R²=-0.0044
============================================================


📊 Round 135 Test Metrics:
   Loss: 0.0920, RMSE: 0.3033, MAE: 0.2602, R²: -0.0401

📊 Round 135 Test Metrics:
   Loss: 0.0920, RMSE: 0.3033, MAE: 0.2602, R²: -0.0401

📊 Round 135 Test Metrics:
   Loss: 0.0920, RMSE: 0.3032, MAE: 0.2602, R²: -0.0400

📊 Round 135 Test Metrics:
   Loss: 0.0920, RMSE: 0.3032, MAE: 0.2602, R²: -0.0399

============================================================
🔄 Round 141 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0758 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0758, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0758, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0758, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0759, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0759, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0758)

============================================================
📊 Round 141 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=-0.0174
   Val:   Loss=0.0758, RMSE=0.2753, R²=0.0262
============================================================


============================================================
🔄 Round 142 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 142 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2840, R²=-0.0010
   Val:   Loss=0.0813, RMSE=0.2852, R²=-0.0888
============================================================


📊 Round 142 Test Metrics:
   Loss: 0.0919, RMSE: 0.3032, MAE: 0.2602, R²: -0.0399

============================================================
🔄 Round 143 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0775, val=0.0879 (↓), lr=0.000001
   • Epoch   2/100: train=0.0775, val=0.0879, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0774, val=0.0879, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0774, val=0.0879, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0774, val=0.0880, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0773, val=0.0882, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0879)

============================================================
📊 Round 143 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2812, R²=-0.0225
   Val:   Loss=0.0879, RMSE=0.2964, R²=-0.0508
============================================================


📊 Round 143 Test Metrics:
   Loss: 0.0919, RMSE: 0.3032, MAE: 0.2602, R²: -0.0398

============================================================
🔄 Round 144 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0699 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0699, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0699, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0698, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0698, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0698, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0699)

============================================================
📊 Round 144 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=-0.0062
   Val:   Loss=0.0699, RMSE=0.2643, R²=-0.0158
============================================================


📊 Round 144 Test Metrics:
   Loss: 0.0919, RMSE: 0.3032, MAE: 0.2602, R²: -0.0398

============================================================
🔄 Round 145 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 145 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=-0.0121
   Val:   Loss=0.0806, RMSE=0.2840, R²=0.0049
============================================================


============================================================
🔄 Round 146 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0754 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0754, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0754, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0754, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0754, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0753, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0754)

============================================================
📊 Round 146 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=-0.0053
   Val:   Loss=0.0754, RMSE=0.2745, R²=-0.0209
============================================================


📊 Round 146 Test Metrics:
   Loss: 0.0919, RMSE: 0.3032, MAE: 0.2602, R²: -0.0398

============================================================
🔄 Round 148 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0721 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0721, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0720, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0720, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0720, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0720, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0721)

============================================================
📊 Round 148 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=-0.0097
   Val:   Loss=0.0721, RMSE=0.2684, R²=0.0028
============================================================


📊 Round 148 Test Metrics:
   Loss: 0.0919, RMSE: 0.3032, MAE: 0.2602, R²: -0.0399

============================================================
🔄 Round 152 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0882 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0882, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0882, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0882, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0882, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0883, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0882)

============================================================
📊 Round 152 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2810, R²=-0.0229
   Val:   Loss=0.0882, RMSE=0.2969, R²=-0.0001
============================================================


📊 Round 152 Test Metrics:
   Loss: 0.0919, RMSE: 0.3032, MAE: 0.2602, R²: -0.0398

📊 Round 152 Test Metrics:
   Loss: 0.0919, RMSE: 0.3032, MAE: 0.2602, R²: -0.0398

📊 Round 152 Test Metrics:
   Loss: 0.0919, RMSE: 0.3032, MAE: 0.2602, R²: -0.0398

============================================================
🔄 Round 156 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0758 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0759, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0759, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0759, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0759, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0759, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0758)

============================================================
📊 Round 156 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=-0.0175
   Val:   Loss=0.0758, RMSE=0.2754, R²=0.0026
============================================================


📊 Round 156 Test Metrics:
   Loss: 0.0919, RMSE: 0.3032, MAE: 0.2602, R²: -0.0398

📊 Round 156 Test Metrics:
   Loss: 0.0919, RMSE: 0.3032, MAE: 0.2602, R²: -0.0399

📊 Round 156 Test Metrics:
   Loss: 0.0919, RMSE: 0.3032, MAE: 0.2602, R²: -0.0398

============================================================
🔄 Round 161 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0723 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0723, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0723, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0723, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0723, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0723, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0723)

============================================================
📊 Round 161 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2880, R²=-0.0114
   Val:   Loss=0.0723, RMSE=0.2688, R²=0.0096
============================================================


📊 Round 161 Test Metrics:
   Loss: 0.0919, RMSE: 0.3032, MAE: 0.2602, R²: -0.0398

============================================================
🔄 Round 164 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0777 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0777, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0777, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0777, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0777, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0777, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 164 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=-0.0043
   Val:   Loss=0.0777, RMSE=0.2788, R²=-0.0203
============================================================


📊 Round 164 Test Metrics:
   Loss: 0.0920, RMSE: 0.3032, MAE: 0.2602, R²: -0.0400

============================================================
🔄 Round 165 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0776, val=0.0936 (↓), lr=0.000001
   • Epoch   2/100: train=0.0776, val=0.0936, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0776, val=0.0935, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0776, val=0.0935, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0776, val=0.0935, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0775, val=0.0935, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0936)

============================================================
📊 Round 165 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0776, RMSE=0.2786, R²=-0.0036
   Val:   Loss=0.0936, RMSE=0.3059, R²=-0.0206
============================================================


============================================================
🔄 Round 166 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0694 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0694, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0694, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0694, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0694, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0693, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0694)

============================================================
📊 Round 166 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=-0.0105
   Val:   Loss=0.0694, RMSE=0.2634, R²=0.0096
============================================================


📊 Round 166 Test Metrics:
   Loss: 0.0920, RMSE: 0.3033, MAE: 0.2602, R²: -0.0400

📊 Round 166 Test Metrics:
   Loss: 0.0920, RMSE: 0.3032, MAE: 0.2602, R²: -0.0400

============================================================
🔄 Round 170 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0740 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0740, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0740, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0740, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0740, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0739, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0740)

============================================================
📊 Round 170 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2873, R²=-0.0079
   Val:   Loss=0.0740, RMSE=0.2720, R²=-0.0061
============================================================


📊 Round 170 Test Metrics:
   Loss: 0.0920, RMSE: 0.3032, MAE: 0.2602, R²: -0.0400

============================================================
🔄 Round 175 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0774 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0774, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0774, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0774, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0774, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0774, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0774)

============================================================
📊 Round 175 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=-0.0096
   Val:   Loss=0.0774, RMSE=0.2781, R²=-0.0205
============================================================


============================================================
🔄 Round 176 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 176 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=-0.0039
   Val:   Loss=0.0786, RMSE=0.2803, R²=-0.0232
============================================================


============================================================
🔄 Round 177 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0717 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0717, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0717, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0716, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0716, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0716, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0717)

============================================================
📊 Round 177 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=-0.0213
   Val:   Loss=0.0717, RMSE=0.2677, R²=0.0537
============================================================


📊 Round 177 Test Metrics:
   Loss: 0.0920, RMSE: 0.3032, MAE: 0.2602, R²: -0.0400

============================================================
🔄 Round 180 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0753 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0753, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0753, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0753, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0753, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0753, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0753)

============================================================
📊 Round 180 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=-0.0158
   Val:   Loss=0.0753, RMSE=0.2744, R²=0.0253
============================================================


📊 Round 180 Test Metrics:
   Loss: 0.0920, RMSE: 0.3033, MAE: 0.2602, R²: -0.0401

============================================================
🔄 Round 182 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 182 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=-0.0157
   Val:   Loss=0.0808, RMSE=0.2842, R²=-0.0009
============================================================


📊 Round 182 Test Metrics:
   Loss: 0.0920, RMSE: 0.3033, MAE: 0.2602, R²: -0.0401

📊 Round 182 Test Metrics:
   Loss: 0.0920, RMSE: 0.3033, MAE: 0.2602, R²: -0.0402

============================================================
🔄 Round 186 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 186 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2829, R²=-0.0020
   Val:   Loss=0.0840, RMSE=0.2898, R²=-0.0261
============================================================


============================================================
🔄 Round 187 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0867 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0867, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0867, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0867, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0867, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 187 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2816, R²=-0.0073
   Val:   Loss=0.0867, RMSE=0.2945, R²=-0.0051
============================================================


📊 Round 187 Test Metrics:
   Loss: 0.0920, RMSE: 0.3033, MAE: 0.2602, R²: -0.0404

📊 Round 187 Test Metrics:
   Loss: 0.0920, RMSE: 0.3033, MAE: 0.2602, R²: -0.0404

📊 Round 187 Test Metrics:
   Loss: 0.0920, RMSE: 0.3033, MAE: 0.2602, R²: -0.0404

============================================================
🔄 Round 192 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 192 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2818, R²=0.0092
   Val:   Loss=0.0862, RMSE=0.2937, R²=-0.0735
============================================================


📊 Round 192 Test Metrics:
   Loss: 0.0920, RMSE: 0.3033, MAE: 0.2602, R²: -0.0404

============================================================
🔄 Round 193 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 193 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=-0.0077
   Val:   Loss=0.0809, RMSE=0.2845, R²=-0.0080
============================================================


📊 Round 193 Test Metrics:
   Loss: 0.0920, RMSE: 0.3033, MAE: 0.2602, R²: -0.0404

📊 Round 193 Test Metrics:
   Loss: 0.0920, RMSE: 0.3033, MAE: 0.2602, R²: -0.0404

============================================================
🔄 Round 196 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0771 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0771, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0772, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0772, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0772, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0771)

============================================================
📊 Round 196 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=-0.0062
   Val:   Loss=0.0771, RMSE=0.2777, R²=-0.0131
============================================================


============================================================
🔄 Round 197 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0762, val=0.0903 (↓), lr=0.000001
   • Epoch   2/100: train=0.0762, val=0.0903, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0762, val=0.0903, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0762, val=0.0903, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0761, val=0.0904, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0761, val=0.0904, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0903)

============================================================
📊 Round 197 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2800, R²=-0.0058
   Val:   Loss=0.0903, RMSE=0.3005, R²=-0.0154
============================================================


📊 Round 197 Test Metrics:
   Loss: 0.0920, RMSE: 0.3033, MAE: 0.2602, R²: -0.0403

📊 Round 197 Test Metrics:
   Loss: 0.0920, RMSE: 0.3033, MAE: 0.2602, R²: -0.0404

============================================================
🔄 Round 201 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0643 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0643, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0643, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0643, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0643, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0643, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0643)

============================================================
📊 Round 201 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=-0.0180
   Val:   Loss=0.0643, RMSE=0.2535, R²=0.0397
============================================================


============================================================
🔄 Round 202 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0679 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0679, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0679, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0679, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0679, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0679, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0679)

============================================================
📊 Round 202 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2899, R²=-0.0073
   Val:   Loss=0.0679, RMSE=0.2605, R²=-0.0071
============================================================


📊 Round 202 Test Metrics:
   Loss: 0.0920, RMSE: 0.3033, MAE: 0.2602, R²: -0.0403

============================================================
🔄 Round 204 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0776, val=0.0905 (↓), lr=0.000001
   • Epoch   2/100: train=0.0776, val=0.0905, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0776, val=0.0905, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0776, val=0.0905, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0776, val=0.0905, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0776, val=0.0905, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0905)

============================================================
📊 Round 204 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2799, R²=-0.0100
   Val:   Loss=0.0905, RMSE=0.3009, R²=-0.0441
============================================================


============================================================
🔄 Round 206 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0719 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0719, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0719, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0719, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0719, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0719, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0719)

============================================================
📊 Round 206 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=-0.0050
   Val:   Loss=0.0719, RMSE=0.2682, R²=-0.0171
============================================================


📊 Round 206 Test Metrics:
   Loss: 0.0920, RMSE: 0.3033, MAE: 0.2602, R²: -0.0404

============================================================
🔄 Round 211 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0873 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0872, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0872, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0872, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0872, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0872, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0873)

============================================================
📊 Round 211 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2814, R²=0.0032
   Val:   Loss=0.0873, RMSE=0.2954, R²=-0.0465
============================================================


📊 Round 211 Test Metrics:
   Loss: 0.0920, RMSE: 0.3033, MAE: 0.2602, R²: -0.0402

============================================================
🔄 Round 213 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 213 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2821, R²=-0.0180
   Val:   Loss=0.0857, RMSE=0.2927, R²=0.0325
============================================================


📊 Round 213 Test Metrics:
   Loss: 0.0920, RMSE: 0.3033, MAE: 0.2602, R²: -0.0402

📊 Round 213 Test Metrics:
   Loss: 0.0920, RMSE: 0.3033, MAE: 0.2602, R²: -0.0403

============================================================
🔄 Round 216 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0770, val=0.0932 (↓), lr=0.000001
   • Epoch   2/100: train=0.0770, val=0.0932, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0770, val=0.0932, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0770, val=0.0932, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0769, val=0.0932, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0769, val=0.0932, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0932)

============================================================
📊 Round 216 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0777, RMSE=0.2788, R²=-0.0229
   Val:   Loss=0.0932, RMSE=0.3052, R²=0.0401
============================================================


📊 Round 216 Test Metrics:
   Loss: 0.0920, RMSE: 0.3033, MAE: 0.2602, R²: -0.0405

📊 Round 216 Test Metrics:
   Loss: 0.0920, RMSE: 0.3033, MAE: 0.2602, R²: -0.0405

============================================================
🔄 Round 218 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0769, val=0.0978 (↓), lr=0.000001
   • Epoch   2/100: train=0.0769, val=0.0978, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0769, val=0.0978, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0769, val=0.0979, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0769, val=0.0979, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0768, val=0.0979, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0978)

============================================================
📊 Round 218 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0765, RMSE=0.2766, R²=-0.0164
   Val:   Loss=0.0978, RMSE=0.3128, R²=0.0038
============================================================


============================================================
🔄 Round 219 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0885 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0885, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0885, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0885, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0886, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0886, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0885)

============================================================
📊 Round 219 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2808, R²=-0.0132
   Val:   Loss=0.0885, RMSE=0.2975, R²=-0.0009
============================================================


📊 Round 219 Test Metrics:
   Loss: 0.0920, RMSE: 0.3033, MAE: 0.2602, R²: -0.0404

📊 Round 219 Test Metrics:
   Loss: 0.0920, RMSE: 0.3033, MAE: 0.2602, R²: -0.0403

📊 Round 219 Test Metrics:
   Loss: 0.0920, RMSE: 0.3033, MAE: 0.2602, R²: -0.0403

============================================================
🔄 Round 222 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0747 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0747, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0747, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0747, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0747, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0746, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0747)

============================================================
📊 Round 222 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=-0.0065
   Val:   Loss=0.0747, RMSE=0.2733, R²=-0.0119
============================================================


============================================================
🔄 Round 223 - Client client_10
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0773, val=0.0974 (↓), lr=0.000001
   • Epoch   2/100: train=0.0773, val=0.0974, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0773, val=0.0974, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0773, val=0.0974, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0773, val=0.0974, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0772, val=0.0973, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0974)

============================================================
📊 Round 223 Summary - Client client_10
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0767, RMSE=0.2769, R²=-0.0041
   Val:   Loss=0.0974, RMSE=0.3121, R²=-0.0217
============================================================


📊 Round 223 Test Metrics:
   Loss: 0.0920, RMSE: 0.3033, MAE: 0.2602, R²: -0.0403

📊 Round 223 Test Metrics:
   Loss: 0.0920, RMSE: 0.3033, MAE: 0.2602, R²: -0.0403

❌ Client client_10 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8687 {grpc_message:"Socket closed", grpc_status:14}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8687 {grpc_message:"Socket closed", grpc_status:14}"
>
