[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fb96daa1-57d2-4b8e-93d0-5480aad9c5cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fb80ff7b-227e-4a7d-b6c5-a28b8857609a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 298f0a8a-9696-4d12-8614-2e4f067a8017
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cae89d71-6fd7-4a48-9f34-4e18414ecd36
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 67cfe99b-c2b6-4d59-9978-2575f1758934
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7c573220-8e96-455e-8cd4-579f3276af0f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c2db6cba-f1fd-460d-857f-3cdd617f8790
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b71d9d41-ac32-468d-84d1-df450bd57d1d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ccb43a23-6056-492f-bbf3-b5fc63d7f96e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6a664728-ceb4-43da-9ae9-035a4b5b142b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4247aa1b-8d18-4db9-80e1-d78ca0b2633d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 02a12fa7-a968-4167-a946-5e33079c46fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cdb8855c-30cf-49b8-8345-aadf156eeb6c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ecf8527b-412a-4c9e-8b63-e91da20a1d77
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d55b6e8a-0383-4023-b075-134ff4b9b7d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b4225bf0-fc05-4ff5-a161-2ad70b923393
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ad7a6e0b-e5de-4564-a8fe-5ab9643c18a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dfef94a8-aac5-4fc7-afe7-d31f49a5d6d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e9875b8f-cc56-4e08-a384-5c83886313bd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 46ec2445-7eb6-41b7-afc8-ad7185df1bca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 17d36c09-125b-461e-a484-0aab7c75dee3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 86dee40c-7cc0-4496-ae1e-51170b505867
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b5f81416-6531-4c8b-8c92-77e4641d7588
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b4c9769f-bf5a-4ec5-b1b6-c27027fa2bf9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f230b2a9-c4c7-4b7c-b2c8-2ddeba8e85f6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 05810ca3-d217-48d5-823d-eaff335ba7fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dfd72d6b-e680-43a5-8db5-4dc7ebbca350
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 87fd9cab-117f-409b-b9fb-762d143a4af5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d0555745-55c7-44d6-8aaf-87190e386730
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fae5bb8b-1079-449a-a307-b73c824a92bc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 315e561c-b41c-4748-868b-667a9657c3f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 48bb68a0-2d61-41d4-9105-6f7d165ebde8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d623cee8-f3db-4414-89e4-a132b59a966a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 22446e3a-db55-4820-a52b-92a5d8551ab6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9ab5aca1-1b4e-4706-a617-b4acb2eeaf73
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 01f4d57f-ae71-4fd6-a325-058ff4d49198
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 348a0b92-ac54-41b6-a70d-f123f660833d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 518c8493-4fca-48ed-9a42-ce6c69a601ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 664026ac-d5f3-46a2-bc80-518de638eb19
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e7818e26-619d-4eb9-85c1-de9ddabcc862
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6d56b5fe-1c47-4215-9924-e04b03b96fd2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 68ce5498-f405-4cd9-bb9a-760adef63b4e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 76ee1b3f-0961-4e12-a088-4fccf5848e35
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9f8ff650-882d-4d3f-94ff-7ae93bf3bf49
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cc7181eb-1c7d-4f9c-80dd-4ef1c52d1dd1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a8adc79a-27ca-41cd-aa9f-55e50bdfa707
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8bbf3eaa-5f99-4551-823e-0b5aeb071085
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 08e9a6cc-a9a4-43b3-96a9-fa2f99b6769b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 92849d9d-ca2d-470b-8a4a-da52c7a9628b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b71bd9fe-2c59-4a0b-83d4-ca74acabae65
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d0052c43-a094-47d4-b5a1-d57f66ef33fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d9671dad-2fff-4744-af5e-c714fb1a9a2e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a5d69d5b-4770-4eb7-ab9d-653a3b704bd9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message beb3b9ac-9b62-4875-b627-02d794684f7a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f5e4c7e6-e9cc-42ab-b3ed-3f09fe17397c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 31bdff33-df92-4767-a278-d9707d905cb9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8819b31f-debc-4f15-a0df-4c309ce67b5b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1de5d27b-7a85-4249-add5-96ebeace20e5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7b5879d4-102f-4c41-a737-1117293e776d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3635eb0e-615f-4e67-94c1-0641293aca59
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 569d832b-013d-4f54-a175-4b4b0a8583a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1489b3b6-a071-45b1-b899-839b925ec5c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0874e5b8-49d2-42a7-8c89-cc7cea7b720b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9e0af23d-c1b0-4a18-8405-8100da89724a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 79c91ae1-c88c-4177-b084-6bcb2bd55fe3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1e5bca48-6659-4e86-bbc5-a3b91a12e73c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 699c3ca6-0dd8-49cc-86f4-4a2097e8fb3d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 960baf2f-2a4d-481d-9752-7d82d49de632
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f7a7f27e-021f-4b5c-b9bc-e2fb82c69b9a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3c0ec8f3-351f-47e1-ac91-7577bfd1a844
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 61e03517-00f0-4b81-8323-a4855b645ef9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eab3b34f-e19e-4016-8d89-9b9923e08ff0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4bd8e939-397f-47ee-b2ac-82259a9885bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7d033e3e-14ea-4ee1-b7f4-bd4864a92a61
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2f1a13e6-ef6b-4764-adf1-4e62b4a024b5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fe2a1374-604e-431b-9650-d945a69fddb5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 79feaff5-5422-4945-9212-a8851de5ebb3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a80998ed-40b2-4f04-8adc-a32a93f3d0fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 20515732-8c0c-45a6-8616-71ebc9965422
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d23d3e63-ade3-4c11-bee9-633554ef4d43
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 19729d1e-0d4c-446c-8011-c319b6340300
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 22c13d93-5486-4347-b465-c49681d61c5c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e3fe8a72-564d-49a3-a6a4-6076b858004a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2de138cb-de67-4205-ac0b-77b3c2727e9f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 382650a5-d6e6-463d-9b75-87567cfd18ce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 460d5eae-5b40-4e19-9421-292de10abf11
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cfc44732-8f11-4e49-b324-292678d265c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6ec93533-20df-46bf-85eb-6ed97c741e92
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 98798a2c-b767-417c-a024-9c8c4751ac2a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 93eb5276-e59c-4b83-bacd-1b4a1d71a149
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 36904b06-6b42-438a-a6a5-bd5c838940cd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9b5bc405-7667-475a-bcd8-6eb75aee661c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 638d5ae6-f5b3-4b5c-84fb-825ed53d89b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8e98c29c-6211-42be-85b6-df8bcd453748
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 56edc69e-14d9-4c4c-ba96-eaf651a5df4c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cc67df11-1ad6-4682-a30a-a1304dca1f29
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 43c8f3dd-39c6-4946-815f-47a7a604dd45
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 91551f1b-1ef0-4d6c-9b8f-0eef44f8e2b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3424e680-019e-4230-b5ed-db74cd1d7aea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 44b28d54-7bbf-4251-9e54-901720e07a4f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c0393c5f-60d3-4efd-b546-1ab688a30f24
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 192f9b90-6ca2-416b-84d2-c5581d082dc0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d97b234d-c77c-4700-8876-a0a42e1fcc5e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 58367340-255d-4b5a-878e-8d8d95858ff6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 51a41087-3bc2-4353-9bfc-6fd86b66cc1f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 897dccef-b4c1-4b28-a0ff-1680201c0ffd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b4c83e4d-c3ba-4969-8970-5428140c89af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 000c9262-a370-4131-b465-0668042a6335
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 55583143-120c-4967-b229-4ecac37f66db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a78d987f-5c3a-462f-9e95-aa47d7daa629
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 84c43e1a-783e-4380-acbe-9b360aeb18e2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 96af0866-606e-4f06-a849-b83946d866a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bd46c255-61ff-47fa-9366-e40aae49e32d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 12abb4aa-19ba-49df-a18a-f88c9f8b1e50
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 89923046-f872-4d20-9a33-f28364efc06a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6339e727-4d8a-4233-974f-87c62bad4f5d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3add72ad-4aed-4d1c-a340-64bc7c699c19
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message da0cf85f-6691-4bb0-b0c6-3cffad146109
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 11dc7096-4f92-4b55-859d-43e06b6e34af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d69901bf-decf-4e18-a130-a68a88130e8f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d82f9a5e-af56-4e54-8398-3d4d9b5d1903
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b5f9ddcc-f180-4fa4-882d-756232d4353e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5aca3b23-201f-4c09-8cbe-eaea170ab4f9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7b94e536-2602-4ce7-aba1-fa5009272275
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d0d18778-2587-4f3c-8596-6e602d9a4576
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ec6064fe-ad9c-4ba8-b743-3fb66abc98f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ed0a4065-b24c-4d57-a999-400cc7b062e1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4cfecadd-077d-40a9-bfae-f2bc7b61e871
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9c6a88b2-e08c-4b49-8278-7994399f479d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7875c729-3bab-48c7-a558-c3ab222ce709
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e3d71933-e8d2-48f4-971d-c87c9f78642a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 34249637-51fb-498e-a18e-2e0908141fce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 774ad141-a5b6-43fe-b92b-f20587d37ddf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 024e4de0-b792-4dce-ad28-fbfb752615df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7b5a2d8a-51e1-4328-be50-dde609fa324e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 43796a88-c52f-423e-9530-3f1d62462fc4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 65c2720e-9df6-4c01-ba14-4326554f590b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 55668de8-85f7-4e5c-8d7c-d65838cb436f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d2748599-ac0e-4672-a35c-448dfaf8648d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9bac2a68-02c7-4ed9-9c81-87d49791b74e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 87927fe6-f5c1-4bb6-8c24-73aa2ff3a889
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d369b6c3-915e-4c00-b791-d9a923eabc20
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9b4eec2d-0d98-44fa-b4ea-1d3f011c32b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 032cd222-98ce-40e5-92a0-f3a6f2215e28
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7f269ed2-4880-4aa8-ba2b-d4033a8d5f87
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 49fde1fd-97be-48b1-a793-7de88b252da8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 34a84f68-3942-4b78-ad30-6b1d52f0d787
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c77d50d1-7c5d-4e8b-975b-6fe7bd74e701
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a2fd2aa1-6367-444f-b771-423d541b21d1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 960a99eb-7c58-47da-8380-ccc64adc0481
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8870ee5b-4415-42dd-bc9e-01ffd0d3430c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ee727de4-bda0-40ad-a1ba-ef260807e873
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1d3261da-7d53-4b11-a446-d34f331f01ea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ce443617-37e4-4178-9bfb-3404ae572f37
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 976d7732-6726-450c-a2c3-507930587ff7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 25989ada-5912-4a36-9ff1-6c09e63720f8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 55bce073-fcd6-4cab-8793-562edbb57b6e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 039829bb-10ab-45c6-b1c4-f4d7464f5ff7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d1560578-f139-4b68-a207-60c938dfddc2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e4d46bf2-7b32-4a2a-ad58-6bd72d6505bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8633ba49-6676-45bf-b896-1dfaa6650f27
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f36ae383-5f6e-43ad-8ee0-a712adf7f7bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 838b5b82-e2e3-4a1a-b5f2-f550f7212b3b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4e11eeb0-0c0e-45bb-95f1-3d7c26cb3e00
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e7354cb9-1757-45ba-86bb-315c43c7b972
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bf11062b-b5e8-454f-b8a0-a635f6fd9c76
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 655ef197-ac95-46e8-9866-ad385bb15488
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 350bc52e-013e-4278-8649-1812f63ebc36
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 31caf61d-1c33-41f5-8ced-592e56449618
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fcb32de6-4f53-44e4-8e27-46d03de658ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5dd6f60c-bf78-489a-8a92-b0ff428df9a7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message abf05cd4-525d-4c15-a7f2-fc27abceac7f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 16a86129-234e-4c5c-ab15-7f1c3acd1c37
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bcb42483-d4ab-43d8-ae36-850293c74ab5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 23691cbe-5873-40fe-8cac-de3b2dd8092e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7da19efb-0827-4675-b1bb-34e6c202d090
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2a803928-9773-44a0-aca9-dd2aed5987bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ae7fc4ea-e5d2-4c3f-b1fc-72ef9c53632d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 90c46f52-d2f2-42b7-8950-6c9aaac90140
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f7934240-2182-4338-8f02-b6617b352984
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8687 {grpc_message:"Socket closed", grpc_status:14}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_11
Server: localhost:8687
Algorithm: FEDAVG
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_11
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_11/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_11/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_11/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_11/test_labels.txt

📊 Raw data loaded:
   Train: X=(301, 24), y=(301,)
   Test:  X=(76, 24), y=(76,)

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 292 samples, 5 features
   Test:  67 samples, 5 features
✅ Client client_11 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

============================================================
🔄 Round 1 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.3799, val=0.3288 (↓), lr=0.001000
   ✓ Epoch   2/100: train=0.2328, val=0.1365 (↓), lr=0.001000
   ✓ Epoch   3/100: train=0.0952, val=0.1051 (↓), lr=0.001000
   ✓ Epoch   4/100: train=0.0953, val=0.0925 (↓), lr=0.001000
   ✓ Epoch   5/100: train=0.0875, val=0.0902 (↓), lr=0.001000
   • Epoch  11/100: train=0.0816, val=0.0855, patience=5/15, lr=0.001000
   • Epoch  21/100: train=0.0802, val=0.0845, patience=8/15, lr=0.001000
   • Epoch  31/100: train=0.0794, val=0.0841, patience=9/15, lr=0.001000
   • Epoch  41/100: train=0.0779, val=0.0833, patience=1/15, lr=0.001000
   • Epoch  51/100: train=0.0737, val=0.0827, patience=6/15, lr=0.001000
   📉 Epoch 55: LR reduced 0.001000 → 0.000500

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 1 Summary - Client client_11
   Epochs: 60/100 (early stopped)
   LR: 0.001000 → 0.000500 (1 reductions)
   Train: Loss=0.0779, RMSE=0.2790, R²=0.0661
   Val:   Loss=0.0828, RMSE=0.2878, R²=0.0475
============================================================


📊 Round 1 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2524, R²: 0.0090

============================================================
🔄 Round 5 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000500
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0956 (↓), lr=0.000500
   ✓ Epoch   2/100: train=0.0816, val=0.0947 (↓), lr=0.000500
   📉 Epoch 3: LR reduced 0.000500 → 0.000250
   ✓ Epoch   3/100: train=0.0810, val=0.0941 (↓), lr=0.000250
   • Epoch   4/100: train=0.0806, val=0.0940, patience=1/15, lr=0.000250
   • Epoch   5/100: train=0.0804, val=0.0939, patience=2/15, lr=0.000250
   📉 Epoch 11: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0794, val=0.0927, patience=1/15, lr=0.000125
   📉 Epoch 19: LR reduced 0.000125 → 0.000063
   • Epoch  21/100: train=0.0788, val=0.0921, patience=5/15, lr=0.000063
   📉 Epoch 27: LR reduced 0.000063 → 0.000031
   • Epoch  31/100: train=0.0785, val=0.0919, patience=15/15, lr=0.000031

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0924)

============================================================
📊 Round 5 Summary - Client client_11
   Epochs: 31/100 (early stopped)
   LR: 0.000500 → 0.000031 (4 reductions)
   Train: Loss=0.0809, RMSE=0.2845, R²=0.0089
   Val:   Loss=0.0924, RMSE=0.3039, R²=-0.0275
============================================================


📊 Round 5 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2533, R²: 0.0058

============================================================
🔄 Round 6 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000031
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0928 (↓), lr=0.000031
   • Epoch   2/100: train=0.0835, val=0.0927, patience=1/15, lr=0.000031
   • Epoch   3/100: train=0.0833, val=0.0926, patience=2/15, lr=0.000031
   📉 Epoch 4: LR reduced 0.000031 → 0.000016
   • Epoch   4/100: train=0.0832, val=0.0925, patience=3/15, lr=0.000016
   • Epoch   5/100: train=0.0830, val=0.0924, patience=4/15, lr=0.000016
   • Epoch  11/100: train=0.0828, val=0.0922, patience=3/15, lr=0.000016
   📉 Epoch 12: LR reduced 0.000016 → 0.000008
   📉 Epoch 20: LR reduced 0.000008 → 0.000004
   • Epoch  21/100: train=0.0825, val=0.0921, patience=13/15, lr=0.000004

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0923)

============================================================
📊 Round 6 Summary - Client client_11
   Epochs: 23/100 (early stopped)
   LR: 0.000031 → 0.000004 (3 reductions)
   Train: Loss=0.0854, RMSE=0.2923, R²=-0.0246
   Val:   Loss=0.0923, RMSE=0.3038, R²=-0.0547
============================================================


============================================================
🔄 Round 7 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000004
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0887, val=0.0794 (↓), lr=0.000004
   • Epoch   2/100: train=0.0887, val=0.0794, patience=1/15, lr=0.000004
   • Epoch   3/100: train=0.0886, val=0.0794, patience=2/15, lr=0.000004
   • Epoch   4/100: train=0.0886, val=0.0794, patience=3/15, lr=0.000004
   • Epoch   5/100: train=0.0886, val=0.0793, patience=4/15, lr=0.000004
   • Epoch  11/100: train=0.0885, val=0.0793, patience=10/15, lr=0.000004

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 7 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000004 → 0.000004 (0 reductions)
   Train: Loss=0.0907, RMSE=0.3012, R²=-0.0619
   Val:   Loss=0.0794, RMSE=0.2817, R²=-0.0073
============================================================


============================================================
🔄 Round 8 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000004
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.1134 (↓), lr=0.000004
   • Epoch   2/100: train=0.0862, val=0.1134, patience=1/15, lr=0.000004
   • Epoch   3/100: train=0.0861, val=0.1134, patience=2/15, lr=0.000004
   • Epoch   4/100: train=0.0861, val=0.1133, patience=3/15, lr=0.000004
   📉 Epoch 5: LR reduced 0.000004 → 0.000002
   • Epoch   5/100: train=0.0861, val=0.1133, patience=4/15, lr=0.000002
   • Epoch  11/100: train=0.0860, val=0.1132, patience=10/15, lr=0.000002
   📉 Epoch 13: LR reduced 0.000002 → 0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.1134)

============================================================
📊 Round 8 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000004 → 0.000001 (2 reductions)
   Train: Loss=0.0833, RMSE=0.2887, R²=-0.0451
   Val:   Loss=0.1134, RMSE=0.3368, R²=-0.1111
============================================================


📊 Round 8 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2533, R²: 0.0027

📊 Round 8 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2526, R²: 0.0066

📊 Round 8 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2526, R²: 0.0062

📊 Round 8 Test Metrics:
   Loss: 0.0826, RMSE: 0.2874, MAE: 0.2523, R²: 0.0071

============================================================
🔄 Round 14 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0957 (↓), lr=0.000001
   • Epoch   2/100: train=0.0867, val=0.0957, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0867, val=0.0957, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0867, val=0.0957, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0957, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0866, val=0.0957, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0957)

============================================================
📊 Round 14 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0886, RMSE=0.2976, R²=-0.0770
   Val:   Loss=0.0957, RMSE=0.3094, R²=-0.0405
============================================================


📊 Round 14 Test Metrics:
   Loss: 0.0823, RMSE: 0.2870, MAE: 0.2527, R²: 0.0103

============================================================
🔄 Round 17 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0907, val=0.0997 (↓), lr=0.000001
   • Epoch   2/100: train=0.0907, val=0.0997, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0907, val=0.0997, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0907, val=0.0997, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0907, val=0.0997, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0906, val=0.0996, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0997)

============================================================
📊 Round 17 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0889, RMSE=0.2982, R²=-0.0657
   Val:   Loss=0.0997, RMSE=0.3158, R²=-0.1497
============================================================


📊 Round 17 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2528, R²: 0.0102

📊 Round 17 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2526, R²: 0.0109

📊 Round 17 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2527, R²: 0.0121

============================================================
🔄 Round 22 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0928, val=0.0888 (↓), lr=0.000001
   • Epoch   2/100: train=0.0928, val=0.0888, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0928, val=0.0887, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0928, val=0.0887, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0927, val=0.0887, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0927, val=0.0887, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0888)

============================================================
📊 Round 22 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0924, RMSE=0.3040, R²=-0.0855
   Val:   Loss=0.0888, RMSE=0.2979, R²=-0.1066
============================================================


📊 Round 22 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2526, R²: 0.0121

============================================================
🔄 Round 23 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0897, val=0.0886 (↓), lr=0.000001
   • Epoch   2/100: train=0.0897, val=0.0886, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0896, val=0.0886, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0896, val=0.0886, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0896, val=0.0886, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0896, val=0.0886, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0886)

============================================================
📊 Round 23 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0924, RMSE=0.3040, R²=-0.0810
   Val:   Loss=0.0886, RMSE=0.2977, R²=-0.1225
============================================================


📊 Round 23 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2527, R²: 0.0119

📊 Round 23 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2526, R²: 0.0121

============================================================
🔄 Round 25 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.1001, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.1001, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.1001, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.1001, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.1001, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.1000, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 25 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0941, RMSE=0.3068, R²=-0.0865
   Val:   Loss=0.0818, RMSE=0.2861, R²=-0.1096
============================================================


📊 Round 25 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2526, R²: 0.0121

============================================================
🔄 Round 28 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0927, val=0.0925 (↓), lr=0.000001
   • Epoch   2/100: train=0.0927, val=0.0925, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0927, val=0.0925, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0927, val=0.0925, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0926, val=0.0925, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0926, val=0.0924, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0925)

============================================================
📊 Round 28 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0915, RMSE=0.3025, R²=-0.0865
   Val:   Loss=0.0925, RMSE=0.3041, R²=-0.1405
============================================================


📊 Round 28 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2526, R²: 0.0121

============================================================
🔄 Round 30 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0928, val=0.1017 (↓), lr=0.000001
   • Epoch   2/100: train=0.0928, val=0.1017, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0927, val=0.1017, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0927, val=0.1017, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0927, val=0.1017, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0926, val=0.1017, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.1017)

============================================================
📊 Round 30 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0892, RMSE=0.2987, R²=-0.0720
   Val:   Loss=0.1017, RMSE=0.3189, R²=-0.1649
============================================================


📊 Round 30 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2526, R²: 0.0121

📊 Round 30 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2526, R²: 0.0121

============================================================
🔄 Round 35 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0898, val=0.0951 (↓), lr=0.000001
   • Epoch   2/100: train=0.0898, val=0.0951, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0898, val=0.0951, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0898, val=0.0951, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0898, val=0.0951, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0897, val=0.0951, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0951)

============================================================
📊 Round 35 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0909, RMSE=0.3014, R²=-0.0973
   Val:   Loss=0.0951, RMSE=0.3084, R²=-0.0619
============================================================


============================================================
🔄 Round 36 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0927, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0927, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0927, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0927, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0927, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0927, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 36 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0948, RMSE=0.3079, R²=-0.0948
   Val:   Loss=0.0792, RMSE=0.2814, R²=-0.0623
============================================================


📊 Round 36 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2526, R²: 0.0122

============================================================
🔄 Round 37 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0897, val=0.0920 (↓), lr=0.000001
   • Epoch   2/100: train=0.0897, val=0.0920, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0897, val=0.0920, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0897, val=0.0919, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0897, val=0.0919, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0897, val=0.0919, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0920)

============================================================
📊 Round 37 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0916, RMSE=0.3027, R²=-0.0812
   Val:   Loss=0.0920, RMSE=0.3033, R²=-0.1328
============================================================


============================================================
🔄 Round 38 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0939, val=0.0938 (↓), lr=0.000001
   • Epoch   2/100: train=0.0939, val=0.0938, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0939, val=0.0938, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0939, val=0.0938, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0939, val=0.0938, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0938, val=0.0938, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0938)

============================================================
📊 Round 38 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0912, RMSE=0.3020, R²=-0.0718
   Val:   Loss=0.0938, RMSE=0.3063, R²=-0.1717
============================================================


📊 Round 38 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2526, R²: 0.0122

📊 Round 38 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2526, R²: 0.0122

============================================================
🔄 Round 40 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0869, val=0.0934 (↓), lr=0.000001
   • Epoch   2/100: train=0.0869, val=0.0934, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0869, val=0.0934, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0869, val=0.0934, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0869, val=0.0934, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0868, val=0.0934, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0934)

============================================================
📊 Round 40 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0913, RMSE=0.3021, R²=-0.1056
   Val:   Loss=0.0934, RMSE=0.3056, R²=-0.0345
============================================================


📊 Round 40 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2526, R²: 0.0122

============================================================
🔄 Round 42 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0892, val=0.0958 (↓), lr=0.000001
   • Epoch   2/100: train=0.0892, val=0.0958, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0892, val=0.0958, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0892, val=0.0958, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0892, val=0.0958, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0892, val=0.0957, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0958)

============================================================
📊 Round 42 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0907, RMSE=0.3011, R²=-0.0925
   Val:   Loss=0.0958, RMSE=0.3095, R²=-0.0766
============================================================


============================================================
🔄 Round 46 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0921, val=0.0951 (↓), lr=0.000001
   • Epoch   2/100: train=0.0921, val=0.0951, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0920, val=0.0951, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0920, val=0.0951, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0920, val=0.0951, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0920, val=0.0952, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0951)

============================================================
📊 Round 46 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0909, RMSE=0.3014, R²=-0.0874
   Val:   Loss=0.0951, RMSE=0.3084, R²=-0.1546
============================================================


============================================================
🔄 Round 47 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0953, val=0.0725 (↓), lr=0.000001
   • Epoch   2/100: train=0.0953, val=0.0725, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0953, val=0.0725, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0952, val=0.0725, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0952, val=0.0725, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0952, val=0.0725, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0725)

============================================================
📊 Round 47 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0965, RMSE=0.3106, R²=-0.0937
   Val:   Loss=0.0725, RMSE=0.2692, R²=-0.0813
============================================================


============================================================
🔄 Round 48 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.1088 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.1088, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.1088, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.1088, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.1088, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.1088, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.1088)

============================================================
📊 Round 48 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0875, RMSE=0.2957, R²=-0.0842
   Val:   Loss=0.1088, RMSE=0.3299, R²=-0.1225
============================================================


📊 Round 48 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2526, R²: 0.0123

============================================================
🔄 Round 49 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0904, val=0.0974 (↓), lr=0.000001
   • Epoch   2/100: train=0.0904, val=0.0974, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0904, val=0.0973, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0904, val=0.0973, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0904, val=0.0973, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0903, val=0.0973, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0974)

============================================================
📊 Round 49 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0903, RMSE=0.3005, R²=-0.0923
   Val:   Loss=0.0974, RMSE=0.3120, R²=-0.0827
============================================================


📊 Round 49 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2526, R²: 0.0123

============================================================
🔄 Round 51 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0912, val=0.0770 (↓), lr=0.000001
   • Epoch   2/100: train=0.0911, val=0.0770, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0911, val=0.0770, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0911, val=0.0770, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0911, val=0.0770, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0910, val=0.0770, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0770)

============================================================
📊 Round 51 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0954, RMSE=0.3088, R²=-0.1082
   Val:   Loss=0.0770, RMSE=0.2775, R²=-0.0281
============================================================


📊 Round 51 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2526, R²: 0.0123

📊 Round 51 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2526, R²: 0.0124

============================================================
🔄 Round 54 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0944, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0944, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0944, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0944, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0944, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0943, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 54 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0933, RMSE=0.3055, R²=-0.0857
   Val:   Loss=0.0851, RMSE=0.2918, R²=-0.1188
============================================================


============================================================
🔄 Round 58 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0938, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0938, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0938, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0938, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0938, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0938, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 58 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0938, RMSE=0.3063, R²=-0.0979
   Val:   Loss=0.0832, RMSE=0.2884, R²=-0.0534
============================================================


📊 Round 58 Test Metrics:
   Loss: 0.0822, RMSE: 0.2866, MAE: 0.2526, R²: 0.0124

============================================================
🔄 Round 59 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0903, val=0.1052 (↓), lr=0.000001
   • Epoch   2/100: train=0.0903, val=0.1052, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0903, val=0.1052, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0903, val=0.1052, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0903, val=0.1052, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0902, val=0.1052, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.1052)

============================================================
📊 Round 59 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0884, RMSE=0.2973, R²=-0.0992
   Val:   Loss=0.1052, RMSE=0.3243, R²=-0.1015
============================================================


============================================================
🔄 Round 61 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0967, val=0.0770 (↓), lr=0.000001
   • Epoch   2/100: train=0.0967, val=0.0770, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0967, val=0.0770, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0967, val=0.0770, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0967, val=0.0770, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0966, val=0.0769, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0770)

============================================================
📊 Round 61 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0954, RMSE=0.3088, R²=-0.0969
   Val:   Loss=0.0770, RMSE=0.2775, R²=-0.0529
============================================================


============================================================
🔄 Round 63 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0894, val=0.1019 (↓), lr=0.000001
   • Epoch   2/100: train=0.0893, val=0.1020, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0893, val=0.1020, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0893, val=0.1020, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0893, val=0.1020, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0891, val=0.1023, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.1019)

============================================================
📊 Round 63 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0892, RMSE=0.2986, R²=-0.0868
   Val:   Loss=0.1019, RMSE=0.3193, R²=-0.2404
============================================================


============================================================
🔄 Round 64 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0870, val=0.0907 (↓), lr=0.000001
   • Epoch   2/100: train=0.0870, val=0.0907, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0870, val=0.0907, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0870, val=0.0907, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0870, val=0.0906, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0869, val=0.0906, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0907)

============================================================
📊 Round 64 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0920, RMSE=0.3033, R²=-0.0853
   Val:   Loss=0.0907, RMSE=0.3011, R²=-0.1062
============================================================


📊 Round 64 Test Metrics:
   Loss: 0.0822, RMSE: 0.2866, MAE: 0.2526, R²: 0.0125

============================================================
🔄 Round 65 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0920, val=0.0906 (↓), lr=0.000001
   • Epoch   2/100: train=0.0920, val=0.0905, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0920, val=0.0905, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0919, val=0.0905, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0919, val=0.0905, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0919, val=0.0905, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0906)

============================================================
📊 Round 65 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0920, RMSE=0.3033, R²=-0.0759
   Val:   Loss=0.0906, RMSE=0.3009, R²=-0.1522
============================================================


============================================================
🔄 Round 66 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0903, val=0.0895 (↓), lr=0.000001
   • Epoch   2/100: train=0.0903, val=0.0895, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0903, val=0.0895, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0903, val=0.0895, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0903, val=0.0895, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0902, val=0.0895, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0895)

============================================================
📊 Round 66 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0923, RMSE=0.3037, R²=-0.0848
   Val:   Loss=0.0895, RMSE=0.2992, R²=-0.1305
============================================================


📊 Round 66 Test Metrics:
   Loss: 0.0822, RMSE: 0.2866, MAE: 0.2526, R²: 0.0124

📊 Round 66 Test Metrics:
   Loss: 0.0822, RMSE: 0.2866, MAE: 0.2526, R²: 0.0124

📊 Round 66 Test Metrics:
   Loss: 0.0822, RMSE: 0.2866, MAE: 0.2526, R²: 0.0124

📊 Round 66 Test Metrics:
   Loss: 0.0822, RMSE: 0.2866, MAE: 0.2526, R²: 0.0124

📊 Round 66 Test Metrics:
   Loss: 0.0822, RMSE: 0.2866, MAE: 0.2526, R²: 0.0125

============================================================
🔄 Round 72 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0911, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0911, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0911, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0911, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0911, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0911, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 72 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0933, RMSE=0.3055, R²=-0.0821
   Val:   Loss=0.0852, RMSE=0.2918, R²=-0.1323
============================================================


📊 Round 72 Test Metrics:
   Loss: 0.0822, RMSE: 0.2866, MAE: 0.2526, R²: 0.0125

📊 Round 72 Test Metrics:
   Loss: 0.0822, RMSE: 0.2866, MAE: 0.2526, R²: 0.0125

📊 Round 72 Test Metrics:
   Loss: 0.0822, RMSE: 0.2866, MAE: 0.2526, R²: 0.0125

📊 Round 72 Test Metrics:
   Loss: 0.0822, RMSE: 0.2866, MAE: 0.2526, R²: 0.0125

============================================================
🔄 Round 79 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0903, val=0.0905 (↓), lr=0.000001
   • Epoch   2/100: train=0.0902, val=0.0905, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0902, val=0.0905, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0902, val=0.0905, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0902, val=0.0905, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0901, val=0.0905, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0905)

============================================================
📊 Round 79 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0920, RMSE=0.3034, R²=-0.0932
   Val:   Loss=0.0905, RMSE=0.3008, R²=-0.0940
============================================================


============================================================
🔄 Round 80 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0959, val=0.0705 (↓), lr=0.000001
   • Epoch   2/100: train=0.0959, val=0.0705, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0958, val=0.0705, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0958, val=0.0705, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0958, val=0.0705, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0958, val=0.0704, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0705)

============================================================
📊 Round 80 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0970, RMSE=0.3114, R²=-0.0922
   Val:   Loss=0.0705, RMSE=0.2655, R²=-0.0759
============================================================


============================================================
🔄 Round 81 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0909, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0909, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0909, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0909, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0908, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0908, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 81 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0935, RMSE=0.3057, R²=-0.0944
   Val:   Loss=0.0847, RMSE=0.2910, R²=-0.0721
============================================================


📊 Round 81 Test Metrics:
   Loss: 0.0822, RMSE: 0.2866, MAE: 0.2526, R²: 0.0125

============================================================
🔄 Round 82 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0950, val=0.0731 (↓), lr=0.000001
   • Epoch   2/100: train=0.0950, val=0.0731, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0950, val=0.0731, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0950, val=0.0731, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0950, val=0.0731, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0949, val=0.0731, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0731)

============================================================
📊 Round 82 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0963, RMSE=0.3104, R²=-0.1022
   Val:   Loss=0.0731, RMSE=0.2703, R²=-0.0434
============================================================


📊 Round 82 Test Metrics:
   Loss: 0.0822, RMSE: 0.2866, MAE: 0.2526, R²: 0.0125

📊 Round 82 Test Metrics:
   Loss: 0.0822, RMSE: 0.2866, MAE: 0.2526, R²: 0.0125

📊 Round 82 Test Metrics:
   Loss: 0.0822, RMSE: 0.2866, MAE: 0.2526, R²: 0.0125

============================================================
🔄 Round 88 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0887, val=0.1016 (↓), lr=0.000001
   • Epoch   2/100: train=0.0887, val=0.1016, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0887, val=0.1016, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0887, val=0.1016, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0887, val=0.1016, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0886, val=0.1016, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.1016)

============================================================
📊 Round 88 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0893, RMSE=0.2988, R²=-0.0761
   Val:   Loss=0.1016, RMSE=0.3188, R²=-0.1421
============================================================


📊 Round 88 Test Metrics:
   Loss: 0.0822, RMSE: 0.2866, MAE: 0.2526, R²: 0.0126

📊 Round 88 Test Metrics:
   Loss: 0.0822, RMSE: 0.2866, MAE: 0.2526, R²: 0.0126

📊 Round 88 Test Metrics:
   Loss: 0.0822, RMSE: 0.2866, MAE: 0.2526, R²: 0.0126

📊 Round 88 Test Metrics:
   Loss: 0.0822, RMSE: 0.2866, MAE: 0.2526, R²: 0.0126

============================================================
🔄 Round 100 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.1027 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.1027, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.1027, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.1027, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.1027, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.1026, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.1027)

============================================================
📊 Round 100 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0890, RMSE=0.2983, R²=-0.0917
   Val:   Loss=0.1027, RMSE=0.3204, R²=-0.0901
============================================================


📊 Round 100 Test Metrics:
   Loss: 0.0822, RMSE: 0.2866, MAE: 0.2526, R²: 0.0126

============================================================
🔄 Round 101 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0936, val=0.0887 (↓), lr=0.000001
   • Epoch   2/100: train=0.0936, val=0.0887, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0936, val=0.0887, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0936, val=0.0887, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0936, val=0.0887, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0935, val=0.0887, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0887)

============================================================
📊 Round 101 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0925, RMSE=0.3041, R²=-0.0845
   Val:   Loss=0.0887, RMSE=0.2978, R²=-0.1590
============================================================


📊 Round 101 Test Metrics:
   Loss: 0.0822, RMSE: 0.2866, MAE: 0.2526, R²: 0.0126

============================================================
🔄 Round 103 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.1008 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.1007, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.1007, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.1007, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.1007, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.1007, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.1008)

============================================================
📊 Round 103 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0895, RMSE=0.2991, R²=-0.0852
   Val:   Loss=0.1008, RMSE=0.3174, R²=-0.1064
============================================================


📊 Round 103 Test Metrics:
   Loss: 0.0822, RMSE: 0.2866, MAE: 0.2526, R²: 0.0126

📊 Round 103 Test Metrics:
   Loss: 0.0822, RMSE: 0.2866, MAE: 0.2526, R²: 0.0126

============================================================
🔄 Round 105 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0883, val=0.1112 (↓), lr=0.000001
   • Epoch   2/100: train=0.0883, val=0.1112, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0883, val=0.1112, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0883, val=0.1112, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0883, val=0.1112, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0882, val=0.1112, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.1112)

============================================================
📊 Round 105 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0869, RMSE=0.2948, R²=-0.0898
   Val:   Loss=0.1112, RMSE=0.3335, R²=-0.1154
============================================================


📊 Round 105 Test Metrics:
   Loss: 0.0822, RMSE: 0.2866, MAE: 0.2526, R²: 0.0126

📊 Round 105 Test Metrics:
   Loss: 0.0822, RMSE: 0.2866, MAE: 0.2526, R²: 0.0126

============================================================
🔄 Round 112 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0905, val=0.1068 (↓), lr=0.000001
   • Epoch   2/100: train=0.0905, val=0.1068, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0905, val=0.1068, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0904, val=0.1068, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0904, val=0.1068, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0904, val=0.1068, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.1068)

============================================================
📊 Round 112 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0880, RMSE=0.2966, R²=-0.0835
   Val:   Loss=0.1068, RMSE=0.3269, R²=-0.1178
============================================================


📊 Round 112 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2526, R²: 0.0126

============================================================
🔄 Round 114 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0937, val=0.0744 (↓), lr=0.000001
   • Epoch   2/100: train=0.0937, val=0.0744, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0937, val=0.0744, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0937, val=0.0744, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0937, val=0.0744, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0936, val=0.0744, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0744)

============================================================
📊 Round 114 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0960, RMSE=0.3099, R²=-0.1081
   Val:   Loss=0.0744, RMSE=0.2728, R²=-0.0199
============================================================


============================================================
🔄 Round 116 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0904, val=0.0930 (↓), lr=0.000001
   • Epoch   2/100: train=0.0904, val=0.0930, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0904, val=0.0930, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0904, val=0.0930, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0904, val=0.0930, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0903, val=0.0930, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0930)

============================================================
📊 Round 116 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0914, RMSE=0.3024, R²=-0.0862
   Val:   Loss=0.0930, RMSE=0.3050, R²=-0.1028
============================================================


📊 Round 116 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2526, R²: 0.0126

============================================================
🔄 Round 117 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0938, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0938, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0938, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0938, val=0.0859, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0938, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0937, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 117 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0932, RMSE=0.3053, R²=-0.1137
   Val:   Loss=0.0859, RMSE=0.2931, R²=0.0031
============================================================


============================================================
🔄 Round 118 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0882, val=0.0963 (↓), lr=0.000001
   • Epoch   2/100: train=0.0882, val=0.0963, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0882, val=0.0962, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0882, val=0.0962, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0882, val=0.0962, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0881, val=0.0962, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0963)

============================================================
📊 Round 118 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0906, RMSE=0.3010, R²=-0.0882
   Val:   Loss=0.0963, RMSE=0.3103, R²=-0.1046
============================================================


📊 Round 118 Test Metrics:
   Loss: 0.0822, RMSE: 0.2866, MAE: 0.2526, R²: 0.0126

============================================================
🔄 Round 119 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0916, val=0.0975 (↓), lr=0.000001
   • Epoch   2/100: train=0.0916, val=0.0975, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0916, val=0.0975, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0916, val=0.0975, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0916, val=0.0975, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0915, val=0.0975, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0975)

============================================================
📊 Round 119 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0903, RMSE=0.3005, R²=-0.1005
   Val:   Loss=0.0975, RMSE=0.3123, R²=-0.0633
============================================================


============================================================
🔄 Round 121 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0919, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0919, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0919, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0919, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0919, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0918, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 121 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0937, RMSE=0.3062, R²=-0.0902
   Val:   Loss=0.0837, RMSE=0.2893, R²=-0.0872
============================================================


📊 Round 121 Test Metrics:
   Loss: 0.0822, RMSE: 0.2866, MAE: 0.2526, R²: 0.0126

📊 Round 121 Test Metrics:
   Loss: 0.0822, RMSE: 0.2866, MAE: 0.2526, R²: 0.0126

📊 Round 121 Test Metrics:
   Loss: 0.0822, RMSE: 0.2866, MAE: 0.2526, R²: 0.0126

📊 Round 121 Test Metrics:
   Loss: 0.0822, RMSE: 0.2866, MAE: 0.2526, R²: 0.0126

📊 Round 121 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2526, R²: 0.0127

📊 Round 121 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2526, R²: 0.0128

============================================================
🔄 Round 132 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0905, val=0.1022 (↓), lr=0.000001
   • Epoch   2/100: train=0.0905, val=0.1022, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0905, val=0.1022, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0905, val=0.1022, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0905, val=0.1022, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0904, val=0.1022, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.1022)

============================================================
📊 Round 132 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0891, RMSE=0.2986, R²=-0.0966
   Val:   Loss=0.1022, RMSE=0.3197, R²=-0.1026
============================================================


📊 Round 132 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2526, R²: 0.0128

📊 Round 132 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2526, R²: 0.0128

📊 Round 132 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2526, R²: 0.0128

============================================================
🔄 Round 137 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0963, val=0.0761 (↓), lr=0.000001
   • Epoch   2/100: train=0.0962, val=0.0761, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0962, val=0.0761, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0962, val=0.0761, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0962, val=0.0761, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0961, val=0.0761, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0761)

============================================================
📊 Round 137 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0956, RMSE=0.3092, R²=-0.1050
   Val:   Loss=0.0761, RMSE=0.2758, R²=-0.0302
============================================================


📊 Round 137 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2526, R²: 0.0128

============================================================
🔄 Round 141 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0895, val=0.0955 (↓), lr=0.000001
   • Epoch   2/100: train=0.0895, val=0.0955, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0895, val=0.0955, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0895, val=0.0955, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0895, val=0.0955, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0894, val=0.0955, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0955)

============================================================
📊 Round 141 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0908, RMSE=0.3013, R²=-0.0792
   Val:   Loss=0.0955, RMSE=0.3091, R²=-0.1680
============================================================


📊 Round 141 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2526, R²: 0.0128

📊 Round 141 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2526, R²: 0.0128

============================================================
🔄 Round 146 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0933, val=0.0904 (↓), lr=0.000001
   • Epoch   2/100: train=0.0933, val=0.0904, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0933, val=0.0904, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0933, val=0.0904, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0933, val=0.0904, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0932, val=0.0904, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0904)

============================================================
📊 Round 146 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0921, RMSE=0.3034, R²=-0.0776
   Val:   Loss=0.0904, RMSE=0.3007, R²=-0.1423
============================================================


📊 Round 146 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2526, R²: 0.0128

============================================================
🔄 Round 147 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0880, val=0.1041 (↓), lr=0.000001
   • Epoch   2/100: train=0.0880, val=0.1041, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0880, val=0.1041, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0880, val=0.1041, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0880, val=0.1041, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0879, val=0.1041, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.1041)

============================================================
📊 Round 147 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0887, RMSE=0.2978, R²=-0.0868
   Val:   Loss=0.1041, RMSE=0.3227, R²=-0.1183
============================================================


📊 Round 147 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2526, R²: 0.0128

📊 Round 147 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2526, R²: 0.0128

📊 Round 147 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2526, R²: 0.0128

============================================================
🔄 Round 152 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0903, val=0.0890 (↓), lr=0.000001
   • Epoch   2/100: train=0.0902, val=0.0890, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0902, val=0.0890, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0902, val=0.0890, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0902, val=0.0890, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0902, val=0.0890, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0890)

============================================================
📊 Round 152 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0924, RMSE=0.3040, R²=-0.1002
   Val:   Loss=0.0890, RMSE=0.2983, R²=-0.0685
============================================================


============================================================
🔄 Round 153 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0932, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0932, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0932, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0932, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0932, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0932, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 153 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0936, RMSE=0.3060, R²=-0.0884
   Val:   Loss=0.0842, RMSE=0.2902, R²=-0.1840
============================================================


📊 Round 153 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2526, R²: 0.0128

📊 Round 153 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2526, R²: 0.0128

============================================================
🔄 Round 155 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0948, val=0.0986 (↓), lr=0.000001
   • Epoch   2/100: train=0.0948, val=0.0986, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0948, val=0.0986, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0948, val=0.0986, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0948, val=0.0986, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0947, val=0.0987, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0986)

============================================================
📊 Round 155 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0901, RMSE=0.3001, R²=-0.1035
   Val:   Loss=0.0986, RMSE=0.3140, R²=-0.1410
============================================================


📊 Round 155 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2526, R²: 0.0129

============================================================
🔄 Round 160 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0934, val=0.0885 (↓), lr=0.000001
   • Epoch   2/100: train=0.0934, val=0.0885, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0934, val=0.0885, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0934, val=0.0885, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0934, val=0.0885, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0933, val=0.0885, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0885)

============================================================
📊 Round 160 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0926, RMSE=0.3042, R²=-0.1070
   Val:   Loss=0.0885, RMSE=0.2975, R²=-0.0296
============================================================


📊 Round 160 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2526, R²: 0.0128

📊 Round 160 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2526, R²: 0.0128

============================================================
🔄 Round 162 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0912, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0912, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0911, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0911, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0911, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0911, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 162 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0951, RMSE=0.3084, R²=-0.0822
   Val:   Loss=0.0781, RMSE=0.2795, R²=-0.1798
============================================================


📊 Round 162 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2526, R²: 0.0128

📊 Round 162 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2526, R²: 0.0128

============================================================
🔄 Round 164 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0869, val=0.1044 (↓), lr=0.000001
   • Epoch   2/100: train=0.0869, val=0.1044, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0869, val=0.1044, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0869, val=0.1044, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0869, val=0.1044, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0868, val=0.1044, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.1044)

============================================================
📊 Round 164 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0886, RMSE=0.2977, R²=-0.0900
   Val:   Loss=0.1044, RMSE=0.3231, R²=-0.1149
============================================================


📊 Round 164 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2526, R²: 0.0129

📊 Round 164 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2526, R²: 0.0129

============================================================
🔄 Round 168 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0905, val=0.1003 (↓), lr=0.000001
   • Epoch   2/100: train=0.0905, val=0.1003, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0904, val=0.1003, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0904, val=0.1003, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0904, val=0.1003, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0903, val=0.1003, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.1003)

============================================================
📊 Round 168 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0896, RMSE=0.2994, R²=-0.1139
   Val:   Loss=0.1003, RMSE=0.3167, R²=-0.0187
============================================================


📊 Round 168 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2526, R²: 0.0129

============================================================
🔄 Round 170 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0934, val=0.0905 (↓), lr=0.000001
   • Epoch   2/100: train=0.0934, val=0.0905, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0934, val=0.0905, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0934, val=0.0905, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0934, val=0.0905, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0933, val=0.0907, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0905)

============================================================
📊 Round 170 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0921, RMSE=0.3034, R²=-0.1061
   Val:   Loss=0.0905, RMSE=0.3008, R²=-0.1073
============================================================


📊 Round 170 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2526, R²: 0.0130

📊 Round 170 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2526, R²: 0.0129

============================================================
🔄 Round 173 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0921, val=0.1033 (↓), lr=0.000001
   • Epoch   2/100: train=0.0921, val=0.1033, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0921, val=0.1033, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0921, val=0.1033, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0921, val=0.1033, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0920, val=0.1033, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.1033)

============================================================
📊 Round 173 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0889, RMSE=0.2981, R²=-0.0834
   Val:   Loss=0.1033, RMSE=0.3215, R²=-0.1126
============================================================


📊 Round 173 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2526, R²: 0.0129

📊 Round 173 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2526, R²: 0.0129

============================================================
🔄 Round 177 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0950, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0950, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0950, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0949, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0949, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0949, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 177 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0935, RMSE=0.3057, R²=-0.1154
   Val:   Loss=0.0848, RMSE=0.2912, R²=-0.0168
============================================================


📊 Round 177 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2526, R²: 0.0129

============================================================
🔄 Round 178 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0870, val=0.1110 (↓), lr=0.000001
   • Epoch   2/100: train=0.0870, val=0.1110, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0870, val=0.1110, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0869, val=0.1110, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0869, val=0.1110, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0869, val=0.1110, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.1110)

============================================================
📊 Round 178 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0870, RMSE=0.2949, R²=-0.0882
   Val:   Loss=0.1110, RMSE=0.3331, R²=-0.1030
============================================================


============================================================
🔄 Round 180 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0959, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0959, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0959, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0958, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0958, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0958, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 180 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0946, RMSE=0.3076, R²=-0.0922
   Val:   Loss=0.0801, RMSE=0.2830, R²=-0.1294
============================================================


📊 Round 180 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2525, R²: 0.0130

============================================================
🔄 Round 181 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.1134 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.1134, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.1134, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.1134, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.1134, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.1135, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.1134)

============================================================
📊 Round 181 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2939, R²=-0.0821
   Val:   Loss=0.1134, RMSE=0.3368, R²=-0.1658
============================================================


📊 Round 181 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2525, R²: 0.0130

📊 Round 181 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2525, R²: 0.0130

============================================================
🔄 Round 183 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0893, val=0.0924 (↓), lr=0.000001
   • Epoch   2/100: train=0.0893, val=0.0924, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0893, val=0.0924, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0893, val=0.0924, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0892, val=0.0924, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0892, val=0.0925, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0924)

============================================================
📊 Round 183 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0916, RMSE=0.3026, R²=-0.1101
   Val:   Loss=0.0924, RMSE=0.3040, R²=-0.0318
============================================================


📊 Round 183 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2525, R²: 0.0131

============================================================
🔄 Round 186 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.1066 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.1066, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.1066, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.1066, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.1066, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.1066, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.1066)

============================================================
📊 Round 186 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0881, RMSE=0.2968, R²=-0.0801
   Val:   Loss=0.1066, RMSE=0.3265, R²=-0.1368
============================================================


📊 Round 186 Test Metrics:
   Loss: 0.0821, RMSE: 0.2865, MAE: 0.2525, R²: 0.0131

============================================================
🔄 Round 190 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0930, val=0.0920 (↓), lr=0.000001
   • Epoch   2/100: train=0.0930, val=0.0920, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0929, val=0.0920, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0929, val=0.0920, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0929, val=0.0920, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0929, val=0.0920, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0920)

============================================================
📊 Round 190 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0917, RMSE=0.3028, R²=-0.0933
   Val:   Loss=0.0920, RMSE=0.3034, R²=-0.0767
============================================================


📊 Round 190 Test Metrics:
   Loss: 0.0821, RMSE: 0.2865, MAE: 0.2525, R²: 0.0132

📊 Round 190 Test Metrics:
   Loss: 0.0821, RMSE: 0.2865, MAE: 0.2525, R²: 0.0132

============================================================
🔄 Round 199 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0910, val=0.0890 (↓), lr=0.000001
   • Epoch   2/100: train=0.0910, val=0.0890, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0910, val=0.0890, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0910, val=0.0890, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0910, val=0.0890, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0909, val=0.0890, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0890)

============================================================
📊 Round 199 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0924, RMSE=0.3040, R²=-0.0761
   Val:   Loss=0.0890, RMSE=0.2984, R²=-0.1740
============================================================


📊 Round 199 Test Metrics:
   Loss: 0.0821, RMSE: 0.2865, MAE: 0.2525, R²: 0.0132

📊 Round 199 Test Metrics:
   Loss: 0.0821, RMSE: 0.2865, MAE: 0.2525, R²: 0.0132

📊 Round 199 Test Metrics:
   Loss: 0.0821, RMSE: 0.2865, MAE: 0.2525, R²: 0.0132

============================================================
🔄 Round 203 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0923, val=0.0910 (↓), lr=0.000001
   • Epoch   2/100: train=0.0923, val=0.0910, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0923, val=0.0910, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0923, val=0.0910, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0923, val=0.0910, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0922, val=0.0910, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0910)

============================================================
📊 Round 203 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0919, RMSE=0.3032, R²=-0.0874
   Val:   Loss=0.0910, RMSE=0.3017, R²=-0.0997
============================================================


📊 Round 203 Test Metrics:
   Loss: 0.0821, RMSE: 0.2865, MAE: 0.2525, R²: 0.0132

============================================================
🔄 Round 206 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0900, val=0.0944 (↓), lr=0.000001
   • Epoch   2/100: train=0.0900, val=0.0944, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0900, val=0.0944, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0900, val=0.0944, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0900, val=0.0944, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0899, val=0.0943, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0944)

============================================================
📊 Round 206 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0911, RMSE=0.3018, R²=-0.0861
   Val:   Loss=0.0944, RMSE=0.3072, R²=-0.1056
============================================================


📊 Round 206 Test Metrics:
   Loss: 0.0821, RMSE: 0.2865, MAE: 0.2525, R²: 0.0132

📊 Round 206 Test Metrics:
   Loss: 0.0821, RMSE: 0.2865, MAE: 0.2525, R²: 0.0132

============================================================
🔄 Round 209 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0879, val=0.0993 (↓), lr=0.000001
   • Epoch   2/100: train=0.0879, val=0.0993, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0879, val=0.0993, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0879, val=0.0993, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0879, val=0.0993, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0879, val=0.0993, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0993)

============================================================
📊 Round 209 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0899, RMSE=0.2998, R²=-0.0839
   Val:   Loss=0.0993, RMSE=0.3151, R²=-0.1390
============================================================


📊 Round 209 Test Metrics:
   Loss: 0.0821, RMSE: 0.2865, MAE: 0.2525, R²: 0.0132

============================================================
🔄 Round 212 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0885, val=0.1052 (↓), lr=0.000001
   • Epoch   2/100: train=0.0885, val=0.1052, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0885, val=0.1052, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0885, val=0.1052, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0885, val=0.1052, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0885, val=0.1052, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.1052)

============================================================
📊 Round 212 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0884, RMSE=0.2974, R²=-0.0736
   Val:   Loss=0.1052, RMSE=0.3243, R²=-0.1537
============================================================


============================================================
🔄 Round 215 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.1081 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.1081, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.1081, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.1081, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.1082, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.1082, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.1081)

============================================================
📊 Round 215 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0877, RMSE=0.2962, R²=-0.0725
   Val:   Loss=0.1081, RMSE=0.3288, R²=-0.1953
============================================================


📊 Round 215 Test Metrics:
   Loss: 0.0821, RMSE: 0.2865, MAE: 0.2525, R²: 0.0132

📊 Round 215 Test Metrics:
   Loss: 0.0821, RMSE: 0.2865, MAE: 0.2525, R²: 0.0133

============================================================
🔄 Round 218 - Client client_11
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0927, val=0.0877 (↓), lr=0.000001
   • Epoch   2/100: train=0.0927, val=0.0876, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0927, val=0.0876, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0927, val=0.0876, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0926, val=0.0876, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0926, val=0.0876, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0877)

============================================================
📊 Round 218 Summary - Client client_11
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0928, RMSE=0.3046, R²=-0.0938
   Val:   Loss=0.0877, RMSE=0.2961, R²=-0.0780
============================================================


📊 Round 218 Test Metrics:
   Loss: 0.0821, RMSE: 0.2865, MAE: 0.2525, R²: 0.0132

📊 Round 218 Test Metrics:
   Loss: 0.0821, RMSE: 0.2865, MAE: 0.2525, R²: 0.0132

📊 Round 218 Test Metrics:
   Loss: 0.0821, RMSE: 0.2865, MAE: 0.2525, R²: 0.0132

📊 Round 218 Test Metrics:
   Loss: 0.0821, RMSE: 0.2865, MAE: 0.2525, R²: 0.0132

❌ Client client_11 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8687 {grpc_message:"Socket closed", grpc_status:14}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8687 {grpc_message:"Socket closed", grpc_status:14}"
>
