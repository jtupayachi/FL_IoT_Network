[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 38f15050-2327-4eb5-bba5-cee0028a0ea7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 76ed4d73-f9b3-4950-9f25-2e96aeebe1a0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c86fdd3f-a9fa-41fa-a377-ec6812bc06a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d792bec8-5afd-483f-ae98-a6a4ec33eb2c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fc285357-f981-4382-850e-6b713e364ecf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d479549c-3b83-4eef-9cc8-494c43b0c3a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fb3ad556-5863-446f-943e-66618024f051
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 446e27d4-29c6-402a-883f-7dda29f480a0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c0c4c958-6c68-40de-8492-fc02b0fcf92d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a35e28c1-14de-498e-a471-7e9bdfb892a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0284ee0f-c2e4-41a7-857f-6d81a514d106
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5dc7d66d-001a-44dc-9fa4-fa61e51609c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 402f480a-f08a-47d2-82c3-18157f525312
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 585ddf76-da92-4e2b-b69b-de79f4d2bc7b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 83e0a0fd-50d0-437b-9ff9-5623e168942f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 85678a69-4dff-41b1-bb69-3431c2b52646
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 388cff11-7ed6-4341-8c7e-48554e7f862b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e6189ea4-4d05-4a98-b61e-8ba7cb49f2c3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ad367ef8-9ef8-4505-9ce8-26b35289dff9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 536fba49-5d3e-431a-aa2e-57243ad29e0e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bfbfe597-b082-4293-b618-1652639bb80f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d1dedcc1-72a6-4efd-a83c-8121648cb4c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c0f1d716-c961-4ca8-94ed-e8e017ddd360
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fa8a8c82-6dcf-41e4-865a-8ef1d6fcbe5b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 156528ca-28f5-4a91-a285-2e1f2a017fd1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a554d17b-a7e2-4101-9113-9f0186135df2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ed72432a-5a9f-4e2a-b363-81d0a628fed8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c947bc49-56e9-44c5-b940-9f9e4a52fba2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1882a883-3902-494c-a559-0c89e1d583ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 13d1977c-366a-40d2-983b-8c07c8a1e161
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 60702e72-5487-4adc-bc3f-d684cb7923de
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 01846fc6-a7a6-45a7-b929-ff55e799996d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 45730072-2569-4dac-a8bf-36de68b27d9d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 011ce631-7ebd-49f3-ac92-e7c7a6a597df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 272dd5d6-83f5-457b-b5a8-248310370635
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 33af5077-aed3-4282-99d9-3fd52ca3dab2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c04c295a-d14e-456a-898c-c72dc6739bc4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b9055cea-dac5-4869-ba69-abaa8ce3c143
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0792baa1-ac83-4a70-8081-e7a8524f3679
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ed4acdc7-7770-43d2-b170-c8a4301ea205
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d0637338-89c4-4002-a648-9e8a8ae62d30
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c64bd8bd-c539-47c4-a920-5ac4ae028b5f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 03cc15e0-c5ac-4775-b4a8-dbaa987d0767
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message da41366b-7570-4b81-b963-d62683b53c25
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 64ef69e2-af7c-48d1-963e-8d3ff214621b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 782492c5-7482-49f4-b44a-0b4d5790461f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b8abfa2e-8a02-44fe-bd9e-dc65f393d116
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cc41fb25-7fb5-405b-a0b1-50ae1ae8446a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 67ed0a26-0f3c-47cd-bb87-596e27663987
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7a7d7f65-646e-4356-82ea-74051c13c972
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 83b5923d-868e-4fba-bf87-3868396efb22
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a8bbe7e9-55dc-4a1c-a174-ef402ef2a920
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 31dd40e7-8f16-4cfe-bfd2-df3813483757
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e6c89d4e-fbc4-4873-91f7-f802ac0fd452
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6b406d56-f52c-409c-8c19-4817cff284dd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message db021603-d7a9-4ec1-b72a-cad349caa20e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bafac122-8999-492d-b33e-2ac81429c63c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 65f365b0-7988-4483-acfe-5553bafea46d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f058c2fe-bb43-4a8d-9cb9-d5aebe9107d9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 76895129-ca9b-4c69-b2e7-bd11003eec9a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 36addb36-4545-4153-b88f-185a189fbf5d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f13709e5-b223-4769-92ec-8c9f6792c4de
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message de510a87-ebaf-482c-87f8-2739e568f493
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bfa5d285-72fb-411d-af74-4f8965f3f84d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a9803841-d853-4a26-a33e-77c80e3b1d81
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6cf7e48c-51c7-4b12-9f28-b0c8e5773c70
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a7637aad-c490-44e1-915b-5f9dc9f8f7d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ae384f4b-8cac-439b-aace-9bd22b00eba8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 718fff20-ada3-4b12-ae5a-0da8d27ff3fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4d5f2d93-152a-413e-9e51-48b68ef91aeb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 97b4e1b7-71c6-45e3-8fa4-1ba500858f3d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 86d38277-2710-4766-87ef-17c6eb62fde6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ce4906a5-27bd-4570-970a-cec0251e19a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cedfcbf2-a266-4c63-bd5f-3db85b1813d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c753597e-bd70-4ff8-ac89-54121ddafabe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fec84ec6-638f-4a77-bf5d-5f3ef315e865
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 637e4509-38d0-43cc-a81c-b3aaf3e8f4d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f8024d35-472b-4120-8829-93c934d14040
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c17bf0a0-31d0-4d82-9cfb-23c70074b3da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f6e70e74-1f18-4e33-a421-4a5ec709c3dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6d5748b5-e1ee-4d3d-a2b7-04d3b498f276
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1e4ccbe9-8150-4ab7-9d51-43b5ff02f28c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b3bb7f42-e384-455c-ab9f-93a52952bcba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 527f6e60-ad47-4fed-8dc9-01baccdcfddb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b186006b-38ad-455c-bdc8-d279a0d994b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c6778ab3-e65f-48ca-9d46-233706b9c4f6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message de087c35-ea18-4b36-b1c4-21a6b8df6f21
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2742444a-ae3f-40c1-b442-77db47b57295
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5b4bf360-b096-4c52-88ac-9afa8d3bfac2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b6cf3c3a-03cd-478d-9dc6-6c16946fbc25
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 946338b7-ce3b-4dbc-929d-3c89eb35fa04
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2a97a0e3-c1ad-4412-bc43-9c4d36bc9d7d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8a94bd95-0ad2-49c0-83f0-2721c0fa50fb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 94970c8d-50d0-4acd-9f7f-63303f86360d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 14273186-a395-4d8d-968d-b269b3fceaf0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bff59cfe-2dad-464b-a3a9-5943ba8bded8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b817eca3-2889-49dc-b75f-8ecf5a09bc6b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 72c832fd-2e40-4918-83ad-d61c05cd3922
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 181802ad-117b-44ca-b8f2-26ec33bfbdf1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0af03093-7df3-4d59-bce0-7a680b80e4f3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3375a8fb-1773-41b6-ae33-9cbcb8c45235
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8815416a-81c8-4bc1-9af4-4ccf61dfdf36
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4d7d094a-d217-4ca2-ba65-15099182a099
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bc28aa7a-fcda-496b-bae5-88f5f9cac601
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5db0ea00-a3bd-43f8-8120-d0bf61957da9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3a4b6516-d857-444a-a67c-d70ad02a9b6e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 846f0ece-6e95-4faf-b083-d040457d57cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7cdd45c9-f147-447e-9579-26ef7494609c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8d96da42-9eaa-4de3-9721-9a87a889605f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 564bc53f-c3d7-4e50-b787-92b385abcc57
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 84e440cd-167b-43b5-8475-dbeea5ef2024
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ae283749-9aa0-40e9-9084-0ee8dd8ba91d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d346c5e3-0a35-46ed-ac34-692e4be9040d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e5a96be7-93e2-42ed-93ac-c0eeaf4c2459
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 203ce8fa-5a76-48a3-8d37-ca76ef5acd98
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 33ace5b7-4ab5-4993-a804-0db5a66d2a5e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3ee73216-5a5b-4400-b617-f60eae8d69cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a97f18ba-654b-4d54-93d8-d9bea374d04c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d64a14f3-bdd2-4373-9c18-53e8bd392890
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2d58da6e-55aa-4dbf-b4ce-6878d56bc920
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bdd850c0-0b51-4744-aafb-f015ab93e377
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 22c7f343-ae41-450e-bb9a-c1cf2fecff40
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3b9e4a6b-fbf9-45fb-ab13-7a09a5c688ea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 993cb34e-b42f-445f-b62d-e376c57b233a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bc5df80f-c6a1-40b0-b5e6-c3ae683bdde2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c2ed1d5d-c52f-479e-b6ed-96d5eb28e12e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5f3228d4-0088-4a61-9f97-c1b51242ad2c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f6f14cb9-c7aa-48ed-a858-2e30afe5dd45
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d96dc48d-6a3a-4d7f-bf3e-ced841b72582
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 84c196b0-be68-4f5a-bf9d-54da65529078
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 288378f9-440a-49a0-973a-1f1dd099b8b1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b3eb35e0-53c5-4b3f-b2c4-a264de3815c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9e150fdc-11d4-4c0d-a51e-cca41fa55a05
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0142c8f2-0381-4558-b820-858c73a88221
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f73831a2-6588-4b8c-9079-4ef7f7ea8bf1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a23b5074-84d0-469a-80a2-9f34f74156d9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ee6efc90-ec6a-4b1c-aa72-aa54fb1ae32a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0350e8fd-6987-4d23-8a19-d0fdb1e093dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e0438918-950f-4744-80b1-afbced453a89
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d1af1985-15df-4e7b-89fc-463a58a859f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 50bf7808-1001-4047-b765-fe2db3fe3922
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b984642d-53f2-4f43-89b9-8e6358dab95b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0daabd9f-edc7-4299-a056-94ecc2dbb899
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1e53a767-a4ba-4f23-8c25-6662cfbc0e7c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a846014c-e6ea-4221-a85e-2dcf73b26e20
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9897ecfd-5e2a-4797-bc45-039662115abb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6915ef6c-d235-4da0-974d-d21887c6ae58
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bad73c01-5df9-406b-a556-bed489753b44
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5f9fb46c-bd56-47f3-8e7f-3628d70e6019
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b017b95f-07f5-4a30-a209-f07bbb6c8bad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d3b79cfa-ede7-4583-88d8-a62b218e251e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d791dd48-01ce-4022-a603-462f65c4440b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message db81f60a-c9b8-4fd8-bad3-e0c625bab93d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1d61fb30-99a1-4e89-85d2-c55d4378a3f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a1b0bbdd-20df-4fd7-9def-473cb95c6e73
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 907b7fcb-ee42-4b5b-9bea-85da83df4385
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f757ecd2-8efd-409d-8e94-1bdd72bb6265
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 71c2bbc4-b586-4701-8c98-2a5ca67e5a67
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3cd6c534-166c-4f34-ad87-2fe093615f1a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b5e9b45d-7283-4075-9c6d-a996de02c8fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3fe2cb77-4982-45d1-ad0f-36f5ac6506eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2dc8fd31-679f-431e-bb80-d4eededc65ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 02300379-0379-4767-a0ca-8f1f015bfd16
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 97d33e65-71cd-4ed1-aee7-98144f4262f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5296ed9c-ed46-4e6c-b4e3-7a556b6bb5d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a2e9538e-d877-41a0-b136-4808e2f7588f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4644e538-fa2e-49b8-b5ee-4cff24ffd729
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e0568a4a-f565-4dfc-84d9-7fe7f63fee2c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d5ea75de-906c-4959-8bcd-5b227b69ef2e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dfd4400a-b154-429e-9fa0-18076318bac8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cc971eb5-4740-4b45-9367-505e0d65e042
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aa6ace77-3f06-42f8-9f92-d041ab1ef510
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3a986e36-8492-4556-a2fa-8757cf4ddb8e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b7165f86-cfc3-4f29-8919-022cc02c532d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a13fa185-c72e-4ef0-a45d-5bdb965e0f1b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message edacaf86-b113-479c-8936-4a689df08ca7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2a0c362d-2423-4b7a-9509-5c3f8397d99a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 48cc1634-a3bb-463e-876c-ee0e340e096c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 54fda4d6-8b6b-4993-a99a-aa4191bbb0cd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a42ef9c5-6408-4821-864b-a183b755fd56
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dbc13ed1-7b15-4255-aafa-9702f3374169
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1021c496-a7e9-4694-883e-3d47f08cedc6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8e1f7043-b23b-49e3-bc0d-7b1df2839382
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4027c2a3-ca9a-4301-93fe-aa39a91621eb
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8687 {grpc_status:14, grpc_message:"Socket closed"}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_12
Server: localhost:8687
Algorithm: FEDAVG
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_12
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_12/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_12/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_12/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_12/test_labels.txt

📊 Raw data loaded:
   Train: X=(1530, 24), y=(1530,)
   Test:  X=(383, 24), y=(383,)

⚠️  Limiting training data: 1530 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  374 samples, 5 features
✅ Client client_12 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

============================================================
🔄 Round 1 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.2516, val=0.0940 (↓), lr=0.001000
   ✓ Epoch   2/100: train=0.0946, val=0.0895 (↓), lr=0.001000
   ✓ Epoch   3/100: train=0.0846, val=0.0871 (↓), lr=0.001000
   ✓ Epoch   4/100: train=0.0835, val=0.0856 (↓), lr=0.001000
   • Epoch   5/100: train=0.0826, val=0.0864, patience=1/15, lr=0.001000
   📉 Epoch 10: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0816, val=0.0888, patience=7/15, lr=0.000500
   📉 Epoch 18: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 1 Summary - Client client_12
   Epochs: 19/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0821, RMSE=0.2864, R²=0.0101
   Val:   Loss=0.0856, RMSE=0.2925, R²=-0.0230
============================================================


📊 Round 1 Test Metrics:
   Loss: 0.0856, RMSE: 0.2925, MAE: 0.2520, R²: -0.0373

============================================================
🔄 Round 3 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0780 (↓), lr=0.000250
   • Epoch   2/100: train=0.0831, val=0.0780, patience=1/15, lr=0.000250
   • Epoch   3/100: train=0.0830, val=0.0782, patience=2/15, lr=0.000250
   • Epoch   4/100: train=0.0829, val=0.0782, patience=3/15, lr=0.000250
   • Epoch   5/100: train=0.0828, val=0.0783, patience=4/15, lr=0.000250
   📉 Epoch 7: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0823, val=0.0785, patience=10/15, lr=0.000125
   📉 Epoch 15: LR reduced 0.000125 → 0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 3 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000250 → 0.000063 (2 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=0.0134
   Val:   Loss=0.0780, RMSE=0.2793, R²=-0.0051
============================================================


============================================================
🔄 Round 4 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0789 (↓), lr=0.000063
   • Epoch   2/100: train=0.0826, val=0.0790, patience=1/15, lr=0.000063
   • Epoch   3/100: train=0.0825, val=0.0791, patience=2/15, lr=0.000063
   • Epoch   4/100: train=0.0824, val=0.0793, patience=3/15, lr=0.000063
   • Epoch   5/100: train=0.0823, val=0.0794, patience=4/15, lr=0.000063
   📉 Epoch 7: LR reduced 0.000063 → 0.000031
   • Epoch  11/100: train=0.0820, val=0.0798, patience=10/15, lr=0.000031
   📉 Epoch 15: LR reduced 0.000031 → 0.000016

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 4 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000063 → 0.000016 (2 reductions)
   Train: Loss=0.0826, RMSE=0.2875, R²=0.0162
   Val:   Loss=0.0789, RMSE=0.2809, R²=0.0064
============================================================


============================================================
🔄 Round 6 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000016
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0834 (↓), lr=0.000016
   • Epoch   2/100: train=0.0804, val=0.0835, patience=1/15, lr=0.000016
   • Epoch   3/100: train=0.0803, val=0.0836, patience=2/15, lr=0.000016
   • Epoch   4/100: train=0.0803, val=0.0836, patience=3/15, lr=0.000016
   • Epoch   5/100: train=0.0802, val=0.0836, patience=4/15, lr=0.000016
   📉 Epoch 7: LR reduced 0.000016 → 0.000008
   • Epoch  11/100: train=0.0801, val=0.0837, patience=10/15, lr=0.000008
   📉 Epoch 15: LR reduced 0.000008 → 0.000004

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 6 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000016 → 0.000004 (2 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=0.0314
   Val:   Loss=0.0834, RMSE=0.2888, R²=-0.0126
============================================================


📊 Round 6 Test Metrics:
   Loss: 0.0796, RMSE: 0.2822, MAE: 0.2436, R²: 0.0347

============================================================
🔄 Round 7 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000004
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0823 (↓), lr=0.000004
   • Epoch   2/100: train=0.0800, val=0.0823, patience=1/15, lr=0.000004
   • Epoch   3/100: train=0.0800, val=0.0823, patience=2/15, lr=0.000004
   • Epoch   4/100: train=0.0800, val=0.0823, patience=3/15, lr=0.000004
   • Epoch   5/100: train=0.0800, val=0.0823, patience=4/15, lr=0.000004
   📉 Epoch 7: LR reduced 0.000004 → 0.000002
   • Epoch  11/100: train=0.0799, val=0.0823, patience=10/15, lr=0.000002
   📉 Epoch 15: LR reduced 0.000002 → 0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 7 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000004 → 0.000001 (2 reductions)
   Train: Loss=0.0802, RMSE=0.2831, R²=0.0193
   Val:   Loss=0.0823, RMSE=0.2869, R²=0.0671
============================================================


📊 Round 7 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2434, R²: 0.0349

============================================================
🔄 Round 8 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0761 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0761, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0761, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0761, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0761, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0762, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0761)

============================================================
📊 Round 8 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=0.0296
   Val:   Loss=0.0761, RMSE=0.2759, R²=0.0515
============================================================


📊 Round 8 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2436, R²: 0.0349

📊 Round 8 Test Metrics:
   Loss: 0.0792, RMSE: 0.2815, MAE: 0.2431, R²: 0.0394

📊 Round 8 Test Metrics:
   Loss: 0.0790, RMSE: 0.2811, MAE: 0.2425, R²: 0.0422

📊 Round 8 Test Metrics:
   Loss: 0.0789, RMSE: 0.2810, MAE: 0.2423, R²: 0.0430

📊 Round 8 Test Metrics:
   Loss: 0.0790, RMSE: 0.2810, MAE: 0.2422, R²: 0.0427

============================================================
🔄 Round 16 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 16 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2829, R²=0.0451
   Val:   Loss=0.0784, RMSE=0.2801, R²=0.0210
============================================================


📊 Round 16 Test Metrics:
   Loss: 0.0789, RMSE: 0.2809, MAE: 0.2420, R²: 0.0435

📊 Round 16 Test Metrics:
   Loss: 0.0789, RMSE: 0.2809, MAE: 0.2421, R²: 0.0430

============================================================
🔄 Round 20 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0771 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0771, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0771, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0771, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0771, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0771, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0771)

============================================================
📊 Round 20 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=0.0396
   Val:   Loss=0.0771, RMSE=0.2777, R²=0.0453
============================================================


============================================================
🔄 Round 21 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0762 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0762, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0762, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0762, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0762, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0762, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0762)

============================================================
📊 Round 21 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=0.0405
   Val:   Loss=0.0762, RMSE=0.2761, R²=0.0443
============================================================


📊 Round 21 Test Metrics:
   Loss: 0.0789, RMSE: 0.2809, MAE: 0.2419, R²: 0.0435

📊 Round 21 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2418, R²: 0.0438

📊 Round 21 Test Metrics:
   Loss: 0.0789, RMSE: 0.2809, MAE: 0.2418, R²: 0.0437

============================================================
🔄 Round 25 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0778, val=0.0868 (↓), lr=0.000001
   • Epoch   2/100: train=0.0778, val=0.0868, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0778, val=0.0868, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0778, val=0.0868, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0778, val=0.0868, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0777, val=0.0868, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0868)

============================================================
📊 Round 25 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0779, RMSE=0.2790, R²=0.0405
   Val:   Loss=0.0868, RMSE=0.2945, R²=0.0369
============================================================


============================================================
🔄 Round 26 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0774 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0774, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0774, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0774, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0774, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0774, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0774)

============================================================
📊 Round 26 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=0.0411
   Val:   Loss=0.0774, RMSE=0.2782, R²=0.0431
============================================================


============================================================
🔄 Round 29 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 29 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2810, R²=0.0467
   Val:   Loss=0.0822, RMSE=0.2867, R²=0.0198
============================================================


📊 Round 29 Test Metrics:
   Loss: 0.0789, RMSE: 0.2809, MAE: 0.2419, R²: 0.0436

============================================================
🔄 Round 31 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 31 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=0.0317
   Val:   Loss=0.0789, RMSE=0.2810, R²=0.0766
============================================================


============================================================
🔄 Round 32 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0777, val=0.0870 (↓), lr=0.000001
   • Epoch   2/100: train=0.0777, val=0.0870, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0777, val=0.0870, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0777, val=0.0870, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0777, val=0.0870, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0777, val=0.0870, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 32 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0778, RMSE=0.2789, R²=0.0322
   Val:   Loss=0.0870, RMSE=0.2950, R²=0.0734
============================================================


📊 Round 32 Test Metrics:
   Loss: 0.0789, RMSE: 0.2809, MAE: 0.2419, R²: 0.0436

============================================================
🔄 Round 33 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0782, val=0.0865 (↓), lr=0.000001
   • Epoch   2/100: train=0.0782, val=0.0865, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0782, val=0.0865, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0782, val=0.0866, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0782, val=0.0866, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0781, val=0.0866, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0865)

============================================================
📊 Round 33 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0779, RMSE=0.2791, R²=0.0440
   Val:   Loss=0.0865, RMSE=0.2942, R²=0.0292
============================================================


📊 Round 33 Test Metrics:
   Loss: 0.0789, RMSE: 0.2809, MAE: 0.2419, R²: 0.0435

============================================================
🔄 Round 35 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0785, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0785, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0785, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0785, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0785, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 35 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2800, R²=0.0465
   Val:   Loss=0.0845, RMSE=0.2907, R²=0.0216
============================================================


============================================================
🔄 Round 36 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0787, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 36 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2804, R²=0.0431
   Val:   Loss=0.0836, RMSE=0.2891, R²=0.0316
============================================================


============================================================
🔄 Round 38 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 38 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2822, R²=0.0447
   Val:   Loss=0.0795, RMSE=0.2820, R²=0.0277
============================================================


============================================================
🔄 Round 39 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 39 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2817, R²=0.0413
   Val:   Loss=0.0806, RMSE=0.2839, R²=0.0234
============================================================


============================================================
🔄 Round 40 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 40 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=0.0522
   Val:   Loss=0.0788, RMSE=0.2807, R²=-0.0041
============================================================


📊 Round 40 Test Metrics:
   Loss: 0.0789, RMSE: 0.2809, MAE: 0.2419, R²: 0.0435

============================================================
🔄 Round 43 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0771, val=0.0911 (↓), lr=0.000001
   • Epoch   2/100: train=0.0770, val=0.0911, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0770, val=0.0911, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0770, val=0.0911, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0770, val=0.0911, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0770, val=0.0911, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0911)

============================================================
📊 Round 43 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0768, RMSE=0.2770, R²=0.0490
   Val:   Loss=0.0911, RMSE=0.3019, R²=0.0124
============================================================


📊 Round 43 Test Metrics:
   Loss: 0.0789, RMSE: 0.2809, MAE: 0.2419, R²: 0.0435

📊 Round 43 Test Metrics:
   Loss: 0.0789, RMSE: 0.2809, MAE: 0.2419, R²: 0.0435

📊 Round 43 Test Metrics:
   Loss: 0.0789, RMSE: 0.2809, MAE: 0.2419, R²: 0.0434

============================================================
🔄 Round 48 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0763, val=0.0919 (↓), lr=0.000001
   • Epoch   2/100: train=0.0763, val=0.0920, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0763, val=0.0920, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0763, val=0.0920, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0763, val=0.0920, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0763, val=0.0920, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0919)

============================================================
📊 Round 48 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0765, RMSE=0.2767, R²=0.0494
   Val:   Loss=0.0919, RMSE=0.3032, R²=0.0080
============================================================


============================================================
🔄 Round 49 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0743 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0743, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0743, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0743, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0743, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0743, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0743)

============================================================
📊 Round 49 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2845, R²=0.0373
   Val:   Loss=0.0743, RMSE=0.2726, R²=0.0593
============================================================


============================================================
🔄 Round 51 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0782, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0782, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0782, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0782, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0782, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0782, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 51 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0783, RMSE=0.2799, R²=0.0396
   Val:   Loss=0.0847, RMSE=0.2911, R²=0.0482
============================================================


📊 Round 51 Test Metrics:
   Loss: 0.0789, RMSE: 0.2809, MAE: 0.2419, R²: 0.0433

============================================================
🔄 Round 52 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 52 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2819, R²=0.0512
   Val:   Loss=0.0803, RMSE=0.2834, R²=-0.0178
============================================================


📊 Round 52 Test Metrics:
   Loss: 0.0789, RMSE: 0.2809, MAE: 0.2419, R²: 0.0433

============================================================
🔄 Round 54 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0787, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 54 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2807, R²=0.0358
   Val:   Loss=0.0830, RMSE=0.2880, R²=0.0627
============================================================


📊 Round 54 Test Metrics:
   Loss: 0.0789, RMSE: 0.2809, MAE: 0.2419, R²: 0.0432

============================================================
🔄 Round 55 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0771 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0771, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0771, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0771, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0772, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0771)

============================================================
📊 Round 55 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2833, R²=0.0506
   Val:   Loss=0.0771, RMSE=0.2777, R²=-0.0083
============================================================


📊 Round 55 Test Metrics:
   Loss: 0.0789, RMSE: 0.2809, MAE: 0.2419, R²: 0.0432

============================================================
🔄 Round 56 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0706 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0706, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0706, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0706, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0706, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0706, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0706)

============================================================
📊 Round 56 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2861, R²=0.0416
   Val:   Loss=0.0706, RMSE=0.2657, R²=0.0417
============================================================


📊 Round 56 Test Metrics:
   Loss: 0.0789, RMSE: 0.2809, MAE: 0.2419, R²: 0.0431

============================================================
🔄 Round 59 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 59 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2801, R²=0.0504
   Val:   Loss=0.0843, RMSE=0.2903, R²=0.0067
============================================================


📊 Round 59 Test Metrics:
   Loss: 0.0789, RMSE: 0.2809, MAE: 0.2419, R²: 0.0431

============================================================
🔄 Round 60 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0752 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0752, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0752, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0752, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0752, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0752, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0752)

============================================================
📊 Round 60 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=0.0367
   Val:   Loss=0.0752, RMSE=0.2742, R²=0.0595
============================================================


============================================================
🔄 Round 62 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 62 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2812, R²=0.0375
   Val:   Loss=0.0819, RMSE=0.2861, R²=0.0558
============================================================


📊 Round 62 Test Metrics:
   Loss: 0.0789, RMSE: 0.2809, MAE: 0.2419, R²: 0.0431

📊 Round 62 Test Metrics:
   Loss: 0.0789, RMSE: 0.2809, MAE: 0.2419, R²: 0.0431

📊 Round 62 Test Metrics:
   Loss: 0.0789, RMSE: 0.2809, MAE: 0.2419, R²: 0.0431

============================================================
🔄 Round 66 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0766 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0766, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0766, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0766, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0766, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0766, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0766)

============================================================
📊 Round 66 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=0.0402
   Val:   Loss=0.0766, RMSE=0.2767, R²=0.0449
============================================================


📊 Round 66 Test Metrics:
   Loss: 0.0789, RMSE: 0.2809, MAE: 0.2419, R²: 0.0431

📊 Round 66 Test Metrics:
   Loss: 0.0789, RMSE: 0.2809, MAE: 0.2419, R²: 0.0431

📊 Round 66 Test Metrics:
   Loss: 0.0789, RMSE: 0.2809, MAE: 0.2419, R²: 0.0431

📊 Round 66 Test Metrics:
   Loss: 0.0789, RMSE: 0.2809, MAE: 0.2419, R²: 0.0430

📊 Round 66 Test Metrics:
   Loss: 0.0789, RMSE: 0.2809, MAE: 0.2419, R²: 0.0430

📊 Round 66 Test Metrics:
   Loss: 0.0789, RMSE: 0.2810, MAE: 0.2419, R²: 0.0430

📊 Round 66 Test Metrics:
   Loss: 0.0789, RMSE: 0.2810, MAE: 0.2419, R²: 0.0430

============================================================
🔄 Round 80 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0764 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0764, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0764, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0764, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0764, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0764, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0764)

============================================================
📊 Round 80 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=0.0343
   Val:   Loss=0.0764, RMSE=0.2763, R²=0.0705
============================================================


📊 Round 80 Test Metrics:
   Loss: 0.0789, RMSE: 0.2810, MAE: 0.2419, R²: 0.0430

📊 Round 80 Test Metrics:
   Loss: 0.0789, RMSE: 0.2810, MAE: 0.2419, R²: 0.0430

📊 Round 80 Test Metrics:
   Loss: 0.0789, RMSE: 0.2810, MAE: 0.2419, R²: 0.0429

📊 Round 80 Test Metrics:
   Loss: 0.0789, RMSE: 0.2810, MAE: 0.2419, R²: 0.0429

============================================================
🔄 Round 87 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 87 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2818, R²=0.0334
   Val:   Loss=0.0805, RMSE=0.2837, R²=0.0728
============================================================


📊 Round 87 Test Metrics:
   Loss: 0.0789, RMSE: 0.2810, MAE: 0.2419, R²: 0.0428

📊 Round 87 Test Metrics:
   Loss: 0.0789, RMSE: 0.2810, MAE: 0.2419, R²: 0.0429

============================================================
🔄 Round 89 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 89 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=0.0438
   Val:   Loss=0.0794, RMSE=0.2818, R²=0.0323
============================================================


📊 Round 89 Test Metrics:
   Loss: 0.0789, RMSE: 0.2810, MAE: 0.2419, R²: 0.0428

📊 Round 89 Test Metrics:
   Loss: 0.0789, RMSE: 0.2810, MAE: 0.2419, R²: 0.0428

============================================================
🔄 Round 92 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0754 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0754, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0754, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0754, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0754, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0754, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0754)

============================================================
📊 Round 92 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2840, R²=0.0423
   Val:   Loss=0.0754, RMSE=0.2746, R²=0.0381
============================================================


============================================================
🔄 Round 93 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0717 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0717, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0717, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0717, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0717, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0718, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0717)

============================================================
📊 Round 93 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=0.0490
   Val:   Loss=0.0717, RMSE=0.2678, R²=0.0049
============================================================


============================================================
🔄 Round 94 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 94 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2809, R²=0.0420
   Val:   Loss=0.0826, RMSE=0.2873, R²=0.0192
============================================================


📊 Round 94 Test Metrics:
   Loss: 0.0790, RMSE: 0.2810, MAE: 0.2419, R²: 0.0427

============================================================
🔄 Round 96 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 96 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2817, R²=0.0547
   Val:   Loss=0.0807, RMSE=0.2841, R²=-0.0145
============================================================


📊 Round 96 Test Metrics:
   Loss: 0.0790, RMSE: 0.2810, MAE: 0.2419, R²: 0.0427

============================================================
🔄 Round 97 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 97 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2810, R²=0.0321
   Val:   Loss=0.0822, RMSE=0.2868, R²=0.0718
============================================================


📊 Round 97 Test Metrics:
   Loss: 0.0790, RMSE: 0.2810, MAE: 0.2420, R²: 0.0427

📊 Round 97 Test Metrics:
   Loss: 0.0790, RMSE: 0.2810, MAE: 0.2420, R²: 0.0427

📊 Round 97 Test Metrics:
   Loss: 0.0790, RMSE: 0.2810, MAE: 0.2420, R²: 0.0427

============================================================
🔄 Round 101 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 101 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2820, R²=0.0347
   Val:   Loss=0.0799, RMSE=0.2826, R²=0.0593
============================================================


============================================================
🔄 Round 102 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 102 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=0.0493
   Val:   Loss=0.0789, RMSE=0.2809, R²=0.0076
============================================================


============================================================
🔄 Round 103 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0778, val=0.0876 (↓), lr=0.000001
   • Epoch   2/100: train=0.0778, val=0.0876, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0778, val=0.0876, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0778, val=0.0876, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0778, val=0.0876, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0778, val=0.0876, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0876)

============================================================
📊 Round 103 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0776, RMSE=0.2786, R²=0.0480
   Val:   Loss=0.0876, RMSE=0.2959, R²=0.0152
============================================================


📊 Round 103 Test Metrics:
   Loss: 0.0790, RMSE: 0.2810, MAE: 0.2420, R²: 0.0427

📊 Round 103 Test Metrics:
   Loss: 0.0790, RMSE: 0.2810, MAE: 0.2420, R²: 0.0427

📊 Round 103 Test Metrics:
   Loss: 0.0790, RMSE: 0.2810, MAE: 0.2420, R²: 0.0426

📊 Round 103 Test Metrics:
   Loss: 0.0790, RMSE: 0.2810, MAE: 0.2419, R²: 0.0427

============================================================
🔄 Round 108 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 108 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=0.0430
   Val:   Loss=0.0781, RMSE=0.2795, R²=0.0333
============================================================


📊 Round 108 Test Metrics:
   Loss: 0.0790, RMSE: 0.2810, MAE: 0.2420, R²: 0.0426

📊 Round 108 Test Metrics:
   Loss: 0.0790, RMSE: 0.2810, MAE: 0.2420, R²: 0.0425

============================================================
🔄 Round 115 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 115 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2819, R²=0.0370
   Val:   Loss=0.0802, RMSE=0.2832, R²=0.0506
============================================================


============================================================
🔄 Round 117 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 117 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2817, R²=0.0412
   Val:   Loss=0.0807, RMSE=0.2840, R²=0.0432
============================================================


📊 Round 117 Test Metrics:
   Loss: 0.0790, RMSE: 0.2810, MAE: 0.2420, R²: 0.0425

============================================================
🔄 Round 119 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0760, val=0.0947 (↓), lr=0.000001
   • Epoch   2/100: train=0.0760, val=0.0947, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0760, val=0.0947, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0760, val=0.0947, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0760, val=0.0947, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0760, val=0.0947, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0947)

============================================================
📊 Round 119 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0758, RMSE=0.2754, R²=0.0392
   Val:   Loss=0.0947, RMSE=0.3078, R²=0.0495
============================================================


📊 Round 119 Test Metrics:
   Loss: 0.0790, RMSE: 0.2810, MAE: 0.2420, R²: 0.0425

============================================================
🔄 Round 120 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 120 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=0.0539
   Val:   Loss=0.0793, RMSE=0.2817, R²=-0.0150
============================================================


============================================================
🔄 Round 122 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 122 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2803, R²=0.0361
   Val:   Loss=0.0837, RMSE=0.2893, R²=0.0599
============================================================


============================================================
🔄 Round 123 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 123 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2813, R²=0.0366
   Val:   Loss=0.0816, RMSE=0.2856, R²=0.0560
============================================================


============================================================
🔄 Round 124 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0785, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0785, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0785, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0785, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0785, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 124 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2806, R²=0.0402
   Val:   Loss=0.0832, RMSE=0.2885, R²=0.0437
============================================================


============================================================
🔄 Round 126 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0743 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0743, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0743, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0743, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0743, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0743, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0743)

============================================================
📊 Round 126 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2845, R²=0.0370
   Val:   Loss=0.0743, RMSE=0.2726, R²=0.0618
============================================================


📊 Round 126 Test Metrics:
   Loss: 0.0790, RMSE: 0.2811, MAE: 0.2420, R²: 0.0423

============================================================
🔄 Round 132 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 132 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2822, R²=0.0370
   Val:   Loss=0.0795, RMSE=0.2820, R²=0.0605
============================================================


📊 Round 132 Test Metrics:
   Loss: 0.0790, RMSE: 0.2811, MAE: 0.2420, R²: 0.0422

📊 Round 132 Test Metrics:
   Loss: 0.0790, RMSE: 0.2811, MAE: 0.2420, R²: 0.0421

============================================================
🔄 Round 136 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 136 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2809, R²=0.0292
   Val:   Loss=0.0823, RMSE=0.2869, R²=0.0847
============================================================


📊 Round 136 Test Metrics:
   Loss: 0.0790, RMSE: 0.2811, MAE: 0.2420, R²: 0.0421

============================================================
🔄 Round 137 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0785, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0785, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0785, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0785, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 137 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2803, R²=0.0497
   Val:   Loss=0.0838, RMSE=0.2895, R²=0.0067
============================================================


📊 Round 137 Test Metrics:
   Loss: 0.0790, RMSE: 0.2811, MAE: 0.2420, R²: 0.0421

============================================================
🔄 Round 138 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0699 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0699, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0699, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0699, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0699, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0700, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0699)

============================================================
📊 Round 138 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=0.0474
   Val:   Loss=0.0699, RMSE=0.2645, R²=0.0115
============================================================


============================================================
🔄 Round 139 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0779, val=0.0869 (↓), lr=0.000001
   • Epoch   2/100: train=0.0779, val=0.0869, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0779, val=0.0869, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0778, val=0.0870, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0778, val=0.0870, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0778, val=0.0870, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 139 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0778, RMSE=0.2789, R²=0.0424
   Val:   Loss=0.0869, RMSE=0.2948, R²=0.0228
============================================================


📊 Round 139 Test Metrics:
   Loss: 0.0790, RMSE: 0.2811, MAE: 0.2420, R²: 0.0421

📊 Round 139 Test Metrics:
   Loss: 0.0790, RMSE: 0.2811, MAE: 0.2420, R²: 0.0421

📊 Round 139 Test Metrics:
   Loss: 0.0790, RMSE: 0.2811, MAE: 0.2420, R²: 0.0421

============================================================
🔄 Round 143 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 143 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=0.0414
   Val:   Loss=0.0781, RMSE=0.2795, R²=0.0407
============================================================


============================================================
🔄 Round 144 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 144 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=0.0464
   Val:   Loss=0.0792, RMSE=0.2814, R²=0.0220
============================================================


📊 Round 144 Test Metrics:
   Loss: 0.0790, RMSE: 0.2811, MAE: 0.2420, R²: 0.0421

============================================================
🔄 Round 145 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 145 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2821, R²=0.0422
   Val:   Loss=0.0798, RMSE=0.2825, R²=0.0326
============================================================


📊 Round 145 Test Metrics:
   Loss: 0.0790, RMSE: 0.2811, MAE: 0.2420, R²: 0.0420

📊 Round 145 Test Metrics:
   Loss: 0.0790, RMSE: 0.2811, MAE: 0.2420, R²: 0.0420

============================================================
🔄 Round 152 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0696 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0696, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0696, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0696, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0696, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0697, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0696)

============================================================
📊 Round 152 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=0.0368
   Val:   Loss=0.0696, RMSE=0.2638, R²=0.0614
============================================================


📊 Round 152 Test Metrics:
   Loss: 0.0790, RMSE: 0.2811, MAE: 0.2420, R²: 0.0420

============================================================
🔄 Round 154 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 154 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2819, R²=0.0375
   Val:   Loss=0.0801, RMSE=0.2830, R²=0.0515
============================================================


============================================================
🔄 Round 155 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 155 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2814, R²=0.0385
   Val:   Loss=0.0812, RMSE=0.2850, R²=0.0446
============================================================


📊 Round 155 Test Metrics:
   Loss: 0.0790, RMSE: 0.2811, MAE: 0.2420, R²: 0.0419

============================================================
🔄 Round 156 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0770 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0770, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0770, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0770, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0770, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0770, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0770)

============================================================
📊 Round 156 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2833, R²=0.0426
   Val:   Loss=0.0770, RMSE=0.2775, R²=0.0378
============================================================


📊 Round 156 Test Metrics:
   Loss: 0.0790, RMSE: 0.2811, MAE: 0.2420, R²: 0.0419

============================================================
🔄 Round 158 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 158 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2811, R²=0.0360
   Val:   Loss=0.0821, RMSE=0.2865, R²=0.0086
============================================================


============================================================
🔄 Round 159 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0787, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 159 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2803, R²=0.0478
   Val:   Loss=0.0838, RMSE=0.2895, R²=0.0171
============================================================


📊 Round 159 Test Metrics:
   Loss: 0.0790, RMSE: 0.2811, MAE: 0.2421, R²: 0.0419

📊 Round 159 Test Metrics:
   Loss: 0.0790, RMSE: 0.2811, MAE: 0.2421, R²: 0.0419

============================================================
🔄 Round 162 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0778, val=0.0877 (↓), lr=0.000001
   • Epoch   2/100: train=0.0778, val=0.0877, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0778, val=0.0877, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0778, val=0.0877, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0778, val=0.0877, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0778, val=0.0877, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0877)

============================================================
📊 Round 162 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0776, RMSE=0.2785, R²=0.0449
   Val:   Loss=0.0877, RMSE=0.2962, R²=0.0304
============================================================


📊 Round 162 Test Metrics:
   Loss: 0.0790, RMSE: 0.2811, MAE: 0.2421, R²: 0.0418

📊 Round 162 Test Metrics:
   Loss: 0.0790, RMSE: 0.2811, MAE: 0.2421, R²: 0.0418

============================================================
🔄 Round 164 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 164 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2809, R²=0.0479
   Val:   Loss=0.0824, RMSE=0.2870, R²=0.0097
============================================================


============================================================
🔄 Round 166 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0782, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0782, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0782, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0782, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0782, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0782, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 166 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0782, RMSE=0.2797, R²=0.0401
   Val:   Loss=0.0852, RMSE=0.2919, R²=0.0448
============================================================


============================================================
🔄 Round 167 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0739 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0740, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0740, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0739, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0739, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0740, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0739)

============================================================
📊 Round 167 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=0.0455
   Val:   Loss=0.0739, RMSE=0.2719, R²=0.0211
============================================================


📊 Round 167 Test Metrics:
   Loss: 0.0790, RMSE: 0.2811, MAE: 0.2421, R²: 0.0417

============================================================
🔄 Round 176 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0781, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0781, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0781, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0781, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0781, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0781, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 176 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0782, RMSE=0.2797, R²=0.0444
   Val:   Loss=0.0851, RMSE=0.2917, R²=0.0260
============================================================


============================================================
🔄 Round 177 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0782, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0782, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0782, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0782, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0782, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0782, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 177 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0783, RMSE=0.2799, R²=0.0392
   Val:   Loss=0.0847, RMSE=0.2910, R²=0.0461
============================================================


📊 Round 177 Test Metrics:
   Loss: 0.0790, RMSE: 0.2811, MAE: 0.2421, R²: 0.0416

📊 Round 177 Test Metrics:
   Loss: 0.0790, RMSE: 0.2812, MAE: 0.2421, R²: 0.0416

============================================================
🔄 Round 181 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 181 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2802, R²=0.0348
   Val:   Loss=0.0839, RMSE=0.2897, R²=0.0657
============================================================


============================================================
🔄 Round 182 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 182 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2809, R²=0.0457
   Val:   Loss=0.0823, RMSE=0.2869, R²=0.0240
============================================================


📊 Round 182 Test Metrics:
   Loss: 0.0791, RMSE: 0.2812, MAE: 0.2421, R²: 0.0415

📊 Round 182 Test Metrics:
   Loss: 0.0791, RMSE: 0.2812, MAE: 0.2421, R²: 0.0415

============================================================
🔄 Round 186 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0781, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0781, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0781, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0781, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0781, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0781, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 186 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0781, RMSE=0.2794, R²=0.0412
   Val:   Loss=0.0858, RMSE=0.2929, R²=0.0437
============================================================


📊 Round 186 Test Metrics:
   Loss: 0.0791, RMSE: 0.2812, MAE: 0.2421, R²: 0.0414

📊 Round 186 Test Metrics:
   Loss: 0.0791, RMSE: 0.2812, MAE: 0.2421, R²: 0.0413

📊 Round 186 Test Metrics:
   Loss: 0.0791, RMSE: 0.2812, MAE: 0.2421, R²: 0.0413

📊 Round 186 Test Metrics:
   Loss: 0.0791, RMSE: 0.2812, MAE: 0.2421, R²: 0.0413

📊 Round 186 Test Metrics:
   Loss: 0.0791, RMSE: 0.2812, MAE: 0.2422, R²: 0.0412

============================================================
🔄 Round 192 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 192 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=0.0385
   Val:   Loss=0.0789, RMSE=0.2809, R²=0.0538
============================================================


============================================================
🔄 Round 193 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0783, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0783, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0783, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0783, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0783, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 193 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0781, RMSE=0.2795, R²=0.0435
   Val:   Loss=0.0856, RMSE=0.2925, R²=0.0352
============================================================


📊 Round 193 Test Metrics:
   Loss: 0.0791, RMSE: 0.2812, MAE: 0.2422, R²: 0.0412

============================================================
🔄 Round 195 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 195 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2822, R²=0.0454
   Val:   Loss=0.0794, RMSE=0.2818, R²=0.0155
============================================================


📊 Round 195 Test Metrics:
   Loss: 0.0791, RMSE: 0.2812, MAE: 0.2422, R²: 0.0412

📊 Round 195 Test Metrics:
   Loss: 0.0791, RMSE: 0.2812, MAE: 0.2422, R²: 0.0412

📊 Round 195 Test Metrics:
   Loss: 0.0791, RMSE: 0.2812, MAE: 0.2422, R²: 0.0411

📊 Round 195 Test Metrics:
   Loss: 0.0791, RMSE: 0.2812, MAE: 0.2422, R²: 0.0410

============================================================
🔄 Round 210 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 210 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2810, R²=0.0302
   Val:   Loss=0.0821, RMSE=0.2866, R²=0.0698
============================================================


📊 Round 210 Test Metrics:
   Loss: 0.0791, RMSE: 0.2812, MAE: 0.2422, R²: 0.0410

📊 Round 210 Test Metrics:
   Loss: 0.0791, RMSE: 0.2812, MAE: 0.2422, R²: 0.0410

============================================================
🔄 Round 213 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0743 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0743, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0743, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0743, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0743, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0743, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0743)

============================================================
📊 Round 213 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2845, R²=0.0438
   Val:   Loss=0.0743, RMSE=0.2725, R²=0.0229
============================================================


📊 Round 213 Test Metrics:
   Loss: 0.0791, RMSE: 0.2812, MAE: 0.2422, R²: 0.0410

============================================================
🔄 Round 215 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0771, val=0.0891 (↓), lr=0.000001
   • Epoch   2/100: train=0.0771, val=0.0891, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0771, val=0.0891, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0771, val=0.0891, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0771, val=0.0891, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0770, val=0.0891, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0891)

============================================================
📊 Round 215 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0772, RMSE=0.2779, R²=0.0445
   Val:   Loss=0.0891, RMSE=0.2984, R²=0.0321
============================================================


📊 Round 215 Test Metrics:
   Loss: 0.0791, RMSE: 0.2812, MAE: 0.2422, R²: 0.0409

============================================================
🔄 Round 216 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 216 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2822, R²=0.0301
   Val:   Loss=0.0794, RMSE=0.2818, R²=0.0829
============================================================


📊 Round 216 Test Metrics:
   Loss: 0.0791, RMSE: 0.2813, MAE: 0.2422, R²: 0.0408

============================================================
🔄 Round 219 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0732 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0732, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0732, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0732, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0732, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0732, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0732)

============================================================
📊 Round 219 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=0.0340
   Val:   Loss=0.0732, RMSE=0.2706, R²=0.0744
============================================================


📊 Round 219 Test Metrics:
   Loss: 0.0791, RMSE: 0.2813, MAE: 0.2422, R²: 0.0409

============================================================
🔄 Round 220 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 220 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2818, R²=0.0314
   Val:   Loss=0.0803, RMSE=0.2834, R²=0.0771
============================================================


📊 Round 220 Test Metrics:
   Loss: 0.0791, RMSE: 0.2813, MAE: 0.2422, R²: 0.0409

============================================================
🔄 Round 221 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0747 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0747, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0747, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0747, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0747, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0747, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0747)

============================================================
📊 Round 221 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=0.0455
   Val:   Loss=0.0747, RMSE=0.2734, R²=0.0253
============================================================


📊 Round 221 Test Metrics:
   Loss: 0.0791, RMSE: 0.2813, MAE: 0.2422, R²: 0.0409

============================================================
🔄 Round 224 - Client client_12
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0785, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 224 Summary - Client client_12
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2802, R²=0.0499
   Val:   Loss=0.0840, RMSE=0.2899, R²=0.0033
============================================================


❌ Client client_12 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8687 {grpc_status:14, grpc_message:"Socket closed"}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8687 {grpc_status:14, grpc_message:"Socket closed"}"
>
