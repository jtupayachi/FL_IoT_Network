[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 03d2be23-8019-4b4f-b5b4-4e6f1b48f0d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2e12c86a-e768-4725-8e39-aae682c4e76e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d1ecb57c-8b06-4b3c-b498-d1f4739d8709
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 84df1d48-de0d-4eab-ba1c-bdb86dba41eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0cbdbe15-09cf-49e2-8e0a-33f46b3c8377
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a0016a42-d8f6-4048-9a1d-6800cc520036
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3e5a5e3c-803c-4a9b-af42-a7fb24be1d8c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a5e78df5-ba6d-4fbd-8d9d-11981fefe75b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f2290b6e-8cf2-43c6-a3b5-7aa540568799
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 71d586a0-04e9-4367-aedf-f76e574b7855
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9a995544-3847-47ff-bd8d-1152a4c144ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ef1d897e-ac8b-489d-b42b-1480924e2c2f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 48be90c5-58c2-4190-b257-b7bf17bab02b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f44841e4-53d7-4fa5-918c-7d0b4be46931
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 14783cd9-ed34-4b28-a8c9-f91d378674a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 09a97750-ecbd-4516-8377-6c7d516afb69
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c6797374-7ab1-474e-9129-a58751c670ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 660fe960-46a9-4e6e-a8dd-1c2991c40586
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 21692b99-b786-4d96-b3f3-836bc48251bc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7cf001a7-7bfc-45c3-a9d3-7f0c44262e44
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 901f38f8-a5b7-4c7c-b51b-22b746d217ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a5aaa5e1-157e-4345-9cf9-977eb8aa17f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 509b7bc8-ca7d-49b0-bd7b-31847bd0ce7b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 233909a4-db18-4a50-b612-135aba8dc057
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e346d71c-98bd-4ac1-9a9f-76868ec17059
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 76cb9f62-a420-4440-acb4-3f1d42e3293a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 16f02fd0-a3a3-4f60-b1ec-ba96a6b86a71
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7400ea81-6d3b-4437-8d55-165f022c940d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f1611aa0-70af-4ac2-9772-4f66c360bf79
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 09b7eda1-87dc-4943-8664-7d9cb6b7ddf9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9dd6b3f3-69ad-4dd9-a141-0b17c099f525
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f426ebd5-924d-42e1-8eab-3b331794d024
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2abf0f09-aa78-4dbe-adb5-a5fe8a2ae1dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 05fd4917-b5b5-48a8-979e-1b8c13b985a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 98c41d1d-ad68-421a-94b6-5d0715331c3d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 91892ae8-f662-4ef7-b89a-c9c785a96e71
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message de6e4bde-f9cc-4b73-a5c8-12ecc869426c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a5c7e0d2-c3e4-4d45-8cc8-fc5c2036a9ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message abff23e8-9188-465c-9cdb-2877ed8b2bc6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8761f46e-0ce7-4d4c-9a03-b99eac346aaf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5e3b787e-c7a4-4d47-a242-a873b6415eca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f5e62f95-aab9-4ba9-a856-15fd2e20c6bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b4675d39-7dce-4ba6-a56a-5c8d505ce9e2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 38204163-df5b-418e-a3e0-928687b2ac06
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1e55019f-45a9-4477-a10f-5c1ce7851694
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2af02845-ef48-4171-afa1-b3989cfe3770
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message df842eed-f754-4600-a55e-118b86feb5d9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 37345950-bb23-466f-9dac-707bd6759d5e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 978bb7ac-d9cc-4ed0-9e06-a68c42884739
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b81b2a5d-9504-4637-b79e-6db4f07ebe64
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0360b29b-351c-4fe2-adba-2ab32c1a1de1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f1c9e4e3-f38a-4b5a-9341-b726b1dc7f25
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 231c2d34-6b2a-4478-9113-4ea8f7949cc3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d4b7b759-ac16-4f7b-b90b-a63f5121e0cb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4c3ed46c-b094-46b8-bf13-1e647934926c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 89b89e4e-7977-4615-b068-0a091c17adc6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fbee62d3-ff36-4c50-b3a9-a3d692ec5b9d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dc7644b5-9ad8-4ffa-85c2-a2572fe8a52e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8dfdfd51-63bc-44f8-815d-5a7bb2749135
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 962accdb-00bb-4d8f-aac5-1dabcabfffe5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 24b736e7-d979-4b48-a5fc-d30819889371
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ec161ada-967c-4fe9-9dd3-069278b728ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7088b5de-067f-4c17-9c80-0604b40d6241
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1a626d86-1d80-4583-a48e-e7117f3b7b77
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 21384915-c5dc-4807-84a9-ce1454046484
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3dbb37b2-21dc-4950-9950-8780a86eba7c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 04d3500a-866c-46a6-b4f0-ad86063c4177
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 59fd1bc4-cd9b-4522-ba11-9568518b0300
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4989906b-5b72-4988-834c-2dc8fc169305
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 92791d4b-354f-4eeb-936b-afc7429def23
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c75a1919-9ba4-4253-a3f7-b98b76795fe8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6a0ce6a1-8254-4e18-8a38-7a55fa7d9785
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 787cec2c-75c6-47a9-8876-fcba9607d9a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 69dc71bb-c515-47b8-879c-1e8d63558cc9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message deed15b2-b625-4e28-8e79-f3b5f6e9eb75
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fccc2e97-bab5-45a6-9afc-70657a3a0355
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 24463398-deae-45bb-b69c-071b0f3045ce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 65054ccf-69e2-4f65-beca-d087f8699aac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 276aff6c-dbc6-4526-b3fe-d4daaacb11af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0339de17-4a74-4e2a-9932-70f4d1180585
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ad4a2fe7-71d5-4b71-98ca-a401bd1ff434
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3df07049-646d-4e5d-8737-80eeaa6bedb8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 77aace7c-fe7d-4554-87ec-e0c4a4954dfa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f4292c4f-a836-43fd-a7f5-b4bc9a2e6f8f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b243ef2b-c28b-44c0-8352-87c8aa69f6e8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 76cd84a9-a4ab-48f7-a99e-a8468d7509fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e9800007-967e-4c5f-93b9-21e66e45d46f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a380c56c-d29f-4acd-84e0-c9b776cb58c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ad4f8c87-d381-4149-bc30-2b75806b6f58
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f8895dc6-5f5b-4249-81f3-f475e35a5c56
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0439d21e-7521-4b30-8c6f-36a533a7bb0e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8416b1b5-f233-4996-b423-201136884532
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 21cb23c0-52a8-47a8-8a9f-bad0ef54bbd6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fe592805-6ff6-42e7-9fd5-60c6b01d4233
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bc328e4d-f152-49de-9f17-c4a0d4149c4a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 31ac3545-800f-4474-9a55-e6129a83bbf0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message acd30382-7359-4ecb-aca1-829112891c39
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4b91fdee-91ed-476d-b22a-4a7754291cc6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c29343bb-023f-4fd0-8577-58a5d1fb5450
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1c323c71-2a62-4d21-b097-9d46c6a98ab9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0a7a9a3e-4485-4102-8058-9fd7363ae82c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f917952c-85a8-4c34-baad-0dcdc60d3d12
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 06675bc7-4771-4f6a-b01b-a97a87aa985f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9089bd63-0001-438c-8312-7b4dfadec359
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b0f3b3fe-0936-4333-aefb-4a42cc29c3ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8ce61cdf-0dcd-47cc-9cd1-8d110b221665
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d25bbc3a-45e4-44d3-887f-9dc8967a3aed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a97ab0d1-3fce-4acf-83c9-f36bfd4051a7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7e20b030-b2bd-4209-9b7d-0c96c18a71b0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 85668798-d602-4bdb-83a3-5222674b1855
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8942c305-fb5c-476f-980c-74fcbc1d7798
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aaf7d679-b282-4a8d-be0f-66d99ffe179b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a90bbafd-4d85-41b5-9ad7-640961c24d3c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2cf8e47d-d7a4-4ca4-8f3f-be8fefc74bbc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 09dbd678-1ef9-46e4-9b49-e2ebac577cfb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 791963f9-b4bc-4f65-ac95-e5bf99554cb4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a44cf09e-cebe-4a08-b72a-81d771e0435f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 63810e21-4a02-4711-abc4-c37c844a54bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e37d706b-837c-49ef-98d6-7a756ae1b524
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f118a224-439f-41d1-b31e-23f4d9ec8a09
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6f86f8ce-bcee-4f4f-af29-d796dbff87f2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1906d794-6bf4-4489-b723-ec7f54363026
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 142047a0-77a7-4cf8-a540-bede11277a39
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c5fc7194-4de7-497e-a955-4cb31665997e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8d32a1b9-ac8b-42f2-a044-06f839f1c853
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a28a454b-4f89-4674-b96f-9a8ad4d37807
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ce06c688-1b51-4060-9a64-b2cdb1fd1093
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 38c1d667-3aa0-4e91-9fb9-6e57ae69865b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7e0d61bd-0a4c-4f15-b20a-eb018af467b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b5fcb8a5-b9be-4c73-839c-0610125e28b8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 728b4fc5-56ec-4b93-bc83-f0d2cf9c04d1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 783ce7dc-1e31-40e2-9440-a437f07b865c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c262c776-f537-4d4d-aed9-1c478a1d4134
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 818a40a8-0516-4252-b2c9-fd157b5e4ff9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9cec2b9d-7911-4db5-8bfe-e9b659f03cc2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 109d68a4-2f34-4678-912b-76b4d44afa01
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6f0e2362-dfda-47fb-8b39-6ddca95970f8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 707936ef-22e1-401a-870a-e31a2423d1a3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 63a76956-9fa5-493b-86a0-0bb931232789
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0e562584-c027-452b-b02c-fde7478e0f1c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b5f1b6b3-ded3-4f5a-a421-8f5db02bd41a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 74c3625c-f2f6-439a-aea6-4fa3aad1b66c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2b562a88-dead-47ef-8c3e-8505039fbb5a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 29cdc13a-dc7d-4337-bee8-0b44c54688cd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8671ed64-1a4c-478e-ba7e-889a17e28073
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b212040c-d5ab-425b-8f41-765ef2c070da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cfbb892e-1a3d-4c40-8d52-e8507278cc4e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fad497c2-b9b9-42b9-91c4-bc91a81ef6e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dacf7a78-c669-48b5-ae41-2ce3fcfb571f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 389d38de-744d-4f39-8e1e-19982e036f0f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b3080c88-ad29-4cb8-b712-7013b6a10a33
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 43b682a1-b5c8-44a2-8e6c-65bb32e2c2a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ea47b858-db17-4b8e-9ef1-a6bb296d1541
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b79121eb-8535-4968-858a-487dbdcd33b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9e559ab9-0b56-4d58-aea1-102defd9f033
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c9c0f43c-a056-4083-b3ca-2354d4c6575b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d441029e-54c9-4f13-9e27-c732e7a011ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8751f744-9f20-41a6-8982-daaf85b0ec1e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f2cf3aaa-97f2-4bef-8367-c1a92af3e40d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8fc97fc1-b252-426f-a4e9-b41ba7c61004
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cd6e72ff-4ddf-4098-92e3-7eb695d362f3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 808904ad-f635-4c93-b507-c75f78127b54
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4c31c651-7537-4d99-b67c-8f01892364ea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ecb04de7-3702-450b-909b-58b99862ef50
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 410dc078-2965-43ef-9973-be30a1edc5be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ecb45e6b-f64b-4687-b1bd-715911e916c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1a2a307b-6dfb-41c9-9ac6-14f4998a55ff
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8687 {grpc_status:14, grpc_message:"Socket closed"}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_13
Server: localhost:8687
Algorithm: FEDAVG
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_13
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_13/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_13/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_13/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_13/test_labels.txt

📊 Raw data loaded:
   Train: X=(1098, 24), y=(1098,)
   Test:  X=(275, 24), y=(275,)

⚠️  Limiting training data: 1098 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  266 samples, 5 features
✅ Client client_13 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

📊 Round 0 Test Metrics:
   Loss: 0.0921, RMSE: 0.3034, MAE: 0.2693, R²: -0.0090

📊 Round 0 Test Metrics:
   Loss: 0.0927, RMSE: 0.3045, MAE: 0.2703, R²: -0.0165

📊 Round 0 Test Metrics:
   Loss: 0.0933, RMSE: 0.3054, MAE: 0.2713, R²: -0.0221

============================================================
🔄 Round 5 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0859 (↓), lr=0.001000
   ✓ Epoch   2/100: train=0.0800, val=0.0842 (↓), lr=0.001000
   • Epoch   3/100: train=0.0797, val=0.0837, patience=1/15, lr=0.001000
   • Epoch   4/100: train=0.0786, val=0.0840, patience=2/15, lr=0.001000
   • Epoch   5/100: train=0.0780, val=0.0841, patience=3/15, lr=0.001000
   📉 Epoch 9: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0759, val=0.0847, patience=9/15, lr=0.000500
   📉 Epoch 17: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 5 Summary - Client client_13
   Epochs: 17/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0771, RMSE=0.2777, R²=0.0163
   Val:   Loss=0.0842, RMSE=0.2901, R²=-0.0336
============================================================


============================================================
🔄 Round 6 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0781, val=0.0845 (↓), lr=0.000250
   • Epoch   2/100: train=0.0775, val=0.0846, patience=1/15, lr=0.000250
   • Epoch   3/100: train=0.0771, val=0.0847, patience=2/15, lr=0.000250
   • Epoch   4/100: train=0.0770, val=0.0846, patience=3/15, lr=0.000250
   • Epoch   5/100: train=0.0768, val=0.0845, patience=4/15, lr=0.000250
   📉 Epoch 8: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0764, val=0.0843, patience=10/15, lr=0.000125
   📉 Epoch 16: LR reduced 0.000125 → 0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 6 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000250 → 0.000063 (2 reductions)
   Train: Loss=0.0778, RMSE=0.2789, R²=0.0054
   Val:   Loss=0.0845, RMSE=0.2908, R²=-0.0219
============================================================


============================================================
🔄 Round 7 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0815 (↓), lr=0.000063
   • Epoch   2/100: train=0.0791, val=0.0816, patience=1/15, lr=0.000063
   • Epoch   3/100: train=0.0789, val=0.0817, patience=2/15, lr=0.000063
   • Epoch   4/100: train=0.0788, val=0.0816, patience=3/15, lr=0.000063
   • Epoch   5/100: train=0.0787, val=0.0815, patience=4/15, lr=0.000063
   • Epoch  11/100: train=0.0783, val=0.0814, patience=10/15, lr=0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 7 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000063 → 0.000063 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2811, R²=-0.0009
   Val:   Loss=0.0815, RMSE=0.2855, R²=-0.0390
============================================================


📊 Round 7 Test Metrics:
   Loss: 0.0957, RMSE: 0.3094, MAE: 0.2747, R²: -0.0493

📊 Round 7 Test Metrics:
   Loss: 0.0957, RMSE: 0.3094, MAE: 0.2744, R²: -0.0491

============================================================
🔄 Round 10 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0788 (↓), lr=0.000063
   • Epoch   2/100: train=0.0796, val=0.0793, patience=1/15, lr=0.000063
   • Epoch   3/100: train=0.0794, val=0.0793, patience=2/15, lr=0.000063
   • Epoch   4/100: train=0.0792, val=0.0791, patience=3/15, lr=0.000063
   • Epoch   5/100: train=0.0791, val=0.0789, patience=4/15, lr=0.000063
   • Epoch  11/100: train=0.0787, val=0.0786, patience=10/15, lr=0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 10 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000063 → 0.000063 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2829, R²=-0.0078
   Val:   Loss=0.0788, RMSE=0.2808, R²=-0.0258
============================================================


============================================================
🔄 Round 11 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0841 (↓), lr=0.000063
   • Epoch   2/100: train=0.0784, val=0.0839, patience=1/15, lr=0.000063
   • Epoch   3/100: train=0.0782, val=0.0837, patience=2/15, lr=0.000063
   • Epoch   4/100: train=0.0780, val=0.0837, patience=3/15, lr=0.000063
   📉 Epoch 5: LR reduced 0.000063 → 0.000031
   • Epoch   5/100: train=0.0779, val=0.0836, patience=4/15, lr=0.000031
   • Epoch  11/100: train=0.0777, val=0.0835, patience=5/15, lr=0.000031
   📉 Epoch 13: LR reduced 0.000031 → 0.000016
   📉 Epoch 21: LR reduced 0.000016 → 0.000008
   • Epoch  21/100: train=0.0775, val=0.0835, patience=15/15, lr=0.000008

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 11 Summary - Client client_13
   Epochs: 21/100 (early stopped)
   LR: 0.000063 → 0.000008 (3 reductions)
   Train: Loss=0.0779, RMSE=0.2792, R²=-0.0005
   Val:   Loss=0.0836, RMSE=0.2891, R²=0.0081
============================================================


📊 Round 11 Test Metrics:
   Loss: 0.0951, RMSE: 0.3084, MAE: 0.2737, R²: -0.0426

📊 Round 11 Test Metrics:
   Loss: 0.0951, RMSE: 0.3084, MAE: 0.2737, R²: -0.0424

📊 Round 11 Test Metrics:
   Loss: 0.0952, RMSE: 0.3086, MAE: 0.2739, R²: -0.0438

============================================================
🔄 Round 15 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000008
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0823 (↓), lr=0.000008
   • Epoch   2/100: train=0.0798, val=0.0822, patience=1/15, lr=0.000008
   • Epoch   3/100: train=0.0797, val=0.0821, patience=2/15, lr=0.000008
   • Epoch   4/100: train=0.0796, val=0.0821, patience=3/15, lr=0.000008
   • Epoch   5/100: train=0.0795, val=0.0821, patience=4/15, lr=0.000008
   📉 Epoch 8: LR reduced 0.000008 → 0.000004
   • Epoch  11/100: train=0.0793, val=0.0819, patience=10/15, lr=0.000004
   📉 Epoch 16: LR reduced 0.000004 → 0.000002

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 15 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000008 → 0.000002 (2 reductions)
   Train: Loss=0.0797, RMSE=0.2822, R²=-0.0122
   Val:   Loss=0.0823, RMSE=0.2868, R²=-0.0149
============================================================


📊 Round 15 Test Metrics:
   Loss: 0.0956, RMSE: 0.3091, MAE: 0.2742, R²: -0.0473

============================================================
🔄 Round 17 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000002
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0781, val=0.0886 (↓), lr=0.000002
   • Epoch   2/100: train=0.0781, val=0.0886, patience=1/15, lr=0.000002
   • Epoch   3/100: train=0.0781, val=0.0885, patience=2/15, lr=0.000002
   • Epoch   4/100: train=0.0781, val=0.0885, patience=3/15, lr=0.000002
   • Epoch   5/100: train=0.0781, val=0.0885, patience=4/15, lr=0.000002
   📉 Epoch 8: LR reduced 0.000002 → 0.000001
   • Epoch  11/100: train=0.0780, val=0.0885, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0886)

============================================================
📊 Round 17 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000002 → 0.000001 (1 reductions)
   Train: Loss=0.0782, RMSE=0.2796, R²=-0.0140
   Val:   Loss=0.0886, RMSE=0.2976, R²=-0.0174
============================================================


📊 Round 17 Test Metrics:
   Loss: 0.0955, RMSE: 0.3090, MAE: 0.2742, R²: -0.0467

📊 Round 17 Test Metrics:
   Loss: 0.0958, RMSE: 0.3095, MAE: 0.2747, R²: -0.0500

📊 Round 17 Test Metrics:
   Loss: 0.0958, RMSE: 0.3095, MAE: 0.2747, R²: -0.0500

============================================================
🔄 Round 27 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0759 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0759, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0759, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0759, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0759, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0758, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0759)

============================================================
📊 Round 27 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=-0.0133
   Val:   Loss=0.0759, RMSE=0.2756, R²=-0.0246
============================================================


============================================================
🔄 Round 28 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 28 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=-0.0163
   Val:   Loss=0.0785, RMSE=0.2801, R²=-0.0109
============================================================


📊 Round 28 Test Metrics:
   Loss: 0.0958, RMSE: 0.3095, MAE: 0.2746, R²: -0.0500

📊 Round 28 Test Metrics:
   Loss: 0.0958, RMSE: 0.3095, MAE: 0.2747, R²: -0.0501

============================================================
🔄 Round 36 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0738 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0738, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0738, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0738, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0738, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0737, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0738)

============================================================
📊 Round 36 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=-0.0213
   Val:   Loss=0.0738, RMSE=0.2717, R²=0.0110
============================================================


📊 Round 36 Test Metrics:
   Loss: 0.0958, RMSE: 0.3095, MAE: 0.2747, R²: -0.0501

📊 Round 36 Test Metrics:
   Loss: 0.0958, RMSE: 0.3095, MAE: 0.2747, R²: -0.0501

============================================================
🔄 Round 39 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 39 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2813, R²=-0.0201
   Val:   Loss=0.0854, RMSE=0.2922, R²=0.0024
============================================================


📊 Round 39 Test Metrics:
   Loss: 0.0958, RMSE: 0.3095, MAE: 0.2747, R²: -0.0501

============================================================
🔄 Round 44 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0719 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0719, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0719, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0719, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0719, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0718, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0719)

============================================================
📊 Round 44 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=-0.0191
   Val:   Loss=0.0719, RMSE=0.2681, R²=-0.0033
============================================================


📊 Round 44 Test Metrics:
   Loss: 0.0958, RMSE: 0.3095, MAE: 0.2747, R²: -0.0502

📊 Round 44 Test Metrics:
   Loss: 0.0958, RMSE: 0.3095, MAE: 0.2747, R²: -0.0501

📊 Round 44 Test Metrics:
   Loss: 0.0958, RMSE: 0.3096, MAE: 0.2747, R²: -0.0502

============================================================
🔄 Round 53 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 53 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=-0.0149
   Val:   Loss=0.0817, RMSE=0.2858, R²=-0.0416
============================================================


============================================================
🔄 Round 54 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0736 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0736, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0735, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0735, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0735, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0734, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0736)

============================================================
📊 Round 54 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=-0.0156
   Val:   Loss=0.0736, RMSE=0.2712, R²=-0.0323
============================================================


📊 Round 54 Test Metrics:
   Loss: 0.0958, RMSE: 0.3095, MAE: 0.2747, R²: -0.0502

============================================================
🔄 Round 55 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 55 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2822, R²=-0.0092
   Val:   Loss=0.0835, RMSE=0.2890, R²=-0.0394
============================================================


============================================================
🔄 Round 57 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 57 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2826, R²=-0.0069
   Val:   Loss=0.0824, RMSE=0.2871, R²=-0.0764
============================================================


📊 Round 57 Test Metrics:
   Loss: 0.0958, RMSE: 0.3095, MAE: 0.2747, R²: -0.0502

============================================================
🔄 Round 59 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0868 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0868, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0868, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0867, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0867, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0868)

============================================================
📊 Round 59 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2807, R²=-0.0112
   Val:   Loss=0.0868, RMSE=0.2946, R²=-0.0317
============================================================


============================================================
🔄 Round 60 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 60 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=-0.0121
   Val:   Loss=0.0833, RMSE=0.2885, R²=-0.0317
============================================================


📊 Round 60 Test Metrics:
   Loss: 0.0958, RMSE: 0.3096, MAE: 0.2747, R²: -0.0503

============================================================
🔄 Round 62 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 62 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=-0.0145
   Val:   Loss=0.0784, RMSE=0.2799, R²=-0.0187
============================================================


============================================================
🔄 Round 63 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 63 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=-0.0224
   Val:   Loss=0.0821, RMSE=0.2864, R²=0.0041
============================================================


📊 Round 63 Test Metrics:
   Loss: 0.0958, RMSE: 0.3096, MAE: 0.2747, R²: -0.0503

📊 Round 63 Test Metrics:
   Loss: 0.0958, RMSE: 0.3096, MAE: 0.2747, R²: -0.0503

============================================================
🔄 Round 65 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0734 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0734, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0734, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0734, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0733, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0733, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0734)

============================================================
📊 Round 65 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2866, R²=-0.0133
   Val:   Loss=0.0734, RMSE=0.2709, R²=-0.0238
============================================================


📊 Round 65 Test Metrics:
   Loss: 0.0958, RMSE: 0.3096, MAE: 0.2747, R²: -0.0503

📊 Round 65 Test Metrics:
   Loss: 0.0958, RMSE: 0.3096, MAE: 0.2747, R²: -0.0503

============================================================
🔄 Round 68 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0717 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0717, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0717, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0717, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0717, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0717, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0717)

============================================================
📊 Round 68 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2873, R²=-0.0165
   Val:   Loss=0.0717, RMSE=0.2678, R²=-0.0142
============================================================


📊 Round 68 Test Metrics:
   Loss: 0.0958, RMSE: 0.3096, MAE: 0.2747, R²: -0.0504

📊 Round 68 Test Metrics:
   Loss: 0.0958, RMSE: 0.3096, MAE: 0.2747, R²: -0.0504

📊 Round 68 Test Metrics:
   Loss: 0.0958, RMSE: 0.3096, MAE: 0.2747, R²: -0.0504

============================================================
🔄 Round 73 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0777, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0777, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0777, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0777, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0777, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 73 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2847, R²=-0.0178
   Val:   Loss=0.0778, RMSE=0.2788, R²=-0.0114
============================================================


📊 Round 73 Test Metrics:
   Loss: 0.0958, RMSE: 0.3096, MAE: 0.2747, R²: -0.0505

============================================================
🔄 Round 75 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 75 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2833, R²=-0.0166
   Val:   Loss=0.0810, RMSE=0.2845, R²=-0.0128
============================================================


============================================================
🔄 Round 77 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 77 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2831, R²=-0.0111
   Val:   Loss=0.0814, RMSE=0.2854, R²=-0.0345
============================================================


📊 Round 77 Test Metrics:
   Loss: 0.0959, RMSE: 0.3096, MAE: 0.2747, R²: -0.0505

============================================================
🔄 Round 81 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 81 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2814, R²=-0.0128
   Val:   Loss=0.0851, RMSE=0.2917, R²=-0.0248
============================================================


📊 Round 81 Test Metrics:
   Loss: 0.0959, RMSE: 0.3096, MAE: 0.2747, R²: -0.0506

============================================================
🔄 Round 87 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0685 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0685, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0684, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0684, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0684, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0684, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0685)

============================================================
📊 Round 87 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2887, R²=-0.0176
   Val:   Loss=0.0685, RMSE=0.2617, R²=-0.0037
============================================================


📊 Round 87 Test Metrics:
   Loss: 0.0959, RMSE: 0.3096, MAE: 0.2747, R²: -0.0506

============================================================
🔄 Round 89 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 89 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=-0.0084
   Val:   Loss=0.0783, RMSE=0.2799, R²=-0.0504
============================================================


📊 Round 89 Test Metrics:
   Loss: 0.0959, RMSE: 0.3096, MAE: 0.2747, R²: -0.0506

📊 Round 89 Test Metrics:
   Loss: 0.0959, RMSE: 0.3096, MAE: 0.2747, R²: -0.0507

============================================================
🔄 Round 92 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 92 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=-0.0214
   Val:   Loss=0.0820, RMSE=0.2863, R²=0.0033
============================================================


============================================================
🔄 Round 93 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0760 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0760, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0759, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0759, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0759, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0759, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0760)

============================================================
📊 Round 93 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2854, R²=-0.0107
   Val:   Loss=0.0760, RMSE=0.2756, R²=-0.0400
============================================================


============================================================
🔄 Round 94 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 94 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2840, R²=-0.0146
   Val:   Loss=0.0792, RMSE=0.2814, R²=-0.0185
============================================================


============================================================
🔄 Round 96 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 96 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2812, R²=-0.0188
   Val:   Loss=0.0856, RMSE=0.2926, R²=-0.0038
============================================================


📊 Round 96 Test Metrics:
   Loss: 0.0959, RMSE: 0.3096, MAE: 0.2747, R²: -0.0507

============================================================
🔄 Round 98 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 98 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2814, R²=-0.0109
   Val:   Loss=0.0851, RMSE=0.2918, R²=-0.0465
============================================================


📊 Round 98 Test Metrics:
   Loss: 0.0959, RMSE: 0.3096, MAE: 0.2748, R²: -0.0507

📊 Round 98 Test Metrics:
   Loss: 0.0959, RMSE: 0.3096, MAE: 0.2748, R²: -0.0507

============================================================
🔄 Round 101 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0867 (↓), lr=0.000001
   • Epoch   2/100: train=0.0787, val=0.0867, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0867, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0867, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0867, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 101 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2807, R²=-0.0175
   Val:   Loss=0.0867, RMSE=0.2945, R²=-0.0073
============================================================


📊 Round 101 Test Metrics:
   Loss: 0.0959, RMSE: 0.3096, MAE: 0.2748, R²: -0.0507

📊 Round 101 Test Metrics:
   Loss: 0.0959, RMSE: 0.3096, MAE: 0.2748, R²: -0.0508

============================================================
🔄 Round 104 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 104 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2833, R²=-0.0141
   Val:   Loss=0.0809, RMSE=0.2844, R²=-0.0202
============================================================


📊 Round 104 Test Metrics:
   Loss: 0.0959, RMSE: 0.3096, MAE: 0.2748, R²: -0.0508

📊 Round 104 Test Metrics:
   Loss: 0.0959, RMSE: 0.3096, MAE: 0.2748, R²: -0.0508

============================================================
🔄 Round 107 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 107 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2831, R²=-0.0093
   Val:   Loss=0.0812, RMSE=0.2850, R²=-0.0428
============================================================


📊 Round 107 Test Metrics:
   Loss: 0.0959, RMSE: 0.3097, MAE: 0.2748, R²: -0.0509

============================================================
🔄 Round 111 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0700 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0700, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0700, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0700, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0700, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0700, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0700)

============================================================
📊 Round 111 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2880, R²=-0.0194
   Val:   Loss=0.0700, RMSE=0.2647, R²=-0.0085
============================================================


📊 Round 111 Test Metrics:
   Loss: 0.0959, RMSE: 0.3096, MAE: 0.2748, R²: -0.0509

📊 Round 111 Test Metrics:
   Loss: 0.0959, RMSE: 0.3097, MAE: 0.2748, R²: -0.0509

============================================================
🔄 Round 117 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 117 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2838, R²=-0.0196
   Val:   Loss=0.0796, RMSE=0.2821, R²=-0.0090
============================================================


============================================================
🔄 Round 118 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0714 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0714, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0714, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0714, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0714, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0714, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0714)

============================================================
📊 Round 118 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=-0.0135
   Val:   Loss=0.0714, RMSE=0.2673, R²=-0.0250
============================================================


============================================================
🔄 Round 119 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 119 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2826, R²=-0.0126
   Val:   Loss=0.0823, RMSE=0.2869, R²=-0.0246
============================================================


📊 Round 119 Test Metrics:
   Loss: 0.0959, RMSE: 0.3097, MAE: 0.2748, R²: -0.0511

============================================================
🔄 Round 121 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 121 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2815, R²=-0.0138
   Val:   Loss=0.0848, RMSE=0.2913, R²=-0.0201
============================================================


📊 Round 121 Test Metrics:
   Loss: 0.0959, RMSE: 0.3097, MAE: 0.2748, R²: -0.0511

============================================================
🔄 Round 123 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0771 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0771, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0771, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0771, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0771, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0771, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0771)

============================================================
📊 Round 123 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=-0.0214
   Val:   Loss=0.0771, RMSE=0.2777, R²=0.0114
============================================================


============================================================
🔄 Round 127 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 127 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=-0.0068
   Val:   Loss=0.0831, RMSE=0.2882, R²=-0.1026
============================================================


📊 Round 127 Test Metrics:
   Loss: 0.0959, RMSE: 0.3097, MAE: 0.2748, R²: -0.0511

============================================================
🔄 Round 128 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0764 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0764, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0764, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0764, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0764, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0765, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0764)

============================================================
📊 Round 128 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2852, R²=-0.0124
   Val:   Loss=0.0764, RMSE=0.2765, R²=-0.0302
============================================================


📊 Round 128 Test Metrics:
   Loss: 0.0959, RMSE: 0.3097, MAE: 0.2748, R²: -0.0511

📊 Round 128 Test Metrics:
   Loss: 0.0959, RMSE: 0.3097, MAE: 0.2748, R²: -0.0511

============================================================
🔄 Round 132 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 132 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=-0.0194
   Val:   Loss=0.0804, RMSE=0.2835, R²=-0.0058
============================================================


📊 Round 132 Test Metrics:
   Loss: 0.0959, RMSE: 0.3097, MAE: 0.2748, R²: -0.0512

============================================================
🔄 Round 134 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0770, val=0.0931 (↓), lr=0.000001
   • Epoch   2/100: train=0.0770, val=0.0931, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0770, val=0.0931, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0770, val=0.0931, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0770, val=0.0931, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0769, val=0.0930, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0931)

============================================================
📊 Round 134 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0772, RMSE=0.2779, R²=-0.0101
   Val:   Loss=0.0931, RMSE=0.3051, R²=-0.0341
============================================================


📊 Round 134 Test Metrics:
   Loss: 0.0959, RMSE: 0.3097, MAE: 0.2748, R²: -0.0512

📊 Round 134 Test Metrics:
   Loss: 0.0959, RMSE: 0.3097, MAE: 0.2748, R²: -0.0511

============================================================
🔄 Round 136 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0770 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0770, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0770, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0770, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0770, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0770, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0770)

============================================================
📊 Round 136 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=-0.0168
   Val:   Loss=0.0770, RMSE=0.2776, R²=-0.0104
============================================================


============================================================
🔄 Round 137 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0864, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0864, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 137 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2808, R²=-0.0144
   Val:   Loss=0.0864, RMSE=0.2940, R²=-0.0215
============================================================


============================================================
🔄 Round 138 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0759 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0759, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0758, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0758, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0758, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0758, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0759)

============================================================
📊 Round 138 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=-0.0158
   Val:   Loss=0.0759, RMSE=0.2754, R²=-0.0126
============================================================


============================================================
🔄 Round 142 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 142 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=-0.0137
   Val:   Loss=0.0810, RMSE=0.2846, R²=-0.0381
============================================================


============================================================
🔄 Round 146 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0726 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0726, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0726, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0726, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0726, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0725, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0726)

============================================================
📊 Round 146 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=-0.0151
   Val:   Loss=0.0726, RMSE=0.2695, R²=-0.0149
============================================================


📊 Round 146 Test Metrics:
   Loss: 0.0959, RMSE: 0.3097, MAE: 0.2748, R²: -0.0513

============================================================
🔄 Round 148 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 148 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2819, R²=-0.0127
   Val:   Loss=0.0840, RMSE=0.2898, R²=-0.0361
============================================================


📊 Round 148 Test Metrics:
   Loss: 0.0959, RMSE: 0.3097, MAE: 0.2748, R²: -0.0513

============================================================
🔄 Round 150 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 150 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=-0.0139
   Val:   Loss=0.0805, RMSE=0.2838, R²=-0.0223
============================================================


============================================================
🔄 Round 151 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0865 (↓), lr=0.000001
   • Epoch   2/100: train=0.0787, val=0.0865, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0865, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0865, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0865, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0865)

============================================================
📊 Round 151 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2808, R²=-0.0177
   Val:   Loss=0.0865, RMSE=0.2942, R²=-0.0060
============================================================


📊 Round 151 Test Metrics:
   Loss: 0.0959, RMSE: 0.3097, MAE: 0.2748, R²: -0.0513

📊 Round 151 Test Metrics:
   Loss: 0.0959, RMSE: 0.3097, MAE: 0.2748, R²: -0.0513

============================================================
🔄 Round 153 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 153 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=-0.0169
   Val:   Loss=0.0805, RMSE=0.2838, R²=-0.0302
============================================================


📊 Round 153 Test Metrics:
   Loss: 0.0959, RMSE: 0.3097, MAE: 0.2748, R²: -0.0513

============================================================
🔄 Round 157 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0783, val=0.0888 (↓), lr=0.000001
   • Epoch   2/100: train=0.0782, val=0.0888, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0782, val=0.0888, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0782, val=0.0888, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0782, val=0.0888, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0782, val=0.0887, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0888)

============================================================
📊 Round 157 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0783, RMSE=0.2798, R²=-0.0108
   Val:   Loss=0.0888, RMSE=0.2980, R²=-0.0332
============================================================


📊 Round 157 Test Metrics:
   Loss: 0.0959, RMSE: 0.3097, MAE: 0.2748, R²: -0.0513

============================================================
🔄 Round 164 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0735 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0735, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0735, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0735, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0735, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0735, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0735)

============================================================
📊 Round 164 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=-0.0098
   Val:   Loss=0.0735, RMSE=0.2711, R²=-0.0438
============================================================


📊 Round 164 Test Metrics:
   Loss: 0.0959, RMSE: 0.3097, MAE: 0.2748, R²: -0.0514

============================================================
🔄 Round 166 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0779 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0779, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0779, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0779, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0779, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0778, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0779)

============================================================
📊 Round 166 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=-0.0108
   Val:   Loss=0.0779, RMSE=0.2791, R²=-0.0662
============================================================


============================================================
🔄 Round 168 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 168 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2840, R²=-0.0162
   Val:   Loss=0.0793, RMSE=0.2815, R²=-0.0114
============================================================


📊 Round 168 Test Metrics:
   Loss: 0.0959, RMSE: 0.3097, MAE: 0.2748, R²: -0.0514

============================================================
🔄 Round 169 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 169 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=-0.0245
   Val:   Loss=0.0821, RMSE=0.2865, R²=0.0097
============================================================


============================================================
🔄 Round 172 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0779 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0779, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0779, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0779, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0779, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0779, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0779)

============================================================
📊 Round 172 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=-0.0140
   Val:   Loss=0.0779, RMSE=0.2791, R²=-0.0207
============================================================


============================================================
🔄 Round 173 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 173 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2809, R²=-0.0121
   Val:   Loss=0.0864, RMSE=0.2939, R²=-0.0283
============================================================


📊 Round 173 Test Metrics:
   Loss: 0.0959, RMSE: 0.3097, MAE: 0.2748, R²: -0.0515

============================================================
🔄 Round 174 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 174 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2840, R²=-0.0133
   Val:   Loss=0.0793, RMSE=0.2816, R²=-0.0266
============================================================


📊 Round 174 Test Metrics:
   Loss: 0.0959, RMSE: 0.3097, MAE: 0.2748, R²: -0.0515

📊 Round 174 Test Metrics:
   Loss: 0.0959, RMSE: 0.3097, MAE: 0.2748, R²: -0.0515

📊 Round 174 Test Metrics:
   Loss: 0.0959, RMSE: 0.3097, MAE: 0.2748, R²: -0.0515

============================================================
🔄 Round 177 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0774, val=0.0928 (↓), lr=0.000001
   • Epoch   2/100: train=0.0774, val=0.0928, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0774, val=0.0928, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0774, val=0.0928, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0773, val=0.0928, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0773, val=0.0927, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0928)

============================================================
📊 Round 177 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0773, RMSE=0.2780, R²=-0.0103
   Val:   Loss=0.0928, RMSE=0.3046, R²=-0.0328
============================================================


============================================================
🔄 Round 178 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0777 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0777, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0777, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0777, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0777, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 178 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2847, R²=-0.0132
   Val:   Loss=0.0777, RMSE=0.2787, R²=-0.0298
============================================================


============================================================
🔄 Round 180 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 180 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=-0.0135
   Val:   Loss=0.0830, RMSE=0.2882, R²=-0.0234
============================================================


📊 Round 180 Test Metrics:
   Loss: 0.0959, RMSE: 0.3097, MAE: 0.2748, R²: -0.0515

============================================================
🔄 Round 185 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 185 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2811, R²=-0.0158
   Val:   Loss=0.0858, RMSE=0.2930, R²=-0.0150
============================================================


============================================================
🔄 Round 187 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 187 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=-0.0191
   Val:   Loss=0.0801, RMSE=0.2831, R²=-0.0022
============================================================


============================================================
🔄 Round 188 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 188 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2810, R²=-0.0107
   Val:   Loss=0.0861, RMSE=0.2935, R²=-0.0336
============================================================


============================================================
🔄 Round 189 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 189 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=-0.0140
   Val:   Loss=0.0812, RMSE=0.2849, R²=-0.0223
============================================================


📊 Round 189 Test Metrics:
   Loss: 0.0959, RMSE: 0.3098, MAE: 0.2748, R²: -0.0516

============================================================
🔄 Round 193 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0774, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 193 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=-0.0108
   Val:   Loss=0.0775, RMSE=0.2784, R²=-0.0357
============================================================


============================================================
🔄 Round 194 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 194 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2819, R²=-0.0101
   Val:   Loss=0.0842, RMSE=0.2901, R²=-0.0366
============================================================


📊 Round 194 Test Metrics:
   Loss: 0.0960, RMSE: 0.3098, MAE: 0.2748, R²: -0.0516

📊 Round 194 Test Metrics:
   Loss: 0.0960, RMSE: 0.3098, MAE: 0.2748, R²: -0.0517

📊 Round 194 Test Metrics:
   Loss: 0.0960, RMSE: 0.3098, MAE: 0.2748, R²: -0.0517

============================================================
🔄 Round 203 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 203 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2819, R²=-0.0183
   Val:   Loss=0.0841, RMSE=0.2901, R²=-0.0055
============================================================


📊 Round 203 Test Metrics:
   Loss: 0.0960, RMSE: 0.3098, MAE: 0.2748, R²: -0.0517

============================================================
🔄 Round 206 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 206 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=-0.0141
   Val:   Loss=0.0805, RMSE=0.2837, R²=-0.0218
============================================================


📊 Round 206 Test Metrics:
   Loss: 0.0960, RMSE: 0.3098, MAE: 0.2748, R²: -0.0517

============================================================
🔄 Round 207 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0764 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0764, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0764, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0764, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0764, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0764, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0764)

============================================================
📊 Round 207 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=-0.0170
   Val:   Loss=0.0764, RMSE=0.2764, R²=-0.0119
============================================================


📊 Round 207 Test Metrics:
   Loss: 0.0960, RMSE: 0.3098, MAE: 0.2748, R²: -0.0518

============================================================
🔄 Round 210 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 210 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2812, R²=-0.0126
   Val:   Loss=0.0857, RMSE=0.2927, R²=-0.0282
============================================================


============================================================
🔄 Round 211 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0710 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0710, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0710, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0710, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0710, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0711, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0710)

============================================================
📊 Round 211 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=-0.0220
   Val:   Loss=0.0710, RMSE=0.2664, R²=-0.0024
============================================================


📊 Round 211 Test Metrics:
   Loss: 0.0960, RMSE: 0.3098, MAE: 0.2748, R²: -0.0518

============================================================
🔄 Round 212 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0782, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 212 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2845, R²=-0.0074
   Val:   Loss=0.0782, RMSE=0.2797, R²=-0.0592
============================================================


============================================================
🔄 Round 213 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0781, val=0.0885 (↓), lr=0.000001
   • Epoch   2/100: train=0.0781, val=0.0885, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0781, val=0.0885, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0781, val=0.0885, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0781, val=0.0885, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0780, val=0.0884, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0885)

============================================================
📊 Round 213 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2800, R²=-0.0193
   Val:   Loss=0.0885, RMSE=0.2975, R²=-0.0019
============================================================


📊 Round 213 Test Metrics:
   Loss: 0.0960, RMSE: 0.3098, MAE: 0.2749, R²: -0.0519

📊 Round 213 Test Metrics:
   Loss: 0.0960, RMSE: 0.3098, MAE: 0.2748, R²: -0.0518

============================================================
🔄 Round 215 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 215 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2829, R²=-0.0208
   Val:   Loss=0.0818, RMSE=0.2860, R²=0.0049
============================================================


📊 Round 215 Test Metrics:
   Loss: 0.0960, RMSE: 0.3098, MAE: 0.2748, R²: -0.0518

📊 Round 215 Test Metrics:
   Loss: 0.0960, RMSE: 0.3098, MAE: 0.2748, R²: -0.0518

============================================================
🔄 Round 218 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 218 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2813, R²=-0.0104
   Val:   Loss=0.0855, RMSE=0.2924, R²=-0.0395
============================================================


============================================================
🔄 Round 219 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 219 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=-0.0192
   Val:   Loss=0.0824, RMSE=0.2871, R²=-0.0026
============================================================


============================================================
🔄 Round 220 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 220 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=-0.0219
   Val:   Loss=0.0785, RMSE=0.2802, R²=-0.0046
============================================================


📊 Round 220 Test Metrics:
   Loss: 0.0960, RMSE: 0.3098, MAE: 0.2749, R²: -0.0519

📊 Round 220 Test Metrics:
   Loss: 0.0960, RMSE: 0.3098, MAE: 0.2749, R²: -0.0519

============================================================
🔄 Round 222 - Client client_13
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0765 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0765, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0765, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0764, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0764, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0764, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0765)

============================================================
📊 Round 222 Summary - Client client_13
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=-0.0172
   Val:   Loss=0.0765, RMSE=0.2765, R²=-0.0079
============================================================


📊 Round 222 Test Metrics:
   Loss: 0.0960, RMSE: 0.3098, MAE: 0.2749, R²: -0.0519

📊 Round 222 Test Metrics:
   Loss: 0.0960, RMSE: 0.3098, MAE: 0.2749, R²: -0.0519

❌ Client client_13 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8687 {grpc_status:14, grpc_message:"Socket closed"}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8687 {grpc_status:14, grpc_message:"Socket closed"}"
>
