[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d257efd0-dd2f-4acc-b2d4-6df7fb56a91e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 72509532-0128-4873-8fd9-2d21fb5dc95c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cbb810bf-0c46-4240-8402-cb0680bafd8d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6f373a01-f131-4f69-a666-8b958d24a86b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 195ffa84-80dc-4c76-888f-c0b06b9343ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 25d3511f-0e76-49c0-8cc2-150fb16231aa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 04bdf395-750f-4408-a112-02c859ff5d72
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4fdd396a-b9d8-47a9-8858-24af82797c61
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e38d57f5-4d91-4a12-a25c-fd3d30e55b2d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1cd613b0-8382-49c7-8778-c5b9dbe4666b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 148e3ca1-9f4b-40e7-b458-48477ba1f8df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d064d70d-9884-418e-bd53-33f186e5b03a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 44e313dd-636c-4819-8199-cd9dfe0a3cdf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0ddfd17b-db03-495c-85c1-6d90d945eca7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dd148c30-b94b-4e7f-b141-3119791ab6d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f2e9baba-9454-458c-8ec0-ad1217e4dd7e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7a0ff969-52df-4a8f-a0e4-220596afa6ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c2fa7c1a-66ff-4534-b07c-5dfba17740ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d0f5ac90-fc49-41ab-8c88-dbb0d9f66ca2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c0d16150-2626-41f4-8356-630393cff58c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ac244ee1-bced-42f0-b1a6-34094ccc7ada
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e999e54b-a87a-4de3-ac88-f48712313972
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 85a3f63d-c653-42fe-bafa-1d922742b6f8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 44914de1-9a87-4b2e-9cce-8e037834fa4f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7b9357ef-a210-41be-b82d-f517fdbdb95c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 016cff1c-ff94-42fc-8fbc-97f95ed83613
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message adf8dc8f-bec0-4580-95c8-428dc0095345
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 73b95a67-4108-446d-a2c2-e7c3cfefbf74
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d778f8df-3992-4c96-ad9f-e076a1e50241
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 26201504-c332-4b7f-a93f-89d69ba443d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f139b9b4-e4d3-4a32-b08d-57a8fb7fe89b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0b31ee5f-bc48-4a38-9081-2ff50759fef1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6182525b-5264-4180-894d-16a09949a260
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 23d16b56-9ce9-49ce-82b5-793b00844b90
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 87d5975d-deaa-4459-a25b-c373d99dae7f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b6c213bb-9c0f-45f8-980a-5e352bb194f3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 70c05b3f-68a4-4707-bf64-32655e831d2d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1f30e792-39bb-43e9-8189-5e1c843b26d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5e6d49cb-4df4-407c-be8d-acc5851e5c9d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9a1dfe75-d955-4476-a8b8-0aaa2186fa0d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message edb19d7f-67cd-4143-af7d-30b351381d1d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 43684b5e-a4c1-48cf-962c-28496da1d08c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 00385a77-e3e8-4827-8712-d826f31f4fa7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1372bdc2-1c65-4402-8f67-0d1e2e34457f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2a9a5dd6-cf84-46b2-929c-f73d22c91743
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d0095504-70c3-4064-9128-51bbad61064c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eff1384f-2893-414e-865e-501e949aae85
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7bd7dfe0-acdf-4ebd-be10-026093c7abe4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f18302c8-6d33-45f2-bb77-316b19b31f83
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 062a2aef-8260-41b7-a8de-dd8decda925c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 943c2b5a-5ba2-45bb-bbfe-607053f52cb1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b962defb-a0f6-4971-9a4a-0da78f15cbed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 75e06a64-6675-4c32-830a-2ad8dfac77d5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2ffc1edd-3b33-4fb6-afb5-ad216e03db82
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 22c5202d-9b8c-40b8-b701-27dca94994d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 894d4a90-16ab-439d-9834-162fc1587033
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 71564bb8-2e04-423d-96d7-74061ab4dab3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 94b52736-5c73-4cea-b906-a2ee91227d89
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f8c138d4-9988-4352-a468-a48e50b50568
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 21c9e3fb-67fd-42d1-9992-9ece9077255e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5f83caed-fd83-43cf-9b00-92a31be0798e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d50a9d94-55e5-4c09-8448-5d69eac53b92
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9f3491ff-ff7d-4fab-baa8-eff393ca6f2d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 48845cb7-9a24-48ec-a58b-9e58a0b8df3a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ccb65e23-d174-4d08-ab4c-b706389e1b90
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dc7d9c14-2709-44e9-9895-fa6a00bf0fec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f9a30fa2-a3e3-4c63-bc86-bba548ccfe3a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ad1c62f1-3096-4069-a760-65df32032b13
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 50aa67eb-eecb-4223-af55-27826402ccef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b1b51f73-c66d-4ee5-99ae-99467b822215
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message edb26be2-ec8e-46ae-9916-74b8dc53aba8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b26465a4-d3a9-4d30-85ec-01980dfed123
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 57b1eed0-19f3-4b83-94b5-fd36c7e6de31
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ee07cfe6-370d-4033-83c8-43048e3a153d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6efe8ed6-9c00-4944-899a-5ff23ebbe6a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a3bd5b9b-588d-4631-86f6-1b65a5f56509
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c9efbbf5-a08d-432e-ba4d-4c28ae4cfd00
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 47e71469-d9a5-432e-a68b-c29e762c2830
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ae6dc4f2-3f58-41df-b0d3-2922b3953b97
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f8fc821b-c958-4b35-b19c-603d71c7d75c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c66eff3c-2c2d-4d8c-98be-804f50004c93
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 40d3febf-482c-45b6-9a11-051e0511fe5b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1cb220c4-5c27-4e26-ad4e-943706b4d28e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d48d9dd6-0016-4cb8-a9f6-00ba88a514e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4a95b09b-2f0d-4e0e-ac57-570383ed1c2c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1544be3e-6e38-4274-b570-7b50aaabc727
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9bd59daf-9c73-4638-b4f6-c4eeed8ea2c4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a48476f1-c6af-41e7-814a-0d854a7263b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 40afd7dd-6d17-49c8-be30-4f2ecabc2101
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ac5bb3a3-7d57-482f-aafc-b66f62acb9cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d2ecb266-eca6-4e99-ad6f-25d082dce425
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8e4175de-2b74-411a-9223-da2b6e66975a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b5c24537-8a8c-4d11-bf14-8ece5f311fa5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7971311b-1564-4f88-9bfe-cbeaddec4a7f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ec3ef06f-ad38-4244-964d-2ef4ec061701
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e44f80c4-1e54-4b39-947e-6a6e6073fdbf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 68c58116-4663-4220-b9c5-9c6a262990bc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 97da5b46-91cd-42bc-b63c-7bad2a5d3038
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1e88f1cb-9480-49b3-a831-ec5b15c45388
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9bc00c35-1fcb-4350-a2f3-2790a2389ea2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 352acc7a-e15c-4aa3-8103-a2cfefdbbb92
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 25734a4e-cc67-489f-bb4d-7e7a729bfbb5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8dfbcdd2-ecaf-43e6-af28-585d534f13c6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 51cd2ac8-893e-4871-ac3d-fc3c1e87d943
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8de96612-5df0-4184-bda6-7ec797b069d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 15ab7dec-a64b-40ab-937f-5fad591129ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5ec792f5-9e31-47d1-aca5-759759d620f8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eb44ed88-578d-4a70-891c-daee624be0d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9fe06a2f-633a-4c32-9b48-d00818177441
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 460d30a2-0395-4678-ac5f-21405ba844ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8f9ed45a-e368-44f3-9e20-151fd4be0f11
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d2d131a5-1ac2-4582-8a31-d579221094aa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message afccaf78-ea69-4c74-a4c3-114a16655f88
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ed0cd876-b650-48d9-9a5e-2e150adce8d8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1fcec3af-532f-43ac-956d-a76bf4106239
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0d31c248-9228-421b-a65d-d9184b27d6c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3646beb9-af9d-46db-b676-8d67a6f1a1cd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ee413952-a694-49f6-828b-87a5a036bf8a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ced94ea5-ca32-4f93-839e-8a8fed26f121
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 95ead3ec-6862-4dfa-a73c-e4914f984b29
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8078b669-d63a-40fa-8127-bac1a2497f4b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1d0f8ec5-85fc-4b3a-9068-1417003f4f68
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1dfbf668-ffd2-4731-8b04-f6a5d2391ccc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5c699f41-c170-487f-84d6-869da0809d52
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b5409311-8278-416c-a3b1-7579c03cf14e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3b8e441c-aa05-4d16-bd40-f0808057552f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6de87c0d-e264-4b43-90c4-b41c444575ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 16585c22-7209-4577-bc1d-4b65a83bfc16
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d869ee07-c014-4499-9ecf-42149c834b98
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 088e51c3-3ede-4552-850f-966466956b79
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 57aa1c7a-41a9-4ea2-af6f-5f277ab511f4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2d2d391d-40ab-4c9c-a747-7e9492c0fedc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ee3421bc-6527-4a68-b813-04d3eba5ae6c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d1f76fcd-2ee3-46c2-af66-1ed5c2218043
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3a86b61a-a669-49f6-a9f6-1fb5f9a4bc66
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e6b9f388-8dc2-4e46-bf41-797860ccbb3c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7df15426-f954-4b42-bfb1-ccd2dc233e88
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fc7550f3-8f81-4dbb-8d8b-25fbc87b3a17
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 840a844d-50ac-4b39-b0ec-f27dbe7bc626
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6d298e30-72fa-4cfe-a2bb-cec6294c59fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ace11165-84ea-4c63-a701-8753301ddd30
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 88e1a3b4-fa80-4a8e-aa67-2bf6b6a6dc0c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 47dfed55-d156-47a2-917d-f2aa11dc4cdc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9d2e716b-927b-4165-be58-bb4a9824b2d5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 89286876-b187-412f-a09a-2dd9b50bec38
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 72caaa44-736a-4002-a4d0-557bff8ae586
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fa90b39f-ec3d-46f8-9fbb-92c2a0561548
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 48a60a46-8063-43af-928d-f52ed20c4217
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6cc0af28-4521-4fbf-80cd-b1c65f74e9f3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message db28f5bb-662e-485d-b1b0-50c611020173
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c11ad180-c9ad-4d2a-a3cc-44c369244d06
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 252de6c1-3d27-4c33-bf7a-860729192394
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f622bc44-42c5-434f-afb1-7fb6eb036b21
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c2d09ab0-57f8-4302-b74a-b6de61b17786
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b74571d9-69fd-4ce1-b5dc-7781eab4f2a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0a4a2ccc-be0e-4931-8dfa-626fbdb565fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3043e32c-4499-4180-a600-d193f15a9163
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d0493bb2-e24d-46d3-969d-240fa521da64
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4ba1e23d-6d24-4be6-b8a2-0e40cd94ebd2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 98eda5da-8a85-486f-9bb5-9198f789c034
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b902dfe7-cfb9-4cbc-939a-671d63e166a3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 33bb37f6-f494-4d16-9ae6-763eb9d5d1a0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e067b0cb-5a81-460a-ac21-7c21c5984b29
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 76de8746-4b86-4891-87cc-de04d3767313
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 52a73371-b050-47de-bf35-2a9c8cac6be2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5f4c54fd-557f-4f79-9a49-4b6d579473a7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fb1497a8-8fbe-40a8-91ff-f3d1c4d54b73
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eb97200b-a725-4c5f-9c07-e41a27f4cdb0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9b1c520a-d05f-409c-be3e-99db7cea7576
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0c4d7dcb-a11c-4da0-b07f-b4de76fd0c91
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d4a0d96a-100f-4efb-93c1-ef582689d7ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 53a5d73c-54f7-467d-a3d6-f3cc36d31e6f
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8687 {grpc_message:"Socket closed", grpc_status:14}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_14
Server: localhost:8687
Algorithm: FEDAVG
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_14
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_14/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_14/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_14/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_14/test_labels.txt

📊 Raw data loaded:
   Train: X=(601, 24), y=(601,)
   Test:  X=(151, 24), y=(151,)

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 592 samples, 5 features
   Test:  142 samples, 5 features
✅ Client client_14 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

📊 Round 0 Test Metrics:
   Loss: 0.0833, RMSE: 0.2886, MAE: 0.2464, R²: -0.0069

📊 Round 0 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2471, R²: -0.0110

============================================================
🔄 Round 5 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0916 (↓), lr=0.001000
   ✓ Epoch   2/100: train=0.0822, val=0.0909 (↓), lr=0.001000
   • Epoch   3/100: train=0.0820, val=0.0908, patience=1/15, lr=0.001000
   • Epoch   4/100: train=0.0811, val=0.0913, patience=2/15, lr=0.001000
   • Epoch   5/100: train=0.0807, val=0.0915, patience=3/15, lr=0.001000
   📉 Epoch 9: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0786, val=0.0928, patience=9/15, lr=0.000500
   📉 Epoch 17: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0909)

============================================================
📊 Round 5 Summary - Client client_14
   Epochs: 17/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=-0.0028
   Val:   Loss=0.0909, RMSE=0.3015, R²=-0.0370
============================================================


📊 Round 5 Test Metrics:
   Loss: 0.0856, RMSE: 0.2927, MAE: 0.2508, R²: -0.0353

📊 Round 5 Test Metrics:
   Loss: 0.0868, RMSE: 0.2946, MAE: 0.2527, R²: -0.0487

============================================================
🔄 Round 7 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0941 (↓), lr=0.000250
   • Epoch   2/100: train=0.0822, val=0.0948, patience=1/15, lr=0.000250
   • Epoch   3/100: train=0.0814, val=0.0949, patience=2/15, lr=0.000250
   • Epoch   4/100: train=0.0809, val=0.0952, patience=3/15, lr=0.000250
   • Epoch   5/100: train=0.0807, val=0.0954, patience=4/15, lr=0.000250
   📉 Epoch 8: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0799, val=0.0954, patience=10/15, lr=0.000125
   📉 Epoch 16: LR reduced 0.000125 → 0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0941)

============================================================
📊 Round 7 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000250 → 0.000063 (2 reductions)
   Train: Loss=0.0829, RMSE=0.2880, R²=-0.0236
   Val:   Loss=0.0941, RMSE=0.3068, R²=-0.0196
============================================================


📊 Round 7 Test Metrics:
   Loss: 0.0878, RMSE: 0.2963, MAE: 0.2536, R²: -0.0611

============================================================
🔄 Round 12 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0875, val=0.0815 (↓), lr=0.000063
   • Epoch   2/100: train=0.0869, val=0.0811, patience=1/15, lr=0.000063
   ✓ Epoch   3/100: train=0.0863, val=0.0808 (↓), lr=0.000063
   • Epoch   4/100: train=0.0859, val=0.0807, patience=1/15, lr=0.000063
   • Epoch   5/100: train=0.0856, val=0.0807, patience=2/15, lr=0.000063
   • Epoch  11/100: train=0.0847, val=0.0808, patience=8/15, lr=0.000063
   📉 Epoch 12: LR reduced 0.000063 → 0.000031

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 12 Summary - Client client_14
   Epochs: 18/100 (early stopped)
   LR: 0.000063 → 0.000031 (1 reductions)
   Train: Loss=0.0860, RMSE=0.2933, R²=-0.0233
   Val:   Loss=0.0808, RMSE=0.2843, R²=-0.0066
============================================================


============================================================
🔄 Round 13 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000031
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0881 (↓), lr=0.000031
   📉 Epoch 2: LR reduced 0.000031 → 0.000016
   • Epoch   2/100: train=0.0861, val=0.0881, patience=1/15, lr=0.000016
   • Epoch   3/100: train=0.0859, val=0.0882, patience=2/15, lr=0.000016
   • Epoch   4/100: train=0.0857, val=0.0882, patience=3/15, lr=0.000016
   • Epoch   5/100: train=0.0856, val=0.0881, patience=4/15, lr=0.000016
   📉 Epoch 10: LR reduced 0.000016 → 0.000008
   • Epoch  11/100: train=0.0848, val=0.0879, patience=10/15, lr=0.000008

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0881)

============================================================
📊 Round 13 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000031 → 0.000008 (2 reductions)
   Train: Loss=0.0859, RMSE=0.2932, R²=-0.0301
   Val:   Loss=0.0881, RMSE=0.2968, R²=-0.0760
============================================================


📊 Round 13 Test Metrics:
   Loss: 0.0881, RMSE: 0.2969, MAE: 0.2542, R²: -0.0653

============================================================
🔄 Round 14 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000008
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0860 (↓), lr=0.000008
   📉 Epoch 2: LR reduced 0.000008 → 0.000004
   • Epoch   2/100: train=0.0865, val=0.0860, patience=1/15, lr=0.000004
   • Epoch   3/100: train=0.0864, val=0.0860, patience=2/15, lr=0.000004
   • Epoch   4/100: train=0.0864, val=0.0859, patience=3/15, lr=0.000004
   • Epoch   5/100: train=0.0863, val=0.0859, patience=4/15, lr=0.000004
   📉 Epoch 10: LR reduced 0.000004 → 0.000002
   • Epoch  11/100: train=0.0861, val=0.0859, patience=10/15, lr=0.000002

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 14 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000008 → 0.000002 (2 reductions)
   Train: Loss=0.0868, RMSE=0.2947, R²=-0.0383
   Val:   Loss=0.0860, RMSE=0.2933, R²=-0.0483
============================================================


============================================================
🔄 Round 15 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000002
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0895 (↓), lr=0.000002
   📉 Epoch 2: LR reduced 0.000002 → 0.000001
   • Epoch   2/100: train=0.0866, val=0.0895, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0895, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0895, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0895, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0894, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0895)

============================================================
📊 Round 15 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000002 → 0.000001 (1 reductions)
   Train: Loss=0.0865, RMSE=0.2941, R²=-0.0457
   Val:   Loss=0.0895, RMSE=0.2992, R²=-0.0434
============================================================


📊 Round 15 Test Metrics:
   Loss: 0.0885, RMSE: 0.2976, MAE: 0.2547, R²: -0.0703

📊 Round 15 Test Metrics:
   Loss: 0.0886, RMSE: 0.2977, MAE: 0.2547, R²: -0.0711

============================================================
🔄 Round 18 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0934 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0934, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0934, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0934, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0934, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0934, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0934)

============================================================
📊 Round 18 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2929, R²=-0.0523
   Val:   Loss=0.0934, RMSE=0.3057, R²=-0.0312
============================================================


============================================================
🔄 Round 19 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0869, val=0.0894 (↓), lr=0.000001
   • Epoch   2/100: train=0.0869, val=0.0894, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0869, val=0.0894, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0869, val=0.0894, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0869, val=0.0894, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0868, val=0.0894, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0894)

============================================================
📊 Round 19 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2946, R²=-0.0569
   Val:   Loss=0.0894, RMSE=0.2990, R²=-0.0222
============================================================


📊 Round 19 Test Metrics:
   Loss: 0.0885, RMSE: 0.2975, MAE: 0.2545, R²: -0.0702

============================================================
🔄 Round 20 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0876, val=0.0868 (↓), lr=0.000001
   • Epoch   2/100: train=0.0875, val=0.0868, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0875, val=0.0868, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0875, val=0.0868, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0875, val=0.0868, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0874, val=0.0868, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0868)

============================================================
📊 Round 20 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0876, RMSE=0.2959, R²=-0.0563
   Val:   Loss=0.0868, RMSE=0.2946, R²=-0.0368
============================================================


📊 Round 20 Test Metrics:
   Loss: 0.0889, RMSE: 0.2982, MAE: 0.2551, R²: -0.0752

============================================================
🔄 Round 21 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0872, val=0.0898 (↓), lr=0.000001
   • Epoch   2/100: train=0.0872, val=0.0898, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0872, val=0.0898, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0872, val=0.0898, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0872, val=0.0898, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0871, val=0.0897, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0898)

============================================================
📊 Round 21 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0872, RMSE=0.2953, R²=-0.0430
   Val:   Loss=0.0898, RMSE=0.2997, R²=-0.0973
============================================================


============================================================
🔄 Round 22 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0904, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0904, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0903, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0903, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0903, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0903, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 22 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0901, RMSE=0.3001, R²=-0.0519
   Val:   Loss=0.0786, RMSE=0.2804, R²=-0.0622
============================================================


📊 Round 22 Test Metrics:
   Loss: 0.0889, RMSE: 0.2982, MAE: 0.2550, R²: -0.0751

============================================================
🔄 Round 24 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0907, val=0.0770 (↓), lr=0.000001
   • Epoch   2/100: train=0.0906, val=0.0770, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0906, val=0.0769, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0906, val=0.0769, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0906, val=0.0769, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0906, val=0.0769, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0770)

============================================================
📊 Round 24 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0905, RMSE=0.3009, R²=-0.0528
   Val:   Loss=0.0770, RMSE=0.2774, R²=-0.0591
============================================================


============================================================
🔄 Round 25 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0891, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0891, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0891, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0891, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0890, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0890, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 25 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0891, RMSE=0.2985, R²=-0.0513
   Val:   Loss=0.0828, RMSE=0.2877, R²=-0.0928
============================================================


📊 Round 25 Test Metrics:
   Loss: 0.0890, RMSE: 0.2983, MAE: 0.2550, R²: -0.0754

📊 Round 25 Test Metrics:
   Loss: 0.0889, RMSE: 0.2982, MAE: 0.2549, R²: -0.0752

============================================================
🔄 Round 32 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0932 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0932, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0932, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0932, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0932, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0932, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0932)

============================================================
📊 Round 32 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2941, R²=-0.0508
   Val:   Loss=0.0932, RMSE=0.3053, R²=-0.0737
============================================================


📊 Round 32 Test Metrics:
   Loss: 0.0890, RMSE: 0.2983, MAE: 0.2550, R²: -0.0753

============================================================
🔄 Round 37 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0891, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0891, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0891, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0891, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0891, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0890, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 37 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0890, RMSE=0.2983, R²=-0.0625
   Val:   Loss=0.0832, RMSE=0.2885, R²=-0.0331
============================================================


📊 Round 37 Test Metrics:
   Loss: 0.0890, RMSE: 0.2983, MAE: 0.2550, R²: -0.0753

============================================================
🔄 Round 39 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0883, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0883, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0883, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0883, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0883, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0882, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 39 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0883, RMSE=0.2971, R²=-0.0569
   Val:   Loss=0.0860, RMSE=0.2933, R²=-0.0446
============================================================


📊 Round 39 Test Metrics:
   Loss: 0.0890, RMSE: 0.2983, MAE: 0.2550, R²: -0.0754

📊 Round 39 Test Metrics:
   Loss: 0.0890, RMSE: 0.2983, MAE: 0.2550, R²: -0.0754

📊 Round 39 Test Metrics:
   Loss: 0.0890, RMSE: 0.2983, MAE: 0.2550, R²: -0.0754

📊 Round 39 Test Metrics:
   Loss: 0.0890, RMSE: 0.2983, MAE: 0.2550, R²: -0.0755

📊 Round 39 Test Metrics:
   Loss: 0.0890, RMSE: 0.2983, MAE: 0.2550, R²: -0.0753

📊 Round 39 Test Metrics:
   Loss: 0.0890, RMSE: 0.2983, MAE: 0.2550, R²: -0.0754

============================================================
🔄 Round 54 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0888, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0888, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0888, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0887, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0887, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0886, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 54 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0888, RMSE=0.2980, R²=-0.0688
   Val:   Loss=0.0840, RMSE=0.2898, R²=-0.0377
============================================================


📊 Round 54 Test Metrics:
   Loss: 0.0890, RMSE: 0.2983, MAE: 0.2550, R²: -0.0753

============================================================
🔄 Round 56 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0892, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0892, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0892, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0892, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0892, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0891, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 56 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0892, RMSE=0.2987, R²=-0.0624
   Val:   Loss=0.0822, RMSE=0.2868, R²=-0.0266
============================================================


============================================================
🔄 Round 57 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0904, val=0.0776 (↓), lr=0.000001
   • Epoch   2/100: train=0.0904, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0903, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0903, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0903, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0903, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 57 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0904, RMSE=0.3007, R²=-0.0707
   Val:   Loss=0.0776, RMSE=0.2785, R²=0.0150
============================================================


============================================================
🔄 Round 61 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.0936 (↓), lr=0.000001
   • Epoch   2/100: train=0.0867, val=0.0936, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0867, val=0.0935, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0867, val=0.0935, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0867, val=0.0935, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0867, val=0.0935, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0936)

============================================================
📊 Round 61 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2940, R²=-0.0481
   Val:   Loss=0.0936, RMSE=0.3059, R²=-0.0779
============================================================


📊 Round 61 Test Metrics:
   Loss: 0.0890, RMSE: 0.2983, MAE: 0.2550, R²: -0.0754

============================================================
🔄 Round 64 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0886, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0886, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0886, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0886, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0886, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0885, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 64 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0884, RMSE=0.2973, R²=-0.0680
   Val:   Loss=0.0857, RMSE=0.2927, R²=-0.0011
============================================================


============================================================
🔄 Round 65 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.1009 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.1009, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.1009, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.1009, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.1009, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.1008, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.1009)

============================================================
📊 Round 65 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=-0.0452
   Val:   Loss=0.1009, RMSE=0.3176, R²=-0.0919
============================================================


📊 Round 65 Test Metrics:
   Loss: 0.0890, RMSE: 0.2983, MAE: 0.2550, R²: -0.0756

============================================================
🔄 Round 72 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0902, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0902, val=0.0778, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0902, val=0.0778, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0902, val=0.0778, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0902, val=0.0778, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0901, val=0.0779, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 72 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0903, RMSE=0.3006, R²=-0.0602
   Val:   Loss=0.0778, RMSE=0.2789, R²=-0.0497
============================================================


============================================================
🔄 Round 74 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0869, val=0.0905 (↓), lr=0.000001
   • Epoch   2/100: train=0.0869, val=0.0905, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0869, val=0.0905, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0868, val=0.0905, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0868, val=0.0905, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0868, val=0.0905, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0905)

============================================================
📊 Round 74 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0872, RMSE=0.2953, R²=-0.0523
   Val:   Loss=0.0905, RMSE=0.3008, R²=-0.0702
============================================================


📊 Round 74 Test Metrics:
   Loss: 0.0890, RMSE: 0.2983, MAE: 0.2550, R²: -0.0756

============================================================
🔄 Round 75 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.0919 (↓), lr=0.000001
   • Epoch   2/100: train=0.0868, val=0.0919, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0868, val=0.0918, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0868, val=0.0918, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0867, val=0.0918, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0867, val=0.0918, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0919)

============================================================
📊 Round 75 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2947, R²=-0.0520
   Val:   Loss=0.0919, RMSE=0.3031, R²=-0.0634
============================================================


============================================================
🔄 Round 76 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0885, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0885, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0884, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0884, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0884, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0884, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 76 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0884, RMSE=0.2972, R²=-0.0516
   Val:   Loss=0.0858, RMSE=0.2929, R²=-0.0654
============================================================


📊 Round 76 Test Metrics:
   Loss: 0.0890, RMSE: 0.2983, MAE: 0.2550, R²: -0.0757

============================================================
🔄 Round 77 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0877, val=0.0899 (↓), lr=0.000001
   • Epoch   2/100: train=0.0877, val=0.0899, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0877, val=0.0899, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0876, val=0.0899, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0876, val=0.0899, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0875, val=0.0899, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0899)

============================================================
📊 Round 77 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0873, RMSE=0.2955, R²=-0.0588
   Val:   Loss=0.0899, RMSE=0.2998, R²=-0.0614
============================================================


📊 Round 77 Test Metrics:
   Loss: 0.0890, RMSE: 0.2983, MAE: 0.2551, R²: -0.0757

============================================================
🔄 Round 78 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0878, val=0.0881 (↓), lr=0.000001
   • Epoch   2/100: train=0.0878, val=0.0881, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0878, val=0.0881, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0878, val=0.0881, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0877, val=0.0881, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0877, val=0.0881, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0881)

============================================================
📊 Round 78 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0878, RMSE=0.2963, R²=-0.0457
   Val:   Loss=0.0881, RMSE=0.2969, R²=-0.1024
============================================================


📊 Round 78 Test Metrics:
   Loss: 0.0890, RMSE: 0.2983, MAE: 0.2551, R²: -0.0758

============================================================
🔄 Round 79 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0951 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0951, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0951, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0951, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0951, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0950, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0951)

============================================================
📊 Round 79 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2933, R²=-0.0402
   Val:   Loss=0.0951, RMSE=0.3084, R²=-0.1182
============================================================


============================================================
🔄 Round 82 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0932 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0932, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0932, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0932, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0932, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0866, val=0.0931, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0932)

============================================================
📊 Round 82 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2941, R²=-0.0445
   Val:   Loss=0.0932, RMSE=0.3054, R²=-0.0927
============================================================


📊 Round 82 Test Metrics:
   Loss: 0.0890, RMSE: 0.2983, MAE: 0.2550, R²: -0.0757

============================================================
🔄 Round 84 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0884, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0883, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0883, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0883, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0883, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0882, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 84 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0884, RMSE=0.2974, R²=-0.0519
   Val:   Loss=0.0855, RMSE=0.2925, R²=-0.0668
============================================================


============================================================
🔄 Round 85 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0870, val=0.0912 (↓), lr=0.000001
   • Epoch   2/100: train=0.0870, val=0.0912, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0870, val=0.0912, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0870, val=0.0912, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0870, val=0.0912, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0869, val=0.0912, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0912)

============================================================
📊 Round 85 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0870, RMSE=0.2950, R²=-0.0449
   Val:   Loss=0.0912, RMSE=0.3021, R²=-0.0918
============================================================


============================================================
🔄 Round 89 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.0926 (↓), lr=0.000001
   • Epoch   2/100: train=0.0868, val=0.0926, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0868, val=0.0926, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0867, val=0.0926, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0867, val=0.0926, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0867, val=0.0925, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0926)

============================================================
📊 Round 89 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0867, RMSE=0.2944, R²=-0.0488
   Val:   Loss=0.0926, RMSE=0.3043, R²=-0.0755
============================================================


📊 Round 89 Test Metrics:
   Loss: 0.0890, RMSE: 0.2983, MAE: 0.2551, R²: -0.0757

============================================================
🔄 Round 90 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0897, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0896, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0896, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0896, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0896, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0895, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 90 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0895, RMSE=0.2992, R²=-0.0659
   Val:   Loss=0.0812, RMSE=0.2849, R²=-0.0057
============================================================


📊 Round 90 Test Metrics:
   Loss: 0.0890, RMSE: 0.2983, MAE: 0.2551, R²: -0.0757

============================================================
🔄 Round 95 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0889, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0889, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0889, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0888, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0888, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0888, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 95 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0885, RMSE=0.2976, R²=-0.0547
   Val:   Loss=0.0851, RMSE=0.2917, R²=-0.0622
============================================================


📊 Round 95 Test Metrics:
   Loss: 0.0890, RMSE: 0.2983, MAE: 0.2551, R²: -0.0758

============================================================
🔄 Round 97 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0906, val=0.0765 (↓), lr=0.000001
   • Epoch   2/100: train=0.0906, val=0.0765, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0906, val=0.0765, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0906, val=0.0765, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0906, val=0.0765, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0905, val=0.0765, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0765)

============================================================
📊 Round 97 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0907, RMSE=0.3011, R²=-0.0592
   Val:   Loss=0.0765, RMSE=0.2766, R²=-0.0314
============================================================


============================================================
🔄 Round 100 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.0929 (↓), lr=0.000001
   • Epoch   2/100: train=0.0868, val=0.0929, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0868, val=0.0929, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0867, val=0.0929, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0867, val=0.0929, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0867, val=0.0929, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0929)

============================================================
📊 Round 100 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2942, R²=-0.0518
   Val:   Loss=0.0929, RMSE=0.3049, R²=-0.0644
============================================================


📊 Round 100 Test Metrics:
   Loss: 0.0890, RMSE: 0.2984, MAE: 0.2551, R²: -0.0760

============================================================
🔄 Round 104 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0879, val=0.0881 (↓), lr=0.000001
   • Epoch   2/100: train=0.0879, val=0.0881, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0879, val=0.0881, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0878, val=0.0881, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0878, val=0.0881, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0878, val=0.0881, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0881)

============================================================
📊 Round 104 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0878, RMSE=0.2963, R²=-0.0464
   Val:   Loss=0.0881, RMSE=0.2968, R²=-0.1013
============================================================


============================================================
🔄 Round 105 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.0928 (↓), lr=0.000001
   • Epoch   2/100: train=0.0868, val=0.0928, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0868, val=0.0928, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0868, val=0.0928, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0867, val=0.0928, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0867, val=0.0927, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0928)

============================================================
📊 Round 105 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2943, R²=-0.0399
   Val:   Loss=0.0928, RMSE=0.3047, R²=-0.1139
============================================================


============================================================
🔄 Round 106 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0893, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0893, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0893, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0892, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0892, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0892, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 106 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0893, RMSE=0.2988, R²=-0.0533
   Val:   Loss=0.0821, RMSE=0.2865, R²=-0.0632
============================================================


============================================================
🔄 Round 107 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0885, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0885, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0885, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0885, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0885, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0884, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 107 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0883, RMSE=0.2971, R²=-0.0437
   Val:   Loss=0.0862, RMSE=0.2937, R²=-0.1005
============================================================


📊 Round 107 Test Metrics:
   Loss: 0.0890, RMSE: 0.2984, MAE: 0.2551, R²: -0.0761

============================================================
🔄 Round 109 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0886, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0886, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0885, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0885, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0885, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0885, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 109 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0883, RMSE=0.2972, R²=-0.0494
   Val:   Loss=0.0860, RMSE=0.2932, R²=-0.1048
============================================================


============================================================
🔄 Round 110 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0994 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0994, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0994, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0994, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0994, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0994, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0994)

============================================================
📊 Round 110 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2915, R²=-0.0540
   Val:   Loss=0.0994, RMSE=0.3153, R²=-0.0570
============================================================


============================================================
🔄 Round 111 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0901, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0901, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0901, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0901, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0901, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0900, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 111 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0899, RMSE=0.2998, R²=-0.0538
   Val:   Loss=0.0797, RMSE=0.2824, R²=-0.0587
============================================================


📊 Round 111 Test Metrics:
   Loss: 0.0890, RMSE: 0.2984, MAE: 0.2551, R²: -0.0760

============================================================
🔄 Round 112 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0899, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0899, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0899, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0899, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0898, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0898, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 112 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0902, RMSE=0.3004, R²=-0.0579
   Val:   Loss=0.0784, RMSE=0.2799, R²=-0.0543
============================================================


============================================================
🔄 Round 113 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0921 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0921, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0921, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0921, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0921, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0921, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0921)

============================================================
📊 Round 113 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2946, R²=-0.0460
   Val:   Loss=0.0921, RMSE=0.3035, R²=-0.0969
============================================================


📊 Round 113 Test Metrics:
   Loss: 0.0890, RMSE: 0.2984, MAE: 0.2551, R²: -0.0761

============================================================
🔄 Round 114 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0924 (↓), lr=0.000001
   • Epoch   2/100: train=0.0867, val=0.0924, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0867, val=0.0924, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0867, val=0.0924, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0867, val=0.0924, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0866, val=0.0925, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0924)

============================================================
📊 Round 114 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0867, RMSE=0.2945, R²=-0.0581
   Val:   Loss=0.0924, RMSE=0.3040, R²=-0.0486
============================================================


============================================================
🔄 Round 115 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0870, val=0.0918 (↓), lr=0.000001
   • Epoch   2/100: train=0.0870, val=0.0918, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0870, val=0.0918, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0870, val=0.0918, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0870, val=0.0918, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0869, val=0.0918, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0918)

============================================================
📊 Round 115 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0869, RMSE=0.2948, R²=-0.0519
   Val:   Loss=0.0918, RMSE=0.3029, R²=-0.0730
============================================================


📊 Round 115 Test Metrics:
   Loss: 0.0890, RMSE: 0.2984, MAE: 0.2552, R²: -0.0762

============================================================
🔄 Round 119 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0890, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0890, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0890, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0889, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0889, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0889, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 119 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0887, RMSE=0.2978, R²=-0.0648
   Val:   Loss=0.0846, RMSE=0.2909, R²=-0.0126
============================================================


📊 Round 119 Test Metrics:
   Loss: 0.0890, RMSE: 0.2984, MAE: 0.2552, R²: -0.0763

============================================================
🔄 Round 122 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0875, val=0.0910 (↓), lr=0.000001
   • Epoch   2/100: train=0.0875, val=0.0910, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0875, val=0.0910, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0875, val=0.0910, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0875, val=0.0910, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0874, val=0.0910, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0910)

============================================================
📊 Round 122 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0871, RMSE=0.2951, R²=-0.0446
   Val:   Loss=0.0910, RMSE=0.3016, R²=-0.1109
============================================================


📊 Round 122 Test Metrics:
   Loss: 0.0890, RMSE: 0.2984, MAE: 0.2552, R²: -0.0764

📊 Round 122 Test Metrics:
   Loss: 0.0890, RMSE: 0.2984, MAE: 0.2552, R²: -0.0763

📊 Round 122 Test Metrics:
   Loss: 0.0890, RMSE: 0.2984, MAE: 0.2552, R²: -0.0763

============================================================
🔄 Round 126 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0875, val=0.0897 (↓), lr=0.000001
   • Epoch   2/100: train=0.0875, val=0.0897, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0875, val=0.0897, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0875, val=0.0897, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0875, val=0.0897, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0874, val=0.0896, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0897)

============================================================
📊 Round 126 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0874, RMSE=0.2956, R²=-0.0471
   Val:   Loss=0.0897, RMSE=0.2995, R²=-0.0922
============================================================


📊 Round 126 Test Metrics:
   Loss: 0.0890, RMSE: 0.2984, MAE: 0.2552, R²: -0.0764

============================================================
🔄 Round 128 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0947 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0947, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0947, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0947, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0947, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0947, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0947)

============================================================
📊 Round 128 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2935, R²=-0.0679
   Val:   Loss=0.0947, RMSE=0.3077, R²=-0.0140
============================================================


============================================================
🔄 Round 129 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0885, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0885, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0885, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0884, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0884, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0884, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 129 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0886, RMSE=0.2977, R²=-0.0656
   Val:   Loss=0.0848, RMSE=0.2911, R²=-0.0129
============================================================


============================================================
🔄 Round 130 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0881, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0881, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0881, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0880, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0880, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0879, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 130 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0883, RMSE=0.2972, R²=-0.0731
   Val:   Loss=0.0861, RMSE=0.2934, R²=-0.0134
============================================================


📊 Round 130 Test Metrics:
   Loss: 0.0890, RMSE: 0.2984, MAE: 0.2551, R²: -0.0761

📊 Round 130 Test Metrics:
   Loss: 0.0890, RMSE: 0.2984, MAE: 0.2551, R²: -0.0762

============================================================
🔄 Round 133 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0871, val=0.0913 (↓), lr=0.000001
   • Epoch   2/100: train=0.0871, val=0.0913, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0871, val=0.0913, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0871, val=0.0913, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0870, val=0.0913, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0870, val=0.0912, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0913)

============================================================
📊 Round 133 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0870, RMSE=0.2950, R²=-0.0587
   Val:   Loss=0.0913, RMSE=0.3021, R²=-0.0380
============================================================


📊 Round 133 Test Metrics:
   Loss: 0.0890, RMSE: 0.2984, MAE: 0.2551, R²: -0.0762

============================================================
🔄 Round 134 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0870, val=0.0907 (↓), lr=0.000001
   • Epoch   2/100: train=0.0870, val=0.0907, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0870, val=0.0907, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0870, val=0.0907, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0870, val=0.0907, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0869, val=0.0907, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0907)

============================================================
📊 Round 134 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0872, RMSE=0.2952, R²=-0.0632
   Val:   Loss=0.0907, RMSE=0.3011, R²=-0.0405
============================================================


📊 Round 134 Test Metrics:
   Loss: 0.0890, RMSE: 0.2984, MAE: 0.2551, R²: -0.0761

📊 Round 134 Test Metrics:
   Loss: 0.0890, RMSE: 0.2984, MAE: 0.2551, R²: -0.0760

============================================================
🔄 Round 136 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0897, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0896, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0896, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0896, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0896, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0895, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 136 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0897, RMSE=0.2995, R²=-0.0632
   Val:   Loss=0.0805, RMSE=0.2838, R²=-0.0186
============================================================


📊 Round 136 Test Metrics:
   Loss: 0.0890, RMSE: 0.2984, MAE: 0.2551, R²: -0.0760

============================================================
🔄 Round 141 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0927, val=0.0685 (↓), lr=0.000001
   • Epoch   2/100: train=0.0927, val=0.0684, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0927, val=0.0684, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0927, val=0.0684, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0927, val=0.0684, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0926, val=0.0684, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0685)

============================================================
📊 Round 141 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0927, RMSE=0.3045, R²=-0.0633
   Val:   Loss=0.0685, RMSE=0.2616, R²=-0.0085
============================================================


============================================================
🔄 Round 143 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0884, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0884, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0883, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0883, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0883, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0883, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 143 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0884, RMSE=0.2973, R²=-0.0620
   Val:   Loss=0.0857, RMSE=0.2928, R²=-0.0245
============================================================


📊 Round 143 Test Metrics:
   Loss: 0.0890, RMSE: 0.2984, MAE: 0.2551, R²: -0.0761

============================================================
🔄 Round 145 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0957 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0957, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0957, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0957, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0957, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0956, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0957)

============================================================
📊 Round 145 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2931, R²=-0.0355
   Val:   Loss=0.0957, RMSE=0.3093, R²=-0.1286
============================================================


📊 Round 145 Test Metrics:
   Loss: 0.0890, RMSE: 0.2984, MAE: 0.2552, R²: -0.0762

📊 Round 145 Test Metrics:
   Loss: 0.0890, RMSE: 0.2984, MAE: 0.2552, R²: -0.0762

📊 Round 145 Test Metrics:
   Loss: 0.0890, RMSE: 0.2984, MAE: 0.2551, R²: -0.0762

📊 Round 145 Test Metrics:
   Loss: 0.0890, RMSE: 0.2984, MAE: 0.2551, R²: -0.0762

============================================================
🔄 Round 151 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0981 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0981, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0981, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0981, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0981, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0980, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0981)

============================================================
📊 Round 151 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2921, R²=-0.0498
   Val:   Loss=0.0981, RMSE=0.3132, R²=-0.0806
============================================================


📊 Round 151 Test Metrics:
   Loss: 0.0890, RMSE: 0.2984, MAE: 0.2551, R²: -0.0762

📊 Round 151 Test Metrics:
   Loss: 0.0890, RMSE: 0.2984, MAE: 0.2552, R²: -0.0762

📊 Round 151 Test Metrics:
   Loss: 0.0890, RMSE: 0.2984, MAE: 0.2552, R²: -0.0763

============================================================
🔄 Round 155 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0986 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0986, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0986, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0986, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0985, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0985, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0986)

============================================================
📊 Round 155 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2919, R²=-0.0444
   Val:   Loss=0.0986, RMSE=0.3140, R²=-0.0909
============================================================


📊 Round 155 Test Metrics:
   Loss: 0.0890, RMSE: 0.2984, MAE: 0.2552, R²: -0.0763

============================================================
🔄 Round 156 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0976 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0976, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0976, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0976, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0976, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0976, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0976)

============================================================
📊 Round 156 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2923, R²=-0.0474
   Val:   Loss=0.0976, RMSE=0.3124, R²=-0.0802
============================================================


📊 Round 156 Test Metrics:
   Loss: 0.0890, RMSE: 0.2984, MAE: 0.2552, R²: -0.0762

============================================================
🔄 Round 158 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0879, val=0.0878 (↓), lr=0.000001
   • Epoch   2/100: train=0.0878, val=0.0878, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0878, val=0.0878, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0878, val=0.0878, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0878, val=0.0878, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0878, val=0.0879, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0878)

============================================================
📊 Round 158 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0879, RMSE=0.2964, R²=-0.0548
   Val:   Loss=0.0878, RMSE=0.2964, R²=-0.0719
============================================================


📊 Round 158 Test Metrics:
   Loss: 0.0890, RMSE: 0.2984, MAE: 0.2552, R²: -0.0763

============================================================
🔄 Round 160 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0986 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0986, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0986, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0986, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0986, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0986, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0986)

============================================================
📊 Round 160 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2919, R²=-0.0512
   Val:   Loss=0.0986, RMSE=0.3140, R²=-0.0675
============================================================


📊 Round 160 Test Metrics:
   Loss: 0.0890, RMSE: 0.2984, MAE: 0.2552, R²: -0.0762

📊 Round 160 Test Metrics:
   Loss: 0.0890, RMSE: 0.2984, MAE: 0.2552, R²: -0.0762

============================================================
🔄 Round 163 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0880, val=0.0881 (↓), lr=0.000001
   • Epoch   2/100: train=0.0879, val=0.0881, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0879, val=0.0881, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0879, val=0.0881, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0879, val=0.0881, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0879, val=0.0880, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0881)

============================================================
📊 Round 163 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0878, RMSE=0.2963, R²=-0.0394
   Val:   Loss=0.0881, RMSE=0.2969, R²=-0.1202
============================================================


📊 Round 163 Test Metrics:
   Loss: 0.0890, RMSE: 0.2984, MAE: 0.2552, R²: -0.0762

============================================================
🔄 Round 164 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0880, val=0.0872 (↓), lr=0.000001
   • Epoch   2/100: train=0.0880, val=0.0872, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0880, val=0.0872, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0880, val=0.0872, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0880, val=0.0872, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0879, val=0.0872, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0872)

============================================================
📊 Round 164 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0880, RMSE=0.2967, R²=-0.0573
   Val:   Loss=0.0872, RMSE=0.2953, R²=-0.0520
============================================================


============================================================
🔄 Round 165 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0908, val=0.0761 (↓), lr=0.000001
   • Epoch   2/100: train=0.0908, val=0.0761, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0908, val=0.0761, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0908, val=0.0761, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0908, val=0.0761, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0907, val=0.0761, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0761)

============================================================
📊 Round 165 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0908, RMSE=0.3013, R²=-0.0607
   Val:   Loss=0.0761, RMSE=0.2759, R²=-0.0260
============================================================


📊 Round 165 Test Metrics:
   Loss: 0.0890, RMSE: 0.2984, MAE: 0.2551, R²: -0.0762

============================================================
🔄 Round 168 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0892, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0892, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0892, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0892, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0892, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0891, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 168 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0893, RMSE=0.2988, R²=-0.0507
   Val:   Loss=0.0823, RMSE=0.2868, R²=-0.0729
============================================================


📊 Round 168 Test Metrics:
   Loss: 0.0890, RMSE: 0.2984, MAE: 0.2551, R²: -0.0761

============================================================
🔄 Round 170 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0966 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0966, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0966, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0966, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0966, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0966, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0966)

============================================================
📊 Round 170 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2927, R²=-0.0538
   Val:   Loss=0.0966, RMSE=0.3108, R²=-0.0590
============================================================


============================================================
🔄 Round 172 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0888, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0888, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0888, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0888, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0888, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0887, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 172 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0890, RMSE=0.2983, R²=-0.0440
   Val:   Loss=0.0833, RMSE=0.2886, R²=-0.1121
============================================================


📊 Round 172 Test Metrics:
   Loss: 0.0890, RMSE: 0.2984, MAE: 0.2551, R²: -0.0762

============================================================
🔄 Round 173 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0924, val=0.0704 (↓), lr=0.000001
   • Epoch   2/100: train=0.0924, val=0.0704, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0923, val=0.0704, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0923, val=0.0704, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0923, val=0.0704, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0923, val=0.0704, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0704)

============================================================
📊 Round 173 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0922, RMSE=0.3037, R²=-0.0527
   Val:   Loss=0.0704, RMSE=0.2653, R²=-0.0791
============================================================


============================================================
🔄 Round 174 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0884, val=0.0865 (↓), lr=0.000001
   • Epoch   2/100: train=0.0884, val=0.0865, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0884, val=0.0865, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0884, val=0.0865, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0884, val=0.0865, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0883, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0865)

============================================================
📊 Round 174 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0882, RMSE=0.2970, R²=-0.0560
   Val:   Loss=0.0865, RMSE=0.2942, R²=-0.0484
============================================================


📊 Round 174 Test Metrics:
   Loss: 0.0890, RMSE: 0.2984, MAE: 0.2551, R²: -0.0762

============================================================
🔄 Round 179 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0922 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0922, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0922, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0922, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0922, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0866, val=0.0922, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0922)

============================================================
📊 Round 179 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2946, R²=-0.0293
   Val:   Loss=0.0922, RMSE=0.3036, R²=-0.1726
============================================================


📊 Round 179 Test Metrics:
   Loss: 0.0890, RMSE: 0.2984, MAE: 0.2551, R²: -0.0761

📊 Round 179 Test Metrics:
   Loss: 0.0890, RMSE: 0.2984, MAE: 0.2551, R²: -0.0760

📊 Round 179 Test Metrics:
   Loss: 0.0890, RMSE: 0.2984, MAE: 0.2551, R²: -0.0761

============================================================
🔄 Round 184 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0881, val=0.0871 (↓), lr=0.000001
   • Epoch   2/100: train=0.0881, val=0.0871, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0881, val=0.0871, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0881, val=0.0871, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0881, val=0.0871, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0880, val=0.0871, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0871)

============================================================
📊 Round 184 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0881, RMSE=0.2968, R²=-0.0455
   Val:   Loss=0.0871, RMSE=0.2951, R²=-0.1077
============================================================


📊 Round 184 Test Metrics:
   Loss: 0.0890, RMSE: 0.2983, MAE: 0.2551, R²: -0.0759

============================================================
🔄 Round 191 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0882, val=0.0878 (↓), lr=0.000001
   • Epoch   2/100: train=0.0882, val=0.0878, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0882, val=0.0878, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0882, val=0.0878, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0882, val=0.0878, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0881, val=0.0878, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0878)

============================================================
📊 Round 191 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0879, RMSE=0.2965, R²=-0.0576
   Val:   Loss=0.0878, RMSE=0.2963, R²=-0.0449
============================================================


📊 Round 191 Test Metrics:
   Loss: 0.0890, RMSE: 0.2983, MAE: 0.2551, R²: -0.0759

📊 Round 191 Test Metrics:
   Loss: 0.0890, RMSE: 0.2983, MAE: 0.2551, R²: -0.0758

============================================================
🔄 Round 196 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0879, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0879, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0879, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0879, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0879, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0878, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 196 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0883, RMSE=0.2971, R²=-0.0547
   Val:   Loss=0.0862, RMSE=0.2936, R²=-0.0672
============================================================


📊 Round 196 Test Metrics:
   Loss: 0.0890, RMSE: 0.2983, MAE: 0.2551, R²: -0.0759

📊 Round 196 Test Metrics:
   Loss: 0.0890, RMSE: 0.2983, MAE: 0.2551, R²: -0.0759

============================================================
🔄 Round 199 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0879, val=0.0878 (↓), lr=0.000001
   • Epoch   2/100: train=0.0879, val=0.0878, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0879, val=0.0878, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0878, val=0.0878, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0878, val=0.0878, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0878, val=0.0878, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0878)

============================================================
📊 Round 199 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0879, RMSE=0.2965, R²=-0.0517
   Val:   Loss=0.0878, RMSE=0.2963, R²=-0.0693
============================================================


============================================================
🔄 Round 200 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0887, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0887, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0887, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0886, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0886, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0886, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 200 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0887, RMSE=0.2979, R²=-0.0507
   Val:   Loss=0.0844, RMSE=0.2906, R²=-0.0726
============================================================


📊 Round 200 Test Metrics:
   Loss: 0.0890, RMSE: 0.2983, MAE: 0.2551, R²: -0.0759

============================================================
🔄 Round 202 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0877, val=0.0881 (↓), lr=0.000001
   • Epoch   2/100: train=0.0877, val=0.0880, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0876, val=0.0880, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0876, val=0.0880, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0876, val=0.0880, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0876, val=0.0880, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0881)

============================================================
📊 Round 202 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0878, RMSE=0.2964, R²=-0.0528
   Val:   Loss=0.0881, RMSE=0.2967, R²=-0.0640
============================================================


============================================================
🔄 Round 204 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0886, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0886, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0886, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0886, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0886, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0885, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 204 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0885, RMSE=0.2976, R²=-0.0564
   Val:   Loss=0.0852, RMSE=0.2919, R²=-0.0475
============================================================


📊 Round 204 Test Metrics:
   Loss: 0.0890, RMSE: 0.2983, MAE: 0.2551, R²: -0.0757

📊 Round 204 Test Metrics:
   Loss: 0.0890, RMSE: 0.2983, MAE: 0.2551, R²: -0.0758

📊 Round 204 Test Metrics:
   Loss: 0.0890, RMSE: 0.2983, MAE: 0.2551, R²: -0.0758

📊 Round 204 Test Metrics:
   Loss: 0.0890, RMSE: 0.2983, MAE: 0.2551, R²: -0.0758

📊 Round 204 Test Metrics:
   Loss: 0.0890, RMSE: 0.2983, MAE: 0.2551, R²: -0.0759

============================================================
🔄 Round 210 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0943 (↓), lr=0.000001
   • Epoch   2/100: train=0.0867, val=0.0943, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0867, val=0.0943, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0867, val=0.0943, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0867, val=0.0943, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0866, val=0.0943, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0943)

============================================================
📊 Round 210 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2937, R²=-0.0511
   Val:   Loss=0.0943, RMSE=0.3071, R²=-0.0755
============================================================


📊 Round 210 Test Metrics:
   Loss: 0.0890, RMSE: 0.2983, MAE: 0.2551, R²: -0.0759

📊 Round 210 Test Metrics:
   Loss: 0.0890, RMSE: 0.2983, MAE: 0.2551, R²: -0.0759

📊 Round 210 Test Metrics:
   Loss: 0.0890, RMSE: 0.2983, MAE: 0.2551, R²: -0.0759

============================================================
🔄 Round 214 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0878, val=0.0885 (↓), lr=0.000001
   • Epoch   2/100: train=0.0878, val=0.0885, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0878, val=0.0885, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0878, val=0.0885, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0878, val=0.0885, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0877, val=0.0884, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0885)

============================================================
📊 Round 214 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0877, RMSE=0.2962, R²=-0.0382
   Val:   Loss=0.0885, RMSE=0.2976, R²=-0.1255
============================================================


📊 Round 214 Test Metrics:
   Loss: 0.0890, RMSE: 0.2983, MAE: 0.2551, R²: -0.0758

📊 Round 214 Test Metrics:
   Loss: 0.0890, RMSE: 0.2983, MAE: 0.2551, R²: -0.0758

📊 Round 214 Test Metrics:
   Loss: 0.0890, RMSE: 0.2983, MAE: 0.2551, R²: -0.0759

============================================================
🔄 Round 221 - Client client_14
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0884, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0884, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0884, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0883, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0883, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0883, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 221 Summary - Client client_14
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0887, RMSE=0.2978, R²=-0.0729
   Val:   Loss=0.0846, RMSE=0.2909, R²=0.0157
============================================================


📊 Round 221 Test Metrics:
   Loss: 0.0890, RMSE: 0.2983, MAE: 0.2551, R²: -0.0759

📊 Round 221 Test Metrics:
   Loss: 0.0890, RMSE: 0.2984, MAE: 0.2551, R²: -0.0760

❌ Client client_14 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8687 {grpc_message:"Socket closed", grpc_status:14}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8687 {grpc_message:"Socket closed", grpc_status:14}"
>
