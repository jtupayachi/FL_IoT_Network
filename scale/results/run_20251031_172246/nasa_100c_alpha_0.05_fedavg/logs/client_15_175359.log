[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 477c9a75-ad13-4fb5-9503-ea198a3e6a0b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2716be14-af94-4ac0-ba67-a8d333ec8a83
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a05800ed-58ea-4e30-befa-d13ad950d6df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d5f529da-60b2-4056-ae57-8402fe73c462
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f9328b57-91c3-43b8-abeb-b50fc7b1eb13
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 77cb8de2-9390-46c4-b505-8a390a48854e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 11f34ece-2ca5-4e8e-806f-efcbe845e31a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 48e5533d-dbba-4f8d-be9f-02d146629b97
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3ed634d3-9f8f-420d-bf11-9229141affa1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b9e418e0-bba9-4e7d-97d0-530291ead4d1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fc4279e3-5818-4f69-82b9-26b9778def25
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d5bf4572-6783-47db-a4de-a4a8a0d143c7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3ffe5451-c905-4707-8d07-50b069feae5a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3dd63af6-fd97-46d8-a084-e73b0d511f3e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 962ed4e6-90a4-4c1a-aebe-ac74651881f3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4dfae7b7-7e87-44ae-8482-361bb198186a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4b4c6215-c51e-457a-abd1-568ff0865443
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 706dd214-f31e-4c85-957d-c5dac2238d58
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 987efed7-9f55-46c6-ba63-bae4e2a1551d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7f2877bb-c199-4f15-8e18-41e8c28bff2f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message acb94f0f-1711-4f41-8e0c-31ae54dc2b1e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eecb3d61-e446-4a34-8faf-8eb9688e8d61
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message db007b44-ff66-4f94-bafb-db80b2cc355d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7fbc32cc-696a-42a2-8591-fcfdc3cbd99b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 494f529c-150c-4952-bb6a-4b18af51eb96
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2cd1c95e-5ba8-49d3-84b3-2891f9d162db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f6dde895-e0ea-4cb8-9ab5-8754fd119efc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6a1eebac-ec1f-4c71-9590-10a862888836
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3be7a1e6-2c9d-473a-9229-a1aeee830958
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c34bcf27-f7c4-408e-ac74-8fb2de417686
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ceb0995f-0f35-458e-8a64-893b46e4102f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2108a343-8ad6-4d19-b80b-c7ff2f714d46
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3bebfdc6-80e4-4a92-a14b-d8a82dddc170
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 483b1545-ed3a-47c9-8636-d3b9f0f32f12
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9469cc90-cd52-428e-a334-2bdfddc470aa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3d351e54-f699-404a-be3c-f76ff0323013
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1e382ccb-9577-4a68-9563-11fb612ac13c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0edcf02b-90bf-4724-8df9-d444ef97d47f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e3504388-dcc4-4004-921e-0fc689af01f4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6caa4eba-056d-4e51-94b8-b6d64870251b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 87feaac5-7825-43ef-90dd-3933ef2b76b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 62ec4e42-4757-4a50-8cbe-a40f35d2b1db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3743d056-03e3-4b14-9cf1-7045e92deced
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1082fcd1-7eb6-4f57-ad2e-772022ca0ae9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 26bdb5f5-04ae-4a87-a49c-a1bd2f645023
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 19223e7e-3136-483a-93cf-3b8751d36542
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7105c3cd-1d17-471f-9ea3-7335f440d78f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0e46bcdc-6d96-4b4c-84df-17d95e0ada53
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 05ebcae0-955f-4b8a-b8e8-fcaaf2ab2038
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b9751b37-7fe8-4332-8eb8-1ffafd70a385
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5ed8738f-a57c-4b5c-9a1b-d872854625fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c2e61176-b2d1-44f4-8bd7-8ea1ea49ddab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 82b54be8-e31e-4063-842d-6dbae71f42fb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 60b83bbb-4713-4973-9081-217ca84962a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9f4116c7-33b7-4935-b93e-248ea53020a0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4e4db74b-6244-4dd6-9c25-d743431acbcc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c79ee30d-0424-4d7a-abfa-2a48c977a69d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 31ba31e9-781b-41c0-9330-46cf2d1187ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 83ccebd8-b4fb-4e0f-9f84-3883f595dac9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7bd3ca9c-f386-4c89-8574-bde27da135ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aa96f0e8-50d0-4c0a-9dc0-ae4d51747f3c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3ed499c0-5730-4175-b942-58f169c66f75
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 90f1792f-5176-4d5c-9225-6632a50b72f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 180e6ab9-9556-4dcd-a046-57913e86fc03
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4f74fcce-46a3-44c9-8797-2d7403975efc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5484f86c-2f92-4b4d-9d56-06d951c8402d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 715fdd2a-1fa3-4d5b-8aaa-bf071e6ae676
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dbe31e9e-d2f0-4f5b-8376-f2378ab8a13a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e5dce344-5803-4448-ac06-9fef747e423c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0e9af209-ab6b-41fd-8859-48db481f30b9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cb4d42b2-a098-48b6-97c0-23498e66c005
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ed0892fa-0665-4bd5-ac64-15e6a66c1a90
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 053118b2-685a-477a-8542-67d2d9d8562b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aef3fef4-0e03-4513-b279-463fe79879db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 065cda6d-8aad-445b-9fcf-1abd360d1d88
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5aa2348a-ec10-4e34-aafe-e98185faba8a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a01bf008-8415-4849-a566-ef94580d96bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ed25d83b-e425-4202-bd09-921cd4186a6f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f3c6ae5a-51ee-417f-bcc8-f059cbd4c33e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fd0f84b0-0b5f-41b9-8a09-3e8e34026a13
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 54fefe59-d450-41d1-b3a5-df90b265cc10
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4afd56d0-5dc7-4df4-8e79-1cc1561ce516
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4ef3c48d-3f8c-43a8-8499-cf7b1330d17a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8cddb268-733a-4dc6-a7d3-b75e59f5e063
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 22ab24ba-02e2-427e-b554-3d3e0416e3c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fd78d04f-f7ef-4642-9e1e-2a56b26b2de7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 33eea798-b271-46c1-be61-9a652e0f88cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6ec8c173-d257-4496-bb0e-399bda229e37
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 89b497d2-1c20-4172-b786-e5242049615a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 496734e1-3bff-4c3e-a0a4-db7416cf06e6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d9e29051-043c-45a1-93ab-97a2779074f2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 49aed8d3-081a-4df5-89a8-a56b96fbab56
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bd6a7d35-9529-45c3-96fb-8e0b3abd055c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 848dfa54-810b-4a5a-aa2d-b6d7d470ed12
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 062e6c2b-af48-4b91-889e-7c52e2c23a68
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2ef1d7cd-70aa-4c3f-ab82-354519c59841
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e16e3824-6ac2-42c1-bb1e-ab2b5f806786
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 28228782-ea9f-4608-a951-588540095c74
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 24d19f2d-978b-48a0-84bb-4aa8ad80a80c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2e8b6e36-8951-49f4-b07c-209e13dd0ae3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cb3b1d74-ef91-44ed-9c2a-3348951911a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f890cab9-aa06-4639-8f0f-b2c5a683d1f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bdffd2de-56e5-4e62-9744-101e5c904fa5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 314607ac-3b7a-4253-9862-29902cf19b60
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6c37d3fe-42e6-4a52-b316-e07f8cb2129b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 05b41b7c-4d8d-4a9e-9256-113a8ab062da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7b05e0f7-81b7-488d-9956-4686e1e5b53b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 65ee90eb-cdb9-4353-b900-443e3ac0b984
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5dca82ce-bc00-43e5-9e93-4eadc5aa9206
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5e1d8a99-dbd3-4f36-9270-31b9ed06b282
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a887f153-a6e0-47f6-9634-11bac8ca4b91
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f81129f4-fe84-42d1-b6d5-92057dee7cc3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7977dcc9-c94b-44da-ab46-454e810cf535
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 22c42c6d-27a8-4345-a7f7-b38a1396bacd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5a477d51-8592-412d-9163-cdd77175f615
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 60c27e45-61da-4b1b-a421-118dfd621407
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f30c1e86-bf51-46f0-bcbd-5d89ca014669
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2ab18e80-31f4-42ed-b2a6-30d7cd9f0d56
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ca755763-2c86-402f-9b49-2ff163cb5336
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9c591cf2-fc50-4c08-9c9b-a28fb2aa0d38
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 96e874c8-4e69-4d2d-9362-8ca8ce9c4430
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cfb571e0-7db7-4c41-b32d-95ff054d6728
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b3220ede-4c1e-45df-9ffd-73dd1d0d5438
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5a2aa303-3208-4775-831a-5dd5479ad0a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6fc31193-2dff-4654-9cad-500cd47b9dcc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 56099b94-bd96-4c3a-8a7c-cea559b12985
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ce1bb8b0-6b3d-482c-85e2-4cdd7930de44
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 886067b3-5d29-42fa-9d46-4244ee3cf126
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 67cf1ca6-8d3e-4471-a51f-76cefe6f96c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d8ef5647-3513-4c3f-a669-33d827a98c62
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2be86d95-1c7a-4708-a8e7-deaf340ece32
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f21bd7cb-f411-4549-a0d1-ef5778e735a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e5df98cf-79b9-4e7f-a659-ffe6e6dc8618
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c40b203d-0cc3-4095-89eb-4d2dec8a92a0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 545529c1-ff30-4f05-aeaf-f62fd4ffbbd4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 42f9f0b0-dcd5-4afa-babf-a5cd9337c85d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f3fc1256-340d-4045-b0e1-828606d01641
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 49e31d61-8bd8-4a0d-80b2-58882cf9def2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6e4ee88f-1d3f-4f8a-bcca-7365c9360f5c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 54f00da9-44dc-44ba-a5f5-fb3936659e31
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6ba2b885-96e6-45ee-8e0e-ce9fcd7bf08c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 15e0071b-1559-48ff-9482-372222d5993f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 332dd3c5-05ca-41d8-85ac-590d502f0350
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message add19b9d-b121-4e8f-8301-c3b0a3c1a2f4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e946f87c-1778-435e-aa42-381b70bd8f37
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3a8fa127-1ce9-4ff0-b725-b5585fad5b0f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 43cd6c54-bfb4-42dc-b7f3-d49c4c987fee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 32cf1c69-40ce-4dac-8827-a1b783c58813
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2dcba3c3-f7a9-4de8-b9c7-dfd5fe745ff9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 68dab904-4585-4f60-9a4d-bf3f75541fdf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message df9c8cfc-bc8d-417b-826b-473f45f88592
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4833c34b-c9ad-4c24-ac21-ca273bcb1fce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a1a405b8-d0f9-4d17-8e9a-7610c886a80f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 82c4e525-b07a-4122-9b98-9925158e2bde
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 772fa4a9-3fe1-40ae-ba35-b9e38fbe7cda
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a82a1234-633c-4038-b8d4-57ed4c9ddf0c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 542aabba-bb6d-4b49-9fdd-27a907fe5a21
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 42317202-63bc-4471-9759-eb4eed892ade
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ca823840-0cc2-448c-bd8c-efe7eca27766
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e9339354-d21f-423a-92a3-966f76218759
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fd3ae1f7-c36c-4ab2-874d-4b85b9784cd3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 32c3a2e6-f1d3-43bb-b398-7333acddb3b8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 408edbe6-f14d-4c87-ba22-c5b874f15b06
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1f1a82c7-81a3-4dc7-8f0f-a82361501df5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 857f26e3-1e03-41cb-b484-7f25099b51db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c714de31-9221-42c0-9e13-7384de42c903
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e3574cb6-4841-451c-9418-c59e815aacbb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1119d7d6-05fc-4ef0-8043-d854face5841
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 241d286a-639b-4d47-b5b4-ea69c2d4c670
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 227f2c12-fce5-4d17-92d1-4dbd7bdc45f3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 62aedd56-b5a9-49fd-99a4-04edfe248ab9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7fc1958c-14bb-4855-822a-fc390a01a627
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8687 {grpc_message:"Socket closed", grpc_status:14}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_15
Server: localhost:8687
Algorithm: FEDAVG
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_15
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_15/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_15/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_15/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_15/test_labels.txt

📊 Raw data loaded:
   Train: X=(875, 24), y=(875,)
   Test:  X=(219, 24), y=(219,)

⚠️  Limiting training data: 875 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  210 samples, 5 features
✅ Client client_15 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

============================================================
🔄 Round 4 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0872, val=0.0833 (↓), lr=0.001000
   ✓ Epoch   2/100: train=0.0854, val=0.0798 (↓), lr=0.001000
   • Epoch   3/100: train=0.0847, val=0.0798, patience=1/15, lr=0.001000
   • Epoch   4/100: train=0.0840, val=0.0799, patience=2/15, lr=0.001000
   • Epoch   5/100: train=0.0834, val=0.0801, patience=3/15, lr=0.001000
   📉 Epoch 8: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0797, val=0.0813, patience=9/15, lr=0.000500
   📉 Epoch 16: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 4 Summary - Client client_15
   Epochs: 17/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0827, RMSE=0.2877, R²=0.0157
   Val:   Loss=0.0798, RMSE=0.2824, R²=0.0258
============================================================


📊 Round 4 Test Metrics:
   Loss: 0.0778, RMSE: 0.2789, MAE: 0.2419, R²: -0.0039

📊 Round 4 Test Metrics:
   Loss: 0.0774, RMSE: 0.2783, MAE: 0.2412, R²: 0.0002

============================================================
🔄 Round 6 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0813 (↓), lr=0.000250
   • Epoch   2/100: train=0.0837, val=0.0809, patience=1/15, lr=0.000250
   ✓ Epoch   3/100: train=0.0831, val=0.0807 (↓), lr=0.000250
   • Epoch   4/100: train=0.0829, val=0.0806, patience=1/15, lr=0.000250
   • Epoch   5/100: train=0.0827, val=0.0805, patience=2/15, lr=0.000250
   📉 Epoch 7: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0818, val=0.0803, patience=8/15, lr=0.000125
   📉 Epoch 15: LR reduced 0.000125 → 0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 6 Summary - Client client_15
   Epochs: 18/100 (early stopped)
   LR: 0.000250 → 0.000063 (2 reductions)
   Train: Loss=0.0827, RMSE=0.2875, R²=0.0182
   Val:   Loss=0.0807, RMSE=0.2841, R²=0.0086
============================================================


📊 Round 6 Test Metrics:
   Loss: 0.0775, RMSE: 0.2785, MAE: 0.2417, R²: -0.0011

============================================================
🔄 Round 7 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0875 (↓), lr=0.000063
   • Epoch   2/100: train=0.0824, val=0.0876, patience=1/15, lr=0.000063
   • Epoch   3/100: train=0.0822, val=0.0876, patience=2/15, lr=0.000063
   • Epoch   4/100: train=0.0821, val=0.0875, patience=3/15, lr=0.000063
   📉 Epoch 5: LR reduced 0.000063 → 0.000031
   • Epoch   5/100: train=0.0820, val=0.0875, patience=4/15, lr=0.000031
   • Epoch  11/100: train=0.0815, val=0.0874, patience=10/15, lr=0.000031
   📉 Epoch 13: LR reduced 0.000031 → 0.000016

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0875)

============================================================
📊 Round 7 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000063 → 0.000016 (2 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=0.0036
   Val:   Loss=0.0875, RMSE=0.2959, R²=-0.0017
============================================================


📊 Round 7 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2408, R²: 0.0046

📊 Round 7 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2411, R²: 0.0009

============================================================
🔄 Round 11 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000016
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0941 (↓), lr=0.000016
   • Epoch   2/100: train=0.0810, val=0.0940, patience=1/15, lr=0.000016
   • Epoch   3/100: train=0.0808, val=0.0939, patience=2/15, lr=0.000016
   • Epoch   4/100: train=0.0807, val=0.0939, patience=3/15, lr=0.000016
   📉 Epoch 5: LR reduced 0.000016 → 0.000008
   • Epoch   5/100: train=0.0806, val=0.0938, patience=4/15, lr=0.000008
   • Epoch  11/100: train=0.0804, val=0.0938, patience=10/15, lr=0.000008
   📉 Epoch 13: LR reduced 0.000008 → 0.000004

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0941)

============================================================
📊 Round 11 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000016 → 0.000004 (2 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=0.0012
   Val:   Loss=0.0941, RMSE=0.3068, R²=-0.0056
============================================================


📊 Round 11 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2415, R²: -0.0027

============================================================
🔄 Round 14 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000004
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0934 (↓), lr=0.000004
   • Epoch   2/100: train=0.0812, val=0.0933, patience=1/15, lr=0.000004
   • Epoch   3/100: train=0.0812, val=0.0933, patience=2/15, lr=0.000004
   • Epoch   4/100: train=0.0811, val=0.0933, patience=3/15, lr=0.000004
   📉 Epoch 5: LR reduced 0.000004 → 0.000002
   • Epoch   5/100: train=0.0811, val=0.0933, patience=4/15, lr=0.000002
   • Epoch  11/100: train=0.0810, val=0.0932, patience=10/15, lr=0.000002
   📉 Epoch 13: LR reduced 0.000002 → 0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0934)

============================================================
📊 Round 14 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000004 → 0.000001 (2 reductions)
   Train: Loss=0.0813, RMSE=0.2852, R²=-0.0028
   Val:   Loss=0.0934, RMSE=0.3056, R²=0.0059
============================================================


============================================================
🔄 Round 15 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0991 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0991, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0991, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0991, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0991, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0990, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0991)

============================================================
📊 Round 15 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=0.0032
   Val:   Loss=0.0991, RMSE=0.3149, R²=-0.0374
============================================================


📊 Round 15 Test Metrics:
   Loss: 0.0776, RMSE: 0.2786, MAE: 0.2414, R²: -0.0019

📊 Round 15 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2415, R²: -0.0027

📊 Round 15 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2415, R²: -0.0030

📊 Round 15 Test Metrics:
   Loss: 0.0776, RMSE: 0.2786, MAE: 0.2414, R²: -0.0022

📊 Round 15 Test Metrics:
   Loss: 0.0778, RMSE: 0.2789, MAE: 0.2418, R²: -0.0044

============================================================
🔄 Round 21 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0871 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0871, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0871, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0871, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0871, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0871, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0871)

============================================================
📊 Round 21 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2880, R²=-0.0096
   Val:   Loss=0.0871, RMSE=0.2952, R²=0.0283
============================================================


📊 Round 21 Test Metrics:
   Loss: 0.0778, RMSE: 0.2789, MAE: 0.2417, R²: -0.0042

============================================================
🔄 Round 25 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0873 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0873, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0873, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0873, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0873, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0872, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0873)

============================================================
📊 Round 25 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2880, R²=-0.0066
   Val:   Loss=0.0873, RMSE=0.2955, R²=0.0136
============================================================


============================================================
🔄 Round 27 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0768 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0768, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0768, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0768, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0768, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0767, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0768)

============================================================
📊 Round 27 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2925, R²=-0.0064
   Val:   Loss=0.0768, RMSE=0.2771, R²=0.0185
============================================================


============================================================
🔄 Round 28 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 28 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2911, R²=-0.0038
   Val:   Loss=0.0802, RMSE=0.2832, R²=-0.0176
============================================================


📊 Round 28 Test Metrics:
   Loss: 0.0778, RMSE: 0.2789, MAE: 0.2417, R²: -0.0042

============================================================
🔄 Round 30 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 30 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2911, R²=-0.0080
   Val:   Loss=0.0800, RMSE=0.2829, R²=0.0201
============================================================


📊 Round 30 Test Metrics:
   Loss: 0.0778, RMSE: 0.2789, MAE: 0.2417, R²: -0.0042

📊 Round 30 Test Metrics:
   Loss: 0.0778, RMSE: 0.2789, MAE: 0.2417, R²: -0.0043

📊 Round 30 Test Metrics:
   Loss: 0.0778, RMSE: 0.2789, MAE: 0.2417, R²: -0.0042

============================================================
🔄 Round 34 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0887 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0887, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0887, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0887, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0886, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0886, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0887)

============================================================
📊 Round 34 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=-0.0019
   Val:   Loss=0.0887, RMSE=0.2978, R²=-0.0216
============================================================


📊 Round 34 Test Metrics:
   Loss: 0.0778, RMSE: 0.2789, MAE: 0.2417, R²: -0.0043

============================================================
🔄 Round 36 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 36 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=-0.0018
   Val:   Loss=0.0834, RMSE=0.2888, R²=-0.0083
============================================================


📊 Round 36 Test Metrics:
   Loss: 0.0778, RMSE: 0.2789, MAE: 0.2417, R²: -0.0042

============================================================
🔄 Round 38 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0897 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0897, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0897, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0897, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0897, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0896, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0897)

============================================================
📊 Round 38 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2870, R²=-0.0064
   Val:   Loss=0.0897, RMSE=0.2995, R²=0.0136
============================================================


📊 Round 38 Test Metrics:
   Loss: 0.0778, RMSE: 0.2789, MAE: 0.2417, R²: -0.0042

============================================================
🔄 Round 40 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 40 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2887, R²=-0.0057
   Val:   Loss=0.0856, RMSE=0.2927, R²=0.0117
============================================================


📊 Round 40 Test Metrics:
   Loss: 0.0778, RMSE: 0.2789, MAE: 0.2417, R²: -0.0042

============================================================
🔄 Round 41 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0874 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0874, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0874, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0874, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0874, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0873, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0874)

============================================================
📊 Round 41 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=0.0014
   Val:   Loss=0.0874, RMSE=0.2957, R²=-0.0170
============================================================


📊 Round 41 Test Metrics:
   Loss: 0.0778, RMSE: 0.2789, MAE: 0.2417, R²: -0.0043

============================================================
🔄 Round 44 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0865 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0865, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0865, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0865, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0865, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0864, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0865)

============================================================
📊 Round 44 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=-0.0074
   Val:   Loss=0.0865, RMSE=0.2942, R²=0.0191
============================================================


📊 Round 44 Test Metrics:
   Loss: 0.0778, RMSE: 0.2789, MAE: 0.2417, R²: -0.0041

============================================================
🔄 Round 52 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0870 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0870, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0869, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0869, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0869, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0868, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 52 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=0.0009
   Val:   Loss=0.0870, RMSE=0.2949, R²=-0.0200
============================================================


============================================================
🔄 Round 53 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0895 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0895, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0895, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0895, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0895, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0895, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0895)

============================================================
📊 Round 53 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=0.0007
   Val:   Loss=0.0895, RMSE=0.2992, R²=-0.0155
============================================================


📊 Round 53 Test Metrics:
   Loss: 0.0778, RMSE: 0.2789, MAE: 0.2417, R²: -0.0040

============================================================
🔄 Round 57 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0737 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0737, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0737, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0737, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0737, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0736, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0737)

============================================================
📊 Round 57 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2938, R²=-0.0026
   Val:   Loss=0.0737, RMSE=0.2715, R²=0.0012
============================================================


📊 Round 57 Test Metrics:
   Loss: 0.0778, RMSE: 0.2788, MAE: 0.2417, R²: -0.0039

============================================================
🔄 Round 58 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 58 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=-0.0037
   Val:   Loss=0.0835, RMSE=0.2889, R²=-0.0046
============================================================


============================================================
🔄 Round 59 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0956 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0957, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0957, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0957, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0958, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0960, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0956)

============================================================
📊 Round 59 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=-0.0009
   Val:   Loss=0.0956, RMSE=0.3093, R²=-0.0507
============================================================


📊 Round 59 Test Metrics:
   Loss: 0.0778, RMSE: 0.2788, MAE: 0.2417, R²: -0.0039

============================================================
🔄 Round 60 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 60 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=0.0007
   Val:   Loss=0.0843, RMSE=0.2903, R²=-0.0329
============================================================


📊 Round 60 Test Metrics:
   Loss: 0.0778, RMSE: 0.2788, MAE: 0.2417, R²: -0.0039

============================================================
🔄 Round 62 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0864, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 62 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=0.0056
   Val:   Loss=0.0864, RMSE=0.2940, R²=-0.0322
============================================================


============================================================
🔄 Round 64 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 64 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=-0.0047
   Val:   Loss=0.0811, RMSE=0.2848, R²=0.0081
============================================================


📊 Round 64 Test Metrics:
   Loss: 0.0778, RMSE: 0.2789, MAE: 0.2417, R²: -0.0040

============================================================
🔄 Round 66 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 66 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2908, R²=-0.0082
   Val:   Loss=0.0808, RMSE=0.2843, R²=0.0136
============================================================


============================================================
🔄 Round 67 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0863 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 67 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=-0.0028
   Val:   Loss=0.0863, RMSE=0.2937, R²=-0.0013
============================================================


📊 Round 67 Test Metrics:
   Loss: 0.0778, RMSE: 0.2789, MAE: 0.2417, R²: -0.0040

============================================================
🔄 Round 70 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 70 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=-0.0005
   Val:   Loss=0.0807, RMSE=0.2841, R²=-0.0089
============================================================


============================================================
🔄 Round 71 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0868 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0868, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0868, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0868, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0868, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0867, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0868)

============================================================
📊 Round 71 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2882, R²=0.0014
   Val:   Loss=0.0868, RMSE=0.2946, R²=-0.0148
============================================================


============================================================
🔄 Round 74 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 74 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=-0.0109
   Val:   Loss=0.0795, RMSE=0.2820, R²=0.0330
============================================================


============================================================
🔄 Round 75 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 75 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2906, R²=-0.0000
   Val:   Loss=0.0814, RMSE=0.2853, R²=-0.0102
============================================================


📊 Round 75 Test Metrics:
   Loss: 0.0778, RMSE: 0.2789, MAE: 0.2417, R²: -0.0041

============================================================
🔄 Round 78 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0895 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0895, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0895, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0894, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0894, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0894, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0895)

============================================================
📊 Round 78 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=-0.0034
   Val:   Loss=0.0895, RMSE=0.2991, R²=0.0020
============================================================


📊 Round 78 Test Metrics:
   Loss: 0.0778, RMSE: 0.2789, MAE: 0.2417, R²: -0.0041

============================================================
🔄 Round 80 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0869 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0868, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0868, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0868, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0868, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0867, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 80 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2882, R²=-0.0064
   Val:   Loss=0.0869, RMSE=0.2947, R²=0.0146
============================================================


============================================================
🔄 Round 82 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 82 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=0.0013
   Val:   Loss=0.0851, RMSE=0.2917, R²=-0.0419
============================================================


============================================================
🔄 Round 83 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 83 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2887, R²=-0.0040
   Val:   Loss=0.0858, RMSE=0.2929, R²=0.0053
============================================================


============================================================
🔄 Round 84 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 84 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2915, R²=-0.0013
   Val:   Loss=0.0793, RMSE=0.2815, R²=-0.0153
============================================================


============================================================
🔄 Round 87 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0737 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0736, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0736, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0736, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0736, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0736, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0737)

============================================================
📊 Round 87 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2939, R²=0.0049
   Val:   Loss=0.0737, RMSE=0.2714, R²=-0.0356
============================================================


============================================================
🔄 Round 88 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 88 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2906, R²=-0.0013
   Val:   Loss=0.0813, RMSE=0.2851, R²=-0.0067
============================================================


📊 Round 88 Test Metrics:
   Loss: 0.0778, RMSE: 0.2789, MAE: 0.2417, R²: -0.0040

============================================================
🔄 Round 89 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0879 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0879, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0879, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0879, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0879, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0879, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0879)

============================================================
📊 Round 89 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=-0.0057
   Val:   Loss=0.0879, RMSE=0.2965, R²=0.0083
============================================================


📊 Round 89 Test Metrics:
   Loss: 0.0778, RMSE: 0.2789, MAE: 0.2417, R²: -0.0040

============================================================
🔄 Round 91 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 91 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=-0.0005
   Val:   Loss=0.0852, RMSE=0.2919, R²=-0.0081
============================================================


============================================================
🔄 Round 92 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 92 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=-0.0038
   Val:   Loss=0.0806, RMSE=0.2840, R²=0.0052
============================================================


============================================================
🔄 Round 93 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 93 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=-0.0062
   Val:   Loss=0.0855, RMSE=0.2924, R²=0.0136
============================================================


📊 Round 93 Test Metrics:
   Loss: 0.0778, RMSE: 0.2789, MAE: 0.2417, R²: -0.0039

📊 Round 93 Test Metrics:
   Loss: 0.0778, RMSE: 0.2789, MAE: 0.2417, R²: -0.0040

============================================================
🔄 Round 95 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0900 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0900, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0900, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0900, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0900, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0899, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0900)

============================================================
📊 Round 95 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2868, R²=0.0048
   Val:   Loss=0.0900, RMSE=0.3000, R²=-0.0287
============================================================


📊 Round 95 Test Metrics:
   Loss: 0.0778, RMSE: 0.2789, MAE: 0.2417, R²: -0.0040

============================================================
🔄 Round 97 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 97 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2908, R²=-0.0001
   Val:   Loss=0.0809, RMSE=0.2845, R²=-0.0109
============================================================


📊 Round 97 Test Metrics:
   Loss: 0.0778, RMSE: 0.2789, MAE: 0.2417, R²: -0.0040

============================================================
🔄 Round 98 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0878 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0878, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0878, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0878, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0878, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0879, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0878)

============================================================
📊 Round 98 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=-0.0137
   Val:   Loss=0.0878, RMSE=0.2964, R²=0.0390
============================================================


============================================================
🔄 Round 100 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 100 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2892, R²=0.0013
   Val:   Loss=0.0845, RMSE=0.2907, R²=-0.0160
============================================================


📊 Round 100 Test Metrics:
   Loss: 0.0778, RMSE: 0.2789, MAE: 0.2417, R²: -0.0041

============================================================
🔄 Round 105 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 105 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=0.0011
   Val:   Loss=0.0861, RMSE=0.2934, R²=-0.0528
============================================================


📊 Round 105 Test Metrics:
   Loss: 0.0778, RMSE: 0.2789, MAE: 0.2417, R²: -0.0041

============================================================
🔄 Round 108 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 108 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2904, R²=-0.0030
   Val:   Loss=0.0818, RMSE=0.2860, R²=-0.0017
============================================================


============================================================
🔄 Round 109 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 109 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=0.0002
   Val:   Loss=0.0811, RMSE=0.2848, R²=-0.0202
============================================================


============================================================
🔄 Round 110 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 110 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2917, R²=-0.0016
   Val:   Loss=0.0789, RMSE=0.2809, R²=-0.0055
============================================================


📊 Round 110 Test Metrics:
   Loss: 0.0778, RMSE: 0.2789, MAE: 0.2417, R²: -0.0040

============================================================
🔄 Round 112 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 112 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=0.0010
   Val:   Loss=0.0806, RMSE=0.2839, R²=-0.0153
============================================================


============================================================
🔄 Round 113 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 113 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2894, R²=-0.0007
   Val:   Loss=0.0842, RMSE=0.2902, R²=-0.0080
============================================================


📊 Round 113 Test Metrics:
   Loss: 0.0778, RMSE: 0.2789, MAE: 0.2417, R²: -0.0040

============================================================
🔄 Round 116 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0900 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0900, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0900, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0900, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0900, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0899, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0900)

============================================================
📊 Round 116 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=0.0033
   Val:   Loss=0.0900, RMSE=0.3000, R²=-0.0336
============================================================


📊 Round 116 Test Metrics:
   Loss: 0.0778, RMSE: 0.2789, MAE: 0.2417, R²: -0.0041

============================================================
🔄 Round 120 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 120 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2911, R²=0.0040
   Val:   Loss=0.0803, RMSE=0.2833, R²=-0.0294
============================================================


============================================================
🔄 Round 121 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0730 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0730, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0730, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0730, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0730, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0729, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0730)

============================================================
📊 Round 121 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2942, R²=0.0014
   Val:   Loss=0.0730, RMSE=0.2702, R²=-0.0191
============================================================


============================================================
🔄 Round 123 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 123 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=-0.0013
   Val:   Loss=0.0862, RMSE=0.2936, R²=-0.0115
============================================================


============================================================
🔄 Round 125 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 125 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=-0.0009
   Val:   Loss=0.0838, RMSE=0.2895, R²=-0.0407
============================================================


============================================================
🔄 Round 126 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0992 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0992, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0992, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0992, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0991, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0991, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0992)

============================================================
📊 Round 126 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=-0.0023
   Val:   Loss=0.0992, RMSE=0.3149, R²=-0.0014
============================================================


📊 Round 126 Test Metrics:
   Loss: 0.0778, RMSE: 0.2789, MAE: 0.2417, R²: -0.0041

============================================================
🔄 Round 127 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0923 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0923, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0923, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0923, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0923, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0923, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0923)

============================================================
📊 Round 127 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=-0.0010
   Val:   Loss=0.0923, RMSE=0.3038, R²=-0.0125
============================================================


📊 Round 127 Test Metrics:
   Loss: 0.0778, RMSE: 0.2789, MAE: 0.2417, R²: -0.0040

============================================================
🔄 Round 134 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0757 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0757, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0757, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0757, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0756, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0756, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0757)

============================================================
📊 Round 134 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2931, R²=0.0012
   Val:   Loss=0.0757, RMSE=0.2751, R²=-0.0365
============================================================


📊 Round 134 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2416, R²: -0.0037

============================================================
🔄 Round 135 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0882 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0882, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0882, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0882, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0882, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0881, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0882)

============================================================
📊 Round 135 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=0.0064
   Val:   Loss=0.0882, RMSE=0.2971, R²=-0.0586
============================================================


============================================================
🔄 Round 137 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0925 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0925, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0925, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0924, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0924, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0923, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0925)

============================================================
📊 Round 137 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=0.0026
   Val:   Loss=0.0925, RMSE=0.3041, R²=-0.0216
============================================================


============================================================
🔄 Round 138 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 138 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=-0.0099
   Val:   Loss=0.0820, RMSE=0.2864, R²=0.0245
============================================================


============================================================
🔄 Round 141 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0876 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0876, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0875, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0875, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0875, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0875, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0876)

============================================================
📊 Round 141 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2880, R²=-0.0008
   Val:   Loss=0.0876, RMSE=0.2959, R²=-0.0078
============================================================


============================================================
🔄 Round 143 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 143 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=-0.0051
   Val:   Loss=0.0807, RMSE=0.2841, R²=0.0057
============================================================


============================================================
🔄 Round 144 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 144 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=-0.0071
   Val:   Loss=0.0818, RMSE=0.2860, R²=0.0099
============================================================


📊 Round 144 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2416, R²: -0.0037

============================================================
🔄 Round 146 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 146 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=0.0059
   Val:   Loss=0.0835, RMSE=0.2890, R²=-0.0364
============================================================


📊 Round 146 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2416, R²: -0.0037

============================================================
🔄 Round 148 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 148 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2906, R²=-0.0062
   Val:   Loss=0.0816, RMSE=0.2856, R²=0.0134
============================================================


📊 Round 148 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2416, R²: -0.0037

============================================================
🔄 Round 149 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 149 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=-0.0027
   Val:   Loss=0.0840, RMSE=0.2898, R²=-0.0003
============================================================


============================================================
🔄 Round 150 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 150 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2904, R²=-0.0002
   Val:   Loss=0.0820, RMSE=0.2864, R²=-0.0137
============================================================


📊 Round 150 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2416, R²: -0.0036

📊 Round 150 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2416, R²: -0.0036

📊 Round 150 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2416, R²: -0.0036

============================================================
🔄 Round 154 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 154 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2916, R²=-0.0042
   Val:   Loss=0.0792, RMSE=0.2814, R²=0.0033
============================================================


📊 Round 154 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2416, R²: -0.0036

============================================================
🔄 Round 155 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0872 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0872, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0871, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0871, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0871, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0871, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0872)

============================================================
📊 Round 155 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=0.0100
   Val:   Loss=0.0872, RMSE=0.2952, R²=-0.0534
============================================================


============================================================
🔄 Round 156 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 156 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=0.0036
   Val:   Loss=0.0850, RMSE=0.2915, R²=-0.0308
============================================================


📊 Round 156 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2416, R²: -0.0036

📊 Round 156 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2416, R²: -0.0035

============================================================
🔄 Round 161 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0963 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0963, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0963, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0963, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0963, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0963, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0963)

============================================================
📊 Round 161 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=0.0074
   Val:   Loss=0.0963, RMSE=0.3104, R²=-0.0369
============================================================


📊 Round 161 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2416, R²: -0.0035

📊 Round 161 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2416, R²: -0.0036

============================================================
🔄 Round 164 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 164 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2908, R²=-0.0126
   Val:   Loss=0.0811, RMSE=0.2848, R²=0.0269
============================================================


📊 Round 164 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2416, R²: -0.0034

============================================================
🔄 Round 165 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0878 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0878, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0878, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0878, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0878, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0877, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0878)

============================================================
📊 Round 165 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=0.0058
   Val:   Loss=0.0878, RMSE=0.2964, R²=-0.0352
============================================================


📊 Round 165 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2416, R²: -0.0034

============================================================
🔄 Round 166 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 166 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2915, R²=-0.0065
   Val:   Loss=0.0795, RMSE=0.2820, R²=0.0149
============================================================


============================================================
🔄 Round 167 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 167 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=0.0010
   Val:   Loss=0.0807, RMSE=0.2841, R²=-0.0169
============================================================


============================================================
🔄 Round 168 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0869 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0868, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0868, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0868, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0868, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0868, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 168 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=0.0018
   Val:   Loss=0.0869, RMSE=0.2947, R²=-0.0211
============================================================


============================================================
🔄 Round 173 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0765 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0765, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0765, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0765, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0765, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0766, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0765)

============================================================
📊 Round 173 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2927, R²=-0.0149
   Val:   Loss=0.0765, RMSE=0.2765, R²=0.0064
============================================================


📊 Round 173 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2416, R²: -0.0034

📊 Round 173 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2416, R²: -0.0034

============================================================
🔄 Round 175 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 175 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=-0.0069
   Val:   Loss=0.0806, RMSE=0.2838, R²=0.0150
============================================================


============================================================
🔄 Round 176 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 176 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=0.0017
   Val:   Loss=0.0861, RMSE=0.2934, R²=-0.0187
============================================================


📊 Round 176 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2416, R²: -0.0034

============================================================
🔄 Round 178 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 178 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=-0.0057
   Val:   Loss=0.0812, RMSE=0.2850, R²=0.0037
============================================================


📊 Round 178 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2416, R²: -0.0032

============================================================
🔄 Round 182 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 182 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=-0.0074
   Val:   Loss=0.0855, RMSE=0.2924, R²=0.0145
============================================================


============================================================
🔄 Round 183 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0748 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0748, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0747, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0747, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0747, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0747, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0748)

============================================================
📊 Round 183 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2935, R²=-0.0035
   Val:   Loss=0.0748, RMSE=0.2734, R²=0.0000
============================================================


📊 Round 183 Test Metrics:
   Loss: 0.0777, RMSE: 0.2788, MAE: 0.2416, R²: -0.0032

============================================================
🔄 Round 184 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0992 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0992, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0992, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0992, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0991, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0991, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0992)

============================================================
📊 Round 184 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2829, R²=0.0058
   Val:   Loss=0.0992, RMSE=0.3149, R²=-0.0390
============================================================


============================================================
🔄 Round 188 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0876 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0876, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0876, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0876, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0876, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0876, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0876)

============================================================
📊 Round 188 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2880, R²=-0.0012
   Val:   Loss=0.0876, RMSE=0.2959, R²=-0.0145
============================================================


============================================================
🔄 Round 189 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0870 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0870, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0870, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0870, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0870, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0870, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 189 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=-0.0119
   Val:   Loss=0.0870, RMSE=0.2949, R²=0.0254
============================================================


📊 Round 189 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2415, R²: -0.0030

============================================================
🔄 Round 191 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0879 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0879, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0879, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0879, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0878, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0878, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0879)

============================================================
📊 Round 191 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=0.0031
   Val:   Loss=0.0879, RMSE=0.2965, R²=-0.0344
============================================================


📊 Round 191 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2415, R²: -0.0029

📊 Round 191 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2415, R²: -0.0029

============================================================
🔄 Round 195 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0898 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0898, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0898, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0898, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0898, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0898, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0898)

============================================================
📊 Round 195 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=-0.0029
   Val:   Loss=0.0898, RMSE=0.2997, R²=-0.0183
============================================================


============================================================
🔄 Round 198 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 198 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=-0.0005
   Val:   Loss=0.0823, RMSE=0.2869, R²=-0.0147
============================================================


📊 Round 198 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2415, R²: -0.0029

============================================================
🔄 Round 200 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0746 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0745, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0745, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0745, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0745, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0745, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0746)

============================================================
📊 Round 200 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2936, R²=-0.0045
   Val:   Loss=0.0746, RMSE=0.2730, R²=0.0047
============================================================


📊 Round 200 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2415, R²: -0.0029

📊 Round 200 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2415, R²: -0.0029

============================================================
🔄 Round 205 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0916 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0916, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0916, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0916, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0916, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0916, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0916)

============================================================
📊 Round 205 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=-0.0048
   Val:   Loss=0.0916, RMSE=0.3027, R²=-0.0009
============================================================


📊 Round 205 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2415, R²: -0.0027

📊 Round 205 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2415, R²: -0.0028

📊 Round 205 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2415, R²: -0.0028

📊 Round 205 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2415, R²: -0.0028

============================================================
🔄 Round 213 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 213 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2921, R²=-0.0062
   Val:   Loss=0.0782, RMSE=0.2796, R²=0.0085
============================================================


📊 Round 213 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2415, R²: -0.0028

============================================================
🔄 Round 217 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0778, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0778, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0778, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0777, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0777, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 217 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2923, R²=-0.0021
   Val:   Loss=0.0778, RMSE=0.2789, R²=-0.0065
============================================================


📊 Round 217 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2415, R²: -0.0027

============================================================
🔄 Round 220 - Client client_15
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 220 Summary - Client client_15
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=0.0020
   Val:   Loss=0.0824, RMSE=0.2871, R²=-0.0578
============================================================


📊 Round 220 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2415, R²: -0.0027

📊 Round 220 Test Metrics:
   Loss: 0.0777, RMSE: 0.2787, MAE: 0.2415, R²: -0.0028

❌ Client client_15 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8687 {grpc_message:"Socket closed", grpc_status:14}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8687 {grpc_message:"Socket closed", grpc_status:14}"
>
