[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 546e2629-a0ae-4b34-9788-23e0f5fdd8ce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1bde1940-9339-4817-86e1-1ca076d65a47
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9202b4db-8e0f-4f4e-aadb-89d3a3030f60
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1472b779-b9b0-48a4-b80e-1a075ea151c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 69c26587-cc64-429e-b24a-773d8436cdd3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bb2c318f-1356-49c8-b859-b711a8427089
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0fa3cbdd-8962-46f9-8477-e4f73bc6f7ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e8651f60-8364-485d-b21b-8bf3ebe77260
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ccb1eff6-c5b5-474c-a1a5-bb5a8c93f296
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6ec8768d-334b-48a5-a56c-dd6da75b9a12
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 57cb3750-9947-404f-8762-d3cfcdef872a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b939fd43-1a00-42f4-afc4-3bcbb125af13
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2301610c-1c14-4014-b272-65e527a29d52
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6256514b-f4bf-4fef-9505-5125e689124a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4e221d18-07e2-4de5-aff7-a68d63e7eedc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2baef01f-0ae1-4e0c-9a37-5c589efed616
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2323e824-6386-4a90-97c7-0fc966bb6b08
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0a2a0005-b5d7-48df-bf68-f51ee92c5da1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7914d2e1-c06a-4653-bd78-e2c22daf8b95
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d1b61644-2537-4f27-8b5c-778836e2c362
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 515b6f9a-f162-4b7a-be5f-d69176baa5cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1744ed48-c5ca-4bf7-8648-b3c1c72c9a65
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7c333264-ad21-4bf2-903d-766dd72c5cf4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 45d7f1f8-1081-4e9b-8a29-176e13ad02a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8086d866-b942-471a-ab6f-6c94861009ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 61716e5c-487d-43a1-bd1a-82e709f6e946
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0028a907-40a1-4686-b306-53af12868bac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7979afe3-d75e-43b1-a8a7-5311d71c2909
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 15d169cf-f597-46a2-b1be-449da45fe4fb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 498b7188-b440-435c-b37a-717b2a5d456e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 372a8ea2-f2f5-4e9b-8a4c-4f94ab446489
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 03741a2d-3c50-4a0b-ae7f-7e6b699d6602
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a38b42bd-ba36-4ed2-85b4-2ffb555eb3c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fc15ba9e-d1b3-476b-a382-7b03a1c4a900
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0ad41536-f3c7-496d-bb8b-bdef24648323
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7c4a01b4-af7b-4f03-8eb9-34dc5cb5b249
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a8d087a4-e11c-49e3-9130-bc78d3d2a405
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 413b5c03-70b2-489c-9f73-2c6f560bff51
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 119c1adc-02bb-4820-a03a-a82d81f46cf0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4063501e-a81e-49ab-9a52-9d22bd962f03
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f5414f9a-d1c8-4607-a557-d9302b7504ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 08d6d912-ee1c-405a-bddf-a787cc1c51d9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 16899c51-4343-4097-93cb-e04a3124b4bc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4ed12a4d-3953-421a-a28a-3e477ecb2690
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bebcebb9-a70d-4b81-ab5b-651b91b439af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 247323ba-af83-47a5-86ca-d3dcc061bd91
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 25b87cd9-8b3c-4080-8881-08df8053dfd1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 390d0812-779e-464f-9386-dd0eee9ee0a8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f0c3e9a0-b227-47a5-8646-f7a7f6ebe693
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e446ce43-f8b6-4329-b5a2-a01d6906c1cd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 07cb5aec-7e01-4302-9a44-5a0bd2c03099
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cb7bd50d-0d81-4475-b1c3-ba7068180192
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f65d9e3e-987d-4981-96e3-fa1b98d70689
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dfe5bb0a-d12b-484a-99ba-79c926825fc4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eeecc408-b804-43d4-8337-d190284c33ce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7f930d81-8f89-4b7b-9d0c-b014590f17b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 779547b0-de97-4f64-9c0b-f132ec7f452f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message da268753-1f8b-4fcf-84f7-ba87efcb4059
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0caca0b6-65b2-41b1-b011-91fd04d09d8f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d0d0d2cb-0939-4ff7-86ec-0706cedf2717
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fade730d-df87-41c7-8237-48d1e76b2037
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a0abd8ff-c065-44a6-883a-661eb8738d4a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 60fb031f-9d9c-43c0-ab73-c51dc66d68e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 514957ce-42b6-47e1-a9bc-cee1c5532d0e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cda568a0-607e-4d12-be10-5766f940a1a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 09961b34-ec0f-49b6-8c4e-095fe06c4310
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message de2d348e-a459-4a14-808f-5d34b72d9230
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 405d2162-4445-46b9-b374-7cba574ecc89
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 22a802ea-adeb-4e0c-803a-3945b1be93cd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0fb9f5bd-533f-4a16-af7e-271177dec978
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1858f17c-60bd-4acf-8505-ea89b7ae8c71
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1edf0a3b-ad80-400f-bac5-1a01cb8eec9c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f4a2e43b-6355-4770-bf39-5c204296be80
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d33e3b8d-d000-4794-95c8-43d3361a4390
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c1c39c77-1da6-4eb8-b68d-12a73827f1b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b46c3ddb-8175-4fed-918c-adb3d5dc1e89
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 40d12291-a099-4ce0-bd75-ebde4d386a6a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cd6d9d3f-67f3-4839-b776-70149fb25237
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5a96bdf9-9585-49d5-a4ad-9a182dd526dd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e1b39479-9037-4a85-bcd1-277640f9be11
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 91c4629e-8ea2-4b61-9746-f4d9c79c268e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message de8f4494-de6f-44a6-9dfe-f050ef6195aa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1f597fe9-ca62-45b8-bf7a-c67599b8e592
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a1924da3-41a5-4ce7-a605-6a57dff9d684
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 48a4cd8b-dbce-42a2-b027-0dd4eee724e1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b8c4e6e5-2e1a-4b19-ab03-1df59c0ead52
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8b1f01b7-7f53-427d-ad1a-820508732775
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message abdd5019-36af-4281-bf64-92edb2ccf2a0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 14cd2599-4fff-4245-8125-090a94344ec8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c68895e4-86eb-4e4b-a1d9-8300cc555306
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 37359565-54e1-4eb2-815f-b8bc3cef42cd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4992ea36-9ff9-4f68-bef0-c39e0d584823
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 054bea6e-5253-4df8-99c3-625c32addea0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5b47c23b-1538-4094-a825-6f1689a3284c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ecb6d3af-eb63-449e-8fd8-6b75728f05d1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eaa0574d-2b8d-493a-89c8-1de3fe2ff592
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eda0ae37-faf5-437d-b4e4-25cc07a1a4ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d1e463c4-e663-4ee0-97c5-bdba4e87f56e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f0f1aa2d-0027-48c8-ac84-be77548d1c88
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 269c967c-4b37-43ff-8b74-33e1539ef0dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 54c3b5bd-7cee-40ae-9c3e-7c1600eff698
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 03bca967-049a-4d73-a76f-0649c666859f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3667d2f7-5570-499b-879e-a75955023672
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2a4e7a6a-2097-48fd-bc92-a83e8615dd11
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a3656a5d-8968-4a07-a23b-8f05a14be503
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 38af5595-9e5b-4ead-9078-423ecf1f2993
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2c816ad6-83af-4dfb-a394-1255bb7759fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 368dfd39-fd5d-4119-8ebf-cae66b26d53a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 166b6825-6ad1-4dbc-836a-d789ea324170
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ffea8b73-2d9b-4aa5-ae3f-fa010041da90
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 086d1547-e734-4aa1-b7b6-1ac491c6b0c9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 947c5d9f-34ed-4189-80d4-d8fdae84a020
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a4d066e2-9134-4d6d-ae5d-19f86b34b512
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message feb02d11-79f3-4f71-b0bc-c8d4d89af3d8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 182c498c-469b-4275-a27e-4e913bd0a8ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0d51c2fc-9955-4b85-b27c-488861878624
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e59b93f4-d808-4fc8-b8ca-c3dc98180c27
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1e8cf94c-773b-4453-b437-a747567a6939
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dfc1fe12-2ec8-4b07-9114-425c0094b75f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f4715ef6-415a-44fd-85b3-40ab4fd9eeb7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dac8aa7a-5800-4f32-8084-e19511cef202
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dff8f510-0eb2-4105-b04d-771798bcce01
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e8dbb65c-e9af-4c1b-ad05-df480515405a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2eadee28-dc08-40ef-9cc9-f384f160dbe9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a9604372-c7a5-444f-b305-e8a14763940d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d5568554-336e-42ab-8dcd-6a9d4bcffcdd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9b4fa04e-9277-4d6c-949a-8954379bffce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7bc84d13-c9bf-46da-93ee-7569f33dda20
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9b6a49a0-5184-4931-9282-59f9d4950205
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 62567051-6ed8-40e8-ad7a-ebb86129a616
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a8ab727f-8fb1-46de-ab39-59440d905fa2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2612f1f3-8199-4d82-8d8a-d6648e54edcf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e30368af-c7d4-4e54-8a3a-1751d2fa4d47
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3cf2bffe-63b5-4691-8436-f440910bc84e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7596ff0e-96a3-433d-bbc6-4de3964542ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ae163c36-3922-4ae2-956d-bc38b9833397
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cd20b342-b9f9-4f2b-a817-f2f219e6b4b9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 62981681-8ef6-4d32-a5a1-1e26793c4f00
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a6efc454-2d23-41fb-9d2e-9055f7103386
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3558e977-a9cb-4ba0-b0de-d3e5043d8eed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2e855d97-3e98-4bb5-97fe-872b0c04efa7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 25803cba-2329-4344-9783-c45f2fa882e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 869b9110-6318-41f0-b2b2-4798010013d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9a85ddea-e4f6-4fdc-b6fc-794ae511d0b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message db21bfbe-a729-48d9-a695-de69b824e61e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1bc4744a-843d-4632-8631-a2f1a2e7b9b0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0e92e723-4124-4bca-a1aa-c97b59e32a8e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 131a23a6-7c3c-4a74-8587-57e3d5bdda32
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b95e65a1-164e-44a9-8f88-34f58151dccb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0fd36b3c-837f-4369-8fae-9356029b2288
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7165f63d-3582-4eed-a47f-b8ddf32f00b8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a752c873-6135-43fb-baee-683863f4c8da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f8780963-8d92-40f4-b25e-17d589517e2e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6c9ac905-38fc-4c7b-8769-f2163366efe1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5d1f8d95-c9d2-41d0-a65d-4f0c663a39cb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 151cf547-27f7-429b-9156-383c819c116b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 47a852e8-59d2-4e59-be19-d657c1821374
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c9dc42f8-0afe-4cfd-98ea-75ccfeaf7982
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 31cac1ee-ba2f-4639-b89a-c62d0c0ae4f8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 78f39deb-7246-4452-a319-f8bc953f33c5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e05ce599-8752-4739-8e80-351e1fa5d043
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a756800c-5a94-40cb-9af3-ecafb75d63d1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b14cabbf-433e-4600-96a1-c17551044f93
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7aef514d-eb56-4d21-b5d4-f4502305cb22
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2500bdf2-e554-4050-81f3-9df77d7bd77c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 768c1d32-4e5c-4fd0-a6f7-46f8d8c138f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0999477e-98ed-493b-bd4f-d54fe1b01452
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a4aec445-d35b-44ba-8625-2be37745203a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fb0c3b14-fda6-47f8-ad41-ca7091bf992a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dd208f67-1d47-4408-ade3-e02db0369e67
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7dc68596-6074-4561-8053-672aec3b7499
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7e2d4555-52f6-4c98-be12-ea96263f2cba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d94d0c56-22bd-4bcd-828e-6426efd3cf0c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5e68c98a-3735-4633-a1b7-61cd13e2ba9d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5fa8b716-c9fd-4a5f-9554-1a7f05999405
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 388669a8-5a6f-446d-b1b4-042b75b14194
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aa3741e6-9912-468a-81c1-a51afb06c9c4
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8687 {grpc_status:14, grpc_message:"Socket closed"}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_16
Server: localhost:8687
Algorithm: FEDAVG
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_16
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_16/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_16/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_16/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_16/test_labels.txt

📊 Raw data loaded:
   Train: X=(1530, 24), y=(1530,)
   Test:  X=(383, 24), y=(383,)

⚠️  Limiting training data: 1530 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  374 samples, 5 features
✅ Client client_16 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

============================================================
🔄 Round 2 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0880, val=0.0875 (↓), lr=0.001000
   ✓ Epoch   2/100: train=0.0910, val=0.0759 (↓), lr=0.001000
   ✓ Epoch   3/100: train=0.0909, val=0.0728 (↓), lr=0.001000
   • Epoch   4/100: train=0.0854, val=0.0727, patience=1/15, lr=0.001000
   • Epoch   5/100: train=0.0854, val=0.0726, patience=2/15, lr=0.001000
   • Epoch  11/100: train=0.0843, val=0.0721, patience=2/15, lr=0.001000
   📉 Epoch 18: LR reduced 0.001000 → 0.000500
   • Epoch  21/100: train=0.0757, val=0.0762, patience=12/15, lr=0.000500

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0722)

============================================================
📊 Round 2 Summary - Client client_16
   Epochs: 24/100 (early stopped)
   LR: 0.001000 → 0.000500 (1 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=0.0201
   Val:   Loss=0.0722, RMSE=0.2688, R²=0.0174
============================================================


📊 Round 2 Test Metrics:
   Loss: 0.0796, RMSE: 0.2822, MAE: 0.2438, R²: 0.0179

============================================================
🔄 Round 4 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000500
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0865 (↓), lr=0.000500
   📉 Epoch 2: LR reduced 0.000500 → 0.000250
   • Epoch   2/100: train=0.0812, val=0.0876, patience=1/15, lr=0.000250
   ✓ Epoch   3/100: train=0.0798, val=0.0857 (↓), lr=0.000250
   • Epoch   4/100: train=0.0794, val=0.0862, patience=1/15, lr=0.000250
   • Epoch   5/100: train=0.0793, val=0.0860, patience=2/15, lr=0.000250
   📉 Epoch 10: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0782, val=0.0858, patience=8/15, lr=0.000125
   📉 Epoch 18: LR reduced 0.000125 → 0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 4 Summary - Client client_16
   Epochs: 18/100 (early stopped)
   LR: 0.000500 → 0.000063 (3 reductions)
   Train: Loss=0.0790, RMSE=0.2811, R²=0.0254
   Val:   Loss=0.0857, RMSE=0.2927, R²=-0.0038
============================================================


============================================================
🔄 Round 5 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0847 (↓), lr=0.000063
   • Epoch   2/100: train=0.0793, val=0.0856, patience=1/15, lr=0.000063
   • Epoch   3/100: train=0.0792, val=0.0859, patience=2/15, lr=0.000063
   • Epoch   4/100: train=0.0791, val=0.0860, patience=3/15, lr=0.000063
   • Epoch   5/100: train=0.0790, val=0.0860, patience=4/15, lr=0.000063
   📉 Epoch 8: LR reduced 0.000063 → 0.000031
   • Epoch  11/100: train=0.0786, val=0.0864, patience=10/15, lr=0.000031
   📉 Epoch 16: LR reduced 0.000031 → 0.000016

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 5 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000063 → 0.000016 (2 reductions)
   Train: Loss=0.0794, RMSE=0.2817, R²=0.0211
   Val:   Loss=0.0847, RMSE=0.2911, R²=-0.0009
============================================================


📊 Round 5 Test Metrics:
   Loss: 0.0767, RMSE: 0.2770, MAE: 0.2398, R²: 0.0534

📊 Round 5 Test Metrics:
   Loss: 0.0766, RMSE: 0.2767, MAE: 0.2391, R²: 0.0556

============================================================
🔄 Round 9 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000016
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0750 (↓), lr=0.000016
   • Epoch   2/100: train=0.0799, val=0.0749, patience=1/15, lr=0.000016
   • Epoch   3/100: train=0.0797, val=0.0747, patience=2/15, lr=0.000016
   • Epoch   4/100: train=0.0795, val=0.0746, patience=3/15, lr=0.000016
   ✓ Epoch   5/100: train=0.0793, val=0.0745 (↓), lr=0.000016
   📉 Epoch 8: LR reduced 0.000016 → 0.000008
   • Epoch  11/100: train=0.0788, val=0.0742, patience=6/15, lr=0.000008
   📉 Epoch 16: LR reduced 0.000008 → 0.000004

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0745)

============================================================
📊 Round 9 Summary - Client client_16
   Epochs: 20/100 (early stopped)
   LR: 0.000016 → 0.000004 (2 reductions)
   Train: Loss=0.0794, RMSE=0.2818, R²=0.0437
   Val:   Loss=0.0745, RMSE=0.2729, R²=0.0447
============================================================


📊 Round 9 Test Metrics:
   Loss: 0.0761, RMSE: 0.2759, MAE: 0.2384, R²: 0.0606

📊 Round 9 Test Metrics:
   Loss: 0.0761, RMSE: 0.2759, MAE: 0.2384, R²: 0.0611

📊 Round 9 Test Metrics:
   Loss: 0.0763, RMSE: 0.2762, MAE: 0.2388, R²: 0.0590

============================================================
🔄 Round 12 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000004
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0810 (↓), lr=0.000004
   • Epoch   2/100: train=0.0784, val=0.0810, patience=1/15, lr=0.000004
   • Epoch   3/100: train=0.0784, val=0.0809, patience=2/15, lr=0.000004
   📉 Epoch 4: LR reduced 0.000004 → 0.000002
   • Epoch   4/100: train=0.0784, val=0.0809, patience=3/15, lr=0.000002
   • Epoch   5/100: train=0.0783, val=0.0809, patience=4/15, lr=0.000002
   • Epoch  11/100: train=0.0782, val=0.0808, patience=10/15, lr=0.000002
   📉 Epoch 12: LR reduced 0.000002 → 0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 12 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000004 → 0.000001 (2 reductions)
   Train: Loss=0.0786, RMSE=0.2804, R²=0.0415
   Val:   Loss=0.0810, RMSE=0.2846, R²=0.0122
============================================================


============================================================
🔄 Round 13 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0776 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0776, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0776, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 13 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2819, R²=0.0409
   Val:   Loss=0.0776, RMSE=0.2785, R²=0.0150
============================================================


📊 Round 13 Test Metrics:
   Loss: 0.0762, RMSE: 0.2760, MAE: 0.2387, R²: 0.0601

============================================================
🔄 Round 15 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0734 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0734, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0734, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0734, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0733, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0733, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0734)

============================================================
📊 Round 15 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=0.0385
   Val:   Loss=0.0734, RMSE=0.2709, R²=0.0406
============================================================


📊 Round 15 Test Metrics:
   Loss: 0.0760, RMSE: 0.2757, MAE: 0.2384, R²: 0.0624

📊 Round 15 Test Metrics:
   Loss: 0.0760, RMSE: 0.2756, MAE: 0.2383, R²: 0.0629

📊 Round 15 Test Metrics:
   Loss: 0.0760, RMSE: 0.2757, MAE: 0.2384, R²: 0.0624

============================================================
🔄 Round 20 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0759 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0758, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0758, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0758, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0758, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0757, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0759)

============================================================
📊 Round 20 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2821, R²=0.0347
   Val:   Loss=0.0759, RMSE=0.2754, R²=0.0501
============================================================


📊 Round 20 Test Metrics:
   Loss: 0.0758, RMSE: 0.2753, MAE: 0.2381, R²: 0.0653

============================================================
🔄 Round 22 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0727 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0727, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0727, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0726, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0726, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0726, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0727)

============================================================
📊 Round 22 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2831, R²=0.0354
   Val:   Loss=0.0727, RMSE=0.2696, R²=0.0606
============================================================


📊 Round 22 Test Metrics:
   Loss: 0.0758, RMSE: 0.2752, MAE: 0.2381, R²: 0.0654

============================================================
🔄 Round 29 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0774, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0774, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0774, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0774, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0774, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0773, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 29 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0776, RMSE=0.2787, R²=0.0455
   Val:   Loss=0.0827, RMSE=0.2875, R²=0.0250
============================================================


============================================================
🔄 Round 31 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0782, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0782, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0782, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0782, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0782, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0781, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 31 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0782, RMSE=0.2797, R²=0.0397
   Val:   Loss=0.0802, RMSE=0.2833, R²=0.0449
============================================================


📊 Round 31 Test Metrics:
   Loss: 0.0757, RMSE: 0.2752, MAE: 0.2380, R²: 0.0655

📊 Round 31 Test Metrics:
   Loss: 0.0757, RMSE: 0.2752, MAE: 0.2380, R²: 0.0655

============================================================
🔄 Round 35 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0754 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0754, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0754, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0753, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0753, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0752, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0754)

============================================================
📊 Round 35 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2819, R²=0.0385
   Val:   Loss=0.0754, RMSE=0.2746, R²=0.0336
============================================================


============================================================
🔄 Round 36 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0766, val=0.0881 (↓), lr=0.000001
   • Epoch   2/100: train=0.0766, val=0.0881, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0766, val=0.0881, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0766, val=0.0881, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0765, val=0.0881, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0764, val=0.0881, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0881)

============================================================
📊 Round 36 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0763, RMSE=0.2762, R²=0.0409
   Val:   Loss=0.0881, RMSE=0.2968, R²=0.0396
============================================================


============================================================
🔄 Round 37 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0773, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0773, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0773, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0773, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0772, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0772, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 37 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0774, RMSE=0.2782, R²=0.0404
   Val:   Loss=0.0836, RMSE=0.2892, R²=0.0392
============================================================


============================================================
🔄 Round 38 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0711 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0711, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0711, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0711, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0711, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0710, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0711)

============================================================
📊 Round 38 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=0.0408
   Val:   Loss=0.0711, RMSE=0.2667, R²=0.0435
============================================================


============================================================
🔄 Round 39 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0699 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0699, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0699, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0699, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0699, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0700, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0699)

============================================================
📊 Round 39 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=0.0342
   Val:   Loss=0.0699, RMSE=0.2643, R²=0.0539
============================================================


📊 Round 39 Test Metrics:
   Loss: 0.0757, RMSE: 0.2752, MAE: 0.2380, R²: 0.0656

📊 Round 39 Test Metrics:
   Loss: 0.0757, RMSE: 0.2752, MAE: 0.2380, R²: 0.0656

📊 Round 39 Test Metrics:
   Loss: 0.0757, RMSE: 0.2752, MAE: 0.2380, R²: 0.0656

============================================================
🔄 Round 43 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0642 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0643, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0643, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0644, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0644, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0646, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0642)

============================================================
📊 Round 43 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=0.0301
   Val:   Loss=0.0642, RMSE=0.2535, R²=0.0302
============================================================


📊 Round 43 Test Metrics:
   Loss: 0.0757, RMSE: 0.2752, MAE: 0.2380, R²: 0.0656

📊 Round 43 Test Metrics:
   Loss: 0.0757, RMSE: 0.2752, MAE: 0.2380, R²: 0.0656

============================================================
🔄 Round 46 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0759 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0759, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0758, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0758, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0758, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0757, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0759)

============================================================
📊 Round 46 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2817, R²=0.0423
   Val:   Loss=0.0759, RMSE=0.2754, R²=0.0379
============================================================


📊 Round 46 Test Metrics:
   Loss: 0.0757, RMSE: 0.2752, MAE: 0.2380, R²: 0.0656

============================================================
🔄 Round 50 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0693 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0693, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0693, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0693, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0693, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0693, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0693)

============================================================
📊 Round 50 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=0.0394
   Val:   Loss=0.0693, RMSE=0.2632, R²=0.0432
============================================================


============================================================
🔄 Round 51 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0764 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0764, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0764, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0764, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0763, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0763, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0764)

============================================================
📊 Round 51 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2814, R²=0.0457
   Val:   Loss=0.0764, RMSE=0.2764, R²=0.0227
============================================================


📊 Round 51 Test Metrics:
   Loss: 0.0757, RMSE: 0.2752, MAE: 0.2380, R²: 0.0656

============================================================
🔄 Round 52 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0774, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0774, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0774, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0774, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0773, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0772, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 52 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0775, RMSE=0.2783, R²=0.0405
   Val:   Loss=0.0833, RMSE=0.2886, R²=0.0413
============================================================


============================================================
🔄 Round 53 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0785, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0785, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0785, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0785, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 53 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2804, R²=0.0409
   Val:   Loss=0.0787, RMSE=0.2806, R²=0.0437
============================================================


============================================================
🔄 Round 54 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0787, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 54 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2806, R²=0.0395
   Val:   Loss=0.0783, RMSE=0.2799, R²=0.0476
============================================================


============================================================
🔄 Round 56 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0749 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0749, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0749, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0749, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0749, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0748, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0749)

============================================================
📊 Round 56 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2821, R²=0.0445
   Val:   Loss=0.0749, RMSE=0.2736, R²=0.0243
============================================================


============================================================
🔄 Round 57 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0747 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0747, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0747, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0747, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0747, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0746, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0747)

============================================================
📊 Round 57 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2821, R²=0.0411
   Val:   Loss=0.0747, RMSE=0.2734, R²=0.0430
============================================================


============================================================
🔄 Round 58 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0717 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0717, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0717, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0717, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0717, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0716, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0717)

============================================================
📊 Round 58 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=0.0418
   Val:   Loss=0.0717, RMSE=0.2678, R²=0.0389
============================================================


📊 Round 58 Test Metrics:
   Loss: 0.0757, RMSE: 0.2752, MAE: 0.2380, R²: 0.0656

📊 Round 58 Test Metrics:
   Loss: 0.0757, RMSE: 0.2752, MAE: 0.2380, R²: 0.0656

📊 Round 58 Test Metrics:
   Loss: 0.0757, RMSE: 0.2752, MAE: 0.2380, R²: 0.0656

============================================================
🔄 Round 64 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0626 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0626, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0625, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0625, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0625, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0624, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0626)

============================================================
📊 Round 64 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2875, R²=0.0389
   Val:   Loss=0.0626, RMSE=0.2501, R²=0.0538
============================================================


============================================================
🔄 Round 66 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0782, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0782, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0782, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0782, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0782, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0781, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 66 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0781, RMSE=0.2796, R²=0.0381
   Val:   Loss=0.0806, RMSE=0.2839, R²=0.0532
============================================================


📊 Round 66 Test Metrics:
   Loss: 0.0757, RMSE: 0.2752, MAE: 0.2380, R²: 0.0657

📊 Round 66 Test Metrics:
   Loss: 0.0757, RMSE: 0.2752, MAE: 0.2380, R²: 0.0657

============================================================
🔄 Round 68 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0767, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0767, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0767, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0767, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0767, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0766, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 68 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0768, RMSE=0.2770, R²=0.0483
   Val:   Loss=0.0861, RMSE=0.2935, R²=0.0164
============================================================


============================================================
🔄 Round 69 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0778, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0778, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0778, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0778, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0778, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0777, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 69 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0779, RMSE=0.2791, R²=0.0419
   Val:   Loss=0.0815, RMSE=0.2854, R²=0.0400
============================================================


📊 Round 69 Test Metrics:
   Loss: 0.0757, RMSE: 0.2752, MAE: 0.2380, R²: 0.0658

============================================================
🔄 Round 72 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0781, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0781, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0781, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0781, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0781, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0780, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 72 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0782, RMSE=0.2796, R²=0.0417
   Val:   Loss=0.0804, RMSE=0.2835, R²=0.0292
============================================================


============================================================
🔄 Round 73 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0751 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0751, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0751, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0751, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0751, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0751, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0751)

============================================================
📊 Round 73 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2819, R²=0.0362
   Val:   Loss=0.0751, RMSE=0.2741, R²=0.0576
============================================================


============================================================
🔄 Round 74 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0717 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0717, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0717, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0717, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0717, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0716, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0717)

============================================================
📊 Round 74 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2835, R²=0.0436
   Val:   Loss=0.0717, RMSE=0.2678, R²=0.0285
============================================================


============================================================
🔄 Round 75 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0761 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0761, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0761, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0761, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0761, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0762, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0761)

============================================================
📊 Round 75 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2815, R²=0.0366
   Val:   Loss=0.0761, RMSE=0.2759, R²=0.0506
============================================================


📊 Round 75 Test Metrics:
   Loss: 0.0757, RMSE: 0.2752, MAE: 0.2380, R²: 0.0659

============================================================
🔄 Round 78 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0755 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0755, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0755, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0755, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0754, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0754, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0755)

============================================================
📊 Round 78 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2818, R²=0.0382
   Val:   Loss=0.0755, RMSE=0.2748, R²=0.0533
============================================================


📊 Round 78 Test Metrics:
   Loss: 0.0757, RMSE: 0.2752, MAE: 0.2380, R²: 0.0659

📊 Round 78 Test Metrics:
   Loss: 0.0757, RMSE: 0.2752, MAE: 0.2380, R²: 0.0659

============================================================
🔄 Round 80 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0785, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0785, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 80 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2806, R²=0.0379
   Val:   Loss=0.0782, RMSE=0.2796, R²=0.0559
============================================================


📊 Round 80 Test Metrics:
   Loss: 0.0757, RMSE: 0.2752, MAE: 0.2380, R²: 0.0659

📊 Round 80 Test Metrics:
   Loss: 0.0757, RMSE: 0.2752, MAE: 0.2380, R²: 0.0659

📊 Round 80 Test Metrics:
   Loss: 0.0757, RMSE: 0.2752, MAE: 0.2380, R²: 0.0659

📊 Round 80 Test Metrics:
   Loss: 0.0757, RMSE: 0.2752, MAE: 0.2380, R²: 0.0659

============================================================
🔄 Round 90 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0781, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0780, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0780, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0780, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0780, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0780, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 90 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0779, RMSE=0.2791, R²=0.0369
   Val:   Loss=0.0814, RMSE=0.2854, R²=0.0584
============================================================


============================================================
🔄 Round 95 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0783, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0783, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0783, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0782, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0782, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0781, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 95 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0780, RMSE=0.2793, R²=0.0420
   Val:   Loss=0.0810, RMSE=0.2846, R²=0.0410
============================================================


📊 Round 95 Test Metrics:
   Loss: 0.0757, RMSE: 0.2751, MAE: 0.2380, R²: 0.0660

============================================================
🔄 Round 98 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0779, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0779, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0779, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0779, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0778, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0777, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 98 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0779, RMSE=0.2791, R²=0.0387
   Val:   Loss=0.0813, RMSE=0.2851, R²=0.0455
============================================================


📊 Round 98 Test Metrics:
   Loss: 0.0757, RMSE: 0.2751, MAE: 0.2380, R²: 0.0661

============================================================
🔄 Round 101 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0770, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0770, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0769, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0769, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0769, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0768, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 101 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0771, RMSE=0.2777, R²=0.0378
   Val:   Loss=0.0844, RMSE=0.2905, R²=0.0565
============================================================


============================================================
🔄 Round 102 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0773, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 102 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2809, R²=0.0442
   Val:   Loss=0.0773, RMSE=0.2780, R²=0.0310
============================================================


📊 Round 102 Test Metrics:
   Loss: 0.0757, RMSE: 0.2751, MAE: 0.2380, R²: 0.0661

============================================================
🔄 Round 103 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0782, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0782, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0782, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0781, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0781, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0780, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 103 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0781, RMSE=0.2794, R²=0.0427
   Val:   Loss=0.0806, RMSE=0.2840, R²=0.0392
============================================================


============================================================
🔄 Round 104 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0767, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0767, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0767, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0767, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0767, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0766, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 104 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0767, RMSE=0.2769, R²=0.0466
   Val:   Loss=0.0862, RMSE=0.2936, R²=0.0158
============================================================


📊 Round 104 Test Metrics:
   Loss: 0.0757, RMSE: 0.2751, MAE: 0.2380, R²: 0.0661

============================================================
🔄 Round 106 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0715 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0715, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0715, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0715, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0715, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0714, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0715)

============================================================
📊 Round 106 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2835, R²=0.0345
   Val:   Loss=0.0715, RMSE=0.2674, R²=0.0735
============================================================


📊 Round 106 Test Metrics:
   Loss: 0.0757, RMSE: 0.2751, MAE: 0.2380, R²: 0.0662

============================================================
🔄 Round 107 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0777, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0777, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0777, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0777, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0776, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0776, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 107 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0776, RMSE=0.2786, R²=0.0463
   Val:   Loss=0.0824, RMSE=0.2870, R²=0.0257
============================================================


============================================================
🔄 Round 108 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0763, val=0.0867 (↓), lr=0.000001
   • Epoch   2/100: train=0.0763, val=0.0867, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0763, val=0.0867, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0763, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0763, val=0.0867, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0762, val=0.0866, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 108 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0766, RMSE=0.2767, R²=0.0440
   Val:   Loss=0.0867, RMSE=0.2945, R²=0.0064
============================================================


📊 Round 108 Test Metrics:
   Loss: 0.0757, RMSE: 0.2751, MAE: 0.2380, R²: 0.0662

📊 Round 108 Test Metrics:
   Loss: 0.0757, RMSE: 0.2751, MAE: 0.2380, R²: 0.0662

📊 Round 108 Test Metrics:
   Loss: 0.0757, RMSE: 0.2751, MAE: 0.2380, R²: 0.0662

============================================================
🔄 Round 113 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0779 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0779, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0780, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0785, val=0.0780, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0785, val=0.0780, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0779)

============================================================
📊 Round 113 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2806, R²=0.0365
   Val:   Loss=0.0779, RMSE=0.2791, R²=0.0225
============================================================


📊 Round 113 Test Metrics:
   Loss: 0.0757, RMSE: 0.2751, MAE: 0.2380, R²: 0.0662

============================================================
🔄 Round 116 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0715 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0714, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0714, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0714, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0714, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0713, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0715)

============================================================
📊 Round 116 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2835, R²=0.0374
   Val:   Loss=0.0715, RMSE=0.2673, R²=0.0614
============================================================


============================================================
🔄 Round 117 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0753 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0753, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0753, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0753, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0753, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0753, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0753)

============================================================
📊 Round 117 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2818, R²=0.0405
   Val:   Loss=0.0753, RMSE=0.2744, R²=0.0429
============================================================


============================================================
🔄 Round 118 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0718 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0718, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0718, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0718, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0718, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0717, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0718)

============================================================
📊 Round 118 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2833, R²=0.0389
   Val:   Loss=0.0718, RMSE=0.2680, R²=0.0559
============================================================


📊 Round 118 Test Metrics:
   Loss: 0.0757, RMSE: 0.2751, MAE: 0.2380, R²: 0.0663

============================================================
🔄 Round 119 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0767 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0767, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0767, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0767, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0767, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0767, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0767)

============================================================
📊 Round 119 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2811, R²=0.0358
   Val:   Loss=0.0767, RMSE=0.2770, R²=0.0586
============================================================


📊 Round 119 Test Metrics:
   Loss: 0.0757, RMSE: 0.2751, MAE: 0.2380, R²: 0.0664

📊 Round 119 Test Metrics:
   Loss: 0.0757, RMSE: 0.2751, MAE: 0.2380, R²: 0.0664

📊 Round 119 Test Metrics:
   Loss: 0.0757, RMSE: 0.2751, MAE: 0.2380, R²: 0.0664

============================================================
🔄 Round 123 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0770, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0770, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0770, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0769, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0769, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0768, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 123 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0772, RMSE=0.2779, R²=0.0363
   Val:   Loss=0.0839, RMSE=0.2896, R²=0.0587
============================================================


============================================================
🔄 Round 124 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0758 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0758, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0758, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0758, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0758, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0758, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0758)

============================================================
📊 Round 124 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2815, R²=0.0462
   Val:   Loss=0.0758, RMSE=0.2753, R²=0.0215
============================================================


📊 Round 124 Test Metrics:
   Loss: 0.0757, RMSE: 0.2751, MAE: 0.2380, R²: 0.0664

============================================================
🔄 Round 125 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0759 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0758, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0758, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0758, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0758, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0757, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0759)

============================================================
📊 Round 125 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2815, R²=0.0442
   Val:   Loss=0.0759, RMSE=0.2754, R²=0.0150
============================================================


📊 Round 125 Test Metrics:
   Loss: 0.0757, RMSE: 0.2751, MAE: 0.2380, R²: 0.0664

📊 Round 125 Test Metrics:
   Loss: 0.0757, RMSE: 0.2751, MAE: 0.2380, R²: 0.0664

📊 Round 125 Test Metrics:
   Loss: 0.0757, RMSE: 0.2751, MAE: 0.2380, R²: 0.0664

============================================================
🔄 Round 130 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0785, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0785, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 130 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2804, R²=0.0420
   Val:   Loss=0.0784, RMSE=0.2800, R²=0.0372
============================================================


📊 Round 130 Test Metrics:
   Loss: 0.0757, RMSE: 0.2751, MAE: 0.2380, R²: 0.0664

📊 Round 130 Test Metrics:
   Loss: 0.0757, RMSE: 0.2751, MAE: 0.2380, R²: 0.0664

📊 Round 130 Test Metrics:
   Loss: 0.0757, RMSE: 0.2751, MAE: 0.2380, R²: 0.0664

============================================================
🔄 Round 136 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0765 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0765, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0765, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0764, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0764, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0763, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0765)

============================================================
📊 Round 136 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2812, R²=0.0411
   Val:   Loss=0.0765, RMSE=0.2766, R²=0.0343
============================================================


📊 Round 136 Test Metrics:
   Loss: 0.0757, RMSE: 0.2751, MAE: 0.2380, R²: 0.0663

============================================================
🔄 Round 137 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0761 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0761, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0761, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0760, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0760, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0759, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0761)

============================================================
📊 Round 137 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2814, R²=0.0414
   Val:   Loss=0.0761, RMSE=0.2758, R²=0.0452
============================================================


============================================================
🔄 Round 141 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0760 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0760, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0760, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0759, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0759, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0758, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0760)

============================================================
📊 Round 141 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2814, R²=0.0448
   Val:   Loss=0.0760, RMSE=0.2757, R²=0.0215
============================================================


📊 Round 141 Test Metrics:
   Loss: 0.0757, RMSE: 0.2751, MAE: 0.2380, R²: 0.0664

📊 Round 141 Test Metrics:
   Loss: 0.0757, RMSE: 0.2751, MAE: 0.2380, R²: 0.0664

============================================================
🔄 Round 145 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0762 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0762, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0762, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0762, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0762, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0761, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0762)

============================================================
📊 Round 145 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2813, R²=0.0379
   Val:   Loss=0.0762, RMSE=0.2761, R²=0.0604
============================================================


📊 Round 145 Test Metrics:
   Loss: 0.0757, RMSE: 0.2751, MAE: 0.2380, R²: 0.0665

📊 Round 145 Test Metrics:
   Loss: 0.0757, RMSE: 0.2751, MAE: 0.2380, R²: 0.0665

📊 Round 145 Test Metrics:
   Loss: 0.0757, RMSE: 0.2751, MAE: 0.2380, R²: 0.0665

============================================================
🔄 Round 152 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0744 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0744, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0744, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0744, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0744, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0743, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0744)

============================================================
📊 Round 152 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2821, R²=0.0373
   Val:   Loss=0.0744, RMSE=0.2728, R²=0.0616
============================================================


============================================================
🔄 Round 153 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0730 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0730, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0730, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0730, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0730, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0730, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0730)

============================================================
📊 Round 153 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=0.0437
   Val:   Loss=0.0730, RMSE=0.2702, R²=0.0316
============================================================


📊 Round 153 Test Metrics:
   Loss: 0.0757, RMSE: 0.2751, MAE: 0.2380, R²: 0.0665

📊 Round 153 Test Metrics:
   Loss: 0.0757, RMSE: 0.2751, MAE: 0.2380, R²: 0.0666

📊 Round 153 Test Metrics:
   Loss: 0.0757, RMSE: 0.2751, MAE: 0.2380, R²: 0.0666

📊 Round 153 Test Metrics:
   Loss: 0.0757, RMSE: 0.2751, MAE: 0.2380, R²: 0.0666

============================================================
🔄 Round 158 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0739 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0739, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0739, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0739, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0739, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0739, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0739)

============================================================
📊 Round 158 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=0.0408
   Val:   Loss=0.0739, RMSE=0.2719, R²=0.0472
============================================================


📊 Round 158 Test Metrics:
   Loss: 0.0757, RMSE: 0.2751, MAE: 0.2380, R²: 0.0666

============================================================
🔄 Round 162 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0781, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0781, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0781, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0780, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0780, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0779, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 162 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0780, RMSE=0.2793, R²=0.0450
   Val:   Loss=0.0808, RMSE=0.2842, R²=0.0290
============================================================


============================================================
🔄 Round 163 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0734 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0734, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0733, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0733, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0733, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0732, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0734)

============================================================
📊 Round 163 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2826, R²=0.0443
   Val:   Loss=0.0734, RMSE=0.2709, R²=0.0337
============================================================


📊 Round 163 Test Metrics:
   Loss: 0.0757, RMSE: 0.2751, MAE: 0.2380, R²: 0.0665

============================================================
🔄 Round 165 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0762 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0762, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0762, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0762, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0762, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0761, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0762)

============================================================
📊 Round 165 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2813, R²=0.0362
   Val:   Loss=0.0762, RMSE=0.2761, R²=0.0646
============================================================


============================================================
🔄 Round 170 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0768, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0768, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0768, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0768, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0768, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0767, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 170 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0769, RMSE=0.2773, R²=0.0391
   Val:   Loss=0.0852, RMSE=0.2919, R²=0.0536
============================================================


============================================================
🔄 Round 171 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0779, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0779, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0778, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0778, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0778, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0777, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 171 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0776, RMSE=0.2786, R²=0.0382
   Val:   Loss=0.0823, RMSE=0.2869, R²=0.0539
============================================================


📊 Round 171 Test Metrics:
   Loss: 0.0757, RMSE: 0.2751, MAE: 0.2379, R²: 0.0666

📊 Round 171 Test Metrics:
   Loss: 0.0757, RMSE: 0.2751, MAE: 0.2379, R²: 0.0666

============================================================
🔄 Round 175 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0763 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0763, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0763, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0763, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0763, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0763, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0763)

============================================================
📊 Round 175 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2812, R²=0.0394
   Val:   Loss=0.0763, RMSE=0.2763, R²=0.0530
============================================================


============================================================
🔄 Round 176 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0729 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0729, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0729, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0729, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0729, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0729, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0729)

============================================================
📊 Round 176 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=0.0393
   Val:   Loss=0.0729, RMSE=0.2701, R²=0.0560
============================================================


============================================================
🔄 Round 180 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0783, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0783, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0782, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0782, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0782, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0781, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 180 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0781, RMSE=0.2795, R²=0.0457
   Val:   Loss=0.0803, RMSE=0.2834, R²=0.0289
============================================================


📊 Round 180 Test Metrics:
   Loss: 0.0757, RMSE: 0.2751, MAE: 0.2379, R²: 0.0666

📊 Round 180 Test Metrics:
   Loss: 0.0757, RMSE: 0.2751, MAE: 0.2379, R²: 0.0667

============================================================
🔄 Round 182 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0782, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0782, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0782, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0782, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0781, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0780, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 182 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2802, R²=0.0429
   Val:   Loss=0.0787, RMSE=0.2805, R²=0.0327
============================================================


📊 Round 182 Test Metrics:
   Loss: 0.0757, RMSE: 0.2751, MAE: 0.2379, R²: 0.0667

📊 Round 182 Test Metrics:
   Loss: 0.0757, RMSE: 0.2750, MAE: 0.2379, R²: 0.0667

📊 Round 182 Test Metrics:
   Loss: 0.0757, RMSE: 0.2751, MAE: 0.2379, R²: 0.0666

============================================================
🔄 Round 185 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0780 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0780, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0780, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0780, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0780, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0785, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 185 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2805, R²=0.0438
   Val:   Loss=0.0780, RMSE=0.2793, R²=0.0364
============================================================


📊 Round 185 Test Metrics:
   Loss: 0.0757, RMSE: 0.2750, MAE: 0.2379, R²: 0.0667

============================================================
🔄 Round 187 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0785, val=0.0778, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0785, val=0.0777, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0785, val=0.0777, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0777, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0777, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 187 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2806, R²=0.0465
   Val:   Loss=0.0778, RMSE=0.2789, R²=0.0238
============================================================


📊 Round 187 Test Metrics:
   Loss: 0.0757, RMSE: 0.2751, MAE: 0.2379, R²: 0.0667

📊 Round 187 Test Metrics:
   Loss: 0.0757, RMSE: 0.2751, MAE: 0.2379, R²: 0.0666

============================================================
🔄 Round 189 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0785, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 189 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2803, R²=0.0420
   Val:   Loss=0.0786, RMSE=0.2803, R²=0.0438
============================================================


📊 Round 189 Test Metrics:
   Loss: 0.0757, RMSE: 0.2751, MAE: 0.2379, R²: 0.0667

📊 Round 189 Test Metrics:
   Loss: 0.0757, RMSE: 0.2751, MAE: 0.2379, R²: 0.0667

📊 Round 189 Test Metrics:
   Loss: 0.0757, RMSE: 0.2751, MAE: 0.2379, R²: 0.0667

============================================================
🔄 Round 197 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0741 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0741, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0741, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0741, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0741, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0741, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0741)

============================================================
📊 Round 197 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=0.0374
   Val:   Loss=0.0741, RMSE=0.2722, R²=0.0564
============================================================


📊 Round 197 Test Metrics:
   Loss: 0.0756, RMSE: 0.2750, MAE: 0.2379, R²: 0.0667

============================================================
🔄 Round 200 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0777, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0777, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0777, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0777, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0776, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0776, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 200 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0775, RMSE=0.2784, R²=0.0427
   Val:   Loss=0.0826, RMSE=0.2875, R²=0.0421
============================================================


📊 Round 200 Test Metrics:
   Loss: 0.0756, RMSE: 0.2750, MAE: 0.2379, R²: 0.0668

============================================================
🔄 Round 203 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0762 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0761, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0761, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0761, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0761, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0760, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0762)

============================================================
📊 Round 203 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2813, R²=0.0374
   Val:   Loss=0.0762, RMSE=0.2760, R²=0.0620
============================================================


============================================================
🔄 Round 204 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0738 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0738, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0738, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0738, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0738, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0738, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0738)

============================================================
📊 Round 204 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2824, R²=0.0395
   Val:   Loss=0.0738, RMSE=0.2717, R²=0.0535
============================================================


📊 Round 204 Test Metrics:
   Loss: 0.0757, RMSE: 0.2750, MAE: 0.2379, R²: 0.0667

============================================================
🔄 Round 207 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0771 (↓), lr=0.000001
   • Epoch   2/100: train=0.0787, val=0.0771, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0771, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0771, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0771, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0785, val=0.0770, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0771)

============================================================
📊 Round 207 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2809, R²=0.0475
   Val:   Loss=0.0771, RMSE=0.2777, R²=0.0214
============================================================


📊 Round 207 Test Metrics:
   Loss: 0.0756, RMSE: 0.2750, MAE: 0.2379, R²: 0.0668

============================================================
🔄 Round 208 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0780, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0779, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0779, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0779, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0779, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0778, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 208 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0780, RMSE=0.2792, R²=0.0459
   Val:   Loss=0.0809, RMSE=0.2845, R²=0.0290
============================================================


📊 Round 208 Test Metrics:
   Loss: 0.0756, RMSE: 0.2750, MAE: 0.2379, R²: 0.0668

============================================================
🔄 Round 212 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0762, val=0.0881 (↓), lr=0.000001
   • Epoch   2/100: train=0.0762, val=0.0881, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0761, val=0.0881, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0761, val=0.0880, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0761, val=0.0880, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0760, val=0.0879, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0881)

============================================================
📊 Round 212 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0762, RMSE=0.2760, R²=0.0480
   Val:   Loss=0.0881, RMSE=0.2968, R²=0.0232
============================================================


📊 Round 212 Test Metrics:
   Loss: 0.0756, RMSE: 0.2750, MAE: 0.2379, R²: 0.0669

============================================================
🔄 Round 213 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0714 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0714, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0714, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0713, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0713, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0712, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0714)

============================================================
📊 Round 213 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=0.0466
   Val:   Loss=0.0714, RMSE=0.2672, R²=0.0151
============================================================


📊 Round 213 Test Metrics:
   Loss: 0.0756, RMSE: 0.2750, MAE: 0.2379, R²: 0.0669

============================================================
🔄 Round 216 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0774, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0774, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0774, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0774, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0774, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0773, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 216 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0774, RMSE=0.2783, R²=0.0462
   Val:   Loss=0.0829, RMSE=0.2880, R²=0.0290
============================================================


📊 Round 216 Test Metrics:
   Loss: 0.0756, RMSE: 0.2750, MAE: 0.2379, R²: 0.0668

============================================================
🔄 Round 218 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0744 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0744, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0743, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0743, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0743, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0742, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0744)

============================================================
📊 Round 218 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2821, R²=0.0396
   Val:   Loss=0.0744, RMSE=0.2727, R²=0.0540
============================================================


📊 Round 218 Test Metrics:
   Loss: 0.0756, RMSE: 0.2750, MAE: 0.2379, R²: 0.0669

📊 Round 218 Test Metrics:
   Loss: 0.0756, RMSE: 0.2750, MAE: 0.2379, R²: 0.0669

============================================================
🔄 Round 221 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0749 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0749, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0749, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0749, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0749, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0748, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0749)

============================================================
📊 Round 221 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2818, R²=0.0434
   Val:   Loss=0.0749, RMSE=0.2737, R²=0.0379
============================================================


============================================================
🔄 Round 223 - Client client_16
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0785, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0785, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0785, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0785, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 223 Summary - Client client_16
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2803, R²=0.0450
   Val:   Loss=0.0784, RMSE=0.2801, R²=0.0307
============================================================


📊 Round 223 Test Metrics:
   Loss: 0.0756, RMSE: 0.2750, MAE: 0.2379, R²: 0.0669

📊 Round 223 Test Metrics:
   Loss: 0.0756, RMSE: 0.2750, MAE: 0.2379, R²: 0.0670

❌ Client client_16 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8687 {grpc_status:14, grpc_message:"Socket closed"}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8687 {grpc_status:14, grpc_message:"Socket closed"}"
>
