[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b6292d4b-7be4-494c-8141-634b3d84c20d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 460b4d1a-ab0b-48a6-9807-bd0b88a56e9b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 65106614-3fcf-4528-ab79-f3f843d0bd15
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 10e2f0da-aaec-4090-ae38-1c83795acbe0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ca023df5-6c97-494f-8839-8b7e86cb3378
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2d94914a-d9ab-493f-85c3-1513e50fb587
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 12588259-547e-4c5b-9614-b25bc1db0c74
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bf0094ec-6349-495d-971a-b4362b4281ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 422cfeda-340e-41cb-b93b-0de785807773
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a109cb84-e0e9-4966-ac18-008e59c49cf5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 33703171-517d-4b3f-b84e-769f4892295e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 17b7ac7b-aa7b-43fa-972f-75ba2633e6bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 280f9832-5da4-45be-8d0a-4e6135465578
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ace33009-2313-4727-8474-b8c8ac6751dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f4b727b5-c296-48bc-aa8e-f4a5df932565
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 50f0086b-e608-4f2b-97bb-ea29c61fca36
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 30d09f0a-7cac-41b9-9469-5a8086726306
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fe9d0378-5467-4499-97a5-2dd737aa159c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c239e865-c409-43a0-aeb5-64ca1c5252a3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2c85c4a1-0ae9-4863-a1b6-d16b12da0be9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8d3807ea-1644-445c-b0ed-5d731ba192df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6d326951-d7a7-441e-bdb3-2b0e1d1991be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dce48b41-3820-45ca-b46a-273fdc7d03d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f6911090-f593-41ac-98fc-c0ab489a4bee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 238f3854-006e-4e55-a1f8-784a2ae51bdf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3c391df7-e594-47ac-b8ec-dff406dadfde
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message feb88a9c-e2e6-4f13-a0e2-ef636bef9adb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 77aa841d-3c5c-4f78-aeaf-e756b33c934d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 78c67a02-97dd-45d7-aa63-cc20a2d16a41
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0f9551cf-07d6-4b7a-816a-0b49076a6447
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d6944959-eb6c-4b88-846f-906fa49917c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 58e7245a-1bc7-4978-be1e-c2a05c2c1caf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 89c44ba1-5a42-4349-8278-8eddfcaf97ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 390b631a-3362-4aa3-a3ab-b11ea64a15a8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1c962b76-699a-4284-b663-b3a05c56460b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b154d88a-a14d-4c34-9619-f962ce6ba5a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e27e0efd-bd4b-4bf2-b9c3-1e1abe876aea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 10be8fd8-e6cb-4e1f-9312-40ba35b173c5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cd83a510-64ed-4a7a-891b-bd65332d3aec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 42f844c9-128d-4ff8-8805-36a84194811f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 785091e9-8bf1-41ad-bd79-0454e735a425
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0febe8b3-6d12-45dc-a6f2-a613259712c3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 14267bca-f530-439c-822e-9e629be9946a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7c87a556-0a9a-4d00-ada6-53ed90510c1f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 07f7a5f9-70e6-4627-b163-8d933508efab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 509d290c-6859-42e2-9011-0b57f3f657cb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3fc096b5-6f61-4b91-8c4e-c07fae9d20af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0438cc16-ebd0-4c5e-b16c-4f177f6a041e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ff1ea878-1da7-4015-bf4f-473b6ed0d125
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1659f9c0-20f0-40b1-af86-2ec009a18480
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 37162f25-9faa-44b3-94b5-36fa44592392
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 51f36f61-9b21-41b4-a48a-d26cfddb0ab9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a20568c9-5462-491d-8feb-de3ab05befdc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 03ea063b-917c-4e1e-823e-3db1c3f388d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 37821d33-bb61-4f6c-a7f7-a3a05db59805
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2ebfdf0c-a1d9-429e-96b9-96820fa07bcc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 54a3fc31-465b-41a2-b6f7-ff0e4aa0194d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 516a498d-1e2a-4922-9bc7-149bf18840e1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1eae0625-af49-4943-ae21-7a44f38e340e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ac35a4d1-22b5-4e0f-a75e-cca7d6d4910c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d9ce8637-dc26-4bd5-9e66-5455b12e6e56
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 017969a2-b672-4997-aaa3-83182aadd82d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8a4daa68-1764-4701-b5a5-801dc48ee769
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 527f23c9-7118-4a12-81cc-6ffdc3443aca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 762b7239-5aea-4c4c-b3e8-9d11204ba2fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 03b2ce2c-f587-4a6d-a51b-9c964ac40303
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c4dea877-6484-41b2-8a8a-141726c5ae1a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4bfae632-bd45-486b-9ab2-ac068e84b64d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 69e7aa94-0486-4bac-a9db-86acdddd6bd4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9b6e1a28-0d5d-4245-9ad2-e73afd5799bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ede5e6e2-37a7-4dcd-b91c-5bdb75145541
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 83f1bd78-3386-41e2-831d-45da03e6b71c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8757a2c3-2299-4a4c-a76c-528bbf7e36e5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4fa94d52-b70a-4772-8fc6-22a6ad9b64d1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ac21d7ea-b10a-49f5-81a0-1966b5b2141b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a3af6c6d-62c2-4dde-9376-467b55935df8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b67708a1-2e3f-4695-8f78-296e80964f85
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9d6a0b30-7e6e-4365-a035-932edab2863f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6e20e5db-82d1-415a-b738-26cec8f1d457
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e8be142c-7c87-487b-a982-e58367296c8e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 78de2097-5d97-47e8-b069-efe5a78575f4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9e68a498-ee1c-4084-bfca-4cc195fcbf8e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message df7b930e-a08f-4d98-b36e-46d135dcfc03
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ebee414d-161d-427e-98a2-96e17270fbdb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 640b280a-107b-4ef5-8ba4-bda09ac8a1fb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b405a94c-4825-4aef-9b95-822e77523d18
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a85664a3-4004-477a-a789-78a6732c0427
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 445f876c-a566-4039-9c59-dab2a93531cd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e70cfdf7-befd-4e02-a27b-ddaf506dff21
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6d78470e-3f81-4681-a227-32febb74eb1a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0e6aa091-53da-4704-8820-ae6b9fb903ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2ad045b7-a226-43a2-aee2-8794d9f5c4ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2a1a33e8-8594-499e-b3f2-04a29b04c11f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0816e114-089d-437f-b183-ef40db159d56
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 22e28e1a-d2b4-4566-8935-c5266a048059
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0464dada-31ac-41ea-9ce3-46cb91a94d3b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cf5196d3-80cb-40ed-b8a9-b723cdb79ac7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b0d07b6b-715c-425d-bf0f-930c1d61e349
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d2b406d0-5d2b-4ea3-8616-5d31a38be8b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ac911163-f6d5-4aaf-8b0a-8bc1b1cec984
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 30d09dbb-9304-499c-81c6-be50c955bbf4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a23038da-7878-40b0-abde-5b2deca94f1a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cfabfd37-b901-412f-acad-4e4056c8442a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cd8a67c9-37eb-4940-a5ac-eef323d29c7a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1eef1bc0-311c-454a-a099-7300bbf4cb62
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 328e2fb1-d930-497e-9c79-3b0ca82a8e9d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e8f68d2c-55a2-4f3a-9662-4bfb3fbc2872
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e84332b5-35bc-4d5d-be18-f49c6ad83380
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7cffdc34-9ae6-42b4-aae9-5c918e8cb31f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c5304b4b-b2b2-49ab-aa9e-d2a2fd5bc034
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b3db0693-d226-4ef0-813a-30719c558488
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a445a8d0-5343-44e3-8653-72d39de62c7c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 74078d53-7031-4884-913f-fdf74a0662ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 80a90c82-8b02-40d3-9088-d42cadc66f1b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4a5a6746-d26d-4c42-b89a-2de4e51dd0ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0eabcb3e-12cb-4455-a974-fe91ce14c5ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 13c5607b-ddbb-44f4-ae6e-6bc525b4a795
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a79a6c7e-4488-4c0f-b36e-a0f96e2dd03a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f49c85ac-ec2f-465a-b9d4-bfe85eaa5352
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aa4f54df-555f-4368-8e36-69ff23d1150f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ba33df85-24f8-4e1f-a178-a4801265871f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 784158be-9cf9-4afe-9c4b-9cc64e830059
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 068f1d74-4b98-4a90-83dc-b18d98e2f5cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a6fc95c2-1f06-4bd3-b315-19bd36dec3e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f02208b0-83b7-4baf-a2eb-7330e12443d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2a096ed9-5a5f-44e3-91bc-6a7c2e41d92f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 31dd6cf6-1fe5-45f6-83ec-e2e023cd908d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0dcb8647-c006-491a-9ed2-e875c985b192
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5a94b08b-d087-48f9-8183-cf17e55b0ff4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b646883e-0dfe-4039-8115-cff58dddce01
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 76ed4fb8-31f1-45ff-8459-e62e06cf2bf0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9998bcf2-9597-40b5-8adb-ec0fbd51013d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9e406d4a-4922-4842-b650-de51bf3ca3a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a8a49a2b-6117-4c26-a5f5-7501620d5d19
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 68f854b5-36bc-42e7-8f93-7fe9e27fb6bc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c3494de1-d44e-4404-964a-8512ea9a9a3c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c3ea6792-00e7-43c4-9b44-7dbfafa22efe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3e4ed012-fe8c-4740-b2b6-1570c7c8215e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 374e3f26-256a-46d0-944e-56f22d2bd47e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 89ebef9b-c992-4673-a667-06dcb76c7497
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d2f3d106-bde8-476b-bc2b-7f4b8e33ba9d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 24945f8d-f379-444b-bcec-d28e1e43ae01
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 664e9f88-c65a-43e9-ac39-3cea43f1aaf6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 30af5fb7-f52d-4bb4-b9b1-659cc9a4daae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d3b8f597-1e49-4f2b-bd87-031b6505a697
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 095eb09b-4f99-4b32-aee4-06f09d72e6ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f01ce9e1-0e8a-49aa-b8a0-5ad231a5ed57
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d3b6c448-a00f-406a-9d9b-3d9eec6834cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7d0503da-472b-4e94-8ed2-ac45b0c85f05
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b4c8e3d4-6986-4014-bd70-761c0e7489e9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e650a9c1-9484-4457-bf65-aab43f6f423d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8a787279-998f-4cdf-952c-0ca44cd56150
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cb3ab108-3513-400d-803e-0eb7893c5599
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a37c4b31-aafb-40d0-b60c-b565b3969cb2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c44b9a8c-dd4c-488c-9ec6-993537a7b2af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c66a7546-d365-4717-86f1-f2905b6b4236
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d5ae30e1-8374-4ccd-85fa-7b20277594e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fe7dccc0-22e4-4378-8b09-400a4450126e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b3a239c5-ed97-45f8-af0e-da8d1073ad95
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bb33f69f-1709-4e27-8115-7bf152838b23
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 64164286-abe0-435e-92fc-4418fe8cdcef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2d9bd54c-f6cd-477b-95c3-c4a012ad2165
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 84ff285c-2545-443b-8421-a38673d1c46a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b19a97c3-a48a-4b5f-99cd-5711289b6e24
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4551a298-cdff-432e-8b67-c50f51c2ef8f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b47b921a-dfec-4309-964d-a0ea84056c7b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 552060ed-588f-4223-8fb5-7ba9fd1ccce5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8c1ce02b-716b-4b5d-94a5-5db30fb9629d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5351ba27-72b6-45a2-bc9a-cc5f6a7e0e0d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dd258c78-2a4e-4683-9f1a-223722de1857
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5fa48245-5da8-46da-bfbc-041a4e47b95d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 431a5870-d1f2-4b90-8c50-aa26080208d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 369a6a61-7159-420a-8b3d-7260a2564d35
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b8b901ca-4788-4dd9-a265-f3f0153f299c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2e4527ed-77d3-4406-9ff9-3ce45f64ce53
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 529568c9-94c5-4010-88ba-c729e18aa321
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3aaa024f-927a-4904-83f1-7dd4daec8e9a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5c165e28-e69d-4751-9163-ab881b704ab3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5a2aebf2-c576-4906-8d70-3a4863d80a6f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d00d4772-9c3d-41cd-ae34-ca7e3d0808e9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message adb81490-9f79-4fcc-8fda-0daba4c6b975
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8e499143-1202-4017-8c27-422c4b860b39
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 862fca2a-4f71-4ffb-8f92-7b4f0285ceed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0c51b83a-09dc-4b96-b65d-5555002b1a68
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 87c576f2-be77-4393-85db-53b3c6b6c548
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f7870608-c56d-4056-b70c-665a787a7522
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a51ae90f-7392-4c09-a3c3-b1da702da1ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 89b31dd7-b29b-41dd-b01c-3734a56c400c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d85f5923-24bf-4c2c-a52f-9d5bf530559a
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8687 {grpc_status:14, grpc_message:"Socket closed"}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_18
Server: localhost:8687
Algorithm: FEDAVG
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_18
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_18/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_18/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_18/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_18/test_labels.txt

📊 Raw data loaded:
   Train: X=(1054, 24), y=(1054,)
   Test:  X=(264, 24), y=(264,)

⚠️  Limiting training data: 1054 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  255 samples, 5 features
✅ Client client_18 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

============================================================
🔄 Round 1 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.2402, val=0.1119 (↓), lr=0.001000
   ✓ Epoch   2/100: train=0.0909, val=0.0820 (↓), lr=0.001000
   • Epoch   3/100: train=0.0851, val=0.0840, patience=1/15, lr=0.001000
   • Epoch   4/100: train=0.0847, val=0.0819, patience=2/15, lr=0.001000
   • Epoch   5/100: train=0.0838, val=0.0816, patience=3/15, lr=0.001000
   📉 Epoch 11: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0831, val=0.0823, patience=9/15, lr=0.000500
   📉 Epoch 19: LR reduced 0.000500 → 0.000250
   • Epoch  21/100: train=0.0804, val=0.0807, patience=9/15, lr=0.000250
   📉 Epoch 27: LR reduced 0.000250 → 0.000125

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 1 Summary - Client client_18
   Epochs: 27/100 (early stopped)
   LR: 0.001000 → 0.000125 (3 reductions)
   Train: Loss=0.0810, RMSE=0.2845, R²=0.0256
   Val:   Loss=0.0806, RMSE=0.2840, R²=0.0102
============================================================


📊 Round 1 Test Metrics:
   Loss: 0.0839, RMSE: 0.2896, MAE: 0.2512, R²: 0.0052

============================================================
🔄 Round 2 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000125
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0775 (↓), lr=0.000125
   • Epoch   2/100: train=0.0833, val=0.0774, patience=1/15, lr=0.000125
   • Epoch   3/100: train=0.0831, val=0.0774, patience=2/15, lr=0.000125
   • Epoch   4/100: train=0.0830, val=0.0775, patience=3/15, lr=0.000125
   • Epoch   5/100: train=0.0829, val=0.0776, patience=4/15, lr=0.000125
   📉 Epoch 9: LR reduced 0.000125 → 0.000063
   • Epoch  11/100: train=0.0823, val=0.0777, patience=10/15, lr=0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 2 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000125 → 0.000063 (1 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=0.0152
   Val:   Loss=0.0775, RMSE=0.2785, R²=-0.0266
============================================================


============================================================
🔄 Round 3 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0767 (↓), lr=0.000063
   • Epoch   2/100: train=0.0832, val=0.0765, patience=1/15, lr=0.000063
   • Epoch   3/100: train=0.0830, val=0.0765, patience=2/15, lr=0.000063
   • Epoch   4/100: train=0.0829, val=0.0765, patience=3/15, lr=0.000063
   • Epoch   5/100: train=0.0828, val=0.0765, patience=4/15, lr=0.000063
   📉 Epoch 9: LR reduced 0.000063 → 0.000031
   • Epoch  11/100: train=0.0825, val=0.0766, patience=10/15, lr=0.000031

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0767)

============================================================
📊 Round 3 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000063 → 0.000031 (1 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=0.0074
   Val:   Loss=0.0767, RMSE=0.2769, R²=0.0252
============================================================


📊 Round 3 Test Metrics:
   Loss: 0.0828, RMSE: 0.2878, MAE: 0.2502, R²: 0.0175

============================================================
🔄 Round 4 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000031
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   📉 Epoch 1: LR reduced 0.000031 → 0.000016
   ✓ Epoch   1/100: train=0.0806, val=0.0855 (↓), lr=0.000016
   • Epoch   2/100: train=0.0804, val=0.0854, patience=1/15, lr=0.000016
   • Epoch   3/100: train=0.0803, val=0.0853, patience=2/15, lr=0.000016
   • Epoch   4/100: train=0.0803, val=0.0853, patience=3/15, lr=0.000016
   • Epoch   5/100: train=0.0802, val=0.0853, patience=4/15, lr=0.000016
   📉 Epoch 9: LR reduced 0.000016 → 0.000008
   • Epoch  11/100: train=0.0800, val=0.0852, patience=10/15, lr=0.000008

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 4 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000031 → 0.000008 (2 reductions)
   Train: Loss=0.0806, RMSE=0.2838, R²=0.0177
   Val:   Loss=0.0855, RMSE=0.2923, R²=0.0056
============================================================


📊 Round 4 Test Metrics:
   Loss: 0.0828, RMSE: 0.2877, MAE: 0.2503, R²: 0.0182

============================================================
🔄 Round 5 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000008
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   📉 Epoch 1: LR reduced 0.000008 → 0.000004
   ✓ Epoch   1/100: train=0.0824, val=0.0777 (↓), lr=0.000004
   • Epoch   2/100: train=0.0824, val=0.0776, patience=1/15, lr=0.000004
   • Epoch   3/100: train=0.0823, val=0.0776, patience=2/15, lr=0.000004
   • Epoch   4/100: train=0.0822, val=0.0775, patience=3/15, lr=0.000004
   • Epoch   5/100: train=0.0822, val=0.0775, patience=4/15, lr=0.000004
   📉 Epoch 9: LR reduced 0.000004 → 0.000002
   • Epoch  11/100: train=0.0820, val=0.0773, patience=10/15, lr=0.000002

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 5 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000008 → 0.000002 (2 reductions)
   Train: Loss=0.0825, RMSE=0.2873, R²=0.0143
   Val:   Loss=0.0777, RMSE=0.2787, R²=0.0169
============================================================


📊 Round 5 Test Metrics:
   Loss: 0.0810, RMSE: 0.2846, MAE: 0.2475, R²: 0.0394

📊 Round 5 Test Metrics:
   Loss: 0.0810, RMSE: 0.2845, MAE: 0.2474, R²: 0.0399

============================================================
🔄 Round 12 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000002
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   📉 Epoch 1: LR reduced 0.000002 → 0.000001
   ✓ Epoch   1/100: train=0.0792, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 12 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000002 → 0.000001 (1 reductions)
   Train: Loss=0.0791, RMSE=0.2812, R²=0.0297
   Val:   Loss=0.0841, RMSE=0.2900, R²=0.0363
============================================================


📊 Round 12 Test Metrics:
   Loss: 0.0811, RMSE: 0.2847, MAE: 0.2475, R²: 0.0387

📊 Round 12 Test Metrics:
   Loss: 0.0810, RMSE: 0.2846, MAE: 0.2473, R²: 0.0393

📊 Round 12 Test Metrics:
   Loss: 0.0810, RMSE: 0.2846, MAE: 0.2473, R²: 0.0395

============================================================
🔄 Round 20 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 20 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2822, R²=0.0196
   Val:   Loss=0.0823, RMSE=0.2869, R²=0.0730
============================================================


📊 Round 20 Test Metrics:
   Loss: 0.0810, RMSE: 0.2846, MAE: 0.2473, R²: 0.0398

============================================================
🔄 Round 21 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 21 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2811, R²=0.0247
   Val:   Loss=0.0850, RMSE=0.2916, R²=0.0531
============================================================


📊 Round 21 Test Metrics:
   Loss: 0.0810, RMSE: 0.2845, MAE: 0.2473, R²: 0.0399

============================================================
🔄 Round 23 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0745 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0745, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0745, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0745, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0745, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0745, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0745)

============================================================
📊 Round 23 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=0.0347
   Val:   Loss=0.0745, RMSE=0.2729, R²=0.0115
============================================================


============================================================
🔄 Round 24 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0762 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0762, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0761, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0761, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0761, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0761, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0762)

============================================================
📊 Round 24 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=0.0317
   Val:   Loss=0.0762, RMSE=0.2760, R²=0.0246
============================================================


📊 Round 24 Test Metrics:
   Loss: 0.0810, RMSE: 0.2845, MAE: 0.2473, R²: 0.0399

============================================================
🔄 Round 26 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 26 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2818, R²=0.0342
   Val:   Loss=0.0836, RMSE=0.2891, R²=-0.0033
============================================================


📊 Round 26 Test Metrics:
   Loss: 0.0810, RMSE: 0.2845, MAE: 0.2473, R²: 0.0399

============================================================
🔄 Round 29 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 29 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2814, R²=0.0251
   Val:   Loss=0.0844, RMSE=0.2904, R²=0.0521
============================================================


============================================================
🔄 Round 30 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 30 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=0.0282
   Val:   Loss=0.0818, RMSE=0.2861, R²=0.0318
============================================================


📊 Round 30 Test Metrics:
   Loss: 0.0810, RMSE: 0.2845, MAE: 0.2473, R²: 0.0399

============================================================
🔄 Round 32 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 32 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2806, R²=0.0303
   Val:   Loss=0.0861, RMSE=0.2935, R²=0.0051
============================================================


📊 Round 32 Test Metrics:
   Loss: 0.0810, RMSE: 0.2845, MAE: 0.2473, R²: 0.0399

============================================================
🔄 Round 36 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 36 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2818, R²=0.0232
   Val:   Loss=0.0835, RMSE=0.2890, R²=0.0475
============================================================


============================================================
🔄 Round 37 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0766, val=0.0941 (↓), lr=0.000001
   • Epoch   2/100: train=0.0766, val=0.0941, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0766, val=0.0941, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0766, val=0.0941, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0766, val=0.0941, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0766, val=0.0941, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0941)

============================================================
📊 Round 37 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0768, RMSE=0.2771, R²=0.0395
   Val:   Loss=0.0941, RMSE=0.3067, R²=0.0010
============================================================


============================================================
🔄 Round 39 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 39 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=0.0370
   Val:   Loss=0.0823, RMSE=0.2868, R²=-0.0015
============================================================


📊 Round 39 Test Metrics:
   Loss: 0.0810, RMSE: 0.2845, MAE: 0.2473, R²: 0.0398

============================================================
🔄 Round 43 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 43 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=0.0345
   Val:   Loss=0.0795, RMSE=0.2819, R²=0.0162
============================================================


📊 Round 43 Test Metrics:
   Loss: 0.0810, RMSE: 0.2846, MAE: 0.2473, R²: 0.0398

============================================================
🔄 Round 45 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 45 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2833, R²=0.0292
   Val:   Loss=0.0800, RMSE=0.2829, R²=0.0317
============================================================


============================================================
🔄 Round 46 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0777, val=0.0900 (↓), lr=0.000001
   • Epoch   2/100: train=0.0777, val=0.0900, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0777, val=0.0900, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0776, val=0.0900, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0776, val=0.0900, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0776, val=0.0900, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0900)

============================================================
📊 Round 46 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0778, RMSE=0.2789, R²=0.0324
   Val:   Loss=0.0900, RMSE=0.3001, R²=0.0253
============================================================


📊 Round 46 Test Metrics:
   Loss: 0.0810, RMSE: 0.2845, MAE: 0.2473, R²: 0.0398

============================================================
🔄 Round 49 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0742 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0742, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0742, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0742, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0742, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0742, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0742)

============================================================
📊 Round 49 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=0.0299
   Val:   Loss=0.0742, RMSE=0.2725, R²=0.0359
============================================================


📊 Round 49 Test Metrics:
   Loss: 0.0810, RMSE: 0.2846, MAE: 0.2473, R²: 0.0398

============================================================
🔄 Round 50 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 50 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2805, R²=0.0334
   Val:   Loss=0.0864, RMSE=0.2939, R²=0.0189
============================================================


============================================================
🔄 Round 58 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 58 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=0.0306
   Val:   Loss=0.0819, RMSE=0.2861, R²=0.0197
============================================================


📊 Round 58 Test Metrics:
   Loss: 0.0810, RMSE: 0.2846, MAE: 0.2473, R²: 0.0398

============================================================
🔄 Round 59 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0671 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0671, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0671, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0671, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0671, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0671, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0671)

============================================================
📊 Round 59 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=0.0320
   Val:   Loss=0.0671, RMSE=0.2591, R²=0.0247
============================================================


📊 Round 59 Test Metrics:
   Loss: 0.0810, RMSE: 0.2846, MAE: 0.2473, R²: 0.0398

📊 Round 59 Test Metrics:
   Loss: 0.0810, RMSE: 0.2846, MAE: 0.2473, R²: 0.0398

📊 Round 59 Test Metrics:
   Loss: 0.0810, RMSE: 0.2846, MAE: 0.2473, R²: 0.0398

============================================================
🔄 Round 63 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 63 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=0.0306
   Val:   Loss=0.0807, RMSE=0.2840, R²=0.0330
============================================================


📊 Round 63 Test Metrics:
   Loss: 0.0810, RMSE: 0.2846, MAE: 0.2473, R²: 0.0397

============================================================
🔄 Round 69 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 69 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2806, R²=0.0378
   Val:   Loss=0.0861, RMSE=0.2935, R²=0.0053
============================================================


============================================================
🔄 Round 70 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 70 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2814, R²=0.0293
   Val:   Loss=0.0844, RMSE=0.2905, R²=0.0341
============================================================


============================================================
🔄 Round 72 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 72 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=0.0343
   Val:   Loss=0.0807, RMSE=0.2841, R²=0.0173
============================================================


============================================================
🔄 Round 73 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 73 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2826, R²=0.0305
   Val:   Loss=0.0815, RMSE=0.2855, R²=0.0264
============================================================


📊 Round 73 Test Metrics:
   Loss: 0.0810, RMSE: 0.2846, MAE: 0.2473, R²: 0.0397

============================================================
🔄 Round 74 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0763, val=0.0961 (↓), lr=0.000001
   • Epoch   2/100: train=0.0763, val=0.0961, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0763, val=0.0961, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0763, val=0.0961, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0762, val=0.0961, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0762, val=0.0961, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0961)

============================================================
📊 Round 74 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0763, RMSE=0.2761, R²=0.0298
   Val:   Loss=0.0961, RMSE=0.3100, R²=0.0327
============================================================


📊 Round 74 Test Metrics:
   Loss: 0.0810, RMSE: 0.2846, MAE: 0.2473, R²: 0.0397

📊 Round 74 Test Metrics:
   Loss: 0.0810, RMSE: 0.2846, MAE: 0.2473, R²: 0.0397

📊 Round 74 Test Metrics:
   Loss: 0.0810, RMSE: 0.2846, MAE: 0.2473, R²: 0.0396

============================================================
🔄 Round 80 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0755 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0755, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0755, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0755, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0755, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0756, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0755)

============================================================
📊 Round 80 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=0.0265
   Val:   Loss=0.0755, RMSE=0.2748, R²=0.0363
============================================================


📊 Round 80 Test Metrics:
   Loss: 0.0810, RMSE: 0.2846, MAE: 0.2473, R²: 0.0396

============================================================
🔄 Round 81 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 81 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=0.0308
   Val:   Loss=0.0792, RMSE=0.2815, R²=0.0315
============================================================


📊 Round 81 Test Metrics:
   Loss: 0.0810, RMSE: 0.2846, MAE: 0.2473, R²: 0.0396

📊 Round 81 Test Metrics:
   Loss: 0.0810, RMSE: 0.2846, MAE: 0.2473, R²: 0.0396

============================================================
🔄 Round 83 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0783, val=0.0874 (↓), lr=0.000001
   • Epoch   2/100: train=0.0782, val=0.0874, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0782, val=0.0874, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0782, val=0.0874, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0782, val=0.0874, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0782, val=0.0874, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0874)

============================================================
📊 Round 83 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2800, R²=0.0283
   Val:   Loss=0.0874, RMSE=0.2957, R²=0.0359
============================================================


============================================================
🔄 Round 84 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 84 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2833, R²=0.0391
   Val:   Loss=0.0801, RMSE=0.2829, R²=-0.0027
============================================================


📊 Round 84 Test Metrics:
   Loss: 0.0810, RMSE: 0.2846, MAE: 0.2473, R²: 0.0396

============================================================
🔄 Round 86 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0771 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0771, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0771, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0771, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0771, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0770, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0771)

============================================================
📊 Round 86 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=0.0215
   Val:   Loss=0.0771, RMSE=0.2776, R²=0.0683
============================================================


============================================================
🔄 Round 87 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 87 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2821, R²=0.0339
   Val:   Loss=0.0828, RMSE=0.2878, R²=0.0191
============================================================


============================================================
🔄 Round 89 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 89 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2813, R²=0.0234
   Val:   Loss=0.0845, RMSE=0.2907, R²=0.0591
============================================================


============================================================
🔄 Round 90 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 90 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2808, R²=0.0329
   Val:   Loss=0.0858, RMSE=0.2928, R²=0.0219
============================================================


📊 Round 90 Test Metrics:
   Loss: 0.0810, RMSE: 0.2846, MAE: 0.2473, R²: 0.0396

============================================================
🔄 Round 92 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 92 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2818, R²=0.0214
   Val:   Loss=0.0834, RMSE=0.2887, R²=0.0607
============================================================


📊 Round 92 Test Metrics:
   Loss: 0.0810, RMSE: 0.2846, MAE: 0.2473, R²: 0.0396

============================================================
🔄 Round 96 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0756 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0756, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0756, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0756, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0756, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0756, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0756)

============================================================
📊 Round 96 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2852, R²=0.0206
   Val:   Loss=0.0756, RMSE=0.2749, R²=0.0739
============================================================


============================================================
🔄 Round 97 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 97 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2831, R²=0.0330
   Val:   Loss=0.0804, RMSE=0.2836, R²=0.0207
============================================================


📊 Round 97 Test Metrics:
   Loss: 0.0810, RMSE: 0.2846, MAE: 0.2473, R²: 0.0396

============================================================
🔄 Round 99 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 99 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=0.0342
   Val:   Loss=0.0797, RMSE=0.2824, R²=0.0186
============================================================


📊 Round 99 Test Metrics:
   Loss: 0.0810, RMSE: 0.2846, MAE: 0.2473, R²: 0.0395

============================================================
🔄 Round 101 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0782, val=0.0873 (↓), lr=0.000001
   • Epoch   2/100: train=0.0782, val=0.0873, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0781, val=0.0873, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0781, val=0.0874, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0781, val=0.0874, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0781, val=0.0874, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0873)

============================================================
📊 Round 101 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2800, R²=0.0292
   Val:   Loss=0.0873, RMSE=0.2955, R²=0.0380
============================================================


📊 Round 101 Test Metrics:
   Loss: 0.0810, RMSE: 0.2846, MAE: 0.2473, R²: 0.0395

📊 Round 101 Test Metrics:
   Loss: 0.0810, RMSE: 0.2846, MAE: 0.2473, R²: 0.0395

============================================================
🔄 Round 103 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 103 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2840, R²=0.0355
   Val:   Loss=0.0784, RMSE=0.2801, R²=0.0125
============================================================


============================================================
🔄 Round 104 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0765 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0765, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0765, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0765, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0765, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0765, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0765)

============================================================
📊 Round 104 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=0.0239
   Val:   Loss=0.0765, RMSE=0.2766, R²=0.0590
============================================================


📊 Round 104 Test Metrics:
   Loss: 0.0810, RMSE: 0.2846, MAE: 0.2473, R²: 0.0395

============================================================
🔄 Round 106 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 106 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2816, R²=0.0249
   Val:   Loss=0.0837, RMSE=0.2893, R²=0.0428
============================================================


📊 Round 106 Test Metrics:
   Loss: 0.0810, RMSE: 0.2846, MAE: 0.2473, R²: 0.0395

📊 Round 106 Test Metrics:
   Loss: 0.0810, RMSE: 0.2846, MAE: 0.2473, R²: 0.0395

============================================================
🔄 Round 108 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0767 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0767, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0767, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0767, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0767, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0767, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0767)

============================================================
📊 Round 108 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2847, R²=0.0327
   Val:   Loss=0.0767, RMSE=0.2769, R²=0.0007
============================================================


📊 Round 108 Test Metrics:
   Loss: 0.0810, RMSE: 0.2846, MAE: 0.2473, R²: 0.0395

============================================================
🔄 Round 109 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 109 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2821, R²=0.0357
   Val:   Loss=0.0827, RMSE=0.2876, R²=0.0136
============================================================


============================================================
🔄 Round 110 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 110 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=0.0285
   Val:   Loss=0.0786, RMSE=0.2803, R²=0.0407
============================================================


📊 Round 110 Test Metrics:
   Loss: 0.0810, RMSE: 0.2846, MAE: 0.2473, R²: 0.0395

============================================================
🔄 Round 115 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0727 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0727, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0727, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0727, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0727, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0727, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0727)

============================================================
📊 Round 115 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=0.0315
   Val:   Loss=0.0727, RMSE=0.2696, R²=0.0209
============================================================


📊 Round 115 Test Metrics:
   Loss: 0.0810, RMSE: 0.2846, MAE: 0.2473, R²: 0.0395

============================================================
🔄 Round 116 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0865 (↓), lr=0.000001
   • Epoch   2/100: train=0.0787, val=0.0865, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0865, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0865, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0865, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0864, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0865)

============================================================
📊 Round 116 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2804, R²=0.0294
   Val:   Loss=0.0865, RMSE=0.2941, R²=0.0377
============================================================


📊 Round 116 Test Metrics:
   Loss: 0.0810, RMSE: 0.2846, MAE: 0.2473, R²: 0.0395

📊 Round 116 Test Metrics:
   Loss: 0.0810, RMSE: 0.2846, MAE: 0.2473, R²: 0.0395

============================================================
🔄 Round 119 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 119 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2814, R²=0.0341
   Val:   Loss=0.0842, RMSE=0.2901, R²=0.0202
============================================================


📊 Round 119 Test Metrics:
   Loss: 0.0810, RMSE: 0.2846, MAE: 0.2473, R²: 0.0395

============================================================
🔄 Round 120 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0749 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0750, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0750, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0750, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0750, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0751, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0749)

============================================================
📊 Round 120 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=0.0220
   Val:   Loss=0.0749, RMSE=0.2737, R²=0.0290
============================================================


============================================================
🔄 Round 121 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 121 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=0.0293
   Val:   Loss=0.0797, RMSE=0.2822, R²=0.0368
============================================================


============================================================
🔄 Round 123 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 123 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2840, R²=0.0291
   Val:   Loss=0.0783, RMSE=0.2799, R²=0.0346
============================================================


============================================================
🔄 Round 124 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0770, val=0.0935 (↓), lr=0.000001
   • Epoch   2/100: train=0.0770, val=0.0935, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0770, val=0.0935, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0770, val=0.0935, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0770, val=0.0935, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0769, val=0.0935, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0935)

============================================================
📊 Round 124 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0769, RMSE=0.2773, R²=0.0370
   Val:   Loss=0.0935, RMSE=0.3058, R²=0.0035
============================================================


============================================================
🔄 Round 125 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 125 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=0.0278
   Val:   Loss=0.0794, RMSE=0.2817, R²=0.0425
============================================================


============================================================
🔄 Round 126 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 126 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2819, R²=0.0308
   Val:   Loss=0.0830, RMSE=0.2882, R²=0.0331
============================================================


📊 Round 126 Test Metrics:
   Loss: 0.0810, RMSE: 0.2846, MAE: 0.2473, R²: 0.0394

============================================================
🔄 Round 127 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 127 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2826, R²=0.0307
   Val:   Loss=0.0816, RMSE=0.2857, R²=0.0026
============================================================


============================================================
🔄 Round 129 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 129 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=0.0256
   Val:   Loss=0.0806, RMSE=0.2839, R²=0.0359
============================================================


📊 Round 129 Test Metrics:
   Loss: 0.0810, RMSE: 0.2846, MAE: 0.2473, R²: 0.0395

============================================================
🔄 Round 131 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 131 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2817, R²=0.0278
   Val:   Loss=0.0836, RMSE=0.2891, R²=0.0395
============================================================


📊 Round 131 Test Metrics:
   Loss: 0.0810, RMSE: 0.2846, MAE: 0.2473, R²: 0.0395

============================================================
🔄 Round 133 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 133 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=0.0273
   Val:   Loss=0.0792, RMSE=0.2814, R²=0.0394
============================================================


📊 Round 133 Test Metrics:
   Loss: 0.0810, RMSE: 0.2846, MAE: 0.2473, R²: 0.0395

============================================================
🔄 Round 134 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 134 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=0.0333
   Val:   Loss=0.0801, RMSE=0.2830, R²=0.0171
============================================================


📊 Round 134 Test Metrics:
   Loss: 0.0810, RMSE: 0.2846, MAE: 0.2473, R²: 0.0395

============================================================
🔄 Round 139 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 139 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=0.0402
   Val:   Loss=0.0811, RMSE=0.2847, R²=-0.0059
============================================================


📊 Round 139 Test Metrics:
   Loss: 0.0810, RMSE: 0.2846, MAE: 0.2473, R²: 0.0395

============================================================
🔄 Round 140 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 140 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=0.0287
   Val:   Loss=0.0790, RMSE=0.2811, R²=0.0283
============================================================


📊 Round 140 Test Metrics:
   Loss: 0.0810, RMSE: 0.2846, MAE: 0.2473, R²: 0.0395

============================================================
🔄 Round 141 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0780, val=0.0897 (↓), lr=0.000001
   • Epoch   2/100: train=0.0780, val=0.0897, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0780, val=0.0897, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0779, val=0.0897, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0779, val=0.0897, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0779, val=0.0897, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0897)

============================================================
📊 Round 141 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0778, RMSE=0.2789, R²=0.0256
   Val:   Loss=0.0897, RMSE=0.2996, R²=0.0502
============================================================


📊 Round 141 Test Metrics:
   Loss: 0.0810, RMSE: 0.2846, MAE: 0.2473, R²: 0.0395

============================================================
🔄 Round 143 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0724 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0724, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0724, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0724, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0724, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0724, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0724)

============================================================
📊 Round 143 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2866, R²=0.0300
   Val:   Loss=0.0724, RMSE=0.2691, R²=0.0342
============================================================


📊 Round 143 Test Metrics:
   Loss: 0.0810, RMSE: 0.2846, MAE: 0.2473, R²: 0.0395

============================================================
🔄 Round 145 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 145 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2812, R²=0.0363
   Val:   Loss=0.0846, RMSE=0.2909, R²=0.0120
============================================================


============================================================
🔄 Round 147 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0766 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0766, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0766, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0766, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0766, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0766, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0766)

============================================================
📊 Round 147 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=0.0300
   Val:   Loss=0.0766, RMSE=0.2767, R²=0.0333
============================================================


📊 Round 147 Test Metrics:
   Loss: 0.0810, RMSE: 0.2846, MAE: 0.2473, R²: 0.0395

============================================================
🔄 Round 150 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0753 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0753, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0753, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0753, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0753, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0753, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0753)

============================================================
📊 Round 150 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=0.0292
   Val:   Loss=0.0753, RMSE=0.2744, R²=0.0367
============================================================


============================================================
🔄 Round 153 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0746 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0745, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0745, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0745, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0745, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0745, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0746)

============================================================
📊 Round 153 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=0.0354
   Val:   Loss=0.0746, RMSE=0.2730, R²=0.0137
============================================================


📊 Round 153 Test Metrics:
   Loss: 0.0810, RMSE: 0.2846, MAE: 0.2473, R²: 0.0394

📊 Round 153 Test Metrics:
   Loss: 0.0810, RMSE: 0.2846, MAE: 0.2473, R²: 0.0394

============================================================
🔄 Round 157 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0772, val=0.0934 (↓), lr=0.000001
   • Epoch   2/100: train=0.0772, val=0.0934, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0772, val=0.0934, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0772, val=0.0934, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0772, val=0.0934, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0771, val=0.0935, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0934)

============================================================
📊 Round 157 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0769, RMSE=0.2773, R²=0.0365
   Val:   Loss=0.0934, RMSE=0.3057, R²=0.0141
============================================================


============================================================
🔄 Round 158 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0761 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0761, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0761, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0761, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0761, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0761, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0761)

============================================================
📊 Round 158 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=0.0351
   Val:   Loss=0.0761, RMSE=0.2759, R²=0.0116
============================================================


============================================================
🔄 Round 159 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0740 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0741, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0741, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0741, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0741, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0741, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0740)

============================================================
📊 Round 159 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=0.0259
   Val:   Loss=0.0740, RMSE=0.2721, R²=0.0491
============================================================


📊 Round 159 Test Metrics:
   Loss: 0.0810, RMSE: 0.2846, MAE: 0.2473, R²: 0.0394

============================================================
🔄 Round 160 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0731 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0731, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0731, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0731, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0731, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0731, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0731)

============================================================
📊 Round 160 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=0.0240
   Val:   Loss=0.0731, RMSE=0.2703, R²=0.0510
============================================================


============================================================
🔄 Round 161 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0752 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0752, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0752, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0751, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0751, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0751, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0752)

============================================================
📊 Round 161 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2854, R²=0.0385
   Val:   Loss=0.0752, RMSE=0.2742, R²=-0.0012
============================================================


📊 Round 161 Test Metrics:
   Loss: 0.0810, RMSE: 0.2846, MAE: 0.2473, R²: 0.0394

📊 Round 161 Test Metrics:
   Loss: 0.0810, RMSE: 0.2846, MAE: 0.2473, R²: 0.0394

============================================================
🔄 Round 165 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0741 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0741, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0741, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0741, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0741, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0741, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0741)

============================================================
📊 Round 165 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=0.0342
   Val:   Loss=0.0741, RMSE=0.2722, R²=0.0194
============================================================


============================================================
🔄 Round 166 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 166 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2811, R²=0.0370
   Val:   Loss=0.0847, RMSE=0.2911, R²=0.0061
============================================================


📊 Round 166 Test Metrics:
   Loss: 0.0810, RMSE: 0.2846, MAE: 0.2473, R²: 0.0394

============================================================
🔄 Round 168 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0736 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0736, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0736, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0736, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0736, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0736, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0736)

============================================================
📊 Round 168 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=0.0287
   Val:   Loss=0.0736, RMSE=0.2713, R²=0.0439
============================================================


📊 Round 168 Test Metrics:
   Loss: 0.0810, RMSE: 0.2846, MAE: 0.2473, R²: 0.0394

============================================================
🔄 Round 169 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0778, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0778, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0778, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0778, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0779, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 169 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=0.0397
   Val:   Loss=0.0778, RMSE=0.2789, R²=-0.0333
============================================================


📊 Round 169 Test Metrics:
   Loss: 0.0810, RMSE: 0.2846, MAE: 0.2473, R²: 0.0394

============================================================
🔄 Round 171 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 171 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=0.0239
   Val:   Loss=0.0796, RMSE=0.2821, R²=0.0313
============================================================


============================================================
🔄 Round 172 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 172 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=0.0417
   Val:   Loss=0.0822, RMSE=0.2867, R²=-0.0104
============================================================


📊 Round 172 Test Metrics:
   Loss: 0.0810, RMSE: 0.2846, MAE: 0.2473, R²: 0.0394

📊 Round 172 Test Metrics:
   Loss: 0.0810, RMSE: 0.2846, MAE: 0.2473, R²: 0.0394

📊 Round 172 Test Metrics:
   Loss: 0.0810, RMSE: 0.2846, MAE: 0.2473, R²: 0.0394

============================================================
🔄 Round 177 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0742 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0742, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0742, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0742, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0742, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0742, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0742)

============================================================
📊 Round 177 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=0.0255
   Val:   Loss=0.0742, RMSE=0.2725, R²=0.0497
============================================================


📊 Round 177 Test Metrics:
   Loss: 0.0810, RMSE: 0.2846, MAE: 0.2473, R²: 0.0394

============================================================
🔄 Round 179 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 179 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2831, R²=0.0324
   Val:   Loss=0.0803, RMSE=0.2834, R²=0.0213
============================================================


📊 Round 179 Test Metrics:
   Loss: 0.0810, RMSE: 0.2846, MAE: 0.2473, R²: 0.0394

============================================================
🔄 Round 180 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0697 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0697, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0697, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0697, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0697, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0697, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0697)

============================================================
📊 Round 180 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=0.0303
   Val:   Loss=0.0697, RMSE=0.2641, R²=0.0372
============================================================


============================================================
🔄 Round 182 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 182 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=0.0265
   Val:   Loss=0.0821, RMSE=0.2865, R²=0.0495
============================================================


📊 Round 182 Test Metrics:
   Loss: 0.0810, RMSE: 0.2846, MAE: 0.2473, R²: 0.0394

============================================================
🔄 Round 185 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0767 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0767, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0767, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0767, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0767, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0767, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0767)

============================================================
📊 Round 185 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2847, R²=0.0264
   Val:   Loss=0.0767, RMSE=0.2769, R²=0.0530
============================================================


============================================================
🔄 Round 186 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 186 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2819, R²=0.0173
   Val:   Loss=0.0831, RMSE=0.2882, R²=0.0785
============================================================


📊 Round 186 Test Metrics:
   Loss: 0.0810, RMSE: 0.2846, MAE: 0.2473, R²: 0.0394

📊 Round 186 Test Metrics:
   Loss: 0.0810, RMSE: 0.2846, MAE: 0.2473, R²: 0.0394

============================================================
🔄 Round 189 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0776 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0777, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0777, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0777, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0777, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0779, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 189 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=0.0363
   Val:   Loss=0.0776, RMSE=0.2786, R²=-0.0447
============================================================


============================================================
🔄 Round 190 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 190 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2814, R²=0.0362
   Val:   Loss=0.0841, RMSE=0.2899, R²=0.0123
============================================================


📊 Round 190 Test Metrics:
   Loss: 0.0810, RMSE: 0.2846, MAE: 0.2473, R²: 0.0394

📊 Round 190 Test Metrics:
   Loss: 0.0810, RMSE: 0.2846, MAE: 0.2473, R²: 0.0394

============================================================
🔄 Round 195 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 195 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2808, R²=0.0359
   Val:   Loss=0.0854, RMSE=0.2923, R²=0.0098
============================================================


============================================================
🔄 Round 197 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0780 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0780, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0780, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0780, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0780, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 197 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=0.0270
   Val:   Loss=0.0780, RMSE=0.2792, R²=0.0420
============================================================


============================================================
🔄 Round 198 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0743 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0743, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0743, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0743, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0743, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0743, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0743)

============================================================
📊 Round 198 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=0.0301
   Val:   Loss=0.0743, RMSE=0.2726, R²=0.0256
============================================================


============================================================
🔄 Round 199 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 199 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2819, R²=0.0349
   Val:   Loss=0.0829, RMSE=0.2879, R²=-0.0083
============================================================


============================================================
🔄 Round 200 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 200 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=0.0310
   Val:   Loss=0.0775, RMSE=0.2785, R²=0.0329
============================================================


============================================================
🔄 Round 201 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 201 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2829, R²=0.0373
   Val:   Loss=0.0807, RMSE=0.2840, R²=0.0090
============================================================


============================================================
🔄 Round 203 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0776, val=0.0891 (↓), lr=0.000001
   • Epoch   2/100: train=0.0776, val=0.0891, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0776, val=0.0891, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0776, val=0.0891, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0776, val=0.0891, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0775, val=0.0892, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0891)

============================================================
📊 Round 203 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0779, RMSE=0.2792, R²=0.0279
   Val:   Loss=0.0891, RMSE=0.2984, R²=0.0248
============================================================


📊 Round 203 Test Metrics:
   Loss: 0.0810, RMSE: 0.2846, MAE: 0.2473, R²: 0.0393

============================================================
🔄 Round 205 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0758 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0758, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0758, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0758, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0758, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0759, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0758)

============================================================
📊 Round 205 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=0.0370
   Val:   Loss=0.0758, RMSE=0.2753, R²=-0.0168
============================================================


📊 Round 205 Test Metrics:
   Loss: 0.0810, RMSE: 0.2846, MAE: 0.2473, R²: 0.0393

📊 Round 205 Test Metrics:
   Loss: 0.0810, RMSE: 0.2846, MAE: 0.2473, R²: 0.0393

📊 Round 205 Test Metrics:
   Loss: 0.0810, RMSE: 0.2846, MAE: 0.2473, R²: 0.0393

📊 Round 205 Test Metrics:
   Loss: 0.0810, RMSE: 0.2846, MAE: 0.2473, R²: 0.0393

📊 Round 205 Test Metrics:
   Loss: 0.0810, RMSE: 0.2846, MAE: 0.2473, R²: 0.0393

============================================================
🔄 Round 212 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 212 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2820, R²=0.0365
   Val:   Loss=0.0826, RMSE=0.2874, R²=0.0117
============================================================


📊 Round 212 Test Metrics:
   Loss: 0.0810, RMSE: 0.2846, MAE: 0.2473, R²: 0.0393

============================================================
🔄 Round 213 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 213 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2833, R²=0.0313
   Val:   Loss=0.0796, RMSE=0.2822, R²=0.0320
============================================================


📊 Round 213 Test Metrics:
   Loss: 0.0810, RMSE: 0.2846, MAE: 0.2473, R²: 0.0393

============================================================
🔄 Round 214 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 214 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2831, R²=0.0244
   Val:   Loss=0.0802, RMSE=0.2833, R²=0.0422
============================================================


📊 Round 214 Test Metrics:
   Loss: 0.0810, RMSE: 0.2846, MAE: 0.2473, R²: 0.0393

📊 Round 214 Test Metrics:
   Loss: 0.0810, RMSE: 0.2846, MAE: 0.2473, R²: 0.0393

============================================================
🔄 Round 220 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 220 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2833, R²=0.0340
   Val:   Loss=0.0797, RMSE=0.2823, R²=0.0230
============================================================


📊 Round 220 Test Metrics:
   Loss: 0.0810, RMSE: 0.2846, MAE: 0.2473, R²: 0.0392

📊 Round 220 Test Metrics:
   Loss: 0.0810, RMSE: 0.2846, MAE: 0.2473, R²: 0.0392

============================================================
🔄 Round 224 - Client client_18
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0774 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0774, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0774, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0774, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0774, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0774)

============================================================
📊 Round 224 Summary - Client client_18
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=0.0281
   Val:   Loss=0.0774, RMSE=0.2782, R²=0.0473
============================================================


❌ Client client_18 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8687 {grpc_status:14, grpc_message:"Socket closed"}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8687 {grpc_status:14, grpc_message:"Socket closed"}"
>
