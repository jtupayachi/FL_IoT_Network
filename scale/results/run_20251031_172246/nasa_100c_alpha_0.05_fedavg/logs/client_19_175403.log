[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aaed2b34-9e29-4864-811c-c4c6ac3a3635
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 16ef90cd-b270-4f7b-a698-1c18cb2b8505
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 00f38247-a455-450c-8c7b-a72d51257e69
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message affc7e92-bbb3-42e5-a2b5-4be08994d410
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6517e649-06cc-474a-8d2d-e3be06719430
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5d816b7f-2fe8-40f3-a552-1e62ac291437
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 73d73ed3-c8b6-40c4-bc42-9f1e9d6c491d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2cffce84-40fd-469f-8e51-14b44b6f9f51
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ae452c73-53c8-4213-8fbd-18759d2b4f53
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3730e538-fca6-49e5-92e0-f2564fc7991b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3a6edda6-1275-48fe-82f6-8732f858ac87
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ed765be5-d594-45f4-be22-5aff38b7688b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 560eebec-8463-4eb8-ad00-79b0c5fea9a0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c56352b4-1b85-4487-9115-59c86532d068
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ca463629-0e8e-403a-a173-e3291bb8d958
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3c0e8c90-4f68-4052-a0d6-aad7888f9c93
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 70c68c5c-e688-43c3-a00d-5d89d8b0c88b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dc98a032-da8b-4e37-a417-67f779785023
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 767d54f3-13c4-437a-89cd-522ee72b4a25
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9986c3d1-dd35-4bee-8c9e-839285878ff0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d076579a-6650-4ead-a6dd-f7ec5960304b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bc29660d-376f-4261-8270-5bda0955a43e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 30e513d0-43cb-46e4-8493-b274d07ec3a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6bbd8c10-14ac-44f2-bba6-4159d17231b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 644e64a8-4b5f-4672-93b3-2ad9e6ab98da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8afba642-4c2b-4893-bb5d-14dec896fa5e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dcbed838-d3d1-48b7-a601-e06aa088d0a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ae68b18f-4c4c-4108-8ba4-40f56087f8c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c2e2fca1-a3f6-4f74-a79d-14a4648d530d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 73292915-636c-4efa-87aa-2faaa6894f2b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9f528ffb-1de2-479d-bc64-2651634410bc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 933dac00-13d2-48e6-a4fe-543e664e3ab7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 71554c4c-1221-45d0-90ce-0aa40ccc1ebc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4599c2fc-34d9-4026-9f6f-f5a474a9c32c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6ef881e7-6a8e-4a41-ab7a-8d2540bf6104
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 437a9e4d-d8e6-49df-8a4c-6a33b2fc7030
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d461fede-b93b-41b0-8aa1-bf698590f283
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 88a89b36-fa86-4e49-b22e-f667a0e35267
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5612b19f-36e9-4695-8299-6d00976f2c67
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 59e16740-0686-4356-8951-d6f8c29aa76a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 318823b0-ca02-4e12-8c56-fa3c4e0426e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e3a945e0-05c3-4f44-80a6-eae5158b4233
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cbd6245f-97b1-47fd-915c-293853f51029
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 132b64c4-3973-43e4-93b0-64ab7df27291
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4d9300e0-b8a9-412d-83c5-340ffb4ee6d8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b5f3eb4f-b199-45b0-88d2-1f902eec9e4c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 912909a4-f312-4609-8152-b65091df155b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4a6be54e-1ddf-4e14-999d-c0de7af1a4c6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 528b4f0c-e999-4360-81b9-250e042f2246
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 62f6bfbc-9224-47eb-b198-9551257b9a33
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 458bc922-c02e-4ca1-9c0f-e5bef9a979d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0373a267-18b0-4901-ac30-74e3f9c61c8c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4ce66449-412b-4ee6-8aac-7af41e90a125
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 551317d1-2928-4c83-bd5f-1acf2fad838d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 80c8d604-468c-471a-89d2-4914d77bbba4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4eb08cb5-b234-40c1-9a8c-dc292d21e4da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 123b3be4-1024-4604-9925-1b107d312856
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 872a5ac7-25ac-422b-8b34-8a61eb7f50d1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c6c15c96-671c-483b-93cd-a4855cc80553
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3ce5f358-5b8e-4c7d-8eae-8c786ec8c63d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bc163d47-6af0-40f0-b031-0234b26b6d4b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c0b453ce-c1e8-4024-a91d-6f35011f545a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 049102ce-0c0a-46de-80e2-66a4a774c218
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3f1744e8-ba8b-4255-b10a-04ee8e88dd8e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8ab1d50b-02c8-414a-9899-a697c1083db1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4d42e8a9-9205-42ce-8242-2e877e3bd6e1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 006f7970-c335-4082-be84-723d017790c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 22c978ed-d0e4-405f-926a-6a179f105305
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b01033c1-581b-4d00-9755-2b8dd9083c5f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1f01df93-ccf9-485e-b337-fc38a4ad44ea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d0311e3a-7e07-4e1c-89ab-363dbd4ad5fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 292167b5-fc81-476f-a462-190e6a82c4f4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5530572d-a1f1-4652-9f24-59191d3cde3b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e2e5bc7a-7483-474b-93d2-799ef51d8508
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 85638917-568d-4101-810c-0cd04a242083
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d7372c7f-fca6-4416-a060-f4e394cff6b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fb6f1c5a-9d33-4a58-afc3-83da210d49e8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f7eec6cf-de61-48a6-a834-c50de81783aa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 08360162-90b8-4ff8-bca2-0dcfdb38ca99
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c5431d6b-ab5f-4030-82f6-907d4f0ea079
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message caa701f8-92ce-4a6f-b9cb-c2e18a260898
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ec670919-f049-4222-beed-7ee3ab0985fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3a302942-1ffc-46ff-9c87-76b53cf26132
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 70929bc5-ce33-4334-a592-3a36c259b233
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 551a5a85-99b7-47d5-8ce1-c87ee15126f2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 115f480f-8edc-49ef-8bc4-cf42e3d4d089
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b3167c5c-65d9-4743-b232-18a46fa87bc4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e9dea878-01a4-4212-9eb7-97b73e64f7fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 55e9205f-e9f2-4997-9511-b9c22e296673
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 26c9a046-8574-4489-ba57-152e63b3d163
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 324d0e08-9772-4b2f-b3e1-da5da86093ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c3f8a58e-e800-4ac6-a5ea-25f126d886c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 35083e25-48d8-482f-90be-3497294c6289
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9548267f-997b-4697-86c4-87eb54197130
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 632958e4-f562-44ec-b198-e2a0d35f2676
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ea391d08-65e1-403c-b105-49fa9c1c5f8d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 881ec1f7-b15d-4f38-880a-11a0083c4d8e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6f9193ac-6ee7-44ed-bcaa-858783006367
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f67ffd10-d922-4e3e-9d14-772549412ee2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 01c70f0a-f698-4c9c-92df-d2d7fa4da2ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a00f1c60-5237-4ade-84b6-c4642772ba4f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2132c6b6-f4ad-4050-b172-b2530055513f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aedb5676-cd40-4d35-892a-04f6f208195a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 862c3139-f9ec-4512-b2b8-5fb61bb912da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 51be8011-21bf-44ae-8a62-551dec6f1473
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9090c5e4-aead-486f-87fb-d37930119317
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d1a7e2f8-6007-4800-bf93-1d9e3325c5e1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5d880de0-eb43-40c2-9b4e-80fdeff32bc9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9137b55a-5024-40f1-97c0-a11b3344f4ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0b4cfb59-8a20-4e01-aa02-4b7bb3bdc527
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 20716023-45a1-4f58-a215-2adbb2c52dde
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2f69e44b-116e-4864-91ca-ffb63c3fc2ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 77aedb2d-797f-435e-858a-9edebf308507
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 15096646-8afc-4e19-a3da-29c344449d05
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e1a852b1-f4d9-4bc0-8736-7aa0fb4c65d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2d943fb5-d841-4747-a42e-e2f80371802b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 498b8a2d-f488-4964-952d-cd12f8a7ce4b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 808734b7-bb17-45e9-b9fd-b676ca2bbfed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6252f83d-c519-49cd-97fa-f9d5d0a0e3ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 80b6a5af-73e3-4ebe-817a-107067a5c51e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 926fe65c-a545-475c-a753-86757777253e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ab1dcc37-ba05-4b5f-8ab3-6928a6aff184
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ed407d89-54bb-4fe0-8882-5ef5e5acbdf0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d671a8c6-79e1-498b-a1a9-7bc2462775ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0d2cf202-40e0-4c53-a9ac-29333156d16f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 918d7871-03f3-43a5-9e7f-3f770db2180a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b054985b-70e3-44b8-a9a9-9ae082212ee8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message af62840a-619e-41bc-b773-06ec509badbb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8a57f894-5224-4159-b1e8-1618847228a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 81858c4a-ca57-4f03-9c7e-dde3e25a9a77
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4b4b0b2b-80e7-436b-a95f-d54565620213
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 17736251-5840-4366-8bab-f5d00b195208
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2031984d-4581-4d4d-9dd1-3fe523155eb4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 85d795d2-47e0-45cd-8c2c-67c7afff275e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 62e87d8d-034e-4e4f-8c15-530e6bed6a36
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3d7f9fe0-608f-4de6-8616-cdcc8b9fcef8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message becc2b61-0e44-4ada-86e8-b3db0b4f275c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3c71464d-8105-4b72-a25a-ff5bd338c4ce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 99b8de87-778f-44c9-904e-bb4c4e6ecc43
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2e5f3c0c-5df5-4e8f-ac02-c115d4af8e2a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 44310a69-70fb-4d22-995e-1cfe345f4f59
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ff22b1d4-d6bd-471d-8076-0aaaab2c3898
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cddcf081-55a5-4b04-92e7-1d4d01217616
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3072b076-254d-4baf-97d5-742e29e17a51
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7fe8f643-8e0d-4425-8887-3b10a5ca52e1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6539e25f-0d04-4516-bca1-ac5f03939282
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 75f2d658-2b19-4c9e-a793-3b7f4cc80246
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1d3a2ec2-6c65-4088-9c16-767366917a5a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 02cd5bdb-208d-445a-9a27-957900844b67
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 870286db-e11e-495d-857e-52f7b0054999
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ad7fe12d-eb89-47ef-b71a-88e0d774ca92
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e1215510-36db-430d-a05d-cc2b2012b857
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7c193075-cccb-4e4d-a849-ec4818dbc74e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e1ed2843-8ca1-4222-8333-217ab7f5bc5d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a5ab066d-cd25-49ca-bc9d-8f7a6656cc51
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bf2c0f9c-cc70-4ed9-a252-d156e53982be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8e92dc52-d98d-4c79-8a72-fb31f9f6c155
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5ac69beb-71e9-436e-8d79-cc2e45632d09
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c537a916-d423-4933-ae01-bda31194b541
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2240bfb8-bc66-4a3c-a2b8-f59b36bf6504
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 452fce81-504b-4649-abad-97001f37e3ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 74a54fe0-7760-41cc-a43b-e4146d84a7ce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7a35ba58-1405-4d4d-b718-f99fd3053e54
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d15a15c2-d016-4982-8eca-3eb6801fbb10
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4445572d-05a9-43ca-a6d8-0dc44e8321f9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 37ef4072-36ca-47aa-914d-5ae59e6e909a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 709e7627-2c46-41ab-a0d5-8b2d5be3d4e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a23558af-54f4-41db-9e1f-017c68311a9b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6e57b7f9-706a-4e50-a9ad-9887b65cf37d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 008aad1a-740f-4cd9-8c5d-658fb043191d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ddebe07d-c578-4490-8bfc-775e7c96f305
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9b497771-ff1a-4f0c-9721-c01494acf646
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4f9e50d7-a66f-4480-9032-4eda0e1e24e5
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8687 {grpc_status:14, grpc_message:"Socket closed"}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_19
Server: localhost:8687
Algorithm: FEDAVG
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_19
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_19/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_19/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_19/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_19/test_labels.txt

📊 Raw data loaded:
   Train: X=(1076, 24), y=(1076,)
   Test:  X=(269, 24), y=(269,)

⚠️  Limiting training data: 1076 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  260 samples, 5 features
✅ Client client_19 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

============================================================
🔄 Round 1 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.2629, val=0.0910 (↓), lr=0.001000
   ✓ Epoch   2/100: train=0.0932, val=0.0822 (↓), lr=0.001000
   ✓ Epoch   3/100: train=0.0826, val=0.0804 (↓), lr=0.001000
   • Epoch   4/100: train=0.0823, val=0.0800, patience=1/15, lr=0.001000
   ✓ Epoch   5/100: train=0.0821, val=0.0799 (↓), lr=0.001000
   • Epoch  11/100: train=0.0809, val=0.0791, patience=1/15, lr=0.001000
   ✓ Epoch  21/100: train=0.0745, val=0.0719 (↓), lr=0.001000
   • Epoch  31/100: train=0.0654, val=0.0646, patience=3/15, lr=0.001000
   📉 Epoch 34: LR reduced 0.001000 → 0.000500
   • Epoch  41/100: train=0.0591, val=0.0658, patience=13/15, lr=0.000500
   📉 Epoch 42: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0633)

============================================================
📊 Round 1 Summary - Client client_19
   Epochs: 43/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0654, RMSE=0.2558, R²=0.2046
   Val:   Loss=0.0633, RMSE=0.2517, R²=0.2196
============================================================


📊 Round 1 Test Metrics:
   Loss: 0.0712, RMSE: 0.2667, MAE: 0.2302, R²: 0.0966

📊 Round 1 Test Metrics:
   Loss: 0.0707, RMSE: 0.2659, MAE: 0.2294, R²: 0.1023

📊 Round 1 Test Metrics:
   Loss: 0.0708, RMSE: 0.2660, MAE: 0.2296, R²: 0.1014

📊 Round 1 Test Metrics:
   Loss: 0.0709, RMSE: 0.2663, MAE: 0.2300, R²: 0.0996

============================================================
🔄 Round 13 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0739, val=0.0685 (↓), lr=0.000250
   ✓ Epoch   2/100: train=0.0720, val=0.0671 (↓), lr=0.000250
   ✓ Epoch   3/100: train=0.0711, val=0.0665 (↓), lr=0.000250
   ✓ Epoch   4/100: train=0.0703, val=0.0657 (↓), lr=0.000250
   ✓ Epoch   5/100: train=0.0696, val=0.0649 (↓), lr=0.000250
   📉 Epoch 7: LR reduced 0.000250 → 0.000125
   ✓ Epoch  11/100: train=0.0669, val=0.0628 (↓), lr=0.000125
   • Epoch  21/100: train=0.0652, val=0.0623, patience=5/15, lr=0.000125
   📉 Epoch 23: LR reduced 0.000125 → 0.000063
   📉 Epoch 31: LR reduced 0.000063 → 0.000031
   • Epoch  31/100: train=0.0642, val=0.0624, patience=15/15, lr=0.000031

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0623)

============================================================
📊 Round 13 Summary - Client client_19
   Epochs: 31/100 (early stopped)
   LR: 0.000250 → 0.000031 (3 reductions)
   Train: Loss=0.0656, RMSE=0.2561, R²=0.2045
   Val:   Loss=0.0623, RMSE=0.2495, R²=0.2281
============================================================


============================================================
🔄 Round 14 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000031
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0730, val=0.0714 (↓), lr=0.000031
   • Epoch   2/100: train=0.0725, val=0.0716, patience=1/15, lr=0.000031
   • Epoch   3/100: train=0.0720, val=0.0716, patience=2/15, lr=0.000031
   • Epoch   4/100: train=0.0715, val=0.0714, patience=3/15, lr=0.000031
   • Epoch   5/100: train=0.0710, val=0.0713, patience=4/15, lr=0.000031
   📉 Epoch 8: LR reduced 0.000031 → 0.000016
   • Epoch  11/100: train=0.0702, val=0.0713, patience=10/15, lr=0.000016
   📉 Epoch 16: LR reduced 0.000016 → 0.000008

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0714)

============================================================
📊 Round 14 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000031 → 0.000008 (2 reductions)
   Train: Loss=0.0729, RMSE=0.2701, R²=0.1082
   Val:   Loss=0.0714, RMSE=0.2672, R²=0.1148
============================================================


📊 Round 14 Test Metrics:
   Loss: 0.0705, RMSE: 0.2655, MAE: 0.2287, R²: 0.1052

============================================================
🔄 Round 15 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000008
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0703, val=0.0814 (↓), lr=0.000008
   • Epoch   2/100: train=0.0702, val=0.0814, patience=1/15, lr=0.000008
   • Epoch   3/100: train=0.0700, val=0.0814, patience=2/15, lr=0.000008
   • Epoch   4/100: train=0.0698, val=0.0813, patience=3/15, lr=0.000008
   • Epoch   5/100: train=0.0697, val=0.0813, patience=4/15, lr=0.000008
   📉 Epoch 8: LR reduced 0.000008 → 0.000004
   • Epoch  11/100: train=0.0689, val=0.0810, patience=10/15, lr=0.000004
   📉 Epoch 16: LR reduced 0.000004 → 0.000002
   • Epoch  21/100: train=0.0683, val=0.0807, patience=9/15, lr=0.000002
   📉 Epoch 24: LR reduced 0.000002 → 0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 15 Summary - Client client_19
   Epochs: 27/100 (early stopped)
   LR: 0.000008 → 0.000001 (3 reductions)
   Train: Loss=0.0688, RMSE=0.2622, R²=0.1397
   Val:   Loss=0.0809, RMSE=0.2845, R²=0.0970
============================================================


📊 Round 15 Test Metrics:
   Loss: 0.0702, RMSE: 0.2650, MAE: 0.2281, R²: 0.1082

============================================================
🔄 Round 17 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0723, val=0.0718 (↓), lr=0.000001
   • Epoch   2/100: train=0.0723, val=0.0717, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0723, val=0.0717, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0723, val=0.0717, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0722, val=0.0717, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0721, val=0.0717, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0718)

============================================================
📊 Round 17 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0724, RMSE=0.2690, R²=0.1260
   Val:   Loss=0.0718, RMSE=0.2679, R²=0.0925
============================================================


============================================================
🔄 Round 18 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0729, val=0.0704 (↓), lr=0.000001
   • Epoch   2/100: train=0.0729, val=0.0704, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0729, val=0.0704, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0728, val=0.0704, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0728, val=0.0704, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0727, val=0.0703, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0704)

============================================================
📊 Round 18 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0727, RMSE=0.2697, R²=0.1231
   Val:   Loss=0.0704, RMSE=0.2654, R²=0.1020
============================================================


📊 Round 18 Test Metrics:
   Loss: 0.0702, RMSE: 0.2650, MAE: 0.2281, R²: 0.1081

============================================================
🔄 Round 20 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0729, val=0.0699 (↓), lr=0.000001
   • Epoch   2/100: train=0.0729, val=0.0699, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0728, val=0.0699, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0728, val=0.0699, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0728, val=0.0699, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0727, val=0.0698, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0699)

============================================================
📊 Round 20 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0728, RMSE=0.2699, R²=0.1214
   Val:   Loss=0.0699, RMSE=0.2644, R²=0.1114
============================================================


============================================================
🔄 Round 21 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0715, val=0.0734 (↓), lr=0.000001
   • Epoch   2/100: train=0.0715, val=0.0734, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0715, val=0.0734, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0715, val=0.0734, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0714, val=0.0734, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0713, val=0.0733, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0734)

============================================================
📊 Round 21 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0716, RMSE=0.2675, R²=0.1251
   Val:   Loss=0.0734, RMSE=0.2710, R²=0.1150
============================================================


📊 Round 21 Test Metrics:
   Loss: 0.0700, RMSE: 0.2645, MAE: 0.2274, R²: 0.1117

============================================================
🔄 Round 22 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0729, val=0.0683 (↓), lr=0.000001
   • Epoch   2/100: train=0.0729, val=0.0683, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0729, val=0.0683, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0728, val=0.0683, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0728, val=0.0683, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0727, val=0.0682, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0683)

============================================================
📊 Round 22 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0728, RMSE=0.2698, R²=0.1077
   Val:   Loss=0.0683, RMSE=0.2614, R²=0.1834
============================================================


📊 Round 22 Test Metrics:
   Loss: 0.0700, RMSE: 0.2645, MAE: 0.2273, R²: 0.1118

📊 Round 22 Test Metrics:
   Loss: 0.0700, RMSE: 0.2645, MAE: 0.2274, R²: 0.1118

============================================================
🔄 Round 29 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0734, val=0.0660 (↓), lr=0.000001
   • Epoch   2/100: train=0.0733, val=0.0660, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0733, val=0.0660, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0733, val=0.0660, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0733, val=0.0659, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0731, val=0.0659, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0660)

============================================================
📊 Round 29 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0734, RMSE=0.2709, R²=0.1242
   Val:   Loss=0.0660, RMSE=0.2569, R²=0.1138
============================================================


📊 Round 29 Test Metrics:
   Loss: 0.0700, RMSE: 0.2645, MAE: 0.2273, R²: 0.1118

============================================================
🔄 Round 32 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0716, val=0.0727 (↓), lr=0.000001
   • Epoch   2/100: train=0.0715, val=0.0727, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0715, val=0.0727, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0715, val=0.0727, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0715, val=0.0727, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0713, val=0.0726, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0727)

============================================================
📊 Round 32 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0717, RMSE=0.2677, R²=0.1248
   Val:   Loss=0.0727, RMSE=0.2697, R²=0.1202
============================================================


📊 Round 32 Test Metrics:
   Loss: 0.0700, RMSE: 0.2645, MAE: 0.2274, R²: 0.1118

============================================================
🔄 Round 33 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0738, val=0.0658 (↓), lr=0.000001
   • Epoch   2/100: train=0.0737, val=0.0658, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0737, val=0.0657, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0737, val=0.0657, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0737, val=0.0657, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0735, val=0.0657, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0658)

============================================================
📊 Round 33 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0734, RMSE=0.2709, R²=0.1236
   Val:   Loss=0.0658, RMSE=0.2565, R²=0.1231
============================================================


============================================================
🔄 Round 36 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0709, val=0.0763 (↓), lr=0.000001
   • Epoch   2/100: train=0.0709, val=0.0763, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0709, val=0.0763, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0709, val=0.0763, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0708, val=0.0763, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0707, val=0.0762, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0763)

============================================================
📊 Round 36 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0708, RMSE=0.2660, R²=0.1244
   Val:   Loss=0.0763, RMSE=0.2763, R²=0.1227
============================================================


📊 Round 36 Test Metrics:
   Loss: 0.0700, RMSE: 0.2645, MAE: 0.2273, R²: 0.1118

============================================================
🔄 Round 43 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0736, val=0.0652 (↓), lr=0.000001
   • Epoch   2/100: train=0.0736, val=0.0652, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0736, val=0.0651, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0735, val=0.0651, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0735, val=0.0651, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0734, val=0.0650, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0652)

============================================================
📊 Round 43 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0735, RMSE=0.2712, R²=0.1218
   Val:   Loss=0.0652, RMSE=0.2553, R²=0.1348
============================================================


📊 Round 43 Test Metrics:
   Loss: 0.0699, RMSE: 0.2645, MAE: 0.2273, R²: 0.1119

============================================================
🔄 Round 44 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0727, val=0.0693 (↓), lr=0.000001
   • Epoch   2/100: train=0.0727, val=0.0693, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0727, val=0.0692, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0727, val=0.0692, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0727, val=0.0692, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0725, val=0.0691, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0693)

============================================================
📊 Round 44 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0725, RMSE=0.2693, R²=0.1196
   Val:   Loss=0.0693, RMSE=0.2632, R²=0.1430
============================================================


============================================================
🔄 Round 48 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0715, val=0.0725 (↓), lr=0.000001
   • Epoch   2/100: train=0.0715, val=0.0724, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0714, val=0.0724, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0714, val=0.0724, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0714, val=0.0724, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0713, val=0.0722, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0725)

============================================================
📊 Round 48 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0717, RMSE=0.2678, R²=0.1345
   Val:   Loss=0.0725, RMSE=0.2692, R²=0.0813
============================================================


============================================================
🔄 Round 51 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0704, val=0.0766 (↓), lr=0.000001
   • Epoch   2/100: train=0.0704, val=0.0766, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0704, val=0.0766, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0704, val=0.0766, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0703, val=0.0765, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0702, val=0.0764, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0766)

============================================================
📊 Round 51 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0707, RMSE=0.2658, R²=0.1207
   Val:   Loss=0.0766, RMSE=0.2768, R²=0.1207
============================================================


📊 Round 51 Test Metrics:
   Loss: 0.0699, RMSE: 0.2645, MAE: 0.2273, R²: 0.1119

📊 Round 51 Test Metrics:
   Loss: 0.0699, RMSE: 0.2645, MAE: 0.2273, R²: 0.1119

============================================================
🔄 Round 56 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0716, val=0.0729 (↓), lr=0.000001
   • Epoch   2/100: train=0.0715, val=0.0729, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0715, val=0.0729, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0715, val=0.0728, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0715, val=0.0728, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0713, val=0.0727, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0729)

============================================================
📊 Round 56 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0716, RMSE=0.2676, R²=0.1240
   Val:   Loss=0.0729, RMSE=0.2700, R²=0.1255
============================================================


============================================================
🔄 Round 57 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0720, val=0.0710 (↓), lr=0.000001
   • Epoch   2/100: train=0.0720, val=0.0710, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0720, val=0.0710, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0720, val=0.0710, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0720, val=0.0710, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0718, val=0.0709, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0710)

============================================================
📊 Round 57 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0721, RMSE=0.2684, R²=0.1268
   Val:   Loss=0.0710, RMSE=0.2665, R²=0.1028
============================================================


📊 Round 57 Test Metrics:
   Loss: 0.0699, RMSE: 0.2645, MAE: 0.2273, R²: 0.1119

📊 Round 57 Test Metrics:
   Loss: 0.0699, RMSE: 0.2645, MAE: 0.2273, R²: 0.1119

📊 Round 57 Test Metrics:
   Loss: 0.0699, RMSE: 0.2645, MAE: 0.2273, R²: 0.1119

📊 Round 57 Test Metrics:
   Loss: 0.0699, RMSE: 0.2645, MAE: 0.2273, R²: 0.1119

📊 Round 57 Test Metrics:
   Loss: 0.0699, RMSE: 0.2645, MAE: 0.2273, R²: 0.1119

📊 Round 57 Test Metrics:
   Loss: 0.0699, RMSE: 0.2645, MAE: 0.2273, R²: 0.1120

============================================================
🔄 Round 66 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0713, val=0.0732 (↓), lr=0.000001
   • Epoch   2/100: train=0.0713, val=0.0732, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0713, val=0.0732, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0712, val=0.0732, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0712, val=0.0732, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0711, val=0.0731, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0732)

============================================================
📊 Round 66 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0715, RMSE=0.2674, R²=0.1254
   Val:   Loss=0.0732, RMSE=0.2706, R²=0.1212
============================================================


📊 Round 66 Test Metrics:
   Loss: 0.0699, RMSE: 0.2645, MAE: 0.2273, R²: 0.1120

============================================================
🔄 Round 67 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0710, val=0.0754 (↓), lr=0.000001
   • Epoch   2/100: train=0.0710, val=0.0754, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0709, val=0.0754, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0709, val=0.0754, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0709, val=0.0753, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0708, val=0.0752, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0754)

============================================================
📊 Round 67 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0709, RMSE=0.2663, R²=0.1235
   Val:   Loss=0.0754, RMSE=0.2746, R²=0.1288
============================================================


============================================================
🔄 Round 68 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0698, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0698, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0698, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0698, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0697, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0696, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 68 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0698, RMSE=0.2642, R²=0.1387
   Val:   Loss=0.0799, RMSE=0.2827, R²=0.0678
============================================================


📊 Round 68 Test Metrics:
   Loss: 0.0699, RMSE: 0.2645, MAE: 0.2273, R²: 0.1120

📊 Round 68 Test Metrics:
   Loss: 0.0699, RMSE: 0.2645, MAE: 0.2273, R²: 0.1121

============================================================
🔄 Round 71 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0715, val=0.0743 (↓), lr=0.000001
   • Epoch   2/100: train=0.0714, val=0.0743, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0714, val=0.0742, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0714, val=0.0742, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0714, val=0.0742, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0713, val=0.0741, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0743)

============================================================
📊 Round 71 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0712, RMSE=0.2668, R²=0.1239
   Val:   Loss=0.0743, RMSE=0.2725, R²=0.1183
============================================================


============================================================
🔄 Round 73 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0727, val=0.0688 (↓), lr=0.000001
   • Epoch   2/100: train=0.0727, val=0.0688, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0727, val=0.0687, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0727, val=0.0687, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0727, val=0.0687, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0725, val=0.0686, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0688)

============================================================
📊 Round 73 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0726, RMSE=0.2694, R²=0.1185
   Val:   Loss=0.0688, RMSE=0.2623, R²=0.1504
============================================================


📊 Round 73 Test Metrics:
   Loss: 0.0699, RMSE: 0.2645, MAE: 0.2273, R²: 0.1121

📊 Round 73 Test Metrics:
   Loss: 0.0699, RMSE: 0.2644, MAE: 0.2273, R²: 0.1121

📊 Round 73 Test Metrics:
   Loss: 0.0699, RMSE: 0.2644, MAE: 0.2273, R²: 0.1121

============================================================
🔄 Round 76 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0726, val=0.0685 (↓), lr=0.000001
   • Epoch   2/100: train=0.0726, val=0.0685, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0726, val=0.0685, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0725, val=0.0685, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0725, val=0.0684, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0724, val=0.0683, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0685)

============================================================
📊 Round 76 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0726, RMSE=0.2695, R²=0.1267
   Val:   Loss=0.0685, RMSE=0.2617, R²=0.1173
============================================================


📊 Round 76 Test Metrics:
   Loss: 0.0699, RMSE: 0.2644, MAE: 0.2273, R²: 0.1122

============================================================
🔄 Round 79 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0739, val=0.0640 (↓), lr=0.000001
   • Epoch   2/100: train=0.0739, val=0.0640, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0738, val=0.0639, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0738, val=0.0639, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0738, val=0.0639, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0737, val=0.0638, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0640)

============================================================
📊 Round 79 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0738, RMSE=0.2716, R²=0.1211
   Val:   Loss=0.0640, RMSE=0.2530, R²=0.1283
============================================================


📊 Round 79 Test Metrics:
   Loss: 0.0699, RMSE: 0.2644, MAE: 0.2273, R²: 0.1122

📊 Round 79 Test Metrics:
   Loss: 0.0699, RMSE: 0.2644, MAE: 0.2273, R²: 0.1122

============================================================
🔄 Round 81 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0742, val=0.0614 (↓), lr=0.000001
   • Epoch   2/100: train=0.0742, val=0.0614, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0741, val=0.0614, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0741, val=0.0614, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0741, val=0.0614, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0740, val=0.0612, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0614)

============================================================
📊 Round 81 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0744, RMSE=0.2727, R²=0.1273
   Val:   Loss=0.0614, RMSE=0.2479, R²=0.1139
============================================================


============================================================
🔄 Round 83 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0714, val=0.0741 (↓), lr=0.000001
   • Epoch   2/100: train=0.0714, val=0.0741, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0714, val=0.0741, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0714, val=0.0741, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0713, val=0.0740, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0712, val=0.0740, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0741)

============================================================
📊 Round 83 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0712, RMSE=0.2669, R²=0.1150
   Val:   Loss=0.0741, RMSE=0.2722, R²=0.1555
============================================================


📊 Round 83 Test Metrics:
   Loss: 0.0699, RMSE: 0.2644, MAE: 0.2273, R²: 0.1121

📊 Round 83 Test Metrics:
   Loss: 0.0699, RMSE: 0.2644, MAE: 0.2273, R²: 0.1121

📊 Round 83 Test Metrics:
   Loss: 0.0699, RMSE: 0.2644, MAE: 0.2273, R²: 0.1121

============================================================
🔄 Round 86 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0728, val=0.0679 (↓), lr=0.000001
   • Epoch   2/100: train=0.0728, val=0.0679, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0728, val=0.0678, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0728, val=0.0678, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0727, val=0.0678, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0726, val=0.0676, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0679)

============================================================
📊 Round 86 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0728, RMSE=0.2698, R²=0.1177
   Val:   Loss=0.0679, RMSE=0.2605, R²=0.1542
============================================================


============================================================
🔄 Round 87 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0720, val=0.0702 (↓), lr=0.000001
   • Epoch   2/100: train=0.0720, val=0.0702, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0720, val=0.0701, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0720, val=0.0701, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0719, val=0.0701, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0718, val=0.0700, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0702)

============================================================
📊 Round 87 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0722, RMSE=0.2687, R²=0.1248
   Val:   Loss=0.0702, RMSE=0.2649, R²=0.1245
============================================================


📊 Round 87 Test Metrics:
   Loss: 0.0699, RMSE: 0.2644, MAE: 0.2273, R²: 0.1121

============================================================
🔄 Round 89 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0730, val=0.0661 (↓), lr=0.000001
   • Epoch   2/100: train=0.0730, val=0.0661, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0729, val=0.0661, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0729, val=0.0661, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0729, val=0.0661, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0728, val=0.0660, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0661)

============================================================
📊 Round 89 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0732, RMSE=0.2706, R²=0.1330
   Val:   Loss=0.0661, RMSE=0.2572, R²=0.0836
============================================================


📊 Round 89 Test Metrics:
   Loss: 0.0699, RMSE: 0.2644, MAE: 0.2273, R²: 0.1122

============================================================
🔄 Round 90 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0723, val=0.0700 (↓), lr=0.000001
   • Epoch   2/100: train=0.0723, val=0.0700, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0723, val=0.0699, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0722, val=0.0699, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0722, val=0.0699, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0721, val=0.0699, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0700)

============================================================
📊 Round 90 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0723, RMSE=0.2688, R²=0.1190
   Val:   Loss=0.0700, RMSE=0.2645, R²=0.1426
============================================================


============================================================
🔄 Round 91 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0711, val=0.0746 (↓), lr=0.000001
   • Epoch   2/100: train=0.0711, val=0.0746, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0711, val=0.0746, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0711, val=0.0746, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0711, val=0.0745, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0709, val=0.0744, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0746)

============================================================
📊 Round 91 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0711, RMSE=0.2666, R²=0.1308
   Val:   Loss=0.0746, RMSE=0.2732, R²=0.1017
============================================================


📊 Round 91 Test Metrics:
   Loss: 0.0699, RMSE: 0.2644, MAE: 0.2273, R²: 0.1122

============================================================
🔄 Round 92 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0721, val=0.0709 (↓), lr=0.000001
   • Epoch   2/100: train=0.0720, val=0.0709, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0720, val=0.0709, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0720, val=0.0709, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0719, val=0.0709, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0718, val=0.0709, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0709)

============================================================
📊 Round 92 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0720, RMSE=0.2683, R²=0.1301
   Val:   Loss=0.0709, RMSE=0.2663, R²=0.0960
============================================================


============================================================
🔄 Round 93 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0710, val=0.0756 (↓), lr=0.000001
   • Epoch   2/100: train=0.0710, val=0.0756, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0710, val=0.0755, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0710, val=0.0755, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0709, val=0.0755, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0708, val=0.0754, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0756)

============================================================
📊 Round 93 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0708, RMSE=0.2661, R²=0.1295
   Val:   Loss=0.0756, RMSE=0.2749, R²=0.1042
============================================================


============================================================
🔄 Round 95 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0724, val=0.0689 (↓), lr=0.000001
   • Epoch   2/100: train=0.0724, val=0.0689, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0723, val=0.0689, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0723, val=0.0688, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0723, val=0.0688, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0722, val=0.0687, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0689)

============================================================
📊 Round 95 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0725, RMSE=0.2693, R²=0.1231
   Val:   Loss=0.0689, RMSE=0.2625, R²=0.1317
============================================================


📊 Round 95 Test Metrics:
   Loss: 0.0699, RMSE: 0.2644, MAE: 0.2273, R²: 0.1122

============================================================
🔄 Round 97 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0728, val=0.0680 (↓), lr=0.000001
   • Epoch   2/100: train=0.0728, val=0.0680, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0727, val=0.0680, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0727, val=0.0680, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0727, val=0.0679, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0726, val=0.0678, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0680)

============================================================
📊 Round 97 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0727, RMSE=0.2697, R²=0.1289
   Val:   Loss=0.0680, RMSE=0.2608, R²=0.1083
============================================================


📊 Round 97 Test Metrics:
   Loss: 0.0699, RMSE: 0.2644, MAE: 0.2273, R²: 0.1123

============================================================
🔄 Round 99 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0714, val=0.0729 (↓), lr=0.000001
   • Epoch   2/100: train=0.0714, val=0.0729, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0714, val=0.0729, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0714, val=0.0729, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0714, val=0.0728, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0712, val=0.0727, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0729)

============================================================
📊 Round 99 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0715, RMSE=0.2674, R²=0.1365
   Val:   Loss=0.0729, RMSE=0.2700, R²=0.0758
============================================================


============================================================
🔄 Round 100 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0731, val=0.0668 (↓), lr=0.000001
   • Epoch   2/100: train=0.0730, val=0.0668, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0730, val=0.0668, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0730, val=0.0668, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0729, val=0.0668, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0728, val=0.0667, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0668)

============================================================
📊 Round 100 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0730, RMSE=0.2702, R²=0.1299
   Val:   Loss=0.0668, RMSE=0.2585, R²=0.0961
============================================================


📊 Round 100 Test Metrics:
   Loss: 0.0699, RMSE: 0.2644, MAE: 0.2273, R²: 0.1123

============================================================
🔄 Round 103 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0710, val=0.0757 (↓), lr=0.000001
   • Epoch   2/100: train=0.0710, val=0.0756, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0710, val=0.0756, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0710, val=0.0756, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0710, val=0.0756, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0709, val=0.0755, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0757)

============================================================
📊 Round 103 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0708, RMSE=0.2661, R²=0.1320
   Val:   Loss=0.0757, RMSE=0.2750, R²=0.0854
============================================================


📊 Round 103 Test Metrics:
   Loss: 0.0699, RMSE: 0.2644, MAE: 0.2273, R²: 0.1123

============================================================
🔄 Round 104 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0720, val=0.0711 (↓), lr=0.000001
   • Epoch   2/100: train=0.0720, val=0.0711, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0720, val=0.0711, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0719, val=0.0711, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0719, val=0.0710, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0717, val=0.0710, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0711)

============================================================
📊 Round 104 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0719, RMSE=0.2682, R²=0.1303
   Val:   Loss=0.0711, RMSE=0.2666, R²=0.0972
============================================================


============================================================
🔄 Round 105 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0720, val=0.0704 (↓), lr=0.000001
   • Epoch   2/100: train=0.0720, val=0.0704, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0720, val=0.0704, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0720, val=0.0704, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0720, val=0.0703, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0718, val=0.0702, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0704)

============================================================
📊 Round 105 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0721, RMSE=0.2685, R²=0.1330
   Val:   Loss=0.0704, RMSE=0.2654, R²=0.0902
============================================================


📊 Round 105 Test Metrics:
   Loss: 0.0699, RMSE: 0.2644, MAE: 0.2272, R²: 0.1124

============================================================
🔄 Round 106 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0716, val=0.0725 (↓), lr=0.000001
   • Epoch   2/100: train=0.0716, val=0.0725, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0716, val=0.0725, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0716, val=0.0724, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0716, val=0.0724, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0715, val=0.0723, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0725)

============================================================
📊 Round 106 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0716, RMSE=0.2675, R²=0.1158
   Val:   Loss=0.0725, RMSE=0.2693, R²=0.1396
============================================================


📊 Round 106 Test Metrics:
   Loss: 0.0699, RMSE: 0.2644, MAE: 0.2272, R²: 0.1124

============================================================
🔄 Round 109 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0739, val=0.0633 (↓), lr=0.000001
   • Epoch   2/100: train=0.0739, val=0.0633, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0739, val=0.0633, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0738, val=0.0633, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0738, val=0.0633, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0736, val=0.0632, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0633)

============================================================
📊 Round 109 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0739, RMSE=0.2718, R²=0.1217
   Val:   Loss=0.0633, RMSE=0.2517, R²=0.1411
============================================================


============================================================
🔄 Round 112 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0720, val=0.0713 (↓), lr=0.000001
   • Epoch   2/100: train=0.0719, val=0.0713, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0719, val=0.0713, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0719, val=0.0713, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0718, val=0.0713, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0717, val=0.0713, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0713)

============================================================
📊 Round 112 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0719, RMSE=0.2681, R²=0.1307
   Val:   Loss=0.0713, RMSE=0.2669, R²=0.0903
============================================================


📊 Round 112 Test Metrics:
   Loss: 0.0699, RMSE: 0.2644, MAE: 0.2272, R²: 0.1124

============================================================
🔄 Round 113 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0719, val=0.0708 (↓), lr=0.000001
   • Epoch   2/100: train=0.0718, val=0.0708, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0718, val=0.0708, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0718, val=0.0708, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0718, val=0.0708, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0717, val=0.0706, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0708)

============================================================
📊 Round 113 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0720, RMSE=0.2683, R²=0.1264
   Val:   Loss=0.0708, RMSE=0.2662, R²=0.1228
============================================================


📊 Round 113 Test Metrics:
   Loss: 0.0699, RMSE: 0.2644, MAE: 0.2272, R²: 0.1125

============================================================
🔄 Round 114 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0721, val=0.0712 (↓), lr=0.000001
   • Epoch   2/100: train=0.0720, val=0.0711, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0720, val=0.0711, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0720, val=0.0711, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0720, val=0.0711, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0719, val=0.0709, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0712)

============================================================
📊 Round 114 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0719, RMSE=0.2681, R²=0.1155
   Val:   Loss=0.0712, RMSE=0.2668, R²=0.1444
============================================================


📊 Round 114 Test Metrics:
   Loss: 0.0699, RMSE: 0.2644, MAE: 0.2272, R²: 0.1125

============================================================
🔄 Round 115 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0712, val=0.0732 (↓), lr=0.000001
   • Epoch   2/100: train=0.0712, val=0.0731, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0712, val=0.0731, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0712, val=0.0731, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0712, val=0.0731, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0710, val=0.0730, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0732)

============================================================
📊 Round 115 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0714, RMSE=0.2672, R²=0.1245
   Val:   Loss=0.0732, RMSE=0.2705, R²=0.1287
============================================================


📊 Round 115 Test Metrics:
   Loss: 0.0699, RMSE: 0.2644, MAE: 0.2272, R²: 0.1125

============================================================
🔄 Round 117 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0722, val=0.0693 (↓), lr=0.000001
   • Epoch   2/100: train=0.0721, val=0.0693, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0721, val=0.0693, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0721, val=0.0693, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0721, val=0.0693, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0719, val=0.0692, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0693)

============================================================
📊 Round 117 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0723, RMSE=0.2689, R²=0.1296
   Val:   Loss=0.0693, RMSE=0.2633, R²=0.1049
============================================================


============================================================
🔄 Round 118 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0693, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0693, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0692, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0692, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0692, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0690, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 118 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0693, RMSE=0.2632, R²=0.1325
   Val:   Loss=0.0815, RMSE=0.2854, R²=0.0992
============================================================


============================================================
🔄 Round 119 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0720, val=0.0709 (↓), lr=0.000001
   • Epoch   2/100: train=0.0720, val=0.0709, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0720, val=0.0709, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0719, val=0.0709, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0719, val=0.0709, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0717, val=0.0709, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0709)

============================================================
📊 Round 119 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0719, RMSE=0.2682, R²=0.1330
   Val:   Loss=0.0709, RMSE=0.2664, R²=0.0900
============================================================


📊 Round 119 Test Metrics:
   Loss: 0.0699, RMSE: 0.2644, MAE: 0.2272, R²: 0.1126

============================================================
🔄 Round 122 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0703, val=0.0770 (↓), lr=0.000001
   • Epoch   2/100: train=0.0703, val=0.0769, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0703, val=0.0769, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0702, val=0.0769, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0702, val=0.0769, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0701, val=0.0768, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0770)

============================================================
📊 Round 122 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0704, RMSE=0.2654, R²=0.1231
   Val:   Loss=0.0770, RMSE=0.2774, R²=0.1305
============================================================


📊 Round 122 Test Metrics:
   Loss: 0.0699, RMSE: 0.2644, MAE: 0.2272, R²: 0.1126

============================================================
🔄 Round 125 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0727, val=0.0680 (↓), lr=0.000001
   • Epoch   2/100: train=0.0727, val=0.0679, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0727, val=0.0679, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0726, val=0.0679, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0726, val=0.0679, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0725, val=0.0678, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0680)

============================================================
📊 Round 125 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0727, RMSE=0.2696, R²=0.1184
   Val:   Loss=0.0680, RMSE=0.2607, R²=0.1558
============================================================


============================================================
🔄 Round 126 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0701, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0701, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0700, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0700, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0700, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0698, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 126 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0700, RMSE=0.2645, R²=0.1277
   Val:   Loss=0.0787, RMSE=0.2806, R²=0.1116
============================================================


📊 Round 126 Test Metrics:
   Loss: 0.0699, RMSE: 0.2644, MAE: 0.2272, R²: 0.1126

============================================================
🔄 Round 128 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0698, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0698, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0698, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0698, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0698, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0696, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 128 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0699, RMSE=0.2643, R²=0.1262
   Val:   Loss=0.0792, RMSE=0.2814, R²=0.1252
============================================================


📊 Round 128 Test Metrics:
   Loss: 0.0699, RMSE: 0.2644, MAE: 0.2272, R²: 0.1126

============================================================
🔄 Round 129 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0707, val=0.0754 (↓), lr=0.000001
   • Epoch   2/100: train=0.0706, val=0.0754, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0706, val=0.0754, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0706, val=0.0754, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0706, val=0.0754, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0704, val=0.0752, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0754)

============================================================
📊 Round 129 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0708, RMSE=0.2661, R²=0.1308
   Val:   Loss=0.0754, RMSE=0.2747, R²=0.1078
============================================================


============================================================
🔄 Round 130 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0713, val=0.0730 (↓), lr=0.000001
   • Epoch   2/100: train=0.0713, val=0.0730, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0713, val=0.0730, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0712, val=0.0730, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0712, val=0.0730, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0711, val=0.0729, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0730)

============================================================
📊 Round 130 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0714, RMSE=0.2672, R²=0.1272
   Val:   Loss=0.0730, RMSE=0.2703, R²=0.1169
============================================================


============================================================
🔄 Round 132 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0718, val=0.0709 (↓), lr=0.000001
   • Epoch   2/100: train=0.0718, val=0.0709, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0718, val=0.0709, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0717, val=0.0708, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0717, val=0.0708, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0716, val=0.0707, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0709)

============================================================
📊 Round 132 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0719, RMSE=0.2682, R²=0.1293
   Val:   Loss=0.0709, RMSE=0.2663, R²=0.1110
============================================================


============================================================
🔄 Round 134 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0725, val=0.0681 (↓), lr=0.000001
   • Epoch   2/100: train=0.0724, val=0.0681, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0724, val=0.0681, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0724, val=0.0681, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0723, val=0.0681, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0722, val=0.0681, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0681)

============================================================
📊 Round 134 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0726, RMSE=0.2695, R²=0.1181
   Val:   Loss=0.0681, RMSE=0.2610, R²=0.1326
============================================================


📊 Round 134 Test Metrics:
   Loss: 0.0699, RMSE: 0.2644, MAE: 0.2272, R²: 0.1126

📊 Round 134 Test Metrics:
   Loss: 0.0699, RMSE: 0.2644, MAE: 0.2272, R²: 0.1126

📊 Round 134 Test Metrics:
   Loss: 0.0699, RMSE: 0.2644, MAE: 0.2272, R²: 0.1126

============================================================
🔄 Round 138 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0712, val=0.0742 (↓), lr=0.000001
   • Epoch   2/100: train=0.0712, val=0.0742, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0712, val=0.0742, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0712, val=0.0742, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0711, val=0.0742, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0710, val=0.0740, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0742)

============================================================
📊 Round 138 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0711, RMSE=0.2666, R²=0.1154
   Val:   Loss=0.0742, RMSE=0.2725, R²=0.1627
============================================================


============================================================
🔄 Round 139 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0716, val=0.0726 (↓), lr=0.000001
   • Epoch   2/100: train=0.0715, val=0.0726, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0715, val=0.0726, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0715, val=0.0726, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0715, val=0.0726, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0713, val=0.0725, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0726)

============================================================
📊 Round 139 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0715, RMSE=0.2674, R²=0.1179
   Val:   Loss=0.0726, RMSE=0.2695, R²=0.1557
============================================================


📊 Round 139 Test Metrics:
   Loss: 0.0699, RMSE: 0.2644, MAE: 0.2272, R²: 0.1127

============================================================
🔄 Round 140 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0712, val=0.0732 (↓), lr=0.000001
   • Epoch   2/100: train=0.0711, val=0.0732, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0711, val=0.0732, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0711, val=0.0731, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0711, val=0.0731, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0709, val=0.0730, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0732)

============================================================
📊 Round 140 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0713, RMSE=0.2671, R²=0.1260
   Val:   Loss=0.0732, RMSE=0.2705, R²=0.1257
============================================================


📊 Round 140 Test Metrics:
   Loss: 0.0699, RMSE: 0.2644, MAE: 0.2272, R²: 0.1127

============================================================
🔄 Round 147 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0720, val=0.0701 (↓), lr=0.000001
   • Epoch   2/100: train=0.0720, val=0.0701, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0720, val=0.0701, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0719, val=0.0701, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0719, val=0.0701, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0717, val=0.0700, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0701)

============================================================
📊 Round 147 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0721, RMSE=0.2685, R²=0.1349
   Val:   Loss=0.0701, RMSE=0.2648, R²=0.0823
============================================================


📊 Round 147 Test Metrics:
   Loss: 0.0699, RMSE: 0.2643, MAE: 0.2272, R²: 0.1128

📊 Round 147 Test Metrics:
   Loss: 0.0699, RMSE: 0.2643, MAE: 0.2272, R²: 0.1128

============================================================
🔄 Round 150 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0719, val=0.0705 (↓), lr=0.000001
   • Epoch   2/100: train=0.0719, val=0.0704, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0719, val=0.0704, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0718, val=0.0704, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0718, val=0.0704, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0716, val=0.0703, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0705)

============================================================
📊 Round 150 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0720, RMSE=0.2683, R²=0.1205
   Val:   Loss=0.0705, RMSE=0.2654, R²=0.1398
============================================================


📊 Round 150 Test Metrics:
   Loss: 0.0699, RMSE: 0.2643, MAE: 0.2272, R²: 0.1128

📊 Round 150 Test Metrics:
   Loss: 0.0699, RMSE: 0.2643, MAE: 0.2272, R²: 0.1128

📊 Round 150 Test Metrics:
   Loss: 0.0699, RMSE: 0.2643, MAE: 0.2272, R²: 0.1128

📊 Round 150 Test Metrics:
   Loss: 0.0699, RMSE: 0.2643, MAE: 0.2272, R²: 0.1129

📊 Round 150 Test Metrics:
   Loss: 0.0699, RMSE: 0.2643, MAE: 0.2272, R²: 0.1129

📊 Round 150 Test Metrics:
   Loss: 0.0699, RMSE: 0.2643, MAE: 0.2272, R²: 0.1129

============================================================
🔄 Round 162 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0734, val=0.0649 (↓), lr=0.000001
   • Epoch   2/100: train=0.0734, val=0.0649, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0734, val=0.0648, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0734, val=0.0648, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0733, val=0.0648, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0732, val=0.0648, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0649)

============================================================
📊 Round 162 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0734, RMSE=0.2709, R²=0.1371
   Val:   Loss=0.0649, RMSE=0.2547, R²=0.0569
============================================================


📊 Round 162 Test Metrics:
   Loss: 0.0699, RMSE: 0.2643, MAE: 0.2272, R²: 0.1129

📊 Round 162 Test Metrics:
   Loss: 0.0699, RMSE: 0.2643, MAE: 0.2272, R²: 0.1129

============================================================
🔄 Round 165 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0702, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0701, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0701, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0701, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0700, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0698, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 165 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0702, RMSE=0.2650, R²=0.1316
   Val:   Loss=0.0775, RMSE=0.2783, R²=0.0704
============================================================


📊 Round 165 Test Metrics:
   Loss: 0.0699, RMSE: 0.2643, MAE: 0.2272, R²: 0.1129

============================================================
🔄 Round 167 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0723, val=0.0690 (↓), lr=0.000001
   • Epoch   2/100: train=0.0723, val=0.0689, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0722, val=0.0689, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0722, val=0.0689, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0722, val=0.0689, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0720, val=0.0688, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0690)

============================================================
📊 Round 167 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0724, RMSE=0.2690, R²=0.1300
   Val:   Loss=0.0690, RMSE=0.2626, R²=0.1105
============================================================


============================================================
🔄 Round 171 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0706, val=0.0757 (↓), lr=0.000001
   • Epoch   2/100: train=0.0706, val=0.0757, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0706, val=0.0757, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0706, val=0.0757, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0706, val=0.0756, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0705, val=0.0755, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0757)

============================================================
📊 Round 171 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0707, RMSE=0.2658, R²=0.1229
   Val:   Loss=0.0757, RMSE=0.2752, R²=0.1291
============================================================


📊 Round 171 Test Metrics:
   Loss: 0.0699, RMSE: 0.2643, MAE: 0.2272, R²: 0.1130

============================================================
🔄 Round 173 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0729, val=0.0664 (↓), lr=0.000001
   • Epoch   2/100: train=0.0729, val=0.0664, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0729, val=0.0664, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0728, val=0.0664, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0728, val=0.0663, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0727, val=0.0662, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0664)

============================================================
📊 Round 173 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0730, RMSE=0.2701, R²=0.1273
   Val:   Loss=0.0664, RMSE=0.2578, R²=0.1228
============================================================


📊 Round 173 Test Metrics:
   Loss: 0.0699, RMSE: 0.2643, MAE: 0.2272, R²: 0.1130

📊 Round 173 Test Metrics:
   Loss: 0.0699, RMSE: 0.2643, MAE: 0.2272, R²: 0.1130

============================================================
🔄 Round 175 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0715, val=0.0724 (↓), lr=0.000001
   • Epoch   2/100: train=0.0715, val=0.0724, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0714, val=0.0723, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0714, val=0.0723, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0714, val=0.0723, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0713, val=0.0722, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0724)

============================================================
📊 Round 175 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0715, RMSE=0.2674, R²=0.1371
   Val:   Loss=0.0724, RMSE=0.2690, R²=0.0788
============================================================


============================================================
🔄 Round 180 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0718, val=0.0704 (↓), lr=0.000001
   • Epoch   2/100: train=0.0718, val=0.0703, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0718, val=0.0703, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0717, val=0.0703, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0717, val=0.0703, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0716, val=0.0701, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0704)

============================================================
📊 Round 180 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0720, RMSE=0.2683, R²=0.1251
   Val:   Loss=0.0704, RMSE=0.2653, R²=0.1311
============================================================


📊 Round 180 Test Metrics:
   Loss: 0.0699, RMSE: 0.2643, MAE: 0.2272, R²: 0.1131

============================================================
🔄 Round 182 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0695, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0695, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0694, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0694, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0694, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0693, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 182 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0697, RMSE=0.2639, R²=0.1231
   Val:   Loss=0.0797, RMSE=0.2823, R²=0.1359
============================================================


============================================================
🔄 Round 183 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0710, val=0.0740 (↓), lr=0.000001
   • Epoch   2/100: train=0.0710, val=0.0739, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0709, val=0.0739, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0709, val=0.0739, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0709, val=0.0739, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0707, val=0.0737, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0740)

============================================================
📊 Round 183 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0711, RMSE=0.2666, R²=0.1392
   Val:   Loss=0.0740, RMSE=0.2720, R²=0.0742
============================================================


📊 Round 183 Test Metrics:
   Loss: 0.0699, RMSE: 0.2643, MAE: 0.2272, R²: 0.1131

============================================================
🔄 Round 187 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0746, val=0.0604 (↓), lr=0.000001
   • Epoch   2/100: train=0.0746, val=0.0603, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0745, val=0.0603, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0745, val=0.0603, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0745, val=0.0603, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0743, val=0.0601, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0604)

============================================================
📊 Round 187 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0745, RMSE=0.2729, R²=0.1132
   Val:   Loss=0.0604, RMSE=0.2457, R²=0.1866
============================================================


============================================================
🔄 Round 193 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0719, val=0.0711 (↓), lr=0.000001
   • Epoch   2/100: train=0.0718, val=0.0710, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0718, val=0.0710, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0718, val=0.0710, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0718, val=0.0710, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0716, val=0.0709, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0711)

============================================================
📊 Round 193 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0718, RMSE=0.2680, R²=0.1378
   Val:   Loss=0.0711, RMSE=0.2666, R²=0.0779
============================================================


============================================================
🔄 Round 194 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0705, val=0.0763 (↓), lr=0.000001
   • Epoch   2/100: train=0.0705, val=0.0763, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0705, val=0.0762, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0705, val=0.0762, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0705, val=0.0762, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0703, val=0.0760, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0763)

============================================================
📊 Round 194 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0705, RMSE=0.2655, R²=0.1196
   Val:   Loss=0.0763, RMSE=0.2762, R²=0.1414
============================================================


============================================================
🔄 Round 195 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0728, val=0.0672 (↓), lr=0.000001
   • Epoch   2/100: train=0.0727, val=0.0672, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0727, val=0.0672, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0727, val=0.0672, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0727, val=0.0671, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0725, val=0.0670, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0672)

============================================================
📊 Round 195 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0728, RMSE=0.2698, R²=0.1149
   Val:   Loss=0.0672, RMSE=0.2592, R²=0.1736
============================================================


============================================================
🔄 Round 199 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0710, val=0.0746 (↓), lr=0.000001
   • Epoch   2/100: train=0.0709, val=0.0745, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0709, val=0.0745, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0709, val=0.0745, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0709, val=0.0745, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0707, val=0.0743, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0746)

============================================================
📊 Round 199 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0709, RMSE=0.2663, R²=0.1099
   Val:   Loss=0.0746, RMSE=0.2731, R²=0.1744
============================================================


============================================================
🔄 Round 202 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0706, val=0.0757 (↓), lr=0.000001
   • Epoch   2/100: train=0.0706, val=0.0756, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0706, val=0.0756, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0705, val=0.0756, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0705, val=0.0756, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0703, val=0.0755, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0757)

============================================================
📊 Round 202 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0706, RMSE=0.2658, R²=0.1180
   Val:   Loss=0.0757, RMSE=0.2751, R²=0.1576
============================================================


📊 Round 202 Test Metrics:
   Loss: 0.0698, RMSE: 0.2643, MAE: 0.2271, R²: 0.1132

============================================================
🔄 Round 203 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0696, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0696, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0695, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0695, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0695, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0693, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 203 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0695, RMSE=0.2636, R²=0.1257
   Val:   Loss=0.0803, RMSE=0.2835, R²=0.1281
============================================================


📊 Round 203 Test Metrics:
   Loss: 0.0698, RMSE: 0.2643, MAE: 0.2271, R²: 0.1132

📊 Round 203 Test Metrics:
   Loss: 0.0698, RMSE: 0.2643, MAE: 0.2272, R²: 0.1132

============================================================
🔄 Round 206 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0716, val=0.0717 (↓), lr=0.000001
   • Epoch   2/100: train=0.0715, val=0.0717, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0715, val=0.0717, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0715, val=0.0717, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0715, val=0.0716, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0713, val=0.0715, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0717)

============================================================
📊 Round 206 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0716, RMSE=0.2676, R²=0.1325
   Val:   Loss=0.0717, RMSE=0.2678, R²=0.0750
============================================================


📊 Round 206 Test Metrics:
   Loss: 0.0698, RMSE: 0.2643, MAE: 0.2271, R²: 0.1132

📊 Round 206 Test Metrics:
   Loss: 0.0698, RMSE: 0.2643, MAE: 0.2271, R²: 0.1133

============================================================
🔄 Round 209 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0724, val=0.0685 (↓), lr=0.000001
   • Epoch   2/100: train=0.0724, val=0.0685, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0723, val=0.0685, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0723, val=0.0685, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0723, val=0.0685, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0721, val=0.0684, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0685)

============================================================
📊 Round 209 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0724, RMSE=0.2691, R²=0.1212
   Val:   Loss=0.0685, RMSE=0.2618, R²=0.1494
============================================================


📊 Round 209 Test Metrics:
   Loss: 0.0698, RMSE: 0.2643, MAE: 0.2271, R²: 0.1133

📊 Round 209 Test Metrics:
   Loss: 0.0698, RMSE: 0.2643, MAE: 0.2271, R²: 0.1133

============================================================
🔄 Round 212 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0720, val=0.0697 (↓), lr=0.000001
   • Epoch   2/100: train=0.0720, val=0.0697, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0719, val=0.0697, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0719, val=0.0696, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0719, val=0.0696, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0718, val=0.0694, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0697)

============================================================
📊 Round 212 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0721, RMSE=0.2685, R²=0.1207
   Val:   Loss=0.0697, RMSE=0.2640, R²=0.1505
============================================================


📊 Round 212 Test Metrics:
   Loss: 0.0698, RMSE: 0.2643, MAE: 0.2271, R²: 0.1133

============================================================
🔄 Round 214 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0708, val=0.0744 (↓), lr=0.000001
   • Epoch   2/100: train=0.0708, val=0.0744, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0708, val=0.0744, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0708, val=0.0744, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0707, val=0.0743, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0706, val=0.0742, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0744)

============================================================
📊 Round 214 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0709, RMSE=0.2663, R²=0.1296
   Val:   Loss=0.0744, RMSE=0.2728, R²=0.1153
============================================================


============================================================
🔄 Round 216 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0727, val=0.0671 (↓), lr=0.000001
   • Epoch   2/100: train=0.0727, val=0.0670, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0726, val=0.0670, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0726, val=0.0670, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0726, val=0.0670, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0724, val=0.0669, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0671)

============================================================
📊 Round 216 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0728, RMSE=0.2697, R²=0.1363
   Val:   Loss=0.0671, RMSE=0.2590, R²=0.0746
============================================================


📊 Round 216 Test Metrics:
   Loss: 0.0698, RMSE: 0.2643, MAE: 0.2271, R²: 0.1133

============================================================
🔄 Round 218 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0717, val=0.0707 (↓), lr=0.000001
   • Epoch   2/100: train=0.0717, val=0.0707, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0716, val=0.0707, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0716, val=0.0707, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0716, val=0.0706, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0715, val=0.0705, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0707)

============================================================
📊 Round 218 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0719, RMSE=0.2681, R²=0.1274
   Val:   Loss=0.0707, RMSE=0.2660, R²=0.1231
============================================================


📊 Round 218 Test Metrics:
   Loss: 0.0698, RMSE: 0.2643, MAE: 0.2271, R²: 0.1134

📊 Round 218 Test Metrics:
   Loss: 0.0698, RMSE: 0.2643, MAE: 0.2271, R²: 0.1134

============================================================
🔄 Round 220 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0721, val=0.0697 (↓), lr=0.000001
   • Epoch   2/100: train=0.0721, val=0.0697, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0721, val=0.0697, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0720, val=0.0697, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0720, val=0.0697, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0718, val=0.0696, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0697)

============================================================
📊 Round 220 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0721, RMSE=0.2685, R²=0.1184
   Val:   Loss=0.0697, RMSE=0.2641, R²=0.1569
============================================================


📊 Round 220 Test Metrics:
   Loss: 0.0698, RMSE: 0.2643, MAE: 0.2271, R²: 0.1134

📊 Round 220 Test Metrics:
   Loss: 0.0698, RMSE: 0.2642, MAE: 0.2271, R²: 0.1134

============================================================
🔄 Round 223 - Client client_19
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0713, val=0.0725 (↓), lr=0.000001
   • Epoch   2/100: train=0.0713, val=0.0725, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0712, val=0.0724, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0712, val=0.0724, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0712, val=0.0724, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0710, val=0.0722, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0725)

============================================================
📊 Round 223 Summary - Client client_19
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0714, RMSE=0.2672, R²=0.1306
   Val:   Loss=0.0725, RMSE=0.2692, R²=0.1114
============================================================


❌ Client client_19 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8687 {grpc_status:14, grpc_message:"Socket closed"}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8687 {grpc_status:14, grpc_message:"Socket closed"}"
>
