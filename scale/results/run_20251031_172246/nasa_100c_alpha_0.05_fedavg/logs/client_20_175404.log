[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 866c22fc-cf05-46b4-bc30-3ae89c25f163
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f54dbccb-9728-4033-b9b1-ec2d386e5114
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 15535a56-87c1-4ec2-8fdd-b393d107a0c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f2030724-d443-4697-97a6-a61947e7011e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2e79576d-ce99-480d-bb91-2dacbc55f274
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message da13238d-d4ab-42c1-aeab-4ab997f21853
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8b7c13a3-25c8-468d-b35f-8054262b839e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 09a6f07d-54d3-4da8-af87-8601e6c8a6f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 619c89d7-4e49-4665-a1b7-9432b11107cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cf1fc54d-762a-4be4-a7ee-916411178ddc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 173a9b8a-aae9-46a0-9871-aa54a7c6acd1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 78e8279a-7040-4fab-bcd3-b6350c798a93
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2898e0ae-13d3-4c23-a1b8-7aa4a96e6e0c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 22a3757f-f62d-40da-a59e-6d1a88810da8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message be57d676-6251-484d-b2a9-305353c32538
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 036bdd5e-6c16-4a2b-af3a-99d0af835ee7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7c519983-f206-4a6d-ae49-1701618dc282
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1d8447fc-a8d0-4de6-9c44-5ae32aea6d5a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 76cef735-21a1-4def-81a3-d44e6fd0ccc0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 413d274c-ab08-46e7-b550-b26992b57d56
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 38c23475-62f7-4896-b039-f25e58e97ed6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a4221d05-5021-4825-ab5a-e910eb5eec30
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f5ebb767-9057-48ce-981d-b54f4e9988e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 77eb62fa-a89d-4a47-b558-436c1669beee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7aaac1e3-3212-44e8-bae6-eacad870f6d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 37279444-c8da-4807-a8c3-26162c9043ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d259237b-c47b-489f-bb67-134bc2fff8b5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bb371b42-c89b-42b7-8769-f01b5c91a9bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 537777ad-6795-48f9-8fe5-883698cf331a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 930b7084-1413-4961-9089-90b0f7a66447
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7dea06e3-fc3f-4162-8383-9cd6f8f4e547
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7e61d4e5-68fa-480b-bc49-161e51e31289
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2bb16ad8-17e3-4a4d-a069-49f45dceaf59
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5070124b-7850-4654-810e-1632ac9ff5e0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6d9451eb-bd44-4325-a4f3-bacb2294fa04
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e05be479-2b95-452d-871b-883b21c33f0b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 23b1d6a6-4935-447f-b979-c1a8e89b762f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d97ce097-4b00-4413-a8b8-4c39b34db562
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a932aeae-9a60-44f1-bf38-6a2f8fca0e93
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7053b949-18f4-46fd-a30d-93d73a7f9d40
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c6413fd2-62ab-43d4-aa3a-f9177a9aa96a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8c5ba4dc-2518-4527-8668-9f269bce219a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 65f96e25-0760-4948-a0bf-2213a0782737
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f599972a-8b0d-431e-8acb-9434bee76054
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1aa67c5c-d816-4cda-b912-954749e57ae3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1e1ad010-4a9b-4acb-abed-3fcbe4d05f73
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f995565f-5393-4d7a-b911-28b193e6b4d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4a83c43e-17f7-4060-ad0a-67cb7f3979e1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b565a9ed-3e81-4840-ac80-5cf19d98c034
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2b1661d5-0158-494e-89e5-f9844aeffc5b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 812ee855-d95b-42e0-90ec-cdaf192e6dc2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a524e46a-7fb6-4a04-8800-acca8ab8fd5c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c078a2b3-1005-4c45-8e50-18aa6d897fe2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6e8e5470-cca9-4bcd-99c8-3c3ff699939b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4332e11a-4ab0-43bc-bf82-e98e6cd2b9a3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a6e14504-bbf1-41c0-b62a-54305bb211d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4d20d898-3187-405d-8b0f-9c0d11170695
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e940a97a-9b4e-4ff5-831c-1440b185a7b1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dd0321f5-9134-429f-9471-b37834b87a80
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6ac96fe9-b8c9-4d10-bed3-b0b0fbef154f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b2780b43-29e5-4994-b98d-c6aae9a6cedd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6abfc7c0-c56b-4c24-9292-da72915af2c6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fc0903d7-3a31-4a36-838d-a60173152432
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5173d920-6933-4059-89cd-fde39ae021f7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1b21ce15-bc43-46b7-a17c-65168d144847
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2d7566d5-3e4d-4314-a205-cc485c2293a8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5fcc7274-f6f9-46e4-8d95-2f6375acbba0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8e80f6e6-089e-4ae6-966b-3fdb42f92200
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9f5f8bb8-8a44-4b88-8c49-9f84c7784889
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 725eac71-6178-4eb2-bdd7-4022e3ca1abf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 75489703-c39b-4b0a-bbc9-9ad1523d9fb9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 92ee6644-b18a-4604-858d-6e43e05b435f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 47512d7d-54ae-40fc-bc33-9b220762b9d8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a44fb4df-6fa3-42a1-9bd9-cba07c64bdce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 205f5500-1deb-4aee-bf4b-5ee154fdd7da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4a1ae8b8-b773-46c2-b43b-d78dad0109e9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2886db78-f462-477f-89f9-4ef532ff29a8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e95e6522-bc87-4580-a89a-6d8a93849efa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 59b0c146-a1e8-497c-b014-f5a18b98e909
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 66e64807-60eb-4a40-9130-2d46fbf4bfa2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6b51096f-8b6d-4b6b-814d-83f3e0018b78
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 289661a6-d6ca-43bb-b918-40f161a3fdd3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9652bc29-e633-4699-8b47-b9bbd48136b5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3bd8b852-feec-45db-a49e-f8d01b1c086a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6c7cc224-40e0-4408-bc6e-20efac305470
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3ce4ddea-7624-454b-899d-99aa5ff52790
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 285090ec-24ba-46b8-8277-5249f794eda6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5c592988-e5a0-4537-84af-8ed7e99b8053
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5de0497e-6c7b-4228-a352-70ad827b2bfe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e52bc585-61b5-4177-b43a-7c174b5b113f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9b3b8a51-ff93-4873-be23-d116c99163c9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0fe93696-3956-4d34-98bc-39558d67caa6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a91f5267-0633-4053-99fc-dd122bb92763
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ea8e7d63-3acd-4a13-be5e-58f4682237c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d3d37f6c-2d1c-4b51-953b-7fb050cdef19
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message da5ab91e-0959-417b-b74b-58b8aeb2aedf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7b76c43d-0649-4b01-a6c2-cb27d52e98ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bb948f0d-8fee-421b-ab31-f2946be24304
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c5181186-e1af-46bf-b646-252ee9409cbb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e4b95ffa-71c2-4b64-a466-c23c8424cd13
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 909a51dd-0304-40bf-ac68-d3801926b472
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c8ba129e-8d63-4d9f-b0ce-16c9480c5aff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d0dd7bb6-33c2-405d-90e5-9fb85ae61453
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8ba2cee8-0001-4779-8ede-62c0807c9c46
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 604632d4-a0c7-4345-bfe9-ec5eec673856
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0d26c0c3-5f91-4d9f-ad21-37ef28cfbeb0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4c4065b4-6dcf-4862-b61e-2b56fbd666f7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 093313a3-e8cb-42fb-9023-91072e49b103
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c8515668-6a59-42af-87db-9e4794f2086e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b121603e-d24d-418d-8a94-58fbb0538134
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 554e8709-d5a6-49c7-8d01-859d913eedde
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a08d1c8e-8923-44ba-97f6-998da97069dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6785edc7-c65f-4e52-90f2-6e627bc7c45b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 969ee6c2-af29-40de-95e4-37b0ae4fa86b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 60552bed-4694-45a6-8932-f796e69a6259
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bf50458f-879a-4fdf-b0b3-92cece1f4923
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a6c22023-8b8f-4f0f-834d-7c03ba7d9245
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6836ef52-b1e7-4fcb-aaaa-d1ba53488ab2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 72363157-713e-4ffe-824a-8817320dbe0d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7944fe80-c39b-4cde-9460-99ff9c81e3f7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b5c616a7-3e3f-4c5f-9f6c-72259f43bada
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e0daa5f1-f6a9-40a6-a904-49d36d5f652e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3f845cb7-2b19-402f-b82c-63f97af953d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f0097c4d-1cf6-4a07-a2ac-3605f4bd5312
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ff7c1f05-e2dd-40a1-ba98-03ed3bb6d136
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bea507b8-649c-4d25-8994-7dfe8b7d0d3f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4ec7055b-b982-4c66-b35d-13441e662337
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 493184f8-f765-452c-84b0-00daa39b48ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 943bd4dd-eb95-4921-bddd-2ce484b2225a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 22f29b35-3448-4d8f-b32f-c8f420b1613f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fb645228-22b4-480c-bada-7732c6d3c527
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2209b17c-e820-4652-9895-96d17e80deaa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 92169d2b-fbc6-4c9f-a32f-1f8b9a5852bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a6449e19-46fe-45b3-aedf-c3946d7a35f2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6d60194f-8abe-4342-b8a9-a949246255ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f8cb36b4-353d-47b9-8aa3-e439bc56ce35
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f1f558fa-697d-49a0-a1c3-f29009cece06
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 33f88f1e-1579-4084-ba36-6c469d5abe45
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 03fb6d60-759b-4fa0-8b05-c3ce2b9ee51f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a91abd5b-07b9-4354-997e-1b69776a17be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6139cbc6-66ae-42eb-96ac-d222a14ae103
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9f17f068-2f68-4c0b-92fa-6f1cc8b87711
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d152f7d3-6498-4f50-9564-ea4d752639b1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d45295eb-7602-4a1b-86de-b90433b600a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4c102683-d9b9-422b-8ef7-0cc0b698e2d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e9efa453-84f8-46a9-bf11-f855eaa55d41
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 69bfaf3f-0586-4e4a-825b-cc997e79e1b5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5c986090-2f36-4fdf-ac4a-e5266d135e6f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 26bb197f-5e86-4f1d-a00e-227f359c0de5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f382dca3-af63-4f05-a130-e4937a39a3f2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8d166041-07a1-4d53-b64c-f2e0bec38105
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d9fded6b-6fe2-49cc-bd60-a95e13104aa9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 700fe257-5b65-4124-8e16-5746e6dad80f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6ed2907d-19d6-47cc-8164-e435d982d6c9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cc815b7d-43ca-49b0-a7ec-f70858abaab5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6122fd59-ae7f-42a8-b755-a0956028013a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d6095d36-24af-4db9-a020-68a184d4c344
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7a810e37-c1c4-40ac-bf98-d945447ceca1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2ef94438-bfaa-48cb-b235-38d145d33d80
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 79b238e0-52d8-4dd2-bc5c-6342345c62f2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 75491b86-1076-47e6-9997-64da4c96410e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cc5cf25d-431b-4928-8dbb-0e88b28e9a3f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9f939937-4460-455e-bb77-daf91bd1ddb5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dc656aa8-78b5-4f41-91de-e0ea11eef779
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 59d582d2-d506-4aef-b71a-a43f0f3a58cb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bd8e64ed-c1d0-422c-b3f5-5ee9dc599dce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c9bbf48a-3454-46e5-95cb-b40202e27b6f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0c349b62-1b6e-4f2a-bec9-161bfbc5c971
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message de732f18-12a1-4588-a6e3-0e525d565829
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fd69d2cf-6746-4727-9e3e-1116ab245bb8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ed33634c-a2c4-4c86-abb6-19ceb732fa0e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e22a31cb-bd97-447d-bfa5-fdb96f4820df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9dc3561e-3bd4-48bb-b4da-7477d1147990
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ea8300a0-067e-494f-adc2-6b082444e89c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6cbec2e6-bd0b-4a46-b5cd-07318b5dc3f7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f52a4b70-b5ac-402f-9c6c-a109edef85c5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 23643cda-1e16-4c10-bde8-9b60e803ebc3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 581198b9-2984-4581-bc6a-fefd8339e8a8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8ff4508d-b838-4dbb-88d8-afaa8549dd11
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f353702b-4f5d-4d44-8bf9-a0aeaa7845fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5cf8f208-54ce-4b95-a948-0fa01ef52eb3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5af8e23b-f6f1-4055-8915-e9cf45c56ffc
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8687 {grpc_message:"Socket closed", grpc_status:14}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_20
Server: localhost:8687
Algorithm: FEDAVG
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_20
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_20/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_20/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_20/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_20/test_labels.txt

📊 Raw data loaded:
   Train: X=(2028, 24), y=(2028,)
   Test:  X=(508, 24), y=(508,)

⚠️  Limiting training data: 2028 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  499 samples, 5 features
✅ Client client_20 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

============================================================
🔄 Round 2 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0860 (↓), lr=0.001000
   • Epoch   2/100: train=0.0839, val=0.0866, patience=1/15, lr=0.001000
   • Epoch   3/100: train=0.0839, val=0.0869, patience=2/15, lr=0.001000
   • Epoch   4/100: train=0.0838, val=0.0871, patience=3/15, lr=0.001000
   • Epoch   5/100: train=0.0837, val=0.0872, patience=4/15, lr=0.001000
   📉 Epoch 7: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0827, val=0.0872, patience=10/15, lr=0.000500
   📉 Epoch 15: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 2 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=0.0041
   Val:   Loss=0.0860, RMSE=0.2932, R²=-0.0134
============================================================


📊 Round 2 Test Metrics:
   Loss: 0.0865, RMSE: 0.2941, MAE: 0.2579, R²: -0.0139

📊 Round 2 Test Metrics:
   Loss: 0.0872, RMSE: 0.2953, MAE: 0.2590, R²: -0.0217

📊 Round 2 Test Metrics:
   Loss: 0.0879, RMSE: 0.2965, MAE: 0.2602, R²: -0.0306

📊 Round 2 Test Metrics:
   Loss: 0.0885, RMSE: 0.2975, MAE: 0.2611, R²: -0.0371

============================================================
🔄 Round 9 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0899 (↓), lr=0.000250
   • Epoch   2/100: train=0.0844, val=0.0903, patience=1/15, lr=0.000250
   • Epoch   3/100: train=0.0843, val=0.0899, patience=2/15, lr=0.000250
   • Epoch   4/100: train=0.0840, val=0.0899, patience=3/15, lr=0.000250
   • Epoch   5/100: train=0.0839, val=0.0898, patience=4/15, lr=0.000250
   📉 Epoch 7: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0832, val=0.0893, patience=2/15, lr=0.000125
   📉 Epoch 15: LR reduced 0.000125 → 0.000063
   • Epoch  21/100: train=0.0828, val=0.0891, patience=12/15, lr=0.000063
   📉 Epoch 23: LR reduced 0.000063 → 0.000031

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0893)

============================================================
📊 Round 9 Summary - Client client_20
   Epochs: 24/100 (early stopped)
   LR: 0.000250 → 0.000031 (3 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=-0.0047
   Val:   Loss=0.0893, RMSE=0.2988, R²=-0.0216
============================================================


📊 Round 9 Test Metrics:
   Loss: 0.0888, RMSE: 0.2980, MAE: 0.2615, R²: -0.0408

📊 Round 9 Test Metrics:
   Loss: 0.0889, RMSE: 0.2982, MAE: 0.2617, R²: -0.0422

============================================================
🔄 Round 11 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000031
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0882, val=0.0797 (↓), lr=0.000031
   ✓ Epoch   2/100: train=0.0880, val=0.0789 (↓), lr=0.000031
   ✓ Epoch   3/100: train=0.0878, val=0.0784 (↓), lr=0.000031
   • Epoch   4/100: train=0.0877, val=0.0780, patience=1/15, lr=0.000031
   ✓ Epoch   5/100: train=0.0876, val=0.0778 (↓), lr=0.000031
   • Epoch  11/100: train=0.0872, val=0.0770, patience=2/15, lr=0.000031
   • Epoch  21/100: train=0.0868, val=0.0765, patience=7/15, lr=0.000031

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0767)

============================================================
📊 Round 11 Summary - Client client_20
   Epochs: 29/100 (early stopped)
   LR: 0.000031 → 0.000031 (0 reductions)
   Train: Loss=0.0871, RMSE=0.2952, R²=-0.0095
   Val:   Loss=0.0767, RMSE=0.2770, R²=-0.0721
============================================================


📊 Round 11 Test Metrics:
   Loss: 0.0888, RMSE: 0.2980, MAE: 0.2616, R²: -0.0408

============================================================
🔄 Round 13 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000031
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0882 (↓), lr=0.000031
   • Epoch   2/100: train=0.0853, val=0.0880, patience=1/15, lr=0.000031
   • Epoch   3/100: train=0.0851, val=0.0880, patience=2/15, lr=0.000031
   • Epoch   4/100: train=0.0850, val=0.0879, patience=3/15, lr=0.000031
   • Epoch   5/100: train=0.0849, val=0.0878, patience=4/15, lr=0.000031
   📉 Epoch 6: LR reduced 0.000031 → 0.000016
   • Epoch  11/100: train=0.0846, val=0.0873, patience=5/15, lr=0.000016
   📉 Epoch 14: LR reduced 0.000016 → 0.000008
   • Epoch  21/100: train=0.0844, val=0.0870, patience=7/15, lr=0.000008
   📉 Epoch 22: LR reduced 0.000008 → 0.000004

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0871)

============================================================
📊 Round 13 Summary - Client client_20
   Epochs: 29/100 (early stopped)
   LR: 0.000031 → 0.000004 (3 reductions)
   Train: Loss=0.0846, RMSE=0.2908, R²=-0.0114
   Val:   Loss=0.0871, RMSE=0.2952, R²=-0.0339
============================================================


📊 Round 13 Test Metrics:
   Loss: 0.0894, RMSE: 0.2990, MAE: 0.2622, R²: -0.0476

============================================================
🔄 Round 15 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000004
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   📉 Epoch 1: LR reduced 0.000004 → 0.000002
   ✓ Epoch   1/100: train=0.0861, val=0.0890 (↓), lr=0.000002
   • Epoch   2/100: train=0.0861, val=0.0890, patience=1/15, lr=0.000002
   • Epoch   3/100: train=0.0860, val=0.0889, patience=2/15, lr=0.000002
   • Epoch   4/100: train=0.0860, val=0.0889, patience=3/15, lr=0.000002
   • Epoch   5/100: train=0.0859, val=0.0889, patience=4/15, lr=0.000002
   📉 Epoch 9: LR reduced 0.000002 → 0.000001
   • Epoch  11/100: train=0.0858, val=0.0887, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0890)

============================================================
📊 Round 15 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000004 → 0.000001 (2 reductions)
   Train: Loss=0.0863, RMSE=0.2938, R²=-0.0357
   Val:   Loss=0.0890, RMSE=0.2983, R²=-0.0409
============================================================


📊 Round 15 Test Metrics:
   Loss: 0.0895, RMSE: 0.2992, MAE: 0.2624, R²: -0.0493

📊 Round 15 Test Metrics:
   Loss: 0.0897, RMSE: 0.2995, MAE: 0.2626, R²: -0.0516

============================================================
🔄 Round 19 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0898, val=0.0749 (↓), lr=0.000001
   • Epoch   2/100: train=0.0898, val=0.0749, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0898, val=0.0749, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0897, val=0.0749, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0897, val=0.0749, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0896, val=0.0749, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0749)

============================================================
📊 Round 19 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0900, RMSE=0.3000, R²=-0.0450
   Val:   Loss=0.0749, RMSE=0.2737, R²=-0.0129
============================================================


📊 Round 19 Test Metrics:
   Loss: 0.0897, RMSE: 0.2995, MAE: 0.2625, R²: -0.0510

============================================================
🔄 Round 22 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0895, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0895, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0895, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0895, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0895, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0894, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 22 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0891, RMSE=0.2985, R²=-0.0447
   Val:   Loss=0.0799, RMSE=0.2827, R²=-0.0311
============================================================


📊 Round 22 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2628, R²: -0.0549

📊 Round 22 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2628, R²: -0.0549

============================================================
🔄 Round 27 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0877, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0877, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0877, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0876, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0876, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0876, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 27 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0876, RMSE=0.2960, R²=-0.0403
   Val:   Loss=0.0862, RMSE=0.2936, R²=-0.0655
============================================================


============================================================
🔄 Round 28 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0875, val=0.0865 (↓), lr=0.000001
   • Epoch   2/100: train=0.0874, val=0.0865, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0874, val=0.0865, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0874, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0874, val=0.0864, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0873, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0865)

============================================================
📊 Round 28 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0875, RMSE=0.2958, R²=-0.0328
   Val:   Loss=0.0865, RMSE=0.2941, R²=-0.0860
============================================================


📊 Round 28 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2628, R²: -0.0548

============================================================
🔄 Round 30 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0893, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0893, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0892, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0892, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0892, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0891, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 30 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0892, RMSE=0.2987, R²=-0.0451
   Val:   Loss=0.0797, RMSE=0.2823, R²=-0.0392
============================================================


📊 Round 30 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2628, R²: -0.0548

============================================================
🔄 Round 31 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0910 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0910, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0910, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0910, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0910, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0911, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0910)

============================================================
📊 Round 31 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2939, R²=-0.0567
   Val:   Loss=0.0910, RMSE=0.3016, R²=-0.0159
============================================================


============================================================
🔄 Round 33 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0872, val=0.0885 (↓), lr=0.000001
   • Epoch   2/100: train=0.0872, val=0.0885, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0872, val=0.0885, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0872, val=0.0884, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0872, val=0.0884, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0871, val=0.0883, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0885)

============================================================
📊 Round 33 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0870, RMSE=0.2950, R²=-0.0381
   Val:   Loss=0.0885, RMSE=0.2975, R²=-0.0719
============================================================


📊 Round 33 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2628, R²: -0.0549

📊 Round 33 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2628, R²: -0.0549

============================================================
🔄 Round 35 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0905 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0904, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0904, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0904, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0904, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0904, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0905)

============================================================
📊 Round 35 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2942, R²=-0.0471
   Val:   Loss=0.0905, RMSE=0.3008, R²=-0.0257
============================================================


📊 Round 35 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2628, R²: -0.0549

============================================================
🔄 Round 37 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0869, val=0.0882 (↓), lr=0.000001
   • Epoch   2/100: train=0.0869, val=0.0882, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0869, val=0.0882, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0869, val=0.0882, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0869, val=0.0882, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0868, val=0.0880, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0882)

============================================================
📊 Round 37 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0871, RMSE=0.2951, R²=-0.0349
   Val:   Loss=0.0882, RMSE=0.2970, R²=-0.0808
============================================================


📊 Round 37 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2628, R²: -0.0549

============================================================
🔄 Round 40 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0886, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0886, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0885, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0885, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0885, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0884, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 40 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0884, RMSE=0.2973, R²=-0.0473
   Val:   Loss=0.0830, RMSE=0.2880, R²=-0.0234
============================================================


📊 Round 40 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2628, R²: -0.0549

============================================================
🔄 Round 43 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0897, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0896, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0896, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0896, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0896, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0895, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 43 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0895, RMSE=0.2992, R²=-0.0455
   Val:   Loss=0.0785, RMSE=0.2801, R²=-0.0284
============================================================


============================================================
🔄 Round 46 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0927 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0927, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0927, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0927, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0927, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0927, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0927)

============================================================
📊 Round 46 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2932, R²=-0.0557
   Val:   Loss=0.0927, RMSE=0.3045, R²=0.0002
============================================================


📊 Round 46 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2628, R²: -0.0549

============================================================
🔄 Round 48 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0903, val=0.0761 (↓), lr=0.000001
   • Epoch   2/100: train=0.0902, val=0.0761, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0902, val=0.0761, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0902, val=0.0761, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0902, val=0.0761, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0901, val=0.0761, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0761)

============================================================
📊 Round 48 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0901, RMSE=0.3002, R²=-0.0490
   Val:   Loss=0.0761, RMSE=0.2759, R²=-0.0154
============================================================


📊 Round 48 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2628, R²: -0.0549

============================================================
🔄 Round 49 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0996 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0996, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0996, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0995, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0995, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0995, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0996)

============================================================
📊 Round 49 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=-0.0502
   Val:   Loss=0.0996, RMSE=0.3155, R²=-0.0208
============================================================


📊 Round 49 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2628, R²: -0.0549

============================================================
🔄 Round 51 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0876, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0876, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0876, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0876, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0876, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0875, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 51 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0877, RMSE=0.2961, R²=-0.0273
   Val:   Loss=0.0858, RMSE=0.2929, R²=-0.1127
============================================================


📊 Round 51 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2628, R²: -0.0550

============================================================
🔄 Round 53 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0874, val=0.0881 (↓), lr=0.000001
   • Epoch   2/100: train=0.0873, val=0.0881, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0873, val=0.0881, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0873, val=0.0881, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0873, val=0.0881, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0871, val=0.0881, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0881)

============================================================
📊 Round 53 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0871, RMSE=0.2952, R²=-0.0368
   Val:   Loss=0.0881, RMSE=0.2968, R²=-0.0739
============================================================


📊 Round 53 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2628, R²: -0.0549

📊 Round 53 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2628, R²: -0.0549

============================================================
🔄 Round 55 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0966 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0967, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0967, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0967, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0967, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0969, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0966)

============================================================
📊 Round 55 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2916, R²=-0.0502
   Val:   Loss=0.0966, RMSE=0.3108, R²=-0.0605
============================================================


============================================================
🔄 Round 57 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0881, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0880, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0880, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0880, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0880, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0879, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 57 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0881, RMSE=0.2968, R²=-0.0445
   Val:   Loss=0.0841, RMSE=0.2901, R²=-0.0359
============================================================


📊 Round 57 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2628, R²: -0.0549

============================================================
🔄 Round 59 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0912 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0912, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0912, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0912, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0912, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0911, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0912)

============================================================
📊 Round 59 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2939, R²=-0.0469
   Val:   Loss=0.0912, RMSE=0.3020, R²=-0.0293
============================================================


📊 Round 59 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2628, R²: -0.0549

📊 Round 59 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2628, R²: -0.0550

============================================================
🔄 Round 63 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0906, val=0.0751 (↓), lr=0.000001
   • Epoch   2/100: train=0.0906, val=0.0751, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0905, val=0.0751, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0905, val=0.0751, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0905, val=0.0752, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0903, val=0.0752, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0751)

============================================================
📊 Round 63 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0904, RMSE=0.3006, R²=-0.0507
   Val:   Loss=0.0751, RMSE=0.2740, R²=-0.0369
============================================================


📊 Round 63 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2628, R²: -0.0550

============================================================
🔄 Round 65 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.0893 (↓), lr=0.000001
   • Epoch   2/100: train=0.0868, val=0.0893, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0867, val=0.0893, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0867, val=0.0893, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0867, val=0.0893, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0893, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0893)

============================================================
📊 Round 65 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2947, R²=-0.0498
   Val:   Loss=0.0893, RMSE=0.2988, R²=-0.0266
============================================================


📊 Round 65 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2628, R²: -0.0551

============================================================
🔄 Round 71 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0876, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0876, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0876, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0875, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0875, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0874, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 71 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0877, RMSE=0.2961, R²=-0.0494
   Val:   Loss=0.0858, RMSE=0.2929, R²=-0.0233
============================================================


📊 Round 71 Test Metrics:
   Loss: 0.0900, RMSE: 0.3001, MAE: 0.2628, R²: -0.0551

============================================================
🔄 Round 72 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0889, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0889, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0889, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0889, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0889, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0888, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 72 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0887, RMSE=0.2978, R²=-0.0400
   Val:   Loss=0.0818, RMSE=0.2860, R²=-0.0619
============================================================


============================================================
🔄 Round 74 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0876, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0876, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0876, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0876, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0876, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0875, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 74 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0878, RMSE=0.2964, R²=-0.0448
   Val:   Loss=0.0853, RMSE=0.2921, R²=-0.0429
============================================================


📊 Round 74 Test Metrics:
   Loss: 0.0900, RMSE: 0.3001, MAE: 0.2628, R²: -0.0552

📊 Round 74 Test Metrics:
   Loss: 0.0900, RMSE: 0.3001, MAE: 0.2628, R²: -0.0552

============================================================
🔄 Round 83 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0894, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0894, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0894, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0894, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0894, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0893, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 83 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0894, RMSE=0.2990, R²=-0.0401
   Val:   Loss=0.0790, RMSE=0.2810, R²=-0.0616
============================================================


============================================================
🔄 Round 84 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0873, val=0.0878 (↓), lr=0.000001
   • Epoch   2/100: train=0.0873, val=0.0878, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0873, val=0.0878, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0872, val=0.0878, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0872, val=0.0878, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0870, val=0.0879, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0878)

============================================================
📊 Round 84 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0872, RMSE=0.2953, R²=-0.0562
   Val:   Loss=0.0878, RMSE=0.2963, R²=-0.0153
============================================================


============================================================
🔄 Round 85 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0880, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0880, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0880, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0880, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0879, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0878, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 85 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0878, RMSE=0.2963, R²=-0.0437
   Val:   Loss=0.0854, RMSE=0.2923, R²=-0.0386
============================================================


============================================================
🔄 Round 87 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0877, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0877, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0877, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0877, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0877, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0877, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 87 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0878, RMSE=0.2963, R²=-0.0328
   Val:   Loss=0.0854, RMSE=0.2922, R²=-0.1050
============================================================


📊 Round 87 Test Metrics:
   Loss: 0.0900, RMSE: 0.3001, MAE: 0.2628, R²: -0.0552

📊 Round 87 Test Metrics:
   Loss: 0.0900, RMSE: 0.3001, MAE: 0.2628, R²: -0.0552

============================================================
🔄 Round 91 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0885, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0885, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0884, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0884, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0884, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0883, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 91 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0884, RMSE=0.2974, R²=-0.0419
   Val:   Loss=0.0829, RMSE=0.2879, R²=-0.0564
============================================================


📊 Round 91 Test Metrics:
   Loss: 0.0900, RMSE: 0.3001, MAE: 0.2628, R²: -0.0553

============================================================
🔄 Round 95 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0878, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0878, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0878, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0878, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0878, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0877, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 95 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0881, RMSE=0.2967, R²=-0.0354
   Val:   Loss=0.0845, RMSE=0.2906, R²=-0.0860
============================================================


============================================================
🔄 Round 96 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0920 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0920, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0920, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0920, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0920, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0918, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0920)

============================================================
📊 Round 96 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2935, R²=-0.0275
   Val:   Loss=0.0920, RMSE=0.3034, R²=-0.1088
============================================================


============================================================
🔄 Round 97 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0916 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0916, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0916, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0916, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0916, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0917, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0916)

============================================================
📊 Round 97 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2937, R²=-0.0538
   Val:   Loss=0.0916, RMSE=0.3026, R²=-0.0201
============================================================


📊 Round 97 Test Metrics:
   Loss: 0.0900, RMSE: 0.3001, MAE: 0.2628, R²: -0.0553

============================================================
🔄 Round 98 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0941 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0940, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0940, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0940, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0940, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0939, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0941)

============================================================
📊 Round 98 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2927, R²=-0.0384
   Val:   Loss=0.0941, RMSE=0.3067, R²=-0.0667
============================================================


============================================================
🔄 Round 99 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0870, val=0.0873 (↓), lr=0.000001
   • Epoch   2/100: train=0.0870, val=0.0873, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0869, val=0.0873, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0869, val=0.0874, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0868, val=0.0874, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0866, val=0.0876, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0873)

============================================================
📊 Round 99 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0873, RMSE=0.2955, R²=-0.0640
   Val:   Loss=0.0873, RMSE=0.2954, R²=-0.0037
============================================================


📊 Round 99 Test Metrics:
   Loss: 0.0900, RMSE: 0.3001, MAE: 0.2628, R²: -0.0553

============================================================
🔄 Round 101 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0938 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0938, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0938, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0938, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0938, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0937, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0938)

============================================================
📊 Round 101 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2927, R²=-0.0341
   Val:   Loss=0.0938, RMSE=0.3063, R²=-0.0758
============================================================


📊 Round 101 Test Metrics:
   Loss: 0.0901, RMSE: 0.3001, MAE: 0.2628, R²: -0.0554

📊 Round 101 Test Metrics:
   Loss: 0.0901, RMSE: 0.3001, MAE: 0.2628, R²: -0.0554

============================================================
🔄 Round 105 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0915 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0914, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0914, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0914, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0914, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0913, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0915)

============================================================
📊 Round 105 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2938, R²=-0.0294
   Val:   Loss=0.0915, RMSE=0.3024, R²=-0.1029
============================================================


📊 Round 105 Test Metrics:
   Loss: 0.0901, RMSE: 0.3001, MAE: 0.2628, R²: -0.0554

📊 Round 105 Test Metrics:
   Loss: 0.0901, RMSE: 0.3001, MAE: 0.2628, R²: -0.0554

============================================================
🔄 Round 109 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0881, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0881, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0880, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0880, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0880, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0879, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 109 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0880, RMSE=0.2967, R²=-0.0395
   Val:   Loss=0.0846, RMSE=0.2909, R²=-0.0562
============================================================


📊 Round 109 Test Metrics:
   Loss: 0.0901, RMSE: 0.3001, MAE: 0.2628, R²: -0.0555

📊 Round 109 Test Metrics:
   Loss: 0.0901, RMSE: 0.3001, MAE: 0.2628, R²: -0.0554

📊 Round 109 Test Metrics:
   Loss: 0.0901, RMSE: 0.3001, MAE: 0.2628, R²: -0.0554

============================================================
🔄 Round 112 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0956 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0956, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0956, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0955, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0955, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0954, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0956)

============================================================
📊 Round 112 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2920, R²=-0.0240
   Val:   Loss=0.0956, RMSE=0.3092, R²=-0.1172
============================================================


📊 Round 112 Test Metrics:
   Loss: 0.0901, RMSE: 0.3001, MAE: 0.2628, R²: -0.0555

============================================================
🔄 Round 113 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0941 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0940, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0940, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0940, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0940, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0939, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0941)

============================================================
📊 Round 113 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2927, R²=-0.0335
   Val:   Loss=0.0941, RMSE=0.3067, R²=-0.0799
============================================================


📊 Round 113 Test Metrics:
   Loss: 0.0901, RMSE: 0.3001, MAE: 0.2628, R²: -0.0555

📊 Round 113 Test Metrics:
   Loss: 0.0901, RMSE: 0.3001, MAE: 0.2628, R²: -0.0555

📊 Round 113 Test Metrics:
   Loss: 0.0901, RMSE: 0.3001, MAE: 0.2629, R²: -0.0556

============================================================
🔄 Round 118 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0915 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0915, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0915, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0914, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0914, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0913, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0915)

============================================================
📊 Round 118 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2938, R²=-0.0321
   Val:   Loss=0.0915, RMSE=0.3025, R²=-0.0853
============================================================


📊 Round 118 Test Metrics:
   Loss: 0.0901, RMSE: 0.3001, MAE: 0.2629, R²: -0.0556

============================================================
🔄 Round 120 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0882, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0882, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0882, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0882, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0882, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0881, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 120 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0885, RMSE=0.2974, R²=-0.0426
   Val:   Loss=0.0828, RMSE=0.2878, R²=-0.0579
============================================================


============================================================
🔄 Round 124 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0938 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0938, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0938, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0937, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0937, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0936, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0938)

============================================================
📊 Round 124 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2928, R²=-0.0444
   Val:   Loss=0.0938, RMSE=0.3063, R²=-0.0391
============================================================


📊 Round 124 Test Metrics:
   Loss: 0.0901, RMSE: 0.3001, MAE: 0.2629, R²: -0.0556

📊 Round 124 Test Metrics:
   Loss: 0.0901, RMSE: 0.3001, MAE: 0.2629, R²: -0.0556

============================================================
🔄 Round 128 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0870, val=0.0895 (↓), lr=0.000001
   • Epoch   2/100: train=0.0870, val=0.0895, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0869, val=0.0895, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0869, val=0.0895, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0869, val=0.0895, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0868, val=0.0894, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0895)

============================================================
📊 Round 128 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2946, R²=-0.0377
   Val:   Loss=0.0895, RMSE=0.2992, R²=-0.0632
============================================================


📊 Round 128 Test Metrics:
   Loss: 0.0901, RMSE: 0.3001, MAE: 0.2628, R²: -0.0555

============================================================
🔄 Round 132 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0918 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0918, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0918, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0918, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0918, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0917, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0918)

============================================================
📊 Round 132 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2937, R²=-0.0467
   Val:   Loss=0.0918, RMSE=0.3030, R²=-0.0302
============================================================


📊 Round 132 Test Metrics:
   Loss: 0.0901, RMSE: 0.3001, MAE: 0.2628, R²: -0.0556

============================================================
🔄 Round 137 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0894, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0893, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0893, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0893, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0893, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0892, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 137 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0892, RMSE=0.2987, R²=-0.0443
   Val:   Loss=0.0799, RMSE=0.2827, R²=-0.0374
============================================================


📊 Round 137 Test Metrics:
   Loss: 0.0901, RMSE: 0.3001, MAE: 0.2628, R²: -0.0555

============================================================
🔄 Round 139 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0878, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0878, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0878, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0878, val=0.0859, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0877, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0876, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 139 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0877, RMSE=0.2962, R²=-0.0484
   Val:   Loss=0.0859, RMSE=0.2932, R²=-0.0240
============================================================


============================================================
🔄 Round 140 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0915 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0914, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0914, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0914, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0914, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0913, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0915)

============================================================
📊 Round 140 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2938, R²=-0.0371
   Val:   Loss=0.0915, RMSE=0.3024, R²=-0.0657
============================================================


📊 Round 140 Test Metrics:
   Loss: 0.0901, RMSE: 0.3001, MAE: 0.2628, R²: -0.0555

============================================================
🔄 Round 143 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0884, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0884, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0883, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0883, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0883, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0881, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 143 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0885, RMSE=0.2975, R²=-0.0612
   Val:   Loss=0.0828, RMSE=0.2877, R²=0.0241
============================================================


============================================================
🔄 Round 144 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0880, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0880, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0880, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0880, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0880, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0879, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 144 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0878, RMSE=0.2963, R²=-0.0409
   Val:   Loss=0.0857, RMSE=0.2927, R²=-0.0550
============================================================


============================================================
🔄 Round 147 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0895, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0895, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0895, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0895, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0895, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0893, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 147 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0894, RMSE=0.2991, R²=-0.0483
   Val:   Loss=0.0790, RMSE=0.2811, R²=-0.0249
============================================================


📊 Round 147 Test Metrics:
   Loss: 0.0901, RMSE: 0.3001, MAE: 0.2629, R²: -0.0556

============================================================
🔄 Round 148 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0937 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0937, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0937, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0937, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0937, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0936, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0937)

============================================================
📊 Round 148 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2928, R²=-0.0352
   Val:   Loss=0.0937, RMSE=0.3062, R²=-0.0738
============================================================


📊 Round 148 Test Metrics:
   Loss: 0.0901, RMSE: 0.3001, MAE: 0.2629, R²: -0.0556

📊 Round 148 Test Metrics:
   Loss: 0.0901, RMSE: 0.3001, MAE: 0.2628, R²: -0.0556

============================================================
🔄 Round 150 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0869, val=0.0909 (↓), lr=0.000001
   • Epoch   2/100: train=0.0869, val=0.0909, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0869, val=0.0909, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0868, val=0.0909, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0868, val=0.0909, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0867, val=0.0909, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0909)

============================================================
📊 Round 150 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2941, R²=-0.0452
   Val:   Loss=0.0909, RMSE=0.3015, R²=-0.0391
============================================================


📊 Round 150 Test Metrics:
   Loss: 0.0901, RMSE: 0.3001, MAE: 0.2629, R²: -0.0556

============================================================
🔄 Round 152 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0924 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0924, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0924, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0924, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0924, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0924, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0924)

============================================================
📊 Round 152 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2934, R²=-0.0469
   Val:   Loss=0.0924, RMSE=0.3039, R²=-0.0350
============================================================


📊 Round 152 Test Metrics:
   Loss: 0.0901, RMSE: 0.3001, MAE: 0.2629, R²: -0.0556

============================================================
🔄 Round 155 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0878, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0878, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0878, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0878, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0877, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0876, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 155 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0879, RMSE=0.2964, R²=-0.0441
   Val:   Loss=0.0853, RMSE=0.2921, R²=-0.0485
============================================================


📊 Round 155 Test Metrics:
   Loss: 0.0901, RMSE: 0.3001, MAE: 0.2629, R²: -0.0556

============================================================
🔄 Round 156 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0980 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0980, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0980, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0980, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0980, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0980, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0980)

============================================================
📊 Round 156 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=-0.0479
   Val:   Loss=0.0980, RMSE=0.3130, R²=-0.0299
============================================================


📊 Round 156 Test Metrics:
   Loss: 0.0901, RMSE: 0.3001, MAE: 0.2629, R²: -0.0556

============================================================
🔄 Round 158 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0889, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0889, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0888, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0888, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0888, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0887, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 158 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0888, RMSE=0.2980, R²=-0.0405
   Val:   Loss=0.0816, RMSE=0.2857, R²=-0.0616
============================================================


📊 Round 158 Test Metrics:
   Loss: 0.0901, RMSE: 0.3001, MAE: 0.2629, R²: -0.0556

============================================================
🔄 Round 161 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0878, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0878, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0878, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0877, val=0.0859, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0877, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0876, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 161 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0877, RMSE=0.2962, R²=-0.0434
   Val:   Loss=0.0859, RMSE=0.2932, R²=-0.0444
============================================================


📊 Round 161 Test Metrics:
   Loss: 0.0901, RMSE: 0.3001, MAE: 0.2629, R²: -0.0556

📊 Round 161 Test Metrics:
   Loss: 0.0901, RMSE: 0.3001, MAE: 0.2629, R²: -0.0556

============================================================
🔄 Round 165 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0874, val=0.0877 (↓), lr=0.000001
   • Epoch   2/100: train=0.0873, val=0.0877, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0873, val=0.0877, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0873, val=0.0878, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0873, val=0.0878, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0871, val=0.0878, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0877)

============================================================
📊 Round 165 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0873, RMSE=0.2954, R²=-0.0509
   Val:   Loss=0.0877, RMSE=0.2962, R²=-0.0364
============================================================


📊 Round 165 Test Metrics:
   Loss: 0.0901, RMSE: 0.3001, MAE: 0.2629, R²: -0.0556

============================================================
🔄 Round 168 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0887, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0886, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0886, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0886, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0886, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0885, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 168 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0887, RMSE=0.2978, R²=-0.0449
   Val:   Loss=0.0820, RMSE=0.2864, R²=-0.0367
============================================================


📊 Round 168 Test Metrics:
   Loss: 0.0901, RMSE: 0.3001, MAE: 0.2628, R²: -0.0556

============================================================
🔄 Round 169 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0869, val=0.0896 (↓), lr=0.000001
   • Epoch   2/100: train=0.0869, val=0.0895, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0868, val=0.0895, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0868, val=0.0895, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0868, val=0.0895, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0867, val=0.0895, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0896)

============================================================
📊 Round 169 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2947, R²=-0.0405
   Val:   Loss=0.0896, RMSE=0.2992, R²=-0.0597
============================================================


📊 Round 169 Test Metrics:
   Loss: 0.0901, RMSE: 0.3001, MAE: 0.2628, R²: -0.0556

============================================================
🔄 Round 171 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0889, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0889, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0889, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0889, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0888, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0887, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 171 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0889, RMSE=0.2981, R²=-0.0459
   Val:   Loss=0.0814, RMSE=0.2853, R²=-0.0347
============================================================


📊 Round 171 Test Metrics:
   Loss: 0.0901, RMSE: 0.3001, MAE: 0.2629, R²: -0.0556

============================================================
🔄 Round 173 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0909 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0909, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0909, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0909, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0909, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0908, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0909)

============================================================
📊 Round 173 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2941, R²=-0.0406
   Val:   Loss=0.0909, RMSE=0.3015, R²=-0.0528
============================================================


📊 Round 173 Test Metrics:
   Loss: 0.0901, RMSE: 0.3001, MAE: 0.2629, R²: -0.0556

📊 Round 173 Test Metrics:
   Loss: 0.0901, RMSE: 0.3001, MAE: 0.2629, R²: -0.0556

============================================================
🔄 Round 179 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0895, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0895, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0895, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0895, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0894, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0894, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 179 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0895, RMSE=0.2992, R²=-0.0444
   Val:   Loss=0.0788, RMSE=0.2807, R²=-0.0390
============================================================


📊 Round 179 Test Metrics:
   Loss: 0.0901, RMSE: 0.3001, MAE: 0.2629, R²: -0.0556

============================================================
🔄 Round 183 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0876, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0876, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0876, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0876, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0876, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0875, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 183 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0877, RMSE=0.2961, R²=-0.0391
   Val:   Loss=0.0861, RMSE=0.2935, R²=-0.0646
============================================================


📊 Round 183 Test Metrics:
   Loss: 0.0901, RMSE: 0.3001, MAE: 0.2629, R²: -0.0556

📊 Round 183 Test Metrics:
   Loss: 0.0901, RMSE: 0.3001, MAE: 0.2628, R²: -0.0556

============================================================
🔄 Round 187 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0909 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0909, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0909, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0909, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0909, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0908, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0909)

============================================================
📊 Round 187 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2941, R²=-0.0346
   Val:   Loss=0.0909, RMSE=0.3015, R²=-0.0786
============================================================


📊 Round 187 Test Metrics:
   Loss: 0.0901, RMSE: 0.3001, MAE: 0.2628, R²: -0.0556

📊 Round 187 Test Metrics:
   Loss: 0.0901, RMSE: 0.3001, MAE: 0.2628, R²: -0.0556

📊 Round 187 Test Metrics:
   Loss: 0.0901, RMSE: 0.3001, MAE: 0.2628, R²: -0.0556

📊 Round 187 Test Metrics:
   Loss: 0.0901, RMSE: 0.3001, MAE: 0.2628, R²: -0.0555

============================================================
🔄 Round 195 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0927 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0927, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0927, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0927, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0927, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0926, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0927)

============================================================
📊 Round 195 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2934, R²=-0.0488
   Val:   Loss=0.0927, RMSE=0.3045, R²=-0.0342
============================================================


📊 Round 195 Test Metrics:
   Loss: 0.0901, RMSE: 0.3001, MAE: 0.2628, R²: -0.0555

============================================================
🔄 Round 196 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0892 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0892, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0892, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0892, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0892, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0891, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0892)

============================================================
📊 Round 196 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0869, RMSE=0.2949, R²=-0.0438
   Val:   Loss=0.0892, RMSE=0.2987, R²=-0.0424
============================================================


📊 Round 196 Test Metrics:
   Loss: 0.0901, RMSE: 0.3001, MAE: 0.2628, R²: -0.0556

============================================================
🔄 Round 198 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0888, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0887, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0887, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0887, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0887, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0885, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 198 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0886, RMSE=0.2977, R²=-0.0526
   Val:   Loss=0.0825, RMSE=0.2873, R²=-0.0090
============================================================


📊 Round 198 Test Metrics:
   Loss: 0.0901, RMSE: 0.3001, MAE: 0.2628, R²: -0.0556

============================================================
🔄 Round 199 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0880, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0880, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0880, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0879, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0879, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0878, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 199 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0879, RMSE=0.2964, R²=-0.0428
   Val:   Loss=0.0855, RMSE=0.2924, R²=-0.0460
============================================================


📊 Round 199 Test Metrics:
   Loss: 0.0901, RMSE: 0.3001, MAE: 0.2628, R²: -0.0556

============================================================
🔄 Round 201 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0889, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0889, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0889, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0889, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0889, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0888, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 201 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0891, RMSE=0.2985, R²=-0.0430
   Val:   Loss=0.0807, RMSE=0.2840, R²=-0.0456
============================================================


📊 Round 201 Test Metrics:
   Loss: 0.0901, RMSE: 0.3001, MAE: 0.2628, R²: -0.0556

============================================================
🔄 Round 204 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0892, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0892, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0892, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0892, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0892, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0891, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 204 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0890, RMSE=0.2983, R²=-0.0402
   Val:   Loss=0.0810, RMSE=0.2847, R²=-0.0866
============================================================


📊 Round 204 Test Metrics:
   Loss: 0.0901, RMSE: 0.3001, MAE: 0.2628, R²: -0.0555

============================================================
🔄 Round 205 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0903 (↓), lr=0.000001
   • Epoch   2/100: train=0.0867, val=0.0903, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0902, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0902, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0902, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0866, val=0.0901, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0903)

============================================================
📊 Round 205 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0867, RMSE=0.2944, R²=-0.0407
   Val:   Loss=0.0903, RMSE=0.3005, R²=-0.0578
============================================================


📊 Round 205 Test Metrics:
   Loss: 0.0901, RMSE: 0.3001, MAE: 0.2628, R²: -0.0555

============================================================
🔄 Round 206 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0872, val=0.0882 (↓), lr=0.000001
   • Epoch   2/100: train=0.0871, val=0.0882, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0871, val=0.0882, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0871, val=0.0881, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0871, val=0.0881, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0870, val=0.0880, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0882)

============================================================
📊 Round 206 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0872, RMSE=0.2953, R²=-0.0418
   Val:   Loss=0.0882, RMSE=0.2970, R²=-0.0519
============================================================


📊 Round 206 Test Metrics:
   Loss: 0.0901, RMSE: 0.3001, MAE: 0.2628, R²: -0.0556

📊 Round 206 Test Metrics:
   Loss: 0.0901, RMSE: 0.3001, MAE: 0.2628, R²: -0.0556

============================================================
🔄 Round 209 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0908 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0908, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0908, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0908, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0908, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0907, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0908)

============================================================
📊 Round 209 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2942, R²=-0.0448
   Val:   Loss=0.0908, RMSE=0.3014, R²=-0.0390
============================================================


📊 Round 209 Test Metrics:
   Loss: 0.0901, RMSE: 0.3001, MAE: 0.2628, R²: -0.0556

============================================================
🔄 Round 210 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0890, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0890, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0890, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0890, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0890, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0888, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 210 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0891, RMSE=0.2985, R²=-0.0475
   Val:   Loss=0.0806, RMSE=0.2839, R²=-0.0272
============================================================


📊 Round 210 Test Metrics:
   Loss: 0.0901, RMSE: 0.3001, MAE: 0.2628, R²: -0.0556

============================================================
🔄 Round 211 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0931 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0930, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0930, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0930, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0930, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0930, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0931)

============================================================
📊 Round 211 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2932, R²=-0.0527
   Val:   Loss=0.0931, RMSE=0.3051, R²=-0.0139
============================================================


📊 Round 211 Test Metrics:
   Loss: 0.0901, RMSE: 0.3001, MAE: 0.2628, R²: -0.0556

📊 Round 211 Test Metrics:
   Loss: 0.0901, RMSE: 0.3001, MAE: 0.2629, R²: -0.0556

============================================================
🔄 Round 214 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0871, val=0.0895 (↓), lr=0.000001
   • Epoch   2/100: train=0.0871, val=0.0895, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0871, val=0.0895, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0871, val=0.0895, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0871, val=0.0895, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0870, val=0.0894, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0895)

============================================================
📊 Round 214 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0869, RMSE=0.2947, R²=-0.0466
   Val:   Loss=0.0895, RMSE=0.2992, R²=-0.0323
============================================================


📊 Round 214 Test Metrics:
   Loss: 0.0901, RMSE: 0.3001, MAE: 0.2628, R²: -0.0556

📊 Round 214 Test Metrics:
   Loss: 0.0901, RMSE: 0.3001, MAE: 0.2628, R²: -0.0556

📊 Round 214 Test Metrics:
   Loss: 0.0901, RMSE: 0.3001, MAE: 0.2628, R²: -0.0556

📊 Round 214 Test Metrics:
   Loss: 0.0901, RMSE: 0.3001, MAE: 0.2628, R²: -0.0556

============================================================
🔄 Round 222 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0911 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0911, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0911, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0910, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0910, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0909, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0911)

============================================================
📊 Round 222 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2941, R²=-0.0434
   Val:   Loss=0.0911, RMSE=0.3018, R²=-0.0494
============================================================


📊 Round 222 Test Metrics:
   Loss: 0.0901, RMSE: 0.3001, MAE: 0.2628, R²: -0.0556

============================================================
🔄 Round 224 - Client client_20
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0883, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0882, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0882, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0882, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0882, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0881, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 224 Summary - Client client_20
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0881, RMSE=0.2969, R²=-0.0521
   Val:   Loss=0.0845, RMSE=0.2908, R²=-0.0095
============================================================


❌ Client client_20 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8687 {grpc_message:"Socket closed", grpc_status:14}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8687 {grpc_message:"Socket closed", grpc_status:14}"
>
