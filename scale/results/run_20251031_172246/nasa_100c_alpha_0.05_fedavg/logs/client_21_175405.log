[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8e1b9152-235e-4ae8-92ae-b609ee827b1a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 01acf1e8-bff9-4dec-8e30-42125b969a26
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6abacb44-8cb0-475a-91ce-69bc748720df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c7bd0f4b-5d3c-4c98-8a2d-643828a4f545
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8f624c32-1ecd-4cf9-8e39-c35176b133ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b41f47c6-274b-4c0e-a12c-4038290ed3d9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 54122ccf-0ab5-40c8-9643-561d04aa4a8b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f09e35b8-bc23-417f-9711-a04105d953b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f5fa590d-b054-4a2e-8a0b-7201298b536d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d05e2140-dcfe-4763-815f-cf3946d6cf73
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b9cc5ee0-e377-4625-aba8-17bfef16c325
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8d5c43e7-f3ed-45d3-b472-7fee3f027d68
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8a61666d-44a1-4604-b3f4-7d673f517fe4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a19ae250-e2c2-4526-9116-680e9072b5ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ef909c2d-6c85-4323-b4ff-90cf1877dc26
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 475bfe2f-0789-4f5a-b81d-fd4c8ac410e1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7a28569a-e8ec-4aef-8c55-40a01cecced4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message df748dbc-c264-4f91-aee9-3acf4f6a6b71
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a73b8732-c73f-4d62-8af1-88d506d2daf7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bc2ddb0f-66d9-4efe-a876-9f71b0efaba8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 61ee4cee-5bd9-4c05-acea-974578a42ba8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3cc064fa-326d-41a8-9c03-163a85ea97e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c42d23b5-2d48-43d1-b14a-df4515fce809
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 35d68d33-6878-4639-87bc-70e1ddfccee9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cc35cd97-faf6-4d1e-acbc-14b263b864cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3644a0a5-141d-4415-a2d0-7ad80de290cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4723661b-913b-457e-918d-008a8857b82a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 19c2eef8-67ad-4979-a936-bd303acc96b5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1996ec9c-f1a8-4983-bc14-f5c2ad55f26a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8f5b6f4c-c103-49ad-8d44-363d1459cc61
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f35f07d6-649b-45d0-86bc-c66064465281
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a35acb13-26b3-44d3-a1a2-ff147f5ee06a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d1595960-632f-47f2-9413-f69c38d204f4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2944d0ab-3f38-4d75-ad25-09929539c900
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c135f6d0-faf3-4adc-88e1-fe647f1d4037
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 02ae3176-16a1-454b-bfb7-f1ae1e491b1d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 32a628be-18e4-4531-8760-e85b9650e7df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2d767c34-11d1-48a0-aa5d-221436daa3af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5059927d-3269-4256-ae0b-c4f13b896a41
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c8195686-d3ec-4b33-ba1f-080e922d52e9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0f0aa43b-0655-49d9-9686-7f3925bcd830
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 82135a80-142e-490b-932b-0051aedab282
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d63cdd96-61e8-4c4b-9f60-fe8c47cdbeee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 73d0a3c6-d1b7-4831-a5bf-bcd30149e1c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8bfa2544-8b43-426d-9a60-0acd8c6718ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 47728ea1-c933-4be4-b955-46607cedbfcd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b931fe09-b41f-470e-b539-1ec8ef62a314
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8a896b08-f7bf-4068-a466-9a8cd3ff2262
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 65e2f25e-3d09-4246-81e7-5f5b3b976df5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f3a7b113-cc32-40d5-bc1a-65dcb2f56ffa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 764a2236-e011-4088-8a6c-ccbf215d12a0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 29760bd4-dd6a-45a5-9916-c5273f083d9b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5f753d60-ad33-41e2-b622-f66b56070a2b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 76ae7b88-18e8-41d9-9886-937941a1ba1d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cda1582a-cf72-4562-9279-5ebe65162b16
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c23ecb5f-f201-4478-bca6-266eea5f9002
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5e2cb889-26a5-4972-bde7-58d2825255ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f9b8f2c0-a6f6-4bb0-bc38-fb3b2e9865d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ec8b6024-7f5f-49d5-b311-921cdc7dd3a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c0ac4da7-2545-49e9-a0f6-f5451ca2bcf1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 37754877-d419-40ac-baf8-c0b6d912e606
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bac6d47b-4e76-4b95-acbb-21ff49284595
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bb184f15-09ff-4d70-b391-106c975ab137
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6fdf9457-1caa-4220-81e4-6ec2c6f478b6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9e343bcc-d3fc-4e09-946f-2996de8e168d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 27919e1a-c84d-4333-8833-8f3da74596a9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d0ca5bc5-cda6-430b-b625-e30e38411fc4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e132eb9b-dfd3-46c9-b44a-2b2fa12806c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 97c0efba-7767-434d-9396-a844933790bd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 17716595-9f20-40a8-9ed6-adda30ac7707
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 76117931-1463-4e86-987d-e7de5ab1a543
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1557bb5c-1495-48ff-9cbf-972a668201d5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9eafcac3-d152-4742-9d65-f2374f5dec60
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 954d99af-7685-4f1e-b597-cf2acb8b3c64
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f5fa43f6-ce1c-4809-9364-be8ea1a99d4a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b2200626-db9d-4751-a5ef-cf1c46c5ff40
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1c96ee29-e978-40b5-8799-86c71b2215f3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fd624c06-80db-488a-903f-37c2aba9b661
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c7783b6d-d6b1-4acf-9f05-93b23b9c9d15
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7b7bd179-e44b-471a-886e-a67ad751ddb9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0c364dba-e053-4278-9855-2b9fac0445ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 63c136fb-5ea8-48b9-8f92-8ac25db70ce8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 31b66b54-3e28-4267-9a9c-b389c36f7536
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6b11022e-50b0-4110-b106-d148e816c7e5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 91c8327c-fcf4-4574-bbe7-f76ebf940fa4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e03d199d-458a-403a-9e46-bd045a5c1449
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 87c04fd0-b916-4831-9169-66026daa70f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e8c23439-f313-4079-98bb-6cd9b718b5b7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0d46cead-832f-430a-9744-683e671ee8e5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 89300a6f-c09c-42cc-b911-9f8d1d5810b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message daf08d15-8583-4856-96fe-acd2ab3975b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 71687fcb-329e-47e4-8345-07d2e407577f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 94eb77e5-defe-4abb-84f2-b4e9fb06058a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 822a8460-1a2d-460c-b72f-879404d9cfcc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cd0f3967-e21b-4902-b3cc-e66195e70b3e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6b66a14f-74f6-426b-8171-c08f4fc9f411
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0c2a2d7e-a1c0-4ec1-a207-9fb500564c51
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 63d9a8ce-f455-488c-8b40-c7be8dfe1af9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a8ee933a-f45a-49c0-84b0-7712fa65e0a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 99f27d62-264e-40a5-8d95-534ae1bdc8b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9ee7c4d0-a2a7-42c8-8e87-f31df2a145fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 35b38832-cf96-4930-8a8f-2f42d5b42e7b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1867eecd-5819-43e9-be45-2f387898ae11
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f06f515b-2cca-448e-90e3-b01ce84c10e8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b21902fe-7f39-489a-a3f4-d38d39847a62
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fac21247-fb25-469b-a067-01eda19f5730
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 52ebab52-97e9-4315-8df4-7ddad52ebce7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b9d98da3-3271-48bd-9a3b-055f9cb6a4c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 16239636-2b59-47ef-8b0b-dd199376594c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7dca36f9-2af3-4bb8-911a-816744fd1b15
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c86373e9-1f35-40c9-9287-41b4f1c68424
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 80d43e01-1aac-4220-802e-1f79de4a865c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c56255f6-83f3-4fdb-97e7-735dc1ec4ada
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 302506bc-e569-4af4-a279-03ce2d92e6e8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b133a7dc-61cd-4b51-858b-d8bc4e766e97
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5c3e59ec-978b-4041-8d4e-bc8ee91bec1d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 69c15ba2-ca1c-41f0-afde-5ca7ec2f5dd8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0197781f-eebd-41c3-87ec-a60ec7a2228b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f98b75a3-78bf-4138-a504-7045c9f11465
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 83feee54-a2be-46b0-859e-eb3369c8a1de
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 413871d1-b884-45f2-99fa-4066bbc143dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f645f121-9325-4dd4-b785-3bbdcdb76985
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 593f9969-32e5-419e-8c1a-2d8534bcaeee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 630f9b70-5530-4763-bab7-e5e89dff3618
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3d6db843-177f-465d-8c3d-9a6c49b72069
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4d6e9cdd-3ef6-4229-8e5a-069d2353757e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3d562751-c820-4d9f-991f-d4fdbc139b5e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e475b459-b61a-4cd8-bd1e-c0153d95b2c3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2ba2b2a4-2e72-4ce9-9a1a-1451f663bacc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9296ca13-1c18-4b4f-9c3e-c781da6c7295
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ce67f584-0b25-45c3-8efe-7a9d8c135c4b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6678ffa0-0fa2-4c5c-b63e-60f045a3b403
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7ad075ca-fb61-4bd2-94d2-df213fe7e3f7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3c3bc998-f349-40a7-bcb6-3540106bc55e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 78cec1f9-d11b-4b9b-b7e6-7c2573c4030a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3cde4fbe-cb50-47c6-9a7f-3dc2137be48c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d5f39c87-d5dd-4f7b-b3f5-f5b29ba3564b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ab6a9c6e-5da6-4e70-8c88-70f567928d99
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 510d85b8-7eaf-48a7-ab0a-96fc6de63224
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 24708229-c857-40df-8703-72b4e096ed56
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 40ed8749-ce43-4443-a614-8549c410865a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f8bb4883-d7e6-4b9d-851e-1977a8315f4a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 88aac843-6bce-41b8-a984-e94ec6accb75
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a4f4054c-a1ea-4b8b-972b-0e8bf7d75217
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fcb12b0b-40cd-41ee-9602-2ccd12090928
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7692abcd-f3f8-4a0d-9bc0-c9d79e7cfae7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 98a2dd9e-c802-4ed5-bcde-e2d025e97b21
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 682be49d-8cf5-4351-8153-7e479e6627a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f40a2a1a-412e-4a78-8856-ce9d9e86af4b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 235cc3ad-f89c-4f6d-9552-2a1553ac8625
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e5f80a9d-ff76-4cbe-9412-02d7d5d8909e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e9e6c90f-c586-44bd-94e2-f8819ff46da0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 44e51937-f35e-4d38-81cf-627d80c1a017
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8160e645-e8d8-4a5b-8859-7de592f1c342
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2a2e6eb2-97b0-45cf-9607-8e5e80180bd8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b3078e81-0291-4d2e-a762-193bd6c9cb11
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0c6ba3f3-1dfe-4c06-b121-65b6010290f6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9da7ca75-6b7d-44cc-9830-26bb0dcdeaf7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3efb5009-507d-47d7-889c-ae053c784beb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a7f5c2ab-20a4-4b1e-90d3-c1894cf3632d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d225b355-898b-4860-a48f-da2e47aa15f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 688ecaf1-8e80-4444-9ba0-dafb0ae0d8e1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 19ed2411-64cb-4720-afd9-d06e5d0c1899
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a0ce702d-65a0-435e-b737-6ba82ab09a0d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 224c7575-26fa-4686-8cf2-08d309a751cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 936983ad-0fbf-46a3-987c-8c684a6467c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7ec05506-bd29-42e0-9952-2a3bb3d124f3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 06a3c98e-92ae-4ad9-8e95-d3f6e63fda62
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6c4bca20-00ad-4784-ab6d-2d3ce0c3e52d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f857fed5-a59a-4a44-a059-85ebf025cb68
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 75902d97-19fb-4df8-b5dc-ec8e34475fab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9e0dbfb1-914d-43e6-a74d-3361c3a34343
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6953de30-676a-41e8-b3be-c7a609a0f674
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3a929cc5-7064-40ba-8e01-d7bf293ca542
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9fab1518-fcfa-4ef3-b33d-9ce83528cf0b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 89bc2e6a-fca2-4d38-9473-d907896e0872
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 065f0f67-6b41-4723-b7b4-27bd22cefe26
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6e2e889c-426b-4ea5-b381-e3524b18f3ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5698ee6c-425a-49a6-b502-f354eb6b0008
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 233b311d-a3f9-42e6-88a2-67dadba958c5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d733fd50-8917-4a58-8edf-a7085d2f5060
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message df92af14-a536-43c7-9e34-401f30de78fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 83ba4b4a-3014-41dd-b244-4936b1948a4e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0fe7039b-f7b4-4add-bcc7-1de72c1a9174
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5f9e8589-ba63-4204-989f-c73e3835cd23
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e8f73e5f-a96f-4e88-a4f0-a25602b1b2e6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 37d587e3-7c1a-4be6-bd9b-7c0542b1957d
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8687 {grpc_status:14, grpc_message:"Socket closed"}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_21
Server: localhost:8687
Algorithm: FEDAVG
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_21
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_21/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_21/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_21/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_21/test_labels.txt

📊 Raw data loaded:
   Train: X=(1494, 24), y=(1494,)
   Test:  X=(374, 24), y=(374,)

⚠️  Limiting training data: 1494 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  365 samples, 5 features
✅ Client client_21 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

============================================================
🔄 Round 3 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0862 (↓), lr=0.001000
   • Epoch   2/100: train=0.0834, val=0.0865, patience=1/15, lr=0.001000
   • Epoch   3/100: train=0.0833, val=0.0864, patience=2/15, lr=0.001000
   • Epoch   4/100: train=0.0832, val=0.0864, patience=3/15, lr=0.001000
   • Epoch   5/100: train=0.0830, val=0.0865, patience=4/15, lr=0.001000
   📉 Epoch 7: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0816, val=0.0871, patience=10/15, lr=0.000500
   📉 Epoch 15: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 3 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0834, RMSE=0.2887, R²=-0.0002
   Val:   Loss=0.0862, RMSE=0.2936, R²=-0.0260
============================================================


📊 Round 3 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2486, R²: -0.0197

📊 Round 3 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2500, R²: -0.0274

============================================================
🔄 Round 8 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0887, val=0.0765 (↓), lr=0.000250
   • Epoch   2/100: train=0.0878, val=0.0762, patience=1/15, lr=0.000250
   • Epoch   3/100: train=0.0873, val=0.0763, patience=2/15, lr=0.000250
   • Epoch   4/100: train=0.0870, val=0.0763, patience=3/15, lr=0.000250
   • Epoch   5/100: train=0.0868, val=0.0763, patience=4/15, lr=0.000250
   📉 Epoch 8: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0856, val=0.0761, patience=10/15, lr=0.000125
   📉 Epoch 16: LR reduced 0.000125 → 0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0765)

============================================================
📊 Round 8 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000250 → 0.000063 (2 reductions)
   Train: Loss=0.0875, RMSE=0.2958, R²=-0.0210
   Val:   Loss=0.0765, RMSE=0.2765, R²=-0.0347
============================================================


============================================================
🔄 Round 10 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0840 (↓), lr=0.000063
   • Epoch   2/100: train=0.0864, val=0.0838, patience=1/15, lr=0.000063
   • Epoch   3/100: train=0.0861, val=0.0836, patience=2/15, lr=0.000063
   • Epoch   4/100: train=0.0859, val=0.0835, patience=3/15, lr=0.000063
   • Epoch   5/100: train=0.0858, val=0.0835, patience=4/15, lr=0.000063
   📉 Epoch 8: LR reduced 0.000063 → 0.000031
   • Epoch  11/100: train=0.0853, val=0.0835, patience=5/15, lr=0.000031
   📉 Epoch 16: LR reduced 0.000031 → 0.000016
   • Epoch  21/100: train=0.0850, val=0.0835, patience=15/15, lr=0.000016

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 10 Summary - Client client_21
   Epochs: 21/100 (early stopped)
   LR: 0.000063 → 0.000016 (2 reductions)
   Train: Loss=0.0855, RMSE=0.2924, R²=-0.0177
   Val:   Loss=0.0835, RMSE=0.2889, R²=-0.0235
============================================================


📊 Round 10 Test Metrics:
   Loss: 0.0835, RMSE: 0.2889, MAE: 0.2499, R²: -0.0262

============================================================
🔄 Round 11 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000016
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0874, val=0.0817 (↓), lr=0.000016
   • Epoch   2/100: train=0.0873, val=0.0817, patience=1/15, lr=0.000016
   📉 Epoch 3: LR reduced 0.000016 → 0.000008
   • Epoch   3/100: train=0.0872, val=0.0817, patience=2/15, lr=0.000008
   • Epoch   4/100: train=0.0872, val=0.0817, patience=3/15, lr=0.000008
   • Epoch   5/100: train=0.0871, val=0.0817, patience=4/15, lr=0.000008
   📉 Epoch 11: LR reduced 0.000008 → 0.000004
   • Epoch  11/100: train=0.0868, val=0.0818, patience=10/15, lr=0.000004

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 11 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000016 → 0.000004 (2 reductions)
   Train: Loss=0.0872, RMSE=0.2952, R²=-0.0316
   Val:   Loss=0.0817, RMSE=0.2859, R²=-0.0294
============================================================


============================================================
🔄 Round 12 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000004
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0963 (↓), lr=0.000004
   • Epoch   2/100: train=0.0831, val=0.0963, patience=1/15, lr=0.000004
   📉 Epoch 3: LR reduced 0.000004 → 0.000002
   • Epoch   3/100: train=0.0831, val=0.0963, patience=2/15, lr=0.000002
   • Epoch   4/100: train=0.0831, val=0.0963, patience=3/15, lr=0.000002
   • Epoch   5/100: train=0.0831, val=0.0963, patience=4/15, lr=0.000002
   📉 Epoch 11: LR reduced 0.000002 → 0.000001
   • Epoch  11/100: train=0.0830, val=0.0963, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0963)

============================================================
📊 Round 12 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000004 → 0.000001 (2 reductions)
   Train: Loss=0.0834, RMSE=0.2887, R²=-0.0300
   Val:   Loss=0.0963, RMSE=0.3103, R²=-0.0313
============================================================


============================================================
🔄 Round 14 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0868 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0868, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0868, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0868, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0868, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0869, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0868)

============================================================
📊 Round 14 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2930, R²=-0.0304
   Val:   Loss=0.0868, RMSE=0.2947, R²=-0.0312
============================================================


📊 Round 14 Test Metrics:
   Loss: 0.0834, RMSE: 0.2888, MAE: 0.2498, R²: -0.0258

============================================================
🔄 Round 15 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0872, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0872, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0872, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0872, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0872, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0871, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 15 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0871, RMSE=0.2952, R²=-0.0353
   Val:   Loss=0.0824, RMSE=0.2870, R²=-0.0210
============================================================


============================================================
🔄 Round 16 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0938 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0938, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0938, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0938, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0938, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0938, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0938)

============================================================
📊 Round 16 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=-0.0377
   Val:   Loss=0.0938, RMSE=0.3063, R²=-0.0215
============================================================


============================================================
🔄 Round 18 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0924 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0924, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0924, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0924, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0924, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0924, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0924)

============================================================
📊 Round 18 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2908, R²=-0.0290
   Val:   Loss=0.0924, RMSE=0.3040, R²=-0.0400
============================================================


============================================================
🔄 Round 19 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 19 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2942, R²=-0.0348
   Val:   Loss=0.0846, RMSE=0.2908, R²=-0.0315
============================================================


============================================================
🔄 Round 20 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0883, val=0.0772 (↓), lr=0.000001
   • Epoch   2/100: train=0.0883, val=0.0772, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0883, val=0.0772, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0883, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0883, val=0.0773, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0882, val=0.0773, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 20 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0884, RMSE=0.2972, R²=-0.0309
   Val:   Loss=0.0772, RMSE=0.2779, R²=-0.0573
============================================================


📊 Round 20 Test Metrics:
   Loss: 0.0834, RMSE: 0.2888, MAE: 0.2498, R²: -0.0257

============================================================
🔄 Round 22 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0873 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0873, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0873, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0873, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0873, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0873, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0873)

============================================================
📊 Round 22 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2932, R²=-0.0339
   Val:   Loss=0.0873, RMSE=0.2955, R²=-0.0256
============================================================


📊 Round 22 Test Metrics:
   Loss: 0.0834, RMSE: 0.2889, MAE: 0.2499, R²: -0.0258

📊 Round 22 Test Metrics:
   Loss: 0.0834, RMSE: 0.2889, MAE: 0.2499, R²: -0.0259

============================================================
🔄 Round 27 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0936 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0936, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0936, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0936, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0936, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0936, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0936)

============================================================
📊 Round 27 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=-0.0343
   Val:   Loss=0.0936, RMSE=0.3060, R²=-0.0313
============================================================


============================================================
🔄 Round 28 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0871, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0871, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0871, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0871, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0871, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0870, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 28 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0870, RMSE=0.2949, R²=-0.0317
   Val:   Loss=0.0833, RMSE=0.2886, R²=-0.0389
============================================================


📊 Round 28 Test Metrics:
   Loss: 0.0835, RMSE: 0.2889, MAE: 0.2499, R²: -0.0260

============================================================
🔄 Round 30 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0869, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0869, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0869, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0869, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0869, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0869, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 30 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2947, R²=-0.0353
   Val:   Loss=0.0838, RMSE=0.2894, R²=-0.0204
============================================================


📊 Round 30 Test Metrics:
   Loss: 0.0835, RMSE: 0.2889, MAE: 0.2499, R²: -0.0259

============================================================
🔄 Round 32 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0883 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0883, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0883, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0883, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0883, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0882, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0883)

============================================================
📊 Round 32 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2928, R²=-0.0268
   Val:   Loss=0.0883, RMSE=0.2971, R²=-0.0579
============================================================


============================================================
🔄 Round 33 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 33 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2941, R²=-0.0351
   Val:   Loss=0.0852, RMSE=0.2919, R²=-0.0235
============================================================


📊 Round 33 Test Metrics:
   Loss: 0.0834, RMSE: 0.2889, MAE: 0.2499, R²: -0.0259

============================================================
🔄 Round 34 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 34 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2942, R²=-0.0354
   Val:   Loss=0.0850, RMSE=0.2915, R²=-0.0263
============================================================


============================================================
🔄 Round 35 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0870, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0870, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0870, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0870, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0870, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0869, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 35 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0871, RMSE=0.2951, R²=-0.0382
   Val:   Loss=0.0828, RMSE=0.2878, R²=-0.0178
============================================================


📊 Round 35 Test Metrics:
   Loss: 0.0835, RMSE: 0.2889, MAE: 0.2499, R²: -0.0260

============================================================
🔄 Round 37 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 37 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2939, R²=-0.0338
   Val:   Loss=0.0857, RMSE=0.2927, R²=-0.0376
============================================================


📊 Round 37 Test Metrics:
   Loss: 0.0835, RMSE: 0.2889, MAE: 0.2499, R²: -0.0260

📊 Round 37 Test Metrics:
   Loss: 0.0835, RMSE: 0.2889, MAE: 0.2499, R²: -0.0260

📊 Round 37 Test Metrics:
   Loss: 0.0834, RMSE: 0.2889, MAE: 0.2499, R²: -0.0259

============================================================
🔄 Round 44 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0891 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0891, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0891, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0891, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0891, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0891, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0891)

============================================================
📊 Round 44 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2924, R²=-0.0385
   Val:   Loss=0.0891, RMSE=0.2985, R²=-0.0235
============================================================


============================================================
🔄 Round 45 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0877 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0877, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0877, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0877, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0876, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0876, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0877)

============================================================
📊 Round 45 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2931, R²=-0.0255
   Val:   Loss=0.0877, RMSE=0.2961, R²=-0.0613
============================================================


📊 Round 45 Test Metrics:
   Loss: 0.0835, RMSE: 0.2889, MAE: 0.2499, R²: -0.0259

📊 Round 45 Test Metrics:
   Loss: 0.0835, RMSE: 0.2889, MAE: 0.2499, R²: -0.0260

============================================================
🔄 Round 50 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0923 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0923, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0923, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0923, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0923, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0922, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0923)

============================================================
📊 Round 50 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2911, R²=-0.0240
   Val:   Loss=0.0923, RMSE=0.3038, R²=-0.0688
============================================================


📊 Round 50 Test Metrics:
   Loss: 0.0835, RMSE: 0.2889, MAE: 0.2499, R²: -0.0260

============================================================
🔄 Round 52 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0874, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0874, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0874, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0874, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0874, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0873, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 52 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0874, RMSE=0.2956, R²=-0.0341
   Val:   Loss=0.0816, RMSE=0.2857, R²=-0.0268
============================================================


============================================================
🔄 Round 53 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0897 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0897, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0897, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0897, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0897, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0897, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0897)

============================================================
📊 Round 53 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2922, R²=-0.0297
   Val:   Loss=0.0897, RMSE=0.2996, R²=-0.0455
============================================================


============================================================
🔄 Round 54 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0872, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0872, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0872, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0871, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0871, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0871, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 54 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0873, RMSE=0.2955, R²=-0.0385
   Val:   Loss=0.0819, RMSE=0.2862, R²=-0.0090
============================================================


============================================================
🔄 Round 55 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0895 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0895, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0895, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0895, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0895, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0895, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0895)

============================================================
📊 Round 55 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2923, R²=-0.0339
   Val:   Loss=0.0895, RMSE=0.2992, R²=-0.0275
============================================================


📊 Round 55 Test Metrics:
   Loss: 0.0835, RMSE: 0.2889, MAE: 0.2499, R²: -0.0260

============================================================
🔄 Round 59 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0905 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0905, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0905, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0905, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0905, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0905, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0905)

============================================================
📊 Round 59 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2918, R²=-0.0275
   Val:   Loss=0.0905, RMSE=0.3009, R²=-0.0525
============================================================


============================================================
🔄 Round 63 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0906 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0906, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0906, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0906, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0906, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0906, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0906)

============================================================
📊 Round 63 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2918, R²=-0.0378
   Val:   Loss=0.0906, RMSE=0.3010, R²=-0.0160
============================================================


📊 Round 63 Test Metrics:
   Loss: 0.0835, RMSE: 0.2889, MAE: 0.2499, R²: -0.0260

📊 Round 63 Test Metrics:
   Loss: 0.0835, RMSE: 0.2889, MAE: 0.2499, R²: -0.0260

============================================================
🔄 Round 66 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0875 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0875, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0875, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0875, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0875, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0875, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0875)

============================================================
📊 Round 66 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2931, R²=-0.0252
   Val:   Loss=0.0875, RMSE=0.2958, R²=-0.0705
============================================================


📊 Round 66 Test Metrics:
   Loss: 0.0834, RMSE: 0.2889, MAE: 0.2499, R²: -0.0259

============================================================
🔄 Round 67 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0869, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0869, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0869, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0869, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0869, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0869, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 67 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0870, RMSE=0.2950, R²=-0.0348
   Val:   Loss=0.0832, RMSE=0.2884, R²=-0.0246
============================================================


📊 Round 67 Test Metrics:
   Loss: 0.0834, RMSE: 0.2889, MAE: 0.2499, R²: -0.0259

============================================================
🔄 Round 68 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0902 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0902, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0902, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0902, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0902, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0902, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0902)

============================================================
📊 Round 68 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2920, R²=-0.0332
   Val:   Loss=0.0902, RMSE=0.3003, R²=-0.0461
============================================================


============================================================
🔄 Round 70 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0872, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0872, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0872, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0872, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0872, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0871, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 70 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0874, RMSE=0.2956, R²=-0.0382
   Val:   Loss=0.0817, RMSE=0.2858, R²=-0.0210
============================================================


📊 Round 70 Test Metrics:
   Loss: 0.0834, RMSE: 0.2889, MAE: 0.2499, R²: -0.0259

============================================================
🔄 Round 72 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 72 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0867, RMSE=0.2945, R²=-0.0311
   Val:   Loss=0.0843, RMSE=0.2903, R²=-0.0386
============================================================


📊 Round 72 Test Metrics:
   Loss: 0.0834, RMSE: 0.2889, MAE: 0.2499, R²: -0.0259

📊 Round 72 Test Metrics:
   Loss: 0.0834, RMSE: 0.2889, MAE: 0.2499, R²: -0.0259

============================================================
🔄 Round 74 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0904 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0904, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0904, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0904, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0904, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0903, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0904)

============================================================
📊 Round 74 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2919, R²=-0.0377
   Val:   Loss=0.0904, RMSE=0.3006, R²=-0.0141
============================================================


📊 Round 74 Test Metrics:
   Loss: 0.0834, RMSE: 0.2889, MAE: 0.2499, R²: -0.0259

📊 Round 74 Test Metrics:
   Loss: 0.0834, RMSE: 0.2889, MAE: 0.2499, R²: -0.0258

============================================================
🔄 Round 82 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0870 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0870, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0870, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0870, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0870, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0869, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 82 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2934, R²=-0.0273
   Val:   Loss=0.0870, RMSE=0.2950, R²=-0.0560
============================================================


📊 Round 82 Test Metrics:
   Loss: 0.0834, RMSE: 0.2889, MAE: 0.2499, R²: -0.0259

============================================================
🔄 Round 83 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0879 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0879, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0879, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0879, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0879, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0879, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0879)

============================================================
📊 Round 83 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2930, R²=-0.0292
   Val:   Loss=0.0879, RMSE=0.2965, R²=-0.0467
============================================================


============================================================
🔄 Round 84 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0869, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0868, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0868, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0868, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0868, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0868, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 84 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2947, R²=-0.0316
   Val:   Loss=0.0840, RMSE=0.2898, R²=-0.0470
============================================================


📊 Round 84 Test Metrics:
   Loss: 0.0834, RMSE: 0.2889, MAE: 0.2499, R²: -0.0258

============================================================
🔄 Round 85 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0920 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0920, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0920, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0920, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0920, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0920, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0920)

============================================================
📊 Round 85 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=-0.0307
   Val:   Loss=0.0920, RMSE=0.3034, R²=-0.0431
============================================================


📊 Round 85 Test Metrics:
   Loss: 0.0834, RMSE: 0.2889, MAE: 0.2499, R²: -0.0258

============================================================
🔄 Round 89 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0946 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0946, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0946, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0946, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0946, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0946, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0946)

============================================================
📊 Round 89 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2901, R²=-0.0255
   Val:   Loss=0.0946, RMSE=0.3076, R²=-0.0592
============================================================


📊 Round 89 Test Metrics:
   Loss: 0.0834, RMSE: 0.2889, MAE: 0.2499, R²: -0.0258

📊 Round 89 Test Metrics:
   Loss: 0.0834, RMSE: 0.2889, MAE: 0.2499, R²: -0.0258

============================================================
🔄 Round 91 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0910 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0910, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0910, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0910, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0910, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0909, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0910)

============================================================
📊 Round 91 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2917, R²=-0.0313
   Val:   Loss=0.0910, RMSE=0.3016, R²=-0.0385
============================================================


============================================================
🔄 Round 92 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 92 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2941, R²=-0.0286
   Val:   Loss=0.0854, RMSE=0.2922, R²=-0.0507
============================================================


📊 Round 92 Test Metrics:
   Loss: 0.0834, RMSE: 0.2888, MAE: 0.2499, R²: -0.0257

📊 Round 92 Test Metrics:
   Loss: 0.0834, RMSE: 0.2889, MAE: 0.2499, R²: -0.0258

📊 Round 92 Test Metrics:
   Loss: 0.0834, RMSE: 0.2889, MAE: 0.2499, R²: -0.0258

📊 Round 92 Test Metrics:
   Loss: 0.0834, RMSE: 0.2888, MAE: 0.2499, R²: -0.0257

📊 Round 92 Test Metrics:
   Loss: 0.0834, RMSE: 0.2888, MAE: 0.2499, R²: -0.0257

📊 Round 92 Test Metrics:
   Loss: 0.0834, RMSE: 0.2888, MAE: 0.2499, R²: -0.0257

============================================================
🔄 Round 102 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0928 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0928, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0928, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0928, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0927, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0927, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0928)

============================================================
📊 Round 102 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=-0.0297
   Val:   Loss=0.0928, RMSE=0.3046, R²=-0.0529
============================================================


📊 Round 102 Test Metrics:
   Loss: 0.0834, RMSE: 0.2888, MAE: 0.2499, R²: -0.0256

============================================================
🔄 Round 105 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0874, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0874, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0874, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0874, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0874, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0873, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 105 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0874, RMSE=0.2956, R²=-0.0330
   Val:   Loss=0.0817, RMSE=0.2858, R²=-0.0322
============================================================


📊 Round 105 Test Metrics:
   Loss: 0.0834, RMSE: 0.2888, MAE: 0.2499, R²: -0.0256

============================================================
🔄 Round 108 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0900 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0900, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0900, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0900, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0900, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0900, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0900)

============================================================
📊 Round 108 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2921, R²=-0.0320
   Val:   Loss=0.0900, RMSE=0.3000, R²=-0.0413
============================================================


📊 Round 108 Test Metrics:
   Loss: 0.0834, RMSE: 0.2888, MAE: 0.2499, R²: -0.0256

📊 Round 108 Test Metrics:
   Loss: 0.0834, RMSE: 0.2888, MAE: 0.2499, R²: -0.0257

📊 Round 108 Test Metrics:
   Loss: 0.0834, RMSE: 0.2888, MAE: 0.2499, R²: -0.0256

============================================================
🔄 Round 114 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0885, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0885, val=0.0777, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0885, val=0.0777, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0885, val=0.0777, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0885, val=0.0777, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0884, val=0.0777, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 114 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0884, RMSE=0.2973, R²=-0.0392
   Val:   Loss=0.0778, RMSE=0.2788, R²=-0.0051
============================================================


📊 Round 114 Test Metrics:
   Loss: 0.0834, RMSE: 0.2888, MAE: 0.2499, R²: -0.0256

📊 Round 114 Test Metrics:
   Loss: 0.0834, RMSE: 0.2888, MAE: 0.2499, R²: -0.0256

📊 Round 114 Test Metrics:
   Loss: 0.0834, RMSE: 0.2888, MAE: 0.2499, R²: -0.0256

📊 Round 114 Test Metrics:
   Loss: 0.0834, RMSE: 0.2888, MAE: 0.2499, R²: -0.0255

📊 Round 114 Test Metrics:
   Loss: 0.0834, RMSE: 0.2888, MAE: 0.2499, R²: -0.0255

📊 Round 114 Test Metrics:
   Loss: 0.0834, RMSE: 0.2888, MAE: 0.2499, R²: -0.0255

============================================================
🔄 Round 122 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0868 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0868, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0868, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0868, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0868, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0867, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0868)

============================================================
📊 Round 122 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2935, R²=-0.0247
   Val:   Loss=0.0868, RMSE=0.2946, R²=-0.0778
============================================================


============================================================
🔄 Round 123 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0972 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0972, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0972, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0972, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0972, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0972, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0972)

============================================================
📊 Round 123 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=-0.0334
   Val:   Loss=0.0972, RMSE=0.3118, R²=-0.0314
============================================================


📊 Round 123 Test Metrics:
   Loss: 0.0834, RMSE: 0.2888, MAE: 0.2499, R²: -0.0255

============================================================
🔄 Round 124 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0882, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0882, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0882, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0882, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0882, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0882, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 124 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0882, RMSE=0.2971, R²=-0.0352
   Val:   Loss=0.0784, RMSE=0.2800, R²=-0.0271
============================================================


📊 Round 124 Test Metrics:
   Loss: 0.0834, RMSE: 0.2888, MAE: 0.2499, R²: -0.0255

📊 Round 124 Test Metrics:
   Loss: 0.0834, RMSE: 0.2888, MAE: 0.2499, R²: -0.0255

============================================================
🔄 Round 126 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0904 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0904, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0904, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0904, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0904, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0904, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0904)

============================================================
📊 Round 126 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2920, R²=-0.0295
   Val:   Loss=0.0904, RMSE=0.3006, R²=-0.0496
============================================================


📊 Round 126 Test Metrics:
   Loss: 0.0834, RMSE: 0.2888, MAE: 0.2499, R²: -0.0255

============================================================
🔄 Round 127 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0894 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0894, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0894, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0894, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0894, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0893, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0894)

============================================================
📊 Round 127 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2924, R²=-0.0356
   Val:   Loss=0.0894, RMSE=0.2989, R²=-0.0264
============================================================


📊 Round 127 Test Metrics:
   Loss: 0.0834, RMSE: 0.2888, MAE: 0.2499, R²: -0.0256

📊 Round 127 Test Metrics:
   Loss: 0.0834, RMSE: 0.2888, MAE: 0.2499, R²: -0.0256

📊 Round 127 Test Metrics:
   Loss: 0.0834, RMSE: 0.2888, MAE: 0.2499, R²: -0.0257

📊 Round 127 Test Metrics:
   Loss: 0.0834, RMSE: 0.2888, MAE: 0.2499, R²: -0.0257

📊 Round 127 Test Metrics:
   Loss: 0.0834, RMSE: 0.2888, MAE: 0.2499, R²: -0.0257

============================================================
🔄 Round 135 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0869, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0869, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0869, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0869, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0869, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0868, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 135 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2943, R²=-0.0347
   Val:   Loss=0.0848, RMSE=0.2912, R²=-0.0560
============================================================


📊 Round 135 Test Metrics:
   Loss: 0.0834, RMSE: 0.2889, MAE: 0.2499, R²: -0.0258

============================================================
🔄 Round 138 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0876, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0876, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0876, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0876, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0876, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0876, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 138 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0875, RMSE=0.2959, R²=-0.0336
   Val:   Loss=0.0812, RMSE=0.2850, R²=-0.0367
============================================================


📊 Round 138 Test Metrics:
   Loss: 0.0834, RMSE: 0.2888, MAE: 0.2499, R²: -0.0257

============================================================
🔄 Round 140 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0976 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0976, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0976, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0975, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0975, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0975, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0976)

============================================================
📊 Round 140 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=-0.0293
   Val:   Loss=0.0976, RMSE=0.3124, R²=-0.0455
============================================================


============================================================
🔄 Round 141 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0887 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0887, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0887, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0887, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0886, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0886, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0887)

============================================================
📊 Round 141 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2927, R²=-0.0342
   Val:   Loss=0.0887, RMSE=0.2978, R²=-0.0333
============================================================


============================================================
🔄 Round 142 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0875 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0875, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0875, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0875, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0875, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0875, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0875)

============================================================
📊 Round 142 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2932, R²=-0.0382
   Val:   Loss=0.0875, RMSE=0.2959, R²=-0.0128
============================================================


📊 Round 142 Test Metrics:
   Loss: 0.0834, RMSE: 0.2888, MAE: 0.2499, R²: -0.0257

============================================================
🔄 Round 143 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0869, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0869, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0869, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0869, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0869, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0868, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 143 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2947, R²=-0.0373
   Val:   Loss=0.0840, RMSE=0.2899, R²=-0.0181
============================================================


============================================================
🔄 Round 144 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0889, val=0.0741 (↓), lr=0.000001
   • Epoch   2/100: train=0.0889, val=0.0741, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0889, val=0.0741, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0889, val=0.0741, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0889, val=0.0741, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0889, val=0.0741, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0741)

============================================================
📊 Round 144 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0893, RMSE=0.2988, R²=-0.0292
   Val:   Loss=0.0741, RMSE=0.2723, R²=-0.0555
============================================================


📊 Round 144 Test Metrics:
   Loss: 0.0834, RMSE: 0.2888, MAE: 0.2499, R²: -0.0256

============================================================
🔄 Round 146 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0884, val=0.0772 (↓), lr=0.000001
   • Epoch   2/100: train=0.0884, val=0.0772, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0884, val=0.0772, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0884, val=0.0772, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0884, val=0.0773, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0883, val=0.0773, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 146 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0885, RMSE=0.2975, R²=-0.0346
   Val:   Loss=0.0772, RMSE=0.2779, R²=-0.0291
============================================================


📊 Round 146 Test Metrics:
   Loss: 0.0834, RMSE: 0.2888, MAE: 0.2499, R²: -0.0256

📊 Round 146 Test Metrics:
   Loss: 0.0834, RMSE: 0.2888, MAE: 0.2499, R²: -0.0257

============================================================
🔄 Round 153 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0868 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0868, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0868, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0868, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0868, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0867, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0868)

============================================================
📊 Round 153 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2935, R²=-0.0332
   Val:   Loss=0.0868, RMSE=0.2946, R²=-0.0324
============================================================


📊 Round 153 Test Metrics:
   Loss: 0.0834, RMSE: 0.2888, MAE: 0.2499, R²: -0.0256

============================================================
🔄 Round 156 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0932 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0932, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0932, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0932, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0933, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0933, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0932)

============================================================
📊 Round 156 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2908, R²=-0.0295
   Val:   Loss=0.0932, RMSE=0.3054, R²=-0.0484
============================================================


📊 Round 156 Test Metrics:
   Loss: 0.0834, RMSE: 0.2888, MAE: 0.2499, R²: -0.0256

============================================================
🔄 Round 157 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0886, val=0.0767 (↓), lr=0.000001
   • Epoch   2/100: train=0.0886, val=0.0766, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0886, val=0.0766, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0886, val=0.0766, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0886, val=0.0766, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0886, val=0.0766, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0767)

============================================================
📊 Round 157 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0887, RMSE=0.2978, R²=-0.0355
   Val:   Loss=0.0767, RMSE=0.2769, R²=-0.0217
============================================================


📊 Round 157 Test Metrics:
   Loss: 0.0834, RMSE: 0.2888, MAE: 0.2499, R²: -0.0256

============================================================
🔄 Round 158 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0882, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0882, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0881, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0881, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0881, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0881, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 158 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0882, RMSE=0.2970, R²=-0.0275
   Val:   Loss=0.0785, RMSE=0.2802, R²=-0.0657
============================================================


============================================================
🔄 Round 159 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0884, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0884, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0884, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0884, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0884, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0883, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 159 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0881, RMSE=0.2969, R²=-0.0290
   Val:   Loss=0.0789, RMSE=0.2809, R²=-0.0569
============================================================


📊 Round 159 Test Metrics:
   Loss: 0.0834, RMSE: 0.2888, MAE: 0.2499, R²: -0.0257

============================================================
🔄 Round 163 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0866 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0866, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0866, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0866, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0866, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0866)

============================================================
📊 Round 163 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2936, R²=-0.0299
   Val:   Loss=0.0866, RMSE=0.2943, R²=-0.0549
============================================================


📊 Round 163 Test Metrics:
   Loss: 0.0834, RMSE: 0.2888, MAE: 0.2499, R²: -0.0257

============================================================
🔄 Round 166 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0895, val=0.0733 (↓), lr=0.000001
   • Epoch   2/100: train=0.0895, val=0.0733, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0895, val=0.0733, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0895, val=0.0733, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0895, val=0.0733, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0894, val=0.0732, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0733)

============================================================
📊 Round 166 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0895, RMSE=0.2992, R²=-0.0308
   Val:   Loss=0.0733, RMSE=0.2707, R²=-0.0454
============================================================


============================================================
🔄 Round 169 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0867, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0867, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0867, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0867, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0867, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 169 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0869, RMSE=0.2948, R²=-0.0288
   Val:   Loss=0.0837, RMSE=0.2892, R²=-0.0561
============================================================


============================================================
🔄 Round 170 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0884, val=0.0767 (↓), lr=0.000001
   • Epoch   2/100: train=0.0884, val=0.0767, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0884, val=0.0768, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0884, val=0.0768, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0883, val=0.0768, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0883, val=0.0769, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0767)

============================================================
📊 Round 170 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0887, RMSE=0.2978, R²=-0.0375
   Val:   Loss=0.0767, RMSE=0.2770, R²=-0.0730
============================================================


============================================================
🔄 Round 172 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0901 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0901, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0901, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0901, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0901, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0900, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0901)

============================================================
📊 Round 172 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2921, R²=-0.0345
   Val:   Loss=0.0901, RMSE=0.3001, R²=-0.0280
============================================================


============================================================
🔄 Round 173 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0884, val=0.0776 (↓), lr=0.000001
   • Epoch   2/100: train=0.0883, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0883, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0883, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0883, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0883, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 173 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0885, RMSE=0.2974, R²=-0.0319
   Val:   Loss=0.0776, RMSE=0.2785, R²=-0.0492
============================================================


📊 Round 173 Test Metrics:
   Loss: 0.0834, RMSE: 0.2888, MAE: 0.2499, R²: -0.0257

============================================================
🔄 Round 174 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 174 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0867, RMSE=0.2944, R²=-0.0286
   Val:   Loss=0.0848, RMSE=0.2912, R²=-0.0516
============================================================


📊 Round 174 Test Metrics:
   Loss: 0.0834, RMSE: 0.2888, MAE: 0.2499, R²: -0.0257

============================================================
🔄 Round 177 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0867, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0867, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0867, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0867, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0867, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 177 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0869, RMSE=0.2948, R²=-0.0345
   Val:   Loss=0.0838, RMSE=0.2895, R²=-0.0389
============================================================


📊 Round 177 Test Metrics:
   Loss: 0.0834, RMSE: 0.2888, MAE: 0.2499, R²: -0.0256

📊 Round 177 Test Metrics:
   Loss: 0.0834, RMSE: 0.2888, MAE: 0.2499, R²: -0.0257

============================================================
🔄 Round 180 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0884, val=0.0767 (↓), lr=0.000001
   • Epoch   2/100: train=0.0884, val=0.0767, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0884, val=0.0767, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0884, val=0.0767, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0883, val=0.0767, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0883, val=0.0766, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0767)

============================================================
📊 Round 180 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0887, RMSE=0.2978, R²=-0.0305
   Val:   Loss=0.0767, RMSE=0.2769, R²=-0.0476
============================================================


📊 Round 180 Test Metrics:
   Loss: 0.0834, RMSE: 0.2889, MAE: 0.2499, R²: -0.0258

============================================================
🔄 Round 183 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0874 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0874, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0874, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0874, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0874, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0873, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0874)

============================================================
📊 Round 183 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2933, R²=-0.0329
   Val:   Loss=0.0874, RMSE=0.2956, R²=-0.0352
============================================================


📊 Round 183 Test Metrics:
   Loss: 0.0834, RMSE: 0.2888, MAE: 0.2499, R²: -0.0257

📊 Round 183 Test Metrics:
   Loss: 0.0834, RMSE: 0.2889, MAE: 0.2499, R²: -0.0258

📊 Round 183 Test Metrics:
   Loss: 0.0834, RMSE: 0.2889, MAE: 0.2499, R²: -0.0258

============================================================
🔄 Round 186 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0876 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0876, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0876, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0876, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0876, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0876, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0876)

============================================================
📊 Round 186 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2932, R²=-0.0300
   Val:   Loss=0.0876, RMSE=0.2960, R²=-0.0455
============================================================


📊 Round 186 Test Metrics:
   Loss: 0.0834, RMSE: 0.2889, MAE: 0.2499, R²: -0.0259

📊 Round 186 Test Metrics:
   Loss: 0.0834, RMSE: 0.2889, MAE: 0.2499, R²: -0.0259

============================================================
🔄 Round 190 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0872, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0872, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0872, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0872, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0872, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0872, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 190 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0874, RMSE=0.2956, R²=-0.0274
   Val:   Loss=0.0818, RMSE=0.2860, R²=-0.0586
============================================================


📊 Round 190 Test Metrics:
   Loss: 0.0834, RMSE: 0.2889, MAE: 0.2499, R²: -0.0259

============================================================
🔄 Round 191 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 191 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2938, R²=-0.0307
   Val:   Loss=0.0860, RMSE=0.2933, R²=-0.0467
============================================================


============================================================
🔄 Round 193 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.1014 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.1014, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.1014, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.1014, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.1014, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.1015, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.1014)

============================================================
📊 Round 193 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2873, R²=-0.0269
   Val:   Loss=0.1014, RMSE=0.3184, R²=-0.0849
============================================================


📊 Round 193 Test Metrics:
   Loss: 0.0834, RMSE: 0.2889, MAE: 0.2499, R²: -0.0259

📊 Round 193 Test Metrics:
   Loss: 0.0835, RMSE: 0.2889, MAE: 0.2499, R²: -0.0260

============================================================
🔄 Round 195 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0880, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0880, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0880, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0880, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0880, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0880, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 195 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0880, RMSE=0.2966, R²=-0.0331
   Val:   Loss=0.0795, RMSE=0.2820, R²=-0.0330
============================================================


============================================================
🔄 Round 196 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0925 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0925, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0925, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0925, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0925, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0925, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0925)

============================================================
📊 Round 196 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2911, R²=-0.0267
   Val:   Loss=0.0925, RMSE=0.3042, R²=-0.0583
============================================================


============================================================
🔄 Round 198 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 198 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2942, R²=-0.0383
   Val:   Loss=0.0851, RMSE=0.2917, R²=-0.0347
============================================================


============================================================
🔄 Round 201 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0892 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0892, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0891, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0891, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0891, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0891, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0892)

============================================================
📊 Round 201 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2925, R²=-0.0302
   Val:   Loss=0.0892, RMSE=0.2986, R²=-0.0460
============================================================


📊 Round 201 Test Metrics:
   Loss: 0.0834, RMSE: 0.2889, MAE: 0.2499, R²: -0.0259

📊 Round 201 Test Metrics:
   Loss: 0.0834, RMSE: 0.2889, MAE: 0.2499, R²: -0.0259

📊 Round 201 Test Metrics:
   Loss: 0.0835, RMSE: 0.2889, MAE: 0.2499, R²: -0.0260

📊 Round 201 Test Metrics:
   Loss: 0.0835, RMSE: 0.2889, MAE: 0.2499, R²: -0.0260

📊 Round 201 Test Metrics:
   Loss: 0.0835, RMSE: 0.2889, MAE: 0.2499, R²: -0.0260

============================================================
🔄 Round 207 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0885 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0885, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0885, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0885, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0885, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0885, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0885)

============================================================
📊 Round 207 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2928, R²=-0.0350
   Val:   Loss=0.0885, RMSE=0.2975, R²=-0.0337
============================================================


============================================================
🔄 Round 208 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0954 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0954, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0954, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0954, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0954, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0954, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0954)

============================================================
📊 Round 208 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=-0.0276
   Val:   Loss=0.0954, RMSE=0.3089, R²=-0.0560
============================================================


📊 Round 208 Test Metrics:
   Loss: 0.0835, RMSE: 0.2889, MAE: 0.2499, R²: -0.0260

============================================================
🔄 Round 209 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0872, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0871, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0871, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0871, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0871, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0871, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 209 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0870, RMSE=0.2949, R²=-0.0329
   Val:   Loss=0.0835, RMSE=0.2890, R²=-0.0346
============================================================


📊 Round 209 Test Metrics:
   Loss: 0.0835, RMSE: 0.2889, MAE: 0.2499, R²: -0.0260

📊 Round 209 Test Metrics:
   Loss: 0.0834, RMSE: 0.2889, MAE: 0.2499, R²: -0.0259

============================================================
🔄 Round 214 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0922 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0922, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0922, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0922, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0921, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0921, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0922)

============================================================
📊 Round 214 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2913, R²=-0.0373
   Val:   Loss=0.0922, RMSE=0.3036, R²=-0.0185
============================================================


============================================================
🔄 Round 215 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0924 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0924, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0924, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0924, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0924, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0924, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0924)

============================================================
📊 Round 215 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=-0.0218
   Val:   Loss=0.0924, RMSE=0.3039, R²=-0.0817
============================================================


📊 Round 215 Test Metrics:
   Loss: 0.0835, RMSE: 0.2889, MAE: 0.2499, R²: -0.0260

============================================================
🔄 Round 218 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0897, val=0.0728 (↓), lr=0.000001
   • Epoch   2/100: train=0.0897, val=0.0728, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0897, val=0.0728, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0897, val=0.0728, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0897, val=0.0728, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0896, val=0.0727, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0728)

============================================================
📊 Round 218 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0897, RMSE=0.2994, R²=-0.0291
   Val:   Loss=0.0728, RMSE=0.2698, R²=-0.0576
============================================================


============================================================
🔄 Round 219 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0906 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0906, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0906, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0906, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0906, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0906, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0906)

============================================================
📊 Round 219 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2919, R²=-0.0284
   Val:   Loss=0.0906, RMSE=0.3010, R²=-0.0550
============================================================


============================================================
🔄 Round 220 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0905 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0906, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0906, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0906, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0906, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0907, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0905)

============================================================
📊 Round 220 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2920, R²=-0.0257
   Val:   Loss=0.0905, RMSE=0.3009, R²=-0.0978
============================================================


============================================================
🔄 Round 221 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0916 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0916, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0916, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0916, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0916, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0915, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0916)

============================================================
📊 Round 221 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2915, R²=-0.0321
   Val:   Loss=0.0916, RMSE=0.3027, R²=-0.0384
============================================================


📊 Round 221 Test Metrics:
   Loss: 0.0834, RMSE: 0.2889, MAE: 0.2499, R²: -0.0259

============================================================
🔄 Round 222 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0876, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0876, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0876, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0876, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0876, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0875, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 222 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0876, RMSE=0.2960, R²=-0.0344
   Val:   Loss=0.0809, RMSE=0.2845, R²=-0.0281
============================================================


============================================================
🔄 Round 223 - Client client_21
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0912 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0912, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0912, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0912, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0912, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0911, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0912)

============================================================
📊 Round 223 Summary - Client client_21
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2917, R²=-0.0292
   Val:   Loss=0.0912, RMSE=0.3020, R²=-0.0491
============================================================


📊 Round 223 Test Metrics:
   Loss: 0.0834, RMSE: 0.2889, MAE: 0.2499, R²: -0.0259

📊 Round 223 Test Metrics:
   Loss: 0.0834, RMSE: 0.2889, MAE: 0.2499, R²: -0.0259

❌ Client client_21 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8687 {grpc_status:14, grpc_message:"Socket closed"}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8687 {grpc_status:14, grpc_message:"Socket closed"}"
>
