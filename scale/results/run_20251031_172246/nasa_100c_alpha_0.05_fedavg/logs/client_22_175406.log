[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a1e284d9-6f79-4510-98f2-3ddb8b670338
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4a6c9e1d-8c6f-4ace-832c-2fe0251ad896
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 74a3ceb2-813f-40bc-88a2-f52e0fdac87b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f69f4b88-4ab0-4d40-990e-b8cbea05e8da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 94a41e37-0176-42e9-a67b-118e479e19c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message de320d04-bb45-46b2-b128-9343d854cb43
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dc97f1ec-4d93-42ef-96ed-3b76c969113b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b242fe9e-45bc-476c-94f8-a588a19b244a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a6619f2f-c1a0-4ea9-9d06-7b97c6deac20
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ab37ee18-14fe-40ea-9bc1-3490ba39538c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0d513381-81d6-4b01-939f-060c44022aa0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6088df33-1f89-45be-b4be-c7e3fb977f56
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c75adc02-f250-4bde-9b36-d2ef14f9b89c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 751ecb7c-fc84-41a9-bdcf-356cfe25bc6f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cbf45c7b-13ea-46e5-948d-92e9b66fa186
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 657d59ae-f7e8-4094-984e-707f5e2829c3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 44d08672-9815-44ac-9c13-fd0f71278588
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 00bf7f54-559f-4065-81aa-25ad796b64f3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b3cd1dbe-9a90-414f-8ddb-c72adfa13cba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c7588ca3-00a5-4d8c-9a6b-721b919a6e11
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c62fad50-281a-4906-b0e8-72b7cbc783e2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1256d2f7-115b-442e-bfba-57e6ac5356e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 85e7d4ad-d2ad-4ec6-a199-be77594e0dd0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9b495ad4-c5f4-436e-9fe3-9c3e876f3707
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fe5bc231-acaf-4063-b2c0-17e0deefe364
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 249877d8-ccf9-43fb-b879-f0d2b7ad0da8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 43c5c151-5868-4cb7-824f-04805f9f4c09
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e2e7109f-520a-4025-a273-d5e9c8fb6949
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 06fb688f-dff4-400a-947e-3ecefed22062
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e14fe58d-b83a-436b-9e06-466a0b445c9f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d2414278-42fb-4606-9bc7-234956a0fa39
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8ab8ae19-8baa-4466-88ed-8e3cd38f92d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 521141f8-9842-4ec0-98d5-52ce808d5984
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d5a23297-9f1c-40c5-8112-aa1c440b45e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 59d4f849-4146-4ef3-b415-f99016f66f31
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f6e3738f-18a9-4644-a70d-325a584331f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e78e56e8-a94b-4c7d-8e09-f137484f4b20
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4404a418-3c9a-41fe-ab00-033074df56a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4985e106-537c-4b65-85de-d3de51239c21
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 96c52ef9-8bc2-44e2-ace7-468a13dc13ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 285819c3-2293-4fb0-b4e5-2b24f5927ca1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 307629db-cf14-467d-af91-773c4f4935c5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7322de94-30bf-4653-b9a7-017ee75cb62f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message be873ed2-cd28-4e70-9368-5891fbe2a6bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5b9658fe-302c-4877-a741-cdb43c66abc2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f3628ee8-dd61-4b1f-aeba-616490bf5c2c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c49a12e4-d6dc-4438-8d08-8c389bb9395d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c28126de-f1da-47ca-befe-a9a7521d670c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dbf747a4-7d16-4f7d-adc0-52cca8a14288
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e2c354ce-d9dd-4c17-aeac-29680b7fd48d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2a099b8f-e616-4e94-8c2f-07f397e0a25a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0de60127-1955-44b4-910f-fc7dbff8dbd1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a9c61c21-3052-4269-911f-267b6ffd656e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 63f6fd36-ddfe-4eaa-b670-391df3034c8f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e9523f3c-35f3-40c3-86a4-db6cb80d4d10
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 64ef0b3c-3601-4558-9940-d732f3e9f93d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 24b3eb85-37b2-4e79-b940-123cfa11025d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message db2c6d5e-e5bb-43c4-b036-1de00288d044
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9a9c7eb3-27b5-4a19-ba64-2a883073dad8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0ca79649-c8f6-4a7a-88ca-07f8821d9d42
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 52b97c01-b6a1-4d81-905d-6c105b5dab79
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5cab13d0-feaa-41e5-ad49-69b4cd5d22bc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8e2e3b86-b0ab-4303-adbb-9424de1be844
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 378ffe0c-c3d7-49f9-bbae-1b5f5faa86e9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6e01bde8-c768-49b5-bfb3-425837081ca3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 80d068ca-5d69-4317-b657-f86ad87ad5b7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f2ad7b52-8d9b-4014-9e1a-61f2c4ccc9d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b9974a79-be84-445f-8d44-15cb511b13ea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 43e3898b-d049-4243-ae9b-067d83cb63d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 08f99bcf-b9f6-4a2b-a055-b4469e6f0fa6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0f18167e-6603-47fa-b4f6-ba660e5b455a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 879b45a7-2937-4b15-9413-43d406a8c084
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 15c58f22-c2bc-4d2a-ad65-25f75eccdd0a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 14d5bfa8-f7cd-45e2-9483-1575eeaaf55b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 02db505f-7f3f-486a-8b2c-11cb3be8d48a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 302f8420-f037-4977-b6ac-36c523d471d8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 26b1af80-5a17-4a15-a19c-9190eb08fafe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 20da7994-c677-41c2-9408-715cde94e103
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 484159cb-6736-4c7b-b376-f639e2b7e001
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b36d2c69-857e-43b3-b2f1-8343cfc8c760
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7a1d1fd8-fbee-4cc9-bb43-018b03bf7558
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0cf4a5c1-ead1-441b-9229-4a7e765bf2f2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b08b769a-dae3-4363-8fef-a73c2b636deb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c02d0d9e-9e1b-41ed-9340-3e33e964486f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1fa45049-1edd-4c37-bfd1-b47b2ab19fa7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a76c59ef-020d-473a-9ba5-b87c40797a53
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b58bceb7-0a87-4ab8-9f81-14c8052be144
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d1109523-c816-4eb8-b343-ba1aeb6377cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1ab6094e-c8c0-4778-9655-2d9dc094b9b0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bb5bbf14-482f-47a5-bba0-8938a38838a9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1fd6f1f9-a55a-4762-b008-dedebec3f057
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7473711d-c242-41f9-8f4b-3396a184afab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ef89d24b-3020-46db-8de1-a85e31001bd5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1139b427-de6e-48e5-807d-24c3de6e0f7f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0f7ef78e-7078-4c96-908d-c4e14330338d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8d38c10c-cf09-4aab-8ef4-59a59f550ce6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cf41fe68-3b13-473f-97f3-cfd19dff45b6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ecdf9225-c1a3-4adf-afe6-30d3fab1a1b5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7642e3fe-2842-4012-bcc6-8270d5c1c427
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7efbb189-c6c1-4834-950d-4d7156cb72f2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4d8dd8a1-3220-4f47-89d2-bd35d74972b1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3cfafc00-1c63-468e-adbf-5f1db678aab3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1c8cb87d-ae9c-4ee2-a744-1ededb7c2540
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3db7840b-6e67-4d1c-b946-363f9482e753
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3fb16c11-b2ad-4238-af91-8eddfde9365e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1712158c-f8a1-44a5-8493-77771e081220
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 030e2bc0-8122-4f0d-be19-0a3506132062
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ee825859-eaaf-4632-940c-1baa6a2ff1bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bbf67072-bdf0-457a-9ef5-0432556c9e72
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0de5c84d-5d3d-48be-9d8d-a0d3c2d0d2f3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a8124079-6fdc-4a28-85a8-f57057802b62
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e7f53a20-649d-47ff-b892-280bb840d93e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c6ee4f9f-9542-44b5-9251-d0984f90f330
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 14a96d5a-7a91-4ebc-8f42-8d96858a745a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f523abe4-3892-49a0-9916-8b840cdc706e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 99514d06-06c7-48b3-9278-795ab8187fb9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1d8e7e6e-9ce3-4a38-b2c1-56ee63e2c564
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 503b05fe-de26-4272-943b-86bf54915e42
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 001acf50-fa5f-492d-9a19-eb38bfe48581
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4fa3152d-eeda-4b6d-92ab-e206a59490ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c50b0611-d84c-4dfb-ae3e-425c087c8505
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0c333b11-fd1a-473b-ac49-0fe7fe2b0d14
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 99d12438-30cd-4682-96c1-2ce09eb37392
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d8b1549f-be8c-49fd-ac91-3d902717b088
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2e83b1e5-24f7-494c-b758-016e7c5f4f28
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a2749648-a983-4979-846d-f156937956ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3cba8345-d22b-4f9f-81df-fd7897c26480
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 94b3ce85-ea98-496c-8ba6-f546c9bf5cf2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 30334e45-11ef-4fd7-a5f2-ce259620ff14
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 772eb87b-11a5-4c60-9afc-67530d4e321b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 35814ca3-fb91-4dd4-99d4-dacf670cdb60
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 84f3a091-79c3-4e2c-bf50-6a1d97a3dd3f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e15b8e87-1bc4-4efa-9c63-5f3310498483
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 602cee12-5f4c-46d3-bdce-e92a3b124eb4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ebac3bd3-9ed6-4f6f-a943-22439d8c4ec4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d12afc7f-ba4a-4462-8c37-84ffd9ce5a6c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f1d5c7d2-112f-4596-a09a-7a4995db3156
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 47364b7e-11b0-454f-a8c7-21dbccbc0481
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0e2c6cb5-e5e6-4d09-a095-350b790286f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cc7962b9-ed27-40ce-b58a-fa9ebbe8c95d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0268ffc3-edf0-4f76-8643-8ba00f8ce570
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 96d76f3c-53f6-449f-bec3-cf6038a2f97c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2d8bcbeb-8938-4334-8b13-71ae2776cc58
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f9ef22fa-cef5-4a3a-a58c-4db4accb2e70
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 64236040-73ce-4d87-a47e-755325a89914
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1dbed716-cbf5-42e3-a854-149a85007c1b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 505af24f-efd2-426b-9091-0bdab0a6ef4f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 457ae9db-4785-4313-b7f2-ecb650e7b33c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b1a15f97-b8fe-4016-812e-1512d875a8d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c4f6abf6-f918-4840-abd1-c5d4ba44e32f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ff19299a-1c5d-4057-b30d-5f94e57a4d92
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0020bdc4-6d9b-4035-8c48-6edf7093f83c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 491d8dfd-d5f9-45a1-89a8-2d9424280be9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b43a58f5-22f2-4480-b813-386cea7c3f05
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3b6ee536-b7c6-428c-8c32-89d86e84b08f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e917db79-2678-4a0a-a85a-2026bb601c7e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5fca4322-1138-47d3-9800-8cbdd17cb2ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2aca70af-fbc1-4977-b29a-b79078fd884e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4814a3ae-442c-4c64-9191-076d0abde0db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 974a20a1-5c95-4d3b-ad65-3928482be09c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a5407cce-e0e6-49c7-99a6-07006c04b02f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 28d7a9b4-d2ba-4d98-948f-cc79d121b490
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6f26addc-1a6b-4bab-9335-8af814269054
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6d867e0d-7674-4241-966d-aa45ca023f7d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b6842aaa-1417-456e-b943-a2fcd8e76c20
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8f4f1ec6-56ce-4af4-9a10-a943fad720cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aa47e918-f72c-4079-a913-5c5c85f05b62
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 998fa6f4-85f2-48ff-adf8-519e8264e3ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eb549dd4-3574-4fda-96a2-b8b024a54ba7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 620d1c42-addd-4f07-ac98-7c7ed9154d46
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 89b251cb-b5a7-44a9-a676-dffad474f6dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2e527bbf-e9d5-4c71-bb1a-da5d24653f8a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ddc308fa-0656-4c12-977b-4324957639d1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c1fd9421-58d9-4568-9740-fce2996cd96f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 513a5d76-a626-4a5f-ac10-a50509b7f30a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4257cf5a-7b55-42fd-92b6-bd74134cf3df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4dc5b64e-e19a-4f90-952e-7cda2efda1df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9cde80a4-4a56-4e92-9148-151398483950
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3236ac4a-e313-4a07-b52f-81c743e7a46e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 91810310-1b53-4d0f-867c-3f4092057109
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 19fc3fd1-50cc-4bdc-b712-d9961b846327
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1da3a69e-d6d4-486f-acd4-43924d1e2795
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7d39e229-9566-4c4b-949b-b668f03789a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6321e78b-cc47-46cc-a2c2-7db7bbbb1cd4
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "recvmsg:Connection reset by peer"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8687 {grpc_status:14, grpc_message:"recvmsg:Connection reset by peer"}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_22
Server: localhost:8687
Algorithm: FEDAVG
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_22
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_22/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_22/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_22/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_22/test_labels.txt

📊 Raw data loaded:
   Train: X=(1312, 24), y=(1312,)
   Test:  X=(329, 24), y=(329,)

⚠️  Limiting training data: 1312 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  320 samples, 5 features
✅ Client client_22 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

============================================================
🔄 Round 3 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0803 (↓), lr=0.001000
   • Epoch   2/100: train=0.0838, val=0.0808, patience=1/15, lr=0.001000
   • Epoch   3/100: train=0.0834, val=0.0813, patience=2/15, lr=0.001000
   • Epoch   4/100: train=0.0828, val=0.0813, patience=3/15, lr=0.001000
   • Epoch   5/100: train=0.0823, val=0.0814, patience=4/15, lr=0.001000
   📉 Epoch 7: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0809, val=0.0821, patience=10/15, lr=0.000500
   📉 Epoch 15: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 3 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0814, RMSE=0.2854, R²=0.0104
   Val:   Loss=0.0803, RMSE=0.2834, R²=-0.0154
============================================================


📊 Round 3 Test Metrics:
   Loss: 0.0792, RMSE: 0.2814, MAE: 0.2426, R²: 0.0001

📊 Round 3 Test Metrics:
   Loss: 0.0791, RMSE: 0.2812, MAE: 0.2429, R²: 0.0013

============================================================
🔄 Round 7 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0817 (↓), lr=0.000250
   • Epoch   2/100: train=0.0799, val=0.0820, patience=1/15, lr=0.000250
   • Epoch   3/100: train=0.0796, val=0.0823, patience=2/15, lr=0.000250
   • Epoch   4/100: train=0.0794, val=0.0826, patience=3/15, lr=0.000250
   • Epoch   5/100: train=0.0792, val=0.0828, patience=4/15, lr=0.000250
   📉 Epoch 7: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0784, val=0.0833, patience=10/15, lr=0.000125
   📉 Epoch 15: LR reduced 0.000125 → 0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 7 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000250 → 0.000063 (2 reductions)
   Train: Loss=0.0799, RMSE=0.2826, R²=0.0168
   Val:   Loss=0.0817, RMSE=0.2858, R²=0.0227
============================================================


📊 Round 7 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2422, R²: 0.0069

============================================================
🔄 Round 10 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0792 (↓), lr=0.000063
   • Epoch   2/100: train=0.0800, val=0.0794, patience=1/15, lr=0.000063
   • Epoch   3/100: train=0.0799, val=0.0795, patience=2/15, lr=0.000063
   • Epoch   4/100: train=0.0798, val=0.0796, patience=3/15, lr=0.000063
   • Epoch   5/100: train=0.0797, val=0.0797, patience=4/15, lr=0.000063
   📉 Epoch 7: LR reduced 0.000063 → 0.000031
   • Epoch  11/100: train=0.0794, val=0.0802, patience=10/15, lr=0.000031
   📉 Epoch 15: LR reduced 0.000031 → 0.000016

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 10 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000063 → 0.000016 (2 reductions)
   Train: Loss=0.0801, RMSE=0.2831, R²=0.0203
   Val:   Loss=0.0792, RMSE=0.2814, R²=0.0269
============================================================


📊 Round 10 Test Metrics:
   Loss: 0.0784, RMSE: 0.2800, MAE: 0.2414, R²: 0.0097

📊 Round 10 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2414, R²: 0.0088

📊 Round 10 Test Metrics:
   Loss: 0.0784, RMSE: 0.2800, MAE: 0.2413, R²: 0.0097

📊 Round 10 Test Metrics:
   Loss: 0.0784, RMSE: 0.2799, MAE: 0.2412, R²: 0.0105

============================================================
🔄 Round 18 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000016
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0771, val=0.0921 (↓), lr=0.000016
   • Epoch   2/100: train=0.0770, val=0.0920, patience=1/15, lr=0.000016
   • Epoch   3/100: train=0.0769, val=0.0919, patience=2/15, lr=0.000016
   • Epoch   4/100: train=0.0768, val=0.0919, patience=3/15, lr=0.000016
   • Epoch   5/100: train=0.0768, val=0.0919, patience=4/15, lr=0.000016
   📉 Epoch 7: LR reduced 0.000016 → 0.000008
   • Epoch  11/100: train=0.0766, val=0.0918, patience=10/15, lr=0.000008
   📉 Epoch 15: LR reduced 0.000008 → 0.000004

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0921)

============================================================
📊 Round 18 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000016 → 0.000004 (2 reductions)
   Train: Loss=0.0772, RMSE=0.2778, R²=0.0211
   Val:   Loss=0.0921, RMSE=0.3035, R²=0.0115
============================================================


📊 Round 18 Test Metrics:
   Loss: 0.0784, RMSE: 0.2800, MAE: 0.2412, R²: 0.0102

📊 Round 18 Test Metrics:
   Loss: 0.0784, RMSE: 0.2800, MAE: 0.2412, R²: 0.0100

============================================================
🔄 Round 23 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000004
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0760 (↓), lr=0.000004
   • Epoch   2/100: train=0.0811, val=0.0760, patience=1/15, lr=0.000004
   • Epoch   3/100: train=0.0810, val=0.0760, patience=2/15, lr=0.000004
   • Epoch   4/100: train=0.0810, val=0.0759, patience=3/15, lr=0.000004
   • Epoch   5/100: train=0.0810, val=0.0759, patience=4/15, lr=0.000004
   • Epoch  11/100: train=0.0809, val=0.0758, patience=10/15, lr=0.000004

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0760)

============================================================
📊 Round 23 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000004 → 0.000004 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2849, R²=0.0249
   Val:   Loss=0.0760, RMSE=0.2757, R²=-0.0047
============================================================


📊 Round 23 Test Metrics:
   Loss: 0.0784, RMSE: 0.2800, MAE: 0.2412, R²: 0.0100

============================================================
🔄 Round 26 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000004
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0768, val=0.0932 (↓), lr=0.000004
   • Epoch   2/100: train=0.0768, val=0.0933, patience=1/15, lr=0.000004
   • Epoch   3/100: train=0.0767, val=0.0934, patience=2/15, lr=0.000004
   📉 Epoch 4: LR reduced 0.000004 → 0.000002
   • Epoch   4/100: train=0.0767, val=0.0935, patience=3/15, lr=0.000002
   • Epoch   5/100: train=0.0766, val=0.0935, patience=4/15, lr=0.000002
   • Epoch  11/100: train=0.0765, val=0.0938, patience=10/15, lr=0.000002
   📉 Epoch 12: LR reduced 0.000002 → 0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0932)

============================================================
📊 Round 26 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000004 → 0.000001 (2 reductions)
   Train: Loss=0.0768, RMSE=0.2772, R²=0.0205
   Val:   Loss=0.0932, RMSE=0.3053, R²=-0.0212
============================================================


============================================================
🔄 Round 29 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0761 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0761, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0761, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0761, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0760, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0760, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0761)

============================================================
📊 Round 29 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=0.0209
   Val:   Loss=0.0761, RMSE=0.2758, R²=0.0123
============================================================


============================================================
🔄 Round 30 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 30 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=0.0220
   Val:   Loss=0.0807, RMSE=0.2842, R²=-0.0246
============================================================


📊 Round 30 Test Metrics:
   Loss: 0.0784, RMSE: 0.2800, MAE: 0.2412, R²: 0.0099

============================================================
🔄 Round 33 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 33 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2812, R²=0.0164
   Val:   Loss=0.0842, RMSE=0.2902, R²=0.0297
============================================================


📊 Round 33 Test Metrics:
   Loss: 0.0784, RMSE: 0.2800, MAE: 0.2412, R²: 0.0099

============================================================
🔄 Round 36 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 36 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=0.0179
   Val:   Loss=0.0812, RMSE=0.2850, R²=0.0137
============================================================


📊 Round 36 Test Metrics:
   Loss: 0.0784, RMSE: 0.2800, MAE: 0.2412, R²: 0.0099

============================================================
🔄 Round 37 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0733 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0733, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0733, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0733, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0733, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0733, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0733)

============================================================
📊 Round 37 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=0.0225
   Val:   Loss=0.0733, RMSE=0.2707, R²=0.0014
============================================================


============================================================
🔄 Round 38 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0760 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0760, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0760, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0760, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0760, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0760, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0760)

============================================================
📊 Round 38 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2849, R²=0.0147
   Val:   Loss=0.0760, RMSE=0.2756, R²=0.0270
============================================================


============================================================
🔄 Round 39 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 39 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2826, R²=0.0182
   Val:   Loss=0.0811, RMSE=0.2847, R²=0.0127
============================================================


============================================================
🔄 Round 40 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0715 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0715, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0715, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0715, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0715, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0715, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0715)

============================================================
📊 Round 40 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2868, R²=0.0199
   Val:   Loss=0.0715, RMSE=0.2674, R²=0.0173
============================================================


📊 Round 40 Test Metrics:
   Loss: 0.0784, RMSE: 0.2800, MAE: 0.2412, R²: 0.0099

============================================================
🔄 Round 41 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0741 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0741, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0741, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0741, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0741, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0741, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0741)

============================================================
📊 Round 41 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=0.0153
   Val:   Loss=0.0741, RMSE=0.2722, R²=0.0343
============================================================


============================================================
🔄 Round 43 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 43 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2833, R²=0.0155
   Val:   Loss=0.0795, RMSE=0.2820, R²=0.0304
============================================================


📊 Round 43 Test Metrics:
   Loss: 0.0784, RMSE: 0.2800, MAE: 0.2412, R²: 0.0098

📊 Round 43 Test Metrics:
   Loss: 0.0784, RMSE: 0.2800, MAE: 0.2412, R²: 0.0098

📊 Round 43 Test Metrics:
   Loss: 0.0784, RMSE: 0.2800, MAE: 0.2412, R²: 0.0098

============================================================
🔄 Round 48 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 48 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=0.0215
   Val:   Loss=0.0785, RMSE=0.2802, R²=0.0057
============================================================


============================================================
🔄 Round 49 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0760 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0760, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0760, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0760, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0760, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0760, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0760)

============================================================
📊 Round 49 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=0.0131
   Val:   Loss=0.0760, RMSE=0.2757, R²=0.0446
============================================================


============================================================
🔄 Round 50 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 50 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2815, R²=0.0179
   Val:   Loss=0.0834, RMSE=0.2889, R²=0.0241
============================================================


📊 Round 50 Test Metrics:
   Loss: 0.0784, RMSE: 0.2800, MAE: 0.2412, R²: 0.0098

============================================================
🔄 Round 51 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 51 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2818, R²=0.0121
   Val:   Loss=0.0829, RMSE=0.2879, R²=0.0479
============================================================


📊 Round 51 Test Metrics:
   Loss: 0.0784, RMSE: 0.2800, MAE: 0.2412, R²: 0.0097

📊 Round 51 Test Metrics:
   Loss: 0.0784, RMSE: 0.2800, MAE: 0.2412, R²: 0.0098

============================================================
🔄 Round 54 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0868 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0867, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0867, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0783, val=0.0867, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0867, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0868)

============================================================
📊 Round 54 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2801, R²=0.0182
   Val:   Loss=0.0868, RMSE=0.2945, R²=0.0244
============================================================


============================================================
🔄 Round 55 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 55 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2817, R²=0.0227
   Val:   Loss=0.0831, RMSE=0.2883, R²=0.0077
============================================================


============================================================
🔄 Round 56 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0768 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0768, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0768, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0768, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0768, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0768, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0768)

============================================================
📊 Round 56 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2845, R²=0.0165
   Val:   Loss=0.0768, RMSE=0.2772, R²=0.0328
============================================================


📊 Round 56 Test Metrics:
   Loss: 0.0784, RMSE: 0.2800, MAE: 0.2412, R²: 0.0097

============================================================
🔄 Round 57 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0761 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0761, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0761, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0761, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0761, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0760, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0761)

============================================================
📊 Round 57 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=0.0120
   Val:   Loss=0.0761, RMSE=0.2758, R²=0.0494
============================================================


============================================================
🔄 Round 59 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0739 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0739, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0740, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0740, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0740, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0740, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0739)

============================================================
📊 Round 59 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=0.0229
   Val:   Loss=0.0739, RMSE=0.2719, R²=0.0063
============================================================


============================================================
🔄 Round 60 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0747 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0747, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0747, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0747, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0747, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0748, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0747)

============================================================
📊 Round 60 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2854, R²=0.0159
   Val:   Loss=0.0747, RMSE=0.2733, R²=-0.0173
============================================================


📊 Round 60 Test Metrics:
   Loss: 0.0784, RMSE: 0.2800, MAE: 0.2412, R²: 0.0097

📊 Round 60 Test Metrics:
   Loss: 0.0784, RMSE: 0.2800, MAE: 0.2412, R²: 0.0097

📊 Round 60 Test Metrics:
   Loss: 0.0784, RMSE: 0.2800, MAE: 0.2412, R²: 0.0096

============================================================
🔄 Round 64 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0776 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0776, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0776, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0776, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0776, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 64 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=0.0142
   Val:   Loss=0.0776, RMSE=0.2785, R²=0.0250
============================================================


📊 Round 64 Test Metrics:
   Loss: 0.0784, RMSE: 0.2800, MAE: 0.2412, R²: 0.0096

📊 Round 64 Test Metrics:
   Loss: 0.0784, RMSE: 0.2800, MAE: 0.2412, R²: 0.0096

📊 Round 64 Test Metrics:
   Loss: 0.0784, RMSE: 0.2800, MAE: 0.2413, R²: 0.0096

============================================================
🔄 Round 72 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0763 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0763, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0763, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0763, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0763, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0763, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0763)

============================================================
📊 Round 72 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2847, R²=0.0212
   Val:   Loss=0.0763, RMSE=0.2762, R²=0.0119
============================================================


📊 Round 72 Test Metrics:
   Loss: 0.0784, RMSE: 0.2801, MAE: 0.2413, R²: 0.0095

============================================================
🔄 Round 74 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 74 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2815, R²=0.0118
   Val:   Loss=0.0834, RMSE=0.2889, R²=0.0249
============================================================


============================================================
🔄 Round 75 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0766 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0766, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0766, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0766, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0766, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0766, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0766)

============================================================
📊 Round 75 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2845, R²=0.0220
   Val:   Loss=0.0766, RMSE=0.2767, R²=0.0055
============================================================


📊 Round 75 Test Metrics:
   Loss: 0.0784, RMSE: 0.2801, MAE: 0.2413, R²: 0.0095

============================================================
🔄 Round 76 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 76 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2813, R²=0.0224
   Val:   Loss=0.0839, RMSE=0.2896, R²=0.0112
============================================================


📊 Round 76 Test Metrics:
   Loss: 0.0784, RMSE: 0.2801, MAE: 0.2413, R²: 0.0095

============================================================
🔄 Round 78 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0869 (↓), lr=0.000001
   • Epoch   2/100: train=0.0785, val=0.0869, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0785, val=0.0869, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0785, val=0.0869, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0785, val=0.0869, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0785, val=0.0869, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 78 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2799, R²=0.0254
   Val:   Loss=0.0869, RMSE=0.2948, R²=0.0002
============================================================


📊 Round 78 Test Metrics:
   Loss: 0.0784, RMSE: 0.2801, MAE: 0.2413, R²: 0.0094

============================================================
🔄 Round 80 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0762 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0762, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0762, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0762, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0762, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0762, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0762)

============================================================
📊 Round 80 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2847, R²=0.0138
   Val:   Loss=0.0762, RMSE=0.2761, R²=0.0454
============================================================


============================================================
🔄 Round 82 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 82 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2831, R²=0.0168
   Val:   Loss=0.0797, RMSE=0.2823, R²=0.0287
============================================================


📊 Round 82 Test Metrics:
   Loss: 0.0784, RMSE: 0.2801, MAE: 0.2413, R²: 0.0094

============================================================
🔄 Round 83 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0731 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0731, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0731, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0731, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0731, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0730, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0731)

============================================================
📊 Round 83 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=0.0169
   Val:   Loss=0.0731, RMSE=0.2703, R²=0.0261
============================================================


📊 Round 83 Test Metrics:
   Loss: 0.0784, RMSE: 0.2801, MAE: 0.2413, R²: 0.0094

📊 Round 83 Test Metrics:
   Loss: 0.0784, RMSE: 0.2801, MAE: 0.2413, R²: 0.0094

📊 Round 83 Test Metrics:
   Loss: 0.0784, RMSE: 0.2801, MAE: 0.2413, R²: 0.0094

📊 Round 83 Test Metrics:
   Loss: 0.0784, RMSE: 0.2801, MAE: 0.2413, R²: 0.0093

============================================================
🔄 Round 92 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0774 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0774, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0774, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0774, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0774, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0774, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0774)

============================================================
📊 Round 92 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=0.0196
   Val:   Loss=0.0774, RMSE=0.2783, R²=0.0232
============================================================


📊 Round 92 Test Metrics:
   Loss: 0.0784, RMSE: 0.2801, MAE: 0.2413, R²: 0.0093

📊 Round 92 Test Metrics:
   Loss: 0.0784, RMSE: 0.2801, MAE: 0.2413, R²: 0.0093

============================================================
🔄 Round 96 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 96 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2811, R²=0.0263
   Val:   Loss=0.0843, RMSE=0.2903, R²=-0.0087
============================================================


============================================================
🔄 Round 98 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 98 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=0.0216
   Val:   Loss=0.0805, RMSE=0.2837, R²=0.0153
============================================================


============================================================
🔄 Round 100 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0766 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0766, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0766, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0766, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0766, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0766, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0766)

============================================================
📊 Round 100 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2845, R²=0.0261
   Val:   Loss=0.0766, RMSE=0.2768, R²=-0.0045
============================================================


📊 Round 100 Test Metrics:
   Loss: 0.0785, RMSE: 0.2801, MAE: 0.2414, R²: 0.0092

============================================================
🔄 Round 103 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 103 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2819, R²=0.0238
   Val:   Loss=0.0824, RMSE=0.2870, R²=-0.0003
============================================================


📊 Round 103 Test Metrics:
   Loss: 0.0785, RMSE: 0.2801, MAE: 0.2414, R²: 0.0092

============================================================
🔄 Round 104 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 104 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2817, R²=0.0255
   Val:   Loss=0.0829, RMSE=0.2880, R²=0.0004
============================================================


============================================================
🔄 Round 105 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0686 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0686, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0686, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0686, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0686, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0686, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0686)

============================================================
📊 Round 105 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2880, R²=0.0201
   Val:   Loss=0.0686, RMSE=0.2618, R²=0.0213
============================================================


============================================================
🔄 Round 106 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0740 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0740, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0740, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0741, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0741, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0741, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0740)

============================================================
📊 Round 106 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=0.0178
   Val:   Loss=0.0740, RMSE=0.2721, R²=0.0091
============================================================


📊 Round 106 Test Metrics:
   Loss: 0.0785, RMSE: 0.2801, MAE: 0.2414, R²: 0.0092

============================================================
🔄 Round 109 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 109 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2822, R²=0.0177
   Val:   Loss=0.0817, RMSE=0.2859, R²=0.0237
============================================================


============================================================
🔄 Round 110 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 110 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2817, R²=0.0188
   Val:   Loss=0.0828, RMSE=0.2878, R²=0.0254
============================================================


📊 Round 110 Test Metrics:
   Loss: 0.0785, RMSE: 0.2801, MAE: 0.2414, R²: 0.0092

============================================================
🔄 Round 111 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 111 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2824, R²=0.0136
   Val:   Loss=0.0813, RMSE=0.2851, R²=0.0469
============================================================


📊 Round 111 Test Metrics:
   Loss: 0.0785, RMSE: 0.2801, MAE: 0.2414, R²: 0.0091

📊 Round 111 Test Metrics:
   Loss: 0.0785, RMSE: 0.2801, MAE: 0.2414, R²: 0.0091

============================================================
🔄 Round 115 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 115 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=0.0186
   Val:   Loss=0.0810, RMSE=0.2846, R²=0.0282
============================================================


============================================================
🔄 Round 118 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 118 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2824, R²=0.0242
   Val:   Loss=0.0811, RMSE=0.2848, R²=0.0049
============================================================


============================================================
🔄 Round 119 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 119 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=0.0255
   Val:   Loss=0.0797, RMSE=0.2823, R²=-0.0193
============================================================


📊 Round 119 Test Metrics:
   Loss: 0.0785, RMSE: 0.2801, MAE: 0.2414, R²: 0.0090

============================================================
🔄 Round 120 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 120 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=0.0200
   Val:   Loss=0.0787, RMSE=0.2806, R²=0.0109
============================================================


============================================================
🔄 Round 122 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0785, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 122 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2805, R²=0.0205
   Val:   Loss=0.0855, RMSE=0.2924, R²=0.0159
============================================================


📊 Round 122 Test Metrics:
   Loss: 0.0785, RMSE: 0.2801, MAE: 0.2414, R²: 0.0090

============================================================
🔄 Round 124 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0779, val=0.0874 (↓), lr=0.000001
   • Epoch   2/100: train=0.0779, val=0.0874, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0779, val=0.0874, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0779, val=0.0874, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0779, val=0.0875, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0778, val=0.0875, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0874)

============================================================
📊 Round 124 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0782, RMSE=0.2796, R²=0.0194
   Val:   Loss=0.0874, RMSE=0.2957, R²=0.0166
============================================================


📊 Round 124 Test Metrics:
   Loss: 0.0785, RMSE: 0.2801, MAE: 0.2414, R²: 0.0090

============================================================
🔄 Round 125 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0761 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0761, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0761, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0761, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0761, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0760, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0761)

============================================================
📊 Round 125 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=0.0198
   Val:   Loss=0.0761, RMSE=0.2758, R²=0.0243
============================================================


📊 Round 125 Test Metrics:
   Loss: 0.0785, RMSE: 0.2801, MAE: 0.2414, R²: 0.0090

📊 Round 125 Test Metrics:
   Loss: 0.0785, RMSE: 0.2801, MAE: 0.2414, R²: 0.0090

============================================================
🔄 Round 127 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 127 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2818, R²=0.0224
   Val:   Loss=0.0824, RMSE=0.2871, R²=0.0107
============================================================


📊 Round 127 Test Metrics:
   Loss: 0.0785, RMSE: 0.2801, MAE: 0.2414, R²: 0.0090

============================================================
🔄 Round 128 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 128 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=0.0244
   Val:   Loss=0.0810, RMSE=0.2845, R²=-0.0003
============================================================


📊 Round 128 Test Metrics:
   Loss: 0.0785, RMSE: 0.2801, MAE: 0.2414, R²: 0.0090

============================================================
🔄 Round 130 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0779, val=0.0884 (↓), lr=0.000001
   • Epoch   2/100: train=0.0779, val=0.0884, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0779, val=0.0884, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0779, val=0.0884, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0779, val=0.0884, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0779, val=0.0884, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0884)

============================================================
📊 Round 130 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0780, RMSE=0.2792, R²=0.0211
   Val:   Loss=0.0884, RMSE=0.2973, R²=0.0117
============================================================


📊 Round 130 Test Metrics:
   Loss: 0.0785, RMSE: 0.2801, MAE: 0.2414, R²: 0.0090

============================================================
🔄 Round 131 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 131 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2819, R²=0.0103
   Val:   Loss=0.0823, RMSE=0.2868, R²=0.0577
============================================================


============================================================
🔄 Round 132 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0725 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0725, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0725, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0725, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0725, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0725, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0725)

============================================================
📊 Round 132 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=0.0212
   Val:   Loss=0.0725, RMSE=0.2693, R²=0.0170
============================================================


📊 Round 132 Test Metrics:
   Loss: 0.0785, RMSE: 0.2801, MAE: 0.2414, R²: 0.0089

============================================================
🔄 Round 133 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 133 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=0.0249
   Val:   Loss=0.0794, RMSE=0.2817, R²=0.0021
============================================================


📊 Round 133 Test Metrics:
   Loss: 0.0785, RMSE: 0.2801, MAE: 0.2414, R²: 0.0089

============================================================
🔄 Round 134 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 134 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=0.0226
   Val:   Loss=0.0813, RMSE=0.2852, R²=0.0012
============================================================


📊 Round 134 Test Metrics:
   Loss: 0.0785, RMSE: 0.2801, MAE: 0.2414, R²: 0.0089

📊 Round 134 Test Metrics:
   Loss: 0.0785, RMSE: 0.2801, MAE: 0.2414, R²: 0.0089

============================================================
🔄 Round 138 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 138 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=0.0204
   Val:   Loss=0.0788, RMSE=0.2806, R²=0.0220
============================================================


============================================================
🔄 Round 139 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0782, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 139 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=0.0208
   Val:   Loss=0.0782, RMSE=0.2796, R²=-0.0047
============================================================


============================================================
🔄 Round 140 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 140 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2824, R²=0.0226
   Val:   Loss=0.0811, RMSE=0.2848, R²=0.0010
============================================================


📊 Round 140 Test Metrics:
   Loss: 0.0785, RMSE: 0.2801, MAE: 0.2414, R²: 0.0089

============================================================
🔄 Round 141 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0782, val=0.0866 (↓), lr=0.000001
   • Epoch   2/100: train=0.0782, val=0.0866, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0782, val=0.0866, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0782, val=0.0866, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0782, val=0.0866, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0782, val=0.0866, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0866)

============================================================
📊 Round 141 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2800, R²=0.0112
   Val:   Loss=0.0866, RMSE=0.2942, R²=0.0535
============================================================


📊 Round 141 Test Metrics:
   Loss: 0.0785, RMSE: 0.2801, MAE: 0.2414, R²: 0.0089

============================================================
🔄 Round 145 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0768 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0768, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0768, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0769, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0769, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0769, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0768)

============================================================
📊 Round 145 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=0.0191
   Val:   Loss=0.0768, RMSE=0.2772, R²=0.0175
============================================================


📊 Round 145 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2414, R²: 0.0088

============================================================
🔄 Round 149 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0659 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0659, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0660, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0660, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0660, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0660, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0659)

============================================================
📊 Round 149 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=0.0196
   Val:   Loss=0.0659, RMSE=0.2568, R²=0.0009
============================================================


📊 Round 149 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2414, R²: 0.0088

============================================================
🔄 Round 152 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0730 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0730, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0730, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0730, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0730, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0730, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0730)

============================================================
📊 Round 152 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=0.0263
   Val:   Loss=0.0730, RMSE=0.2702, R²=-0.0069
============================================================


📊 Round 152 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2414, R²: 0.0087

📊 Round 152 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2414, R²: 0.0087

============================================================
🔄 Round 155 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 155 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2829, R²=0.0296
   Val:   Loss=0.0800, RMSE=0.2828, R²=-0.0159
============================================================


📊 Round 155 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2414, R²: 0.0087

📊 Round 155 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2414, R²: 0.0087

📊 Round 155 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2415, R²: 0.0087

📊 Round 155 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2414, R²: 0.0087

============================================================
🔄 Round 163 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0731 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0731, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0731, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0731, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0731, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0731, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0731)

============================================================
📊 Round 163 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2859, R²=0.0167
   Val:   Loss=0.0731, RMSE=0.2703, R²=0.0242
============================================================


============================================================
🔄 Round 164 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 164 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=0.0274
   Val:   Loss=0.0785, RMSE=0.2802, R²=-0.0067
============================================================


📊 Round 164 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2414, R²: 0.0087

============================================================
🔄 Round 166 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0683 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0683, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0683, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0683, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0683, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0682, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0683)

============================================================
📊 Round 166 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2880, R²=0.0183
   Val:   Loss=0.0683, RMSE=0.2613, R²=0.0330
============================================================


📊 Round 166 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2414, R²: 0.0087

============================================================
🔄 Round 168 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 168 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2815, R²=0.0231
   Val:   Loss=0.0831, RMSE=0.2883, R²=0.0043
============================================================


📊 Round 168 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2414, R²: 0.0087

📊 Round 168 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2414, R²: 0.0086

============================================================
🔄 Round 171 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0770, val=0.0926 (↓), lr=0.000001
   • Epoch   2/100: train=0.0770, val=0.0926, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0770, val=0.0926, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0770, val=0.0926, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0770, val=0.0926, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0769, val=0.0926, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0926)

============================================================
📊 Round 171 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0769, RMSE=0.2773, R²=0.0227
   Val:   Loss=0.0926, RMSE=0.3043, R²=0.0111
============================================================


📊 Round 171 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2415, R²: 0.0086

============================================================
🔄 Round 173 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 173 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=0.0178
   Val:   Loss=0.0793, RMSE=0.2817, R²=0.0327
============================================================


📊 Round 173 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2415, R²: 0.0086

📊 Round 173 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2415, R²: 0.0085

============================================================
🔄 Round 178 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0770, val=0.0916 (↓), lr=0.000001
   • Epoch   2/100: train=0.0770, val=0.0915, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0770, val=0.0915, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0770, val=0.0915, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0770, val=0.0915, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0770, val=0.0915, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0916)

============================================================
📊 Round 178 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0771, RMSE=0.2777, R²=0.0220
   Val:   Loss=0.0916, RMSE=0.3026, R²=0.0171
============================================================


📊 Round 178 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2415, R²: 0.0085

============================================================
🔄 Round 181 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0742 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0742, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0742, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0742, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0742, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0742, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0742)

============================================================
📊 Round 181 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2854, R²=0.0275
   Val:   Loss=0.0742, RMSE=0.2724, R²=-0.0093
============================================================


📊 Round 181 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2415, R²: 0.0085

============================================================
🔄 Round 184 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0714 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0714, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0714, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0714, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0714, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0714, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0714)

============================================================
📊 Round 184 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2866, R²=0.0166
   Val:   Loss=0.0714, RMSE=0.2673, R²=0.0402
============================================================


============================================================
🔄 Round 185 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 185 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=0.0166
   Val:   Loss=0.0813, RMSE=0.2851, R²=0.0334
============================================================


📊 Round 185 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2415, R²: 0.0084

============================================================
🔄 Round 188 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0782, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 188 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=0.0263
   Val:   Loss=0.0782, RMSE=0.2796, R²=-0.0023
============================================================


📊 Round 188 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2415, R²: 0.0084

============================================================
🔄 Round 190 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0775, val=0.0900 (↓), lr=0.000001
   • Epoch   2/100: train=0.0775, val=0.0900, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0775, val=0.0900, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0775, val=0.0900, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0775, val=0.0900, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0775, val=0.0900, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0900)

============================================================
📊 Round 190 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0775, RMSE=0.2784, R²=0.0227
   Val:   Loss=0.0900, RMSE=0.3000, R²=0.0039
============================================================


============================================================
🔄 Round 193 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0787, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 193 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2809, R²=0.0165
   Val:   Loss=0.0846, RMSE=0.2908, R²=0.0335
============================================================


============================================================
🔄 Round 194 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0770, val=0.0924 (↓), lr=0.000001
   • Epoch   2/100: train=0.0770, val=0.0924, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0770, val=0.0924, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0770, val=0.0924, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0770, val=0.0924, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0770, val=0.0924, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0924)

============================================================
📊 Round 194 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0769, RMSE=0.2774, R²=0.0216
   Val:   Loss=0.0924, RMSE=0.3040, R²=0.0187
============================================================


============================================================
🔄 Round 195 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 195 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2824, R²=0.0305
   Val:   Loss=0.0812, RMSE=0.2849, R²=-0.0198
============================================================


📊 Round 195 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2415, R²: 0.0084

============================================================
🔄 Round 198 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 198 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2824, R²=0.0205
   Val:   Loss=0.0812, RMSE=0.2849, R²=0.0199
============================================================


============================================================
🔄 Round 201 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 201 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=0.0137
   Val:   Loss=0.0798, RMSE=0.2824, R²=0.0452
============================================================


📊 Round 201 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2415, R²: 0.0083

============================================================
🔄 Round 203 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0761 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0761, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0761, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0761, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0761, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0761, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0761)

============================================================
📊 Round 203 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=0.0204
   Val:   Loss=0.0761, RMSE=0.2759, R²=0.0206
============================================================


📊 Round 203 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2415, R²: 0.0083

============================================================
🔄 Round 204 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0764 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0764, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0764, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0764, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0764, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0765, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0764)

============================================================
📊 Round 204 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=0.0226
   Val:   Loss=0.0764, RMSE=0.2764, R²=0.0040
============================================================


📊 Round 204 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2415, R²: 0.0083

📊 Round 204 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2415, R²: 0.0082

============================================================
🔄 Round 209 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 209 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2833, R²=0.0202
   Val:   Loss=0.0789, RMSE=0.2810, R²=0.0181
============================================================


============================================================
🔄 Round 211 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 211 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2813, R²=0.0207
   Val:   Loss=0.0835, RMSE=0.2890, R²=0.0154
============================================================


📊 Round 211 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2415, R²: 0.0082

============================================================
🔄 Round 214 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0877 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0877, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0877, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0877, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0877, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0876, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0877)

============================================================
📊 Round 214 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0781, RMSE=0.2794, R²=0.0241
   Val:   Loss=0.0877, RMSE=0.2961, R²=0.0012
============================================================


📊 Round 214 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2415, R²: 0.0082

============================================================
🔄 Round 215 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0761 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0761, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0761, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0761, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0761, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0762, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0761)

============================================================
📊 Round 215 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=0.0234
   Val:   Loss=0.0761, RMSE=0.2759, R²=0.0099
============================================================


📊 Round 215 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2415, R²: 0.0082

📊 Round 215 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2415, R²: 0.0082

📊 Round 215 Test Metrics:
   Loss: 0.0785, RMSE: 0.2803, MAE: 0.2415, R²: 0.0081

📊 Round 215 Test Metrics:
   Loss: 0.0785, RMSE: 0.2803, MAE: 0.2415, R²: 0.0081

📊 Round 215 Test Metrics:
   Loss: 0.0785, RMSE: 0.2803, MAE: 0.2415, R²: 0.0081

============================================================
🔄 Round 223 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 223 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2811, R²=0.0214
   Val:   Loss=0.0840, RMSE=0.2898, R²=0.0182
============================================================


============================================================
🔄 Round 224 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0764 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0764, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0764, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0764, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0764, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0764, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0764)

============================================================
📊 Round 224 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=0.0216
   Val:   Loss=0.0764, RMSE=0.2763, R²=0.0180
============================================================


📊 Round 224 Test Metrics:
   Loss: 0.0785, RMSE: 0.2803, MAE: 0.2415, R²: 0.0081

============================================================
🔄 Round 225 - Client client_22
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 225 Summary - Client client_22
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2810, R²=0.0236
   Val:   Loss=0.0843, RMSE=0.2903, R²=-0.0005
============================================================


❌ Client client_22 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "recvmsg:Connection reset by peer"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8687 {grpc_status:14, grpc_message:"recvmsg:Connection reset by peer"}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "recvmsg:Connection reset by peer"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8687 {grpc_status:14, grpc_message:"recvmsg:Connection reset by peer"}"
>
