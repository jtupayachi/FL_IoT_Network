[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d1ffec96-810b-43fb-84fe-11263ebb2f68
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c3a6bf09-0ef3-4942-8634-0239cbafdac7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 41485c14-9621-406f-a53c-13a3900c2d64
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 08248b9f-d53a-4b95-9b0f-21622c2ec12a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 150eb57d-7c26-492e-a965-ec5af6040b43
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d7c0ac2f-2794-4b59-82f9-d0e8559646bd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f429d973-6818-4b66-a318-1f3aecfef105
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 077a5312-f6d9-4ced-bb8c-78b1bf175cb2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2491e5a4-39b7-493e-be0e-d955ca29a8f2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d69db269-5b1a-4424-8c5f-bbc11bf3ed90
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ac6b6703-e8cf-411f-8423-1b21e9c9e508
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a8a32d5e-a1c8-4f92-9dcd-bccb14dc25d9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ff61abed-8f9b-4aa8-a586-13460f19cd6b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a5657be4-1d06-4369-92f6-1dcd092488ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9ce462c1-94fd-4709-8c04-67597de70fe0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 25873472-0ab7-4711-bb9d-2e3da7111b97
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0766d146-d599-4a4e-b754-7a8f698d8ec3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c7cf814f-8a3a-4f47-b218-ba21ec8763b9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4a77e2cb-25be-4326-8d0e-28453366c91c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6bbfba1d-8a54-4444-b1a7-baa495ecc275
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ca48e6d8-1348-4644-9509-705ba96a01ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a645fddf-055c-4a59-acda-764c82e22452
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b3783682-b162-4883-b9ba-ef57781dea74
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ba6f60e8-3b1d-49a3-af5c-4fa74c3409cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 830cac11-79a9-4c10-b53c-064041155676
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 093fd27c-3d17-4bbb-80cf-8bd23733e75c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a817e4f4-2f5e-48d2-bfcc-eeb51b614f9e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 80c8a39b-6e04-4b22-a6cd-9a463b13d798
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 023710c5-9335-418a-a20d-81ea341e820c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cd292fa6-068f-453d-8b6a-1c7c721342e5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b3fbb549-c991-4bf1-8f61-1c00815caeed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f029906c-9908-466b-9d08-953f46b09594
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9447b1f4-7d0b-4fb8-a8ac-f400b4959ebe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2a2f3c9d-5855-47cb-be5f-93f552435999
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cd3fafcc-3059-4134-8114-8ff398c74695
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 06d146fb-76be-43e0-becf-d11aff805171
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4f1d41df-8c08-4bd7-ae90-3eb33030b79e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ecbfd876-3b27-4021-a061-cc387a87b826
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 82bb8da5-5a8d-4c88-a414-935e05e5dfb1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f708ca73-5a31-491f-8dcc-1783d8a092be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 852f2918-2d1b-4708-9687-05d9301f3f6a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bdfcc48d-f861-4348-972d-c44e44a76820
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e73bcc8c-362c-46ee-8625-d8fbb9fb017d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e5e5be8c-9375-4d83-8432-4b7f91ec46fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f78c6ae4-ebf5-415b-a6de-36c349161848
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7fbbe800-9ff6-4fa1-a25b-40e2f7fcc24a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9e69f28e-0a0c-4fec-88f2-437da2b9cfcf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 68e95090-49d0-44c6-8c82-f70cbafe65a9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4591088c-1dad-4a98-b998-29e3547efadf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c4f24cc9-5858-4802-af47-bec84aec6a2b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e63b257a-9384-4dc2-adb2-35b7f8c3e0ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 99eee1a8-8b4a-446e-a7cc-6bf7598fb0e5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 046b993c-b4b4-4133-90f2-c8aff61190bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bf862f3b-e275-45cd-8b95-b512b6690670
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8b2490e2-4f29-4434-8516-382d55cef7d5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ac3312fc-cb94-4937-bb4a-abdd35bd2429
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a8aa6a17-da47-42e1-8484-9353f6ea565f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 73071816-690e-47ba-9751-a190c124520d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f6f6fa24-4b6c-4c18-aaf4-0dd3879ff73b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 021bc97b-f92f-4426-9af0-350935c59d86
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d1405975-a548-4d64-9410-6b784bf8c303
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6351460e-8819-40c8-a18f-bf48a62034dd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 31ea1c3d-1ac4-40a2-b343-fbcd7214576f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message daf4a11a-1f89-4cd9-817d-3b3965fb02b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9d2298f4-4a24-47f9-b49c-c322fbfad383
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e29dfc79-e28e-422c-addb-33714cd49afa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a3f7782c-95fa-4c12-83e4-dd52c051c8ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0683cc18-f879-4ee4-9089-b4f77b8e3255
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2646c2e1-3094-421f-b7e5-451abe58cf7d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 53e2ce4a-b669-4db8-a097-4275228a136d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1476e2b9-ef3d-4430-8ff4-9f20509912db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fad3aabf-4a7c-4524-9dc1-45c28272143f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2262ae83-f688-4ace-bfa0-dfd7e1b22713
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 938c82f4-da37-432e-855c-ebcedf186b0a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 241dce5f-4cf2-4922-bf9b-7bcdaf4aea11
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 65bdc3b3-2e1a-43ab-9966-e62bcf60a491
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 97258ac0-3fab-4a10-8f62-2e505faad7af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 141a5907-4b80-42ca-981c-aef2761545ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1ceaabb3-35b2-49aa-93e1-b38f148aed35
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0ebe9faf-b09c-4ff7-a673-0b1fdb51a1ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 36647feb-3ce5-42e5-80da-2a40dddf6d2f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2f22568a-5388-4d41-b76e-c1ef3e65b1aa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a19b8810-7ef1-481e-b5a4-912a5ad58d1c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b3ed3361-f19e-4eb7-99b3-7ef5bd55c392
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3685fe15-339a-45ae-8e1d-aefb42335eb5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 13abf400-7187-4634-94a0-6d41ac8773ce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 775bcf5f-6981-46dc-ab48-fc7827ad4f3d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 08192d2c-c27b-4b7e-98db-8f269866f6d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 784c6735-74df-40c2-8779-7e1508f67d45
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eafd0933-326b-4c67-b5d7-e8fadf434391
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 28a2effa-65e4-4dde-987b-c183be3fb2d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2f9c85db-a366-490b-aa87-c85a6330f476
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2400a84d-fcea-4378-9733-6468b15212ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b2888989-aa2b-4f31-9704-c839cc891b01
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d4af6885-a509-42b4-a4c4-93fc6794e375
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b889f49c-1516-48e6-80e3-c8253a62d1e1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 96ceb7ec-ecfc-4657-b1f7-0042d7bcb6a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5dbed49b-0747-41a4-bb7e-6eaf34ce868e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e4578910-ced8-44e0-859a-7f3cfdcb448c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 95890d3b-949e-4180-a058-90c904866710
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5beb1349-0b79-49f7-af9f-d3f715865de3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a6938f06-a84c-44d1-909a-e1d4c08fd0a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5e1f3dc5-4bd3-4f2f-b52e-f75d2a056d89
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b8bb26e7-0e0a-45c3-ade3-74419bfa4ebf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5085d228-e334-474e-bf22-88c8a97a3e61
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e681902d-57ed-41c8-a30b-3c1ab804d331
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 61ced809-9a1a-47cc-8062-df9fd596fda3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ddfef47f-1d56-4739-b3cb-1f8ca386b830
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 43ed2ee0-eab3-4d52-bc8c-11c10f3a21e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9ad06087-8a42-4a17-9618-a682aefd6bd1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 694badb8-f0f8-4f6a-8147-8a953b17cf5b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c8064ff1-42f0-4962-b443-9cb6d0153ebc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aba9a144-9522-4208-8408-33131224809a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ae767237-a90d-48eb-a17d-d09b7c531014
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1fe94bad-12b2-476b-9e38-9df8c7ea64f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cf907b96-94b3-4f98-ba11-38d6ff963fbf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e0af9860-1615-4500-bb25-f00edfff39eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d16b5796-b1f7-4fc8-822a-7b52a0b4077f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c3b02c98-40f7-4228-8186-5c3ec9c27b11
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aea649cf-a2de-45ea-ad81-6924733b83c6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 54213e3a-8388-40dd-872b-3878d0fd5449
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b7693148-571d-48be-beaf-1c32e2f4d45d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eaf561ec-60d2-4f1d-b759-466a20dd9108
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2ddac5d4-3ecd-46f8-9c70-2dc21000a357
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 318021a1-523b-4304-87ec-a7aa6ae1e835
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d00abf80-fdf3-45a6-ae61-e685b6056b08
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 02651b41-f241-4314-b186-5069630266eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e21f5f20-95b9-48db-84d4-0f5912ae2e1c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 11a16ece-332d-4119-8aa6-ad9ed3d8f10e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3e61b0cf-a9dc-4d08-a336-07a0a9c5f69f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dbcb6760-0058-4eed-83b4-c608f088b50c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b9e45802-5418-45b0-9c7d-11d9439c23be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message df61cac2-ceaa-4b22-be3b-3a154d124b19
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f1992510-dbc8-4f08-bc22-56ab90b90f10
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a7cb0624-89d8-416c-bed1-767d0a7e4b7b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 74bd573a-ac7a-4797-b3ef-327826b5b46e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 66f17151-5c22-4dfb-8cb0-9a5e4d6acc2e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c31f38e0-a99b-4826-a3d1-89c923422018
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 614990e5-e0bb-4cb9-9c57-b6b3664f15ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 988965bb-45a1-4d25-ad74-fcc710dbc92f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e550d796-c658-48e5-ab28-6a1b4fedc494
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ec5753cf-e3a2-402a-a8a3-9706a6233e1a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f728adc6-7a60-49de-b02e-656777bdac3a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 24bf4b40-58f3-4578-9f9a-83375b97fc0f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 320feef3-3f20-4295-acda-98299702163f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cd29dc43-3866-4bc2-a213-7c4ef9e245b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9452df4f-b607-48f7-b65c-958750f888c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 65f83c0d-bb38-4b7b-8f6f-a6eec7a1ed03
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6f9de64e-b534-40f5-b5dd-8f69f26e60d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1c30a0a6-3e9d-45e2-8703-08e7430e8bc4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 257dd3d4-b70d-4424-8ccd-3ff972d0bd4c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 57f90170-9012-4bac-be17-328911f2e86b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 27778972-933e-4d31-bd28-bdab7c4e2bfc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ee6a6d26-c1f3-4ee1-ac38-0005efdb754e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a0789b51-010d-4062-abc3-47ee3e827817
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message edb3ef83-ff64-4642-bb43-0f02ab79ae06
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 05913180-6329-4e6c-94e4-c3be6e4aeb96
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5da81329-0c59-4301-82cc-9855e7e4e0a0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 79fd0df3-4f63-425b-945e-aafaf8778a70
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 11a7f84a-d5c3-4078-82ff-9589b261a3cb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9fa74d71-87bf-4228-8027-ec19e3b49fd0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d25d26ce-eb3f-4ce5-b816-0d0ad56c5842
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 013f8d32-e656-4851-aa5a-7e2cca8d5d37
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 54c3329c-ab19-40d0-b658-af5ee885b1aa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a4c836b3-d3d5-4ff2-bf48-128f481117cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0d21079a-653f-4beb-8201-43a183254cc0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 58496b43-9b0e-46e4-ad7b-8aeb89255e60
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8cca8b8e-2b78-4e1e-9db7-c4166df73310
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8687 {grpc_message:"Socket closed", grpc_status:14}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_23
Server: localhost:8687
Algorithm: FEDAVG
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_23
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_23/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_23/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_23/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_23/test_labels.txt

📊 Raw data loaded:
   Train: X=(1172, 24), y=(1172,)
   Test:  X=(293, 24), y=(293,)

⚠️  Limiting training data: 1172 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  284 samples, 5 features
✅ Client client_23 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

============================================================
🔄 Round 2 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0798 (↓), lr=0.001000
   • Epoch   2/100: train=0.0802, val=0.0812, patience=1/15, lr=0.001000
   • Epoch   3/100: train=0.0812, val=0.0856, patience=2/15, lr=0.001000
   • Epoch   4/100: train=0.0804, val=0.0859, patience=3/15, lr=0.001000
   • Epoch   5/100: train=0.0793, val=0.0844, patience=4/15, lr=0.001000
   📉 Epoch 7: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0770, val=0.0833, patience=10/15, lr=0.000500
   📉 Epoch 15: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 2 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=-0.0204
   Val:   Loss=0.0798, RMSE=0.2824, R²=0.0020
============================================================


📊 Round 2 Test Metrics:
   Loss: 0.0910, RMSE: 0.3017, MAE: 0.2612, R²: -0.0399

📊 Round 2 Test Metrics:
   Loss: 0.0908, RMSE: 0.3013, MAE: 0.2607, R²: -0.0376

============================================================
🔄 Round 11 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0717 (↓), lr=0.000250
   ✓ Epoch   2/100: train=0.0807, val=0.0708 (↓), lr=0.000250
   • Epoch   3/100: train=0.0804, val=0.0709, patience=1/15, lr=0.000250
   • Epoch   4/100: train=0.0801, val=0.0708, patience=2/15, lr=0.000250
   • Epoch   5/100: train=0.0799, val=0.0708, patience=3/15, lr=0.000250
   • Epoch  11/100: train=0.0790, val=0.0706, patience=9/15, lr=0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0708)

============================================================
📊 Round 11 Summary - Client client_23
   Epochs: 17/100 (early stopped)
   LR: 0.000250 → 0.000250 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2836, R²=0.0042
   Val:   Loss=0.0708, RMSE=0.2661, R²=-0.0108
============================================================


📊 Round 11 Test Metrics:
   Loss: 0.0906, RMSE: 0.3011, MAE: 0.2604, R²: -0.0359

📊 Round 11 Test Metrics:
   Loss: 0.0907, RMSE: 0.3012, MAE: 0.2604, R²: -0.0366

📊 Round 11 Test Metrics:
   Loss: 0.0906, RMSE: 0.3009, MAE: 0.2600, R²: -0.0349

============================================================
🔄 Round 19 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0750 (↓), lr=0.000250
   • Epoch   2/100: train=0.0807, val=0.0748, patience=1/15, lr=0.000250
   ✓ Epoch   3/100: train=0.0802, val=0.0745 (↓), lr=0.000250
   • Epoch   4/100: train=0.0798, val=0.0745, patience=1/15, lr=0.000250
   • Epoch   5/100: train=0.0796, val=0.0744, patience=2/15, lr=0.000250
   📉 Epoch 6: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0788, val=0.0741, patience=8/15, lr=0.000125
   📉 Epoch 14: LR reduced 0.000125 → 0.000063
   • Epoch  21/100: train=0.0782, val=0.0739, patience=6/15, lr=0.000063
   📉 Epoch 22: LR reduced 0.000063 → 0.000031
   📉 Epoch 30: LR reduced 0.000031 → 0.000016

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0740)

============================================================
📊 Round 19 Summary - Client client_23
   Epochs: 30/100 (early stopped)
   LR: 0.000250 → 0.000016 (4 reductions)
   Train: Loss=0.0779, RMSE=0.2792, R²=0.0262
   Val:   Loss=0.0740, RMSE=0.2719, R²=-0.0091
============================================================


📊 Round 19 Test Metrics:
   Loss: 0.0907, RMSE: 0.3011, MAE: 0.2601, R²: -0.0363

============================================================
🔄 Round 22 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000016
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0721 (↓), lr=0.000016
   • Epoch   2/100: train=0.0831, val=0.0723, patience=1/15, lr=0.000016
   • Epoch   3/100: train=0.0824, val=0.0726, patience=2/15, lr=0.000016
   • Epoch   4/100: train=0.0820, val=0.0729, patience=3/15, lr=0.000016
   • Epoch   5/100: train=0.0818, val=0.0732, patience=4/15, lr=0.000016
   📉 Epoch 8: LR reduced 0.000016 → 0.000008
   • Epoch  11/100: train=0.0811, val=0.0737, patience=10/15, lr=0.000008
   📉 Epoch 16: LR reduced 0.000008 → 0.000004

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0721)

============================================================
📊 Round 22 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000016 → 0.000004 (2 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=-0.0471
   Val:   Loss=0.0721, RMSE=0.2685, R²=0.0325
============================================================


============================================================
🔄 Round 24 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000004
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0817 (↓), lr=0.000004
   • Epoch   2/100: train=0.0815, val=0.0814, patience=1/15, lr=0.000004
   ✓ Epoch   3/100: train=0.0814, val=0.0811 (↓), lr=0.000004
   • Epoch   4/100: train=0.0813, val=0.0809, patience=1/15, lr=0.000004
   • Epoch   5/100: train=0.0812, val=0.0807, patience=2/15, lr=0.000004
   📉 Epoch 8: LR reduced 0.000004 → 0.000002
   • Epoch  11/100: train=0.0809, val=0.0799, patience=1/15, lr=0.000002
   📉 Epoch 16: LR reduced 0.000002 → 0.000001
   ✓ Epoch  21/100: train=0.0807, val=0.0795 (↓), lr=0.000001
   • Epoch  31/100: train=0.0807, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 24 Summary - Client client_23
   Epochs: 36/100 (early stopped)
   LR: 0.000004 → 0.000001 (2 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=-0.0114
   Val:   Loss=0.0795, RMSE=0.2819, R²=-0.0929
============================================================


📊 Round 24 Test Metrics:
   Loss: 0.0907, RMSE: 0.3011, MAE: 0.2600, R²: -0.0364

============================================================
🔄 Round 25 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0840, patience=1/15, lr=0.000001
   • Epoch  21/100: train=0.0804, val=0.0836, patience=11/15, lr=0.000001
   • Epoch  31/100: train=0.0803, val=0.0832, patience=9/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 25 Summary - Client client_23
   Epochs: 37/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=-0.0248
   Val:   Loss=0.0835, RMSE=0.2890, R²=-0.0490
============================================================


📊 Round 25 Test Metrics:
   Loss: 0.0907, RMSE: 0.3011, MAE: 0.2600, R²: -0.0364

============================================================
🔄 Round 26 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 26 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=-0.0519
   Val:   Loss=0.0814, RMSE=0.2854, R²=0.0163
============================================================


📊 Round 26 Test Metrics:
   Loss: 0.0907, RMSE: 0.3012, MAE: 0.2600, R²: -0.0364

============================================================
🔄 Round 27 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0726 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0726, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0725, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0725, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0724, patience=4/15, lr=0.000001
   ✓ Epoch  11/100: train=0.0835, val=0.0721 (↓), lr=0.000001
   • Epoch  21/100: train=0.0832, val=0.0717, patience=10/15, lr=0.000001
   • Epoch  31/100: train=0.0830, val=0.0713, patience=7/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0716)

============================================================
📊 Round 27 Summary - Client client_23
   Epochs: 39/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=-0.0219
   Val:   Loss=0.0716, RMSE=0.2675, R²=-0.0530
============================================================


📊 Round 27 Test Metrics:
   Loss: 0.0907, RMSE: 0.3011, MAE: 0.2600, R²: -0.0363

============================================================
🔄 Round 28 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0772, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0772, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0769, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0818, val=0.0766, patience=7/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0768)

============================================================
📊 Round 28 Summary - Client client_23
   Epochs: 29/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=-0.0325
   Val:   Loss=0.0768, RMSE=0.2772, R²=-0.0146
============================================================


============================================================
🔄 Round 30 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 30 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2852, R²=-0.0478
   Val:   Loss=0.0824, RMSE=0.2871, R²=0.0089
============================================================


📊 Round 30 Test Metrics:
   Loss: 0.0907, RMSE: 0.3011, MAE: 0.2600, R²: -0.0363

============================================================
🔄 Round 32 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 32 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=-0.0231
   Val:   Loss=0.0857, RMSE=0.2928, R²=-0.0868
============================================================


📊 Round 32 Test Metrics:
   Loss: 0.0907, RMSE: 0.3011, MAE: 0.2600, R²: -0.0363

📊 Round 32 Test Metrics:
   Loss: 0.0907, RMSE: 0.3012, MAE: 0.2600, R²: -0.0364

============================================================
🔄 Round 36 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0815, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0808, val=0.0812, patience=7/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 36 Summary - Client client_23
   Epochs: 29/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=-0.0231
   Val:   Loss=0.0814, RMSE=0.2853, R²=-0.0561
============================================================


============================================================
🔄 Round 37 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0765 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0764, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0764, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0764, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0763, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0761, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0765)

============================================================
📊 Round 37 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=-0.0419
   Val:   Loss=0.0765, RMSE=0.2765, R²=-0.0094
============================================================


📊 Round 37 Test Metrics:
   Loss: 0.0907, RMSE: 0.3011, MAE: 0.2600, R²: -0.0364

============================================================
🔄 Round 38 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 38 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=-0.0377
   Val:   Loss=0.0797, RMSE=0.2823, R²=-0.0300
============================================================


📊 Round 38 Test Metrics:
   Loss: 0.0907, RMSE: 0.3012, MAE: 0.2600, R²: -0.0364

============================================================
🔄 Round 40 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0881 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0881, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0881, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0880, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0880, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0878, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0881)

============================================================
📊 Round 40 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=-0.0370
   Val:   Loss=0.0881, RMSE=0.2969, R²=-0.0309
============================================================


📊 Round 40 Test Metrics:
   Loss: 0.0907, RMSE: 0.3012, MAE: 0.2600, R²: -0.0364

============================================================
🔄 Round 42 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 42 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=-0.0308
   Val:   Loss=0.0800, RMSE=0.2828, R²=-0.0586
============================================================


============================================================
🔄 Round 43 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0758 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0758, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0757, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0757, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0757, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0755, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0758)

============================================================
📊 Round 43 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=-0.0376
   Val:   Loss=0.0758, RMSE=0.2754, R²=-0.0296
============================================================


📊 Round 43 Test Metrics:
   Loss: 0.0907, RMSE: 0.3012, MAE: 0.2600, R²: -0.0365

============================================================
🔄 Round 45 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0783, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0817, val=0.0780, patience=5/15, lr=0.000001
   • Epoch  31/100: train=0.0815, val=0.0778, patience=15/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 45 Summary - Client client_23
   Epochs: 31/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=-0.0293
   Val:   Loss=0.0781, RMSE=0.2795, R²=-0.0301
============================================================


📊 Round 45 Test Metrics:
   Loss: 0.0907, RMSE: 0.3012, MAE: 0.2600, R²: -0.0365

📊 Round 45 Test Metrics:
   Loss: 0.0907, RMSE: 0.3012, MAE: 0.2600, R²: -0.0365

============================================================
🔄 Round 47 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0811, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0808, val=0.0807, patience=9/15, lr=0.000001
   • Epoch  31/100: train=0.0806, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  41/100: train=0.0805, val=0.0802, patience=14/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 47 Summary - Client client_23
   Epochs: 42/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=-0.0159
   Val:   Loss=0.0805, RMSE=0.2838, R²=-0.0699
============================================================


📊 Round 47 Test Metrics:
   Loss: 0.0907, RMSE: 0.3012, MAE: 0.2600, R²: -0.0364

📊 Round 47 Test Metrics:
   Loss: 0.0907, RMSE: 0.3012, MAE: 0.2600, R²: -0.0366

============================================================
🔄 Round 53 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0771, val=0.0989 (↓), lr=0.000001
   • Epoch   2/100: train=0.0770, val=0.0988, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0770, val=0.0987, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0770, val=0.0987, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0770, val=0.0986, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0768, val=0.0982, patience=2/15, lr=0.000001
   • Epoch  21/100: train=0.0766, val=0.0977, patience=2/15, lr=0.000001
   ✓ Epoch  31/100: train=0.0765, val=0.0973 (↓), lr=0.000001
   • Epoch  41/100: train=0.0764, val=0.0969, patience=10/15, lr=0.000001
   • Epoch  51/100: train=0.0763, val=0.0966, patience=5/15, lr=0.000001
   • Epoch  61/100: train=0.0763, val=0.0963, patience=15/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0967)

============================================================
📊 Round 53 Summary - Client client_23
   Epochs: 61/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0765, RMSE=0.2767, R²=-0.0065
   Val:   Loss=0.0967, RMSE=0.3110, R²=-0.0946
============================================================


📊 Round 53 Test Metrics:
   Loss: 0.0907, RMSE: 0.3012, MAE: 0.2600, R²: -0.0365

============================================================
🔄 Round 56 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 56 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=-0.0410
   Val:   Loss=0.0836, RMSE=0.2891, R²=-0.0273
============================================================


============================================================
🔄 Round 57 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0832, patience=4/15, lr=0.000001
   ✓ Epoch  11/100: train=0.0807, val=0.0829 (↓), lr=0.000001
   • Epoch  21/100: train=0.0804, val=0.0825, patience=10/15, lr=0.000001
   • Epoch  31/100: train=0.0802, val=0.0822, patience=6/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 57 Summary - Client client_23
   Epochs: 40/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=-0.0229
   Val:   Loss=0.0824, RMSE=0.2870, R²=-0.0381
============================================================


============================================================
🔄 Round 58 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 58 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=-0.0473
   Val:   Loss=0.0783, RMSE=0.2799, R²=0.0081
============================================================


📊 Round 58 Test Metrics:
   Loss: 0.0907, RMSE: 0.3012, MAE: 0.2600, R²: -0.0364

============================================================
🔄 Round 59 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 59 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2866, R²=-0.0481
   Val:   Loss=0.0790, RMSE=0.2810, R²=0.0154
============================================================


============================================================
🔄 Round 60 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0761 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0761, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0762, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0762, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0762, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0763, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0761)

============================================================
📊 Round 60 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=-0.0308
   Val:   Loss=0.0761, RMSE=0.2759, R²=-0.0801
============================================================


📊 Round 60 Test Metrics:
   Loss: 0.0907, RMSE: 0.3012, MAE: 0.2600, R²: -0.0365

📊 Round 60 Test Metrics:
   Loss: 0.0907, RMSE: 0.3012, MAE: 0.2600, R²: -0.0366

============================================================
🔄 Round 71 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0779 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0778, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0778, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0777, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0777, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0775, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0815, val=0.0772, patience=7/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0774)

============================================================
📊 Round 71 Summary - Client client_23
   Epochs: 29/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=-0.0330
   Val:   Loss=0.0774, RMSE=0.2782, R²=-0.0161
============================================================


📊 Round 71 Test Metrics:
   Loss: 0.0907, RMSE: 0.3012, MAE: 0.2600, R²: -0.0368

============================================================
🔄 Round 73 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0796, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0812, val=0.0793, patience=8/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 73 Summary - Client client_23
   Epochs: 28/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=-0.0328
   Val:   Loss=0.0796, RMSE=0.2821, R²=-0.0210
============================================================


📊 Round 73 Test Metrics:
   Loss: 0.0907, RMSE: 0.3012, MAE: 0.2600, R²: -0.0368

============================================================
🔄 Round 75 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 75 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=-0.0362
   Val:   Loss=0.0809, RMSE=0.2844, R²=-0.0342
============================================================


📊 Round 75 Test Metrics:
   Loss: 0.0907, RMSE: 0.3012, MAE: 0.2601, R²: -0.0369

📊 Round 75 Test Metrics:
   Loss: 0.0907, RMSE: 0.3012, MAE: 0.2601, R²: -0.0370

============================================================
🔄 Round 79 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0878 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0877, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0877, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0877, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0877, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0875, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0878)

============================================================
📊 Round 79 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=-0.0431
   Val:   Loss=0.0878, RMSE=0.2963, R²=-0.0133
============================================================


📊 Round 79 Test Metrics:
   Loss: 0.0907, RMSE: 0.3012, MAE: 0.2601, R²: -0.0370

📊 Round 79 Test Metrics:
   Loss: 0.0907, RMSE: 0.3012, MAE: 0.2601, R²: -0.0370

============================================================
🔄 Round 82 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0750 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0749, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0749, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0748, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0747, patience=4/15, lr=0.000001
   ✓ Epoch  11/100: train=0.0830, val=0.0745 (↓), lr=0.000001
   • Epoch  21/100: train=0.0827, val=0.0741, patience=10/15, lr=0.000001
   • Epoch  31/100: train=0.0825, val=0.0738, patience=5/15, lr=0.000001
   • Epoch  41/100: train=0.0824, val=0.0736, patience=15/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0739)

============================================================
📊 Round 82 Summary - Client client_23
   Epochs: 41/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2873, R²=-0.0270
   Val:   Loss=0.0739, RMSE=0.2719, R²=-0.0323
============================================================


📊 Round 82 Test Metrics:
   Loss: 0.0907, RMSE: 0.3012, MAE: 0.2601, R²: -0.0369

============================================================
🔄 Round 84 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0778, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0777, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0777, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0777, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 84 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=-0.0410
   Val:   Loss=0.0778, RMSE=0.2790, R²=-0.0139
============================================================


📊 Round 84 Test Metrics:
   Loss: 0.0907, RMSE: 0.3012, MAE: 0.2601, R²: -0.0369

============================================================
🔄 Round 87 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0673 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0673, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0672, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0672, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0671, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0669, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0844, val=0.0665, patience=8/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0668)

============================================================
📊 Round 87 Summary - Client client_23
   Epochs: 28/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2911, R²=-0.0338
   Val:   Loss=0.0668, RMSE=0.2584, R²=-0.0180
============================================================


📊 Round 87 Test Metrics:
   Loss: 0.0907, RMSE: 0.3012, MAE: 0.2601, R²: -0.0369

============================================================
🔄 Round 89 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0767 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0767, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0767, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0768, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0768, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0770, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0767)

============================================================
📊 Round 89 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=-0.0548
   Val:   Loss=0.0767, RMSE=0.2769, R²=0.0075
============================================================


📊 Round 89 Test Metrics:
   Loss: 0.0908, RMSE: 0.3012, MAE: 0.2601, R²: -0.0371

============================================================
🔄 Round 93 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0785, patience=4/15, lr=0.000001
   ✓ Epoch  11/100: train=0.0821, val=0.0782 (↓), lr=0.000001
   • Epoch  21/100: train=0.0819, val=0.0778, patience=10/15, lr=0.000001
   • Epoch  31/100: train=0.0817, val=0.0775, patience=7/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 93 Summary - Client client_23
   Epochs: 39/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2859, R²=-0.0196
   Val:   Loss=0.0777, RMSE=0.2787, R²=-0.0733
============================================================


📊 Round 93 Test Metrics:
   Loss: 0.0908, RMSE: 0.3013, MAE: 0.2601, R²: -0.0371

📊 Round 93 Test Metrics:
   Loss: 0.0908, RMSE: 0.3013, MAE: 0.2601, R²: -0.0372

============================================================
🔄 Round 100 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0731 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0731, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0730, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0730, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0729, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0727, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0731)

============================================================
📊 Round 100 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=-0.0398
   Val:   Loss=0.0731, RMSE=0.2704, R²=-0.0196
============================================================


📊 Round 100 Test Metrics:
   Loss: 0.0908, RMSE: 0.3013, MAE: 0.2601, R²: -0.0372

============================================================
🔄 Round 101 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0863 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 101 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=-0.0426
   Val:   Loss=0.0863, RMSE=0.2937, R²=-0.0255
============================================================


📊 Round 101 Test Metrics:
   Loss: 0.0908, RMSE: 0.3013, MAE: 0.2601, R²: -0.0373

📊 Round 101 Test Metrics:
   Loss: 0.0908, RMSE: 0.3013, MAE: 0.2601, R²: -0.0373

============================================================
🔄 Round 103 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 103 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2861, R²=-0.0315
   Val:   Loss=0.0805, RMSE=0.2838, R²=-0.0559
============================================================


============================================================
🔄 Round 107 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 107 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=-0.0397
   Val:   Loss=0.0787, RMSE=0.2805, R²=-0.0384
============================================================


============================================================
🔄 Round 109 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0777 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0777, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0777, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0777, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0777, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0777, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 109 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2873, R²=-0.0382
   Val:   Loss=0.0777, RMSE=0.2787, R²=-0.0485
============================================================


============================================================
🔄 Round 110 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0885 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0885, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0884, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0884, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0884, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0881, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0791, val=0.0878, patience=7/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0880)

============================================================
📊 Round 110 Summary - Client client_23
   Epochs: 29/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2818, R²=-0.0301
   Val:   Loss=0.0880, RMSE=0.2967, R²=-0.0336
============================================================


📊 Round 110 Test Metrics:
   Loss: 0.0908, RMSE: 0.3013, MAE: 0.2601, R²: -0.0375

📊 Round 110 Test Metrics:
   Loss: 0.0908, RMSE: 0.3013, MAE: 0.2602, R²: -0.0375

============================================================
🔄 Round 121 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 121 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=-0.0486
   Val:   Loss=0.0804, RMSE=0.2836, R²=-0.0090
============================================================


📊 Round 121 Test Metrics:
   Loss: 0.0908, RMSE: 0.3013, MAE: 0.2602, R²: -0.0378

============================================================
🔄 Round 123 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 123 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=-0.0401
   Val:   Loss=0.0813, RMSE=0.2851, R²=-0.0240
============================================================


============================================================
🔄 Round 127 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0788, patience=1/15, lr=0.000001
   ✓ Epoch  21/100: train=0.0817, val=0.0783 (↓), lr=0.000001
   • Epoch  31/100: train=0.0815, val=0.0779, patience=10/15, lr=0.000001
   • Epoch  41/100: train=0.0814, val=0.0776, patience=6/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 127 Summary - Client client_23
   Epochs: 50/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=-0.0236
   Val:   Loss=0.0777, RMSE=0.2788, R²=-0.0639
============================================================


============================================================
🔄 Round 128 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 128 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2861, R²=-0.0445
   Val:   Loss=0.0805, RMSE=0.2837, R²=-0.0190
============================================================


📊 Round 128 Test Metrics:
   Loss: 0.0908, RMSE: 0.3013, MAE: 0.2602, R²: -0.0377

============================================================
🔄 Round 129 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0762 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0761, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0761, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0760, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0760, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0756, patience=1/15, lr=0.000001
   • Epoch  21/100: train=0.0826, val=0.0752, patience=11/15, lr=0.000001
   • Epoch  31/100: train=0.0824, val=0.0748, patience=9/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0752)

============================================================
📊 Round 129 Summary - Client client_23
   Epochs: 37/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=-0.0333
   Val:   Loss=0.0752, RMSE=0.2741, R²=-0.0127
============================================================


============================================================
🔄 Round 130 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0826, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0804, val=0.0823, patience=7/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 130 Summary - Client client_23
   Epochs: 29/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=-0.0211
   Val:   Loss=0.0825, RMSE=0.2873, R²=-0.0663
============================================================


📊 Round 130 Test Metrics:
   Loss: 0.0908, RMSE: 0.3013, MAE: 0.2602, R²: -0.0376

📊 Round 130 Test Metrics:
   Loss: 0.0908, RMSE: 0.3013, MAE: 0.2602, R²: -0.0376

============================================================
🔄 Round 134 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0776 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0776, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0774, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0772, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0820, val=0.0769, patience=6/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0771)

============================================================
📊 Round 134 Summary - Client client_23
   Epochs: 30/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=-0.0266
   Val:   Loss=0.0771, RMSE=0.2776, R²=-0.0402
============================================================


📊 Round 134 Test Metrics:
   Loss: 0.0908, RMSE: 0.3013, MAE: 0.2602, R²: -0.0376

============================================================
🔄 Round 135 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0825, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0805, val=0.0822, patience=5/15, lr=0.000001
   • Epoch  31/100: train=0.0802, val=0.0820, patience=15/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 135 Summary - Client client_23
   Epochs: 31/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=-0.0248
   Val:   Loss=0.0823, RMSE=0.2869, R²=-0.0414
============================================================


📊 Round 135 Test Metrics:
   Loss: 0.0908, RMSE: 0.3013, MAE: 0.2601, R²: -0.0375

============================================================
🔄 Round 136 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0709 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0709, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0709, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0709, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0709, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0709, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0709)

============================================================
📊 Round 136 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=-0.0481
   Val:   Loss=0.0709, RMSE=0.2663, R²=0.0109
============================================================


📊 Round 136 Test Metrics:
   Loss: 0.0908, RMSE: 0.3013, MAE: 0.2601, R²: -0.0375

📊 Round 136 Test Metrics:
   Loss: 0.0908, RMSE: 0.3013, MAE: 0.2601, R²: -0.0375

============================================================
🔄 Round 138 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 138 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=-0.0436
   Val:   Loss=0.0864, RMSE=0.2939, R²=-0.0225
============================================================


📊 Round 138 Test Metrics:
   Loss: 0.0908, RMSE: 0.3013, MAE: 0.2602, R²: -0.0376

📊 Round 138 Test Metrics:
   Loss: 0.0908, RMSE: 0.3013, MAE: 0.2602, R²: -0.0376

📊 Round 138 Test Metrics:
   Loss: 0.0908, RMSE: 0.3013, MAE: 0.2602, R²: -0.0377

============================================================
🔄 Round 147 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0869 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0869, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0868, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0868, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0868, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0866, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 147 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2833, R²=-0.0475
   Val:   Loss=0.0869, RMSE=0.2948, R²=0.0046
============================================================


📊 Round 147 Test Metrics:
   Loss: 0.0908, RMSE: 0.3013, MAE: 0.2602, R²: -0.0377

============================================================
🔄 Round 148 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0683 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0683, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0682, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0682, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0682, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0680, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0683)

============================================================
📊 Round 148 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2913, R²=-0.0376
   Val:   Loss=0.0683, RMSE=0.2613, R²=-0.0282
============================================================


============================================================
🔄 Round 149 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0833, patience=1/15, lr=0.000001
   • Epoch  21/100: train=0.0803, val=0.0829, patience=11/15, lr=0.000001
   • Epoch  31/100: train=0.0801, val=0.0825, patience=9/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 149 Summary - Client client_23
   Epochs: 37/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=-0.0107
   Val:   Loss=0.0828, RMSE=0.2878, R²=-0.1019
============================================================


📊 Round 149 Test Metrics:
   Loss: 0.0908, RMSE: 0.3013, MAE: 0.2602, R²: -0.0377

📊 Round 149 Test Metrics:
   Loss: 0.0908, RMSE: 0.3013, MAE: 0.2602, R²: -0.0378

📊 Round 149 Test Metrics:
   Loss: 0.0908, RMSE: 0.3014, MAE: 0.2602, R²: -0.0378

📊 Round 149 Test Metrics:
   Loss: 0.0908, RMSE: 0.3014, MAE: 0.2602, R²: -0.0378

📊 Round 149 Test Metrics:
   Loss: 0.0908, RMSE: 0.3014, MAE: 0.2602, R²: -0.0379

============================================================
🔄 Round 159 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0885 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0885, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0884, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0884, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0883, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0881, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0793, val=0.0878, patience=6/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0880)

============================================================
📊 Round 159 Summary - Client client_23
   Epochs: 30/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2816, R²=-0.0235
   Val:   Loss=0.0880, RMSE=0.2966, R²=-0.0511
============================================================


============================================================
🔄 Round 160 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 160 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2840, R²=-0.0485
   Val:   Loss=0.0852, RMSE=0.2918, R²=-0.0059
============================================================


============================================================
🔄 Round 161 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 161 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2863, R²=-0.0432
   Val:   Loss=0.0800, RMSE=0.2828, R²=-0.0104
============================================================


📊 Round 161 Test Metrics:
   Loss: 0.0908, RMSE: 0.3014, MAE: 0.2602, R²: -0.0378

📊 Round 161 Test Metrics:
   Loss: 0.0908, RMSE: 0.3014, MAE: 0.2602, R²: -0.0378

============================================================
🔄 Round 164 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0806, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0811, val=0.0802, patience=9/15, lr=0.000001
   • Epoch  31/100: train=0.0809, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  41/100: train=0.0808, val=0.0797, patience=14/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 164 Summary - Client client_23
   Epochs: 42/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2845, R²=-0.0157
   Val:   Loss=0.0800, RMSE=0.2829, R²=-0.0701
============================================================


📊 Round 164 Test Metrics:
   Loss: 0.0908, RMSE: 0.3013, MAE: 0.2602, R²: -0.0377

============================================================
🔄 Round 167 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0840, patience=1/15, lr=0.000001
   • Epoch  21/100: train=0.0800, val=0.0835, patience=11/15, lr=0.000001
   • Epoch  31/100: train=0.0798, val=0.0832, patience=9/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 167 Summary - Client client_23
   Epochs: 37/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2833, R²=-0.0204
   Val:   Loss=0.0835, RMSE=0.2890, R²=-0.0696
============================================================


📊 Round 167 Test Metrics:
   Loss: 0.0908, RMSE: 0.3013, MAE: 0.2602, R²: -0.0377

============================================================
🔄 Round 171 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0764 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0764, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0763, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0763, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0763, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0761, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0764)

============================================================
📊 Round 171 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=-0.0373
   Val:   Loss=0.0764, RMSE=0.2764, R²=-0.0289
============================================================


📊 Round 171 Test Metrics:
   Loss: 0.0908, RMSE: 0.3014, MAE: 0.2602, R²: -0.0378

📊 Round 171 Test Metrics:
   Loss: 0.0908, RMSE: 0.3014, MAE: 0.2602, R²: -0.0378

============================================================
🔄 Round 174 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 174 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=-0.0340
   Val:   Loss=0.0808, RMSE=0.2843, R²=-0.0634
============================================================


============================================================
🔄 Round 175 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 175 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=-0.0382
   Val:   Loss=0.0847, RMSE=0.2910, R²=-0.0263
============================================================


📊 Round 175 Test Metrics:
   Loss: 0.0908, RMSE: 0.3014, MAE: 0.2602, R²: -0.0379

============================================================
🔄 Round 176 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0875 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0874, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0874, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0873, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0873, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0870, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0795, val=0.0867, patience=8/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 176 Summary - Client client_23
   Epochs: 28/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2822, R²=-0.0233
   Val:   Loss=0.0869, RMSE=0.2949, R²=-0.0559
============================================================


📊 Round 176 Test Metrics:
   Loss: 0.0908, RMSE: 0.3014, MAE: 0.2602, R²: -0.0379

📊 Round 176 Test Metrics:
   Loss: 0.0908, RMSE: 0.3014, MAE: 0.2602, R²: -0.0379

============================================================
🔄 Round 179 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0784, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0813, val=0.0781, patience=8/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 179 Summary - Client client_23
   Epochs: 28/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=-0.0348
   Val:   Loss=0.0783, RMSE=0.2799, R²=-0.0117
============================================================


============================================================
🔄 Round 180 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0772, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0772, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0771, patience=4/15, lr=0.000001
   ✓ Epoch  11/100: train=0.0825, val=0.0768 (↓), lr=0.000001
   • Epoch  21/100: train=0.0823, val=0.0764, patience=10/15, lr=0.000001
   • Epoch  31/100: train=0.0821, val=0.0761, patience=7/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0763)

============================================================
📊 Round 180 Summary - Client client_23
   Epochs: 39/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=-0.0232
   Val:   Loss=0.0763, RMSE=0.2762, R²=-0.0462
============================================================


📊 Round 180 Test Metrics:
   Loss: 0.0908, RMSE: 0.3013, MAE: 0.2602, R²: -0.0378

============================================================
🔄 Round 181 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0737 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0737, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0737, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0736, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0736, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0736, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0737)

============================================================
📊 Round 181 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=-0.0457
   Val:   Loss=0.0737, RMSE=0.2714, R²=0.0013
============================================================


📊 Round 181 Test Metrics:
   Loss: 0.0908, RMSE: 0.3014, MAE: 0.2602, R²: -0.0378

============================================================
🔄 Round 183 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 183 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2868, R²=-0.0301
   Val:   Loss=0.0786, RMSE=0.2804, R²=-0.0619
============================================================


============================================================
🔄 Round 184 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0717 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0716, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0716, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0715, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0715, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0712, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0834, val=0.0709, patience=9/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0712)

============================================================
📊 Round 184 Summary - Client client_23
   Epochs: 27/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=-0.0291
   Val:   Loss=0.0712, RMSE=0.2668, R²=-0.0354
============================================================


📊 Round 184 Test Metrics:
   Loss: 0.0908, RMSE: 0.3013, MAE: 0.2602, R²: -0.0377

============================================================
🔄 Round 186 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0890 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0890, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0889, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0888, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0888, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0884, patience=1/15, lr=0.000001
   • Epoch  21/100: train=0.0790, val=0.0879, patience=1/15, lr=0.000001
   • Epoch  31/100: train=0.0789, val=0.0875, patience=11/15, lr=0.000001
   • Epoch  41/100: train=0.0788, val=0.0872, patience=8/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0874)

============================================================
📊 Round 186 Summary - Client client_23
   Epochs: 48/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2812, R²=-0.0165
   Val:   Loss=0.0874, RMSE=0.2957, R²=-0.0794
============================================================


============================================================
🔄 Round 187 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0863 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 187 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=-0.0444
   Val:   Loss=0.0863, RMSE=0.2938, R²=-0.0023
============================================================


============================================================
🔄 Round 188 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0818, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0808, val=0.0816, patience=6/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 188 Summary - Client client_23
   Epochs: 30/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=-0.0321
   Val:   Loss=0.0817, RMSE=0.2858, R²=-0.0143
============================================================


📊 Round 188 Test Metrics:
   Loss: 0.0908, RMSE: 0.3013, MAE: 0.2601, R²: -0.0377

============================================================
🔄 Round 190 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 190 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=-0.0365
   Val:   Loss=0.0860, RMSE=0.2933, R²=-0.0394
============================================================


============================================================
🔄 Round 191 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0770 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0770, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0770, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0769, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0769, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0766, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0823, val=0.0763, patience=7/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0765)

============================================================
📊 Round 191 Summary - Client client_23
   Epochs: 29/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2866, R²=-0.0399
   Val:   Loss=0.0765, RMSE=0.2766, R²=0.0147
============================================================


📊 Round 191 Test Metrics:
   Loss: 0.0908, RMSE: 0.3013, MAE: 0.2601, R²: -0.0376

============================================================
🔄 Round 192 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0871 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0871, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0870, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0870, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0870, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0869, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0871)

============================================================
📊 Round 192 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=-0.0458
   Val:   Loss=0.0871, RMSE=0.2951, R²=-0.0002
============================================================


📊 Round 192 Test Metrics:
   Loss: 0.0908, RMSE: 0.3013, MAE: 0.2601, R²: -0.0377

============================================================
🔄 Round 194 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0828, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0803, val=0.0825, patience=7/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 194 Summary - Client client_23
   Epochs: 29/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2840, R²=-0.0390
   Val:   Loss=0.0827, RMSE=0.2875, R²=0.0043
============================================================


============================================================
🔄 Round 196 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0756 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0756, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0756, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0755, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0755, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0753, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0756)

============================================================
📊 Round 196 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2880, R²=-0.0273
   Val:   Loss=0.0756, RMSE=0.2750, R²=-0.0713
============================================================


📊 Round 196 Test Metrics:
   Loss: 0.0908, RMSE: 0.3013, MAE: 0.2602, R²: -0.0377

============================================================
🔄 Round 200 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0872 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0871, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0870, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0870, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0869, patience=4/15, lr=0.000001
   ✓ Epoch  11/100: train=0.0798, val=0.0866 (↓), lr=0.000001
   • Epoch  21/100: train=0.0796, val=0.0862, patience=10/15, lr=0.000001
   • Epoch  31/100: train=0.0794, val=0.0859, patience=7/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 200 Summary - Client client_23
   Epochs: 39/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2820, R²=-0.0294
   Val:   Loss=0.0861, RMSE=0.2935, R²=-0.0288
============================================================


📊 Round 200 Test Metrics:
   Loss: 0.0908, RMSE: 0.3013, MAE: 0.2602, R²: -0.0377

📊 Round 200 Test Metrics:
   Loss: 0.0908, RMSE: 0.3013, MAE: 0.2602, R²: -0.0377

============================================================
🔄 Round 203 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0829, patience=4/15, lr=0.000001
   ✓ Epoch  11/100: train=0.0810, val=0.0826 (↓), lr=0.000001
   • Epoch  21/100: train=0.0807, val=0.0822, patience=10/15, lr=0.000001
   • Epoch  31/100: train=0.0806, val=0.0819, patience=7/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 203 Summary - Client client_23
   Epochs: 39/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=-0.0228
   Val:   Loss=0.0821, RMSE=0.2865, R²=-0.0477
============================================================


============================================================
🔄 Round 204 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0793, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0814, val=0.0790, patience=5/15, lr=0.000001
   • Epoch  31/100: train=0.0812, val=0.0788, patience=15/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 204 Summary - Client client_23
   Epochs: 31/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=-0.0252
   Val:   Loss=0.0791, RMSE=0.2813, R²=-0.0406
============================================================


📊 Round 204 Test Metrics:
   Loss: 0.0908, RMSE: 0.3013, MAE: 0.2601, R²: -0.0376

============================================================
🔄 Round 208 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 208 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=-0.0377
   Val:   Loss=0.0799, RMSE=0.2826, R²=-0.0263
============================================================


📊 Round 208 Test Metrics:
   Loss: 0.0908, RMSE: 0.3013, MAE: 0.2601, R²: -0.0377

============================================================
🔄 Round 209 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 209 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2868, R²=-0.0423
   Val:   Loss=0.0784, RMSE=0.2800, R²=-0.0162
============================================================


📊 Round 209 Test Metrics:
   Loss: 0.0908, RMSE: 0.3014, MAE: 0.2602, R²: -0.0378

============================================================
🔄 Round 211 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 211 Summary - Client client_23
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=-0.0379
   Val:   Loss=0.0847, RMSE=0.2910, R²=-0.0291
============================================================


============================================================
🔄 Round 214 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0855, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0797, val=0.0851, patience=9/15, lr=0.000001
   • Epoch  31/100: train=0.0795, val=0.0848, patience=5/15, lr=0.000001
   • Epoch  41/100: train=0.0794, val=0.0845, patience=15/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 214 Summary - Client client_23
   Epochs: 41/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2824, R²=-0.0235
   Val:   Loss=0.0849, RMSE=0.2914, R²=-0.0466
============================================================


📊 Round 214 Test Metrics:
   Loss: 0.0908, RMSE: 0.3014, MAE: 0.2602, R²: -0.0378

============================================================
🔄 Round 216 - Client client_23
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0822, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0807, val=0.0818, patience=9/15, lr=0.000001
   • Epoch  31/100: train=0.0805, val=0.0815, patience=5/15, lr=0.000001
   • Epoch  41/100: train=0.0804, val=0.0812, patience=15/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 216 Summary - Client client_23
   Epochs: 41/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2838, R²=-0.0321
   Val:   Loss=0.0816, RMSE=0.2857, R²=-0.0090
============================================================


📊 Round 216 Test Metrics:
   Loss: 0.0908, RMSE: 0.3013, MAE: 0.2601, R²: -0.0377

📊 Round 216 Test Metrics:
   Loss: 0.0908, RMSE: 0.3014, MAE: 0.2602, R²: -0.0378

📊 Round 216 Test Metrics:
   Loss: 0.0908, RMSE: 0.3014, MAE: 0.2602, R²: -0.0378

📊 Round 216 Test Metrics:
   Loss: 0.0908, RMSE: 0.3014, MAE: 0.2602, R²: -0.0379

❌ Client client_23 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8687 {grpc_message:"Socket closed", grpc_status:14}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8687 {grpc_message:"Socket closed", grpc_status:14}"
>
