[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4a63c957-5871-4640-bbd2-ffb5baadc8c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2e22d1f2-f5a5-4636-a1aa-17981639555b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 64b23dc5-afc9-4e22-81bb-b136a99596e1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f29089c9-a91f-4115-96d6-eae2bb179484
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e5313834-27c1-4ff3-9178-6f77e1757aa5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 28d8d034-ecfb-4e2d-8a27-3d253318fd8d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e8c6b346-6986-482b-a128-234b5a3c5209
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 664d89d1-2ace-4c23-958c-1f68582e823a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 25e63ed7-41fd-4c5b-b7ea-f4b2c2d52921
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9ad3f9a5-d0d3-4adb-9838-7c54ad34970d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4828aa72-1604-4b30-b505-0bc2dacbe619
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message df100f76-dd1d-4924-9829-f2f784cb73eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0a75571b-0997-4d52-b7c9-8feae16da194
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7e7abbb0-cce2-473a-be7a-028c5aa77d02
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3cf1b49e-e1f4-4870-9a47-381926621778
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4c78ca50-eaeb-473b-a1cc-952c976e6658
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 426fc400-317f-4b7e-bbca-a01f914b60f3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6e24a7be-6621-40d3-b917-8f2221ae185c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9c48a01b-361b-4af9-8e1c-0a7c85b721ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dd6dd958-abdc-47f9-9e61-38a211de224f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7ab94c57-28ab-4130-97d9-332a7ceacbe2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8c3ade7a-efc5-4aca-ada2-2642c16c9e6b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 722c9785-e871-4c35-b4fa-42a2c7087e59
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b2bdd2ff-bf94-4e85-b10e-ba8b159554d8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5f5abda8-f51f-48b2-acb6-41afc8b2e924
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c55302c7-9c77-4f29-a11a-9ef647d68cf3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 18a33bf1-ca08-41c5-8fbf-efd41ab6550f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4421a098-71d9-4761-8443-16572a2aa398
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e534bfb6-f186-413a-aa1c-cd1aebb95035
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f71e0b7b-d345-4f7b-9fd7-c5cc8eb9fc44
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 17542289-5304-4d9e-afca-e2ac048cf338
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f0ccef32-6b22-4f49-ab7d-93cf529fdb0b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6cbaa117-2ab7-413a-a627-8fc4728159c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6ac3cdc2-5715-4420-8487-b98bd068a83f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message caa47f5d-48b2-45f5-b70e-908a528d9c8c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f796e609-a0a9-41e6-a96b-8f9b51afffde
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d3608ec1-2f25-4b10-b89d-25eb25307456
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9f98ca1a-a761-49e4-9531-d9ae805083cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 45367a15-a624-4d41-97d7-003ea1f39e5e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a0ef8241-e0b2-4ea8-b8c4-597dbfd3ce2f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5945d382-fa09-44f8-bfeb-f1baac008652
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4201e78b-826f-4869-af2a-ae48a79e4364
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ebd42e30-bfd1-450f-9e84-505dea1bd311
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 89ff1777-5568-40b8-90f1-dd8764883071
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a0dbb810-3449-4536-8879-daaa4b7d3859
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 30b7efff-a8ac-414e-966a-94dbd0b24d29
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b783de6c-683c-4f2a-b665-ffa23ff15e09
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2bea0c20-118c-498f-9322-e61f06ed7b3f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d4e117aa-6a5a-4131-8a0a-6fc61af366a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 45dbf050-718b-476f-8a18-4da51a9826bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 40b78ca8-8e94-4d28-8fcf-3e693c8b3146
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3a4655ff-0f22-4f09-ab3d-33defb7b52b7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e2955d6b-7444-426a-a812-525265c7d590
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message decc5d62-077e-4098-955b-5c0cac7f8f8c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7710b35b-28b5-4270-aa39-eec6f4fbd571
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6aabeba3-7132-4804-beca-af2c46db5462
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 17795897-5894-4076-b122-0751072f1817
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 836884e0-b90f-43d2-9ead-01dd25e84a2e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bc8f1473-0c95-47fa-8cdf-e3533b2b5f48
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d0aa52a1-4c5a-4019-9ffe-3aeb4f887552
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2c4e1165-f764-4a19-980e-5f891ae3216d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ac1c2529-c65f-41e2-9170-a82d4d83fb14
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c62eaccf-121e-43d4-911a-184008acc796
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 82d08f3f-a875-4741-943c-434f0743e4a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a39b257e-0628-417c-bb6b-5776f06fcc45
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 35c8fc70-64fd-4f7a-a118-838321302849
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7430e170-4c66-40b7-9a0d-18a595523dd1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0fc6408f-a67a-4ac6-8d8c-98c72fd041f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f1d54c76-3574-4f50-9781-c559fb042707
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 251f4a4e-06cb-4408-b7c2-0a528d724365
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bafae666-2ad8-448d-afa7-f149d4a59501
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c44fb176-d6b8-4a92-bb42-ef9133a7f252
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c34491ef-f819-4663-8d91-184f79891e40
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 50a0fa4f-58ae-4e3d-a58a-79c584ecfb72
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4c2d58ee-9822-4c72-bc6d-2dc87ccf262c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d11791d0-b117-439c-9635-068e515051bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9e4e8351-bfae-4482-8fa3-a9eb09f7e160
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0f185551-7fe3-436b-9d97-04e16acb1cf8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5f231980-7cd7-4345-9780-a90c39aeb3e1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e1442e62-7b30-49f2-9fdc-06d2a45cfc36
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 43b44ffa-3e71-430e-9f56-0f8428e91577
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6bd453b6-8879-4b21-ae5b-c7d188baaa99
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5cec2ed5-5c66-47e6-b787-53ec22c29132
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b8644c67-d7ba-4cbb-8b37-fd129fe1b97b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 87a71ef6-1b96-415a-bd3c-dcb0d5899470
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 480d9875-d780-45c7-91d1-c48d1059c8a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dc21928c-d84d-49a8-96f2-84cb325305ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7d8f3272-11dd-4093-ad36-fa22653d3535
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1f669724-0af0-460e-b7b0-4bd7adb67246
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d94327f0-688d-4c2c-bfd5-7c41838c9c62
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f2b05575-3d5c-4fc7-a7ca-c8cc62788578
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f6cc3154-d10b-4aef-a891-fa829584a6ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ac127328-491c-4512-8f82-2ca5e6c17237
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 38284b02-2529-4a39-810b-67581a67e8a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 580db52f-c8c1-4cb0-879d-4e17cc8fe5fb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 901246f1-07f5-487d-9da8-eb866683a53f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fdea2edd-d6d1-4b89-8343-9058ff543934
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ff54f528-ce3c-40a1-b4d0-54795c007ea5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 09e474a1-6dd1-47e2-9e49-7cd494234f91
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3a348717-3467-4cbf-89ff-1146a3f2c094
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d849f0b4-8da4-4b7d-bb19-1e6d41a4e496
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d73b5f75-55b3-4192-8652-2092ded6252a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1045e8de-dcdc-4a21-994a-8900bbb420f4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bbb211bf-f22b-4a5c-b6d0-528208860451
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dbf634da-5631-4929-a86f-d7acad0a8def
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5210e9af-97ea-4938-9ae2-767390130f36
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 310b09f7-1d9d-46a2-ae98-876611b3be32
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 690228b1-f0b3-476c-97a4-a4bc511b5e56
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ed5aeafe-a08b-48fe-9ae5-620c7d0aedc8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 965fa513-83df-4a9d-85e1-481f67454d15
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f3f1b4cb-213a-4c1e-a572-f05d93f3d6fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 43e33587-02b9-4bb9-a629-334887bf0782
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fb4ad210-5c4d-49fe-b0af-efc309941272
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 48a2d5be-e9e8-4744-839f-e495a6e88313
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c7babf51-b310-469d-847e-4a0f857cfb30
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ebdea316-d66c-4d89-b5d7-1dda546e7f89
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f4ad5f15-98fb-40ad-9060-3f5b7f35ee94
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f0452cbc-a72b-4614-9c02-ab6b0b8745ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7865d4d4-8373-41a7-8c83-06d0f381e4be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9dad83aa-330c-4d4a-aa28-c2fb1f6dfa3e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ba8ce672-f830-46c1-b7e3-7d349c90dbb7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d5ca9102-87cb-4807-89a4-ead3726ad882
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 697a980f-2f5a-4e0c-8861-4cd92f4ccc0a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4c4679e8-ab11-434d-a6ca-a4b49ad0130a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c1d7fbc9-7117-431d-b204-8764e90514c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8a5da71d-bdc6-45b5-a9b3-05ddaa6f4317
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1894b548-a7f6-4e2d-b783-51fe046c37e1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 438387ac-2e64-455f-9c05-4f25dcb450dd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a0a53fc5-37ec-43d3-a1e8-a0542a6334ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f17732a9-835d-446c-bee6-527c26ac5045
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1950eb41-e2df-46ff-b412-6e26be23f83f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e04cc839-378d-47d9-aa1f-6df32f29db27
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 18e1129c-241f-4384-8550-efa3bcc40adf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bd6a6a08-214f-49fc-95ce-9fc7763f39c9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 813caaca-8921-4393-9362-59f03267132c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0783d15c-98f2-42f9-a65d-4a080be1ef06
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4b35cd39-a128-4891-9f94-71b10606e6ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7abc6a34-cbc2-4cc9-adfe-0768d959b464
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fb3e42fd-84f2-431b-b851-8e91c26ca520
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7dcd12bb-6ff3-465c-b76c-4ce07284f227
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e234dffb-2fd7-41bf-8e1d-44f89af10482
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fd3e7420-0ce6-4b72-a0c1-07cfa6d7b883
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 264fa046-046e-463e-ac4b-18ba7d24beb7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e83459d6-820e-480f-8c5a-6a874f106701
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a035305c-f819-431d-a261-042dd8b57b12
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a3ade715-76b6-46d2-b668-fcbe55cd79fb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6d1d0e14-f90b-424f-9945-d5b697090f59
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4bb1f956-5c08-4d39-ab5d-920ae86fcef2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0638c39b-1b0a-4725-8462-1589ce112379
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e4507d11-634c-485a-add2-956ab171f404
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a76ac285-eddd-47f5-a002-e4ac71f0293d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fd989302-628d-47b1-9d91-4ff953117146
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 820456d9-958b-4f31-be68-3fde65e8e3f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 673b5a60-05e6-4cc6-bac4-71687955daa6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fa8e82d9-18bc-4e3d-b221-ec56f03d8a54
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ce97261f-d1ab-432a-a8e0-60755f8dad39
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cd1e2cdb-0b96-4446-a2f7-ec82d9602af2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 468ecf60-9169-4f0c-91a1-253a51d92072
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1e9023e4-4220-4556-bb62-0fc83a66e218
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6205df14-b8fe-422e-b9ec-292639430b8c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 21e6974c-3a8e-4e05-a0c6-9fd298a20bdb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 384d0278-43f9-4994-989a-d1c3d0f5f485
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cd13f5b9-3a76-4348-8a4c-feefc7682b83
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5050fcab-1ee0-4c36-895f-ce0ca5ae9bac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2cb83558-a690-49d7-bc9e-f1a63870ff9c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 39afe181-e625-44f1-933e-3b6be0500023
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 674a078e-80d1-437b-853d-ff11f36212e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ebab9301-9227-40cc-94d8-258a4791801f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fbfd836a-e928-44d3-b598-6ea4a9bd8afa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 714a43c0-960d-495a-9930-260f0779bdd8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6fdc4994-a435-4332-82ac-c34cf8442f58
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4e174a8e-8885-4cc3-a3c5-4c059f34f1af
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8687 {grpc_message:"Socket closed", grpc_status:14}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_24
Server: localhost:8687
Algorithm: FEDAVG
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_24
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_24/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_24/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_24/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_24/test_labels.txt

📊 Raw data loaded:
   Train: X=(849, 24), y=(849,)
   Test:  X=(213, 24), y=(213,)

⚠️  Limiting training data: 849 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  204 samples, 5 features
✅ Client client_24 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

============================================================
🔄 Round 4 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0891, val=0.0791 (↓), lr=0.001000
   • Epoch   2/100: train=0.0878, val=0.0802, patience=1/15, lr=0.001000
   • Epoch   3/100: train=0.0874, val=0.0810, patience=2/15, lr=0.001000
   • Epoch   4/100: train=0.0871, val=0.0812, patience=3/15, lr=0.001000
   • Epoch   5/100: train=0.0869, val=0.0812, patience=4/15, lr=0.001000
   📉 Epoch 7: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0851, val=0.0806, patience=10/15, lr=0.000500
   📉 Epoch 15: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 4 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0866, RMSE=0.2943, R²=-0.0041
   Val:   Loss=0.0791, RMSE=0.2812, R²=-0.0448
============================================================


============================================================
🔄 Round 5 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0871 (↓), lr=0.000250
   • Epoch   2/100: train=0.0858, val=0.0866, patience=1/15, lr=0.000250
   • Epoch   3/100: train=0.0854, val=0.0870, patience=2/15, lr=0.000250
   • Epoch   4/100: train=0.0852, val=0.0870, patience=3/15, lr=0.000250
   • Epoch   5/100: train=0.0850, val=0.0872, patience=4/15, lr=0.000250
   📉 Epoch 7: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0845, val=0.0874, patience=10/15, lr=0.000125
   📉 Epoch 15: LR reduced 0.000125 → 0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0871)

============================================================
📊 Round 5 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000250 → 0.000063 (2 reductions)
   Train: Loss=0.0857, RMSE=0.2927, R²=-0.0124
   Val:   Loss=0.0871, RMSE=0.2951, R²=-0.0483
============================================================


============================================================
🔄 Round 6 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0904 (↓), lr=0.000063
   • Epoch   2/100: train=0.0864, val=0.0903, patience=1/15, lr=0.000063
   • Epoch   3/100: train=0.0861, val=0.0902, patience=2/15, lr=0.000063
   • Epoch   4/100: train=0.0858, val=0.0901, patience=3/15, lr=0.000063
   • Epoch   5/100: train=0.0856, val=0.0901, patience=4/15, lr=0.000063
   📉 Epoch 7: LR reduced 0.000063 → 0.000031
   • Epoch  11/100: train=0.0850, val=0.0902, patience=10/15, lr=0.000031
   📉 Epoch 15: LR reduced 0.000031 → 0.000016

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0904)

============================================================
📊 Round 6 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000063 → 0.000016 (2 reductions)
   Train: Loss=0.0864, RMSE=0.2939, R²=-0.0319
   Val:   Loss=0.0904, RMSE=0.3007, R²=-0.0206
============================================================


📊 Round 6 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2366, R²: -0.0270

============================================================
🔄 Round 9 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000016
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0890, val=0.0870 (↓), lr=0.000016
   • Epoch   2/100: train=0.0889, val=0.0868, patience=1/15, lr=0.000016
   • Epoch   3/100: train=0.0887, val=0.0867, patience=2/15, lr=0.000016
   • Epoch   4/100: train=0.0886, val=0.0866, patience=3/15, lr=0.000016
   • Epoch   5/100: train=0.0885, val=0.0865, patience=4/15, lr=0.000016
   📉 Epoch 7: LR reduced 0.000016 → 0.000008
   • Epoch  11/100: train=0.0880, val=0.0863, patience=5/15, lr=0.000008
   📉 Epoch 15: LR reduced 0.000008 → 0.000004
   • Epoch  21/100: train=0.0878, val=0.0862, patience=15/15, lr=0.000004

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0865)

============================================================
📊 Round 9 Summary - Client client_24
   Epochs: 21/100 (early stopped)
   LR: 0.000016 → 0.000004 (2 reductions)
   Train: Loss=0.0880, RMSE=0.2966, R²=-0.0366
   Val:   Loss=0.0865, RMSE=0.2941, R²=-0.0313
============================================================


📊 Round 9 Test Metrics:
   Loss: 0.0788, RMSE: 0.2807, MAE: 0.2366, R²: -0.0283

📊 Round 9 Test Metrics:
   Loss: 0.0788, RMSE: 0.2806, MAE: 0.2366, R²: -0.0282

📊 Round 9 Test Metrics:
   Loss: 0.0788, RMSE: 0.2807, MAE: 0.2367, R²: -0.0288

📊 Round 9 Test Metrics:
   Loss: 0.0789, RMSE: 0.2809, MAE: 0.2369, R²: -0.0299

============================================================
🔄 Round 18 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000004
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0896, val=0.0880 (↓), lr=0.000004
   📉 Epoch 2: LR reduced 0.000004 → 0.000002
   • Epoch   2/100: train=0.0895, val=0.0880, patience=1/15, lr=0.000002
   • Epoch   3/100: train=0.0895, val=0.0880, patience=2/15, lr=0.000002
   • Epoch   4/100: train=0.0894, val=0.0880, patience=3/15, lr=0.000002
   • Epoch   5/100: train=0.0894, val=0.0880, patience=4/15, lr=0.000002
   📉 Epoch 10: LR reduced 0.000002 → 0.000001
   • Epoch  11/100: train=0.0892, val=0.0879, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0880)

============================================================
📊 Round 18 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000004 → 0.000001 (2 reductions)
   Train: Loss=0.0896, RMSE=0.2993, R²=-0.0648
   Val:   Loss=0.0880, RMSE=0.2966, R²=-0.0115
============================================================


📊 Round 18 Test Metrics:
   Loss: 0.0788, RMSE: 0.2807, MAE: 0.2367, R²: -0.0288

📊 Round 18 Test Metrics:
   Loss: 0.0789, RMSE: 0.2810, MAE: 0.2370, R²: -0.0305

📊 Round 18 Test Metrics:
   Loss: 0.0789, RMSE: 0.2810, MAE: 0.2371, R²: -0.0306

📊 Round 18 Test Metrics:
   Loss: 0.0789, RMSE: 0.2810, MAE: 0.2371, R²: -0.0306

📊 Round 18 Test Metrics:
   Loss: 0.0789, RMSE: 0.2810, MAE: 0.2371, R²: -0.0306

============================================================
🔄 Round 25 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0892, val=0.0911 (↓), lr=0.000001
   • Epoch   2/100: train=0.0892, val=0.0911, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0892, val=0.0910, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0892, val=0.0910, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0892, val=0.0910, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0891, val=0.0910, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0911)

============================================================
📊 Round 25 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0893, RMSE=0.2988, R²=-0.0651
   Val:   Loss=0.0911, RMSE=0.3018, R²=-0.0378
============================================================


📊 Round 25 Test Metrics:
   Loss: 0.0789, RMSE: 0.2810, MAE: 0.2371, R²: -0.0306

📊 Round 25 Test Metrics:
   Loss: 0.0789, RMSE: 0.2810, MAE: 0.2371, R²: -0.0305

============================================================
🔄 Round 29 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0897, val=0.0903 (↓), lr=0.000001
   • Epoch   2/100: train=0.0897, val=0.0903, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0897, val=0.0903, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0897, val=0.0904, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0896, val=0.0904, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0896, val=0.0904, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0903)

============================================================
📊 Round 29 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0895, RMSE=0.2991, R²=-0.0680
   Val:   Loss=0.0903, RMSE=0.3006, R²=-0.0247
============================================================


============================================================
🔄 Round 30 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0879, val=0.0960 (↓), lr=0.000001
   • Epoch   2/100: train=0.0879, val=0.0960, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0879, val=0.0960, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0879, val=0.0960, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0879, val=0.0960, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0878, val=0.0960, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0960)

============================================================
📊 Round 30 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0881, RMSE=0.2968, R²=-0.0573
   Val:   Loss=0.0960, RMSE=0.3099, R²=-0.0642
============================================================


📊 Round 30 Test Metrics:
   Loss: 0.0789, RMSE: 0.2810, MAE: 0.2371, R²: -0.0305

============================================================
🔄 Round 31 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0900, val=0.0884 (↓), lr=0.000001
   • Epoch   2/100: train=0.0900, val=0.0884, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0900, val=0.0884, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0900, val=0.0884, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0900, val=0.0884, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0899, val=0.0883, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0884)

============================================================
📊 Round 31 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0900, RMSE=0.2999, R²=-0.0532
   Val:   Loss=0.0884, RMSE=0.2973, R²=-0.0862
============================================================


📊 Round 31 Test Metrics:
   Loss: 0.0789, RMSE: 0.2810, MAE: 0.2371, R²: -0.0305

============================================================
🔄 Round 35 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0910, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0910, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0909, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0909, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0909, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0909, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 35 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0910, RMSE=0.3017, R²=-0.0578
   Val:   Loss=0.0843, RMSE=0.2903, R²=-0.0633
============================================================


📊 Round 35 Test Metrics:
   Loss: 0.0789, RMSE: 0.2810, MAE: 0.2371, R²: -0.0305

📊 Round 35 Test Metrics:
   Loss: 0.0789, RMSE: 0.2810, MAE: 0.2371, R²: -0.0305

============================================================
🔄 Round 38 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0889, val=0.0920 (↓), lr=0.000001
   • Epoch   2/100: train=0.0889, val=0.0920, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0889, val=0.0920, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0888, val=0.0920, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0888, val=0.0920, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0887, val=0.0921, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0920)

============================================================
📊 Round 38 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0891, RMSE=0.2984, R²=-0.0671
   Val:   Loss=0.0920, RMSE=0.3033, R²=-0.0360
============================================================


============================================================
🔄 Round 40 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0884, val=0.0959 (↓), lr=0.000001
   • Epoch   2/100: train=0.0884, val=0.0958, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0884, val=0.0958, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0884, val=0.0958, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0884, val=0.0958, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0883, val=0.0958, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0959)

============================================================
📊 Round 40 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0881, RMSE=0.2968, R²=-0.0538
   Val:   Loss=0.0959, RMSE=0.3096, R²=-0.0824
============================================================


============================================================
🔄 Round 42 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0915, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0915, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0915, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0915, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0915, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0914, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 42 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0916, RMSE=0.3027, R²=-0.0665
   Val:   Loss=0.0818, RMSE=0.2861, R²=-0.0257
============================================================


📊 Round 42 Test Metrics:
   Loss: 0.0789, RMSE: 0.2809, MAE: 0.2371, R²: -0.0305

============================================================
🔄 Round 44 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0902, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0902, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0902, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0902, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0902, val=0.0864, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0902, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 44 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0905, RMSE=0.3008, R²=-0.0508
   Val:   Loss=0.0864, RMSE=0.2939, R²=-0.1009
============================================================


📊 Round 44 Test Metrics:
   Loss: 0.0789, RMSE: 0.2809, MAE: 0.2371, R²: -0.0304

============================================================
🔄 Round 46 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0911, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0911, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0911, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0910, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0910, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0910, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 46 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0909, RMSE=0.3016, R²=-0.0638
   Val:   Loss=0.0845, RMSE=0.2907, R²=-0.0477
============================================================


📊 Round 46 Test Metrics:
   Loss: 0.0789, RMSE: 0.2809, MAE: 0.2371, R²: -0.0304

============================================================
🔄 Round 47 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0907, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0907, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0907, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0907, val=0.0859, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0907, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0906, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 47 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0906, RMSE=0.3010, R²=-0.0666
   Val:   Loss=0.0859, RMSE=0.2931, R²=-0.0417
============================================================


📊 Round 47 Test Metrics:
   Loss: 0.0789, RMSE: 0.2809, MAE: 0.2371, R²: -0.0304

📊 Round 47 Test Metrics:
   Loss: 0.0789, RMSE: 0.2809, MAE: 0.2371, R²: -0.0304

============================================================
🔄 Round 51 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0896, val=0.0903 (↓), lr=0.000001
   • Epoch   2/100: train=0.0896, val=0.0903, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0896, val=0.0903, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0896, val=0.0903, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0896, val=0.0903, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0895, val=0.0903, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0903)

============================================================
📊 Round 51 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0895, RMSE=0.2992, R²=-0.0653
   Val:   Loss=0.0903, RMSE=0.3005, R²=-0.0361
============================================================


📊 Round 51 Test Metrics:
   Loss: 0.0789, RMSE: 0.2809, MAE: 0.2371, R²: -0.0304

============================================================
🔄 Round 52 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0904, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0904, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0904, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0904, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0904, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0903, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 52 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0908, RMSE=0.3013, R²=-0.0613
   Val:   Loss=0.0852, RMSE=0.2919, R²=-0.0563
============================================================


📊 Round 52 Test Metrics:
   Loss: 0.0789, RMSE: 0.2809, MAE: 0.2371, R²: -0.0304

============================================================
🔄 Round 53 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0915, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0915, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0915, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0915, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0915, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0914, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 53 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0916, RMSE=0.3026, R²=-0.0572
   Val:   Loss=0.0820, RMSE=0.2864, R²=-0.0663
============================================================


📊 Round 53 Test Metrics:
   Loss: 0.0789, RMSE: 0.2809, MAE: 0.2371, R²: -0.0304

============================================================
🔄 Round 57 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0897, val=0.0921 (↓), lr=0.000001
   • Epoch   2/100: train=0.0897, val=0.0921, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0897, val=0.0921, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0896, val=0.0921, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0896, val=0.0921, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0896, val=0.0921, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0921)

============================================================
📊 Round 57 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0890, RMSE=0.2984, R²=-0.0638
   Val:   Loss=0.0921, RMSE=0.3035, R²=-0.0416
============================================================


📊 Round 57 Test Metrics:
   Loss: 0.0789, RMSE: 0.2809, MAE: 0.2371, R²: -0.0303

📊 Round 57 Test Metrics:
   Loss: 0.0789, RMSE: 0.2809, MAE: 0.2371, R²: -0.0303

============================================================
🔄 Round 61 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0896, val=0.0900 (↓), lr=0.000001
   • Epoch   2/100: train=0.0896, val=0.0900, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0895, val=0.0900, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0895, val=0.0900, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0895, val=0.0900, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0895, val=0.0900, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0900)

============================================================
📊 Round 61 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0896, RMSE=0.2993, R²=-0.0564
   Val:   Loss=0.0900, RMSE=0.3000, R²=-0.0825
============================================================


📊 Round 61 Test Metrics:
   Loss: 0.0789, RMSE: 0.2809, MAE: 0.2371, R²: -0.0303

📊 Round 61 Test Metrics:
   Loss: 0.0789, RMSE: 0.2809, MAE: 0.2371, R²: -0.0303

============================================================
🔄 Round 66 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0896, val=0.0900 (↓), lr=0.000001
   • Epoch   2/100: train=0.0895, val=0.0899, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0895, val=0.0899, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0895, val=0.0899, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0895, val=0.0899, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0894, val=0.0899, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0900)

============================================================
📊 Round 66 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0896, RMSE=0.2993, R²=-0.0622
   Val:   Loss=0.0900, RMSE=0.2999, R²=-0.0547
============================================================


📊 Round 66 Test Metrics:
   Loss: 0.0789, RMSE: 0.2809, MAE: 0.2371, R²: -0.0303

============================================================
🔄 Round 68 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0919, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0919, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0919, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0919, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0919, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0918, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 68 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0917, RMSE=0.3029, R²=-0.0521
   Val:   Loss=0.0813, RMSE=0.2851, R²=-0.0904
============================================================


📊 Round 68 Test Metrics:
   Loss: 0.0789, RMSE: 0.2809, MAE: 0.2371, R²: -0.0303

📊 Round 68 Test Metrics:
   Loss: 0.0789, RMSE: 0.2809, MAE: 0.2371, R²: -0.0303

📊 Round 68 Test Metrics:
   Loss: 0.0789, RMSE: 0.2809, MAE: 0.2371, R²: -0.0303

============================================================
🔄 Round 72 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0915, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0915, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0915, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0915, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0914, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0914, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 72 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0917, RMSE=0.3029, R²=-0.0661
   Val:   Loss=0.0814, RMSE=0.2853, R²=-0.0302
============================================================


============================================================
🔄 Round 74 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0882, val=0.0954 (↓), lr=0.000001
   • Epoch   2/100: train=0.0882, val=0.0954, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0882, val=0.0954, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0882, val=0.0954, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0882, val=0.0954, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0881, val=0.0954, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0954)

============================================================
📊 Round 74 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0882, RMSE=0.2970, R²=-0.0547
   Val:   Loss=0.0954, RMSE=0.3089, R²=-0.0820
============================================================


============================================================
🔄 Round 78 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0920, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0920, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0920, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0920, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0920, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0919, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 78 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0922, RMSE=0.3036, R²=-0.0623
   Val:   Loss=0.0795, RMSE=0.2820, R²=-0.0480
============================================================


============================================================
🔄 Round 79 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0898, val=0.0884 (↓), lr=0.000001
   • Epoch   2/100: train=0.0898, val=0.0883, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0898, val=0.0883, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0898, val=0.0883, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0898, val=0.0883, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0898, val=0.0883, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0884)

============================================================
📊 Round 79 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0900, RMSE=0.3000, R²=-0.0611
   Val:   Loss=0.0884, RMSE=0.2972, R²=-0.0504
============================================================


============================================================
🔄 Round 80 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0905, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0905, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0904, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0904, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0904, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0904, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 80 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0908, RMSE=0.3013, R²=-0.0487
   Val:   Loss=0.0852, RMSE=0.2918, R²=-0.1099
============================================================


📊 Round 80 Test Metrics:
   Loss: 0.0789, RMSE: 0.2809, MAE: 0.2371, R²: -0.0302

📊 Round 80 Test Metrics:
   Loss: 0.0789, RMSE: 0.2809, MAE: 0.2371, R²: -0.0302

============================================================
🔄 Round 83 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0905, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0905, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0905, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0905, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0905, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0904, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 83 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0906, RMSE=0.3009, R²=-0.0518
   Val:   Loss=0.0860, RMSE=0.2933, R²=-0.0901
============================================================


============================================================
🔄 Round 84 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0889, val=0.0912 (↓), lr=0.000001
   • Epoch   2/100: train=0.0889, val=0.0913, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0889, val=0.0913, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0889, val=0.0913, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0888, val=0.0913, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0887, val=0.0914, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0912)

============================================================
📊 Round 84 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0893, RMSE=0.2988, R²=-0.0747
   Val:   Loss=0.0912, RMSE=0.3021, R²=-0.0369
============================================================


============================================================
🔄 Round 85 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0902, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0902, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0902, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0902, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0902, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0901, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 85 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0905, RMSE=0.3009, R²=-0.0658
   Val:   Loss=0.0862, RMSE=0.2936, R²=-0.0315
============================================================


📊 Round 85 Test Metrics:
   Loss: 0.0789, RMSE: 0.2809, MAE: 0.2371, R²: -0.0301

============================================================
🔄 Round 86 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0915, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0915, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0915, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0915, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0914, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0914, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 86 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0915, RMSE=0.3026, R²=-0.0604
   Val:   Loss=0.0821, RMSE=0.2865, R²=-0.0534
============================================================


📊 Round 86 Test Metrics:
   Loss: 0.0789, RMSE: 0.2809, MAE: 0.2371, R²: -0.0301

============================================================
🔄 Round 88 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0893, val=0.0918 (↓), lr=0.000001
   • Epoch   2/100: train=0.0893, val=0.0918, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0893, val=0.0918, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0893, val=0.0918, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0893, val=0.0918, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0892, val=0.0919, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0918)

============================================================
📊 Round 88 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0891, RMSE=0.2985, R²=-0.0651
   Val:   Loss=0.0918, RMSE=0.3030, R²=-0.0532
============================================================


📊 Round 88 Test Metrics:
   Loss: 0.0789, RMSE: 0.2809, MAE: 0.2371, R²: -0.0301

📊 Round 88 Test Metrics:
   Loss: 0.0789, RMSE: 0.2809, MAE: 0.2371, R²: -0.0301

============================================================
🔄 Round 93 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0917, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0917, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0917, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0916, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0916, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0916, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 93 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0921, RMSE=0.3035, R²=-0.0581
   Val:   Loss=0.0798, RMSE=0.2825, R²=-0.0668
============================================================


📊 Round 93 Test Metrics:
   Loss: 0.0789, RMSE: 0.2809, MAE: 0.2371, R²: -0.0301

============================================================
🔄 Round 94 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0886, val=0.0942 (↓), lr=0.000001
   • Epoch   2/100: train=0.0886, val=0.0942, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0886, val=0.0942, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0885, val=0.0942, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0885, val=0.0942, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0885, val=0.0942, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0942)

============================================================
📊 Round 94 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0885, RMSE=0.2975, R²=-0.0636
   Val:   Loss=0.0942, RMSE=0.3069, R²=-0.0501
============================================================


============================================================
🔄 Round 96 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0898, val=0.0886 (↓), lr=0.000001
   • Epoch   2/100: train=0.0898, val=0.0886, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0898, val=0.0885, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0897, val=0.0885, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0897, val=0.0885, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0897, val=0.0885, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0886)

============================================================
📊 Round 96 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0899, RMSE=0.2999, R²=-0.0560
   Val:   Loss=0.0886, RMSE=0.2976, R²=-0.0708
============================================================


============================================================
🔄 Round 99 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0897, val=0.0899 (↓), lr=0.000001
   • Epoch   2/100: train=0.0897, val=0.0899, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0897, val=0.0899, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0897, val=0.0899, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0897, val=0.0899, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0896, val=0.0898, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0899)

============================================================
📊 Round 99 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0896, RMSE=0.2993, R²=-0.0567
   Val:   Loss=0.0899, RMSE=0.2998, R²=-0.0682
============================================================


============================================================
🔄 Round 100 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0888, val=0.0932 (↓), lr=0.000001
   • Epoch   2/100: train=0.0888, val=0.0933, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0888, val=0.0933, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0888, val=0.0933, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0887, val=0.0933, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0887, val=0.0934, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0932)

============================================================
📊 Round 100 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0888, RMSE=0.2979, R²=-0.0625
   Val:   Loss=0.0932, RMSE=0.3054, R²=-0.0950
============================================================


============================================================
🔄 Round 102 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.1022 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.1021, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.1021, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.1021, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.1021, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.1021, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.1022)

============================================================
📊 Round 102 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2942, R²=-0.0629
   Val:   Loss=0.1022, RMSE=0.3196, R²=-0.0452
============================================================


📊 Round 102 Test Metrics:
   Loss: 0.0789, RMSE: 0.2809, MAE: 0.2371, R²: -0.0301

============================================================
🔄 Round 103 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0904, val=0.0866 (↓), lr=0.000001
   • Epoch   2/100: train=0.0904, val=0.0866, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0904, val=0.0866, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0904, val=0.0866, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0904, val=0.0866, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0903, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0866)

============================================================
📊 Round 103 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0904, RMSE=0.3007, R²=-0.0658
   Val:   Loss=0.0866, RMSE=0.2942, R²=-0.0309
============================================================


📊 Round 103 Test Metrics:
   Loss: 0.0789, RMSE: 0.2809, MAE: 0.2371, R²: -0.0301

============================================================
🔄 Round 106 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.1028 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.1028, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.1028, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.1028, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.1028, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.1028, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.1028)

============================================================
📊 Round 106 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2939, R²=-0.0565
   Val:   Loss=0.1028, RMSE=0.3207, R²=-0.0733
============================================================


📊 Round 106 Test Metrics:
   Loss: 0.0789, RMSE: 0.2809, MAE: 0.2371, R²: -0.0301

📊 Round 106 Test Metrics:
   Loss: 0.0789, RMSE: 0.2809, MAE: 0.2371, R²: -0.0301

============================================================
🔄 Round 111 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0887, val=0.0945 (↓), lr=0.000001
   • Epoch   2/100: train=0.0887, val=0.0945, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0887, val=0.0945, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0887, val=0.0946, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0887, val=0.0946, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0886, val=0.0946, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0945)

============================================================
📊 Round 111 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0884, RMSE=0.2974, R²=-0.0549
   Val:   Loss=0.0945, RMSE=0.3075, R²=-0.1054
============================================================


============================================================
🔄 Round 113 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0896, val=0.0901 (↓), lr=0.000001
   • Epoch   2/100: train=0.0895, val=0.0901, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0895, val=0.0901, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0895, val=0.0901, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0895, val=0.0901, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0895, val=0.0901, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0901)

============================================================
📊 Round 113 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0896, RMSE=0.2993, R²=-0.0569
   Val:   Loss=0.0901, RMSE=0.3001, R²=-0.0789
============================================================


📊 Round 113 Test Metrics:
   Loss: 0.0789, RMSE: 0.2809, MAE: 0.2371, R²: -0.0301

============================================================
🔄 Round 115 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0880, val=0.0957 (↓), lr=0.000001
   • Epoch   2/100: train=0.0880, val=0.0957, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0880, val=0.0957, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0880, val=0.0957, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0880, val=0.0957, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0879, val=0.0956, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0957)

============================================================
📊 Round 115 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0882, RMSE=0.2969, R²=-0.0638
   Val:   Loss=0.0957, RMSE=0.3094, R²=-0.0458
============================================================


============================================================
🔄 Round 117 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0890, val=0.0923 (↓), lr=0.000001
   • Epoch   2/100: train=0.0890, val=0.0923, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0889, val=0.0923, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0889, val=0.0923, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0889, val=0.0923, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0889, val=0.0922, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0923)

============================================================
📊 Round 117 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0890, RMSE=0.2983, R²=-0.0560
   Val:   Loss=0.0923, RMSE=0.3038, R²=-0.0724
============================================================


============================================================
🔄 Round 118 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0887, val=0.0943 (↓), lr=0.000001
   • Epoch   2/100: train=0.0886, val=0.0943, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0886, val=0.0943, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0886, val=0.0943, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0886, val=0.0943, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0886, val=0.0943, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0943)

============================================================
📊 Round 118 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0885, RMSE=0.2975, R²=-0.0577
   Val:   Loss=0.0943, RMSE=0.3071, R²=-0.0677
============================================================


============================================================
🔄 Round 119 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0914, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0914, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0913, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0913, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0913, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0913, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 119 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0913, RMSE=0.3021, R²=-0.0608
   Val:   Loss=0.0833, RMSE=0.2886, R²=-0.0505
============================================================


============================================================
🔄 Round 120 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0889, val=0.0931 (↓), lr=0.000001
   • Epoch   2/100: train=0.0889, val=0.0931, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0889, val=0.0931, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0889, val=0.0931, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0889, val=0.0931, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0888, val=0.0930, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0931)

============================================================
📊 Round 120 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0888, RMSE=0.2980, R²=-0.0543
   Val:   Loss=0.0931, RMSE=0.3051, R²=-0.0856
============================================================


============================================================
🔄 Round 121 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0908, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0907, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0907, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0907, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0907, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0907, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 121 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0907, RMSE=0.3012, R²=-0.0569
   Val:   Loss=0.0855, RMSE=0.2925, R²=-0.0683
============================================================


============================================================
🔄 Round 122 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0898, val=0.0889 (↓), lr=0.000001
   • Epoch   2/100: train=0.0898, val=0.0889, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0898, val=0.0889, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0898, val=0.0889, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0898, val=0.0889, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0897, val=0.0889, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0889)

============================================================
📊 Round 122 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0898, RMSE=0.2997, R²=-0.0658
   Val:   Loss=0.0889, RMSE=0.2982, R²=-0.0325
============================================================


📊 Round 122 Test Metrics:
   Loss: 0.0789, RMSE: 0.2809, MAE: 0.2371, R²: -0.0300

📊 Round 122 Test Metrics:
   Loss: 0.0789, RMSE: 0.2809, MAE: 0.2371, R²: -0.0300

============================================================
🔄 Round 124 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0924, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0924, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0924, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0924, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0924, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0923, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 124 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0924, RMSE=0.3040, R²=-0.0712
   Val:   Loss=0.0786, RMSE=0.2804, R²=-0.0045
============================================================


📊 Round 124 Test Metrics:
   Loss: 0.0789, RMSE: 0.2809, MAE: 0.2371, R²: -0.0300

📊 Round 124 Test Metrics:
   Loss: 0.0789, RMSE: 0.2809, MAE: 0.2371, R²: -0.0300

📊 Round 124 Test Metrics:
   Loss: 0.0789, RMSE: 0.2809, MAE: 0.2371, R²: -0.0300

============================================================
🔄 Round 129 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0910, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0910, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0910, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0910, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0910, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0909, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 129 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0911, RMSE=0.3018, R²=-0.0658
   Val:   Loss=0.0840, RMSE=0.2899, R²=-0.0300
============================================================


📊 Round 129 Test Metrics:
   Loss: 0.0789, RMSE: 0.2809, MAE: 0.2371, R²: -0.0299

============================================================
🔄 Round 130 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0907, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0907, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0907, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0907, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0907, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0906, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 130 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0907, RMSE=0.3012, R²=-0.0566
   Val:   Loss=0.0853, RMSE=0.2921, R²=-0.0709
============================================================


📊 Round 130 Test Metrics:
   Loss: 0.0789, RMSE: 0.2809, MAE: 0.2371, R²: -0.0300

📊 Round 130 Test Metrics:
   Loss: 0.0789, RMSE: 0.2809, MAE: 0.2371, R²: -0.0299

📊 Round 130 Test Metrics:
   Loss: 0.0789, RMSE: 0.2809, MAE: 0.2371, R²: -0.0299

============================================================
🔄 Round 133 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0899, val=0.0883 (↓), lr=0.000001
   • Epoch   2/100: train=0.0899, val=0.0883, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0899, val=0.0883, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0899, val=0.0883, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0899, val=0.0882, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0898, val=0.0882, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0883)

============================================================
📊 Round 133 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0900, RMSE=0.3000, R²=-0.0549
   Val:   Loss=0.0883, RMSE=0.2971, R²=-0.0883
============================================================


============================================================
🔄 Round 135 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0895, val=0.0906 (↓), lr=0.000001
   • Epoch   2/100: train=0.0895, val=0.0906, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0895, val=0.0906, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0895, val=0.0906, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0894, val=0.0906, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0894, val=0.0906, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0906)

============================================================
📊 Round 135 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0894, RMSE=0.2991, R²=-0.0530
   Val:   Loss=0.0906, RMSE=0.3010, R²=-0.0971
============================================================


============================================================
🔄 Round 140 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0889, val=0.0928 (↓), lr=0.000001
   • Epoch   2/100: train=0.0889, val=0.0928, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0889, val=0.0928, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0889, val=0.0928, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0889, val=0.0928, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0888, val=0.0927, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0928)

============================================================
📊 Round 140 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0889, RMSE=0.2981, R²=-0.0610
   Val:   Loss=0.0928, RMSE=0.3047, R²=-0.0516
============================================================


============================================================
🔄 Round 143 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0892, val=0.0923 (↓), lr=0.000001
   • Epoch   2/100: train=0.0892, val=0.0922, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0892, val=0.0922, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0892, val=0.0922, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0891, val=0.0922, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0891, val=0.0922, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0923)

============================================================
📊 Round 143 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0890, RMSE=0.2984, R²=-0.0500
   Val:   Loss=0.0923, RMSE=0.3037, R²=-0.0950
============================================================


📊 Round 143 Test Metrics:
   Loss: 0.0789, RMSE: 0.2809, MAE: 0.2371, R²: -0.0299

============================================================
🔄 Round 145 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0892, val=0.0909 (↓), lr=0.000001
   • Epoch   2/100: train=0.0892, val=0.0909, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0892, val=0.0909, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0892, val=0.0909, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0892, val=0.0909, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0891, val=0.0909, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0909)

============================================================
📊 Round 145 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0894, RMSE=0.2989, R²=-0.0570
   Val:   Loss=0.0909, RMSE=0.3015, R²=-0.0717
============================================================


📊 Round 145 Test Metrics:
   Loss: 0.0789, RMSE: 0.2809, MAE: 0.2371, R²: -0.0299

============================================================
🔄 Round 147 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0893, val=0.0920 (↓), lr=0.000001
   • Epoch   2/100: train=0.0893, val=0.0920, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0893, val=0.0920, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0893, val=0.0920, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0893, val=0.0920, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0892, val=0.0920, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0920)

============================================================
📊 Round 147 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0891, RMSE=0.2985, R²=-0.0532
   Val:   Loss=0.0920, RMSE=0.3033, R²=-0.0969
============================================================


📊 Round 147 Test Metrics:
   Loss: 0.0789, RMSE: 0.2809, MAE: 0.2371, R²: -0.0299

============================================================
🔄 Round 149 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0905, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0905, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0905, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0905, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0905, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0904, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 149 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0909, RMSE=0.3016, R²=-0.0553
   Val:   Loss=0.0846, RMSE=0.2908, R²=-0.0749
============================================================


============================================================
🔄 Round 150 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0887, val=0.0940 (↓), lr=0.000001
   • Epoch   2/100: train=0.0887, val=0.0940, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0887, val=0.0940, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0887, val=0.0940, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0887, val=0.0939, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0886, val=0.0939, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0940)

============================================================
📊 Round 150 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0886, RMSE=0.2977, R²=-0.0617
   Val:   Loss=0.0940, RMSE=0.3065, R²=-0.0520
============================================================


📊 Round 150 Test Metrics:
   Loss: 0.0789, RMSE: 0.2809, MAE: 0.2371, R²: -0.0298

============================================================
🔄 Round 153 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0904, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0904, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0904, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0904, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0903, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0903, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 153 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0905, RMSE=0.3008, R²=-0.0582
   Val:   Loss=0.0864, RMSE=0.2939, R²=-0.0640
============================================================


📊 Round 153 Test Metrics:
   Loss: 0.0789, RMSE: 0.2809, MAE: 0.2371, R²: -0.0298

============================================================
🔄 Round 155 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0900, val=0.0881 (↓), lr=0.000001
   • Epoch   2/100: train=0.0900, val=0.0881, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0900, val=0.0881, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0899, val=0.0881, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0899, val=0.0880, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0899, val=0.0880, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0881)

============================================================
📊 Round 155 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0901, RMSE=0.3001, R²=-0.0592
   Val:   Loss=0.0881, RMSE=0.2968, R²=-0.0582
============================================================


📊 Round 155 Test Metrics:
   Loss: 0.0789, RMSE: 0.2809, MAE: 0.2371, R²: -0.0298

============================================================
🔄 Round 157 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0886, val=0.0934 (↓), lr=0.000001
   • Epoch   2/100: train=0.0886, val=0.0934, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0886, val=0.0934, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0886, val=0.0935, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0886, val=0.0935, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0885, val=0.0935, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0934)

============================================================
📊 Round 157 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0887, RMSE=0.2979, R²=-0.0610
   Val:   Loss=0.0934, RMSE=0.3057, R²=-0.0826
============================================================


📊 Round 157 Test Metrics:
   Loss: 0.0789, RMSE: 0.2809, MAE: 0.2371, R²: -0.0298

============================================================
🔄 Round 159 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0891, val=0.0918 (↓), lr=0.000001
   • Epoch   2/100: train=0.0891, val=0.0918, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0891, val=0.0918, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0891, val=0.0918, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0891, val=0.0918, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0890, val=0.0918, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0918)

============================================================
📊 Round 159 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0891, RMSE=0.2986, R²=-0.0628
   Val:   Loss=0.0918, RMSE=0.3030, R²=-0.0615
============================================================


============================================================
🔄 Round 160 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0886, val=0.0947 (↓), lr=0.000001
   • Epoch   2/100: train=0.0886, val=0.0947, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0886, val=0.0947, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0886, val=0.0946, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0886, val=0.0946, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0885, val=0.0946, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0947)

============================================================
📊 Round 160 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0884, RMSE=0.2974, R²=-0.0550
   Val:   Loss=0.0947, RMSE=0.3077, R²=-0.0746
============================================================


📊 Round 160 Test Metrics:
   Loss: 0.0789, RMSE: 0.2809, MAE: 0.2371, R²: -0.0298

📊 Round 160 Test Metrics:
   Loss: 0.0789, RMSE: 0.2809, MAE: 0.2371, R²: -0.0298

============================================================
🔄 Round 167 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0888, val=0.0926 (↓), lr=0.000001
   • Epoch   2/100: train=0.0888, val=0.0926, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0888, val=0.0926, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0888, val=0.0926, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0888, val=0.0926, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0887, val=0.0926, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0926)

============================================================
📊 Round 167 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0889, RMSE=0.2982, R²=-0.0559
   Val:   Loss=0.0926, RMSE=0.3044, R²=-0.0727
============================================================


📊 Round 167 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2371, R²: -0.0297

============================================================
🔄 Round 171 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0908, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0908, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0908, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0907, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0907, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0907, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 171 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0908, RMSE=0.3014, R²=-0.0603
   Val:   Loss=0.0851, RMSE=0.2916, R²=-0.0551
============================================================


============================================================
🔄 Round 173 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0886, val=0.0932 (↓), lr=0.000001
   • Epoch   2/100: train=0.0886, val=0.0932, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0886, val=0.0932, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0886, val=0.0932, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0886, val=0.0932, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0885, val=0.0932, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0932)

============================================================
📊 Round 173 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0888, RMSE=0.2980, R²=-0.0571
   Val:   Loss=0.0932, RMSE=0.3053, R²=-0.0663
============================================================


============================================================
🔄 Round 176 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0903, val=0.0874 (↓), lr=0.000001
   • Epoch   2/100: train=0.0902, val=0.0874, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0902, val=0.0874, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0902, val=0.0874, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0902, val=0.0874, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0901, val=0.0874, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0874)

============================================================
📊 Round 176 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0902, RMSE=0.3004, R²=-0.0737
   Val:   Loss=0.0874, RMSE=0.2956, R²=-0.0107
============================================================


============================================================
🔄 Round 177 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0874, val=0.0995 (↓), lr=0.000001
   • Epoch   2/100: train=0.0874, val=0.0995, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0874, val=0.0995, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0874, val=0.0995, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0874, val=0.0995, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0873, val=0.0996, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0995)

============================================================
📊 Round 177 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0872, RMSE=0.2953, R²=-0.0659
   Val:   Loss=0.0995, RMSE=0.3154, R²=-0.0651
============================================================


============================================================
🔄 Round 178 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0897, val=0.0899 (↓), lr=0.000001
   • Epoch   2/100: train=0.0897, val=0.0899, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0897, val=0.0899, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0897, val=0.0899, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0897, val=0.0899, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0896, val=0.0898, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0899)

============================================================
📊 Round 178 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0896, RMSE=0.2994, R²=-0.0582
   Val:   Loss=0.0899, RMSE=0.2998, R²=-0.0627
============================================================


📊 Round 178 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2371, R²: -0.0297

============================================================
🔄 Round 183 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0890, val=0.0919 (↓), lr=0.000001
   • Epoch   2/100: train=0.0890, val=0.0919, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0890, val=0.0919, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0890, val=0.0919, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0890, val=0.0919, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0889, val=0.0919, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0919)

============================================================
📊 Round 183 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0891, RMSE=0.2985, R²=-0.0618
   Val:   Loss=0.0919, RMSE=0.3032, R²=-0.0546
============================================================


============================================================
🔄 Round 184 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0880, val=0.0952 (↓), lr=0.000001
   • Epoch   2/100: train=0.0880, val=0.0952, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0880, val=0.0952, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0880, val=0.0952, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0880, val=0.0952, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0879, val=0.0952, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0952)

============================================================
📊 Round 184 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0883, RMSE=0.2971, R²=-0.0552
   Val:   Loss=0.0952, RMSE=0.3086, R²=-0.0811
============================================================


============================================================
🔄 Round 185 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0893, val=0.0905 (↓), lr=0.000001
   • Epoch   2/100: train=0.0893, val=0.0905, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0893, val=0.0905, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0893, val=0.0905, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0892, val=0.0905, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0892, val=0.0904, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0905)

============================================================
📊 Round 185 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0895, RMSE=0.2991, R²=-0.0608
   Val:   Loss=0.0905, RMSE=0.3008, R²=-0.0519
============================================================


📊 Round 185 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2371, R²: -0.0296

============================================================
🔄 Round 187 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0893, val=0.0932 (↓), lr=0.000001
   • Epoch   2/100: train=0.0893, val=0.0932, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0893, val=0.0931, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0893, val=0.0931, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0893, val=0.0931, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0892, val=0.0931, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0932)

============================================================
📊 Round 187 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0888, RMSE=0.2980, R²=-0.0505
   Val:   Loss=0.0932, RMSE=0.3052, R²=-0.1006
============================================================


📊 Round 187 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2371, R²: -0.0296

📊 Round 187 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2371, R²: -0.0296

============================================================
🔄 Round 193 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0901, val=0.0875 (↓), lr=0.000001
   • Epoch   2/100: train=0.0901, val=0.0875, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0901, val=0.0875, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0901, val=0.0874, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0901, val=0.0874, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0900, val=0.0874, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0875)

============================================================
📊 Round 193 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0902, RMSE=0.3004, R²=-0.0608
   Val:   Loss=0.0875, RMSE=0.2958, R²=-0.0520
============================================================


============================================================
🔄 Round 194 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0916, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0916, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0916, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0916, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0916, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0915, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 194 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0913, RMSE=0.3022, R²=-0.0640
   Val:   Loss=0.0831, RMSE=0.2883, R²=-0.0422
============================================================


📊 Round 194 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2371, R²: -0.0296

============================================================
🔄 Round 195 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0870, val=0.1005 (↓), lr=0.000001
   • Epoch   2/100: train=0.0870, val=0.1005, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0870, val=0.1005, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0870, val=0.1005, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0870, val=0.1005, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0869, val=0.1004, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.1005)

============================================================
📊 Round 195 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0870, RMSE=0.2949, R²=-0.0490
   Val:   Loss=0.1005, RMSE=0.3171, R²=-0.1049
============================================================


📊 Round 195 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2371, R²: -0.0296

============================================================
🔄 Round 197 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0919, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0919, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0919, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0918, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0918, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0918, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 197 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0919, RMSE=0.3031, R²=-0.0671
   Val:   Loss=0.0808, RMSE=0.2842, R²=-0.0405
============================================================


📊 Round 197 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2371, R²: -0.0296

============================================================
🔄 Round 199 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0914, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0914, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0914, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0913, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0913, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0913, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 199 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0917, RMSE=0.3028, R²=-0.0569
   Val:   Loss=0.0816, RMSE=0.2857, R²=-0.0692
============================================================


📊 Round 199 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2371, R²: -0.0296

============================================================
🔄 Round 200 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0882, val=0.0958 (↓), lr=0.000001
   • Epoch   2/100: train=0.0882, val=0.0958, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0882, val=0.0958, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0882, val=0.0958, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0881, val=0.0958, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0881, val=0.0957, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0958)

============================================================
📊 Round 200 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0882, RMSE=0.2969, R²=-0.0558
   Val:   Loss=0.0958, RMSE=0.3095, R²=-0.0753
============================================================


============================================================
🔄 Round 201 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0881, val=0.0956 (↓), lr=0.000001
   • Epoch   2/100: train=0.0881, val=0.0956, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0881, val=0.0956, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0881, val=0.0955, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0880, val=0.0955, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0880, val=0.0955, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0956)

============================================================
📊 Round 201 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0882, RMSE=0.2970, R²=-0.0562
   Val:   Loss=0.0956, RMSE=0.3091, R²=-0.0774
============================================================


============================================================
🔄 Round 202 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0909, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0909, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0909, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0909, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0908, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0908, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 202 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0910, RMSE=0.3017, R²=-0.0593
   Val:   Loss=0.0843, RMSE=0.2903, R²=-0.0760
============================================================


📊 Round 202 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2371, R²: -0.0296

============================================================
🔄 Round 205 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0895, val=0.0905 (↓), lr=0.000001
   • Epoch   2/100: train=0.0895, val=0.0905, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0895, val=0.0905, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0895, val=0.0905, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0895, val=0.0905, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0894, val=0.0904, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0905)

============================================================
📊 Round 205 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0895, RMSE=0.2991, R²=-0.0637
   Val:   Loss=0.0905, RMSE=0.3008, R²=-0.0414
============================================================


============================================================
🔄 Round 206 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0922, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0921, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0921, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0921, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0921, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0920, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 206 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0921, RMSE=0.3035, R²=-0.0630
   Val:   Loss=0.0800, RMSE=0.2829, R²=-0.0578
============================================================


📊 Round 206 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2371, R²: -0.0295

📊 Round 206 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2371, R²: -0.0295

📊 Round 206 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2371, R²: -0.0295

📊 Round 206 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2371, R²: -0.0295

📊 Round 206 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2371, R²: -0.0295

📊 Round 206 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2371, R²: -0.0295

📊 Round 206 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2371, R²: -0.0295

============================================================
🔄 Round 218 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0890, val=0.0913 (↓), lr=0.000001
   • Epoch   2/100: train=0.0890, val=0.0913, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0890, val=0.0913, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0890, val=0.0913, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0890, val=0.0913, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0889, val=0.0913, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0913)

============================================================
📊 Round 218 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0893, RMSE=0.2988, R²=-0.0538
   Val:   Loss=0.0913, RMSE=0.3022, R²=-0.0822
============================================================


📊 Round 218 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2371, R²: -0.0295

============================================================
🔄 Round 219 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0883, val=0.0951 (↓), lr=0.000001
   • Epoch   2/100: train=0.0883, val=0.0950, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0883, val=0.0950, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0883, val=0.0950, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0883, val=0.0950, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0883, val=0.0949, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0951)

============================================================
📊 Round 219 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0883, RMSE=0.2972, R²=-0.0456
   Val:   Loss=0.0951, RMSE=0.3083, R²=-0.1179
============================================================


📊 Round 219 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2371, R²: -0.0295

============================================================
🔄 Round 220 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0895, val=0.0916 (↓), lr=0.000001
   • Epoch   2/100: train=0.0895, val=0.0916, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0895, val=0.0916, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0895, val=0.0916, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0895, val=0.0916, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0894, val=0.0916, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0916)

============================================================
📊 Round 220 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0892, RMSE=0.2987, R²=-0.0658
   Val:   Loss=0.0916, RMSE=0.3027, R²=-0.0345
============================================================


📊 Round 220 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2371, R²: -0.0295

============================================================
🔄 Round 221 - Client client_24
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0894, val=0.0907 (↓), lr=0.000001
   • Epoch   2/100: train=0.0894, val=0.0907, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0894, val=0.0907, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0894, val=0.0907, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0894, val=0.0907, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0893, val=0.0907, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0907)

============================================================
📊 Round 221 Summary - Client client_24
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0894, RMSE=0.2991, R²=-0.0636
   Val:   Loss=0.0907, RMSE=0.3011, R²=-0.0526
============================================================


❌ Client client_24 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8687 {grpc_message:"Socket closed", grpc_status:14}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8687 {grpc_message:"Socket closed", grpc_status:14}"
>
