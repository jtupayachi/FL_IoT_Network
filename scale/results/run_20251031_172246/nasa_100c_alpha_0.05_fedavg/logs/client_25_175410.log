[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 50a6cee5-085c-470a-82af-7ea3f14bf419
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 33475fa2-5c93-4249-8981-a74fb38a4853
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 38a7a46c-8930-4094-8c64-cc9e57c9a29c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 834fc665-1a05-443e-bb23-633101c4fac1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3ee971a0-172d-4b40-a9d8-6c6c093c52b1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f4a1f8a1-f9fb-40e8-a87e-1d5bbf248e9d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1ac830b6-c73e-41f5-8a1f-5d200ce3feea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3004e37d-9e63-45f6-8bb6-a602377cbb70
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9f80ea56-b647-436c-a430-6b0a13a0457c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9524c45e-7275-46b2-846e-486097cde7b8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3675bdcc-104c-4218-a23a-4d5ee81a1a13
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 42343b79-9518-4465-bf2e-cd26f466ea60
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9d760ef4-1ef1-403f-9e83-59f6487da737
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 87718a1e-d954-4937-803d-879458a7fa2b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 778cf2aa-40a9-4005-939d-621237fb80be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 21359e89-71e2-4240-94d5-2b6a929808d1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c62b335b-df69-405f-9d15-0555d60a6088
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7d7b06c8-9b60-4aee-8765-38caf35ab679
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3b84df03-be5f-420f-996a-85b17555c0f6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 22f0b823-2f0f-46ae-a683-3ded025df329
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3ad300f0-b320-47ec-92d7-a39f1d97c42a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 076bfe33-ca5c-4694-bf81-92b3250e85e9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a4d34769-b4c0-44cd-9d3b-23286f95933a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d399b627-b400-42de-9cdb-aaf80c85393d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7ad0b35f-5f30-4235-9bdc-c2143272f757
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1bc2b764-ec2c-4a54-bcae-6859b711d39a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 43db0ec5-4369-4d3f-88f6-53c2d11b081f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8e30d4ac-043a-4ef8-9cf6-aacc66735bd6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8ed4f7a0-df6c-4386-b8b9-045531131e96
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ae77bbc1-85a4-46ee-818e-1d464783bfef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ff38a0a1-ebe2-4ed2-b55d-bb96c4e9dd18
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 935ef66a-7212-4e5e-88d2-8c03c427b855
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3498c0c0-3970-4e98-b776-26c47b826f8d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message af9b36cb-da0a-4c41-bd97-7e8ec762b027
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b3e900aa-28ca-445e-a027-f0cf3c936103
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f998ed65-f858-40cb-a31d-f7473baeedb0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8582274a-2844-46f0-94f2-e7daadf1406f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7fb1c9cb-794f-4ab3-97a9-1484038dfb0e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 585d2db8-c5fb-4155-8358-875090f87d1b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dc0dd8e9-e8bf-4da7-8338-b9810ceb92a7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ca5848bf-c362-40b0-bf87-74f454d57ae3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6a2bf091-00f7-452c-ae43-aba31b571c97
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ad45686b-a544-4437-b1ed-cec01154d13a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 611af849-6450-4062-8c0e-01d0475f5ec1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d8071d07-981a-423e-8717-d5ddfbde6196
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0adebd4c-66b6-46e7-965f-d723c426fcf3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 550357c6-89ee-4f2d-949f-c6a8515cce8d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8025193c-aced-404f-82d7-60b9cf01f8d1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5b469989-1d93-40a7-b520-85f6db2cf481
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 24b9350b-a72d-41ce-b934-79f3b33badc2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c4006215-e613-4859-afa7-85aa6a9640b7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3449a5e6-fd9b-47b6-9fd8-b2c526ef79c4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5e8e3c80-043a-4a59-9c42-fc496203577f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1bd51da5-5a33-4523-a6c7-e72a64ffdac7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7f5bf425-11d6-4a21-9378-db55f36f102a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f5d773eb-778d-45c9-a1f8-5cec5cea996a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5f77e49f-f595-4991-8cc4-5391941b447d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5220920c-4112-44e7-8d9b-8244f5e9967d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 511111ef-7aa0-4031-aad1-942f73285792
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7c8e7a6b-9925-4932-8032-77b3627111bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ec069aef-56c1-4dc1-8866-3bf246ce38d8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c465a3f3-de05-47eb-a865-27344734af0b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1c5c762a-3732-4687-8c86-e1dafe30ea61
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8673f291-fa42-4f84-92bc-6ec33ef689d9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 828e6393-fb9c-4ec3-85f3-6d2630e31045
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8eae22e3-8790-40bf-8420-f4a38f8ca258
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7f805a0b-d206-4ee1-a64c-62fe4d232bf9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 096dcfea-1261-47b4-9eec-eaa1a0737eec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a10a80d9-5d42-4094-8695-87e4dc75af0f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ebbdef95-604d-4028-bd3c-b1123850739f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 067ac8de-7a71-44aa-ba12-cd47e635074c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 640c5317-e8e2-47ac-aca9-6e1da9143da2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a3315fae-d8c7-4de2-8460-476a6fbb7797
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1640375a-66ea-46eb-974c-6c085437de20
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 07f95e49-b6e1-4834-b2ef-9f42d7b7d46d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b409c57c-4943-47f8-bff7-eb5f58e650a0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f50657e2-7705-40d3-8472-de7ab751aa02
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f6382255-b6a0-4de4-bde5-28cee2e92747
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fe615dad-77c9-45da-bce1-3b74ae873f07
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f6c9d7ea-af55-48d3-95bd-c4c5f35a204e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 083fa35d-cd06-4afd-956e-c2db4232defa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 82961975-f3ef-4f04-b2e9-e3ffee316671
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e711288e-af4b-46a9-8cc4-8a7dae254236
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2fab808e-b8d3-48b3-8ead-8205922f294a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 95f1fd74-96c9-431d-b10d-f91dfa698d57
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cf6f3bc4-feb1-4101-a476-9dbe39a2071b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2133723b-e954-4e64-8c50-8c5be2f3470a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0d7b0a9a-addb-4cfd-aeeb-90bbee039e15
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3fb7e40b-eaa3-4d2c-b845-527d44006d60
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c960a1ba-8a80-4322-85c7-c8f06873ec90
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 70a88550-4191-485e-a2e1-a68b4d390758
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4f2dd805-9630-46ff-9400-0a7ac0bd927d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 276906dd-59be-4048-b60e-28e8ee230ffb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c940a86d-d48a-4438-93a7-575ea9c39c19
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f8f4a0f6-5d1f-4eae-a690-9de8c5cec78d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 978f9832-230f-436a-b636-090202d6e46a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a76a1aea-ed41-481b-82f2-ad59476036db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0bdbb90e-d0bb-4691-8204-551009145a8f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2061026e-ee54-4db3-80e3-dc4af0ef2665
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b939691c-51ba-447d-911a-93131a9f28f6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 028662f7-bd52-4a05-bb92-b7d5c58a1fd5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ef1f2960-94dd-4a7e-b32a-6a2c416777d1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4a01aaf7-cd27-4f38-8c70-f6636b583c76
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b4e4fd19-06e8-408e-810c-f460ebdfe220
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5518af42-16b3-449f-8ad7-08cd9ab5462b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e7c4e3e6-7fb1-429d-86a1-b4df20fcd956
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 12d12d95-575a-4626-ae42-c5f34587967c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 87539679-f25c-4323-970e-0bfe0c94e880
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d8b5abde-c082-44f4-9952-de9ac71260a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d5b26b31-3f74-4dfe-8a5b-5eff13b1c592
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9cba0966-9b5c-408e-9c3f-401397baba9a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c6b999db-a799-49a3-a0c2-af1bbc5d18e9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3efb02fb-7917-4bb7-a909-dd9f71ac5806
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1a17350f-2ffa-4299-929b-3d017dbe81cb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fe5ec996-16a7-4a07-9d21-76ed292bd4e2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 93cec4ae-935c-4b35-8477-a70730cc67e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a3941378-291d-430e-a449-fd536ea17a8c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2246e002-2d41-403f-bc1f-e5930c358fde
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5d7393ef-fa1b-45da-90c5-2fccb77c34fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9c803516-398e-48fb-9812-fd19aadaa558
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e9e3119e-eb12-4011-a334-091ba96adb26
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7acfe185-9eb3-4c39-ae74-5734da77df1c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 472818f3-2bc0-43c7-962a-d62cdeb1e451
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cd79f370-bef6-493e-af89-483dce1c1a4c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e9e5ad32-0c7a-4b62-8dd5-df84d957a470
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e41c63d7-3b01-47c6-a96c-999534b1fe19
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f71d5b86-b917-468d-8155-eadc433f5409
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9211d249-a8a3-426e-84c5-d2d57a28494d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 43448a91-8102-4206-99aa-008156f949c4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 27d4a622-9a10-4027-92d8-f9247518c404
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f1a8c3c8-5608-4472-ba2c-2afcae322c24
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f7f07c73-f3f5-4de3-a5c2-d2c9fef7b955
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c16b5d19-397b-4624-b170-d12e07f39e91
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message af72f1f0-64ca-4638-954a-f37e1aa5f015
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 91187552-5e62-4271-816c-d2acec08d41d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1098d1a9-76f9-4b77-b721-f260682d48c3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3e7d12f3-0cd2-42f1-8316-c07d815c4bc0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e18642c7-9201-4260-859c-66b98f81a7c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4c38af1e-b479-4087-ad0c-86db47bb9f30
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 327ad59f-83b6-4de1-b24f-6d3664e9fda3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2dec3d4c-33a4-4b5f-802e-46a586769afc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 28e8e456-abb8-4418-a43f-a1e285beeb96
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7b5e84b5-f691-4666-972c-dc10fd37b20d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 055e8925-47d1-47e5-ad19-8ec5914082b8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6895bf57-5a6a-4f11-9a93-16b87ade24a0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9250aa8b-9b7a-496d-bf91-989f045bf14c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3dc52856-91d4-4d00-bbe3-f843438b6e69
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 46f91c83-3e71-4919-b6bb-9c0b79cc718a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3ef2d995-e835-49d6-90c4-3517509a3a76
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message db967876-a42c-4865-addd-9bcd09b5ec06
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0eccbcc6-97dc-4340-ab0e-7066211093e8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 00ea4231-4876-44f5-a72a-da88e8e515e1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fc7f326a-0987-4fc9-8d64-1c740f5ef24b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 86fa71b5-f1ef-475c-be4b-4783e00a2e0a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1189bb27-5581-4af1-bba9-29640acb89b7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1335337e-0b8b-4e28-b187-da16d0cfcb26
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3e147a2d-a43b-4cda-a863-0b13dc6d356b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c96e0d0e-710e-4429-989d-cc68a7c1c68e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fa336305-caca-4dbc-a53b-de86cc92fcfc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4e5d061e-d347-4bec-868d-96cd95a96eff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 360cb3bd-2639-4c44-9d67-e3719e9965b5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9d66a198-da5b-45ec-a703-f16965fefc6c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 551f6bbc-452c-4327-938e-b1c0a83cc395
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 50b1177b-8b4d-4ce4-9f99-d53e6071bae7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a6b44db3-e2fe-45d1-b0de-55617de88fe8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 55c5b05a-ee4b-4335-a4f7-2682ca8b9815
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 472e1403-91b7-4ef2-8909-31213a9e6689
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d67945de-628a-43be-a589-cc0d0b2c6a71
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e703eda4-49e0-4920-add8-216a7c271557
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 280d4e66-c527-4dcc-9942-09ae77c6d30c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4f8bcb31-3f1c-4c4d-b027-f869526e16b9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b24e91e6-09e7-4780-8a0c-94ca4b0ef726
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9694c19f-2a71-44bf-b698-e959a900de34
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6dbaa34e-8425-4813-911e-9cea4833237d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f8ca4a8f-a800-4fe1-afa4-9d8224ceb07f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 08ce24f9-5073-4f1a-bcb9-e049d5996506
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5ab7ca4b-b715-4875-a21b-a37be0e12121
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 642d0421-58c6-4003-86e7-62358ed5092a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2ef5688f-1d52-467f-b196-778fa2634a5c
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "recvmsg:Connection reset by peer"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8687 {grpc_message:"recvmsg:Connection reset by peer", grpc_status:14}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_25
Server: localhost:8687
Algorithm: FEDAVG
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_25
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_25/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_25/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_25/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_25/test_labels.txt

📊 Raw data loaded:
   Train: X=(1671, 24), y=(1671,)
   Test:  X=(418, 24), y=(418,)

⚠️  Limiting training data: 1671 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  409 samples, 5 features
✅ Client client_25 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

📊 Round 0 Test Metrics:
   Loss: 0.0814, RMSE: 0.2854, MAE: 0.2450, R²: -0.0307

============================================================
🔄 Round 2 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0980 (↓), lr=0.001000
   ✓ Epoch   2/100: train=0.0854, val=0.0948 (↓), lr=0.001000
   • Epoch   3/100: train=0.0847, val=0.0955, patience=1/15, lr=0.001000
   • Epoch   4/100: train=0.0830, val=0.0951, patience=2/15, lr=0.001000
   • Epoch   5/100: train=0.0824, val=0.0949, patience=3/15, lr=0.001000
   📉 Epoch 8: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0807, val=0.0950, patience=9/15, lr=0.000500
   📉 Epoch 16: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0948)

============================================================
📊 Round 2 Summary - Client client_25
   Epochs: 17/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=0.0071
   Val:   Loss=0.0948, RMSE=0.3080, R²=-0.0005
============================================================


============================================================
🔄 Round 3 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0947 (↓), lr=0.000250
   • Epoch   2/100: train=0.0816, val=0.0947, patience=1/15, lr=0.000250
   • Epoch   3/100: train=0.0814, val=0.0948, patience=2/15, lr=0.000250
   • Epoch   4/100: train=0.0813, val=0.0949, patience=3/15, lr=0.000250
   • Epoch   5/100: train=0.0812, val=0.0950, patience=4/15, lr=0.000250
   📉 Epoch 8: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0808, val=0.0955, patience=10/15, lr=0.000125
   📉 Epoch 16: LR reduced 0.000125 → 0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0947)

============================================================
📊 Round 3 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000250 → 0.000063 (2 reductions)
   Train: Loss=0.0814, RMSE=0.2854, R²=0.0092
   Val:   Loss=0.0947, RMSE=0.3077, R²=-0.0373
============================================================


📊 Round 3 Test Metrics:
   Loss: 0.0794, RMSE: 0.2818, MAE: 0.2429, R²: -0.0053

============================================================
🔄 Round 7 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0860 (↓), lr=0.000063
   • Epoch   2/100: train=0.0838, val=0.0863, patience=1/15, lr=0.000063
   • Epoch   3/100: train=0.0836, val=0.0863, patience=2/15, lr=0.000063
   • Epoch   4/100: train=0.0834, val=0.0863, patience=3/15, lr=0.000063
   • Epoch   5/100: train=0.0833, val=0.0862, patience=4/15, lr=0.000063
   • Epoch  11/100: train=0.0828, val=0.0859, patience=10/15, lr=0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 7 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000063 → 0.000063 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2894, R²=0.0036
   Val:   Loss=0.0860, RMSE=0.2933, R²=-0.0425
============================================================


📊 Round 7 Test Metrics:
   Loss: 0.0791, RMSE: 0.2812, MAE: 0.2420, R²: -0.0008

============================================================
🔄 Round 10 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0831 (↓), lr=0.000063
   • Epoch   2/100: train=0.0845, val=0.0830, patience=1/15, lr=0.000063
   • Epoch   3/100: train=0.0842, val=0.0829, patience=2/15, lr=0.000063
   • Epoch   4/100: train=0.0840, val=0.0827, patience=3/15, lr=0.000063
   ✓ Epoch   5/100: train=0.0838, val=0.0826 (↓), lr=0.000063
   • Epoch  11/100: train=0.0831, val=0.0821, patience=6/15, lr=0.000063
   ✓ Epoch  21/100: train=0.0823, val=0.0815 (↓), lr=0.000063
   • Epoch  31/100: train=0.0815, val=0.0811, patience=10/15, lr=0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 10 Summary - Client client_25
   Epochs: 36/100 (early stopped)
   LR: 0.000063 → 0.000063 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2866, R²=0.0370
   Val:   Loss=0.0815, RMSE=0.2854, R²=-0.0088
============================================================


📊 Round 10 Test Metrics:
   Loss: 0.0791, RMSE: 0.2812, MAE: 0.2420, R²: -0.0006

============================================================
🔄 Round 13 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0872 (↓), lr=0.000063
   • Epoch   2/100: train=0.0840, val=0.0871, patience=1/15, lr=0.000063
   • Epoch   3/100: train=0.0838, val=0.0870, patience=2/15, lr=0.000063
   • Epoch   4/100: train=0.0836, val=0.0868, patience=3/15, lr=0.000063
   ✓ Epoch   5/100: train=0.0834, val=0.0866 (↓), lr=0.000063
   📉 Epoch 6: LR reduced 0.000063 → 0.000031
   • Epoch  11/100: train=0.0826, val=0.0860, patience=1/15, lr=0.000031
   📉 Epoch 14: LR reduced 0.000031 → 0.000016
   • Epoch  21/100: train=0.0820, val=0.0859, patience=11/15, lr=0.000016
   📉 Epoch 22: LR reduced 0.000016 → 0.000008

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 13 Summary - Client client_25
   Epochs: 25/100 (early stopped)
   LR: 0.000063 → 0.000008 (3 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=0.0141
   Val:   Loss=0.0861, RMSE=0.2934, R²=0.0280
============================================================


📊 Round 13 Test Metrics:
   Loss: 0.0790, RMSE: 0.2812, MAE: 0.2420, R²: -0.0004

📊 Round 13 Test Metrics:
   Loss: 0.0789, RMSE: 0.2810, MAE: 0.2418, R²: 0.0009

📊 Round 13 Test Metrics:
   Loss: 0.0788, RMSE: 0.2808, MAE: 0.2417, R²: 0.0024

📊 Round 13 Test Metrics:
   Loss: 0.0788, RMSE: 0.2807, MAE: 0.2416, R²: 0.0030

📊 Round 13 Test Metrics:
   Loss: 0.0788, RMSE: 0.2807, MAE: 0.2416, R²: 0.0029

📊 Round 13 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2414, R²: 0.0047

📊 Round 13 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2413, R²: 0.0054

============================================================
🔄 Round 23 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000008
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0864 (↓), lr=0.000008
   • Epoch   2/100: train=0.0835, val=0.0864, patience=1/15, lr=0.000008
   • Epoch   3/100: train=0.0835, val=0.0864, patience=2/15, lr=0.000008
   • Epoch   4/100: train=0.0834, val=0.0864, patience=3/15, lr=0.000008
   📉 Epoch 5: LR reduced 0.000008 → 0.000004
   • Epoch   5/100: train=0.0833, val=0.0864, patience=4/15, lr=0.000004
   • Epoch  11/100: train=0.0830, val=0.0864, patience=10/15, lr=0.000004
   📉 Epoch 13: LR reduced 0.000004 → 0.000002

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 23 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000008 → 0.000002 (2 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=0.0031
   Val:   Loss=0.0864, RMSE=0.2940, R²=-0.0085
============================================================


📊 Round 23 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2413, R²: 0.0055

📊 Round 23 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2413, R²: 0.0055

============================================================
🔄 Round 25 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000002
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0844 (↓), lr=0.000002
   • Epoch   2/100: train=0.0842, val=0.0844, patience=1/15, lr=0.000002
   • Epoch   3/100: train=0.0842, val=0.0844, patience=2/15, lr=0.000002
   • Epoch   4/100: train=0.0841, val=0.0844, patience=3/15, lr=0.000002
   📉 Epoch 5: LR reduced 0.000002 → 0.000001
   • Epoch   5/100: train=0.0841, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 25 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000002 → 0.000001 (1 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=0.0033
   Val:   Loss=0.0844, RMSE=0.2905, R²=-0.0152
============================================================


============================================================
🔄 Round 27 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0764 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0764, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0764, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0764, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0764, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0764, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0764)

============================================================
📊 Round 27 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2934, R²=0.0013
   Val:   Loss=0.0764, RMSE=0.2764, R²=0.0056
============================================================


📊 Round 27 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2413, R²: 0.0054

📊 Round 27 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2413, R²: 0.0054

📊 Round 27 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2413, R²: 0.0055

============================================================
🔄 Round 30 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0746 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0746, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0746, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0746, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0746, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0746, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0746)

============================================================
📊 Round 30 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2942, R²=0.0052
   Val:   Loss=0.0746, RMSE=0.2732, R²=-0.0065
============================================================


📊 Round 30 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2413, R²: 0.0055

============================================================
🔄 Round 31 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 31 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=0.0106
   Val:   Loss=0.0837, RMSE=0.2893, R²=-0.0530
============================================================


============================================================
🔄 Round 32 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 32 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=0.0051
   Val:   Loss=0.0855, RMSE=0.2924, R²=-0.0276
============================================================


============================================================
🔄 Round 34 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0873, val=0.0720 (↓), lr=0.000001
   • Epoch   2/100: train=0.0873, val=0.0720, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0873, val=0.0720, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0873, val=0.0720, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0873, val=0.0720, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0872, val=0.0720, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0720)

============================================================
📊 Round 34 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0872, RMSE=0.2953, R²=0.0021
   Val:   Loss=0.0720, RMSE=0.2684, R²=0.0069
============================================================


📊 Round 34 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2412, R²: 0.0056

============================================================
🔄 Round 36 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0930 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0929, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0930, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0930, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0930, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0930, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0930)

============================================================
📊 Round 36 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=0.0057
   Val:   Loss=0.0930, RMSE=0.3049, R²=-0.0277
============================================================


============================================================
🔄 Round 37 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0929 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0929, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0929, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0929, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0929, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0929, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0929)

============================================================
📊 Round 37 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=0.0022
   Val:   Loss=0.0929, RMSE=0.3048, R²=0.0020
============================================================


============================================================
🔄 Round 38 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 38 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2892, R²=-0.0006
   Val:   Loss=0.0861, RMSE=0.2935, R²=0.0178
============================================================


============================================================
🔄 Round 40 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0887 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0887, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0887, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0887, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0887, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0887, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0887)

============================================================
📊 Round 40 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=0.0068
   Val:   Loss=0.0887, RMSE=0.2979, R²=-0.0163
============================================================


📊 Round 40 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2412, R²: 0.0058

📊 Round 40 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2412, R²: 0.0058

📊 Round 40 Test Metrics:
   Loss: 0.0785, RMSE: 0.2803, MAE: 0.2412, R²: 0.0060

============================================================
🔄 Round 45 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 45 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=-0.0021
   Val:   Loss=0.0850, RMSE=0.2915, R²=0.0194
============================================================


============================================================
🔄 Round 46 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 46 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=0.0047
   Val:   Loss=0.0848, RMSE=0.2912, R²=-0.0073
============================================================


============================================================
🔄 Round 47 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 47 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2929, R²=-0.0010
   Val:   Loss=0.0775, RMSE=0.2783, R²=0.0032
============================================================


============================================================
🔄 Round 49 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 49 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=0.0031
   Val:   Loss=0.0855, RMSE=0.2925, R²=-0.0174
============================================================


============================================================
🔄 Round 50 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0934 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0934, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0934, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0934, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0934, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0934, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0934)

============================================================
📊 Round 50 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=0.0068
   Val:   Loss=0.0934, RMSE=0.3057, R²=-0.0293
============================================================


📊 Round 50 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2412, R²: 0.0061

📊 Round 50 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2412, R²: 0.0061

============================================================
🔄 Round 53 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 53 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=0.0072
   Val:   Loss=0.0836, RMSE=0.2892, R²=-0.0238
============================================================


📊 Round 53 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2412, R²: 0.0061

============================================================
🔄 Round 55 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 55 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2925, R²=0.0059
   Val:   Loss=0.0784, RMSE=0.2800, R²=-0.0258
============================================================


============================================================
🔄 Round 56 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0906 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0906, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0906, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0906, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0906, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0906, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0906)

============================================================
📊 Round 56 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=0.0071
   Val:   Loss=0.0906, RMSE=0.3011, R²=-0.0105
============================================================


📊 Round 56 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2412, R²: 0.0062

============================================================
🔄 Round 59 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0904 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0904, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0904, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0904, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0904, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0904, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0904)

============================================================
📊 Round 59 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2873, R²=-0.0010
   Val:   Loss=0.0904, RMSE=0.3006, R²=0.0009
============================================================


📊 Round 59 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2412, R²: 0.0062

============================================================
🔄 Round 60 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0902 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0902, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0901, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0901, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0901, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0901, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0902)

============================================================
📊 Round 60 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=0.0008
   Val:   Loss=0.0902, RMSE=0.3003, R²=0.0096
============================================================


============================================================
🔄 Round 61 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0902 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0902, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0902, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0902, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0901, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0901, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0902)

============================================================
📊 Round 61 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=0.0008
   Val:   Loss=0.0902, RMSE=0.3003, R²=0.0130
============================================================


============================================================
🔄 Round 62 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 62 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2919, R²=0.0058
   Val:   Loss=0.0798, RMSE=0.2826, R²=-0.0146
============================================================


📊 Round 62 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2412, R²: 0.0063

============================================================
🔄 Round 63 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0943 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0943, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0943, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0943, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0942, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0942, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0943)

============================================================
📊 Round 63 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=0.0038
   Val:   Loss=0.0943, RMSE=0.3071, R²=0.0024
============================================================


============================================================
🔄 Round 64 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 64 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=0.0135
   Val:   Loss=0.0810, RMSE=0.2846, R²=-0.0453
============================================================


📊 Round 64 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2412, R²: 0.0064

============================================================
🔄 Round 65 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 65 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2925, R²=0.0005
   Val:   Loss=0.0784, RMSE=0.2801, R²=0.0160
============================================================


📊 Round 65 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2411, R²: 0.0065

📊 Round 65 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2411, R²: 0.0065

📊 Round 65 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2411, R²: 0.0066

============================================================
🔄 Round 69 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 69 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2904, R²=0.0061
   Val:   Loss=0.0832, RMSE=0.2884, R²=-0.0071
============================================================


============================================================
🔄 Round 70 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 70 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=-0.0009
   Val:   Loss=0.0808, RMSE=0.2843, R²=0.0219
============================================================


============================================================
🔄 Round 71 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0909 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0909, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0908, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0908, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0908, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0908, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0909)

============================================================
📊 Round 71 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=0.0083
   Val:   Loss=0.0909, RMSE=0.3014, R²=-0.0154
============================================================


============================================================
🔄 Round 73 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0889 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0889, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0889, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0889, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0889, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0889, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0889)

============================================================
📊 Round 73 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2880, R²=0.0130
   Val:   Loss=0.0889, RMSE=0.2982, R²=-0.0352
============================================================


📊 Round 73 Test Metrics:
   Loss: 0.0785, RMSE: 0.2801, MAE: 0.2411, R²: 0.0068

📊 Round 73 Test Metrics:
   Loss: 0.0785, RMSE: 0.2801, MAE: 0.2411, R²: 0.0069

📊 Round 73 Test Metrics:
   Loss: 0.0785, RMSE: 0.2801, MAE: 0.2411, R²: 0.0069

============================================================
🔄 Round 78 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 78 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2913, R²=-0.0074
   Val:   Loss=0.0812, RMSE=0.2849, R²=0.0445
============================================================


============================================================
🔄 Round 81 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 81 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=-0.0015
   Val:   Loss=0.0848, RMSE=0.2912, R²=0.0152
============================================================


============================================================
🔄 Round 82 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 82 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2923, R²=-0.0016
   Val:   Loss=0.0789, RMSE=0.2808, R²=0.0222
============================================================


============================================================
🔄 Round 83 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 83 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2904, R²=-0.0005
   Val:   Loss=0.0832, RMSE=0.2885, R²=0.0158
============================================================


📊 Round 83 Test Metrics:
   Loss: 0.0785, RMSE: 0.2801, MAE: 0.2411, R²: 0.0071

📊 Round 83 Test Metrics:
   Loss: 0.0785, RMSE: 0.2801, MAE: 0.2411, R²: 0.0071

============================================================
🔄 Round 88 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 88 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=0.0125
   Val:   Loss=0.0846, RMSE=0.2909, R²=-0.0330
============================================================


============================================================
🔄 Round 90 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 90 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2904, R²=-0.0009
   Val:   Loss=0.0831, RMSE=0.2882, R²=0.0186
============================================================


📊 Round 90 Test Metrics:
   Loss: 0.0784, RMSE: 0.2801, MAE: 0.2410, R²: 0.0073

============================================================
🔄 Round 92 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0776 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0776, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0776, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0776, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0776, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 92 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2928, R²=-0.0010
   Val:   Loss=0.0776, RMSE=0.2786, R²=0.0213
============================================================


============================================================
🔄 Round 93 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 93 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2920, R²=0.0056
   Val:   Loss=0.0795, RMSE=0.2819, R²=-0.0205
============================================================


📊 Round 93 Test Metrics:
   Loss: 0.0784, RMSE: 0.2801, MAE: 0.2410, R²: 0.0074

📊 Round 93 Test Metrics:
   Loss: 0.0784, RMSE: 0.2800, MAE: 0.2410, R²: 0.0075

📊 Round 93 Test Metrics:
   Loss: 0.0784, RMSE: 0.2800, MAE: 0.2410, R²: 0.0076

============================================================
🔄 Round 101 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0871, val=0.0731 (↓), lr=0.000001
   • Epoch   2/100: train=0.0871, val=0.0731, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0871, val=0.0731, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0870, val=0.0731, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0870, val=0.0731, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0870, val=0.0730, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0731)

============================================================
📊 Round 101 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2947, R²=0.0022
   Val:   Loss=0.0731, RMSE=0.2704, R²=0.0116
============================================================


📊 Round 101 Test Metrics:
   Loss: 0.0784, RMSE: 0.2800, MAE: 0.2410, R²: 0.0076

📊 Round 101 Test Metrics:
   Loss: 0.0784, RMSE: 0.2800, MAE: 0.2410, R²: 0.0077

📊 Round 101 Test Metrics:
   Loss: 0.0784, RMSE: 0.2800, MAE: 0.2410, R²: 0.0077

============================================================
🔄 Round 106 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0765 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0765, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0765, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0765, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0765, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0765, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0765)

============================================================
📊 Round 106 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2932, R²=0.0013
   Val:   Loss=0.0765, RMSE=0.2766, R²=-0.0154
============================================================


📊 Round 106 Test Metrics:
   Loss: 0.0784, RMSE: 0.2800, MAE: 0.2410, R²: 0.0078

============================================================
🔄 Round 107 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 107 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2918, R²=0.0095
   Val:   Loss=0.0798, RMSE=0.2825, R²=-0.0352
============================================================


📊 Round 107 Test Metrics:
   Loss: 0.0784, RMSE: 0.2800, MAE: 0.2410, R²: 0.0078

============================================================
🔄 Round 109 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 109 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2901, R²=0.0073
   Val:   Loss=0.0839, RMSE=0.2896, R²=-0.0113
============================================================


📊 Round 109 Test Metrics:
   Loss: 0.0784, RMSE: 0.2800, MAE: 0.2410, R²: 0.0079

============================================================
🔄 Round 111 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0875 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0875, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0875, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0875, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0875, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0875, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0875)

============================================================
📊 Round 111 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=0.0107
   Val:   Loss=0.0875, RMSE=0.2958, R²=-0.0308
============================================================


📊 Round 111 Test Metrics:
   Loss: 0.0784, RMSE: 0.2800, MAE: 0.2410, R²: 0.0079

============================================================
🔄 Round 113 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0939 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0939, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0939, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0939, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0939, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0938, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0939)

============================================================
📊 Round 113 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=0.0043
   Val:   Loss=0.0939, RMSE=0.3064, R²=-0.0011
============================================================


📊 Round 113 Test Metrics:
   Loss: 0.0784, RMSE: 0.2800, MAE: 0.2409, R²: 0.0080

============================================================
🔄 Round 116 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 116 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=-0.0045
   Val:   Loss=0.0820, RMSE=0.2863, R²=0.0364
============================================================


📊 Round 116 Test Metrics:
   Loss: 0.0784, RMSE: 0.2800, MAE: 0.2409, R²: 0.0081

============================================================
🔄 Round 117 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0774 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0774, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0774, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0774, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0774, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0774, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0774)

============================================================
📊 Round 117 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2928, R²=0.0078
   Val:   Loss=0.0774, RMSE=0.2783, R²=-0.0261
============================================================


============================================================
🔄 Round 118 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 118 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2913, R²=0.0091
   Val:   Loss=0.0809, RMSE=0.2844, R²=-0.0221
============================================================


📊 Round 118 Test Metrics:
   Loss: 0.0784, RMSE: 0.2799, MAE: 0.2409, R²: 0.0082

📊 Round 118 Test Metrics:
   Loss: 0.0784, RMSE: 0.2799, MAE: 0.2409, R²: 0.0083

============================================================
🔄 Round 122 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 122 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2896, R²=0.0049
   Val:   Loss=0.0850, RMSE=0.2915, R²=-0.0024
============================================================


============================================================
🔄 Round 123 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 123 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=0.0021
   Val:   Loss=0.0846, RMSE=0.2909, R²=0.0072
============================================================


📊 Round 123 Test Metrics:
   Loss: 0.0784, RMSE: 0.2799, MAE: 0.2409, R²: 0.0083

📊 Round 123 Test Metrics:
   Loss: 0.0784, RMSE: 0.2799, MAE: 0.2409, R²: 0.0083

📊 Round 123 Test Metrics:
   Loss: 0.0784, RMSE: 0.2799, MAE: 0.2409, R²: 0.0083

============================================================
🔄 Round 127 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0896 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0896, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0896, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0896, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0896, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0896, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0896)

============================================================
📊 Round 127 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=0.0060
   Val:   Loss=0.0896, RMSE=0.2993, R²=-0.0030
============================================================


📊 Round 127 Test Metrics:
   Loss: 0.0784, RMSE: 0.2799, MAE: 0.2409, R²: 0.0083

============================================================
🔄 Round 128 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 128 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=0.0019
   Val:   Loss=0.0862, RMSE=0.2936, R²=0.0095
============================================================


📊 Round 128 Test Metrics:
   Loss: 0.0784, RMSE: 0.2799, MAE: 0.2409, R²: 0.0083

============================================================
🔄 Round 133 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0895 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0895, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0895, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0895, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0895, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0895, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0895)

============================================================
📊 Round 133 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=0.0048
   Val:   Loss=0.0895, RMSE=0.2992, R²=0.0020
============================================================


📊 Round 133 Test Metrics:
   Loss: 0.0784, RMSE: 0.2799, MAE: 0.2409, R²: 0.0084

📊 Round 133 Test Metrics:
   Loss: 0.0784, RMSE: 0.2799, MAE: 0.2409, R²: 0.0084

============================================================
🔄 Round 135 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 135 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=-0.0013
   Val:   Loss=0.0845, RMSE=0.2907, R²=0.0242
============================================================


📊 Round 135 Test Metrics:
   Loss: 0.0784, RMSE: 0.2799, MAE: 0.2409, R²: 0.0084

============================================================
🔄 Round 136 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0868 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0868, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0868, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0868, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0868, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0867, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0868)

============================================================
📊 Round 136 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2887, R²=0.0017
   Val:   Loss=0.0868, RMSE=0.2947, R²=0.0134
============================================================


📊 Round 136 Test Metrics:
   Loss: 0.0783, RMSE: 0.2799, MAE: 0.2409, R²: 0.0085

============================================================
🔄 Round 141 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0763 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0763, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0763, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0763, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0763, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0763, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0763)

============================================================
📊 Round 141 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2932, R²=0.0042
   Val:   Loss=0.0763, RMSE=0.2762, R²=0.0011
============================================================


============================================================
🔄 Round 142 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0877 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0877, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0877, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0877, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0877, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0876, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0877)

============================================================
📊 Round 142 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=0.0057
   Val:   Loss=0.0877, RMSE=0.2961, R²=-0.0011
============================================================


============================================================
🔄 Round 143 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0881 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0881, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0881, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0881, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0881, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0881, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0881)

============================================================
📊 Round 143 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2882, R²=0.0081
   Val:   Loss=0.0881, RMSE=0.2968, R²=-0.0108
============================================================


============================================================
🔄 Round 144 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 144 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2904, R²=-0.0002
   Val:   Loss=0.0828, RMSE=0.2878, R²=0.0107
============================================================


📊 Round 144 Test Metrics:
   Loss: 0.0783, RMSE: 0.2799, MAE: 0.2409, R²: 0.0087

============================================================
🔄 Round 147 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0874, val=0.0713 (↓), lr=0.000001
   • Epoch   2/100: train=0.0874, val=0.0713, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0874, val=0.0713, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0874, val=0.0713, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0874, val=0.0713, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0873, val=0.0712, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0713)

============================================================
📊 Round 147 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0872, RMSE=0.2954, R²=0.0070
   Val:   Loss=0.0713, RMSE=0.2669, R²=-0.0176
============================================================


📊 Round 147 Test Metrics:
   Loss: 0.0783, RMSE: 0.2799, MAE: 0.2408, R²: 0.0087

============================================================
🔄 Round 149 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 149 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2894, R²=0.0099
   Val:   Loss=0.0853, RMSE=0.2920, R²=-0.0428
============================================================


📊 Round 149 Test Metrics:
   Loss: 0.0783, RMSE: 0.2799, MAE: 0.2408, R²: 0.0088

📊 Round 149 Test Metrics:
   Loss: 0.0783, RMSE: 0.2799, MAE: 0.2408, R²: 0.0088

============================================================
🔄 Round 152 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0898 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0898, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0898, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0898, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0898, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0898, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0898)

============================================================
📊 Round 152 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=-0.0034
   Val:   Loss=0.0898, RMSE=0.2996, R²=0.0220
============================================================


📊 Round 152 Test Metrics:
   Loss: 0.0783, RMSE: 0.2798, MAE: 0.2408, R²: 0.0089

============================================================
🔄 Round 154 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 154 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2908, R²=0.0061
   Val:   Loss=0.0819, RMSE=0.2861, R²=-0.0070
============================================================


============================================================
🔄 Round 155 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0975 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0975, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0975, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0974, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0974, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0974, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0975)

============================================================
📊 Round 155 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=0.0051
   Val:   Loss=0.0975, RMSE=0.3122, R²=0.0019
============================================================


📊 Round 155 Test Metrics:
   Loss: 0.0783, RMSE: 0.2798, MAE: 0.2408, R²: 0.0090

============================================================
🔄 Round 158 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0911 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0911, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0911, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0911, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0911, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0911, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0911)

============================================================
📊 Round 158 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2868, R²=0.0043
   Val:   Loss=0.0911, RMSE=0.3019, R²=0.0052
============================================================


📊 Round 158 Test Metrics:
   Loss: 0.0783, RMSE: 0.2798, MAE: 0.2408, R²: 0.0090

============================================================
🔄 Round 161 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 161 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=-0.0004
   Val:   Loss=0.0826, RMSE=0.2875, R²=0.0223
============================================================


📊 Round 161 Test Metrics:
   Loss: 0.0783, RMSE: 0.2798, MAE: 0.2408, R²: 0.0090

============================================================
🔄 Round 163 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0866 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0865, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0865, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0865, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0865, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0866)

============================================================
📊 Round 163 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=0.0052
   Val:   Loss=0.0866, RMSE=0.2942, R²=0.0016
============================================================


============================================================
🔄 Round 164 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 164 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=0.0057
   Val:   Loss=0.0813, RMSE=0.2852, R²=-0.0025
============================================================


============================================================
🔄 Round 165 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0915 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0915, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0915, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0915, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0915, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0915, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0915)

============================================================
📊 Round 165 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2866, R²=0.0071
   Val:   Loss=0.0915, RMSE=0.3026, R²=-0.0052
============================================================


📊 Round 165 Test Metrics:
   Loss: 0.0783, RMSE: 0.2798, MAE: 0.2408, R²: 0.0091

============================================================
🔄 Round 168 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0772 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0772, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0772, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0772, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0772, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 168 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2928, R²=0.0042
   Val:   Loss=0.0772, RMSE=0.2778, R²=-0.0225
============================================================


============================================================
🔄 Round 170 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 170 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=-0.0013
   Val:   Loss=0.0848, RMSE=0.2912, R²=0.0261
============================================================


============================================================
🔄 Round 171 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0914 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0914, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0914, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0914, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0914, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0915, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0914)

============================================================
📊 Round 171 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=0.0078
   Val:   Loss=0.0914, RMSE=0.3024, R²=-0.0147
============================================================


📊 Round 171 Test Metrics:
   Loss: 0.0783, RMSE: 0.2798, MAE: 0.2408, R²: 0.0092

============================================================
🔄 Round 173 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 173 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2899, R²=0.0046
   Val:   Loss=0.0839, RMSE=0.2897, R²=-0.0403
============================================================


============================================================
🔄 Round 174 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 174 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=0.0085
   Val:   Loss=0.0813, RMSE=0.2852, R²=-0.0351
============================================================


📊 Round 174 Test Metrics:
   Loss: 0.0783, RMSE: 0.2798, MAE: 0.2408, R²: 0.0093

📊 Round 174 Test Metrics:
   Loss: 0.0783, RMSE: 0.2798, MAE: 0.2408, R²: 0.0094

📊 Round 174 Test Metrics:
   Loss: 0.0783, RMSE: 0.2798, MAE: 0.2407, R²: 0.0094

📊 Round 174 Test Metrics:
   Loss: 0.0783, RMSE: 0.2798, MAE: 0.2407, R²: 0.0095

📊 Round 174 Test Metrics:
   Loss: 0.0783, RMSE: 0.2798, MAE: 0.2407, R²: 0.0094

============================================================
🔄 Round 188 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 188 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=0.0013
   Val:   Loss=0.0825, RMSE=0.2873, R²=0.0167
============================================================


📊 Round 188 Test Metrics:
   Loss: 0.0783, RMSE: 0.2797, MAE: 0.2407, R²: 0.0096

============================================================
🔄 Round 193 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0896 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0896, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0896, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0896, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0896, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0896, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0896)

============================================================
📊 Round 193 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=0.0081
   Val:   Loss=0.0896, RMSE=0.2994, R²=-0.0067
============================================================


============================================================
🔄 Round 195 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 195 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=0.0088
   Val:   Loss=0.0818, RMSE=0.2861, R²=-0.0118
============================================================


============================================================
🔄 Round 197 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 197 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2901, R²=0.0041
   Val:   Loss=0.0833, RMSE=0.2886, R²=0.0075
============================================================


📊 Round 197 Test Metrics:
   Loss: 0.0783, RMSE: 0.2797, MAE: 0.2407, R²: 0.0097

============================================================
🔄 Round 198 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 198 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=0.0067
   Val:   Loss=0.0818, RMSE=0.2860, R²=-0.0018
============================================================


============================================================
🔄 Round 200 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0968 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0968, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0968, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0968, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0968, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0969, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0968)

============================================================
📊 Round 200 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=0.0038
   Val:   Loss=0.0968, RMSE=0.3111, R²=-0.0342
============================================================


============================================================
🔄 Round 201 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 201 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=0.0008
   Val:   Loss=0.0825, RMSE=0.2872, R²=0.0115
============================================================


📊 Round 201 Test Metrics:
   Loss: 0.0782, RMSE: 0.2797, MAE: 0.2407, R²: 0.0098

============================================================
🔄 Round 205 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0869, val=0.0728 (↓), lr=0.000001
   • Epoch   2/100: train=0.0869, val=0.0728, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0869, val=0.0728, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0869, val=0.0728, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0869, val=0.0728, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0868, val=0.0728, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0728)

============================================================
📊 Round 205 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2946, R²=0.0022
   Val:   Loss=0.0728, RMSE=0.2698, R²=0.0144
============================================================


============================================================
🔄 Round 206 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 206 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2913, R²=0.0035
   Val:   Loss=0.0805, RMSE=0.2837, R²=-0.0042
============================================================


📊 Round 206 Test Metrics:
   Loss: 0.0782, RMSE: 0.2797, MAE: 0.2407, R²: 0.0098

============================================================
🔄 Round 207 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0931 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0931, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0931, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0931, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0931, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0931, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0931)

============================================================
📊 Round 207 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=0.0159
   Val:   Loss=0.0931, RMSE=0.3051, R²=-0.0350
============================================================


📊 Round 207 Test Metrics:
   Loss: 0.0782, RMSE: 0.2797, MAE: 0.2407, R²: 0.0099

============================================================
🔄 Round 208 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0773, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0773, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 208 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2927, R²=-0.0015
   Val:   Loss=0.0773, RMSE=0.2780, R²=0.0199
============================================================


============================================================
🔄 Round 209 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0780 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0780, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0780, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0780, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0780, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 209 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2923, R²=0.0030
   Val:   Loss=0.0780, RMSE=0.2794, R²=0.0076
============================================================


============================================================
🔄 Round 211 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0875 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0875, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0875, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0875, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0875, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0875, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0875)

============================================================
📊 Round 211 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=0.0033
   Val:   Loss=0.0875, RMSE=0.2958, R²=0.0124
============================================================


============================================================
🔄 Round 215 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0752 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0752, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0752, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0752, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0752, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0753, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0752)

============================================================
📊 Round 215 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2935, R²=-0.0085
   Val:   Loss=0.0752, RMSE=0.2742, R²=0.0535
============================================================


📊 Round 215 Test Metrics:
   Loss: 0.0782, RMSE: 0.2797, MAE: 0.2406, R²: 0.0101

📊 Round 215 Test Metrics:
   Loss: 0.0782, RMSE: 0.2797, MAE: 0.2406, R²: 0.0101

📊 Round 215 Test Metrics:
   Loss: 0.0782, RMSE: 0.2797, MAE: 0.2406, R²: 0.0101

============================================================
🔄 Round 218 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 218 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2899, R²=0.0118
   Val:   Loss=0.0836, RMSE=0.2891, R²=-0.0300
============================================================


============================================================
🔄 Round 221 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0927 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0927, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0927, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0927, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0927, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0927, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0927)

============================================================
📊 Round 221 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=0.0073
   Val:   Loss=0.0927, RMSE=0.3045, R²=-0.0019
============================================================


📊 Round 221 Test Metrics:
   Loss: 0.0782, RMSE: 0.2797, MAE: 0.2406, R²: 0.0103

============================================================
🔄 Round 225 - Client client_25
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 225 Summary - Client client_25
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=0.0126
   Val:   Loss=0.0801, RMSE=0.2830, R²=-0.0331
============================================================


❌ Client client_25 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "recvmsg:Connection reset by peer"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8687 {grpc_message:"recvmsg:Connection reset by peer", grpc_status:14}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "recvmsg:Connection reset by peer"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8687 {grpc_message:"recvmsg:Connection reset by peer", grpc_status:14}"
>
