[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1761ef6d-491d-4775-9e88-40ec54e38638
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c8496bb3-2788-45b0-8425-dd92f342207d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ba6a5cc0-7857-4124-8184-ca03b452f874
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1b4711f7-e9ab-416b-aae7-cb8717e4bec5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b5601811-a678-448d-b9e7-866e836a0eaa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1566fb30-d75e-4929-a31e-2a1479ef9a96
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e00ac723-2290-46fa-a75f-2a65541cfd15
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7498993e-4d9e-4cdf-a3b7-5a6d56a5cd78
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b31bec86-e5ff-4932-b6ca-9a0294801310
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a44e8dbb-1744-4ab3-9371-7b7a9ccc9ee8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e5075f92-18a1-4e55-8c5a-24ba14c9f2dd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e3cf0ee4-0cf7-4c70-93eb-e3cd5b5d8836
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8fdb1185-a244-4e5b-ab47-c7ec139cdc8b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 871de2d8-fca2-4db8-a55e-2ea97828462e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a80f1536-406d-43c2-b439-038e09987b82
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7c981e3d-037a-4555-87aa-ce3307263fb7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ab6a7ef4-5cec-41bf-92d3-d78122f19cff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 846702ba-4099-4a84-9627-f2920fec815b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 74c373ee-a2b8-4244-87e8-175fce92456b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9307cb1f-5f0c-4d11-ab35-001e6c7e24a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b21dea21-fc71-4ec2-8fd3-daa19df8f7d5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2b93a0d6-80ef-495a-a978-a6bd5b025c0c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 38c6f495-7357-4300-9dfd-9562b99b2bcc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fabad8f6-35cd-4b9e-b1d5-2bd28317e0d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2f2b4633-8cbe-4825-84f0-cf243fef1872
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b63ab173-6b46-4d22-b4ff-5267cd52ec71
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c050ed40-8b8f-41fb-a93b-a0734345f543
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 82038924-9279-4e95-92a3-ea711f2c4c84
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 65d037a1-69ab-4d70-830c-651f66e72d6f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 91617614-a232-46e0-821e-240c0daa3450
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a6f4e1b4-5e5b-4d2b-a44a-5de242e4750a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f183bc5c-dd88-4dcd-ad3d-a09e3f988e28
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e8e39a2a-7081-440b-995a-2b4444435c39
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0245570e-291a-49dd-9bed-b19845965ea8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6eab8954-e47b-49c7-9456-eccb134a080f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9b151468-89cd-4c43-91eb-aa002a7eed5d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 594dc2ee-c460-453f-9ee6-0ff79f567b44
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fcff0d7f-092e-4669-9768-ba0ed09fceed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 87247c7c-701d-4d7d-b742-6c9c8faf960d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b52ca327-7359-4dbe-9da2-fb87fc66715c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0847805f-01d1-4fd7-b0bd-81b479a28a05
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 83aa3cca-0587-4b7c-acb7-385aad4a61ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8e0f5664-dd3d-47fa-b781-62fb821b535f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message de0bb8b0-982b-4b11-ad13-3f65bedbc399
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8b11f5b6-e9f5-42d9-950f-ebeb7ba24f31
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d169fcb6-88c5-497a-8dfa-d16ac91e37a7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8cd6e0ea-9a2e-4ef8-a84a-3d98c55b2dec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 14c54ecc-4b6e-4332-911a-24f9bb408876
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d5bed3df-558e-4f48-b245-68af93826236
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4e330f34-aef0-4be9-8f37-c03feafe9f63
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 58d3367e-484d-45be-8e05-b1359519cc8f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ece87848-45b2-4587-833c-bc29809af3ea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b3425138-690d-44f4-9822-6e6956808c3e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1948cfec-cfff-4722-8082-7d534b064ad5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 14b077d5-8964-471e-842c-3ebefaeb0f02
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 69b9892a-d8bb-4aa2-8749-d440f2065551
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3655d48b-ce05-45fe-af7c-a35db959b31b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1946494a-bcde-4c5d-811b-5c624d9d6c1b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 812bd45d-9d99-4dfe-a891-029e955b6765
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6b91f75e-2dfc-4e1f-a10e-f1782daf6a22
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message da94e863-4e4c-424e-99a3-2dd35d08b865
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1d941d6f-9b3f-45a0-b966-c0c9da88eb11
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7c565b26-ff35-4227-aea2-95489f225e48
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 64226791-cead-41e8-ab87-c35145713076
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 62f42cdf-8302-44fb-a01c-ffe6516c23a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3ec80376-1525-4b91-92eb-3884fc119a0d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 66585228-3c3b-4705-9751-08b160b232fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2bb1a540-0114-405c-8b66-fd4cdfc37a3c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 457a5386-248a-46c2-8fa7-0635dc87104b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1c5f8c5f-147c-4c06-924a-a933f049471f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c63cf60f-6165-4f01-871e-49888322f2b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e3d8c015-f8d2-4f4b-ad88-dc94e0f4c19f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 48b27db3-6030-4ec9-9abd-86ef6afb206f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2367fca7-3ca7-4ede-a17d-0d34a0837da3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d7151736-9576-4cfd-ab4d-b322a72d7d5d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3abc14ed-bc36-450a-b00b-a432e9eee176
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e3697994-b0b2-46ff-bcca-e8121f4e4b02
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d62f69c4-35a3-4402-8bd3-8b500421c639
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aa8e16c7-ac7b-45bb-91fa-e1390eda0153
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3b8992cf-2a85-4ac8-86a8-23a5ba36fc0b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e321149a-180b-48be-8d63-be46b1d0127e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d40ad54c-d829-4f08-83dc-d1b8cbf3cbb1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 719bc953-dcfe-4804-bf04-b357e1cc592f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1d2c76db-df74-48e2-8760-1e11aac5efb6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 73820274-96fc-4db7-96d5-5777a50ed235
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3541e1d3-d58d-4a47-97b9-a2fa309ea6f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 29b9f48a-5e87-4f4c-92fd-09322bf13e2f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d5e82577-6040-470f-aa6d-38fdf65fa67b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eda389ba-12e0-4f80-8a44-9b44228584c6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d7393496-91e1-430c-a770-83f68b3a1db8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f14a692f-408d-425f-b77b-08bbfdc454a9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f0c6cb72-a301-4043-9bcb-eccc00a2a6b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 868cc7f5-4a57-46df-b379-1d91f7ce09ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6a343b2b-e48e-40ba-a3a5-2338819c4d88
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 53ad48ce-c802-40e9-8ca5-c974ca82c406
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a7c909b4-f88d-470e-a4b6-cc5fc560f2b9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 18235e6f-0a0e-4ebc-b552-6f2cb7bddd14
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c9697ce5-701a-4029-9814-84232c985700
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d3f1e799-4f01-4f9b-9b05-6f7d731a0d24
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 937220d2-e5bf-4768-b406-9aaebb02257f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 69495a85-dbea-4203-bd1f-10a5df5344e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3fd82a4c-aeb1-409a-ab71-1a008e64682a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a9c17298-23a0-46ce-9434-2637fc50204e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fbc618d5-5523-4a1a-9e8f-540330e2bef2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3df7f19d-03bd-432b-9cb1-b3b97f8f3b14
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message df75285b-ae52-4a65-952e-4a23a1406d92
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 916da0ac-8525-4d94-a597-b63b28767a83
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7bd02936-0f82-4a99-a214-a314892b7840
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2f07299c-8e24-4a3b-aac7-cb9feced1bda
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c9046d09-937d-4b42-b26c-96d14cd1d62c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 491f0f0f-b4f0-4575-a5d0-0f9950b1d800
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 03581da7-d838-490e-9075-be708db22c82
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 029f6e13-53ee-4454-8471-301e6b5572be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 22e40611-eaef-4329-a531-c98fdb7c63dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c4079011-cb3e-484c-b8f1-97316d7b87f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message db3d0207-f42a-4383-bf68-91419ba8c56a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 63fddea3-de64-4f6b-ac31-999a996daf9f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a3769d26-01e6-4848-9339-36e1a0e5329e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cdb7a4cc-73f4-4fed-a892-b5663059628e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fd65bcda-ce9b-4faa-93ce-212c8e110bb0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e80e02e7-b56d-4020-b39a-eee4be88389c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 99aadb37-9074-4c4f-b18d-fdf244943c53
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d7f7b8ec-d76e-4df4-8236-ee6c35d61fba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f05fb8fc-95b3-4303-8ffc-dc4e264d1d3e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f547c6ac-7b31-4b24-b944-7fd8fe1d0f5a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4cc1a747-549b-4549-9d80-b195867214ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d9668035-67e1-48fb-8721-b96cbe99af47
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ec28ed4b-1c1a-40ec-a4ad-b883e54bbcce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7e4f7f49-927f-4316-84d8-7ed3c4f2d08f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 19b478ed-33c8-4fe6-994a-f4bcab84c9b7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d1c8a164-f8b5-4ad0-a1e8-c4b0d2a5a97a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eb2f667d-e148-4071-bb9f-4ae3b2f5ecaa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 34839c87-bfa2-47a6-b73e-fe803415ecfa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ebbe8294-3f64-43d3-9cff-58769dd2a2c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 535bcc8e-eff8-44af-a70c-3cefb7adbbd5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a2f074a4-2acc-494f-b961-de7319797864
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 49ed4089-01ea-4e10-bd8b-16b86054c897
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ebfc91d5-7d41-4bbd-894f-3cbcb1ecf134
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5b371a52-8030-41d5-bcb6-5561d7d65e4e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f477480e-f11c-4877-a5fe-2c6994b7cbe1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2d247639-4bac-4e2c-8454-69c41be4d90e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c3025ffa-4e47-4edd-8431-a71b22e7a9ce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4203e179-0d95-4dfe-8f1d-d4d4ff3cb5f4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2eac0788-0d68-4384-9a8f-bacbc38b6bbe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 50cc9779-d148-4782-abd1-6c1a340bde9d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4c2d6f46-f020-403e-9ac9-524bc4fb69cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8bebaeff-33ee-44f0-b38f-a68de49acb9b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eead8559-49e0-45a2-802a-08c813f4d794
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1b3d99d0-9d1e-43a4-bb2e-8a50c797a8fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9d0dd7e1-ab0a-44f5-99a1-1bc85b3597d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 015c4053-9c98-49b2-b809-f8327b601f40
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message df615a87-dabe-4843-8ba3-436f577abcbe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 90ff1f8a-c907-4928-ae55-a0c95d290004
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 96dad726-be01-4cd7-bd23-b624dbc6918d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0f38b5fb-b54e-4fab-9be1-45b0164c5d59
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2025c1e4-e01e-475b-a67f-0a35c3d49b21
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d5f94bd8-5458-4262-9848-57b6a30eccab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f0c95a14-b20c-43d6-a437-7e5713d72b72
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4a002e8a-4f40-4aee-a959-05601bfb596c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9ae404d5-755e-400d-83c5-9130a15dcc72
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fac8604e-47b1-4870-a859-95d61b3a2a79
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bd17b780-b959-4222-acad-125c3d1d101e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 03fc6237-a6ef-4df1-bad0-d213a3631067
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dcacb560-9577-4f3c-b889-d0cdb5293ef8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 166a7ae3-b100-4485-ba9b-d84a3324b2fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f72964b4-fbe2-432e-ac95-be895da6bb5a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0910f7f7-2416-4090-a6e2-e22cd82907fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3325e399-49d0-4a93-b6b5-0580b66b4e8c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4ac31e18-fcab-4de7-9ee5-2fbfe935a772
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 43ba74f4-7ae6-4bcb-959d-0116fc2df71a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 48756272-8f1b-4bd4-9edd-73ce2eaaf791
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d8fb9273-c47e-4229-88ea-cd098eb7270c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 38a710fc-6c24-4af2-a990-e62f9db93edb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7a18b138-8628-4924-b9a1-e416096db1f3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b423f084-4940-4933-b414-e3f0d94125bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1c58da43-5648-4f1e-a211-c916ad85b689
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a7e35e67-c0a9-4711-bf3e-6948a5914d94
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d6306c96-f715-4d20-b731-b1e6502bb4c9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8e790c53-e561-42cf-b619-c3255f533b4a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a2922614-2f2a-4c39-ab9d-5e27ce57fb7c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 56a075a4-5aea-49f7-b0ad-47ae62641022
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message be223d2b-7307-474b-a265-9631aca38638
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a2b068ea-c877-4dc1-82dd-8baef1431e98
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a7374ec2-a70a-4204-a44e-fde75d143dd2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0a3bb21f-a143-42bd-8d70-65fd96a65800
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8687 {grpc_message:"Socket closed", grpc_status:14}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_26
Server: localhost:8687
Algorithm: FEDAVG
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_26
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_26/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_26/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_26/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_26/test_labels.txt

📊 Raw data loaded:
   Train: X=(1231, 24), y=(1231,)
   Test:  X=(308, 24), y=(308,)

⚠️  Limiting training data: 1231 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  299 samples, 5 features
✅ Client client_26 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

📊 Round 0 Test Metrics:
   Loss: 0.0872, RMSE: 0.2953, MAE: 0.2603, R²: -0.0140

============================================================
🔄 Round 3 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0834 (↓), lr=0.001000
   • Epoch   2/100: train=0.0822, val=0.0855, patience=1/15, lr=0.001000
   • Epoch   3/100: train=0.0822, val=0.0877, patience=2/15, lr=0.001000
   • Epoch   4/100: train=0.0817, val=0.0871, patience=3/15, lr=0.001000
   • Epoch   5/100: train=0.0810, val=0.0864, patience=4/15, lr=0.001000
   📉 Epoch 7: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0785, val=0.0853, patience=10/15, lr=0.000500
   📉 Epoch 15: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 3 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=-0.0155
   Val:   Loss=0.0834, RMSE=0.2888, R²=0.0032
============================================================


📊 Round 3 Test Metrics:
   Loss: 0.0860, RMSE: 0.2932, MAE: 0.2592, R²: -0.0001

============================================================
🔄 Round 6 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0846 (↓), lr=0.000250
   • Epoch   2/100: train=0.0803, val=0.0845, patience=1/15, lr=0.000250
   • Epoch   3/100: train=0.0798, val=0.0846, patience=2/15, lr=0.000250
   • Epoch   4/100: train=0.0795, val=0.0847, patience=3/15, lr=0.000250
   • Epoch   5/100: train=0.0792, val=0.0848, patience=4/15, lr=0.000250
   📉 Epoch 7: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0780, val=0.0850, patience=10/15, lr=0.000125
   📉 Epoch 15: LR reduced 0.000125 → 0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 6 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000250 → 0.000063 (2 reductions)
   Train: Loss=0.0799, RMSE=0.2826, R²=0.0203
   Val:   Loss=0.0846, RMSE=0.2909, R²=0.0053
============================================================


============================================================
🔄 Round 8 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0811 (↓), lr=0.000063
   • Epoch   2/100: train=0.0806, val=0.0808, patience=1/15, lr=0.000063
   • Epoch   3/100: train=0.0804, val=0.0807, patience=2/15, lr=0.000063
   • Epoch   4/100: train=0.0802, val=0.0806, patience=3/15, lr=0.000063
   ✓ Epoch   5/100: train=0.0801, val=0.0805 (↓), lr=0.000063
   • Epoch  11/100: train=0.0795, val=0.0801, patience=6/15, lr=0.000063
   • Epoch  21/100: train=0.0787, val=0.0794, patience=1/15, lr=0.000063
   • Epoch  31/100: train=0.0780, val=0.0787, patience=3/15, lr=0.000063
   • Epoch  41/100: train=0.0774, val=0.0781, patience=5/15, lr=0.000063
   • Epoch  51/100: train=0.0767, val=0.0777, patience=6/15, lr=0.000063
   • Epoch  61/100: train=0.0760, val=0.0773, patience=2/15, lr=0.000063
   • Epoch  71/100: train=0.0753, val=0.0771, patience=12/15, lr=0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 8 Summary - Client client_26
   Epochs: 74/100 (early stopped)
   LR: 0.000063 → 0.000063 (0 reductions)
   Train: Loss=0.0761, RMSE=0.2758, R²=0.0770
   Val:   Loss=0.0773, RMSE=0.2781, R²=0.0516
============================================================


📊 Round 8 Test Metrics:
   Loss: 0.0867, RMSE: 0.2944, MAE: 0.2597, R²: -0.0078

============================================================
🔄 Round 9 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0865 (↓), lr=0.000063
   • Epoch   2/100: train=0.0795, val=0.0866, patience=1/15, lr=0.000063
   • Epoch   3/100: train=0.0792, val=0.0865, patience=2/15, lr=0.000063
   • Epoch   4/100: train=0.0789, val=0.0864, patience=3/15, lr=0.000063
   • Epoch   5/100: train=0.0787, val=0.0863, patience=4/15, lr=0.000063
   📉 Epoch 6: LR reduced 0.000063 → 0.000031
   • Epoch  11/100: train=0.0783, val=0.0861, patience=10/15, lr=0.000031
   📉 Epoch 14: LR reduced 0.000031 → 0.000016

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0865)

============================================================
📊 Round 9 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000063 → 0.000016 (2 reductions)
   Train: Loss=0.0796, RMSE=0.2821, R²=0.0107
   Val:   Loss=0.0865, RMSE=0.2942, R²=0.0280
============================================================


📊 Round 9 Test Metrics:
   Loss: 0.0869, RMSE: 0.2948, MAE: 0.2597, R²: -0.0106

📊 Round 9 Test Metrics:
   Loss: 0.0869, RMSE: 0.2947, MAE: 0.2598, R²: -0.0103

============================================================
🔄 Round 13 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000016
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0848 (↓), lr=0.000016
   • Epoch   2/100: train=0.0803, val=0.0847, patience=1/15, lr=0.000016
   • Epoch   3/100: train=0.0802, val=0.0847, patience=2/15, lr=0.000016
   • Epoch   4/100: train=0.0801, val=0.0847, patience=3/15, lr=0.000016
   • Epoch   5/100: train=0.0801, val=0.0846, patience=4/15, lr=0.000016
   📉 Epoch 6: LR reduced 0.000016 → 0.000008
   • Epoch  11/100: train=0.0798, val=0.0845, patience=10/15, lr=0.000008
   📉 Epoch 14: LR reduced 0.000008 → 0.000004

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 13 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000016 → 0.000004 (2 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=0.0149
   Val:   Loss=0.0848, RMSE=0.2912, R²=0.0047
============================================================


📊 Round 13 Test Metrics:
   Loss: 0.0868, RMSE: 0.2946, MAE: 0.2596, R²: -0.0096

============================================================
🔄 Round 14 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000004
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0837 (↓), lr=0.000004
   • Epoch   2/100: train=0.0803, val=0.0838, patience=1/15, lr=0.000004
   • Epoch   3/100: train=0.0803, val=0.0838, patience=2/15, lr=0.000004
   • Epoch   4/100: train=0.0803, val=0.0838, patience=3/15, lr=0.000004
   • Epoch   5/100: train=0.0802, val=0.0838, patience=4/15, lr=0.000004
   📉 Epoch 6: LR reduced 0.000004 → 0.000002
   • Epoch  11/100: train=0.0801, val=0.0839, patience=10/15, lr=0.000002
   📉 Epoch 14: LR reduced 0.000002 → 0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 14 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000004 → 0.000001 (2 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=0.0123
   Val:   Loss=0.0837, RMSE=0.2894, R²=0.0121
============================================================


📊 Round 14 Test Metrics:
   Loss: 0.0868, RMSE: 0.2947, MAE: 0.2596, R²: -0.0097

============================================================
🔄 Round 15 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 15 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=0.0207
   Val:   Loss=0.0805, RMSE=0.2837, R²=-0.0134
============================================================


📊 Round 15 Test Metrics:
   Loss: 0.0867, RMSE: 0.2945, MAE: 0.2595, R²: -0.0086

📊 Round 15 Test Metrics:
   Loss: 0.0866, RMSE: 0.2943, MAE: 0.2593, R²: -0.0071

============================================================
🔄 Round 17 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0781, val=0.0925 (↓), lr=0.000001
   • Epoch   2/100: train=0.0780, val=0.0925, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0780, val=0.0924, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0780, val=0.0924, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0780, val=0.0924, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0780, val=0.0924, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0925)

============================================================
📊 Round 17 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0780, RMSE=0.2792, R²=0.0159
   Val:   Loss=0.0925, RMSE=0.3041, R²=0.0050
============================================================


📊 Round 17 Test Metrics:
   Loss: 0.0866, RMSE: 0.2942, MAE: 0.2593, R²: -0.0069

============================================================
🔄 Round 18 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0871 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0871, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0871, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0871, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0871, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0871, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0871)

============================================================
📊 Round 18 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2816, R²=0.0122
   Val:   Loss=0.0871, RMSE=0.2952, R²=0.0319
============================================================


============================================================
🔄 Round 19 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 19 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2829, R²=0.0133
   Val:   Loss=0.0842, RMSE=0.2902, R²=-0.0007
============================================================


============================================================
🔄 Round 20 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0765 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0765, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0765, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0765, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0765, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0765, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0765)

============================================================
📊 Round 20 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=0.0153
   Val:   Loss=0.0765, RMSE=0.2766, R²=0.0120
============================================================


📊 Round 20 Test Metrics:
   Loss: 0.0864, RMSE: 0.2939, MAE: 0.2590, R²: -0.0044

============================================================
🔄 Round 23 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 23 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=0.0199
   Val:   Loss=0.0819, RMSE=0.2861, R²=0.0157
============================================================


============================================================
🔄 Round 24 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 24 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2847, R²=0.0121
   Val:   Loss=0.0792, RMSE=0.2814, R²=0.0193
============================================================


📊 Round 24 Test Metrics:
   Loss: 0.0864, RMSE: 0.2939, MAE: 0.2590, R²: -0.0043

📊 Round 24 Test Metrics:
   Loss: 0.0864, RMSE: 0.2939, MAE: 0.2590, R²: -0.0043

============================================================
🔄 Round 26 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0894 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0893, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0893, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0893, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0893, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0893, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0894)

============================================================
📊 Round 26 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2802, R²=0.0272
   Val:   Loss=0.0894, RMSE=0.2989, R²=-0.0103
============================================================


============================================================
🔄 Round 28 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0734 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0734, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0734, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0734, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0734, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0734, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0734)

============================================================
📊 Round 28 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=0.0142
   Val:   Loss=0.0734, RMSE=0.2710, R²=0.0351
============================================================


============================================================
🔄 Round 30 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0769 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0769, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0769, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0769, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0769, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0768, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0769)

============================================================
📊 Round 30 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=0.0212
   Val:   Loss=0.0769, RMSE=0.2773, R²=-0.0005
============================================================


============================================================
🔄 Round 31 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0747 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0747, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0747, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0747, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0747, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0747, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0747)

============================================================
📊 Round 31 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2866, R²=0.0223
   Val:   Loss=0.0747, RMSE=0.2733, R²=-0.0232
============================================================


📊 Round 31 Test Metrics:
   Loss: 0.0864, RMSE: 0.2939, MAE: 0.2590, R²: -0.0042

============================================================
🔄 Round 34 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 34 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2840, R²=0.0190
   Val:   Loss=0.0808, RMSE=0.2843, R²=0.0172
============================================================


============================================================
🔄 Round 37 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0709 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0709, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0709, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0709, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0709, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0708, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0709)

============================================================
📊 Round 37 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=0.0086
   Val:   Loss=0.0709, RMSE=0.2662, R²=0.0632
============================================================


📊 Round 37 Test Metrics:
   Loss: 0.0864, RMSE: 0.2939, MAE: 0.2590, R²: -0.0042

📊 Round 37 Test Metrics:
   Loss: 0.0863, RMSE: 0.2939, MAE: 0.2590, R²: -0.0042

============================================================
🔄 Round 39 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0757 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0757, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0757, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0758, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0758, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0758, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0757)

============================================================
📊 Round 39 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=0.0139
   Val:   Loss=0.0757, RMSE=0.2752, R²=0.0323
============================================================


============================================================
🔄 Round 41 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0882 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0882, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0882, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0882, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0882, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0882, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0882)

============================================================
📊 Round 41 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2807, R²=0.0260
   Val:   Loss=0.0882, RMSE=0.2970, R²=-0.0055
============================================================


📊 Round 41 Test Metrics:
   Loss: 0.0863, RMSE: 0.2938, MAE: 0.2590, R²: -0.0041

============================================================
🔄 Round 42 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0772 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0772, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0772, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0772, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0772, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 42 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=0.0354
   Val:   Loss=0.0772, RMSE=0.2778, R²=-0.0681
============================================================


📊 Round 42 Test Metrics:
   Loss: 0.0863, RMSE: 0.2938, MAE: 0.2590, R²: -0.0041

============================================================
🔄 Round 44 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 44 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2818, R²=0.0329
   Val:   Loss=0.0857, RMSE=0.2927, R²=-0.0666
============================================================


============================================================
🔄 Round 45 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0755 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0755, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0755, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0755, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0755, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0755, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0755)

============================================================
📊 Round 45 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2863, R²=0.0131
   Val:   Loss=0.0755, RMSE=0.2748, R²=0.0266
============================================================


============================================================
🔄 Round 50 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 50 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=0.0212
   Val:   Loss=0.0830, RMSE=0.2881, R²=0.0097
============================================================


📊 Round 50 Test Metrics:
   Loss: 0.0863, RMSE: 0.2938, MAE: 0.2590, R²: -0.0041

============================================================
🔄 Round 51 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 51 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2833, R²=0.0273
   Val:   Loss=0.0822, RMSE=0.2867, R²=-0.0124
============================================================


============================================================
🔄 Round 52 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0884 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0884, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0884, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0884, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0884, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0884, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0884)

============================================================
📊 Round 52 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2805, R²=0.0172
   Val:   Loss=0.0884, RMSE=0.2974, R²=0.0115
============================================================


📊 Round 52 Test Metrics:
   Loss: 0.0863, RMSE: 0.2938, MAE: 0.2590, R²: -0.0040

============================================================
🔄 Round 54 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 54 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=0.0230
   Val:   Loss=0.0818, RMSE=0.2860, R²=0.0035
============================================================


📊 Round 54 Test Metrics:
   Loss: 0.0863, RMSE: 0.2938, MAE: 0.2590, R²: -0.0041

============================================================
🔄 Round 55 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0879 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0879, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0878, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0878, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0878, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0877, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0879)

============================================================
📊 Round 55 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2808, R²=0.0113
   Val:   Loss=0.0879, RMSE=0.2964, R²=0.0471
============================================================


📊 Round 55 Test Metrics:
   Loss: 0.0863, RMSE: 0.2938, MAE: 0.2589, R²: -0.0040

============================================================
🔄 Round 59 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0887 (↓), lr=0.000001
   • Epoch   2/100: train=0.0787, val=0.0887, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0887, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0887, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0887, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0886, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0887)

============================================================
📊 Round 59 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2804, R²=0.0151
   Val:   Loss=0.0887, RMSE=0.2978, R²=0.0352
============================================================


============================================================
🔄 Round 60 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0723 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0723, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0723, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0723, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0723, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0722, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0723)

============================================================
📊 Round 60 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=0.0136
   Val:   Loss=0.0723, RMSE=0.2690, R²=0.0429
============================================================


📊 Round 60 Test Metrics:
   Loss: 0.0863, RMSE: 0.2938, MAE: 0.2589, R²: -0.0040

📊 Round 60 Test Metrics:
   Loss: 0.0863, RMSE: 0.2938, MAE: 0.2589, R²: -0.0040

============================================================
🔄 Round 63 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 63 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=0.0152
   Val:   Loss=0.0816, RMSE=0.2857, R²=0.0368
============================================================


📊 Round 63 Test Metrics:
   Loss: 0.0863, RMSE: 0.2938, MAE: 0.2589, R²: -0.0039

============================================================
🔄 Round 65 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 65 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2831, R²=0.0119
   Val:   Loss=0.0826, RMSE=0.2874, R²=0.0482
============================================================


============================================================
🔄 Round 66 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 66 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=0.0172
   Val:   Loss=0.0775, RMSE=0.2784, R²=0.0184
============================================================


============================================================
🔄 Round 69 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0717 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0717, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0717, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0717, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0716, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0716, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0717)

============================================================
📊 Round 69 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=0.0158
   Val:   Loss=0.0717, RMSE=0.2677, R²=0.0332
============================================================


📊 Round 69 Test Metrics:
   Loss: 0.0863, RMSE: 0.2938, MAE: 0.2589, R²: -0.0037

📊 Round 69 Test Metrics:
   Loss: 0.0863, RMSE: 0.2938, MAE: 0.2589, R²: -0.0037

============================================================
🔄 Round 73 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0898 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0898, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0898, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0897, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0897, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0897, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0898)

============================================================
📊 Round 73 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0783, RMSE=0.2799, R²=0.0290
   Val:   Loss=0.0898, RMSE=0.2996, R²=-0.0166
============================================================


📊 Round 73 Test Metrics:
   Loss: 0.0863, RMSE: 0.2938, MAE: 0.2589, R²: -0.0037

📊 Round 73 Test Metrics:
   Loss: 0.0863, RMSE: 0.2938, MAE: 0.2589, R²: -0.0036

============================================================
🔄 Round 76 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 76 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=0.0220
   Val:   Loss=0.0784, RMSE=0.2800, R²=0.0106
============================================================


============================================================
🔄 Round 77 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 77 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=0.0159
   Val:   Loss=0.0801, RMSE=0.2829, R²=0.0314
============================================================


📊 Round 77 Test Metrics:
   Loss: 0.0863, RMSE: 0.2938, MAE: 0.2589, R²: -0.0036

📊 Round 77 Test Metrics:
   Loss: 0.0863, RMSE: 0.2937, MAE: 0.2589, R²: -0.0035

📊 Round 77 Test Metrics:
   Loss: 0.0863, RMSE: 0.2937, MAE: 0.2589, R²: -0.0035

============================================================
🔄 Round 80 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 80 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=0.0368
   Val:   Loss=0.0822, RMSE=0.2867, R²=-0.0606
============================================================


============================================================
🔄 Round 81 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0770 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0770, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0770, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0770, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0770, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0770, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0770)

============================================================
📊 Round 81 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=0.0194
   Val:   Loss=0.0770, RMSE=0.2776, R²=0.0218
============================================================


📊 Round 81 Test Metrics:
   Loss: 0.0863, RMSE: 0.2938, MAE: 0.2589, R²: -0.0035

============================================================
🔄 Round 83 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 83 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2831, R²=0.0207
   Val:   Loss=0.0824, RMSE=0.2871, R²=0.0147
============================================================


============================================================
🔄 Round 84 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0783, val=0.0895 (↓), lr=0.000001
   • Epoch   2/100: train=0.0783, val=0.0895, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0783, val=0.0895, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0783, val=0.0895, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0783, val=0.0895, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0782, val=0.0895, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0895)

============================================================
📊 Round 84 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2800, R²=0.0242
   Val:   Loss=0.0895, RMSE=0.2992, R²=0.0043
============================================================


📊 Round 84 Test Metrics:
   Loss: 0.0863, RMSE: 0.2937, MAE: 0.2589, R²: -0.0035

📊 Round 84 Test Metrics:
   Loss: 0.0863, RMSE: 0.2937, MAE: 0.2589, R²: -0.0035

📊 Round 84 Test Metrics:
   Loss: 0.0863, RMSE: 0.2937, MAE: 0.2589, R²: -0.0035

📊 Round 84 Test Metrics:
   Loss: 0.0863, RMSE: 0.2937, MAE: 0.2589, R²: -0.0034

📊 Round 84 Test Metrics:
   Loss: 0.0863, RMSE: 0.2937, MAE: 0.2589, R²: -0.0034

============================================================
🔄 Round 92 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 92 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2818, R²=0.0191
   Val:   Loss=0.0855, RMSE=0.2924, R²=0.0159
============================================================


📊 Round 92 Test Metrics:
   Loss: 0.0863, RMSE: 0.2937, MAE: 0.2589, R²: -0.0033

============================================================
🔄 Round 95 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 95 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=0.0262
   Val:   Loss=0.0816, RMSE=0.2857, R²=-0.0161
============================================================


📊 Round 95 Test Metrics:
   Loss: 0.0863, RMSE: 0.2937, MAE: 0.2589, R²: -0.0033

============================================================
🔄 Round 97 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0746 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0746, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0745, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0745, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0745, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0745, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0746)

============================================================
📊 Round 97 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=0.0194
   Val:   Loss=0.0746, RMSE=0.2731, R²=0.0212
============================================================


============================================================
🔄 Round 98 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 98 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=0.0232
   Val:   Loss=0.0795, RMSE=0.2820, R²=0.0044
============================================================


📊 Round 98 Test Metrics:
   Loss: 0.0863, RMSE: 0.2937, MAE: 0.2589, R²: -0.0032

============================================================
🔄 Round 100 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0873 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0873, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0873, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0873, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0873, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0873, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0873)

============================================================
📊 Round 100 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2809, R²=0.0274
   Val:   Loss=0.0873, RMSE=0.2955, R²=-0.0118
============================================================


============================================================
🔄 Round 102 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 102 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2845, R²=0.0216
   Val:   Loss=0.0791, RMSE=0.2813, R²=-0.0221
============================================================


📊 Round 102 Test Metrics:
   Loss: 0.0863, RMSE: 0.2937, MAE: 0.2589, R²: -0.0032

============================================================
🔄 Round 103 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 103 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=0.0181
   Val:   Loss=0.0827, RMSE=0.2875, R²=0.0279
============================================================


📊 Round 103 Test Metrics:
   Loss: 0.0863, RMSE: 0.2937, MAE: 0.2589, R²: -0.0031

📊 Round 103 Test Metrics:
   Loss: 0.0863, RMSE: 0.2937, MAE: 0.2589, R²: -0.0031

📊 Round 103 Test Metrics:
   Loss: 0.0863, RMSE: 0.2937, MAE: 0.2588, R²: -0.0031

📊 Round 103 Test Metrics:
   Loss: 0.0863, RMSE: 0.2937, MAE: 0.2588, R²: -0.0031

============================================================
🔄 Round 108 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0782, val=0.0898 (↓), lr=0.000001
   • Epoch   2/100: train=0.0782, val=0.0898, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0782, val=0.0898, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0782, val=0.0898, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0782, val=0.0898, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0781, val=0.0897, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0898)

============================================================
📊 Round 108 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0783, RMSE=0.2798, R²=0.0224
   Val:   Loss=0.0898, RMSE=0.2997, R²=0.0124
============================================================


============================================================
🔄 Round 110 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 110 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=0.0192
   Val:   Loss=0.0781, RMSE=0.2795, R²=0.0243
============================================================


============================================================
🔄 Round 111 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0739 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0738, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0738, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0738, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0738, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0738, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0739)

============================================================
📊 Round 111 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2868, R²=0.0173
   Val:   Loss=0.0739, RMSE=0.2718, R²=0.0323
============================================================


📊 Round 111 Test Metrics:
   Loss: 0.0863, RMSE: 0.2937, MAE: 0.2588, R²: -0.0031

============================================================
🔄 Round 115 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 115 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2821, R²=0.0149
   Val:   Loss=0.0845, RMSE=0.2907, R²=0.0380
============================================================


📊 Round 115 Test Metrics:
   Loss: 0.0862, RMSE: 0.2937, MAE: 0.2588, R²: -0.0030

📊 Round 115 Test Metrics:
   Loss: 0.0862, RMSE: 0.2937, MAE: 0.2588, R²: -0.0029

============================================================
🔄 Round 117 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0748 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0748, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0748, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0748, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0747, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0747, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0748)

============================================================
📊 Round 117 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=0.0219
   Val:   Loss=0.0748, RMSE=0.2735, R²=0.0128
============================================================


============================================================
🔄 Round 118 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0865 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0865, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0865, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0865, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0865, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0865)

============================================================
📊 Round 118 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2812, R²=0.0186
   Val:   Loss=0.0865, RMSE=0.2941, R²=0.0120
============================================================


============================================================
🔄 Round 119 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 119 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=0.0209
   Val:   Loss=0.0796, RMSE=0.2821, R²=0.0010
============================================================


============================================================
🔄 Round 120 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0769 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0769, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0769, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0769, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0769, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0768, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0769)

============================================================
📊 Round 120 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=0.0129
   Val:   Loss=0.0769, RMSE=0.2773, R²=0.0369
============================================================


📊 Round 120 Test Metrics:
   Loss: 0.0862, RMSE: 0.2936, MAE: 0.2588, R²: -0.0028

============================================================
🔄 Round 122 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 122 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2817, R²=0.0204
   Val:   Loss=0.0855, RMSE=0.2924, R²=0.0156
============================================================


📊 Round 122 Test Metrics:
   Loss: 0.0862, RMSE: 0.2936, MAE: 0.2588, R²: -0.0028

📊 Round 122 Test Metrics:
   Loss: 0.0862, RMSE: 0.2936, MAE: 0.2588, R²: -0.0028

============================================================
🔄 Round 129 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0750 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0750, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0750, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0750, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0750, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0749, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0750)

============================================================
📊 Round 129 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2863, R²=0.0165
   Val:   Loss=0.0750, RMSE=0.2739, R²=0.0367
============================================================


============================================================
🔄 Round 132 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0864, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0864, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 132 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2813, R²=0.0270
   Val:   Loss=0.0864, RMSE=0.2939, R²=-0.0214
============================================================


============================================================
🔄 Round 134 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0741 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0741, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0741, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0741, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0741, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0740, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0741)

============================================================
📊 Round 134 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2866, R²=0.0197
   Val:   Loss=0.0741, RMSE=0.2722, R²=0.0217
============================================================


📊 Round 134 Test Metrics:
   Loss: 0.0862, RMSE: 0.2936, MAE: 0.2588, R²: -0.0028

============================================================
🔄 Round 136 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 136 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2838, R²=0.0140
   Val:   Loss=0.0806, RMSE=0.2838, R²=0.0431
============================================================


📊 Round 136 Test Metrics:
   Loss: 0.0862, RMSE: 0.2937, MAE: 0.2588, R²: -0.0029

============================================================
🔄 Round 137 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 137 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=0.0212
   Val:   Loss=0.0793, RMSE=0.2815, R²=0.0132
============================================================


============================================================
🔄 Round 139 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0782, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 139 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=0.0194
   Val:   Loss=0.0783, RMSE=0.2798, R²=0.0257
============================================================


📊 Round 139 Test Metrics:
   Loss: 0.0862, RMSE: 0.2936, MAE: 0.2588, R²: -0.0028

============================================================
🔄 Round 140 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0755 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0755, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0755, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0755, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0755, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0755, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0755)

============================================================
📊 Round 140 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=0.0211
   Val:   Loss=0.0755, RMSE=0.2748, R²=0.0074
============================================================


============================================================
🔄 Round 142 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0767 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0767, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0767, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0767, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0767, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0766, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0767)

============================================================
📊 Round 142 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=0.0175
   Val:   Loss=0.0767, RMSE=0.2770, R²=0.0299
============================================================


📊 Round 142 Test Metrics:
   Loss: 0.0862, RMSE: 0.2936, MAE: 0.2588, R²: -0.0027

============================================================
🔄 Round 144 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 144 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2829, R²=0.0214
   Val:   Loss=0.0827, RMSE=0.2876, R²=0.0131
============================================================


📊 Round 144 Test Metrics:
   Loss: 0.0862, RMSE: 0.2936, MAE: 0.2588, R²: -0.0027

============================================================
🔄 Round 146 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 146 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2822, R²=0.0170
   Val:   Loss=0.0843, RMSE=0.2903, R²=0.0300
============================================================


📊 Round 146 Test Metrics:
   Loss: 0.0862, RMSE: 0.2936, MAE: 0.2588, R²: -0.0026

📊 Round 146 Test Metrics:
   Loss: 0.0862, RMSE: 0.2936, MAE: 0.2588, R²: -0.0026

📊 Round 146 Test Metrics:
   Loss: 0.0862, RMSE: 0.2936, MAE: 0.2588, R²: -0.0025

📊 Round 146 Test Metrics:
   Loss: 0.0862, RMSE: 0.2936, MAE: 0.2588, R²: -0.0026

============================================================
🔄 Round 151 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 151 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=0.0181
   Val:   Loss=0.0808, RMSE=0.2842, R²=0.0273
============================================================


📊 Round 151 Test Metrics:
   Loss: 0.0862, RMSE: 0.2936, MAE: 0.2588, R²: -0.0025

============================================================
🔄 Round 153 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 153 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2845, R²=0.0195
   Val:   Loss=0.0789, RMSE=0.2809, R²=0.0178
============================================================


============================================================
🔄 Round 154 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0776 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0776, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0776, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0776, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0776, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0777, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 154 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=0.0139
   Val:   Loss=0.0776, RMSE=0.2785, R²=0.0263
============================================================


📊 Round 154 Test Metrics:
   Loss: 0.0862, RMSE: 0.2936, MAE: 0.2587, R²: -0.0024

📊 Round 154 Test Metrics:
   Loss: 0.0862, RMSE: 0.2936, MAE: 0.2587, R²: -0.0024

📊 Round 154 Test Metrics:
   Loss: 0.0862, RMSE: 0.2936, MAE: 0.2587, R²: -0.0024

============================================================
🔄 Round 158 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 158 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2847, R²=0.0257
   Val:   Loss=0.0785, RMSE=0.2802, R²=-0.0186
============================================================


📊 Round 158 Test Metrics:
   Loss: 0.0862, RMSE: 0.2936, MAE: 0.2587, R²: -0.0024

📊 Round 158 Test Metrics:
   Loss: 0.0862, RMSE: 0.2936, MAE: 0.2587, R²: -0.0024

============================================================
🔄 Round 162 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0759 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0759, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0759, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0759, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0759, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0760, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0759)

============================================================
📊 Round 162 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=0.0175
   Val:   Loss=0.0759, RMSE=0.2755, R²=0.0165
============================================================


📊 Round 162 Test Metrics:
   Loss: 0.0862, RMSE: 0.2936, MAE: 0.2587, R²: -0.0023

📊 Round 162 Test Metrics:
   Loss: 0.0862, RMSE: 0.2936, MAE: 0.2587, R²: -0.0023

📊 Round 162 Test Metrics:
   Loss: 0.0862, RMSE: 0.2936, MAE: 0.2587, R²: -0.0023

============================================================
🔄 Round 167 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0877 (↓), lr=0.000001
   • Epoch   2/100: train=0.0785, val=0.0877, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0785, val=0.0877, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0785, val=0.0877, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0785, val=0.0877, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0876, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0877)

============================================================
📊 Round 167 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2806, R²=0.0247
   Val:   Loss=0.0877, RMSE=0.2961, R²=0.0009
============================================================


============================================================
🔄 Round 169 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 169 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=0.0233
   Val:   Loss=0.0838, RMSE=0.2895, R²=0.0070
============================================================


============================================================
🔄 Round 171 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 171 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2847, R²=0.0232
   Val:   Loss=0.0784, RMSE=0.2799, R²=0.0099
============================================================


============================================================
🔄 Round 172 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 172 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=0.0301
   Val:   Loss=0.0839, RMSE=0.2896, R²=-0.0167
============================================================


============================================================
🔄 Round 173 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0781, val=0.0894 (↓), lr=0.000001
   • Epoch   2/100: train=0.0781, val=0.0894, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0781, val=0.0894, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0781, val=0.0894, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0781, val=0.0894, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0780, val=0.0894, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0894)

============================================================
📊 Round 173 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0783, RMSE=0.2798, R²=0.0195
   Val:   Loss=0.0894, RMSE=0.2991, R²=0.0270
============================================================


============================================================
🔄 Round 174 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0876 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0876, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0876, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0876, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0876, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0876, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0876)

============================================================
📊 Round 174 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2806, R²=0.0358
   Val:   Loss=0.0876, RMSE=0.2960, R²=-0.0451
============================================================


============================================================
🔄 Round 175 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 175 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2815, R²=0.0198
   Val:   Loss=0.0855, RMSE=0.2923, R²=0.0263
============================================================


📊 Round 175 Test Metrics:
   Loss: 0.0862, RMSE: 0.2935, MAE: 0.2587, R²: -0.0021

============================================================
🔄 Round 176 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0871 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0871, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0871, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0871, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0871, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0870, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0871)

============================================================
📊 Round 176 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2808, R²=0.0206
   Val:   Loss=0.0871, RMSE=0.2951, R²=0.0227
============================================================


📊 Round 176 Test Metrics:
   Loss: 0.0862, RMSE: 0.2935, MAE: 0.2587, R²: -0.0021

============================================================
🔄 Round 178 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 178 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=0.0275
   Val:   Loss=0.0826, RMSE=0.2874, R²=-0.0113
============================================================


📊 Round 178 Test Metrics:
   Loss: 0.0862, RMSE: 0.2935, MAE: 0.2587, R²: -0.0020

============================================================
🔄 Round 179 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0864, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 179 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2811, R²=0.0234
   Val:   Loss=0.0864, RMSE=0.2940, R²=0.0134
============================================================


📊 Round 179 Test Metrics:
   Loss: 0.0862, RMSE: 0.2935, MAE: 0.2587, R²: -0.0021

============================================================
🔄 Round 180 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 180 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2812, R²=0.0236
   Val:   Loss=0.0862, RMSE=0.2937, R²=0.0059
============================================================


📊 Round 180 Test Metrics:
   Loss: 0.0862, RMSE: 0.2935, MAE: 0.2587, R²: -0.0021

============================================================
🔄 Round 181 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0782, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 181 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2847, R²=0.0160
   Val:   Loss=0.0782, RMSE=0.2797, R²=0.0292
============================================================


📊 Round 181 Test Metrics:
   Loss: 0.0862, RMSE: 0.2935, MAE: 0.2587, R²: -0.0021

📊 Round 181 Test Metrics:
   Loss: 0.0862, RMSE: 0.2935, MAE: 0.2587, R²: -0.0020

📊 Round 181 Test Metrics:
   Loss: 0.0862, RMSE: 0.2935, MAE: 0.2587, R²: -0.0021

============================================================
🔄 Round 186 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 186 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2836, R²=0.0283
   Val:   Loss=0.0806, RMSE=0.2839, R²=-0.0128
============================================================


📊 Round 186 Test Metrics:
   Loss: 0.0862, RMSE: 0.2935, MAE: 0.2587, R²: -0.0021

============================================================
🔄 Round 188 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 188 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=0.0169
   Val:   Loss=0.0789, RMSE=0.2809, R²=0.0398
============================================================


📊 Round 188 Test Metrics:
   Loss: 0.0862, RMSE: 0.2935, MAE: 0.2587, R²: -0.0021

============================================================
🔄 Round 189 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0868 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0868, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0868, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0868, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0868, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0867, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0868)

============================================================
📊 Round 189 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2809, R²=0.0199
   Val:   Loss=0.0868, RMSE=0.2946, R²=0.0249
============================================================


📊 Round 189 Test Metrics:
   Loss: 0.0862, RMSE: 0.2935, MAE: 0.2587, R²: -0.0020

============================================================
🔄 Round 197 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0695 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0695, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0695, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0695, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0695, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0694, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0695)

============================================================
📊 Round 197 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=0.0238
   Val:   Loss=0.0695, RMSE=0.2637, R²=0.0072
============================================================


📊 Round 197 Test Metrics:
   Loss: 0.0861, RMSE: 0.2935, MAE: 0.2587, R²: -0.0019

============================================================
🔄 Round 200 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0773, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 200 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=0.0116
   Val:   Loss=0.0773, RMSE=0.2781, R²=0.0540
============================================================


============================================================
🔄 Round 201 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 201 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=0.0150
   Val:   Loss=0.0827, RMSE=0.2875, R²=0.0456
============================================================


============================================================
🔄 Round 202 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0869 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0869, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0869, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0869, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0869, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0868, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 202 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2808, R²=0.0116
   Val:   Loss=0.0869, RMSE=0.2948, R²=0.0563
============================================================


📊 Round 202 Test Metrics:
   Loss: 0.0861, RMSE: 0.2935, MAE: 0.2586, R²: -0.0018

📊 Round 202 Test Metrics:
   Loss: 0.0861, RMSE: 0.2935, MAE: 0.2586, R²: -0.0019

============================================================
🔄 Round 208 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 208 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=0.0143
   Val:   Loss=0.0829, RMSE=0.2880, R²=0.0499
============================================================


============================================================
🔄 Round 209 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 209 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=0.0314
   Val:   Loss=0.0787, RMSE=0.2805, R²=-0.0202
============================================================


📊 Round 209 Test Metrics:
   Loss: 0.0861, RMSE: 0.2935, MAE: 0.2586, R²: -0.0017

============================================================
🔄 Round 216 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 216 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=0.0225
   Val:   Loss=0.0790, RMSE=0.2811, R²=-0.0188
============================================================


📊 Round 216 Test Metrics:
   Loss: 0.0861, RMSE: 0.2935, MAE: 0.2586, R²: -0.0017

============================================================
🔄 Round 217 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0770 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0770, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0770, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0769, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0769, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0768, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0770)

============================================================
📊 Round 217 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=0.0263
   Val:   Loss=0.0770, RMSE=0.2775, R²=-0.0019
============================================================


📊 Round 217 Test Metrics:
   Loss: 0.0861, RMSE: 0.2935, MAE: 0.2586, R²: -0.0016

📊 Round 217 Test Metrics:
   Loss: 0.0861, RMSE: 0.2935, MAE: 0.2586, R²: -0.0016

============================================================
🔄 Round 223 - Client client_26
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 223 Summary - Client client_26
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2814, R²=0.0123
   Val:   Loss=0.0855, RMSE=0.2924, R²=0.0296
============================================================


❌ Client client_26 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8687 {grpc_message:"Socket closed", grpc_status:14}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8687 {grpc_message:"Socket closed", grpc_status:14}"
>
