[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6e6c2a4b-c985-4e00-a908-501d4cebdc32
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3a806af1-e5e9-452d-8b99-f91f4305be92
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ff8f43fd-62f9-48a4-811b-d0177a5204e0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4a110796-e0f6-4721-81e4-8d6dfc4e9661
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 96cedd73-1d82-4491-b456-f2b5db3ac5df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8296b8c8-2772-4216-9aad-f9b3346fd6c6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9f61287b-4ca9-4d6c-9c81-122088f4971e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4c7e4270-f871-4da1-a5b2-49855db59fb3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 34121da7-e46a-4c60-b436-6680b98f2075
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fe1236be-4203-4c03-b784-830c2dacd848
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a6fb57a8-487b-4c7a-94eb-39a0fb90d391
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 61831139-8495-44a3-9877-2e53f325ced8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c0d78297-9af8-4461-ad5b-2df6db9b2499
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ebe61caf-8b6a-40c0-bb1a-32e137d666ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 09a6454b-cfbb-480f-9d99-a6fbbb0b55cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d01a86b9-d3ec-4664-af9b-159815a098a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6d721116-8a62-4f7f-8b7a-575518074e38
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3b0a5155-7fbb-4280-9331-72ad0c0f90c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ed88fd7d-0b26-4d91-8be6-3921d8b23ce2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1df8013d-c060-445a-bea5-371bd287b164
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message db8b4e38-708f-40c5-a30d-1ebbf3ee83e6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 907d30e7-ccd1-4859-8223-9f639e34d9c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message df15f8d2-95a5-4f59-9c08-fb1f7bc91737
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 639320d0-fbd7-4f09-ac9f-a252cc196ae1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c5be1142-d830-4dad-8a8f-751da121564a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c1c25dea-67b3-40b6-adb0-e48d2c75279f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6a19bc06-2c18-4abc-abf3-8a6b4c7c8371
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 34185529-0005-436e-9b24-50a86f4d48a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 56a9af56-cf60-4b05-904d-c0e34d83c044
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 33929239-0f48-498d-b163-53699865aeba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 72efc204-faf4-44e2-9935-0cb8f1e4946d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8c51a824-737b-4004-ba36-11b707b6e740
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 97d17fb2-13ef-4400-9f81-d720ac0a8955
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 869be0f3-747b-4b52-a94a-fdbec50d4c59
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 325606b5-e9be-4e4d-8a80-dd35529d8465
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 72aebaef-c6f2-4ba2-b92d-d45bba134461
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4fa5acb9-ce49-41da-a9a5-4f3ffd044fd7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d0575fc4-6dbd-43f1-9611-e01e0ff04f02
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 174e9b5e-33ce-4aef-993d-f61d1ec21f05
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 48f57523-2692-4c53-a627-f89a5f66bced
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message db9dd904-220b-49a7-8283-00c36f924158
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2debbdb6-8f03-4aad-aa95-76a2a94c66a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message db9cfb7a-c111-4baf-9b22-f5ba9b1c38cb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1412becf-67bd-496e-bf06-86b80f0fade9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6caeb178-bb5d-4896-9707-061842399b8c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 615b340e-a01e-4010-85c8-d864eb692c12
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0c1637c9-7936-4a27-8209-0adbea5f8525
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 09811dd5-5fca-4e57-af36-f1a75ecb4fe1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9a826207-e7e7-4a85-85f8-659024812614
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 27fc292f-d442-44e1-9c4b-e4d534dd8141
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 98c26a1d-dde3-4939-b57f-82c63439ee31
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c9025c1d-a603-403b-9f20-929f6008b394
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c1d6ff30-d9bf-4de2-9995-eaae72ef4469
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2133f7d1-0b6b-425b-ada4-64df16b72fc4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 72aa32b2-522b-49d5-992d-10cce5539b47
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aaf4003d-16b9-4a19-98db-fa34b4937bb4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5c34cc07-f34f-423e-97b2-9c493085677c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fad1a186-1e8b-496c-841a-83b73417f24d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d4acdabd-1b9e-4aba-ad07-65858444b959
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e14db4d2-d24a-415e-a6ab-7d43c02412af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c36a185e-bd6b-43b9-a80b-c4b3882b6f18
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 89338d12-cf12-4fba-b372-a144ec85bba2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f7d2f68c-cf2e-4e3d-a39c-ae6f0ecb03b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 75124b3a-11f1-4169-8c77-12fa0459c183
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bfb52721-6361-4fd5-8e42-6119ce723bd9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 47cff3c8-623d-4fa3-a43a-8573088b8efe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 56a1200d-10dc-4ce5-a4d5-975d4dd37216
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4beff45e-876d-422c-9b67-f6ebb92fd1d1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7e16a963-336c-4f9f-9ab6-d8373b4acd3c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fd593c37-15ea-477e-b573-e8fb6d37eaae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7ffcf6ed-64bf-47dd-bf4f-c75d54bae289
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e673a506-eb03-489c-b8d7-67ce32d7dfa7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7a5d19fe-e940-4623-8928-eddb7d4ef8c7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6bca4b9a-8ece-4cad-9563-f350df51753d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 56c89ebc-215f-49f6-af41-96f2e76064c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 71e9a8d2-da98-4528-b765-d19c1dadcc85
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eccbbab3-b28b-4f24-9d07-a7c3c3e8f01e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3e1d0e6e-bc72-4d81-8bb3-e4fcb3069509
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5ff9fc9e-2f87-426b-a9c2-4a2f98eb636a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4fc89a5e-f2a5-488d-8751-9a7b24ddcf22
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 638f4db6-a9b9-4d1a-a15d-3a490c65f016
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 70a978f3-444b-4559-bd7b-6fc314fcb15e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8c501cfd-e267-45d2-9991-d4df90cb79dd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8e5d6841-6b89-4c57-b1ec-1ac28101b298
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message adfc9196-6a27-49eb-b84b-05092718a6df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 160ab488-d84a-4bd8-b645-f0ec28410e1c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1fef130d-6e4a-4746-a20c-5a3a92734d01
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a647ee3a-f3a8-421b-b885-a660a1096319
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8a441c41-a28b-49f5-b7bc-e4301a446e33
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5be4d0d6-bd15-44ce-b331-1284da2ddc90
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8b282f9d-488e-4bd3-a6c8-e0f8cfc09ace
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 348881f3-9ef7-43eb-b1ba-1c231cf407ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2df37544-64b8-4fa6-aeb4-af547f0297d9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2f66fe4d-0373-4b05-b8d0-e1a4eba11ab2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 48124ceb-4107-4b83-a621-55f94d4a9a01
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 23490beb-07cf-446f-920b-b5061b512dd5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message de2e5ca2-00ac-45ce-8773-bb4363608ecb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ace8bbb9-7985-4020-bcc7-e6a85dab0a73
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 813e69d2-a262-4c94-b0a1-22774f1446cd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f76343bd-7da8-4757-914f-5c2d586e4b84
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 60b66b9d-d056-4895-8b73-bb58be40f8f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ae1bb18a-15c8-4f3e-b627-34a6f75f49a3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5d3a38bf-b4f4-40d9-a892-36dc4fa1d559
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 423b8e75-3741-468e-be4b-3992f0988902
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 65d063e8-41f2-4586-8de1-30bf240c679a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4fe36a2d-6e3c-488b-af6f-046d55d65e39
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c41584ef-a943-497c-bfe1-aac4da79e03e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 78672708-5b8a-45e1-8315-7e1ddf754216
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d7965f87-eea4-4d8a-b47c-e6441be28cf8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7c85cc94-15c8-4555-b233-44520dfbfaa4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9bc4188b-06c3-44a0-b745-b742e8415227
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6e9e4119-3b4d-4e60-942e-f463bdf3956f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 03c3c67d-f223-4e84-9c85-822b5921dbbc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 067c818c-de81-4a06-9887-93e760f3fa0e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 95293345-77be-4e91-8c90-20b58397e2e2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1dace2b8-b9e0-4b93-9892-2488a45a987f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 25f6b219-0acf-47e9-8727-fc642be84d82
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ddd0b7ba-bdce-41e6-9f04-06cf62ea5350
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 18e704cf-6efa-4cdf-95e9-a47018c799f9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d5ba729a-0d75-4387-b197-81764257eac0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 54897832-61c5-4ead-af12-d062fc9d331a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 655a442c-012b-4fe8-9bfa-bbd3dd9205c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c897884d-ab65-4ed5-a532-53a6d71332a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c6ba7998-f584-4579-893c-88179aa87e3e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2aa3ebe8-d5d6-4742-9cb4-53ca63d464ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6eddc925-b713-47dc-b790-5602feb02c15
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9ee0cfcf-742b-48f1-9b82-6011e1f88add
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 980392e2-fb9b-4ca3-8c2e-acb0f6de7d5a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 52caf95c-bafa-4652-baff-edec0ef1d19f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7266a554-0631-4b4e-ae6e-3c86e86d9c0a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bbe05d1b-e5a5-4ec1-855c-2f534d44e413
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b6acf95a-bd04-496c-aa0c-9ab63fcb54ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 88441897-e455-408b-b0c0-d0a6bdd749b0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0a58a92c-ac80-4d13-bdb0-138a1c4a093b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4d46a59b-fc2b-4743-b836-d2412166fb5a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ee066553-751d-4d3d-8fef-6e13179e7308
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1354fe74-dcdb-4077-aa67-a899ad1d9575
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 99feae22-619e-49bb-b520-e7ea6c4398c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d3f171b8-ba5d-4191-8648-ab2e08aa9694
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e91679e6-3cde-4ffe-a98d-f0b089fd2986
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8f29325a-23d8-4dd0-aea6-6e53b2b33c6f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cc529e94-d3c3-4706-979a-c8fdad5b02ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 583cd065-74c1-4267-bc1a-592fe0b90195
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 164eb704-1dfe-4a26-87c1-66d0a58de97c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7fb03df2-dff5-4cfd-a15a-3aa66b23f171
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fcb98912-6d6e-4b15-bbc3-87b3c7cde7c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 16c96660-76e1-4b8e-8009-7ec60a1e82b7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8ff3b2ef-f50a-4d00-b2be-77fd76ef95fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ec3b6894-b7d4-43dd-b3bd-25d0c9e20a67
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4c6cb333-8361-484d-a472-b554aed457c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 48eef00a-60e5-4c88-9b1f-a3896d5bed7a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0f605dbf-e064-4e88-8b7a-8699d073d6e2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a9a4e8b2-07eb-4169-91cf-e6d000c3a769
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2d06b058-848f-440e-818e-532610492a7a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4820ad78-db34-461d-a5f4-7baea62ffc4f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6e5d297c-87ea-4065-8e9d-56677b739ff8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 555a1930-98ed-4f7d-aa48-044edbb44712
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message edd1c02c-9dc3-4d3d-8547-965173512701
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b3b396c5-e3a6-4bff-b697-fca5ba41979c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ab2db3fd-c521-4f00-ab5e-1221111c1ce5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9f71bed4-8d0f-4287-abd7-99674962cbcc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2d3c0530-74d1-4dd9-b98a-7469dc772808
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e3b7cfb8-117c-41b4-bdd1-0d4fce1b7d55
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ae8cccd1-736b-4818-ae70-fae8311364dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message da5337b2-d1ef-4faa-ab4e-494cf50c871d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d14cd27c-f31e-4e61-a320-d3eef0bdc0ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c12fdf8e-418c-43c1-bfe6-fc6753b19e80
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4ec41940-c45c-4ab9-8f45-59ad96596974
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ec275d41-d9cb-4ea1-90d9-68421ca4c5e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3d28396b-d4e6-40a3-84c7-8e8cbc53bde4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 207e5136-10f6-4618-b0e4-e265b362ed80
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2cccceea-737d-43e0-ba53-2c5b6bc6be97
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 684c55fa-6159-4e05-a701-1a2d8c9f8809
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 04f5aa40-eabc-4772-ba08-1cf7dcdd52e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 84cbf926-3d9d-475b-9ff4-d850e7c63c4b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b4d1f8b9-d69d-4ced-bb87-e0b61dae861e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 894baa5c-3735-4591-8c04-bcb7078d6147
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8687 {grpc_message:"Socket closed", grpc_status:14}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_27
Server: localhost:8687
Algorithm: FEDAVG
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_27
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_27/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_27/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_27/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_27/test_labels.txt

📊 Raw data loaded:
   Train: X=(999, 24), y=(999,)
   Test:  X=(250, 24), y=(250,)

⚠️  Limiting training data: 999 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  241 samples, 5 features
✅ Client client_27 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

📊 Round 0 Test Metrics:
   Loss: 0.0916, RMSE: 0.3026, MAE: 0.2627, R²: -0.0286

============================================================
🔄 Round 6 - Client client_27
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0906 (↓), lr=0.001000
   ✓ Epoch   2/100: train=0.0778, val=0.0887 (↓), lr=0.001000
   • Epoch   3/100: train=0.0775, val=0.0891, patience=1/15, lr=0.001000
   • Epoch   4/100: train=0.0770, val=0.0897, patience=2/15, lr=0.001000
   • Epoch   5/100: train=0.0765, val=0.0895, patience=3/15, lr=0.001000
   📉 Epoch 8: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0729, val=0.0919, patience=9/15, lr=0.000500
   📉 Epoch 16: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0887)

============================================================
📊 Round 6 Summary - Client client_27
   Epochs: 17/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0767, RMSE=0.2769, R²=0.0390
   Val:   Loss=0.0887, RMSE=0.2978, R²=-0.0307
============================================================


============================================================
🔄 Round 7 - Client client_27
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0858 (↓), lr=0.000250
   • Epoch   2/100: train=0.0784, val=0.0860, patience=1/15, lr=0.000250
   • Epoch   3/100: train=0.0781, val=0.0863, patience=2/15, lr=0.000250
   • Epoch   4/100: train=0.0779, val=0.0864, patience=3/15, lr=0.000250
   • Epoch   5/100: train=0.0777, val=0.0864, patience=4/15, lr=0.000250
   📉 Epoch 7: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0769, val=0.0863, patience=10/15, lr=0.000125
   📉 Epoch 15: LR reduced 0.000125 → 0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 7 Summary - Client client_27
   Epochs: 16/100 (early stopped)
   LR: 0.000250 → 0.000063 (2 reductions)
   Train: Loss=0.0780, RMSE=0.2793, R²=0.0178
   Val:   Loss=0.0858, RMSE=0.2929, R²=0.0249
============================================================


============================================================
🔄 Round 11 - Client client_27
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0834 (↓), lr=0.000063
   • Epoch   2/100: train=0.0783, val=0.0837, patience=1/15, lr=0.000063
   • Epoch   3/100: train=0.0781, val=0.0839, patience=2/15, lr=0.000063
   • Epoch   4/100: train=0.0780, val=0.0841, patience=3/15, lr=0.000063
   • Epoch   5/100: train=0.0778, val=0.0843, patience=4/15, lr=0.000063
   📉 Epoch 7: LR reduced 0.000063 → 0.000031
   • Epoch  11/100: train=0.0774, val=0.0849, patience=10/15, lr=0.000031
   📉 Epoch 15: LR reduced 0.000031 → 0.000016

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 11 Summary - Client client_27
   Epochs: 16/100 (early stopped)
   LR: 0.000063 → 0.000016 (2 reductions)
   Train: Loss=0.0784, RMSE=0.2800, R²=0.0175
   Val:   Loss=0.0834, RMSE=0.2888, R²=0.0336
============================================================


📊 Round 11 Test Metrics:
   Loss: 0.0871, RMSE: 0.2951, MAE: 0.2573, R²: 0.0219

============================================================
🔄 Round 14 - Client client_27
   Epochs: 100, Batch: 32, LR: 0.000016
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0783, val=0.0838 (↓), lr=0.000016
   • Epoch   2/100: train=0.0783, val=0.0839, patience=1/15, lr=0.000016
   • Epoch   3/100: train=0.0782, val=0.0840, patience=2/15, lr=0.000016
   • Epoch   4/100: train=0.0782, val=0.0840, patience=3/15, lr=0.000016
   • Epoch   5/100: train=0.0781, val=0.0841, patience=4/15, lr=0.000016
   📉 Epoch 7: LR reduced 0.000016 → 0.000008
   • Epoch  11/100: train=0.0779, val=0.0843, patience=10/15, lr=0.000008
   📉 Epoch 15: LR reduced 0.000008 → 0.000004

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 14 Summary - Client client_27
   Epochs: 16/100 (early stopped)
   LR: 0.000016 → 0.000004 (2 reductions)
   Train: Loss=0.0783, RMSE=0.2799, R²=0.0220
   Val:   Loss=0.0838, RMSE=0.2895, R²=0.0113
============================================================


📊 Round 14 Test Metrics:
   Loss: 0.0867, RMSE: 0.2945, MAE: 0.2567, R²: 0.0256

============================================================
🔄 Round 18 - Client client_27
   Epochs: 100, Batch: 32, LR: 0.000004
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0775, val=0.0869 (↓), lr=0.000004
   • Epoch   2/100: train=0.0775, val=0.0869, patience=1/15, lr=0.000004
   • Epoch   3/100: train=0.0775, val=0.0869, patience=2/15, lr=0.000004
   • Epoch   4/100: train=0.0775, val=0.0869, patience=3/15, lr=0.000004
   • Epoch   5/100: train=0.0775, val=0.0869, patience=4/15, lr=0.000004
   📉 Epoch 7: LR reduced 0.000004 → 0.000002
   • Epoch  11/100: train=0.0774, val=0.0869, patience=10/15, lr=0.000002
   📉 Epoch 15: LR reduced 0.000002 → 0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 18 Summary - Client client_27
   Epochs: 16/100 (early stopped)
   LR: 0.000004 → 0.000001 (2 reductions)
   Train: Loss=0.0776, RMSE=0.2785, R²=0.0274
   Val:   Loss=0.0869, RMSE=0.2948, R²=-0.0067
============================================================


📊 Round 18 Test Metrics:
   Loss: 0.0867, RMSE: 0.2944, MAE: 0.2564, R²: 0.0265

============================================================
🔄 Round 22 - Client client_27
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0730 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0730, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0730, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0730, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0730, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0731, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0730)

============================================================
📊 Round 22 Summary - Client client_27
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=0.0146
   Val:   Loss=0.0730, RMSE=0.2702, R²=-0.0038
============================================================


📊 Round 22 Test Metrics:
   Loss: 0.0867, RMSE: 0.2944, MAE: 0.2564, R²: 0.0262

============================================================
🔄 Round 23 - Client client_27
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 23 Summary - Client client_27
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2815, R²=0.0206
   Val:   Loss=0.0805, RMSE=0.2837, R²=0.0180
============================================================


📊 Round 23 Test Metrics:
   Loss: 0.0867, RMSE: 0.2944, MAE: 0.2564, R²: 0.0263

============================================================
🔄 Round 24 - Client client_27
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0783, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0782, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0782, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0782, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0782, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0782, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 24 Summary - Client client_27
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0782, RMSE=0.2797, R²=0.0206
   Val:   Loss=0.0845, RMSE=0.2906, R²=0.0095
============================================================


============================================================
🔄 Round 25 - Client client_27
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0746 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0746, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0746, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0746, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0746, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0746, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0746)

============================================================
📊 Round 25 Summary - Client client_27
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=0.0088
   Val:   Loss=0.0746, RMSE=0.2732, R²=0.0640
============================================================


📊 Round 25 Test Metrics:
   Loss: 0.0867, RMSE: 0.2944, MAE: 0.2564, R²: 0.0261

📊 Round 25 Test Metrics:
   Loss: 0.0867, RMSE: 0.2945, MAE: 0.2564, R²: 0.0260

📊 Round 25 Test Metrics:
   Loss: 0.0867, RMSE: 0.2945, MAE: 0.2564, R²: 0.0260

============================================================
🔄 Round 29 - Client client_27
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 29 Summary - Client client_27
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2807, R²=0.0135
   Val:   Loss=0.0823, RMSE=0.2869, R²=0.0454
============================================================


📊 Round 29 Test Metrics:
   Loss: 0.0867, RMSE: 0.2945, MAE: 0.2564, R²: 0.0260

📊 Round 29 Test Metrics:
   Loss: 0.0867, RMSE: 0.2945, MAE: 0.2564, R²: 0.0261

============================================================
🔄 Round 32 - Client client_27
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0785, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0785, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0785, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0785, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0785, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 32 Summary - Client client_27
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2807, R²=0.0158
   Val:   Loss=0.0823, RMSE=0.2869, R²=0.0243
============================================================


📊 Round 32 Test Metrics:
   Loss: 0.0867, RMSE: 0.2945, MAE: 0.2564, R²: 0.0261

============================================================
🔄 Round 35 - Client client_27
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 35 Summary - Client client_27
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=0.0175
   Val:   Loss=0.0787, RMSE=0.2806, R²=0.0318
============================================================


============================================================
🔄 Round 36 - Client client_27
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0780 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0780, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0780, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 36 Summary - Client client_27
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2826, R²=0.0158
   Val:   Loss=0.0780, RMSE=0.2793, R²=0.0110
============================================================


📊 Round 36 Test Metrics:
   Loss: 0.0867, RMSE: 0.2945, MAE: 0.2564, R²: 0.0260

============================================================
🔄 Round 37 - Client client_27
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0768 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0768, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0768, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0768, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0768, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0768, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0768)

============================================================
📊 Round 37 Summary - Client client_27
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2831, R²=0.0252
   Val:   Loss=0.0768, RMSE=0.2771, R²=-0.0095
============================================================


============================================================
🔄 Round 38 - Client client_27
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0756 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0756, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0756, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0756, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0756, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0756, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0756)

============================================================
📊 Round 38 Summary - Client client_27
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=0.0197
   Val:   Loss=0.0756, RMSE=0.2750, R²=0.0218
============================================================


📊 Round 38 Test Metrics:
   Loss: 0.0867, RMSE: 0.2945, MAE: 0.2564, R²: 0.0261

============================================================
🔄 Round 39 - Client client_27
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0779, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0779, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0779, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0779, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0779, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0778, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 39 Summary - Client client_27
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0779, RMSE=0.2791, R²=0.0227
   Val:   Loss=0.0858, RMSE=0.2929, R²=0.0112
============================================================


📊 Round 39 Test Metrics:
   Loss: 0.0867, RMSE: 0.2945, MAE: 0.2564, R²: 0.0261

============================================================
🔄 Round 40 - Client client_27
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0783, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0783, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0782, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0782, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0782, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0782, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 40 Summary - Client client_27
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0783, RMSE=0.2798, R²=0.0130
   Val:   Loss=0.0844, RMSE=0.2905, R²=0.0469
============================================================


📊 Round 40 Test Metrics:
   Loss: 0.0867, RMSE: 0.2945, MAE: 0.2564, R²: 0.0261

📊 Round 40 Test Metrics:
   Loss: 0.0867, RMSE: 0.2945, MAE: 0.2564, R²: 0.0261

============================================================
🔄 Round 43 - Client client_27
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 43 Summary - Client client_27
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2815, R²=0.0220
   Val:   Loss=0.0804, RMSE=0.2836, R²=0.0131
============================================================


📊 Round 43 Test Metrics:
   Loss: 0.0867, RMSE: 0.2945, MAE: 0.2564, R²: 0.0261

============================================================
🔄 Round 44 - Client client_27
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0780 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0780, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0780, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0780, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0780, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 44 Summary - Client client_27
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2826, R²=0.0197
   Val:   Loss=0.0780, RMSE=0.2793, R²=0.0217
============================================================


📊 Round 44 Test Metrics:
   Loss: 0.0867, RMSE: 0.2945, MAE: 0.2564, R²: 0.0260

============================================================
🔄 Round 46 - Client client_27
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 46 Summary - Client client_27
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2808, R²=0.0289
   Val:   Loss=0.0822, RMSE=0.2866, R²=-0.0140
============================================================


📊 Round 46 Test Metrics:
   Loss: 0.0867, RMSE: 0.2945, MAE: 0.2564, R²: 0.0260

============================================================
🔄 Round 48 - Client client_27
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0779, val=0.0863 (↓), lr=0.000001
   • Epoch   2/100: train=0.0779, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0778, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0778, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0778, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0778, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 48 Summary - Client client_27
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0778, RMSE=0.2789, R²=0.0200
   Val:   Loss=0.0863, RMSE=0.2938, R²=0.0145
============================================================


📊 Round 48 Test Metrics:
   Loss: 0.0867, RMSE: 0.2945, MAE: 0.2564, R²: 0.0260

============================================================
🔄 Round 50 - Client client_27
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0780 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0780, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0780, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0779, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0779, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0779, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 50 Summary - Client client_27
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2826, R²=0.0219
   Val:   Loss=0.0780, RMSE=0.2792, R²=0.0104
============================================================


📊 Round 50 Test Metrics:
   Loss: 0.0867, RMSE: 0.2945, MAE: 0.2564, R²: 0.0260

📊 Round 50 Test Metrics:
   Loss: 0.0867, RMSE: 0.2945, MAE: 0.2564, R²: 0.0260

📊 Round 50 Test Metrics:
   Loss: 0.0867, RMSE: 0.2945, MAE: 0.2565, R²: 0.0259

============================================================
🔄 Round 54 - Client client_27
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0699 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0699, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0699, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0700, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0700, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0700, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0699)

============================================================
📊 Round 54 Summary - Client client_27
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2861, R²=0.0163
   Val:   Loss=0.0699, RMSE=0.2644, R²=0.0186
============================================================


📊 Round 54 Test Metrics:
   Loss: 0.0867, RMSE: 0.2945, MAE: 0.2565, R²: 0.0259

============================================================
🔄 Round 55 - Client client_27
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 55 Summary - Client client_27
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2809, R²=0.0246
   Val:   Loss=0.0819, RMSE=0.2861, R²=-0.0124
============================================================


============================================================
🔄 Round 56 - Client client_27
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0774, val=0.0877 (↓), lr=0.000001
   • Epoch   2/100: train=0.0774, val=0.0877, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0774, val=0.0876, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0774, val=0.0876, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0774, val=0.0876, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0774, val=0.0876, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0877)

============================================================
📊 Round 56 Summary - Client client_27
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0775, RMSE=0.2783, R²=0.0228
   Val:   Loss=0.0877, RMSE=0.2961, R²=0.0093
============================================================


📊 Round 56 Test Metrics:
   Loss: 0.0867, RMSE: 0.2945, MAE: 0.2565, R²: 0.0259

📊 Round 56 Test Metrics:
   Loss: 0.0867, RMSE: 0.2945, MAE: 0.2565, R²: 0.0258

📊 Round 56 Test Metrics:
   Loss: 0.0867, RMSE: 0.2945, MAE: 0.2565, R²: 0.0258

============================================================
🔄 Round 60 - Client client_27
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0779, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0779, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0779, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0779, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0779, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0778, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 60 Summary - Client client_27
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0779, RMSE=0.2791, R²=0.0222
   Val:   Loss=0.0858, RMSE=0.2930, R²=0.0121
============================================================


============================================================
🔄 Round 61 - Client client_27
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0681 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0681, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0681, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0681, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0681, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0681, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0681)

============================================================
📊 Round 61 Summary - Client client_27
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=0.0214
   Val:   Loss=0.0681, RMSE=0.2610, R²=0.0020
============================================================


============================================================
🔄 Round 63 - Client client_27
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0779, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0779, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0779, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0779, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0779, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0778, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 63 Summary - Client client_27
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0778, RMSE=0.2789, R²=0.0196
   Val:   Loss=0.0864, RMSE=0.2939, R²=0.0214
============================================================


============================================================
🔄 Round 65 - Client client_27
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0758 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0758, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0758, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0758, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0758, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0758, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0758)

============================================================
📊 Round 65 Summary - Client client_27
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=0.0245
   Val:   Loss=0.0758, RMSE=0.2753, R²=0.0015
============================================================


============================================================
🔄 Round 66 - Client client_27
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0777, val=0.0866 (↓), lr=0.000001
   • Epoch   2/100: train=0.0777, val=0.0866, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0777, val=0.0866, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0777, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0777, val=0.0867, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0776, val=0.0867, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0866)

============================================================
📊 Round 66 Summary - Client client_27
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0777, RMSE=0.2788, R²=0.0187
   Val:   Loss=0.0866, RMSE=0.2943, R²=0.0153
============================================================


📊 Round 66 Test Metrics:
   Loss: 0.0867, RMSE: 0.2945, MAE: 0.2565, R²: 0.0259

============================================================
🔄 Round 74 - Client client_27
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0783, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0783, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0783, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0783, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0783, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 74 Summary - Client client_27
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0783, RMSE=0.2799, R²=0.0179
   Val:   Loss=0.0842, RMSE=0.2902, R²=0.0269
============================================================


📊 Round 74 Test Metrics:
   Loss: 0.0867, RMSE: 0.2945, MAE: 0.2564, R²: 0.0259

============================================================
🔄 Round 78 - Client client_27
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 78 Summary - Client client_27
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=0.0167
   Val:   Loss=0.0787, RMSE=0.2806, R²=0.0330
============================================================


📊 Round 78 Test Metrics:
   Loss: 0.0867, RMSE: 0.2945, MAE: 0.2564, R²: 0.0259

============================================================
🔄 Round 81 - Client client_27
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 81 Summary - Client client_27
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2810, R²=0.0173
   Val:   Loss=0.0818, RMSE=0.2859, R²=0.0274
============================================================


📊 Round 81 Test Metrics:
   Loss: 0.0867, RMSE: 0.2945, MAE: 0.2565, R²: 0.0259

============================================================
🔄 Round 84 - Client client_27
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0752 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0751, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0751, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0751, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0751, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0751, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0752)

============================================================
📊 Round 84 Summary - Client client_27
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=0.0218
   Val:   Loss=0.0752, RMSE=0.2741, R²=0.0122
============================================================


============================================================
🔄 Round 85 - Client client_27
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0782, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0781, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0781, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0781, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0781, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0781, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 85 Summary - Client client_27
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2799, R²=0.0208
   Val:   Loss=0.0841, RMSE=0.2901, R²=0.0170
============================================================


📊 Round 85 Test Metrics:
   Loss: 0.0867, RMSE: 0.2945, MAE: 0.2565, R²: 0.0259

============================================================
🔄 Round 91 - Client client_27
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 91 Summary - Client client_27
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2824, R²=0.0183
   Val:   Loss=0.0786, RMSE=0.2803, R²=0.0264
============================================================


============================================================
🔄 Round 92 - Client client_27
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 92 Summary - Client client_27
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2808, R²=0.0225
   Val:   Loss=0.0822, RMSE=0.2867, R²=0.0101
============================================================


📊 Round 92 Test Metrics:
   Loss: 0.0867, RMSE: 0.2945, MAE: 0.2564, R²: 0.0259

📊 Round 92 Test Metrics:
   Loss: 0.0867, RMSE: 0.2945, MAE: 0.2565, R²: 0.0258

============================================================
🔄 Round 94 - Client client_27
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 94 Summary - Client client_27
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2818, R²=0.0119
   Val:   Loss=0.0800, RMSE=0.2828, R²=0.0499
============================================================


📊 Round 94 Test Metrics:
   Loss: 0.0867, RMSE: 0.2945, MAE: 0.2565, R²: 0.0258

📊 Round 94 Test Metrics:
   Loss: 0.0867, RMSE: 0.2945, MAE: 0.2565, R²: 0.0259

============================================================
🔄 Round 96 - Client client_27
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0773, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0773, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 96 Summary - Client client_27
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=0.0214
   Val:   Loss=0.0773, RMSE=0.2781, R²=0.0134
============================================================


📊 Round 96 Test Metrics:
   Loss: 0.0867, RMSE: 0.2945, MAE: 0.2565, R²: 0.0259

📊 Round 96 Test Metrics:
   Loss: 0.0867, RMSE: 0.2945, MAE: 0.2564, R²: 0.0259

============================================================
🔄 Round 99 - Client client_27
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0718 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0718, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0718, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0718, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0718, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0718, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0718)

============================================================
📊 Round 99 Summary - Client client_27
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2854, R²=0.0238
   Val:   Loss=0.0718, RMSE=0.2679, R²=0.0010
============================================================


============================================================
🔄 Round 100 - Client client_27
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0746 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0746, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0746, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0746, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0747, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0747, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0746)

============================================================
📊 Round 100 Summary - Client client_27
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=0.0226
   Val:   Loss=0.0746, RMSE=0.2732, R²=-0.0066
============================================================


📊 Round 100 Test Metrics:
   Loss: 0.0867, RMSE: 0.2945, MAE: 0.2564, R²: 0.0259

============================================================
🔄 Round 102 - Client client_27
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 102 Summary - Client client_27
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2817, R²=0.0172
   Val:   Loss=0.0803, RMSE=0.2834, R²=0.0300
============================================================


📊 Round 102 Test Metrics:
   Loss: 0.0867, RMSE: 0.2945, MAE: 0.2564, R²: 0.0259

📊 Round 102 Test Metrics:
   Loss: 0.0867, RMSE: 0.2945, MAE: 0.2564, R²: 0.0259

============================================================
🔄 Round 109 - Client client_27
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0698 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0698, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0698, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0698, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0698, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0698, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0698)

============================================================
📊 Round 109 Summary - Client client_27
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=0.0142
   Val:   Loss=0.0698, RMSE=0.2642, R²=0.0264
============================================================


============================================================
🔄 Round 110 - Client client_27
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0749 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0749, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0748, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0748, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0748, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0748, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0749)

============================================================
📊 Round 110 Summary - Client client_27
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=0.0175
   Val:   Loss=0.0749, RMSE=0.2736, R²=0.0289
============================================================


📊 Round 110 Test Metrics:
   Loss: 0.0867, RMSE: 0.2945, MAE: 0.2564, R²: 0.0259

============================================================
🔄 Round 114 - Client client_27
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0772 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0772, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0772, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0772, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0772, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 114 Summary - Client client_27
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2831, R²=0.0158
   Val:   Loss=0.0772, RMSE=0.2778, R²=0.0357
============================================================


📊 Round 114 Test Metrics:
   Loss: 0.0867, RMSE: 0.2945, MAE: 0.2564, R²: 0.0259

============================================================
🔄 Round 115 - Client client_27
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0754 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0754, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0754, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0754, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0754, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0754, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0754)

============================================================
📊 Round 115 Summary - Client client_27
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2838, R²=0.0286
   Val:   Loss=0.0754, RMSE=0.2746, R²=-0.0208
============================================================


📊 Round 115 Test Metrics:
   Loss: 0.0867, RMSE: 0.2945, MAE: 0.2564, R²: 0.0259

============================================================
🔄 Round 116 - Client client_27
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0720 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0720, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0720, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0720, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0720, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0720, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0720)

============================================================
📊 Round 116 Summary - Client client_27
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=0.0162
   Val:   Loss=0.0720, RMSE=0.2683, R²=0.0285
============================================================


📊 Round 116 Test Metrics:
   Loss: 0.0867, RMSE: 0.2945, MAE: 0.2564, R²: 0.0259

============================================================
🔄 Round 118 - Client client_27
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0782, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 118 Summary - Client client_27
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2826, R²=0.0156
   Val:   Loss=0.0782, RMSE=0.2797, R²=0.0256
============================================================


============================================================
🔄 Round 119 - Client client_27
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0764 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0764, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0764, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0764, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0764, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0764, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0764)

============================================================
📊 Round 119 Summary - Client client_27
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=0.0176
   Val:   Loss=0.0764, RMSE=0.2765, R²=0.0285
============================================================


============================================================
🔄 Round 122 - Client client_27
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 122 Summary - Client client_27
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2819, R²=0.0232
   Val:   Loss=0.0798, RMSE=0.2824, R²=0.0048
============================================================


📊 Round 122 Test Metrics:
   Loss: 0.0867, RMSE: 0.2945, MAE: 0.2564, R²: 0.0259

📊 Round 122 Test Metrics:
   Loss: 0.0867, RMSE: 0.2945, MAE: 0.2564, R²: 0.0259

============================================================
🔄 Round 124 - Client client_27
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0723 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0723, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0723, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0723, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0723, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0723, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0723)

============================================================
📊 Round 124 Summary - Client client_27
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2852, R²=0.0174
   Val:   Loss=0.0723, RMSE=0.2689, R²=0.0300
============================================================


📊 Round 124 Test Metrics:
   Loss: 0.0867, RMSE: 0.2945, MAE: 0.2564, R²: 0.0259

============================================================
🔄 Round 125 - Client client_27
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0707 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0707, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0707, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0707, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0707, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0707, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0707)

============================================================
📊 Round 125 Summary - Client client_27
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=0.0126
   Val:   Loss=0.0707, RMSE=0.2659, R²=0.0510
============================================================


📊 Round 125 Test Metrics:
   Loss: 0.0867, RMSE: 0.2945, MAE: 0.2564, R²: 0.0259

📊 Round 125 Test Metrics:
   Loss: 0.0867, RMSE: 0.2945, MAE: 0.2564, R²: 0.0259

============================================================
🔄 Round 127 - Client client_27
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 127 Summary - Client client_27
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2804, R²=0.0263
   Val:   Loss=0.0832, RMSE=0.2885, R²=-0.0070
============================================================


📊 Round 127 Test Metrics:
   Loss: 0.0867, RMSE: 0.2945, MAE: 0.2564, R²: 0.0258

============================================================
🔄 Round 130 - Client client_27
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0778, val=0.0876 (↓), lr=0.000001
   • Epoch   2/100: train=0.0778, val=0.0876, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0778, val=0.0876, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0778, val=0.0876, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0778, val=0.0876, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0778, val=0.0876, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0876)

============================================================
📊 Round 130 Summary - Client client_27
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0775, RMSE=0.2784, R²=0.0271
   Val:   Loss=0.0876, RMSE=0.2960, R²=-0.0099
============================================================


============================================================
🔄 Round 131 - Client client_27
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0783, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0783, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0783, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0783, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0783, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 131 Summary - Client client_27
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0783, RMSE=0.2799, R²=0.0161
   Val:   Loss=0.0845, RMSE=0.2906, R²=0.0328
============================================================


📊 Round 131 Test Metrics:
   Loss: 0.0867, RMSE: 0.2945, MAE: 0.2565, R²: 0.0257

============================================================
🔄 Round 132 - Client client_27
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 132 Summary - Client client_27
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2824, R²=0.0304
   Val:   Loss=0.0788, RMSE=0.2807, R²=-0.0272
============================================================


📊 Round 132 Test Metrics:
   Loss: 0.0867, RMSE: 0.2945, MAE: 0.2565, R²: 0.0257

============================================================
🔄 Round 136 - Client client_27
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0647 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0647, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0647, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0647, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0647, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0646, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0647)

============================================================
📊 Round 136 Summary - Client client_27
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=0.0148
   Val:   Loss=0.0647, RMSE=0.2543, R²=0.0441
============================================================


📊 Round 136 Test Metrics:
   Loss: 0.0867, RMSE: 0.2945, MAE: 0.2565, R²: 0.0256

📊 Round 136 Test Metrics:
   Loss: 0.0867, RMSE: 0.2945, MAE: 0.2565, R²: 0.0257

📊 Round 136 Test Metrics:
   Loss: 0.0867, RMSE: 0.2945, MAE: 0.2565, R²: 0.0257

📊 Round 136 Test Metrics:
   Loss: 0.0867, RMSE: 0.2945, MAE: 0.2565, R²: 0.0257

============================================================
🔄 Round 143 - Client client_27
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0782, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0781, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0781, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0781, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0781, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0781, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 143 Summary - Client client_27
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0782, RMSE=0.2797, R²=0.0250
   Val:   Loss=0.0848, RMSE=0.2912, R²=-0.0008
============================================================


📊 Round 143 Test Metrics:
   Loss: 0.0867, RMSE: 0.2945, MAE: 0.2565, R²: 0.0257

============================================================
🔄 Round 146 - Client client_27
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0744 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0744, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0744, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0744, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0744, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0744, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0744)

============================================================
📊 Round 146 Summary - Client client_27
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=0.0133
   Val:   Loss=0.0744, RMSE=0.2728, R²=0.0460
============================================================


📊 Round 146 Test Metrics:
   Loss: 0.0867, RMSE: 0.2945, MAE: 0.2565, R²: 0.0257

📊 Round 146 Test Metrics:
   Loss: 0.0867, RMSE: 0.2945, MAE: 0.2565, R²: 0.0257

============================================================
🔄 Round 149 - Client client_27
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0783, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0783, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0783, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0783, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0783, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 149 Summary - Client client_27
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2800, R²=0.0189
   Val:   Loss=0.0841, RMSE=0.2900, R²=0.0219
============================================================


============================================================
🔄 Round 151 - Client client_27
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0759 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0759, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0759, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0759, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0759, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0759, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0759)

============================================================
📊 Round 151 Summary - Client client_27
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=0.0249
   Val:   Loss=0.0759, RMSE=0.2755, R²=-0.0172
============================================================


📊 Round 151 Test Metrics:
   Loss: 0.0867, RMSE: 0.2945, MAE: 0.2565, R²: 0.0256

📊 Round 151 Test Metrics:
   Loss: 0.0867, RMSE: 0.2945, MAE: 0.2565, R²: 0.0256

============================================================
🔄 Round 155 - Client client_27
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 155 Summary - Client client_27
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2826, R²=0.0220
   Val:   Loss=0.0783, RMSE=0.2798, R²=0.0078
============================================================


📊 Round 155 Test Metrics:
   Loss: 0.0867, RMSE: 0.2945, MAE: 0.2565, R²: 0.0257

============================================================
🔄 Round 156 - Client client_27
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0765 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0765, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0765, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0765, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0765, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0765, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0765)

============================================================
📊 Round 156 Summary - Client client_27
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=0.0153
   Val:   Loss=0.0765, RMSE=0.2766, R²=0.0343
============================================================


============================================================
🔄 Round 159 - Client client_27
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0759 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0759, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0759, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0759, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0759, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0759, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0759)

============================================================
📊 Round 159 Summary - Client client_27
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=0.0240
   Val:   Loss=0.0759, RMSE=0.2755, R²=-0.0013
============================================================


============================================================
🔄 Round 160 - Client client_27
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0760 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0760, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0760, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0760, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0760, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0760, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0760)

============================================================
📊 Round 160 Summary - Client client_27
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2836, R²=0.0147
   Val:   Loss=0.0760, RMSE=0.2756, R²=0.0388
============================================================


============================================================
🔄 Round 161 - Client client_27
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0772, val=0.0880 (↓), lr=0.000001
   • Epoch   2/100: train=0.0772, val=0.0880, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0772, val=0.0880, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0772, val=0.0880, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0772, val=0.0880, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0772, val=0.0880, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0880)

============================================================
📊 Round 161 Summary - Client client_27
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0774, RMSE=0.2783, R²=0.0213
   Val:   Loss=0.0880, RMSE=0.2967, R²=0.0132
============================================================


📊 Round 161 Test Metrics:
   Loss: 0.0867, RMSE: 0.2945, MAE: 0.2565, R²: 0.0256

============================================================
🔄 Round 162 - Client client_27
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0757, val=0.0960 (↓), lr=0.000001
   • Epoch   2/100: train=0.0757, val=0.0960, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0757, val=0.0960, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0757, val=0.0959, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0757, val=0.0959, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0757, val=0.0959, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0960)

============================================================
📊 Round 162 Summary - Client client_27
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0755, RMSE=0.2747, R²=0.0310
   Val:   Loss=0.0960, RMSE=0.3098, R²=-0.0192
============================================================


============================================================
🔄 Round 164 - Client client_27
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 164 Summary - Client client_27
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2809, R²=0.0288
   Val:   Loss=0.0821, RMSE=0.2866, R²=-0.0255
============================================================


📊 Round 164 Test Metrics:
   Loss: 0.0868, RMSE: 0.2945, MAE: 0.2565, R²: 0.0255

📊 Round 164 Test Metrics:
   Loss: 0.0868, RMSE: 0.2945, MAE: 0.2565, R²: 0.0255

============================================================
🔄 Round 167 - Client client_27
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0727 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0727, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0727, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0727, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0728, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0728, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0727)

============================================================
📊 Round 167 Summary - Client client_27
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=0.0173
   Val:   Loss=0.0727, RMSE=0.2697, R²=0.0232
============================================================


📊 Round 167 Test Metrics:
   Loss: 0.0868, RMSE: 0.2945, MAE: 0.2565, R²: 0.0255

============================================================
🔄 Round 168 - Client client_27
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0737 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0737, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0737, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0737, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0737, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0737, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0737)

============================================================
📊 Round 168 Summary - Client client_27
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=0.0024
   Val:   Loss=0.0737, RMSE=0.2714, R²=0.0834
============================================================


============================================================
🔄 Round 170 - Client client_27
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0743 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0743, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0743, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0743, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0743, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0744, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0743)

============================================================
📊 Round 170 Summary - Client client_27
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=0.0109
   Val:   Loss=0.0743, RMSE=0.2725, R²=0.0487
============================================================


📊 Round 170 Test Metrics:
   Loss: 0.0868, RMSE: 0.2945, MAE: 0.2565, R²: 0.0255

📊 Round 170 Test Metrics:
   Loss: 0.0868, RMSE: 0.2945, MAE: 0.2565, R²: 0.0255

📊 Round 170 Test Metrics:
   Loss: 0.0868, RMSE: 0.2945, MAE: 0.2565, R²: 0.0255

============================================================
🔄 Round 174 - Client client_27
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 174 Summary - Client client_27
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2822, R²=0.0193
   Val:   Loss=0.0792, RMSE=0.2814, R²=0.0065
============================================================


📊 Round 174 Test Metrics:
   Loss: 0.0868, RMSE: 0.2945, MAE: 0.2565, R²: 0.0255

============================================================
🔄 Round 175 - Client client_27
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 175 Summary - Client client_27
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2824, R²=0.0183
   Val:   Loss=0.0788, RMSE=0.2808, R²=0.0240
============================================================


📊 Round 175 Test Metrics:
   Loss: 0.0868, RMSE: 0.2945, MAE: 0.2565, R²: 0.0255

============================================================
🔄 Round 177 - Client client_27
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0768, val=0.0899 (↓), lr=0.000001
   • Epoch   2/100: train=0.0768, val=0.0899, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0768, val=0.0899, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0768, val=0.0899, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0768, val=0.0899, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0768, val=0.0899, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0899)

============================================================
📊 Round 177 Summary - Client client_27
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0770, RMSE=0.2775, R²=0.0345
   Val:   Loss=0.0899, RMSE=0.2998, R²=-0.0468
============================================================


============================================================
🔄 Round 179 - Client client_27
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0729 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0729, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0729, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0729, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0729, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0729, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0729)

============================================================
📊 Round 179 Summary - Client client_27
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=0.0230
   Val:   Loss=0.0729, RMSE=0.2700, R²=-0.0105
============================================================


============================================================
🔄 Round 181 - Client client_27
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0762, val=0.0932 (↓), lr=0.000001
   • Epoch   2/100: train=0.0762, val=0.0932, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0762, val=0.0932, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0762, val=0.0932, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0762, val=0.0932, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0762, val=0.0931, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0932)

============================================================
📊 Round 181 Summary - Client client_27
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0762, RMSE=0.2760, R²=0.0173
   Val:   Loss=0.0932, RMSE=0.3052, R²=0.0258
============================================================


============================================================
🔄 Round 182 - Client client_27
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0767, val=0.0916 (↓), lr=0.000001
   • Epoch   2/100: train=0.0767, val=0.0916, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0767, val=0.0916, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0767, val=0.0916, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0767, val=0.0916, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0767, val=0.0916, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0916)

============================================================
📊 Round 182 Summary - Client client_27
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0766, RMSE=0.2767, R²=0.0295
   Val:   Loss=0.0916, RMSE=0.3026, R²=-0.0159
============================================================


📊 Round 182 Test Metrics:
   Loss: 0.0868, RMSE: 0.2946, MAE: 0.2565, R²: 0.0254

📊 Round 182 Test Metrics:
   Loss: 0.0868, RMSE: 0.2946, MAE: 0.2565, R²: 0.0254

============================================================
🔄 Round 186 - Client client_27
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0710 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0710, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0710, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0710, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0710, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0710, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0710)

============================================================
📊 Round 186 Summary - Client client_27
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=0.0168
   Val:   Loss=0.0710, RMSE=0.2665, R²=0.0276
============================================================


📊 Round 186 Test Metrics:
   Loss: 0.0868, RMSE: 0.2946, MAE: 0.2565, R²: 0.0253

============================================================
🔄 Round 187 - Client client_27
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 187 Summary - Client client_27
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2806, R²=0.0205
   Val:   Loss=0.0829, RMSE=0.2880, R²=0.0149
============================================================


============================================================
🔄 Round 188 - Client client_27
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 188 Summary - Client client_27
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2820, R²=0.0174
   Val:   Loss=0.0797, RMSE=0.2824, R²=0.0273
============================================================


============================================================
🔄 Round 190 - Client client_27
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 190 Summary - Client client_27
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2815, R²=0.0155
   Val:   Loss=0.0808, RMSE=0.2843, R²=0.0340
============================================================


📊 Round 190 Test Metrics:
   Loss: 0.0868, RMSE: 0.2946, MAE: 0.2565, R²: 0.0252

============================================================
🔄 Round 194 - Client client_27
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0742 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0741, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0741, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0741, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0741, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0741, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0742)

============================================================
📊 Round 194 Summary - Client client_27
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2845, R²=0.0194
   Val:   Loss=0.0742, RMSE=0.2723, R²=0.0193
============================================================


============================================================
🔄 Round 198 - Client client_27
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0750 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0750, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0750, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0750, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0750, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0750, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0750)

============================================================
📊 Round 198 Summary - Client client_27
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=0.0282
   Val:   Loss=0.0750, RMSE=0.2739, R²=-0.0211
============================================================


📊 Round 198 Test Metrics:
   Loss: 0.0868, RMSE: 0.2946, MAE: 0.2565, R²: 0.0253

============================================================
🔄 Round 200 - Client client_27
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 200 Summary - Client client_27
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2822, R²=0.0119
   Val:   Loss=0.0793, RMSE=0.2816, R²=0.0475
============================================================


============================================================
🔄 Round 202 - Client client_27
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0716 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0716, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0716, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0716, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0716, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0717, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0716)

============================================================
📊 Round 202 Summary - Client client_27
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=0.0166
   Val:   Loss=0.0716, RMSE=0.2676, R²=0.0072
============================================================


📊 Round 202 Test Metrics:
   Loss: 0.0868, RMSE: 0.2946, MAE: 0.2565, R²: 0.0251

📊 Round 202 Test Metrics:
   Loss: 0.0868, RMSE: 0.2946, MAE: 0.2565, R²: 0.0251

============================================================
🔄 Round 209 - Client client_27
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 209 Summary - Client client_27
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2809, R²=0.0208
   Val:   Loss=0.0823, RMSE=0.2870, R²=0.0136
============================================================


📊 Round 209 Test Metrics:
   Loss: 0.0868, RMSE: 0.2946, MAE: 0.2565, R²: 0.0252

📊 Round 209 Test Metrics:
   Loss: 0.0868, RMSE: 0.2946, MAE: 0.2565, R²: 0.0252

📊 Round 209 Test Metrics:
   Loss: 0.0868, RMSE: 0.2946, MAE: 0.2565, R²: 0.0252

📊 Round 209 Test Metrics:
   Loss: 0.0868, RMSE: 0.2946, MAE: 0.2565, R²: 0.0252

📊 Round 209 Test Metrics:
   Loss: 0.0868, RMSE: 0.2946, MAE: 0.2565, R²: 0.0251

============================================================
🔄 Round 218 - Client client_27
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0779, val=0.0871 (↓), lr=0.000001
   • Epoch   2/100: train=0.0779, val=0.0871, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0779, val=0.0871, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0779, val=0.0871, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0779, val=0.0871, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0779, val=0.0871, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0871)

============================================================
📊 Round 218 Summary - Client client_27
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0777, RMSE=0.2788, R²=0.0206
   Val:   Loss=0.0871, RMSE=0.2951, R²=0.0144
============================================================


📊 Round 218 Test Metrics:
   Loss: 0.0868, RMSE: 0.2946, MAE: 0.2565, R²: 0.0251

============================================================
🔄 Round 221 - Client client_27
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0764 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0764, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0764, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0764, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0764, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0764, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0764)

============================================================
📊 Round 221 Summary - Client client_27
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=0.0212
   Val:   Loss=0.0764, RMSE=0.2765, R²=0.0096
============================================================


📊 Round 221 Test Metrics:
   Loss: 0.0868, RMSE: 0.2946, MAE: 0.2565, R²: 0.0252

📊 Round 221 Test Metrics:
   Loss: 0.0868, RMSE: 0.2946, MAE: 0.2565, R²: 0.0252

============================================================
🔄 Round 224 - Client client_27
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0736 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0736, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0736, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0736, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0736, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0736, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0736)

============================================================
📊 Round 224 Summary - Client client_27
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2847, R²=0.0182
   Val:   Loss=0.0736, RMSE=0.2713, R²=0.0232
============================================================


❌ Client client_27 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8687 {grpc_message:"Socket closed", grpc_status:14}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8687 {grpc_message:"Socket closed", grpc_status:14}"
>
