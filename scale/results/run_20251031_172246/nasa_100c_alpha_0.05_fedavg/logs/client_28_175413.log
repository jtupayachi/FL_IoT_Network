[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: train message add205be-ed65-4422-a5e5-3f7468a1c501
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 84907e52-3bfc-4bef-a311-6b72ce1584f9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e2df2c81-af5a-47b8-ac3c-73132812bb9c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 821cf3cd-62eb-4213-8b33-d6a8e1c595a7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0047a3af-b8bc-42fd-a72c-35996626843e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3e38cf6a-0106-4e0f-8bef-6450455aade8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2f290b36-eee5-41cf-84fd-5869b30bfb8c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a8bb9eea-6218-4ed0-b5d4-0daf20da05fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d1d41ecd-6aeb-4c49-92a5-92d5deb84fb5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2e58047e-e33a-433b-a0d0-2ce7446115a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3e202680-f390-4178-9f0d-92114ca8acac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a9952212-7cfb-43cb-9953-6735dfc57b51
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0467a496-045b-4228-82cf-f4e080d59e1c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7606e3b2-6ac3-41a1-9675-cd6772112b9a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4699d7e8-ad7c-492c-8c71-6ef1a13c9244
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f3c8505b-10b1-4f59-92d2-ec6a5c581c9e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 54e85c5c-2836-42a9-9b44-b4e78c0e3505
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 02441a58-4949-405f-a4ac-2852a019f5de
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 59abd8c8-527a-488d-882e-a315489120ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f4da1911-177a-49a8-a575-a930e4d796ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9d7b27e9-24a4-419a-881d-d927f8d57601
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 44d12c5e-f73e-4da9-bf38-e5f7a2a9310f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f9ed7541-31e8-4ff6-b801-820374557319
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3cc51d29-86aa-4e2f-bd7a-9f2e9393c544
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2f18e5a7-693a-4e5d-a1af-3a2d893bf81c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 05a44e42-0430-4333-b56e-d88df7499aa1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 69f168a2-159e-4f6f-850f-e1abb2856026
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 60855dba-7d46-4fa9-b90f-1ae8484cf3df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 48635b49-cc73-41f1-a255-077396ecc306
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 23404480-f392-4f49-bcf3-92325f19d78f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f98dc067-de3b-4f73-8c04-38e8afc19df6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0a5231af-d986-4272-84b4-a03fdba74ec9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5c905875-08c2-4a11-9117-65693e07d34a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d90996c0-c402-49f2-8934-3f4ea2b764f4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b7d34ca3-0cfb-4383-bbf4-34676ff546f8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 856b3263-5df4-470a-82be-9be5e77e74b6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7244865d-301e-4934-8a05-0e510433ee12
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1c36e19c-b5c6-48f6-9ad7-0edff6b01ea9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cb07bd7e-3287-4fff-bd60-4b233bed3dc1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 71a861d4-171d-473b-8c3a-21874d048c54
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d7762e73-c9cf-4ff7-a46e-42cb8d63e61f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5a6cb8e7-49c9-410c-a8fe-b006856e002a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9e604b44-fb4a-4287-8ff1-c23b436a0016
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a71f1816-f0fa-447b-af91-77b02f4b9ab7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e5b619ef-b6ed-4d53-86ad-19245957d07a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1e01ba4c-2bcf-47d6-b899-b38b340c3bcb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8f57ae7f-d99c-44c6-8f8a-e54de17c141f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message daa08ce8-4b24-4e00-a9b3-b32140f34e97
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 58fdb52c-a3e1-420e-9c38-31441ab5da40
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4781c743-ef2f-40c4-bf6f-cd5cb858f5b8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3d31f6ea-f00e-42a1-8442-8052ea10d09c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dcd755ab-ba42-486d-9cfb-454fdc10f51b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 075005b5-4ec8-4caa-8b25-d95b91483924
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ac6a22e4-7ecb-42a8-98be-802397a5de3b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 080f0365-31d0-42b5-afdb-fe36e1173a5a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2a85f948-0458-4f92-9ba8-f912d6cbeee2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cabc7b59-a8f7-450c-b4bc-220ff51bc99a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ce0bc67c-7273-453d-a063-50ea31d455a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d0a2e5df-9a62-42a5-ab31-18e987f39693
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a5b87e43-0e79-4c91-94fd-2618eb095493
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e39965f1-add1-4bb1-a2c9-0296d00d77ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5430d737-e041-44f8-8937-779c2eeafeee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bafabca5-541d-4c7d-8bc8-a4afa539b435
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a48a73e5-b7b4-431e-81af-693c959538f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c8236024-0ba9-40c7-a0be-7cd48d25e6ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 87620054-314b-4390-ba09-40e1264c8709
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c12cad66-88a4-4c81-a037-e35840e2db63
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 98ff05a4-f6d8-44fc-bf89-2cb03665af01
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eeea17b5-9e3a-478d-96d9-56652f977736
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 93ea591f-7dfa-4457-8d56-b976f689cd24
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 02d666aa-c4bc-4d23-8b5e-cdd255680c54
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6a487c38-65f1-4bd4-9091-73139555bc36
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 418f274f-e389-4a9b-9c9d-7188789a0e5f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 44d6ed7e-578b-4d82-a2e6-2a8db2933e58
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 97ef2a1e-cc76-4a91-91d0-2510ab07a211
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 63b2dff2-4a9c-413a-ad3f-3fd75163d1a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 157c4b88-0ecf-4947-b25c-d3a021c82bef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aa2ba941-363a-442f-a323-4f12080a7ff2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b0eec91e-29e7-4299-959b-f24184057265
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1654477a-cc6e-4c8b-93d2-a0c1c7245787
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9de974e2-9a5d-4a13-a0f6-cce378e399ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cce2edad-a9af-42b8-90b5-bf3207239f69
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1099b19d-e48d-4b4e-afab-bd02b715a8af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1310885d-a986-4c1a-8db1-e44dd6d16bc7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6ff27273-a38e-42a9-8e9b-e56786dba572
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1876c765-86d7-458c-a158-e261b81385ea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message be2ea3af-1383-4968-836c-667e361510da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f6f8b300-62fc-4a06-bb71-adb9f4a919c9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 83e197c9-96b5-40af-9c14-b1e278f5a419
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message da0775b6-4b58-4307-b7a9-87767b240682
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c0e1d456-df6c-49c1-b552-68d1c1a7ffe5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dd9d1987-86e6-41d2-adfb-e0b7bef16b8c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 501e4df2-a432-453a-9ef6-75bdaf732ce6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5b6ffee0-9ad5-4794-8d04-7671a9ae1f11
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e0cc8b96-cc6f-4ac7-b8f0-ef0009943750
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e4936a88-faf3-4010-bb23-19a428c8ecfc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f4da8dba-9eb5-4c79-beeb-d8b27141ef25
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1e3b8ec2-d1b0-44b1-a5f3-4109a079353b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e00dd5ea-3bf1-4c2a-adf5-566f76e771df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 89b3a86b-5666-47fe-bab9-40aa27caa3f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a03516b5-d63f-45ef-b5fe-ee1a7ff4227b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 976257c1-0a39-4475-a0ab-645ee023ea55
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c8f74e0e-026e-4055-8a57-70d636ab4516
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 378ef854-6ac4-4345-8271-8f55ee1d2ba7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0d08397f-2bbf-417a-a2ec-90ea7b3e62b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a4f77d64-32d3-4263-8f41-7b3d91c88d14
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5545a40a-a92e-4752-947c-7a87649aa35f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5ddfde8a-4196-4a75-a29c-9b745b164d06
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 376d2962-4762-4eca-a97b-b5c278f20409
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2bd7788e-721a-4574-af3f-e1759871fc72
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 54434cc9-311a-4f8d-8618-1f883713c621
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 85812164-9ce4-4cca-a1a0-9d107108b21c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 642a9547-2f76-45eb-a8cb-ff16fac001a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 020ed5a6-5111-4841-9e1b-ab1a9b799f31
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 137e7088-0d53-4fe6-84ce-258a335049c9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c057b925-814e-4fb7-a843-9e365d6dba31
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 548f5fe1-975c-4387-a21b-a7a05e6b82dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 79913586-f395-4380-acab-70791fe5ccfe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1e1903e8-cd6b-4622-83e9-594c68f4385a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5a04ec6c-5a39-4474-9cad-aa28193f7037
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9b118969-5f75-4b03-b0a0-92cec4bc2aae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2baaed26-ea09-48cd-bf26-50470347a1ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1b3341fd-d698-4964-8487-f05d8a23e7a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 07c02dd6-4137-4e77-88b9-b7dd4b65c1e8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ecef90ef-14f5-49d8-86e6-b1fb08af5f15
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 54475212-5ccb-4f54-9730-4f7ab05c09a0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fafd214f-a8c4-4194-a4e0-3dcf20724515
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 96ab81c7-b6a5-4153-928f-533b0f1d63b5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message acc2ec5b-a67a-48a8-a414-3e80ca82f200
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 43a1ae48-c865-4074-a200-ed1c1161eb86
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b2a4a673-26f6-4b84-ae7d-80c0c1a50ba8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a0bf03a4-7c60-4bd0-ac76-5130f77b645b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 42e6030e-400d-4e0e-9336-0fe57fb3d835
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 01cd9cd7-c938-4353-9d09-502e2b20cf18
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 95cf6756-58b4-4839-8609-fe1ea76dbae7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 64f22ce3-b5f1-4366-9143-3091c52ab94f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fc48c32e-b52e-4c58-b57f-8d338b3af3ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e54e1fd2-c734-4838-931f-a5f73ac7db25
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 51121585-8c95-4ea9-8045-b824bff6fc04
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 072ce984-f300-40c2-8e98-1459199efbde
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2706fdf8-07e7-498d-a6ff-ee662b2c9baa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e97c80b8-38fb-446b-9763-8eac547d5ac3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 97f18a22-d2a1-40a7-8065-c22a7b8e0c66
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 30d96ac5-e160-43c4-b8f6-2ad7117eae2f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bfbed086-6dd8-4f9b-a3c8-0d5ad673a601
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 16c0f457-c829-4e7d-a7e8-66142a2d86ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d73d957a-b763-4e66-b0b5-cc58468ce438
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a7b6ce80-0e5e-4f4f-8583-4433c5ef86bc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 96dc4861-f3da-4bd7-ae72-4611d11068a7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 160ff3e3-9909-4949-9065-e2be82e7454e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f19d9aa3-03b1-4381-b874-084b03f9eaac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1a9482c6-a931-473d-a644-713bf6071a4d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ea572ec5-ab66-4272-a76f-afb16e8b49d9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7d68b83a-096a-42ac-839b-31b030f514b5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aee7173f-a5a2-483a-b217-62d3b2418ad0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 386b1453-f81d-4e12-8ccc-9e1e9fc2c837
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 064074ba-1d35-47e0-9ec2-dc1509089ad0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5ea8bbb2-b758-4d34-b61c-03a70be00e38
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d050b382-9386-42cd-b244-e7ffb3ff12ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 651df7ab-0217-4591-bd72-6b1298093b9d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0cb38d45-27c9-4fdb-a83d-622ea8c4c6f8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b9617f16-39fc-42e3-85fa-85f41ab8bf2b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 39a9e1cf-80a3-4a01-8ed8-2e5704f20ff3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 01ecb7ab-4bfd-4d98-b7eb-da1b35497f24
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6076ec17-5ecb-4da1-a664-12d2847dbcef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 689e0d69-3877-4659-80a9-1c110dcf2151
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a489b164-506c-408b-8801-5f4c8d030c67
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dc75ff4a-5d95-49d6-8fac-8ce1536012de
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ca923418-57cf-4756-ad93-63b148654150
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3592f44c-6023-4fc5-855d-27e917d70369
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b5c37217-2037-4f64-bf86-9b2007ab316d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a352128c-9324-4316-9864-35a6a5b083e0
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8687 {grpc_message:"Socket closed", grpc_status:14}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_28
Server: localhost:8687
Algorithm: FEDAVG
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_28
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_28/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_28/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_28/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_28/test_labels.txt

📊 Raw data loaded:
   Train: X=(1617, 24), y=(1617,)
   Test:  X=(405, 24), y=(405,)

⚠️  Limiting training data: 1617 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  396 samples, 5 features
✅ Client client_28 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

============================================================
🔄 Round 2 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0924 (↓), lr=0.001000
   • Epoch   2/100: train=0.0854, val=0.0919, patience=1/15, lr=0.001000
   • Epoch   3/100: train=0.0857, val=0.0922, patience=2/15, lr=0.001000
   • Epoch   4/100: train=0.0857, val=0.0922, patience=3/15, lr=0.001000
   • Epoch   5/100: train=0.0854, val=0.0921, patience=4/15, lr=0.001000
   📉 Epoch 8: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0830, val=0.0930, patience=10/15, lr=0.000500
   📉 Epoch 16: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0924)

============================================================
📊 Round 2 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0839, RMSE=0.2896, R²=0.0059
   Val:   Loss=0.0924, RMSE=0.3040, R²=-0.0181
============================================================


============================================================
🔄 Round 3 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0910 (↓), lr=0.000250
   ✓ Epoch   2/100: train=0.0843, val=0.0904 (↓), lr=0.000250
   • Epoch   3/100: train=0.0841, val=0.0906, patience=1/15, lr=0.000250
   • Epoch   4/100: train=0.0840, val=0.0906, patience=2/15, lr=0.000250
   • Epoch   5/100: train=0.0839, val=0.0907, patience=3/15, lr=0.000250
   📉 Epoch 8: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0835, val=0.0909, patience=9/15, lr=0.000125
   📉 Epoch 16: LR reduced 0.000125 → 0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0904)

============================================================
📊 Round 3 Summary - Client client_28
   Epochs: 17/100 (early stopped)
   LR: 0.000250 → 0.000063 (2 reductions)
   Train: Loss=0.0844, RMSE=0.2904, R²=0.0055
   Val:   Loss=0.0904, RMSE=0.3007, R²=-0.0240
============================================================


📊 Round 3 Test Metrics:
   Loss: 0.0810, RMSE: 0.2847, MAE: 0.2462, R²: -0.0034

📊 Round 3 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2460, R²: -0.0050

📊 Round 3 Test Metrics:
   Loss: 0.0814, RMSE: 0.2854, MAE: 0.2461, R²: -0.0085

📊 Round 3 Test Metrics:
   Loss: 0.0816, RMSE: 0.2857, MAE: 0.2467, R²: -0.0104

============================================================
🔄 Round 9 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0910 (↓), lr=0.000063
   • Epoch   2/100: train=0.0850, val=0.0916, patience=1/15, lr=0.000063
   • Epoch   3/100: train=0.0845, val=0.0921, patience=2/15, lr=0.000063
   • Epoch   4/100: train=0.0842, val=0.0924, patience=3/15, lr=0.000063
   • Epoch   5/100: train=0.0841, val=0.0927, patience=4/15, lr=0.000063
   📉 Epoch 7: LR reduced 0.000063 → 0.000031
   • Epoch  11/100: train=0.0836, val=0.0932, patience=10/15, lr=0.000031
   📉 Epoch 15: LR reduced 0.000031 → 0.000016

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0910)

============================================================
📊 Round 9 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000063 → 0.000016 (2 reductions)
   Train: Loss=0.0852, RMSE=0.2920, R²=-0.0115
   Val:   Loss=0.0910, RMSE=0.3017, R²=0.0054
============================================================


📊 Round 9 Test Metrics:
   Loss: 0.0817, RMSE: 0.2858, MAE: 0.2465, R²: -0.0111

============================================================
🔄 Round 15 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000016
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0898 (↓), lr=0.000016
   • Epoch   2/100: train=0.0859, val=0.0896, patience=1/15, lr=0.000016
   • Epoch   3/100: train=0.0858, val=0.0895, patience=2/15, lr=0.000016
   • Epoch   4/100: train=0.0857, val=0.0893, patience=3/15, lr=0.000016
   ✓ Epoch   5/100: train=0.0856, val=0.0892 (↓), lr=0.000016
   • Epoch  11/100: train=0.0852, val=0.0887, patience=6/15, lr=0.000016
   • Epoch  21/100: train=0.0847, val=0.0882, patience=9/15, lr=0.000016
   • Epoch  31/100: train=0.0843, val=0.0878, patience=9/15, lr=0.000016
   • Epoch  41/100: train=0.0840, val=0.0875, patience=5/15, lr=0.000016
   • Epoch  51/100: train=0.0838, val=0.0873, patience=15/15, lr=0.000016

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0876)

============================================================
📊 Round 15 Summary - Client client_28
   Epochs: 51/100 (early stopped)
   LR: 0.000016 → 0.000016 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2904, R²=0.0076
   Val:   Loss=0.0876, RMSE=0.2960, R²=0.0070
============================================================


============================================================
🔄 Round 16 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000016
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0869, val=0.0864 (↓), lr=0.000016
   • Epoch   2/100: train=0.0868, val=0.0864, patience=1/15, lr=0.000016
   • Epoch   3/100: train=0.0867, val=0.0863, patience=2/15, lr=0.000016
   • Epoch   4/100: train=0.0866, val=0.0862, patience=3/15, lr=0.000016
   • Epoch   5/100: train=0.0865, val=0.0862, patience=4/15, lr=0.000016
   • Epoch  11/100: train=0.0861, val=0.0859, patience=1/15, lr=0.000016
   • Epoch  21/100: train=0.0855, val=0.0855, patience=11/15, lr=0.000016

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 16 Summary - Client client_28
   Epochs: 25/100 (early stopped)
   LR: 0.000016 → 0.000016 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2934, R²=-0.0070
   Val:   Loss=0.0859, RMSE=0.2931, R²=0.0120
============================================================


📊 Round 16 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2462, R²: -0.0077

📊 Round 16 Test Metrics:
   Loss: 0.0813, RMSE: 0.2852, MAE: 0.2461, R²: -0.0070

📊 Round 16 Test Metrics:
   Loss: 0.0812, RMSE: 0.2850, MAE: 0.2460, R²: -0.0057

============================================================
🔄 Round 23 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000016
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0907 (↓), lr=0.000016
   • Epoch   2/100: train=0.0855, val=0.0908, patience=1/15, lr=0.000016
   • Epoch   3/100: train=0.0853, val=0.0908, patience=2/15, lr=0.000016
   • Epoch   4/100: train=0.0852, val=0.0909, patience=3/15, lr=0.000016
   • Epoch   5/100: train=0.0851, val=0.0909, patience=4/15, lr=0.000016
   📉 Epoch 6: LR reduced 0.000016 → 0.000008
   • Epoch  11/100: train=0.0847, val=0.0909, patience=10/15, lr=0.000008
   📉 Epoch 14: LR reduced 0.000008 → 0.000004

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0907)

============================================================
📊 Round 23 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000016 → 0.000004 (2 reductions)
   Train: Loss=0.0857, RMSE=0.2927, R²=-0.0029
   Val:   Loss=0.0907, RMSE=0.3012, R²=-0.0488
============================================================


📊 Round 23 Test Metrics:
   Loss: 0.0812, RMSE: 0.2850, MAE: 0.2460, R²: -0.0056

============================================================
🔄 Round 25 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000004
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0872, val=0.0847 (↓), lr=0.000004
   • Epoch   2/100: train=0.0872, val=0.0847, patience=1/15, lr=0.000004
   • Epoch   3/100: train=0.0872, val=0.0847, patience=2/15, lr=0.000004
   • Epoch   4/100: train=0.0871, val=0.0846, patience=3/15, lr=0.000004
   • Epoch   5/100: train=0.0871, val=0.0846, patience=4/15, lr=0.000004
   • Epoch  11/100: train=0.0869, val=0.0845, patience=10/15, lr=0.000004

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 25 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000004 → 0.000004 (0 reductions)
   Train: Loss=0.0873, RMSE=0.2954, R²=-0.0103
   Val:   Loss=0.0847, RMSE=0.2910, R²=-0.0155
============================================================


📊 Round 25 Test Metrics:
   Loss: 0.0812, RMSE: 0.2850, MAE: 0.2460, R²: -0.0058

============================================================
🔄 Round 29 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000004
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0876, val=0.0836 (↓), lr=0.000004
   • Epoch   2/100: train=0.0875, val=0.0836, patience=1/15, lr=0.000004
   • Epoch   3/100: train=0.0875, val=0.0836, patience=2/15, lr=0.000004
   • Epoch   4/100: train=0.0874, val=0.0837, patience=3/15, lr=0.000004
   • Epoch   5/100: train=0.0874, val=0.0837, patience=4/15, lr=0.000004
   📉 Epoch 7: LR reduced 0.000004 → 0.000002
   • Epoch  11/100: train=0.0872, val=0.0838, patience=10/15, lr=0.000002
   📉 Epoch 15: LR reduced 0.000002 → 0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 29 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000004 → 0.000001 (2 reductions)
   Train: Loss=0.0875, RMSE=0.2959, R²=-0.0164
   Val:   Loss=0.0836, RMSE=0.2891, R²=-0.0091
============================================================


📊 Round 29 Test Metrics:
   Loss: 0.0812, RMSE: 0.2850, MAE: 0.2460, R²: -0.0057

📊 Round 29 Test Metrics:
   Loss: 0.0812, RMSE: 0.2850, MAE: 0.2460, R²: -0.0057

📊 Round 29 Test Metrics:
   Loss: 0.0812, RMSE: 0.2850, MAE: 0.2460, R²: -0.0056

📊 Round 29 Test Metrics:
   Loss: 0.0812, RMSE: 0.2850, MAE: 0.2460, R²: -0.0056

============================================================
🔄 Round 39 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0875 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0875, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0875, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0875, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0875, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0876, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0875)

============================================================
📊 Round 39 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2942, R²=-0.0168
   Val:   Loss=0.0875, RMSE=0.2958, R²=-0.0086
============================================================


============================================================
🔄 Round 42 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0870, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0870, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0870, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0870, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0870, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0869, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 42 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0870, RMSE=0.2950, R²=-0.0097
   Val:   Loss=0.0858, RMSE=0.2929, R²=-0.0234
============================================================


📊 Round 42 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2460, R²: -0.0054

📊 Round 42 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2460, R²: -0.0054

============================================================
🔄 Round 45 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0876, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0876, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0876, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0876, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0875, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0875, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 45 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0880, RMSE=0.2966, R²=-0.0189
   Val:   Loss=0.0819, RMSE=0.2862, R²=-0.0095
============================================================


============================================================
🔄 Round 46 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0897, val=0.0752 (↓), lr=0.000001
   • Epoch   2/100: train=0.0897, val=0.0752, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0897, val=0.0753, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0897, val=0.0753, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0897, val=0.0753, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0896, val=0.0754, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0752)

============================================================
📊 Round 46 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0896, RMSE=0.2994, R²=-0.0150
   Val:   Loss=0.0752, RMSE=0.2743, R²=-0.0280
============================================================


📊 Round 46 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2460, R²: -0.0054

============================================================
🔄 Round 49 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0891 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0891, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0891, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0891, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0891, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0891, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0891)

============================================================
📊 Round 49 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2936, R²=-0.0073
   Val:   Loss=0.0891, RMSE=0.2985, R²=-0.0304
============================================================


📊 Round 49 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2460, R²: -0.0054

============================================================
🔄 Round 50 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0907 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0907, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0907, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0907, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0907, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0907, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0907)

============================================================
📊 Round 50 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2929, R²=-0.0109
   Val:   Loss=0.0907, RMSE=0.3011, R²=-0.0380
============================================================


📊 Round 50 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2460, R²: -0.0053

============================================================
🔄 Round 52 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0884, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0884, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0884, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0884, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0884, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0884, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 52 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0883, RMSE=0.2971, R²=-0.0065
   Val:   Loss=0.0806, RMSE=0.2840, R²=-0.0336
============================================================


📊 Round 52 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2460, R²: -0.0054

📊 Round 52 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2460, R²: -0.0053

📊 Round 52 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2460, R²: -0.0053

📊 Round 52 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2460, R²: -0.0054

============================================================
🔄 Round 59 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0899 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0899, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0899, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0899, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0899, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0899, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0899)

============================================================
📊 Round 59 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2932, R²=-0.0233
   Val:   Loss=0.0899, RMSE=0.2999, R²=0.0315
============================================================


============================================================
🔄 Round 60 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0887 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0887, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0887, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0887, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0887, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0887, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0887)

============================================================
📊 Round 60 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2937, R²=-0.0145
   Val:   Loss=0.0887, RMSE=0.2978, R²=0.0002
============================================================


📊 Round 60 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2460, R²: -0.0053

============================================================
🔄 Round 62 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0872, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0872, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0872, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0872, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0872, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0871, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 62 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0872, RMSE=0.2953, R²=-0.0052
   Val:   Loss=0.0851, RMSE=0.2917, R²=-0.0375
============================================================


📊 Round 62 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2459, R²: -0.0052

============================================================
🔄 Round 64 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0885, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0885, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0885, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0885, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0885, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0884, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 64 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0887, RMSE=0.2979, R²=-0.0161
   Val:   Loss=0.0788, RMSE=0.2806, R²=0.0077
============================================================


📊 Round 64 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2459, R²: -0.0051

============================================================
🔄 Round 68 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0877, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0877, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0877, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0876, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0876, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0876, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 68 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0878, RMSE=0.2963, R²=-0.0189
   Val:   Loss=0.0825, RMSE=0.2873, R²=0.0189
============================================================


📊 Round 68 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2459, R²: -0.0050

📊 Round 68 Test Metrics:
   Loss: 0.0812, RMSE: 0.2849, MAE: 0.2459, R²: -0.0049

📊 Round 68 Test Metrics:
   Loss: 0.0811, RMSE: 0.2849, MAE: 0.2459, R²: -0.0049

📊 Round 68 Test Metrics:
   Loss: 0.0811, RMSE: 0.2849, MAE: 0.2459, R²: -0.0049

============================================================
🔄 Round 75 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0957 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0957, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0957, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0957, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0957, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0957, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0957)

============================================================
📊 Round 75 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=-0.0091
   Val:   Loss=0.0957, RMSE=0.3094, R²=-0.0252
============================================================


============================================================
🔄 Round 77 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0883, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0883, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0883, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0883, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0883, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0883, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 77 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0883, RMSE=0.2972, R²=-0.0158
   Val:   Loss=0.0804, RMSE=0.2836, R²=0.0061
============================================================


📊 Round 77 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2459, R²: -0.0047

============================================================
🔄 Round 81 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.0863 (↓), lr=0.000001
   • Epoch   2/100: train=0.0868, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0868, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0868, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0868, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0868, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 81 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0869, RMSE=0.2947, R²=-0.0078
   Val:   Loss=0.0863, RMSE=0.2937, R²=-0.0306
============================================================


📊 Round 81 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2458, R²: -0.0046

📊 Round 81 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2459, R²: -0.0047

📊 Round 81 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2459, R²: -0.0047

============================================================
🔄 Round 85 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0905 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0905, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0905, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0905, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0905, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0905, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0905)

============================================================
📊 Round 85 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2929, R²=-0.0127
   Val:   Loss=0.0905, RMSE=0.3009, R²=-0.0058
============================================================


============================================================
🔄 Round 87 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0870 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0870, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0870, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0870, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0870, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0870, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 87 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0867, RMSE=0.2944, R²=-0.0197
   Val:   Loss=0.0870, RMSE=0.2949, R²=0.0122
============================================================


============================================================
🔄 Round 90 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0873, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0873, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0873, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0873, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0873, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0872, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 90 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0871, RMSE=0.2952, R²=-0.0211
   Val:   Loss=0.0851, RMSE=0.2917, R²=0.0271
============================================================


📊 Round 90 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2458, R²: -0.0045

============================================================
🔄 Round 91 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0930 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0930, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0930, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0930, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0930, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0929, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0930)

============================================================
📊 Round 91 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2918, R²=-0.0057
   Val:   Loss=0.0930, RMSE=0.3049, R²=-0.0319
============================================================


📊 Round 91 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2458, R²: -0.0045

============================================================
🔄 Round 92 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0943 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0943, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0943, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0943, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0943, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0943, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0943)

============================================================
📊 Round 92 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=-0.0127
   Val:   Loss=0.0943, RMSE=0.3072, R²=-0.0081
============================================================


============================================================
🔄 Round 93 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0960 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0960, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0960, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0960, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0960, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0960, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0960)

============================================================
📊 Round 93 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=-0.0134
   Val:   Loss=0.0960, RMSE=0.3099, R²=-0.0066
============================================================


📊 Round 93 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2458, R²: -0.0045

============================================================
🔄 Round 95 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0870 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0870, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0870, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0870, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0870, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0870, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 95 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0867, RMSE=0.2944, R²=-0.0075
   Val:   Loss=0.0870, RMSE=0.2949, R²=-0.0346
============================================================


📊 Round 95 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2458, R²: -0.0045

============================================================
🔄 Round 97 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0872, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0872, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0872, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0872, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0872, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0872, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 97 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0872, RMSE=0.2953, R²=-0.0109
   Val:   Loss=0.0847, RMSE=0.2910, R²=-0.0116
============================================================


📊 Round 97 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2458, R²: -0.0044

📊 Round 97 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2458, R²: -0.0043

============================================================
🔄 Round 100 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0887 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0887, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0887, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0887, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0887, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0887, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0887)

============================================================
📊 Round 100 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2936, R²=-0.0133
   Val:   Loss=0.0887, RMSE=0.2979, R²=-0.0039
============================================================


📊 Round 100 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2458, R²: -0.0043

============================================================
🔄 Round 101 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0917 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0917, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0917, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0917, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0917, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0917, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0917)

============================================================
📊 Round 101 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2924, R²=-0.0024
   Val:   Loss=0.0917, RMSE=0.3029, R²=-0.0507
============================================================


📊 Round 101 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2458, R²: -0.0042

============================================================
🔄 Round 106 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0867, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0867, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0867, val=0.0859, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0867, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0867, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 106 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0869, RMSE=0.2948, R²=-0.0138
   Val:   Loss=0.0859, RMSE=0.2930, R²=-0.0039
============================================================


============================================================
🔄 Round 107 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0936 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0936, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0936, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0936, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0936, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0936, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0936)

============================================================
📊 Round 107 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2915, R²=-0.0100
   Val:   Loss=0.0936, RMSE=0.3060, R²=-0.0150
============================================================


============================================================
🔄 Round 108 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0891 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0891, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0891, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0891, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0891, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0891, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0891)

============================================================
📊 Round 108 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2935, R²=-0.0124
   Val:   Loss=0.0891, RMSE=0.2985, R²=-0.0072
============================================================


📊 Round 108 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2458, R²: -0.0041

📊 Round 108 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2458, R²: -0.0042

📊 Round 108 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2458, R²: -0.0042

============================================================
🔄 Round 113 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0870 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0870, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0870, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0870, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0870, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0871, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 113 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2943, R²=-0.0105
   Val:   Loss=0.0870, RMSE=0.2950, R²=-0.0154
============================================================


📊 Round 113 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2457, R²: -0.0041

📊 Round 113 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2457, R²: -0.0041

============================================================
🔄 Round 117 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0883, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0883, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0883, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0883, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0882, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0882, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 117 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0879, RMSE=0.2965, R²=-0.0230
   Val:   Loss=0.0819, RMSE=0.2861, R²=0.0375
============================================================


📊 Round 117 Test Metrics:
   Loss: 0.0811, RMSE: 0.2847, MAE: 0.2457, R²: -0.0040

============================================================
🔄 Round 119 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0876, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0876, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0876, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0876, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0876, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0876, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 119 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0871, RMSE=0.2952, R²=-0.0149
   Val:   Loss=0.0851, RMSE=0.2916, R²=-0.0011
============================================================


============================================================
🔄 Round 120 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0867, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0867, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0864, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0866, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 120 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2946, R²=-0.0193
   Val:   Loss=0.0864, RMSE=0.2939, R²=-0.0004
============================================================


============================================================
🔄 Round 121 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0914 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0914, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0914, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0914, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0914, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0914, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0914)

============================================================
📊 Round 121 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2924, R²=-0.0102
   Val:   Loss=0.0914, RMSE=0.3023, R²=-0.0130
============================================================


============================================================
🔄 Round 122 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0885, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0885, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0884, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0884, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0884, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0884, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 122 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0883, RMSE=0.2971, R²=-0.0166
   Val:   Loss=0.0804, RMSE=0.2836, R²=0.0094
============================================================


📊 Round 122 Test Metrics:
   Loss: 0.0811, RMSE: 0.2847, MAE: 0.2457, R²: -0.0039

============================================================
🔄 Round 123 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0939 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0939, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0940, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0940, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0940, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0940, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0939)

============================================================
📊 Round 123 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=-0.0173
   Val:   Loss=0.0939, RMSE=0.3065, R²=-0.0125
============================================================


📊 Round 123 Test Metrics:
   Loss: 0.0811, RMSE: 0.2847, MAE: 0.2457, R²: -0.0039

📊 Round 123 Test Metrics:
   Loss: 0.0811, RMSE: 0.2847, MAE: 0.2457, R²: -0.0039

============================================================
🔄 Round 126 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0884, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0884, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0884, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0884, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0884, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0883, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 126 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0882, RMSE=0.2970, R²=-0.0125
   Val:   Loss=0.0806, RMSE=0.2839, R²=-0.0035
============================================================


📊 Round 126 Test Metrics:
   Loss: 0.0811, RMSE: 0.2847, MAE: 0.2457, R²: -0.0039

📊 Round 126 Test Metrics:
   Loss: 0.0811, RMSE: 0.2847, MAE: 0.2457, R²: -0.0040

📊 Round 126 Test Metrics:
   Loss: 0.0811, RMSE: 0.2847, MAE: 0.2457, R²: -0.0039

📊 Round 126 Test Metrics:
   Loss: 0.0811, RMSE: 0.2847, MAE: 0.2457, R²: -0.0039

============================================================
🔄 Round 137 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.0871 (↓), lr=0.000001
   • Epoch   2/100: train=0.0868, val=0.0871, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0868, val=0.0871, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0868, val=0.0871, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0868, val=0.0871, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0867, val=0.0872, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0871)

============================================================
📊 Round 137 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2943, R²=-0.0188
   Val:   Loss=0.0871, RMSE=0.2951, R²=0.0066
============================================================


============================================================
🔄 Round 139 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0882 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0882, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0882, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0882, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0882, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0882, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0882)

============================================================
📊 Round 139 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2938, R²=-0.0117
   Val:   Loss=0.0882, RMSE=0.2969, R²=-0.0126
============================================================


📊 Round 139 Test Metrics:
   Loss: 0.0811, RMSE: 0.2847, MAE: 0.2457, R²: -0.0039

📊 Round 139 Test Metrics:
   Loss: 0.0811, RMSE: 0.2847, MAE: 0.2457, R²: -0.0039

============================================================
🔄 Round 144 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0884, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0884, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0883, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0883, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0883, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0883, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 144 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0881, RMSE=0.2969, R²=-0.0118
   Val:   Loss=0.0809, RMSE=0.2844, R²=-0.0157
============================================================


============================================================
🔄 Round 146 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0869 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0869, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0869, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0869, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0869, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0869, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 146 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2943, R²=-0.0077
   Val:   Loss=0.0869, RMSE=0.2949, R²=-0.0323
============================================================


============================================================
🔄 Round 148 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0869, val=0.0866 (↓), lr=0.000001
   • Epoch   2/100: train=0.0868, val=0.0866, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0868, val=0.0866, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0868, val=0.0866, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0868, val=0.0866, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0868, val=0.0866, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0866)

============================================================
📊 Round 148 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0867, RMSE=0.2945, R²=-0.0159
   Val:   Loss=0.0866, RMSE=0.2943, R²=0.0083
============================================================


============================================================
🔄 Round 149 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0870, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0870, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0870, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0870, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0870, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0869, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 149 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0871, RMSE=0.2952, R²=-0.0071
   Val:   Loss=0.0850, RMSE=0.2915, R²=-0.0254
============================================================


📊 Round 149 Test Metrics:
   Loss: 0.0811, RMSE: 0.2847, MAE: 0.2457, R²: -0.0038

📊 Round 149 Test Metrics:
   Loss: 0.0811, RMSE: 0.2847, MAE: 0.2457, R²: -0.0037

📊 Round 149 Test Metrics:
   Loss: 0.0811, RMSE: 0.2847, MAE: 0.2457, R²: -0.0037

📊 Round 149 Test Metrics:
   Loss: 0.0810, RMSE: 0.2847, MAE: 0.2457, R²: -0.0036

============================================================
🔄 Round 159 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0892 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0892, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0892, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0892, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0892, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0892, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0892)

============================================================
📊 Round 159 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2933, R²=-0.0140
   Val:   Loss=0.0892, RMSE=0.2987, R²=-0.0060
============================================================


============================================================
🔄 Round 160 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0887, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0887, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0887, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0887, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0887, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0886, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 160 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0886, RMSE=0.2976, R²=-0.0208
   Val:   Loss=0.0791, RMSE=0.2812, R²=0.0326
============================================================


📊 Round 160 Test Metrics:
   Loss: 0.0810, RMSE: 0.2847, MAE: 0.2456, R²: -0.0036

============================================================
🔄 Round 162 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0898 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0898, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0898, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0898, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0898, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0898, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0898)

============================================================
📊 Round 162 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2931, R²=-0.0131
   Val:   Loss=0.0898, RMSE=0.2997, R²=-0.0074
============================================================


============================================================
🔄 Round 163 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0908 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0908, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0908, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0908, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0908, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0907, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0908)

============================================================
📊 Round 163 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2927, R²=-0.0109
   Val:   Loss=0.0908, RMSE=0.3013, R²=-0.0088
============================================================


============================================================
🔄 Round 164 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0869, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0869, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0869, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0869, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0869, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0868, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 164 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0869, RMSE=0.2948, R²=-0.0036
   Val:   Loss=0.0858, RMSE=0.2929, R²=-0.0411
============================================================


============================================================
🔄 Round 165 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0870 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0870, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0870, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0870, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0870, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0870, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 165 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2943, R²=-0.0086
   Val:   Loss=0.0870, RMSE=0.2949, R²=-0.0184
============================================================


============================================================
🔄 Round 166 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0872, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0872, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0871, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0871, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0871, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0871, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 166 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0870, RMSE=0.2949, R²=-0.0022
   Val:   Loss=0.0855, RMSE=0.2924, R²=-0.0462
============================================================


📊 Round 166 Test Metrics:
   Loss: 0.0810, RMSE: 0.2847, MAE: 0.2456, R²: -0.0036

============================================================
🔄 Round 167 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0879, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0879, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0879, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0879, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0879, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0878, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 167 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0878, RMSE=0.2963, R²=-0.0083
   Val:   Loss=0.0823, RMSE=0.2869, R²=-0.0430
============================================================


📊 Round 167 Test Metrics:
   Loss: 0.0810, RMSE: 0.2847, MAE: 0.2456, R²: -0.0036

📊 Round 167 Test Metrics:
   Loss: 0.0810, RMSE: 0.2847, MAE: 0.2456, R²: -0.0036

📊 Round 167 Test Metrics:
   Loss: 0.0810, RMSE: 0.2847, MAE: 0.2456, R²: -0.0036

============================================================
🔄 Round 171 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0882 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0882, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0882, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0882, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0882, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0882, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0882)

============================================================
📊 Round 171 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2937, R²=-0.0026
   Val:   Loss=0.0882, RMSE=0.2971, R²=-0.0448
============================================================


📊 Round 171 Test Metrics:
   Loss: 0.0810, RMSE: 0.2847, MAE: 0.2456, R²: -0.0035

============================================================
🔄 Round 173 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0883, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0883, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0883, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0883, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0883, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0882, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 173 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0885, RMSE=0.2974, R²=-0.0155
   Val:   Loss=0.0795, RMSE=0.2820, R²=0.0070
============================================================


============================================================
🔄 Round 174 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0879, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0879, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0878, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0878, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0878, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0878, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 174 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0879, RMSE=0.2964, R²=-0.0090
   Val:   Loss=0.0818, RMSE=0.2861, R²=-0.0164
============================================================


📊 Round 174 Test Metrics:
   Loss: 0.0810, RMSE: 0.2847, MAE: 0.2456, R²: -0.0034

============================================================
🔄 Round 176 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0873, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0873, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0873, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0873, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0873, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0872, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 176 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0873, RMSE=0.2954, R²=-0.0014
   Val:   Loss=0.0843, RMSE=0.2904, R²=-0.0506
============================================================


============================================================
🔄 Round 177 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0884 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0884, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0884, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0884, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0884, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0883, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0884)

============================================================
📊 Round 177 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2937, R²=-0.0067
   Val:   Loss=0.0884, RMSE=0.2973, R²=-0.0250
============================================================


============================================================
🔄 Round 180 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0901 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0901, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0901, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0901, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0901, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0901, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0901)

============================================================
📊 Round 180 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2929, R²=-0.0009
   Val:   Loss=0.0901, RMSE=0.3002, R²=-0.0537
============================================================


📊 Round 180 Test Metrics:
   Loss: 0.0810, RMSE: 0.2847, MAE: 0.2456, R²: -0.0035

📊 Round 180 Test Metrics:
   Loss: 0.0810, RMSE: 0.2847, MAE: 0.2456, R²: -0.0034

============================================================
🔄 Round 182 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0884, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0884, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0884, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0884, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0884, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0883, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 182 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0886, RMSE=0.2977, R²=-0.0153
   Val:   Loss=0.0789, RMSE=0.2808, R²=0.0040
============================================================


============================================================
🔄 Round 183 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0956 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0956, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0956, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0956, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0956, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0956, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0956)

============================================================
📊 Round 183 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2906, R²=-0.0076
   Val:   Loss=0.0956, RMSE=0.3093, R²=-0.0228
============================================================


============================================================
🔄 Round 184 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0888, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0888, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0888, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0887, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0887, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0887, val=0.0774, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 184 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0890, RMSE=0.2983, R²=-0.0106
   Val:   Loss=0.0775, RMSE=0.2784, R²=-0.0092
============================================================


📊 Round 184 Test Metrics:
   Loss: 0.0810, RMSE: 0.2847, MAE: 0.2456, R²: -0.0034

📊 Round 184 Test Metrics:
   Loss: 0.0810, RMSE: 0.2847, MAE: 0.2456, R²: -0.0034

📊 Round 184 Test Metrics:
   Loss: 0.0810, RMSE: 0.2847, MAE: 0.2456, R²: -0.0034

============================================================
🔄 Round 189 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0875, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0875, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0875, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0875, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0875, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0874, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 189 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0875, RMSE=0.2958, R²=-0.0158
   Val:   Loss=0.0832, RMSE=0.2885, R²=-0.0242
============================================================


📊 Round 189 Test Metrics:
   Loss: 0.0810, RMSE: 0.2847, MAE: 0.2456, R²: -0.0034

============================================================
🔄 Round 190 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0884 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0884, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0884, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0884, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0884, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0883, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0884)

============================================================
📊 Round 190 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2936, R²=-0.0099
   Val:   Loss=0.0884, RMSE=0.2973, R²=-0.0120
============================================================


📊 Round 190 Test Metrics:
   Loss: 0.0810, RMSE: 0.2847, MAE: 0.2456, R²: -0.0034

📊 Round 190 Test Metrics:
   Loss: 0.0810, RMSE: 0.2847, MAE: 0.2456, R²: -0.0034

📊 Round 190 Test Metrics:
   Loss: 0.0810, RMSE: 0.2847, MAE: 0.2456, R²: -0.0034

============================================================
🔄 Round 195 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0874, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0874, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0874, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0874, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0874, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0873, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 195 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0875, RMSE=0.2957, R²=-0.0115
   Val:   Loss=0.0835, RMSE=0.2889, R²=-0.0051
============================================================


📊 Round 195 Test Metrics:
   Loss: 0.0810, RMSE: 0.2847, MAE: 0.2456, R²: -0.0034

============================================================
🔄 Round 196 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.0876 (↓), lr=0.000001
   • Epoch   2/100: train=0.0868, val=0.0876, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0867, val=0.0876, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0867, val=0.0876, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0867, val=0.0876, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0867, val=0.0875, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0876)

============================================================
📊 Round 196 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2940, R²=-0.0165
   Val:   Loss=0.0876, RMSE=0.2959, R²=0.0131
============================================================


📊 Round 196 Test Metrics:
   Loss: 0.0810, RMSE: 0.2847, MAE: 0.2456, R²: -0.0034

📊 Round 196 Test Metrics:
   Loss: 0.0810, RMSE: 0.2846, MAE: 0.2456, R²: -0.0033

============================================================
🔄 Round 198 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0879, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0879, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0879, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0879, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0879, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0879, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 198 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0876, RMSE=0.2961, R²=-0.0067
   Val:   Loss=0.0827, RMSE=0.2876, R²=-0.0255
============================================================


📊 Round 198 Test Metrics:
   Loss: 0.0810, RMSE: 0.2846, MAE: 0.2456, R²: -0.0033

============================================================
🔄 Round 200 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0889 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0889, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0889, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0889, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0889, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0889, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0889)

============================================================
📊 Round 200 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2934, R²=-0.0074
   Val:   Loss=0.0889, RMSE=0.2982, R²=-0.0304
============================================================


📊 Round 200 Test Metrics:
   Loss: 0.0810, RMSE: 0.2846, MAE: 0.2456, R²: -0.0033

============================================================
🔄 Round 204 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0869, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0869, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0869, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0869, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0869, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0869, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 204 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0869, RMSE=0.2948, R²=-0.0147
   Val:   Loss=0.0857, RMSE=0.2927, R²=-0.0048
============================================================


📊 Round 204 Test Metrics:
   Loss: 0.0810, RMSE: 0.2846, MAE: 0.2456, R²: -0.0033

============================================================
🔄 Round 205 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0878 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0878, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0878, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0878, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0878, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0878, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0878)

============================================================
📊 Round 205 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2939, R²=-0.0091
   Val:   Loss=0.0878, RMSE=0.2963, R²=-0.0346
============================================================


📊 Round 205 Test Metrics:
   Loss: 0.0810, RMSE: 0.2846, MAE: 0.2456, R²: -0.0033

📊 Round 205 Test Metrics:
   Loss: 0.0810, RMSE: 0.2846, MAE: 0.2456, R²: -0.0033

============================================================
🔄 Round 210 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0948 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0948, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0948, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0948, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0948, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0948, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0948)

============================================================
📊 Round 210 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=-0.0045
   Val:   Loss=0.0948, RMSE=0.3079, R²=-0.0499
============================================================


📊 Round 210 Test Metrics:
   Loss: 0.0810, RMSE: 0.2846, MAE: 0.2455, R²: -0.0031

============================================================
🔄 Round 215 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0873, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0873, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0873, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0873, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0873, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0872, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 215 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0875, RMSE=0.2958, R²=-0.0173
   Val:   Loss=0.0833, RMSE=0.2887, R²=0.0030
============================================================


📊 Round 215 Test Metrics:
   Loss: 0.0810, RMSE: 0.2846, MAE: 0.2455, R²: -0.0031

📊 Round 215 Test Metrics:
   Loss: 0.0810, RMSE: 0.2846, MAE: 0.2455, R²: -0.0031

📊 Round 215 Test Metrics:
   Loss: 0.0810, RMSE: 0.2846, MAE: 0.2455, R²: -0.0031

============================================================
🔄 Round 219 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.1052 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.1052, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.1052, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.1052, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.1052, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.1051, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.1052)

============================================================
📊 Round 219 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=-0.0043
   Val:   Loss=0.1052, RMSE=0.3243, R²=-0.0284
============================================================


📊 Round 219 Test Metrics:
   Loss: 0.0810, RMSE: 0.2846, MAE: 0.2455, R²: -0.0030

📊 Round 219 Test Metrics:
   Loss: 0.0810, RMSE: 0.2846, MAE: 0.2455, R²: -0.0030

============================================================
🔄 Round 221 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0871, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0870, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0870, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0870, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0870, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0870, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 221 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0871, RMSE=0.2951, R²=-0.0167
   Val:   Loss=0.0849, RMSE=0.2914, R²=-0.0002
============================================================


============================================================
🔄 Round 223 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0897 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0896, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0896, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0896, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0896, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0896, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0897)

============================================================
📊 Round 223 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2931, R²=-0.0114
   Val:   Loss=0.0897, RMSE=0.2994, R²=-0.0074
============================================================


============================================================
🔄 Round 225 - Client client_28
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0874, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0874, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0874, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0874, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0874, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0873, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 225 Summary - Client client_28
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0873, RMSE=0.2955, R²=-0.0195
   Val:   Loss=0.0839, RMSE=0.2896, R²=0.0222
============================================================


❌ Client client_28 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8687 {grpc_message:"Socket closed", grpc_status:14}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8687 {grpc_message:"Socket closed", grpc_status:14}"
>
