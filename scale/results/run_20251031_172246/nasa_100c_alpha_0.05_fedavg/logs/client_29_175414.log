[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a46d6365-0ec1-46b7-b108-4a0d35941758
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0f536e7a-a1a1-44ac-9c01-78a4d364bcf4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d97bf923-1965-42dc-ad0a-0803e490e16a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2a5ea6f1-d33b-465d-8455-ebfc07bb16e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 85e915f8-493d-464e-8cc8-018371ab02ce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f941dd86-3b04-49c6-bcb4-84146aa1a337
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f4fe0939-d36e-40b2-b088-95d4d2733a67
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5401f309-cd69-4ece-872a-581e627d9022
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 33caba43-7b83-4afa-b777-6ba68352f7a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 39bf3456-b508-41dc-9705-5b93937cfe60
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0fac6122-9d67-4982-ae54-716b4f54047a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5693f1c3-a0ef-450c-bf02-147ef71fd455
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f3d27f27-9597-4805-9fc5-afccc1cd83c9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ee1b45e6-0860-4a06-b773-1aab5f2c0379
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2246332f-9c7d-41c2-88e8-576257c95bac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 14584ba3-9f68-4d85-8c24-ef8021e65d42
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 16deab0c-979a-49ef-92c7-402b14e6fd6b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4c5d9501-c7e3-4558-a4a5-1e4c32d98a58
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7f6bb3dd-05e1-4a79-a7d8-005fb862c207
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message da7fdec0-1d72-42fc-9eaa-0fd53a896b2d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f4c7ee8d-e589-4b7e-a662-75b947e6ce75
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 87b28dab-a893-4d65-8065-c518a281c7bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2d2eb7dc-80c0-47c8-8cc7-938d9217c4c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 731c640c-a511-4d92-a012-de1e8382252f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message df055bf0-1479-4657-8308-e144fde39646
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 743f0149-91f4-416b-81b2-0f139428a960
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e3a89608-959c-4f50-b7ee-30b752d8b6db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dda13bd5-4e69-4f50-903f-7421e5ad1636
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5a2322b0-aa9e-4df4-bf71-269012492078
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2adf33b3-2769-4134-b1f6-ba04939b00f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 05e3cbc3-db94-4fa9-b25c-67e49ecc28e2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4073c09a-bdbc-4d07-b333-ac385c63e89a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 244b530d-f8e0-48d2-96ef-dd62e73f1487
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 26ac3c8e-18c3-46e2-a501-f7d1c2a515a8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5b6da193-31ce-4793-ac23-0528ba1d40d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 281e42ff-8c10-4196-a0bf-a01afd4dd44d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 305cc86e-0481-43b2-9ffd-5a7e975f0487
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3f547cb7-ddae-4036-93b7-2c27b1d5e0ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7632a348-ef02-405b-ac3a-6e77d99613f4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f9144942-64ce-487a-9d5a-1ee1755381b7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 875c65fc-1d51-43a3-aa68-e5d9aaf9e1d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 07b84cbf-af82-43b7-9c63-2918cd87a0c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a38a0b8c-5b61-4052-901d-834d18c5e82f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0108b6aa-d354-4086-ba72-27e5ca660687
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 50d382d0-ed80-4299-8e1c-cb37fff49864
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e2805458-c782-4eb1-a595-af6f9bf957cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 66721d04-1759-4573-bdea-2ae3a496dcc9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e031b4fc-d956-4553-b4a1-9f8696920a81
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message de238093-fd03-4b11-bf20-3fb01bb37abf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message de022143-ae16-43b0-83c3-1bffadddcdea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4008ba4e-d8db-4b53-8a8e-6478d851702e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3c747d3a-8fbb-4fe1-adaa-b2578d62658c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6c052cf3-8bf7-42b7-a335-36b3382659a0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f68e4148-3c15-4c0b-81a7-7f6785e0c208
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5496e267-c871-4bdc-a466-fa490e58a17e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bdffff97-1175-41ff-a18d-42d089939dee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ef875699-93ca-4518-80e5-328c43618f33
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9341fa42-1f53-42a5-92b6-2637626545eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e26f3d7f-6036-422a-9870-69ce1c035223
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f32bbd50-b48d-4552-a5ad-724452ab8164
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 31ed3e8d-3b2f-4dbf-b724-47bd2d0da6c4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fab72e2c-1841-4ba4-a98d-688f4136fcee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d43567ed-d733-44a2-a9e6-83a6bedc8a4d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 775a7c8d-22fe-4b3a-bbca-a99d5086f4dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e3e39d47-28d3-4f48-b61c-4406fca239e9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b077c107-eafa-4a2d-b1a8-975bea74e50b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3fcea226-22ca-4168-8e9c-2cc1669123ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9901f968-9b7c-4947-a6fd-eb1d4afaf878
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5cb39d9f-4289-46a3-b49f-ba6368abf3c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a4f6fdf1-b0e8-40b5-8297-aa95929c129f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d9dfb03e-54f6-4158-b207-9893325d4256
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cd9e081b-9945-4725-8dab-d592341f1f8b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e20408fd-0a73-4fd6-98b9-9cc8a5a914a3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e60198c6-cb88-41a6-9419-9148c028a494
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 441a7e42-553f-4108-89d6-29ae756a512b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 653936bf-f050-4fd2-a41d-b82cd0a671ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5ad75ea1-3ec1-4aac-93cd-08f86e3cb3d9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d1a309cf-0c66-4959-bd09-c7706401379e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b84eb130-8e60-4433-8073-4fc54c7c3ae1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 677fb33a-9428-45cd-884b-5c1c4aace46b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 997afc50-9abd-4cef-b82f-e939ef7f613f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bf097560-4cca-47bd-a172-e8b245266fd8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c9428411-522b-4a13-a84a-fea48bc47db3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 11150342-2495-470a-839c-9ceee4eb43f6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1b88faba-03f8-493f-8fec-6734223c6be4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8c74d177-76f5-495d-9eee-fb80d7240cfd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a453aea5-e182-4b44-b754-c558d8b555b8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e88fc818-7c08-4712-91d9-3f3413de8373
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8be2c9cd-43b4-4e3e-b087-1a2194e6f272
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 514f13dd-f4f5-4bed-8daf-b9e4b7324b44
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message af6daba0-2f15-49c8-a7a1-7619f51f71f2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1c037dd0-e517-4d82-bd78-92d5953a7587
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 276c4366-574e-4735-9f2a-2ca23cedd9a9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d09bf425-a3f0-4eeb-b6b7-08abd86122bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 47d4887c-ca97-4a69-b099-c6878ea9d6f8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 50da740d-48af-4ddb-9550-e0e8552f898e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 940ca3e0-8aea-4eb4-8fd7-c0b7b2b2c8cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0b454c86-c876-4fe9-aeb9-736cd2d01fa5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4a6b2eeb-61a6-4722-b2bf-f65dca06fd20
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2b4dd526-77f8-4505-9608-3d8254d24833
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ac7118c7-dd23-4a25-90df-4680b13d41d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d804d865-6388-4968-94c1-35ee419d0d1a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2da010a9-e1c6-4fe4-931e-2eb3630c5a9e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cc3cbb5c-f82b-487f-901d-cc46a057d622
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 968e99a5-90c2-4d0b-9381-8b1a7f313cad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0fad9675-a25b-4c3e-817d-60be53a2badd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 36255264-50f0-4163-b980-f93eb1d532bd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2faceaaa-961a-459e-8273-82abd233b9ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 508bca79-9f15-4dc4-ad77-44598b0cd54c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b1d187ba-a262-4c16-ab51-b41be6b65586
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a09befff-b3a0-46d6-9939-cff11543f29e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9b7f3928-8215-431b-99f2-9a7a41c3742c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d2e75509-21a6-409d-97fa-6a3e32ca14e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 26c2739a-2b3e-48b2-8f9d-cb26f163ae04
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b0b3ab3a-5e18-48d5-b60b-7cda250f40ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 06114db2-3c6b-459d-836a-0c97d170feca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5df9f56e-71ea-4a6b-8927-e7dd0b914d86
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5654ba94-1608-42c8-a769-e3ff4ecc7cc9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 06859330-0d1c-4bf8-bfa3-fbb8a709a8ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cae06b09-15d4-48e6-aee6-bb5662da76b7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1a497ec0-50f0-4ef6-9e9f-a3f7069ec962
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fd6f34da-29f7-4e1a-a8ea-6b80e043fa15
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d9170b8e-0e31-455d-9ab6-8d35470f8141
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d5ad087e-076e-4214-ab9e-34613f9d886a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9c4619be-1956-43da-b756-1eb2dd092ac2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1137b4c3-5f0f-4dc4-be24-af6d91e50629
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 27bbdfc6-23e5-4c73-9bca-09d52ae8de0a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 94d7f091-bd6d-43b6-98fb-19127b2ed3cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cb720671-a5fa-4c13-b30e-3b5053b20f87
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d40069ff-ee82-4046-a91a-80e8372d798d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0f348307-3fca-49ad-881e-5b112a5280df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 88ca39a6-b16b-4043-8346-b48d1838476f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 53870430-ae3d-41f9-abe3-81100c9327e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f5bcf7b5-8403-4f7e-a722-c4a1cdc9ae30
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4fbcd897-c9fb-4439-994a-72bcc02ba64f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e5d894d1-99d9-4466-a2bb-5c9264d1bec7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dc884a96-9579-45ea-b451-cefe6a0ebcdb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b2341878-431f-4086-942c-54a079dce223
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6d45502d-718c-4828-9d17-1f9206ff6167
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5ea90c39-0dd6-4b27-92dd-9eac6cf2d345
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 95cc7fa1-831e-42f3-a5be-547245b2faf3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 21395a1c-8b53-46ad-849c-de94b8c2226e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 15f6aef3-ad9f-4d63-b267-110208b61730
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0783645e-b480-4210-a73f-f230c295a738
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 32ccfec4-ef18-4ff5-89db-e4911b64182c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 02b4dfc6-4b00-4e03-a752-526157b11446
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1b4919f9-a861-48ca-9352-16044c58bb99
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2e201b07-b841-47e6-97e9-88efc8651212
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 93aee1cc-a6ad-4b44-a3fe-8282d72b6bb5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5bbb6dd6-a87c-41e0-b6bc-ac70955e4750
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4e300be0-7b4e-4d5c-9262-892ae3041ffd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6d74b775-caa5-41f5-96bb-917e3c274986
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0ec0c7a3-2ae3-4379-b372-59b7b32226bc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message df791bdf-2761-40f9-bd2e-ffdc21400190
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2dc685eb-26b4-4f51-bed5-da9cfd69f177
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c0cfb3e4-e5c8-4ab6-b85d-17cadc77f805
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dd2ad247-41fd-4bf5-9216-2f6fd97f68d5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message db415114-c6e6-4fe7-80a5-78085ac6ee49
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7cfe83ad-68c7-4e47-b5e6-6100beda1e17
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c86dd88a-763c-4737-ab6a-955ff793324e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 18e37276-e530-4cc1-8650-c3b4fbdd7c6f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 35dd984f-8763-493f-b2d8-1fc2d2e9dbcf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 159a4c18-4aa8-4f0b-af41-dc33a7379365
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 466ab2f8-4200-442e-bb30-c74a60034ef6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f2b3fd5f-04c5-4034-a070-fe937487e843
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2d010668-ba5c-4712-8df0-4996cbc9cad7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c447435c-c16e-45be-a9a2-383cf37e5d34
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b2b08e7c-f515-4794-8fab-31f2f7a4edf4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7e144ecf-8866-444e-afb4-46e5eb10e94d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 95660f87-e3ca-4759-81cc-d105e7b7fe0c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 806bbc5a-6e11-4405-8285-66e57b690bd5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9ac30ba5-07ff-46ff-a679-7f051a0317c3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 192f1d79-9c9d-466d-8ad3-0ed698a5a5ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dd5be33c-04e1-4a1c-a154-8c772aa1b8f3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ec979591-2540-482b-872e-7326a223a340
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 57033134-289b-4f70-84c4-95ed924ad08d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e04e6fa1-2b84-4cc3-9eb2-48d351e508ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eef071eb-2c19-4112-b97f-ddbd64b48fd2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ec01f6ae-25e4-47fd-af62-37b3d47a6de1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bd703307-8af1-447d-99cb-a14545ae5203
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b6a043b0-638a-4901-8bf1-aceff5399153
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7c118b89-71eb-4c61-9a91-50f188a53e3e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cd30e823-ed58-4a46-a5ca-4e0ab0c09182
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a5ae36e8-7340-4d05-b723-0f1832b31072
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f86d92fe-819b-46cb-9c25-1dd65060f0a8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dfb20c29-d583-407a-96fb-7995e2db7e9b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 72bdec8d-1650-444c-9742-ca84b50e521d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6815decb-7693-4d0d-aa82-a674b1164476
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message abb51018-64dd-432c-aed3-a3fa77548e4d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3023ebe5-ce11-4b84-afce-37baf26d2ed5
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "recvmsg:Connection reset by peer"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8687 {grpc_status:14, grpc_message:"recvmsg:Connection reset by peer"}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_29
Server: localhost:8687
Algorithm: FEDAVG
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_29
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_29/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_29/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_29/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_29/test_labels.txt

📊 Raw data loaded:
   Train: X=(2503, 24), y=(2503,)
   Test:  X=(626, 24), y=(626,)

⚠️  Limiting training data: 2503 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  617 samples, 5 features
✅ Client client_29 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

📊 Round 0 Test Metrics:
   Loss: 0.0827, RMSE: 0.2875, MAE: 0.2499, R²: -0.0087

============================================================
🔄 Round 5 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0764 (↓), lr=0.001000
   • Epoch   2/100: train=0.0841, val=0.0774, patience=1/15, lr=0.001000
   • Epoch   3/100: train=0.0834, val=0.0779, patience=2/15, lr=0.001000
   • Epoch   4/100: train=0.0829, val=0.0785, patience=3/15, lr=0.001000
   • Epoch   5/100: train=0.0824, val=0.0789, patience=4/15, lr=0.001000
   📉 Epoch 7: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0791, val=0.0793, patience=10/15, lr=0.000500
   📉 Epoch 15: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0764)

============================================================
📊 Round 5 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=0.0141
   Val:   Loss=0.0764, RMSE=0.2764, R²=-0.0015
============================================================


📊 Round 5 Test Metrics:
   Loss: 0.0833, RMSE: 0.2886, MAE: 0.2502, R²: -0.0163

============================================================
🔄 Round 13 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0911 (↓), lr=0.000250
   ✓ Epoch   2/100: train=0.0826, val=0.0894 (↓), lr=0.000250
   • Epoch   3/100: train=0.0818, val=0.0892, patience=1/15, lr=0.000250
   • Epoch   4/100: train=0.0815, val=0.0889, patience=2/15, lr=0.000250
   ✓ Epoch   5/100: train=0.0812, val=0.0887 (↓), lr=0.000250
   📉 Epoch 7: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0798, val=0.0880, patience=3/15, lr=0.000125
   📉 Epoch 15: LR reduced 0.000125 → 0.000063
   • Epoch  21/100: train=0.0790, val=0.0878, patience=13/15, lr=0.000063
   📉 Epoch 23: LR reduced 0.000063 → 0.000031

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0882)

============================================================
📊 Round 13 Summary - Client client_29
   Epochs: 23/100 (early stopped)
   LR: 0.000250 → 0.000031 (3 reductions)
   Train: Loss=0.0794, RMSE=0.2818, R²=0.0294
   Val:   Loss=0.0882, RMSE=0.2969, R²=0.0072
============================================================


📊 Round 13 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2508, R²: -0.0210

📊 Round 13 Test Metrics:
   Loss: 0.0835, RMSE: 0.2889, MAE: 0.2506, R²: -0.0188

📊 Round 13 Test Metrics:
   Loss: 0.0834, RMSE: 0.2888, MAE: 0.2505, R²: -0.0180

============================================================
🔄 Round 16 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000031
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0853 (↓), lr=0.000031
   • Epoch   2/100: train=0.0836, val=0.0853, patience=1/15, lr=0.000031
   • Epoch   3/100: train=0.0834, val=0.0852, patience=2/15, lr=0.000031
   • Epoch   4/100: train=0.0832, val=0.0851, patience=3/15, lr=0.000031
   • Epoch   5/100: train=0.0830, val=0.0850, patience=4/15, lr=0.000031
   📉 Epoch 8: LR reduced 0.000031 → 0.000016
   • Epoch  11/100: train=0.0819, val=0.0842, patience=1/15, lr=0.000016
   📉 Epoch 16: LR reduced 0.000016 → 0.000008
   • Epoch  21/100: train=0.0814, val=0.0837, patience=3/15, lr=0.000008
   📉 Epoch 24: LR reduced 0.000008 → 0.000004
   • Epoch  31/100: train=0.0813, val=0.0835, patience=13/15, lr=0.000004
   📉 Epoch 32: LR reduced 0.000004 → 0.000002

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 16 Summary - Client client_29
   Epochs: 33/100 (early stopped)
   LR: 0.000031 → 0.000002 (4 reductions)
   Train: Loss=0.0815, RMSE=0.2854, R²=0.0226
   Val:   Loss=0.0838, RMSE=0.2894, R²=-0.0165
============================================================


============================================================
🔄 Round 17 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000002
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0844 (↓), lr=0.000002
   • Epoch   2/100: train=0.0840, val=0.0844, patience=1/15, lr=0.000002
   • Epoch   3/100: train=0.0840, val=0.0843, patience=2/15, lr=0.000002
   • Epoch   4/100: train=0.0840, val=0.0843, patience=3/15, lr=0.000002
   • Epoch   5/100: train=0.0840, val=0.0843, patience=4/15, lr=0.000002
   📉 Epoch 7: LR reduced 0.000002 → 0.000001
   • Epoch  11/100: train=0.0839, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 17 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000002 → 0.000001 (1 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=-0.0158
   Val:   Loss=0.0844, RMSE=0.2904, R²=0.0137
============================================================


============================================================
🔄 Round 18 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0966 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0966, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0966, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0966, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0966, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0966, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0966)

============================================================
📊 Round 18 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=-0.0101
   Val:   Loss=0.0966, RMSE=0.3109, R²=-0.0115
============================================================


============================================================
🔄 Round 19 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 19 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2918, R²=-0.0106
   Val:   Loss=0.0796, RMSE=0.2821, R²=-0.0247
============================================================


============================================================
🔄 Round 20 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 20 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=-0.0072
   Val:   Loss=0.0835, RMSE=0.2890, R²=-0.0293
============================================================


📊 Round 20 Test Metrics:
   Loss: 0.0833, RMSE: 0.2886, MAE: 0.2502, R²: -0.0164

📊 Round 20 Test Metrics:
   Loss: 0.0832, RMSE: 0.2885, MAE: 0.2501, R²: -0.0155

📊 Round 20 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2500, R²: -0.0153

============================================================
🔄 Round 26 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0736 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0736, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0736, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0736, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0736, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0736, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0736)

============================================================
📊 Round 26 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2943, R²=-0.0167
   Val:   Loss=0.0736, RMSE=0.2714, R²=0.0245
============================================================


============================================================
🔄 Round 27 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 27 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=-0.0128
   Val:   Loss=0.0842, RMSE=0.2901, R²=0.0036
============================================================


📊 Round 27 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2500, R²: -0.0151

📊 Round 27 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2500, R²: -0.0151

📊 Round 27 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2500, R²: -0.0151

📊 Round 27 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2500, R²: -0.0151

============================================================
🔄 Round 35 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0875 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0875, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0875, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0875, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0875, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0875, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0875)

============================================================
📊 Round 35 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=0.0059
   Val:   Loss=0.0875, RMSE=0.2958, R²=-0.0686
============================================================


📊 Round 35 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2500, R²: -0.0151

📊 Round 35 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2500, R²: -0.0150

============================================================
🔄 Round 39 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0878 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0878, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0878, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0878, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0878, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0877, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0878)

============================================================
📊 Round 39 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2882, R²=-0.0113
   Val:   Loss=0.0878, RMSE=0.2963, R²=0.0001
============================================================


============================================================
🔄 Round 40 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0927 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0927, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0927, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0927, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0927, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0927, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0927)

============================================================
📊 Round 40 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=-0.0054
   Val:   Loss=0.0927, RMSE=0.3045, R²=-0.0272
============================================================


============================================================
🔄 Round 42 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 42 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2915, R²=-0.0031
   Val:   Loss=0.0801, RMSE=0.2830, R²=-0.0371
============================================================


📊 Round 42 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2500, R²: -0.0150

============================================================
🔄 Round 44 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 44 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=-0.0104
   Val:   Loss=0.0857, RMSE=0.2928, R²=-0.0496
============================================================


📊 Round 44 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2500, R²: -0.0150

📊 Round 44 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2500, R²: -0.0149

📊 Round 44 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2500, R²: -0.0148

============================================================
🔄 Round 48 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0902 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0902, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0902, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0902, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0902, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0903, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0902)

============================================================
📊 Round 48 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=-0.0059
   Val:   Loss=0.0902, RMSE=0.3003, R²=-0.0384
============================================================


📊 Round 48 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2500, R²: -0.0148

============================================================
🔄 Round 49 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0753 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0753, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0753, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0753, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0753, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0753, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0753)

============================================================
📊 Round 49 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2936, R²=-0.0146
   Val:   Loss=0.0753, RMSE=0.2744, R²=0.0116
============================================================


📊 Round 49 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2500, R²: -0.0148

📊 Round 49 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2500, R²: -0.0148

============================================================
🔄 Round 51 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0756 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0756, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0756, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0756, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0756, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0756, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0756)

============================================================
📊 Round 51 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2934, R²=-0.0006
   Val:   Loss=0.0756, RMSE=0.2750, R²=-0.0484
============================================================


📊 Round 51 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2500, R²: -0.0148

============================================================
🔄 Round 52 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 52 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=-0.0173
   Val:   Loss=0.0814, RMSE=0.2853, R²=0.0092
============================================================


============================================================
🔄 Round 53 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 53 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2923, R²=-0.0140
   Val:   Loss=0.0783, RMSE=0.2798, R²=0.0143
============================================================


📊 Round 53 Test Metrics:
   Loss: 0.0831, RMSE: 0.2884, MAE: 0.2500, R²: -0.0146

============================================================
🔄 Round 56 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 56 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2896, R²=-0.0027
   Val:   Loss=0.0846, RMSE=0.2908, R²=-0.0538
============================================================


📊 Round 56 Test Metrics:
   Loss: 0.0831, RMSE: 0.2883, MAE: 0.2499, R²: -0.0145

============================================================
🔄 Round 59 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 59 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=-0.0074
   Val:   Loss=0.0851, RMSE=0.2918, R²=-0.0167
============================================================


============================================================
🔄 Round 61 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0758 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0758, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0758, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0758, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0758, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0758, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0758)

============================================================
📊 Round 61 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2933, R²=-0.0062
   Val:   Loss=0.0758, RMSE=0.2753, R²=-0.0227
============================================================


📊 Round 61 Test Metrics:
   Loss: 0.0831, RMSE: 0.2883, MAE: 0.2499, R²: -0.0144

============================================================
🔄 Round 63 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 63 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=0.0004
   Val:   Loss=0.0852, RMSE=0.2918, R²=-0.0479
============================================================


============================================================
🔄 Round 64 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0768 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0768, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0768, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0768, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0768, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0768, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0768)

============================================================
📊 Round 64 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2929, R²=-0.0134
   Val:   Loss=0.0768, RMSE=0.2772, R²=0.0111
============================================================


📊 Round 64 Test Metrics:
   Loss: 0.0831, RMSE: 0.2883, MAE: 0.2500, R²: -0.0145

============================================================
🔄 Round 70 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0869, val=0.0726 (↓), lr=0.000001
   • Epoch   2/100: train=0.0869, val=0.0726, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0869, val=0.0726, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0869, val=0.0726, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0869, val=0.0726, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0869, val=0.0725, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0726)

============================================================
📊 Round 70 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2947, R²=-0.0111
   Val:   Loss=0.0726, RMSE=0.2694, R²=0.0034
============================================================


📊 Round 70 Test Metrics:
   Loss: 0.0831, RMSE: 0.2883, MAE: 0.2499, R²: -0.0144

============================================================
🔄 Round 72 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 72 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=-0.0115
   Val:   Loss=0.0806, RMSE=0.2840, R²=-0.0012
============================================================


📊 Round 72 Test Metrics:
   Loss: 0.0831, RMSE: 0.2883, MAE: 0.2499, R²: -0.0145

============================================================
🔄 Round 74 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0874, val=0.0702 (↓), lr=0.000001
   • Epoch   2/100: train=0.0873, val=0.0702, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0873, val=0.0702, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0873, val=0.0702, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0873, val=0.0702, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0873, val=0.0702, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0702)

============================================================
📊 Round 74 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0874, RMSE=0.2957, R²=-0.0099
   Val:   Loss=0.0702, RMSE=0.2650, R²=-0.0075
============================================================


📊 Round 74 Test Metrics:
   Loss: 0.0831, RMSE: 0.2883, MAE: 0.2499, R²: -0.0144

============================================================
🔄 Round 75 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 75 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=-0.0044
   Val:   Loss=0.0862, RMSE=0.2937, R²=-0.0244
============================================================


📊 Round 75 Test Metrics:
   Loss: 0.0831, RMSE: 0.2883, MAE: 0.2499, R²: -0.0144

============================================================
🔄 Round 78 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0926 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0926, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0926, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0926, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0926, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0925, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0926)

============================================================
📊 Round 78 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2861, R²=-0.0036
   Val:   Loss=0.0926, RMSE=0.3043, R²=-0.0352
============================================================


============================================================
🔄 Round 79 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0961 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0961, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0961, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0961, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0961, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0961, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0961)

============================================================
📊 Round 79 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2845, R²=0.0010
   Val:   Loss=0.0961, RMSE=0.3100, R²=-0.0567
============================================================


📊 Round 79 Test Metrics:
   Loss: 0.0831, RMSE: 0.2883, MAE: 0.2499, R²: -0.0144

============================================================
🔄 Round 80 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 80 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=-0.0145
   Val:   Loss=0.0813, RMSE=0.2851, R²=0.0021
============================================================


📊 Round 80 Test Metrics:
   Loss: 0.0831, RMSE: 0.2883, MAE: 0.2499, R²: -0.0143

📊 Round 80 Test Metrics:
   Loss: 0.0831, RMSE: 0.2883, MAE: 0.2499, R²: -0.0142

============================================================
🔄 Round 88 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0936 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0936, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0935, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0935, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0935, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0935, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0936)

============================================================
📊 Round 88 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=-0.0011
   Val:   Loss=0.0936, RMSE=0.3059, R²=-0.0362
============================================================


📊 Round 88 Test Metrics:
   Loss: 0.0831, RMSE: 0.2883, MAE: 0.2499, R²: -0.0142

============================================================
🔄 Round 91 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 91 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=-0.0104
   Val:   Loss=0.0813, RMSE=0.2851, R²=-0.0072
============================================================


============================================================
🔄 Round 93 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0907 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0907, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0907, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0907, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0907, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0906, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0907)

============================================================
📊 Round 93 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=0.0031
   Val:   Loss=0.0907, RMSE=0.3011, R²=-0.0519
============================================================


📊 Round 93 Test Metrics:
   Loss: 0.0831, RMSE: 0.2883, MAE: 0.2499, R²: -0.0141

============================================================
🔄 Round 94 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 94 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2916, R²=-0.0088
   Val:   Loss=0.0797, RMSE=0.2824, R²=-0.0061
============================================================


📊 Round 94 Test Metrics:
   Loss: 0.0831, RMSE: 0.2883, MAE: 0.2499, R²: -0.0141

============================================================
🔄 Round 95 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0922 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0922, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0922, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0922, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0922, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0921, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0922)

============================================================
📊 Round 95 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=-0.0091
   Val:   Loss=0.0922, RMSE=0.3036, R²=-0.0066
============================================================


📊 Round 95 Test Metrics:
   Loss: 0.0831, RMSE: 0.2883, MAE: 0.2499, R²: -0.0141

📊 Round 95 Test Metrics:
   Loss: 0.0831, RMSE: 0.2883, MAE: 0.2499, R²: -0.0141

============================================================
🔄 Round 98 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 98 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2918, R²=-0.0084
   Val:   Loss=0.0793, RMSE=0.2815, R²=-0.0252
============================================================


============================================================
🔄 Round 99 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 99 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2915, R²=-0.0066
   Val:   Loss=0.0801, RMSE=0.2829, R²=-0.0237
============================================================


📊 Round 99 Test Metrics:
   Loss: 0.0831, RMSE: 0.2883, MAE: 0.2499, R²: -0.0141

============================================================
🔄 Round 100 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0878 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0878, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0878, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0878, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0878, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0878, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0878)

============================================================
📊 Round 100 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=-0.0113
   Val:   Loss=0.0878, RMSE=0.2963, R²=-0.0159
============================================================


📊 Round 100 Test Metrics:
   Loss: 0.0831, RMSE: 0.2883, MAE: 0.2499, R²: -0.0141

============================================================
🔄 Round 101 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0769 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0769, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0769, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0769, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0769, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0769, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0769)

============================================================
📊 Round 101 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2928, R²=-0.0124
   Val:   Loss=0.0769, RMSE=0.2774, R²=-0.0010
============================================================


📊 Round 101 Test Metrics:
   Loss: 0.0831, RMSE: 0.2883, MAE: 0.2499, R²: -0.0141

📊 Round 101 Test Metrics:
   Loss: 0.0831, RMSE: 0.2883, MAE: 0.2499, R²: -0.0141

📊 Round 101 Test Metrics:
   Loss: 0.0831, RMSE: 0.2883, MAE: 0.2499, R²: -0.0141

============================================================
🔄 Round 105 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0776 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0776, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0776, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0776, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0776, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 105 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2925, R²=-0.0027
   Val:   Loss=0.0776, RMSE=0.2786, R²=-0.0352
============================================================


============================================================
🔄 Round 108 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0875 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0875, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0875, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0875, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0875, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0874, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0875)

============================================================
📊 Round 108 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2882, R²=-0.0033
   Val:   Loss=0.0875, RMSE=0.2958, R²=-0.0354
============================================================


📊 Round 108 Test Metrics:
   Loss: 0.0831, RMSE: 0.2883, MAE: 0.2499, R²: -0.0141

============================================================
🔄 Round 109 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0867 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0867, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0867, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0867, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0867, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 109 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=-0.0090
   Val:   Loss=0.0867, RMSE=0.2945, R²=-0.0104
============================================================


📊 Round 109 Test Metrics:
   Loss: 0.0831, RMSE: 0.2883, MAE: 0.2499, R²: -0.0141

📊 Round 109 Test Metrics:
   Loss: 0.0831, RMSE: 0.2883, MAE: 0.2499, R²: -0.0140

============================================================
🔄 Round 112 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0884 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0884, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0884, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0884, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0884, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0884, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0884)

============================================================
📊 Round 112 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=-0.0087
   Val:   Loss=0.0884, RMSE=0.2973, R²=-0.0176
============================================================


📊 Round 112 Test Metrics:
   Loss: 0.0831, RMSE: 0.2883, MAE: 0.2499, R²: -0.0140

============================================================
🔄 Round 114 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 114 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2887, R²=-0.0029
   Val:   Loss=0.0864, RMSE=0.2939, R²=-0.0328
============================================================


📊 Round 114 Test Metrics:
   Loss: 0.0831, RMSE: 0.2883, MAE: 0.2499, R²: -0.0140

============================================================
🔄 Round 115 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 115 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=-0.0106
   Val:   Loss=0.0818, RMSE=0.2861, R²=-0.0110
============================================================


📊 Round 115 Test Metrics:
   Loss: 0.0831, RMSE: 0.2883, MAE: 0.2499, R²: -0.0140

📊 Round 115 Test Metrics:
   Loss: 0.0831, RMSE: 0.2883, MAE: 0.2499, R²: -0.0140

============================================================
🔄 Round 119 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0759 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0759, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0759, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0759, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0759, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0758, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0759)

============================================================
📊 Round 119 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2932, R²=-0.0151
   Val:   Loss=0.0759, RMSE=0.2755, R²=0.0185
============================================================


============================================================
🔄 Round 120 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 120 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=-0.0016
   Val:   Loss=0.0827, RMSE=0.2876, R²=-0.0388
============================================================


============================================================
🔄 Round 122 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0913 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0913, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0913, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0913, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0913, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0913, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0913)

============================================================
📊 Round 122 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2866, R²=-0.0145
   Val:   Loss=0.0913, RMSE=0.3022, R²=-0.0121
============================================================


📊 Round 122 Test Metrics:
   Loss: 0.0831, RMSE: 0.2883, MAE: 0.2499, R²: -0.0140

============================================================
🔄 Round 127 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 127 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=-0.0058
   Val:   Loss=0.0823, RMSE=0.2869, R²=-0.0197
============================================================


============================================================
🔄 Round 130 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 130 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2906, R²=-0.0115
   Val:   Loss=0.0821, RMSE=0.2865, R²=0.0054
============================================================


📊 Round 130 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2498, R²: -0.0136

============================================================
🔄 Round 131 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0886 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0886, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0886, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0886, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0886, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0886, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0886)

============================================================
📊 Round 131 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=-0.0098
   Val:   Loss=0.0886, RMSE=0.2976, R²=-0.0113
============================================================


============================================================
🔄 Round 132 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 132 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=-0.0089
   Val:   Loss=0.0807, RMSE=0.2841, R²=-0.0220
============================================================


📊 Round 132 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2498, R²: -0.0136

============================================================
🔄 Round 133 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 133 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=0.0030
   Val:   Loss=0.0811, RMSE=0.2848, R²=-0.0573
============================================================


📊 Round 133 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2498, R²: -0.0135

📊 Round 133 Test Metrics:
   Loss: 0.0830, RMSE: 0.2882, MAE: 0.2498, R²: -0.0133

============================================================
🔄 Round 137 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0905 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0905, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0905, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0905, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0905, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0904, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0905)

============================================================
📊 Round 137 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=0.0005
   Val:   Loss=0.0905, RMSE=0.3008, R²=-0.0409
============================================================


============================================================
🔄 Round 138 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0868 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0868, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0868, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0868, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0868, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0868, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0868)

============================================================
📊 Round 138 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=-0.0040
   Val:   Loss=0.0868, RMSE=0.2946, R²=-0.0264
============================================================


📊 Round 138 Test Metrics:
   Loss: 0.0830, RMSE: 0.2882, MAE: 0.2498, R²: -0.0134

📊 Round 138 Test Metrics:
   Loss: 0.0830, RMSE: 0.2882, MAE: 0.2498, R²: -0.0134

============================================================
🔄 Round 141 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 141 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2915, R²=-0.0136
   Val:   Loss=0.0799, RMSE=0.2827, R²=0.0042
============================================================


============================================================
🔄 Round 142 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 142 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=-0.0112
   Val:   Loss=0.0854, RMSE=0.2922, R²=-0.0261
============================================================


📊 Round 142 Test Metrics:
   Loss: 0.0830, RMSE: 0.2882, MAE: 0.2498, R²: -0.0134

📊 Round 142 Test Metrics:
   Loss: 0.0830, RMSE: 0.2882, MAE: 0.2498, R²: -0.0134

📊 Round 142 Test Metrics:
   Loss: 0.0830, RMSE: 0.2882, MAE: 0.2498, R²: -0.0134

📊 Round 142 Test Metrics:
   Loss: 0.0830, RMSE: 0.2882, MAE: 0.2498, R²: -0.0134

============================================================
🔄 Round 148 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 148 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2894, R²=-0.0141
   Val:   Loss=0.0847, RMSE=0.2910, R²=0.0142
============================================================


============================================================
🔄 Round 150 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 150 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=-0.0014
   Val:   Loss=0.0818, RMSE=0.2860, R²=-0.0395
============================================================


============================================================
🔄 Round 151 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 151 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2904, R²=-0.0137
   Val:   Loss=0.0823, RMSE=0.2870, R²=-0.0047
============================================================


============================================================
🔄 Round 153 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 153 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2904, R²=-0.0118
   Val:   Loss=0.0825, RMSE=0.2872, R²=0.0067
============================================================


📊 Round 153 Test Metrics:
   Loss: 0.0830, RMSE: 0.2882, MAE: 0.2498, R²: -0.0132

============================================================
🔄 Round 157 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0895 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0895, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0895, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0895, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0895, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0895, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0895)

============================================================
📊 Round 157 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2873, R²=-0.0081
   Val:   Loss=0.0895, RMSE=0.2992, R²=-0.0070
============================================================


📊 Round 157 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2498, R²: -0.0132

📊 Round 157 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2498, R²: -0.0132

============================================================
🔄 Round 159 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0732 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0732, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0732, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0732, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0732, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0732, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0732)

============================================================
📊 Round 159 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2943, R²=-0.0134
   Val:   Loss=0.0732, RMSE=0.2706, R²=0.0177
============================================================


============================================================
🔄 Round 160 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0865 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0866, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0866, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0866, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0866, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0866, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0865)

============================================================
📊 Round 160 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=-0.0066
   Val:   Loss=0.0865, RMSE=0.2942, R²=-0.0284
============================================================


📊 Round 160 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2498, R²: -0.0130

============================================================
🔄 Round 162 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0744 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0744, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0744, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0744, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0744, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0745, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0744)

============================================================
📊 Round 162 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2938, R²=-0.0087
   Val:   Loss=0.0744, RMSE=0.2728, R²=-0.0222
============================================================


📊 Round 162 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2498, R²: -0.0130

📊 Round 162 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2498, R²: -0.0130

📊 Round 162 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2498, R²: -0.0129

📊 Round 162 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2498, R²: -0.0129

📊 Round 162 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2497, R²: -0.0128

📊 Round 162 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2497, R²: -0.0128

============================================================
🔄 Round 172 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 172 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=-0.0051
   Val:   Loss=0.0844, RMSE=0.2906, R²=-0.0191
============================================================


============================================================
🔄 Round 173 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0884 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0884, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0884, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0884, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0884, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0884, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0884)

============================================================
📊 Round 173 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=-0.0010
   Val:   Loss=0.0884, RMSE=0.2974, R²=-0.0334
============================================================


📊 Round 173 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2497, R²: -0.0128

============================================================
🔄 Round 174 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0888 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0888, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0888, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0888, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0888, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0888, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0888)

============================================================
📊 Round 174 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=-0.0038
   Val:   Loss=0.0888, RMSE=0.2979, R²=-0.0508
============================================================


============================================================
🔄 Round 175 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 175 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=-0.0080
   Val:   Loss=0.0854, RMSE=0.2922, R²=-0.0399
============================================================


📊 Round 175 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2497, R²: -0.0128

============================================================
🔄 Round 176 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 176 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=-0.0095
   Val:   Loss=0.0853, RMSE=0.2921, R²=-0.0006
============================================================


============================================================
🔄 Round 177 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 177 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2901, R²=-0.0137
   Val:   Loss=0.0829, RMSE=0.2879, R²=0.0040
============================================================


📊 Round 177 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2497, R²: -0.0127

============================================================
🔄 Round 179 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0892 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0892, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0892, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0892, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0892, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0892, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0892)

============================================================
📊 Round 179 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=-0.0109
   Val:   Loss=0.0892, RMSE=0.2987, R²=0.0020
============================================================


📊 Round 179 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2497, R²: -0.0126

============================================================
🔄 Round 180 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0886 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0886, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0886, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0886, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0886, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0885, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0886)

============================================================
📊 Round 180 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=-0.0138
   Val:   Loss=0.0886, RMSE=0.2976, R²=0.0111
============================================================


📊 Round 180 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2497, R²: -0.0125

============================================================
🔄 Round 181 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 181 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2922, R²=-0.0086
   Val:   Loss=0.0781, RMSE=0.2795, R²=-0.0148
============================================================


📊 Round 181 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2497, R²: -0.0125

============================================================
🔄 Round 183 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 183 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2899, R²=-0.0082
   Val:   Loss=0.0833, RMSE=0.2887, R²=-0.0073
============================================================


📊 Round 183 Test Metrics:
   Loss: 0.0830, RMSE: 0.2881, MAE: 0.2497, R²: -0.0125

============================================================
🔄 Round 184 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 184 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=-0.0102
   Val:   Loss=0.0832, RMSE=0.2884, R²=-0.0109
============================================================


============================================================
🔄 Round 185 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0877 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0877, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0877, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0876, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0876, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0876, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0877)

============================================================
📊 Round 185 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=-0.0145
   Val:   Loss=0.0877, RMSE=0.2961, R²=0.0178
============================================================


📊 Round 185 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2497, R²: -0.0122

============================================================
🔄 Round 188 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 188 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=-0.0005
   Val:   Loss=0.0815, RMSE=0.2854, R²=-0.0393
============================================================


============================================================
🔄 Round 189 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0741 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0741, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0741, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0741, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0741, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0740, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0741)

============================================================
📊 Round 189 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2939, R²=-0.0068
   Val:   Loss=0.0741, RMSE=0.2723, R²=-0.0174
============================================================


📊 Round 189 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2497, R²: -0.0121

📊 Round 189 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2497, R²: -0.0121

📊 Round 189 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2497, R²: -0.0121

============================================================
🔄 Round 196 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0867 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0867, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0867, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0867, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0866, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 196 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=-0.0066
   Val:   Loss=0.0867, RMSE=0.2945, R²=-0.0117
============================================================


============================================================
🔄 Round 197 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 197 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2919, R²=-0.0074
   Val:   Loss=0.0786, RMSE=0.2804, R²=-0.0150
============================================================


============================================================
🔄 Round 199 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0870, val=0.0718 (↓), lr=0.000001
   • Epoch   2/100: train=0.0869, val=0.0718, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0869, val=0.0718, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0869, val=0.0718, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0869, val=0.0718, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0868, val=0.0718, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0718)

============================================================
📊 Round 199 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0869, RMSE=0.2948, R²=-0.0176
   Val:   Loss=0.0718, RMSE=0.2679, R²=0.0210
============================================================


📊 Round 199 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2497, R²: -0.0120

📊 Round 199 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2496, R²: -0.0119

============================================================
🔄 Round 202 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 202 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=-0.0065
   Val:   Loss=0.0820, RMSE=0.2863, R²=-0.0213
============================================================


📊 Round 202 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2496, R²: -0.0118

📊 Round 202 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2496, R²: -0.0118

============================================================
🔄 Round 205 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 205 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2906, R²=-0.0185
   Val:   Loss=0.0817, RMSE=0.2858, R²=0.0155
============================================================


📊 Round 205 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2496, R²: -0.0118

📊 Round 205 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2496, R²: -0.0118

============================================================
🔄 Round 207 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 207 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2887, R²=-0.0093
   Val:   Loss=0.0861, RMSE=0.2934, R²=-0.0094
============================================================


============================================================
🔄 Round 211 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 211 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=-0.0136
   Val:   Loss=0.0827, RMSE=0.2876, R²=0.0172
============================================================


============================================================
🔄 Round 212 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0882 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0882, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0882, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0882, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0881, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0881, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0882)

============================================================
📊 Round 212 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=-0.0058
   Val:   Loss=0.0882, RMSE=0.2969, R²=-0.0132
============================================================


📊 Round 212 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2496, R²: -0.0118

📊 Round 212 Test Metrics:
   Loss: 0.0829, RMSE: 0.2880, MAE: 0.2496, R²: -0.0118

📊 Round 212 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2496, R²: -0.0117

============================================================
🔄 Round 217 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0737 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0737, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0737, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0737, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0737, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0736, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0737)

============================================================
📊 Round 217 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2940, R²=-0.0125
   Val:   Loss=0.0737, RMSE=0.2714, R²=0.0155
============================================================


📊 Round 217 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2496, R²: -0.0115

============================================================
🔄 Round 218 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 218 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=-0.0116
   Val:   Loss=0.0839, RMSE=0.2896, R²=0.0078
============================================================


============================================================
🔄 Round 220 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0894 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0894, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0894, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0894, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0894, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0893, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0894)

============================================================
📊 Round 220 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=-0.0059
   Val:   Loss=0.0894, RMSE=0.2991, R²=-0.0140
============================================================


============================================================
🔄 Round 221 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 221 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2896, R²=-0.0121
   Val:   Loss=0.0839, RMSE=0.2897, R²=0.0020
============================================================


============================================================
🔄 Round 222 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0893 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0893, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0893, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0893, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0893, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0892, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0893)

============================================================
📊 Round 222 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2873, R²=-0.0098
   Val:   Loss=0.0893, RMSE=0.2988, R²=-0.0021
============================================================


📊 Round 222 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2496, R²: -0.0116

============================================================
🔄 Round 223 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0768 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0768, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0768, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0768, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0768, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0767, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0768)

============================================================
📊 Round 223 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2927, R²=-0.0138
   Val:   Loss=0.0768, RMSE=0.2771, R²=0.0133
============================================================


📊 Round 223 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2496, R²: -0.0116

============================================================
🔄 Round 224 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 224 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=-0.0041
   Val:   Loss=0.0803, RMSE=0.2834, R²=-0.0214
============================================================


============================================================
🔄 Round 225 - Client client_29
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 225 Summary - Client client_29
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=-0.0009
   Val:   Loss=0.0814, RMSE=0.2853, R²=-0.0347
============================================================


❌ Client client_29 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "recvmsg:Connection reset by peer"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8687 {grpc_status:14, grpc_message:"recvmsg:Connection reset by peer"}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "recvmsg:Connection reset by peer"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8687 {grpc_status:14, grpc_message:"recvmsg:Connection reset by peer"}"
>
