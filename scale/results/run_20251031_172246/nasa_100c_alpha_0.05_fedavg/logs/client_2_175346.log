[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 14818a0c-f9e9-4b19-b4f4-f2e5166f42d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dd3da273-c135-4531-a73a-ab4af0e71ef7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 874227c0-1db5-4925-8047-e28294874b00
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e0540f0a-a8f8-4193-b89f-6a6ecfa5a070
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cf9587bc-9fbd-42c2-972e-4c5de7045920
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 69717de5-8a53-4da0-a3af-4ccdb70c99a3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7ef45609-a932-4608-ae17-b90bc7e2726c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bb444a30-4f50-4442-b329-2dad413b07ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c586b6e8-7478-430d-a21e-0fa22b4f369b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0a73f19f-6214-45f9-a2f8-a813ee73ed76
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7cf66985-0e30-4649-9395-517d8d3aa03b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 53c81fbc-9298-4b7a-85ac-66049204fac3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 15a11e37-225f-4341-b3ef-20987ef5bf8c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c7a76854-4dfb-45d8-bba2-7f4d59646d32
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 964d81ee-c118-4d2b-bbd7-505b2a2c4ed9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cbbf51a5-34a0-4305-8275-c5a895a81c0c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2a10f359-d345-4d7b-a0f0-a623d413cfd8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 49a74c1e-5390-4b40-a27a-3062f43c1e8e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message afb51faa-c6fc-4506-aa60-c0a1320495d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 25570eb1-40d4-439f-8f81-afb058c8812c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 94817d22-fcf6-4c91-b0fe-205d45e84cdc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b04c544d-7248-4a8b-9d41-eb44d329611b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 450b475d-7595-4de4-ba40-88d0240d06fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 52ec8aaa-c067-4e00-ad46-2e92eaa2957d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 58445867-687b-49f5-9e1b-520a55296059
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7ee1dd61-e686-42e2-8b88-163e61c843c5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d537d07e-7ac1-4d3d-b4b0-cc8fad2031e1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 25bab9a4-12d1-476e-a1ac-06bd2a505058
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e8cd2902-a015-43ad-a2a8-ff91a1facbfd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b1501aa0-1634-4168-9373-4cb7e2afbff5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3f17a818-076b-4624-b9ab-d60d0ce5cbb5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 403a2213-a3fd-4f25-906d-2f073fdf9b1e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7d424793-372f-4225-b268-46bfc18002be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4f620ea2-34ea-4630-94bf-c7891a2353bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a6e97839-758f-4c1c-ab0c-87a2b7b00af3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cb73a792-cd0b-41fd-a130-d6cbe32c3d04
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4557bf5b-d82e-410f-a2b4-47c0b068a895
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6b04ae76-dd9a-43dd-b904-25db8bfbd56d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eb5656c7-1113-4384-a8ae-18da0500b5c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9e977ecb-57ae-4dfb-bd8a-e1a2524acab0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b158c772-9337-4ba3-8c4e-8c780bd91744
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5536bc8b-789c-45e4-83f9-37aec783fb0a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9a1b823c-fd3d-444b-892e-460b2aa6fa0c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5c63ed74-8e0e-4cbd-8805-de67532b7afe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c7a42d4e-729e-4443-bae4-e5e1db87884f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1a7db29f-9964-4ae9-9d0c-cf00c9e71245
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8a04eb79-250c-4d06-a874-1747ec726c3a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1e26b280-dd13-4e33-92d4-d985185d0aec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 89218d59-a52e-4e50-9130-bfe59d13e1ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9f414870-5844-4a2c-9b03-c8bcd5e3c942
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 799c48ec-6f1c-4edb-9d4b-396be558e8f4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 21e782ac-78e0-46ce-8472-1403a85e6327
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 159f1fea-7890-419c-90e0-3d440631e69a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dc968c02-0ee7-43d9-9e9a-035735679694
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8e438b28-874d-41a8-9eb9-da5c0c76d89d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 76b28720-5380-49b4-add8-eff84567412d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 77130f8f-425b-4d7e-ab0d-8860daf00479
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 23f7f347-c275-4696-a841-75b01025d143
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a9d615cb-ff5a-435a-b1b4-c77a45918936
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ba0d34ec-5b83-4c08-9570-e31a63b3244c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1e57fd03-0c12-4a13-a606-6799e85d66a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f4093238-1d97-410d-9be2-2cd61281bd06
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3932770a-77f5-4668-814b-c0c45837f991
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6fe0de9d-73d0-41d2-ae2d-adea2fc940ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a283feac-693e-4552-976b-6997751a6d19
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 08fcd2e4-c847-4fbd-b097-36f54b419fba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f11f2ae5-6742-4512-bf0c-ccf9487a4fba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 878ab289-259c-42e7-8f7b-1118349a632a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0403cc6f-d68c-4c01-a6fa-f66b00b847e8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1544ebfe-6078-4831-b5b9-7956cd25c478
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 65cab3af-4809-463e-9a36-2e07051051bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 81cf810a-ed89-4f43-99b5-be40d5e7405e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 170ada81-4e28-4011-a3bc-872a645ec2e8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 672fa4b1-694c-4e63-a392-7bdc34573a6e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 81fdfe81-13e0-4031-9aff-43e2fa16fd49
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ed25c4ce-5598-4e02-9cbb-29023c154aaa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fca7ac2b-36c3-4c71-9a3c-f32c0bc6c411
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e8b747ab-f701-46dd-91d0-668fea76eb6b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 36396af2-44ad-421d-94b6-cdf5ecfe02f9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 222debe1-b55a-40f6-92c2-914eec367612
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cdf1c4ad-fcd4-4ee6-8ae1-c5bdc54bd439
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 96b4151d-6cb1-47b0-bf39-53d40791a146
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 530244e6-fb55-400f-8530-35fa0f4d41a8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 613a5528-9015-4c10-991a-6752bdd1d5ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e15f1b1d-01ff-49b6-8461-25109ccdaaba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d4de08cc-2580-4842-8269-3ab62b20960e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e3c7c797-ac5c-4bd8-98d3-0d13111ac710
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9177258f-9b6d-42d0-a65a-2e2e0ea1d21e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2d2d5e07-a545-41ed-8cb0-545159b3cecb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c50b4ea8-447a-4ac6-8e90-a24a00c94f9c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e2856641-8899-4e68-830b-10d67f95a2e8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 51e6e2d1-d6bb-4bb2-965e-55aac944f9f6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 62ef5e2e-3da6-4459-b9d8-e52dce72c20f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8bb1881e-3ffc-4cb6-9878-da1da00e0bec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d77375c2-1c3f-46e0-8f47-3e5b30dc6a24
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 23706ddb-5536-458f-a370-a25782cd4876
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fefbee95-89be-466b-b109-3bf9eb680d07
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ac118250-c866-455c-8a33-7129ca8d6a65
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 334591dc-004f-435d-97c9-cf470220cc7e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ba4323aa-5d96-409e-a660-48f66f901ae6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 270a2237-63f6-43dc-9e8e-152c6a59ae3b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6fa27518-2f40-4e67-bc08-8ccb6b490be1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3f813d1f-2086-47a1-b240-979bc38c5f3d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 30a698d0-99e2-48a3-b07c-de46432e5e94
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c93c5a1a-1aa7-43e9-bc49-6a85ddc2757a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5ad587bf-b90c-427e-9254-75aae8ec6c99
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d6718a98-3a48-418c-b4c2-d351391bc444
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2e24ebec-5eaa-4d5c-86bc-a7872593273e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 96a157bb-0709-45eb-a609-6183587a9816
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f5c3fb3c-96c7-445b-9778-4f243c225f40
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8351fa01-ab84-4a7f-b2a3-d98f5ccae4b5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d3d52e68-f304-46a8-a907-041652c896d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7b42fb29-1530-4477-a27b-969bfdc0d5e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e8f208d4-f4db-4016-8e22-da967b061a0d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 25f13c3a-4de4-4e4e-9a71-99e831113248
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c7221f0a-6f72-418a-a69d-bb9264a5c448
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c8746e39-d242-427f-94bc-31c3d659a783
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1ba96548-0d89-4638-acd6-4ee684e247a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e0ec6daf-8999-4a2d-9655-e609145b504a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 204a66ca-0aee-48e8-b259-e723785373bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fcc15f7a-9c6c-4aab-98c7-d5570f64d5a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aa4cf395-1209-4618-8d96-06e7f6736991
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f56985dc-2e12-4e5d-b878-6187cbd126ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1fb0ba1d-817f-494f-af6a-0c09fad6559f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fd7dcf7e-3a21-451d-8d1f-3f09c8ceb524
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dad92ac9-90e9-471b-a106-0e6e3bca79d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 57df233d-6295-4664-ba40-989e72c408c9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 48c3b30c-35f4-458f-b90d-c60a2c8735a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d0f12ca6-b1c2-44a4-8a7a-6a78497bb0e6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ff5cf63b-8363-4dfb-8a45-9e2f32733e90
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3757311c-e33f-4d52-82d1-78edfd537d64
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0f915ef5-161e-44b0-948f-319d2de125d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f6ba3bda-ee7d-45aa-90bf-f240e889df7a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cfacff32-c42f-4eeb-8d61-a36b6eee7d1f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 51c657f9-c1c5-4a27-82b6-99fc1dc53b68
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8105ea06-fed2-4201-a5ad-6287733b426b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ba58337a-aa9a-4893-884b-fe46c2e21274
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 030521e1-6a75-4c45-b1de-2d8f1e291751
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0787898b-85e5-417a-ba28-284c97f0577b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9012f162-e576-45d9-b77b-89f7f773d1d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 54703753-77ce-4097-8007-d25e7a5c6e4b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4fe6df52-b8d2-4250-86ca-d692c436e750
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2862045d-877c-4c5c-afa7-42fe6ca7af49
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1171f174-35e6-4534-baac-b2e61c539838
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1afbb8f0-85b8-4d63-9c00-66ab168a142c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 082738c6-9d09-4fbc-829e-0cc52893f3af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a29da0fd-968b-4296-a433-eeb5f8c9663c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e6124510-9ffa-4580-9167-36e1e5513cc5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d1553236-9f22-4782-a499-dc7edc586303
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cd2fac76-3d70-4f89-8f43-6962f318f386
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c84a0ddb-edc5-460a-b8a5-b8c675ead76e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 153f254c-79cf-4b6e-ab3c-f85b6c47e49c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d3f483b6-0267-4f47-878c-90cd4183384b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d2dbe3a7-475d-4d7e-af97-5a8e48fd436d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 962b350d-3ece-4626-b439-2a0abdc9e7d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 69c1eab2-3768-44a6-a039-1cbd40b40ccd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 699baa27-7888-48e7-ab98-5ffdbf3c2b1a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a777da40-1458-4ba4-837f-e37bd399ade5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0aa3a17e-4122-4f85-981d-75d4bcb49ab9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4aac1c7a-3cb9-4a34-adf9-09d433b084ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8cf24300-a452-4e8e-a7ba-b5683ab27c33
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 390c6d83-d400-41fb-a1ac-6d77cff5f607
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 742a154a-f962-4475-8390-e1bc01c7163f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b9b30659-cefa-41da-b525-aed2ed286f87
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8be2c0d1-43d2-417b-904f-04a68ce4a2c4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 76383e3f-eddd-409f-8496-ae1f45773263
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c132cbbc-c6fa-44b0-817d-6cf836f16e06
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9dad084e-b8d6-455b-86bc-213b02e3b7cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3aa60210-37a5-49e5-a3c9-c6880557dae8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c9aa9f8a-6899-46c0-a9b8-63400dbd2cb6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 04b9ce92-2ab7-4112-ae05-957d258bf2cb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message df939d69-76ea-4a6e-b91b-0a57294df5f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6781ca5b-20c3-4652-b1d7-a350ee2cac55
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 28b7685a-afd8-41c8-8e80-8976390852c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b4934046-ab86-4b94-aecc-1ec97277b04a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a5f38abd-ddc7-4801-8d4a-c013cc5f882f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5ed4ac36-01f7-433d-8c8f-5160e7eca395
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9ff66f5f-9432-4e61-82b7-f107f4c9eb57
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c8e46e5d-93db-4638-b76a-da5fdaa96d6d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dd22623b-5f3b-4007-ab5e-8e7f028dbd75
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 775c1133-7186-47ac-b907-ccb2f992c7ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eb1be1d1-6fd9-4304-b40a-12560ed097cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 91da8903-32b2-41a8-86d6-05438ce979b7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2f1bdb61-79f4-4c2f-b1af-234899d04fdc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9e38f9e2-85ab-4350-911d-1d1acdfc3f58
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7a6d7564-aa50-4dd8-b176-0a1a47d5a576
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cd44201e-55af-4b48-a680-b6cf70101b1d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6de4aec9-e807-438e-a6cc-b79993c235b7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1e044e31-3a48-43c7-8e1f-fb8648450ad4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3f693c0a-f908-4732-9b43-509baee009af
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8687 {grpc_message:"Socket closed", grpc_status:14}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_2
Server: localhost:8687
Algorithm: FEDAVG
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_2
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_2/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_2/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_2/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_2/test_labels.txt

📊 Raw data loaded:
   Train: X=(848, 24), y=(848,)
   Test:  X=(212, 24), y=(212,)

⚠️  Limiting training data: 848 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  203 samples, 5 features
✅ Client client_2 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

📊 Round 0 Test Metrics:
   Loss: 0.0723, RMSE: 0.2690, MAE: 0.2290, R²: -0.0168

============================================================
🔄 Round 5 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0928 (↓), lr=0.001000
   • Epoch   2/100: train=0.0871, val=0.0947, patience=1/15, lr=0.001000
   • Epoch   3/100: train=0.0894, val=0.0923, patience=2/15, lr=0.001000
   ✓ Epoch   4/100: train=0.0887, val=0.0914 (↓), lr=0.001000
   • Epoch   5/100: train=0.0864, val=0.0916, patience=1/15, lr=0.001000
   📉 Epoch 10: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0842, val=0.0940, patience=7/15, lr=0.000500
   📉 Epoch 18: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0914)

============================================================
📊 Round 5 Summary - Client client_2
   Epochs: 19/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0846, RMSE=0.2908, R²=0.0123
   Val:   Loss=0.0914, RMSE=0.3023, R²=-0.0089
============================================================


📊 Round 5 Test Metrics:
   Loss: 0.0734, RMSE: 0.2709, MAE: 0.2303, R²: -0.0315

📊 Round 5 Test Metrics:
   Loss: 0.0733, RMSE: 0.2708, MAE: 0.2300, R²: -0.0306

============================================================
🔄 Round 10 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0872, val=0.0908 (↓), lr=0.000250
   • Epoch   2/100: train=0.0863, val=0.0910, patience=1/15, lr=0.000250
   • Epoch   3/100: train=0.0857, val=0.0915, patience=2/15, lr=0.000250
   • Epoch   4/100: train=0.0852, val=0.0920, patience=3/15, lr=0.000250
   • Epoch   5/100: train=0.0848, val=0.0922, patience=4/15, lr=0.000250
   📉 Epoch 7: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0837, val=0.0933, patience=10/15, lr=0.000125
   📉 Epoch 15: LR reduced 0.000125 → 0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0908)

============================================================
📊 Round 10 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000250 → 0.000063 (2 reductions)
   Train: Loss=0.0861, RMSE=0.2934, R²=0.0019
   Val:   Loss=0.0908, RMSE=0.3013, R²=-0.0292
============================================================


📊 Round 10 Test Metrics:
   Loss: 0.0731, RMSE: 0.2703, MAE: 0.2296, R²: -0.0271

============================================================
🔄 Round 13 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0883, val=0.0852 (↓), lr=0.000063
   • Epoch   2/100: train=0.0879, val=0.0851, patience=1/15, lr=0.000063
   • Epoch   3/100: train=0.0876, val=0.0852, patience=2/15, lr=0.000063
   • Epoch   4/100: train=0.0875, val=0.0852, patience=3/15, lr=0.000063
   • Epoch   5/100: train=0.0873, val=0.0853, patience=4/15, lr=0.000063
   📉 Epoch 8: LR reduced 0.000063 → 0.000031
   • Epoch  11/100: train=0.0867, val=0.0858, patience=10/15, lr=0.000031
   📉 Epoch 16: LR reduced 0.000031 → 0.000016

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 13 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000063 → 0.000016 (2 reductions)
   Train: Loss=0.0879, RMSE=0.2966, R²=-0.0144
   Val:   Loss=0.0852, RMSE=0.2918, R²=0.0159
============================================================


📊 Round 13 Test Metrics:
   Loss: 0.0732, RMSE: 0.2705, MAE: 0.2297, R²: -0.0282

📊 Round 13 Test Metrics:
   Loss: 0.0733, RMSE: 0.2707, MAE: 0.2299, R²: -0.0304

📊 Round 13 Test Metrics:
   Loss: 0.0732, RMSE: 0.2706, MAE: 0.2299, R²: -0.0294

📊 Round 13 Test Metrics:
   Loss: 0.0732, RMSE: 0.2706, MAE: 0.2298, R²: -0.0289

============================================================
🔄 Round 24 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000016
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0933 (↓), lr=0.000016
   • Epoch   2/100: train=0.0859, val=0.0932, patience=1/15, lr=0.000016
   • Epoch   3/100: train=0.0857, val=0.0932, patience=2/15, lr=0.000016
   • Epoch   4/100: train=0.0856, val=0.0932, patience=3/15, lr=0.000016
   • Epoch   5/100: train=0.0855, val=0.0931, patience=4/15, lr=0.000016
   📉 Epoch 8: LR reduced 0.000016 → 0.000008
   • Epoch  11/100: train=0.0852, val=0.0930, patience=10/15, lr=0.000008
   📉 Epoch 16: LR reduced 0.000008 → 0.000004

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0933)

============================================================
📊 Round 24 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000016 → 0.000004 (2 reductions)
   Train: Loss=0.0860, RMSE=0.2933, R²=-0.0114
   Val:   Loss=0.0933, RMSE=0.3055, R²=-0.0075
============================================================


📊 Round 24 Test Metrics:
   Loss: 0.0731, RMSE: 0.2703, MAE: 0.2296, R²: -0.0273

============================================================
🔄 Round 25 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000004
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0878, val=0.0860 (↓), lr=0.000004
   • Epoch   2/100: train=0.0878, val=0.0860, patience=1/15, lr=0.000004
   • Epoch   3/100: train=0.0878, val=0.0859, patience=2/15, lr=0.000004
   • Epoch   4/100: train=0.0877, val=0.0859, patience=3/15, lr=0.000004
   • Epoch   5/100: train=0.0877, val=0.0859, patience=4/15, lr=0.000004
   📉 Epoch 8: LR reduced 0.000004 → 0.000002
   • Epoch  11/100: train=0.0876, val=0.0858, patience=10/15, lr=0.000002
   📉 Epoch 16: LR reduced 0.000002 → 0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 25 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000004 → 0.000001 (2 reductions)
   Train: Loss=0.0879, RMSE=0.2966, R²=-0.0066
   Val:   Loss=0.0860, RMSE=0.2932, R²=-0.0249
============================================================


============================================================
🔄 Round 26 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0884, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0884, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0884, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0884, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0884, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0884, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 26 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0886, RMSE=0.2977, R²=-0.0090
   Val:   Loss=0.0834, RMSE=0.2889, R²=-0.0267
============================================================


📊 Round 26 Test Metrics:
   Loss: 0.0731, RMSE: 0.2703, MAE: 0.2296, R²: -0.0273

============================================================
🔄 Round 27 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0947 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0946, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0946, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0946, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0946, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0946, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0947)

============================================================
📊 Round 27 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2929, R²=-0.0064
   Val:   Loss=0.0947, RMSE=0.3077, R²=-0.0270
============================================================


📊 Round 27 Test Metrics:
   Loss: 0.0731, RMSE: 0.2703, MAE: 0.2296, R²: -0.0272

============================================================
🔄 Round 28 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.1002 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.1002, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.1002, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.1002, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.1002, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.1002, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.1002)

============================================================
📊 Round 28 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=-0.0071
   Val:   Loss=0.1002, RMSE=0.3166, R²=-0.0383
============================================================


📊 Round 28 Test Metrics:
   Loss: 0.0731, RMSE: 0.2703, MAE: 0.2296, R²: -0.0271

============================================================
🔄 Round 31 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0904, val=0.0772 (↓), lr=0.000001
   • Epoch   2/100: train=0.0904, val=0.0772, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0904, val=0.0772, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0904, val=0.0772, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0904, val=0.0772, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0903, val=0.0771, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 31 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0902, RMSE=0.3003, R²=-0.0050
   Val:   Loss=0.0772, RMSE=0.2779, R²=-0.0371
============================================================


📊 Round 31 Test Metrics:
   Loss: 0.0731, RMSE: 0.2703, MAE: 0.2296, R²: -0.0272

============================================================
🔄 Round 32 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0886, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0886, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0886, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0886, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0886, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0886, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 32 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0884, RMSE=0.2973, R²=-0.0061
   Val:   Loss=0.0842, RMSE=0.2901, R²=-0.0371
============================================================


📊 Round 32 Test Metrics:
   Loss: 0.0731, RMSE: 0.2703, MAE: 0.2296, R²: -0.0272

📊 Round 32 Test Metrics:
   Loss: 0.0731, RMSE: 0.2703, MAE: 0.2296, R²: -0.0272

============================================================
🔄 Round 37 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0947 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0947, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0947, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0947, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0947, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0947, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0947)

============================================================
📊 Round 37 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2929, R²=-0.0113
   Val:   Loss=0.0947, RMSE=0.3078, R²=-0.0088
============================================================


📊 Round 37 Test Metrics:
   Loss: 0.0731, RMSE: 0.2703, MAE: 0.2296, R²: -0.0272

📊 Round 37 Test Metrics:
   Loss: 0.0731, RMSE: 0.2703, MAE: 0.2296, R²: -0.0272

============================================================
🔄 Round 39 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0915, val=0.0723 (↓), lr=0.000001
   • Epoch   2/100: train=0.0915, val=0.0723, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0915, val=0.0723, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0915, val=0.0723, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0915, val=0.0723, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0915, val=0.0723, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0723)

============================================================
📊 Round 39 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0914, RMSE=0.3023, R²=-0.0108
   Val:   Loss=0.0723, RMSE=0.2689, R²=-0.0086
============================================================


📊 Round 39 Test Metrics:
   Loss: 0.0731, RMSE: 0.2703, MAE: 0.2296, R²: -0.0272

============================================================
🔄 Round 42 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0894, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0894, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0894, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0894, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0894, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0893, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 42 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0894, RMSE=0.2990, R²=-0.0106
   Val:   Loss=0.0802, RMSE=0.2832, R²=-0.0212
============================================================


============================================================
🔄 Round 43 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0971 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0971, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0971, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0971, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0971, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0971, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0971)

============================================================
📊 Round 43 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2918, R²=-0.0049
   Val:   Loss=0.0971, RMSE=0.3117, R²=-0.0295
============================================================


📊 Round 43 Test Metrics:
   Loss: 0.0731, RMSE: 0.2703, MAE: 0.2296, R²: -0.0272

📊 Round 43 Test Metrics:
   Loss: 0.0731, RMSE: 0.2703, MAE: 0.2296, R²: -0.0272

📊 Round 43 Test Metrics:
   Loss: 0.0731, RMSE: 0.2703, MAE: 0.2296, R²: -0.0271

============================================================
🔄 Round 46 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0930 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0930, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0930, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0931, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0931, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0931, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0930)

============================================================
📊 Round 46 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2936, R²=-0.0125
   Val:   Loss=0.0930, RMSE=0.3050, R²=-0.0124
============================================================


📊 Round 46 Test Metrics:
   Loss: 0.0731, RMSE: 0.2703, MAE: 0.2296, R²: -0.0272

============================================================
🔄 Round 47 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0886, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0886, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0886, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0886, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0886, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0886, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 47 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0885, RMSE=0.2975, R²=-0.0116
   Val:   Loss=0.0838, RMSE=0.2895, R²=-0.0049
============================================================


============================================================
🔄 Round 48 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0878, val=0.0863 (↓), lr=0.000001
   • Epoch   2/100: train=0.0878, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0878, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0878, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0878, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0877, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 48 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0879, RMSE=0.2965, R²=-0.0129
   Val:   Loss=0.0863, RMSE=0.2937, R²=-0.0011
============================================================


📊 Round 48 Test Metrics:
   Loss: 0.0731, RMSE: 0.2703, MAE: 0.2296, R²: -0.0271

============================================================
🔄 Round 52 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0870, val=0.0896 (↓), lr=0.000001
   • Epoch   2/100: train=0.0870, val=0.0896, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0870, val=0.0896, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0870, val=0.0896, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0869, val=0.0896, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0869, val=0.0896, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0896)

============================================================
📊 Round 52 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0870, RMSE=0.2950, R²=-0.0104
   Val:   Loss=0.0896, RMSE=0.2993, R²=-0.0178
============================================================


============================================================
🔄 Round 53 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0885, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0885, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0885, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0885, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0885, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0884, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 53 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0884, RMSE=0.2974, R²=-0.0120
   Val:   Loss=0.0840, RMSE=0.2899, R²=-0.0045
============================================================


📊 Round 53 Test Metrics:
   Loss: 0.0731, RMSE: 0.2703, MAE: 0.2296, R²: -0.0270

📊 Round 53 Test Metrics:
   Loss: 0.0731, RMSE: 0.2703, MAE: 0.2296, R²: -0.0270

============================================================
🔄 Round 57 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0918 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0918, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0918, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0918, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0918, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0918, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0918)

============================================================
📊 Round 57 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2941, R²=-0.0099
   Val:   Loss=0.0918, RMSE=0.3030, R²=-0.0169
============================================================


============================================================
🔄 Round 58 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0881, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0881, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0881, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0881, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0880, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0880, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 58 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0881, RMSE=0.2968, R²=-0.0053
   Val:   Loss=0.0854, RMSE=0.2923, R²=-0.0356
============================================================


📊 Round 58 Test Metrics:
   Loss: 0.0731, RMSE: 0.2703, MAE: 0.2296, R²: -0.0269

============================================================
🔄 Round 61 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0996 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0996, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0996, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0996, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0996, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0996, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0996)

============================================================
📊 Round 61 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=-0.0139
   Val:   Loss=0.0996, RMSE=0.3156, R²=-0.0001
============================================================


============================================================
🔄 Round 62 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0869, val=0.0913 (↓), lr=0.000001
   • Epoch   2/100: train=0.0869, val=0.0913, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0869, val=0.0913, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0869, val=0.0913, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0869, val=0.0913, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0868, val=0.0913, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0913)

============================================================
📊 Round 62 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2943, R²=-0.0134
   Val:   Loss=0.0913, RMSE=0.3022, R²=0.0022
============================================================


📊 Round 62 Test Metrics:
   Loss: 0.0731, RMSE: 0.2703, MAE: 0.2296, R²: -0.0269

============================================================
🔄 Round 63 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0874, val=0.0883 (↓), lr=0.000001
   • Epoch   2/100: train=0.0874, val=0.0883, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0874, val=0.0883, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0874, val=0.0883, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0874, val=0.0883, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0873, val=0.0883, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0883)

============================================================
📊 Round 63 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0874, RMSE=0.2956, R²=-0.0068
   Val:   Loss=0.0883, RMSE=0.2972, R²=-0.0230
============================================================


📊 Round 63 Test Metrics:
   Loss: 0.0731, RMSE: 0.2703, MAE: 0.2296, R²: -0.0269

============================================================
🔄 Round 65 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0870, val=0.0901 (↓), lr=0.000001
   • Epoch   2/100: train=0.0870, val=0.0901, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0870, val=0.0901, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0870, val=0.0901, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0870, val=0.0901, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0869, val=0.0901, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0901)

============================================================
📊 Round 65 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0869, RMSE=0.2948, R²=-0.0138
   Val:   Loss=0.0901, RMSE=0.3001, R²=-0.0008
============================================================


📊 Round 65 Test Metrics:
   Loss: 0.0731, RMSE: 0.2703, MAE: 0.2296, R²: -0.0270

============================================================
🔄 Round 68 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0928 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0928, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0928, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0928, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0928, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0928, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0928)

============================================================
📊 Round 68 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2936, R²=-0.0057
   Val:   Loss=0.0928, RMSE=0.3046, R²=-0.0440
============================================================


📊 Round 68 Test Metrics:
   Loss: 0.0731, RMSE: 0.2703, MAE: 0.2296, R²: -0.0270

============================================================
🔄 Round 69 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0894, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0894, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0894, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0894, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0894, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0894, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 69 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0892, RMSE=0.2986, R²=-0.0132
   Val:   Loss=0.0810, RMSE=0.2847, R²=-0.0139
============================================================


============================================================
🔄 Round 72 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0874, val=0.0883 (↓), lr=0.000001
   • Epoch   2/100: train=0.0874, val=0.0883, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0874, val=0.0883, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0874, val=0.0883, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0874, val=0.0883, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0873, val=0.0883, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0883)

============================================================
📊 Round 72 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0873, RMSE=0.2955, R²=-0.0066
   Val:   Loss=0.0883, RMSE=0.2972, R²=-0.0233
============================================================


📊 Round 72 Test Metrics:
   Loss: 0.0731, RMSE: 0.2703, MAE: 0.2296, R²: -0.0270

============================================================
🔄 Round 74 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.0907 (↓), lr=0.000001
   • Epoch   2/100: train=0.0868, val=0.0907, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0868, val=0.0907, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0868, val=0.0907, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0868, val=0.0907, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0867, val=0.0907, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0907)

============================================================
📊 Round 74 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0867, RMSE=0.2945, R²=-0.0173
   Val:   Loss=0.0907, RMSE=0.3011, R²=0.0153
============================================================


📊 Round 74 Test Metrics:
   Loss: 0.0731, RMSE: 0.2703, MAE: 0.2296, R²: -0.0271

📊 Round 74 Test Metrics:
   Loss: 0.0731, RMSE: 0.2703, MAE: 0.2296, R²: -0.0271

============================================================
🔄 Round 80 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0904 (↓), lr=0.000001
   • Epoch   2/100: train=0.0867, val=0.0904, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0867, val=0.0904, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0867, val=0.0904, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0867, val=0.0904, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0866, val=0.0904, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0904)

============================================================
📊 Round 80 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2946, R²=-0.0074
   Val:   Loss=0.0904, RMSE=0.3007, R²=-0.0202
============================================================


📊 Round 80 Test Metrics:
   Loss: 0.0731, RMSE: 0.2703, MAE: 0.2296, R²: -0.0271

📊 Round 80 Test Metrics:
   Loss: 0.0731, RMSE: 0.2703, MAE: 0.2296, R²: -0.0271

📊 Round 80 Test Metrics:
   Loss: 0.0731, RMSE: 0.2703, MAE: 0.2296, R²: -0.0270

============================================================
🔄 Round 83 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0871, val=0.0887 (↓), lr=0.000001
   • Epoch   2/100: train=0.0870, val=0.0887, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0870, val=0.0887, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0870, val=0.0887, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0870, val=0.0887, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0869, val=0.0888, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0887)

============================================================
📊 Round 83 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0872, RMSE=0.2953, R²=-0.0078
   Val:   Loss=0.0887, RMSE=0.2978, R²=-0.0346
============================================================


============================================================
🔄 Round 85 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0887, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0886, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0886, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0886, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0886, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0886, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 85 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0885, RMSE=0.2975, R²=-0.0102
   Val:   Loss=0.0836, RMSE=0.2891, R²=-0.0096
============================================================


📊 Round 85 Test Metrics:
   Loss: 0.0731, RMSE: 0.2703, MAE: 0.2296, R²: -0.0271

📊 Round 85 Test Metrics:
   Loss: 0.0731, RMSE: 0.2703, MAE: 0.2296, R²: -0.0270

============================================================
🔄 Round 88 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0956 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0956, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0956, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0957, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0957, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0957, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0956)

============================================================
📊 Round 88 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2924, R²=-0.0108
   Val:   Loss=0.0956, RMSE=0.3092, R²=-0.0494
============================================================


============================================================
🔄 Round 90 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0890, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0890, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0889, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0889, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0889, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0889, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 90 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0885, RMSE=0.2976, R²=-0.0124
   Val:   Loss=0.0834, RMSE=0.2889, R²=0.0002
============================================================


📊 Round 90 Test Metrics:
   Loss: 0.0731, RMSE: 0.2703, MAE: 0.2296, R²: -0.0271

📊 Round 90 Test Metrics:
   Loss: 0.0731, RMSE: 0.2703, MAE: 0.2296, R²: -0.0271

📊 Round 90 Test Metrics:
   Loss: 0.0731, RMSE: 0.2703, MAE: 0.2296, R²: -0.0270

============================================================
🔄 Round 94 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0890, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0890, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0890, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0890, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0890, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0889, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 94 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0886, RMSE=0.2976, R²=-0.0039
   Val:   Loss=0.0832, RMSE=0.2885, R²=-0.0450
============================================================


============================================================
🔄 Round 96 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0966 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0966, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0966, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0966, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0966, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0966, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0966)

============================================================
📊 Round 96 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2920, R²=-0.0082
   Val:   Loss=0.0966, RMSE=0.3108, R²=-0.0442
============================================================


📊 Round 96 Test Metrics:
   Loss: 0.0731, RMSE: 0.2703, MAE: 0.2296, R²: -0.0271

📊 Round 96 Test Metrics:
   Loss: 0.0731, RMSE: 0.2703, MAE: 0.2296, R²: -0.0271

============================================================
🔄 Round 98 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0934 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0934, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0934, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0934, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0934, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0935, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0934)

============================================================
📊 Round 98 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2933, R²=-0.0156
   Val:   Loss=0.0934, RMSE=0.3056, R²=-0.0241
============================================================


📊 Round 98 Test Metrics:
   Loss: 0.0731, RMSE: 0.2703, MAE: 0.2296, R²: -0.0271

============================================================
🔄 Round 101 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0887, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0887, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0886, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0886, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0886, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0886, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 101 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0886, RMSE=0.2976, R²=-0.0163
   Val:   Loss=0.0832, RMSE=0.2884, R²=0.0097
============================================================


📊 Round 101 Test Metrics:
   Loss: 0.0731, RMSE: 0.2703, MAE: 0.2297, R²: -0.0271

============================================================
🔄 Round 102 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0896, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0896, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0895, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0895, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0895, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0895, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 102 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0896, RMSE=0.2993, R²=-0.0145
   Val:   Loss=0.0793, RMSE=0.2815, R²=-0.0739
============================================================


============================================================
🔄 Round 104 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0921 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0921, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0921, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0921, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0921, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0920, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0921)

============================================================
📊 Round 104 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2939, R²=-0.0076
   Val:   Loss=0.0921, RMSE=0.3035, R²=-0.0176
============================================================


============================================================
🔄 Round 105 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0891, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0891, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0891, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0891, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0891, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0890, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 105 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0891, RMSE=0.2985, R²=-0.0093
   Val:   Loss=0.0811, RMSE=0.2848, R²=-0.0105
============================================================


📊 Round 105 Test Metrics:
   Loss: 0.0731, RMSE: 0.2703, MAE: 0.2297, R²: -0.0272

📊 Round 105 Test Metrics:
   Loss: 0.0731, RMSE: 0.2703, MAE: 0.2297, R²: -0.0272

============================================================
🔄 Round 107 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0875, val=0.0874 (↓), lr=0.000001
   • Epoch   2/100: train=0.0875, val=0.0874, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0875, val=0.0874, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0875, val=0.0873, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0875, val=0.0873, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0874, val=0.0873, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0874)

============================================================
📊 Round 107 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0875, RMSE=0.2959, R²=-0.0125
   Val:   Loss=0.0874, RMSE=0.2956, R²=0.0017
============================================================


📊 Round 107 Test Metrics:
   Loss: 0.0731, RMSE: 0.2703, MAE: 0.2297, R²: -0.0272

📊 Round 107 Test Metrics:
   Loss: 0.0731, RMSE: 0.2703, MAE: 0.2297, R²: -0.0272

============================================================
🔄 Round 110 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0934 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0934, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0934, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0934, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0934, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0934, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0934)

============================================================
📊 Round 110 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2933, R²=-0.0091
   Val:   Loss=0.0934, RMSE=0.3056, R²=-0.0371
============================================================


============================================================
🔄 Round 112 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0876, val=0.0878 (↓), lr=0.000001
   • Epoch   2/100: train=0.0876, val=0.0878, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0876, val=0.0878, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0876, val=0.0878, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0876, val=0.0878, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0875, val=0.0878, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0878)

============================================================
📊 Round 112 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0874, RMSE=0.2957, R²=-0.0074
   Val:   Loss=0.0878, RMSE=0.2963, R²=-0.0183
============================================================


============================================================
🔄 Round 113 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0901, val=0.0772 (↓), lr=0.000001
   • Epoch   2/100: train=0.0901, val=0.0772, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0901, val=0.0772, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0901, val=0.0772, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0900, val=0.0772, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0900, val=0.0771, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 113 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0901, RMSE=0.3001, R²=-0.0102
   Val:   Loss=0.0772, RMSE=0.2778, R²=-0.0083
============================================================


📊 Round 113 Test Metrics:
   Loss: 0.0731, RMSE: 0.2703, MAE: 0.2297, R²: -0.0271

📊 Round 113 Test Metrics:
   Loss: 0.0731, RMSE: 0.2703, MAE: 0.2297, R²: -0.0272

============================================================
🔄 Round 115 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0938 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0938, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0937, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0937, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0937, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0937, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0938)

============================================================
📊 Round 115 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2931, R²=-0.0036
   Val:   Loss=0.0938, RMSE=0.3062, R²=-0.0367
============================================================


📊 Round 115 Test Metrics:
   Loss: 0.0731, RMSE: 0.2703, MAE: 0.2297, R²: -0.0272

📊 Round 115 Test Metrics:
   Loss: 0.0731, RMSE: 0.2703, MAE: 0.2297, R²: -0.0273

============================================================
🔄 Round 122 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0882, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0882, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0881, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0881, val=0.0859, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0881, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0880, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 122 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0879, RMSE=0.2965, R²=-0.0123
   Val:   Loss=0.0858, RMSE=0.2930, R²=-0.0272
============================================================


============================================================
🔄 Round 123 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0878, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0878, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0878, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0878, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0878, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0877, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 123 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0879, RMSE=0.2965, R²=-0.0039
   Val:   Loss=0.0856, RMSE=0.2926, R²=-0.0432
============================================================


📊 Round 123 Test Metrics:
   Loss: 0.0731, RMSE: 0.2703, MAE: 0.2297, R²: -0.0273

============================================================
🔄 Round 124 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0873, val=0.0875 (↓), lr=0.000001
   • Epoch   2/100: train=0.0873, val=0.0876, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0873, val=0.0876, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0873, val=0.0876, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0873, val=0.0876, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0872, val=0.0876, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0875)

============================================================
📊 Round 124 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0875, RMSE=0.2957, R²=-0.0186
   Val:   Loss=0.0875, RMSE=0.2959, R²=0.0142
============================================================


============================================================
🔄 Round 125 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0888, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0888, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0888, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0888, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0888, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0888, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 125 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0887, RMSE=0.2978, R²=-0.0071
   Val:   Loss=0.0826, RMSE=0.2874, R²=-0.0213
============================================================


============================================================
🔄 Round 126 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0881, val=0.0866 (↓), lr=0.000001
   • Epoch   2/100: train=0.0881, val=0.0866, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0881, val=0.0866, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0881, val=0.0866, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0881, val=0.0866, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0881, val=0.0866, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0866)

============================================================
📊 Round 126 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0877, RMSE=0.2961, R²=-0.0116
   Val:   Loss=0.0866, RMSE=0.2943, R²=-0.0015
============================================================


📊 Round 126 Test Metrics:
   Loss: 0.0731, RMSE: 0.2703, MAE: 0.2297, R²: -0.0272

============================================================
🔄 Round 129 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0899 (↓), lr=0.000001
   • Epoch   2/100: train=0.0867, val=0.0899, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0867, val=0.0899, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0867, val=0.0899, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0867, val=0.0899, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0866, val=0.0899, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0899)

============================================================
📊 Round 129 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0869, RMSE=0.2947, R²=-0.0085
   Val:   Loss=0.0899, RMSE=0.2999, R²=-0.0122
============================================================


📊 Round 129 Test Metrics:
   Loss: 0.0731, RMSE: 0.2703, MAE: 0.2297, R²: -0.0271

📊 Round 129 Test Metrics:
   Loss: 0.0731, RMSE: 0.2703, MAE: 0.2297, R²: -0.0270

============================================================
🔄 Round 131 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0873, val=0.0877 (↓), lr=0.000001
   • Epoch   2/100: train=0.0873, val=0.0877, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0873, val=0.0877, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0873, val=0.0877, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0873, val=0.0877, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0872, val=0.0877, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0877)

============================================================
📊 Round 131 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0874, RMSE=0.2957, R²=-0.0068
   Val:   Loss=0.0877, RMSE=0.2961, R²=-0.0479
============================================================


📊 Round 131 Test Metrics:
   Loss: 0.0731, RMSE: 0.2703, MAE: 0.2297, R²: -0.0270

📊 Round 131 Test Metrics:
   Loss: 0.0731, RMSE: 0.2703, MAE: 0.2296, R²: -0.0269

📊 Round 131 Test Metrics:
   Loss: 0.0731, RMSE: 0.2703, MAE: 0.2296, R²: -0.0268

============================================================
🔄 Round 136 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0879, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0879, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0879, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0879, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0879, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0878, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 136 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0880, RMSE=0.2966, R²=-0.0074
   Val:   Loss=0.0854, RMSE=0.2923, R²=-0.0203
============================================================


📊 Round 136 Test Metrics:
   Loss: 0.0731, RMSE: 0.2703, MAE: 0.2296, R²: -0.0268

============================================================
🔄 Round 137 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0900 (↓), lr=0.000001
   • Epoch   2/100: train=0.0867, val=0.0900, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0867, val=0.0900, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0867, val=0.0900, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0867, val=0.0900, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0866, val=0.0900, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0900)

============================================================
📊 Round 137 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0869, RMSE=0.2947, R²=-0.0098
   Val:   Loss=0.0900, RMSE=0.3000, R²=-0.0116
============================================================


============================================================
🔄 Round 138 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0882, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0882, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0882, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0882, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0882, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0881, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 138 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0883, RMSE=0.2971, R²=-0.0157
   Val:   Loss=0.0842, RMSE=0.2902, R²=0.0168
============================================================


📊 Round 138 Test Metrics:
   Loss: 0.0731, RMSE: 0.2703, MAE: 0.2296, R²: -0.0269

============================================================
🔄 Round 140 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0878, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0878, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0878, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0878, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0878, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0877, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 140 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0878, RMSE=0.2963, R²=-0.0149
   Val:   Loss=0.0862, RMSE=0.2937, R²=0.0122
============================================================


📊 Round 140 Test Metrics:
   Loss: 0.0731, RMSE: 0.2703, MAE: 0.2296, R²: -0.0269

============================================================
🔄 Round 142 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0881, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0881, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0881, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0881, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0881, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0880, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 142 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0884, RMSE=0.2974, R²=-0.0152
   Val:   Loss=0.0836, RMSE=0.2892, R²=0.0136
============================================================


📊 Round 142 Test Metrics:
   Loss: 0.0731, RMSE: 0.2703, MAE: 0.2297, R²: -0.0269

📊 Round 142 Test Metrics:
   Loss: 0.0731, RMSE: 0.2703, MAE: 0.2297, R²: -0.0269

============================================================
🔄 Round 145 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0890, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0890, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0890, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0890, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0890, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0889, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 145 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0888, RMSE=0.2981, R²=-0.0089
   Val:   Loss=0.0820, RMSE=0.2863, R²=-0.0238
============================================================


============================================================
🔄 Round 146 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0879, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0879, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0879, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0879, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0879, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0878, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 146 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0882, RMSE=0.2970, R²=-0.0128
   Val:   Loss=0.0845, RMSE=0.2907, R²=-0.0221
============================================================


============================================================
🔄 Round 147 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0873, val=0.0876 (↓), lr=0.000001
   • Epoch   2/100: train=0.0873, val=0.0876, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0873, val=0.0876, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0873, val=0.0876, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0873, val=0.0876, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0872, val=0.0875, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0876)

============================================================
📊 Round 147 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0874, RMSE=0.2957, R²=-0.0068
   Val:   Loss=0.0876, RMSE=0.2960, R²=-0.0226
============================================================


📊 Round 147 Test Metrics:
   Loss: 0.0731, RMSE: 0.2703, MAE: 0.2297, R²: -0.0270

============================================================
🔄 Round 149 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0876, val=0.0869 (↓), lr=0.000001
   • Epoch   2/100: train=0.0876, val=0.0869, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0876, val=0.0869, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0876, val=0.0869, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0876, val=0.0869, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0875, val=0.0868, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 149 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0876, RMSE=0.2960, R²=-0.0082
   Val:   Loss=0.0869, RMSE=0.2947, R²=-0.0134
============================================================


📊 Round 149 Test Metrics:
   Loss: 0.0731, RMSE: 0.2703, MAE: 0.2297, R²: -0.0269

============================================================
🔄 Round 150 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0974 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0974, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0974, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0974, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0974, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0974, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0974)

============================================================
📊 Round 150 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2915, R²=-0.0095
   Val:   Loss=0.0974, RMSE=0.3121, R²=-0.0077
============================================================


📊 Round 150 Test Metrics:
   Loss: 0.0731, RMSE: 0.2703, MAE: 0.2297, R²: -0.0269

============================================================
🔄 Round 152 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0888, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0888, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0888, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0888, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0888, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0887, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 152 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0887, RMSE=0.2979, R²=-0.0127
   Val:   Loss=0.0823, RMSE=0.2870, R²=-0.0091
============================================================


📊 Round 152 Test Metrics:
   Loss: 0.0731, RMSE: 0.2703, MAE: 0.2297, R²: -0.0270

📊 Round 152 Test Metrics:
   Loss: 0.0731, RMSE: 0.2703, MAE: 0.2297, R²: -0.0270

============================================================
🔄 Round 157 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0870, val=0.0903 (↓), lr=0.000001
   • Epoch   2/100: train=0.0869, val=0.0903, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0869, val=0.0903, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0869, val=0.0903, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0869, val=0.0903, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0868, val=0.0903, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0903)

============================================================
📊 Round 157 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2946, R²=-0.0083
   Val:   Loss=0.0903, RMSE=0.3004, R²=-0.0128
============================================================


📊 Round 157 Test Metrics:
   Loss: 0.0731, RMSE: 0.2703, MAE: 0.2297, R²: -0.0270

============================================================
🔄 Round 159 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.0900 (↓), lr=0.000001
   • Epoch   2/100: train=0.0868, val=0.0900, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0868, val=0.0900, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0868, val=0.0900, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0868, val=0.0900, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0867, val=0.0900, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0900)

============================================================
📊 Round 159 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2947, R²=-0.0082
   Val:   Loss=0.0900, RMSE=0.3000, R²=-0.0144
============================================================


📊 Round 159 Test Metrics:
   Loss: 0.0731, RMSE: 0.2703, MAE: 0.2297, R²: -0.0269

📊 Round 159 Test Metrics:
   Loss: 0.0731, RMSE: 0.2703, MAE: 0.2297, R²: -0.0269

📊 Round 159 Test Metrics:
   Loss: 0.0731, RMSE: 0.2703, MAE: 0.2296, R²: -0.0268

📊 Round 159 Test Metrics:
   Loss: 0.0731, RMSE: 0.2703, MAE: 0.2297, R²: -0.0268

============================================================
🔄 Round 166 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0887, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0887, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0887, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0886, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0886, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0886, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 166 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0887, RMSE=0.2979, R²=-0.0128
   Val:   Loss=0.0824, RMSE=0.2870, R²=0.0039
============================================================


📊 Round 166 Test Metrics:
   Loss: 0.0731, RMSE: 0.2703, MAE: 0.2297, R²: -0.0269

📊 Round 166 Test Metrics:
   Loss: 0.0730, RMSE: 0.2703, MAE: 0.2296, R²: -0.0268

============================================================
🔄 Round 168 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0891, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0891, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0891, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0891, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0890, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0890, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 168 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0891, RMSE=0.2985, R²=-0.0104
   Val:   Loss=0.0809, RMSE=0.2844, R²=-0.0121
============================================================


📊 Round 168 Test Metrics:
   Loss: 0.0731, RMSE: 0.2703, MAE: 0.2297, R²: -0.0268

📊 Round 168 Test Metrics:
   Loss: 0.0731, RMSE: 0.2703, MAE: 0.2297, R²: -0.0268

📊 Round 168 Test Metrics:
   Loss: 0.0731, RMSE: 0.2703, MAE: 0.2297, R²: -0.0268

📊 Round 168 Test Metrics:
   Loss: 0.0731, RMSE: 0.2703, MAE: 0.2297, R²: -0.0269

📊 Round 168 Test Metrics:
   Loss: 0.0731, RMSE: 0.2703, MAE: 0.2297, R²: -0.0269

📊 Round 168 Test Metrics:
   Loss: 0.0731, RMSE: 0.2703, MAE: 0.2297, R²: -0.0269

============================================================
🔄 Round 176 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0882, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0882, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0882, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0882, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0882, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0881, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 176 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0884, RMSE=0.2973, R²=-0.0010
   Val:   Loss=0.0838, RMSE=0.2895, R²=-0.0463
============================================================


📊 Round 176 Test Metrics:
   Loss: 0.0731, RMSE: 0.2703, MAE: 0.2297, R²: -0.0268

📊 Round 176 Test Metrics:
   Loss: 0.0731, RMSE: 0.2703, MAE: 0.2297, R²: -0.0268

============================================================
🔄 Round 179 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0967 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0967, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0967, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0967, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0967, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0967, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0967)

============================================================
📊 Round 179 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2918, R²=-0.0087
   Val:   Loss=0.0967, RMSE=0.3110, R²=-0.0142
============================================================


============================================================
🔄 Round 181 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0870, val=0.0888 (↓), lr=0.000001
   • Epoch   2/100: train=0.0870, val=0.0888, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0870, val=0.0888, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0870, val=0.0888, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0870, val=0.0888, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0870, val=0.0888, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0888)

============================================================
📊 Round 181 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0871, RMSE=0.2951, R²=-0.0086
   Val:   Loss=0.0888, RMSE=0.2980, R²=-0.0101
============================================================


📊 Round 181 Test Metrics:
   Loss: 0.0730, RMSE: 0.2703, MAE: 0.2297, R²: -0.0268

============================================================
🔄 Round 184 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0880, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0879, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0879, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0879, val=0.0859, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0879, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0878, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 184 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0878, RMSE=0.2964, R²=-0.0108
   Val:   Loss=0.0859, RMSE=0.2931, R²=-0.0036
============================================================


============================================================
🔄 Round 185 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0973 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0973, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0973, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0973, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0973, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0973, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0973)

============================================================
📊 Round 185 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2915, R²=-0.0010
   Val:   Loss=0.0973, RMSE=0.3120, R²=-0.0377
============================================================


📊 Round 185 Test Metrics:
   Loss: 0.0730, RMSE: 0.2703, MAE: 0.2296, R²: -0.0266

============================================================
🔄 Round 189 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0883, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0883, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0883, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0882, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0882, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0882, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 189 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0883, RMSE=0.2972, R²=-0.0106
   Val:   Loss=0.0838, RMSE=0.2895, R²=-0.0063
============================================================


📊 Round 189 Test Metrics:
   Loss: 0.0730, RMSE: 0.2703, MAE: 0.2296, R²: -0.0266

📊 Round 189 Test Metrics:
   Loss: 0.0730, RMSE: 0.2703, MAE: 0.2296, R²: -0.0266

📊 Round 189 Test Metrics:
   Loss: 0.0730, RMSE: 0.2702, MAE: 0.2296, R²: -0.0265

============================================================
🔄 Round 195 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0938 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0938, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0938, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0938, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0938, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0938, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0938)

============================================================
📊 Round 195 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2930, R²=-0.0037
   Val:   Loss=0.0938, RMSE=0.3063, R²=-0.0286
============================================================


============================================================
🔄 Round 196 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0879, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0879, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0879, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0879, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0879, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0878, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 196 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0879, RMSE=0.2965, R²=-0.0066
   Val:   Loss=0.0856, RMSE=0.2925, R²=-0.0274
============================================================


📊 Round 196 Test Metrics:
   Loss: 0.0730, RMSE: 0.2703, MAE: 0.2296, R²: -0.0266

📊 Round 196 Test Metrics:
   Loss: 0.0730, RMSE: 0.2703, MAE: 0.2296, R²: -0.0266

📊 Round 196 Test Metrics:
   Loss: 0.0730, RMSE: 0.2703, MAE: 0.2297, R²: -0.0266

📊 Round 196 Test Metrics:
   Loss: 0.0730, RMSE: 0.2703, MAE: 0.2297, R²: -0.0267

============================================================
🔄 Round 200 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0967 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0967, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0967, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0967, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0967, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0967, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0967)

============================================================
📊 Round 200 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2917, R²=-0.0016
   Val:   Loss=0.0967, RMSE=0.3110, R²=-0.0355
============================================================


📊 Round 200 Test Metrics:
   Loss: 0.0730, RMSE: 0.2703, MAE: 0.2297, R²: -0.0266

============================================================
🔄 Round 203 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0886, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0886, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0886, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0885, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0885, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0885, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 203 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0884, RMSE=0.2972, R²=-0.0106
   Val:   Loss=0.0837, RMSE=0.2894, R²=-0.0011
============================================================


📊 Round 203 Test Metrics:
   Loss: 0.0730, RMSE: 0.2702, MAE: 0.2296, R²: -0.0265

📊 Round 203 Test Metrics:
   Loss: 0.0730, RMSE: 0.2703, MAE: 0.2297, R²: -0.0266

============================================================
🔄 Round 211 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0881, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0881, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0881, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0881, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0881, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0880, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 211 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0882, RMSE=0.2970, R²=-0.0119
   Val:   Loss=0.0843, RMSE=0.2904, R²=0.0030
============================================================


📊 Round 211 Test Metrics:
   Loss: 0.0730, RMSE: 0.2703, MAE: 0.2297, R²: -0.0266

============================================================
🔄 Round 212 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0877, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0877, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0876, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0876, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0876, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0876, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 212 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0880, RMSE=0.2967, R²=-0.0094
   Val:   Loss=0.0850, RMSE=0.2916, R²=-0.0078
============================================================


============================================================
🔄 Round 213 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0878, val=0.0870 (↓), lr=0.000001
   • Epoch   2/100: train=0.0878, val=0.0870, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0878, val=0.0870, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0878, val=0.0870, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0878, val=0.0870, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0877, val=0.0869, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 213 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0875, RMSE=0.2959, R²=-0.0048
   Val:   Loss=0.0870, RMSE=0.2949, R²=-0.0276
============================================================


============================================================
🔄 Round 214 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0885, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0885, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0885, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0884, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0884, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0884, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 214 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0885, RMSE=0.2975, R²=-0.0046
   Val:   Loss=0.0831, RMSE=0.2883, R²=-0.0316
============================================================


📊 Round 214 Test Metrics:
   Loss: 0.0730, RMSE: 0.2703, MAE: 0.2297, R²: -0.0266

============================================================
🔄 Round 215 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0880, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0880, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0880, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0880, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0880, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0879, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 215 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0883, RMSE=0.2971, R²=-0.0080
   Val:   Loss=0.0841, RMSE=0.2900, R²=-0.0140
============================================================


📊 Round 215 Test Metrics:
   Loss: 0.0730, RMSE: 0.2703, MAE: 0.2297, R²: -0.0266

📊 Round 215 Test Metrics:
   Loss: 0.0730, RMSE: 0.2702, MAE: 0.2297, R²: -0.0265

============================================================
🔄 Round 217 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0967 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0967, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0967, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0967, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0967, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0966, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0967)

============================================================
📊 Round 217 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2917, R²=-0.0117
   Val:   Loss=0.0967, RMSE=0.3109, R²=-0.0044
============================================================


============================================================
🔄 Round 218 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0885, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0885, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0884, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0884, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0884, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0884, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 218 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0885, RMSE=0.2974, R²=-0.0116
   Val:   Loss=0.0832, RMSE=0.2885, R²=0.0038
============================================================


📊 Round 218 Test Metrics:
   Loss: 0.0730, RMSE: 0.2703, MAE: 0.2297, R²: -0.0266

============================================================
🔄 Round 221 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0931 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0931, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0931, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0931, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0931, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0930, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0931)

============================================================
📊 Round 221 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2932, R²=-0.0088
   Val:   Loss=0.0931, RMSE=0.3051, R²=-0.0075
============================================================


📊 Round 221 Test Metrics:
   Loss: 0.0730, RMSE: 0.2703, MAE: 0.2297, R²: -0.0267

============================================================
🔄 Round 224 - Client client_2
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0924 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0924, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0924, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0924, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0924, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0924, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0924)

============================================================
📊 Round 224 Summary - Client client_2
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2935, R²=-0.0115
   Val:   Loss=0.0924, RMSE=0.3040, R²=0.0022
============================================================


❌ Client client_2 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8687 {grpc_message:"Socket closed", grpc_status:14}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8687 {grpc_message:"Socket closed", grpc_status:14}"
>
