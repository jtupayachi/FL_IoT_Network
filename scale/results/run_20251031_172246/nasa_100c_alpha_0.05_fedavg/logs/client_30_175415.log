[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 02e82d25-f717-4d2c-86b0-9a05c764070f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message be44c400-52e5-496f-9ab1-6278e62f9543
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e73315cf-4573-4140-9c44-e86ab1dcacb1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 810f2c57-e6d7-4f60-995e-ada76ece13f6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c596748e-8533-4c27-ac4d-e4f34e506c0f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 96565d81-e78b-4a7e-ac12-740d25d12353
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6a018677-af95-429e-99d7-731496cf528e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 40e44a93-65ab-434a-8321-e4c1f6fe44e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7586dd48-0440-49fe-a691-f06b9997cb85
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e9107416-b835-46c3-9725-2b2d2e991fb4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eaaa3803-c51a-4bb8-bbd6-85beb828b6d1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ddea9d81-8e8a-4955-8441-0b4d926630d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e9551f58-9607-4001-8cd2-ce806ef6d2e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0c1b59fe-8758-41f8-8426-dbd10e3837ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message df6ecce7-28e2-424c-bd42-88ebc6ca6825
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a0ae2dd4-8a82-4252-ba77-255d180b8a38
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 59eb708e-f901-41d5-bb94-65c525676e19
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8b320b98-d65d-4e4c-b6ae-00be215c9846
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 25c6edfa-50c3-45f8-8c3c-d92fecfbe557
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cacff7bb-f7d0-43f1-864f-f7cf1d0326a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2918c441-218d-4e2e-995e-42ef735f973f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 98e9f0a5-756c-4cae-903a-0ef968edd16d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 672e44de-8259-4c76-8ad1-c18e67295291
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eb69ccab-ab11-4b1c-ada4-59f1a06377b6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 20eac29a-5783-42ef-b3fd-a0e3c6e3d122
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message db11f2a6-d8f6-4bd9-93e3-02dc8c503940
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e58ed883-a4d4-40c6-b7bf-bf40e1629b50
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7bca1d98-a480-4bbb-8ce8-77fbc65620dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d47123fc-9851-4bc9-b859-fffcd000bfe3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 039a5096-8959-4e10-ba28-a4e9aa4f3412
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dbfa86a2-52d7-428e-88ef-683b49106c19
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7016110a-8c61-4177-af48-041c6dc0e1fb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1be0c320-7dab-496c-9ccf-fc4b758621ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ad53c4ad-c2c1-42aa-a292-5976c451bd06
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3c47edfe-9a64-4d30-bf3d-66b3ea4a4148
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0defdeb1-9deb-433a-a520-be099bb1a56d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 83acb7be-545c-4f87-b131-240e49c753d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c89ff2c0-94c1-4574-83a1-0253848c690b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1eef7e88-70be-49dd-b876-e19b50a9692e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e7023282-5500-4478-911e-728db844813d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eda93683-f8d8-49eb-9ced-4db64ee0af79
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c1c2040e-95e3-4603-bdbb-4811e8d7c0a3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5fbca831-3c5f-4f00-bf85-68ed79d975ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4046aa87-f41e-4e26-b96a-164f58456711
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d63bf588-5062-41e3-845b-f748d25d0acd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 64b8a75b-fd8f-4f9b-9a26-071d5c7c4671
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8a04fa73-6cfc-4c46-b151-9a44f0f6d7ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 53453756-da7d-4450-b33e-47a53df83270
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f606c522-bf35-4b8b-84ef-ec98e6dbbb02
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6d1a4802-cd67-4275-bcc2-59246127acc1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8c22a0b6-2d8b-4803-b12d-6adf4d2fd643
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a10de86e-742b-464e-a91d-de61c51fa193
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d29d2bdb-4a2a-4d85-829c-a317b94eee2e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 804f897b-c291-419e-b3d1-a57bf1146bcd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 28bea28e-7a2e-46a3-b02a-cebe8173c68b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2e0c4781-a656-479a-9467-f44f32192d11
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1adbc297-0c0f-4ecb-9b5d-acf3da8bf469
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f111b5b9-3722-431b-8ff8-1823da7d123e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5115f5a1-a439-4f8c-aace-4e2577964eca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0c90438d-b214-46aa-a8c5-7c0ca05948ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7617bfaa-ceaa-40fe-b5d9-ccace0a01561
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f26dc418-52cf-4d1d-abe7-51e51e35779a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0d312380-4ef9-4f0b-a2a0-3f088cec83b1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a3c9bacb-224b-446e-9927-4e5120eb0bfc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a85344a4-2f47-4cd1-b801-c54dde8e4c22
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9a9243ea-f739-464d-a7b6-2858c91c766d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 820b2a20-3453-425c-90cf-53a41b78a2ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c1b2a66e-e0e6-412e-b098-f00a944e8f99
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 81aa7234-76b5-4474-9056-44a40d78006c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 07d0b791-23a9-483a-8a27-d0a1b5830a31
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ca2b5c3a-81b5-4b43-b5ed-bccac5b92628
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7d586c58-9af0-4f34-a423-555f1548449f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 43447abd-b368-423f-9991-730bb68445ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3030b1aa-fee8-46b1-806e-a4b16be90f22
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1ac8b2c4-9ce8-4908-9a0a-0b9f1fc477f7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 81196225-c093-46c0-a02f-c72153e93834
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2148ad78-a69e-4cd5-b35d-63fbc11afc7f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2164d200-2579-4b92-a181-53d2b2d1cbc8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bc0754e5-6021-4767-9e89-f5bac427d14e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c2152758-c89c-4813-a4ad-00530c162dab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2a87d3d7-736c-4eee-b708-1405cbb6453b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b3765371-62b4-46be-b944-eaa478062f15
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3f68a84f-3a43-4d4b-bccb-8acad3ce4fcc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 74eb8450-4a6a-4035-8c86-efe71f6a04b5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6160f4f0-b151-4a7a-8844-bcea7250a7fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 765ae620-36e2-4a81-9098-835d249affb4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 08e13647-712d-4da2-847e-eaa3b25874e2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 81315467-0fcf-437a-98cc-6b6aeaaa9cd9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eac03a3f-6e70-4021-9b12-f2e235412256
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b043cb10-132f-433f-879f-39354fb1fdd5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a0e5644a-cbb8-44ff-acd0-bbf817194d61
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 78f16c3f-fd2b-4cea-9fc2-ec58ac360be4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 510e3630-1181-4cab-bd77-6d1033cc82e8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f8e1972a-b467-4cac-acd2-7f1323cce398
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 119b5bb9-4635-49ea-83dd-5083c68c6b27
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 372723e2-5c7b-4885-be01-8b96b9bd2f72
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7e6514e2-5985-41f2-8cc6-1a1c44f49726
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1b020148-8099-4975-96d7-64c03d5ac995
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2e2bec16-b5c4-4f21-a3ba-d3500f635974
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 00057a53-2f28-4094-8eaf-d06c0f80eac6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a1843908-33c2-4f63-9379-314d500c6436
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d84d597a-b437-4f62-91ed-4865a32b4e13
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b22ccf14-29a5-4aa0-8f59-6af61b23b160
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9dd8fce0-0600-4170-97f2-b6f435ac4ad9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fe736762-d698-4ff5-96b3-254f269212bc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e3c2f05c-639a-4afb-992f-8da7be2f2cc3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dab9210a-71da-422c-85f1-1a7cf276b53b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3f3bb59f-1f3a-4e62-a6b9-7a4989d1042c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 26a58fd4-9c8d-4507-b53b-887cf23dc41b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f12e5660-8197-4ea6-8f22-83cff89c413f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bfaa477a-acd6-4b48-8ddb-1dc193eb6a77
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message efb9cebb-bf08-4e27-a574-4f14a4bdf10a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4f5766d2-63d2-472d-8b94-7be6b7722318
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 00fa1433-3677-46aa-9ff9-97c665ee79d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 693b0242-93bb-4bd4-9ab3-c2b1be4a8e44
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 468e77f0-9ebd-4dd1-a32c-0abb19598aae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e8c8cb40-559b-4e29-bad4-62f6d1d0feb1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 55a51dba-7675-4269-8b2e-1ae2f7ba5952
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message be527c59-9b34-4020-b49f-195539eae296
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cf4747ca-0e10-477a-94fb-65e705788f0a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8db19d0d-8667-49f6-b8b7-cfe63464782f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 758fe049-192f-4f70-abf2-229d66555660
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 68f244d1-ed9e-4165-ac21-ef8ad308625f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9a1572d7-b75a-447a-b448-f52152876e13
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a23be2f7-3548-4f8a-b0e6-3472c7434290
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 87d9b6df-d94f-4ed8-bf15-4974e4eeab9c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 61d8fe84-95e5-4b5f-84bf-60d611f5ea82
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message edf6a889-eb94-47e0-a13f-5980e129a9e1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d4b1ea46-2a3c-4170-808c-f5891e9b5998
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3578797b-553a-4309-9ee6-94d2f0799859
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ee7e704a-7f18-4e29-86c2-41ffefa78279
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 75366f26-b481-4e0f-b226-3137b8c68c31
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2b580629-de18-4a38-8d56-c9cda5a221b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 13bf1667-c382-4fb0-9f57-e8ed785ac12d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 01832941-d56c-4608-b068-dc7b4e7fc2a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f22dac0f-51c0-4ccc-b71f-28c18a9f1128
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 153666a1-48d7-417b-a9fd-f825f747536b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c68c3c77-7f17-4efb-8e8c-01cbe6394d04
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aa959480-8622-42ef-a4ab-803ad6bdcb34
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 02a82739-42dd-4c39-bcd9-9927758f2afa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9c666413-30de-4e11-8664-555da1746369
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e08c109a-55e7-4473-a46b-722d4a1ab14b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d6608865-3a45-4040-a066-0011c4ae9cc0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5dccc3b3-0542-4ea6-99ac-cef76aee8306
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 68d7c0cf-2760-4d7a-861e-0fbd68664caf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3c2f1681-d7b0-4135-b1e1-e0b7397623ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 862c43a8-ba17-4368-9cfd-08e0177ff1f4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b04dad0f-d336-4915-8808-3316e9d2c78f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e3a6beea-b0c3-4fba-afc3-6652a69f7325
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bccbd06d-f9fc-47f7-bc55-74a904a361c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7f967dd3-6b3a-405e-8443-187fba962c06
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4c8bf7c5-7b1a-454b-aab5-e488ec412ad3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c6f97750-f870-44f7-b489-0efebf08497c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 874febb9-f70d-45f7-a6a8-e2926f88141d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7c04cdd5-55be-4db7-89d2-c9a8944e29c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0ba1dd8b-98ad-4ac1-8a9c-01b79b277b5c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ece7e77a-dd14-4ca2-a295-83d4287c47ce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0ea946b1-e555-4259-9b96-6bd3920a9ed6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fa703e57-8922-4a94-ab67-ffb3bcdc6ac6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c5433720-db29-40c9-b5a1-47ff9b8e7600
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c9c23061-8733-40b7-96c1-d46068e470c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dae0358b-7073-4343-80f8-9661efbc042e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ea8159b8-8867-438c-9efd-0d2bab79de7f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f26e9347-e390-41a6-8984-84dc6644b154
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ad0c89ad-c30f-482c-ad77-b422f238c203
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 64f9aac8-bf0b-457b-a572-3f53f5c153c5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e7d71521-e8ad-4b93-a1f5-943a8f0b4f91
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a1cc9f8a-8fe2-4555-b0a8-caa25a92405d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 551d904f-5dc1-4f01-b793-61b83ce452b1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a70176a6-b0ed-4abf-bd80-184eef2cf895
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a2f70119-d356-4bb3-b7a7-6e2e96ecdb84
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 86ab4823-cb18-406f-8091-ef6e57dfd080
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8f1ebc5f-782e-4e4b-88d2-61a702a52da8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9663332a-519a-4232-9492-68edfc60072e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e27d3564-5983-4583-a542-bab9682e5465
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f54fb7a4-699c-449d-bb4b-185ac373c925
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8174399b-d7cd-4a3a-acd7-72b8ea83903d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 64142c36-5e85-42f1-b2f4-a27c4ea8b1e8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 59e655b5-f7aa-4bfe-bd3f-9a1dd6bfb848
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4ba0eb00-0bba-4b6d-a89e-ea3d67571a9e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 228a0dde-fcc2-48c2-82f3-bfd37ec55747
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 32dc1e6d-03ef-416f-8ad9-9264669c4977
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6f9c0f68-211f-4cec-ba7d-1c71938c23e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e5413166-bf11-47cc-bcac-d98c9a4ea93c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f4aab6d1-94e2-4315-b55c-7d8588ec0d9e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5f2fe63a-eecb-4639-8bc3-13212da7e8d6
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8687 {grpc_status:14, grpc_message:"Socket closed"}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_30
Server: localhost:8687
Algorithm: FEDAVG
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_30
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_30/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_30/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_30/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_30/test_labels.txt

📊 Raw data loaded:
   Train: X=(1432, 24), y=(1432,)
   Test:  X=(358, 24), y=(358,)

⚠️  Limiting training data: 1432 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  349 samples, 5 features
✅ Client client_30 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

============================================================
🔄 Round 4 - Client client_30
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0760 (↓), lr=0.001000
   • Epoch   2/100: train=0.0791, val=0.0775, patience=1/15, lr=0.001000
   • Epoch   3/100: train=0.0787, val=0.0780, patience=2/15, lr=0.001000
   • Epoch   4/100: train=0.0783, val=0.0782, patience=3/15, lr=0.001000
   • Epoch   5/100: train=0.0780, val=0.0782, patience=4/15, lr=0.001000
   📉 Epoch 7: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0757, val=0.0784, patience=10/15, lr=0.000500
   📉 Epoch 15: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0760)

============================================================
📊 Round 4 Summary - Client client_30
   Epochs: 16/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0787, RMSE=0.2805, R²=0.0099
   Val:   Loss=0.0760, RMSE=0.2757, R²=-0.0112
============================================================


📊 Round 4 Test Metrics:
   Loss: 0.0819, RMSE: 0.2861, MAE: 0.2506, R²: 0.0021

📊 Round 4 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2510, R²: -0.0011

============================================================
🔄 Round 6 - Client client_30
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0734 (↓), lr=0.000250
   • Epoch   2/100: train=0.0793, val=0.0740, patience=1/15, lr=0.000250
   • Epoch   3/100: train=0.0791, val=0.0740, patience=2/15, lr=0.000250
   • Epoch   4/100: train=0.0788, val=0.0742, patience=3/15, lr=0.000250
   • Epoch   5/100: train=0.0787, val=0.0742, patience=4/15, lr=0.000250
   📉 Epoch 7: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0776, val=0.0742, patience=10/15, lr=0.000125
   📉 Epoch 15: LR reduced 0.000125 → 0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0734)

============================================================
📊 Round 6 Summary - Client client_30
   Epochs: 16/100 (early stopped)
   LR: 0.000250 → 0.000063 (2 reductions)
   Train: Loss=0.0789, RMSE=0.2809, R²=0.0115
   Val:   Loss=0.0734, RMSE=0.2709, R²=0.0070
============================================================


📊 Round 6 Test Metrics:
   Loss: 0.0823, RMSE: 0.2868, MAE: 0.2510, R²: -0.0027

============================================================
🔄 Round 9 - Client client_30
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0777, val=0.0768 (↓), lr=0.000063
   • Epoch   2/100: train=0.0776, val=0.0766, patience=1/15, lr=0.000063
   • Epoch   3/100: train=0.0774, val=0.0765, patience=2/15, lr=0.000063
   • Epoch   4/100: train=0.0773, val=0.0765, patience=3/15, lr=0.000063
   • Epoch   5/100: train=0.0771, val=0.0765, patience=4/15, lr=0.000063
   📉 Epoch 7: LR reduced 0.000063 → 0.000031
   • Epoch  11/100: train=0.0766, val=0.0764, patience=10/15, lr=0.000031
   📉 Epoch 15: LR reduced 0.000031 → 0.000016

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0768)

============================================================
📊 Round 9 Summary - Client client_30
   Epochs: 16/100 (early stopped)
   LR: 0.000063 → 0.000016 (2 reductions)
   Train: Loss=0.0778, RMSE=0.2789, R²=0.0167
   Val:   Loss=0.0768, RMSE=0.2771, R²=-0.0017
============================================================


📊 Round 9 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2508, R²: -0.0032

============================================================
🔄 Round 11 - Client client_30
   Epochs: 100, Batch: 32, LR: 0.000016
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0780, val=0.0758 (↓), lr=0.000016
   • Epoch   2/100: train=0.0779, val=0.0757, patience=1/15, lr=0.000016
   • Epoch   3/100: train=0.0778, val=0.0757, patience=2/15, lr=0.000016
   • Epoch   4/100: train=0.0777, val=0.0757, patience=3/15, lr=0.000016
   • Epoch   5/100: train=0.0776, val=0.0756, patience=4/15, lr=0.000016
   📉 Epoch 7: LR reduced 0.000016 → 0.000008
   • Epoch  11/100: train=0.0775, val=0.0755, patience=10/15, lr=0.000008
   📉 Epoch 15: LR reduced 0.000008 → 0.000004

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0758)

============================================================
📊 Round 11 Summary - Client client_30
   Epochs: 16/100 (early stopped)
   LR: 0.000016 → 0.000004 (2 reductions)
   Train: Loss=0.0779, RMSE=0.2791, R²=0.0210
   Val:   Loss=0.0758, RMSE=0.2753, R²=-0.0065
============================================================


============================================================
🔄 Round 12 - Client client_30
   Epochs: 100, Batch: 32, LR: 0.000004
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0781, val=0.0756 (↓), lr=0.000004
   • Epoch   2/100: train=0.0780, val=0.0756, patience=1/15, lr=0.000004
   • Epoch   3/100: train=0.0780, val=0.0756, patience=2/15, lr=0.000004
   • Epoch   4/100: train=0.0780, val=0.0755, patience=3/15, lr=0.000004
   • Epoch   5/100: train=0.0780, val=0.0755, patience=4/15, lr=0.000004
   📉 Epoch 7: LR reduced 0.000004 → 0.000002
   • Epoch  11/100: train=0.0779, val=0.0755, patience=10/15, lr=0.000002
   📉 Epoch 15: LR reduced 0.000002 → 0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0756)

============================================================
📊 Round 12 Summary - Client client_30
   Epochs: 16/100 (early stopped)
   LR: 0.000004 → 0.000001 (2 reductions)
   Train: Loss=0.0781, RMSE=0.2795, R²=0.0156
   Val:   Loss=0.0756, RMSE=0.2749, R²=-0.0033
============================================================


============================================================
🔄 Round 13 - Client client_30
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0717 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0717, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0717, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0717, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0717, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0717, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0717)

============================================================
📊 Round 13 Summary - Client client_30
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2812, R²=0.0110
   Val:   Loss=0.0717, RMSE=0.2678, R²=0.0210
============================================================


============================================================
🔄 Round 17 - Client client_30
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0689 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0689, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0689, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0689, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0689, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0689, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0689)

============================================================
📊 Round 17 Summary - Client client_30
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=0.0189
   Val:   Loss=0.0689, RMSE=0.2624, R²=-0.0257
============================================================


📊 Round 17 Test Metrics:
   Loss: 0.0825, RMSE: 0.2873, MAE: 0.2511, R²: -0.0057

============================================================
🔄 Round 19 - Client client_30
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0770, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0770, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0770, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0770, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0770, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0769, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 19 Summary - Client client_30
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0770, RMSE=0.2774, R²=0.0131
   Val:   Loss=0.0797, RMSE=0.2823, R²=0.0225
============================================================


📊 Round 19 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2510, R²: -0.0049

📊 Round 19 Test Metrics:
   Loss: 0.0825, RMSE: 0.2871, MAE: 0.2510, R²: -0.0049

📊 Round 19 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2510, R²: -0.0047

============================================================
🔄 Round 24 - Client client_30
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0775, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0775, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0775, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0774, val=0.0774, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0774, val=0.0774, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0773, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 24 Summary - Client client_30
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0775, RMSE=0.2784, R²=0.0137
   Val:   Loss=0.0773, RMSE=0.2780, R²=-0.0292
============================================================


============================================================
🔄 Round 25 - Client client_30
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0775, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0775, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0775, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0775, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0775, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0774, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 25 Summary - Client client_30
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0774, RMSE=0.2782, R²=0.0061
   Val:   Loss=0.0775, RMSE=0.2784, R²=0.0464
============================================================


📊 Round 25 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2510, R²: -0.0047

📊 Round 25 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2510, R²: -0.0047

============================================================
🔄 Round 28 - Client client_30
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0776, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0776, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0776, val=0.0774, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0776, val=0.0774, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0776, val=0.0774, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0776, val=0.0774, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 28 Summary - Client client_30
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0774, RMSE=0.2783, R²=0.0137
   Val:   Loss=0.0775, RMSE=0.2783, R²=0.0264
============================================================


📊 Round 28 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2510, R²: -0.0048

============================================================
🔄 Round 30 - Client client_30
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0708 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0708, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0708, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0708, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0707, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0707, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0708)

============================================================
📊 Round 30 Summary - Client client_30
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2812, R²=0.0181
   Val:   Loss=0.0708, RMSE=0.2660, R²=0.0067
============================================================


📊 Round 30 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2510, R²: -0.0047

============================================================
🔄 Round 32 - Client client_30
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0777, val=0.0770 (↓), lr=0.000001
   • Epoch   2/100: train=0.0777, val=0.0770, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0777, val=0.0770, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0777, val=0.0770, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0777, val=0.0769, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0777, val=0.0769, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0770)

============================================================
📊 Round 32 Summary - Client client_30
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0776, RMSE=0.2785, R²=0.0127
   Val:   Loss=0.0770, RMSE=0.2774, R²=0.0287
============================================================


📊 Round 32 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2510, R²: -0.0047

📊 Round 32 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2510, R²: -0.0047

============================================================
🔄 Round 34 - Client client_30
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0773, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0773, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0772, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0772, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0772, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0772, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 34 Summary - Client client_30
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0772, RMSE=0.2779, R²=0.0165
   Val:   Loss=0.0783, RMSE=0.2798, R²=0.0113
============================================================


📊 Round 34 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2510, R²: -0.0047

============================================================
🔄 Round 35 - Client client_30
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0770, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0770, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0770, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0770, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0770, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0769, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 35 Summary - Client client_30
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0768, RMSE=0.2771, R²=0.0201
   Val:   Loss=0.0799, RMSE=0.2827, R²=-0.0060
============================================================


📊 Round 35 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2510, R²: -0.0047

============================================================
🔄 Round 37 - Client client_30
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0715 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0715, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0715, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0715, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0715, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0715, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0715)

============================================================
📊 Round 37 Summary - Client client_30
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2809, R²=0.0201
   Val:   Loss=0.0715, RMSE=0.2674, R²=-0.0008
============================================================


============================================================
🔄 Round 38 - Client client_30
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0772, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0772, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0772, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0772, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0772, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0771, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 38 Summary - Client client_30
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0772, RMSE=0.2778, R²=0.0134
   Val:   Loss=0.0784, RMSE=0.2800, R²=0.0243
============================================================


📊 Round 38 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2510, R²: -0.0047

📊 Round 38 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2510, R²: -0.0047

📊 Round 38 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2510, R²: -0.0047

📊 Round 38 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2510, R²: -0.0047

📊 Round 38 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2510, R²: -0.0047

============================================================
🔄 Round 43 - Client client_30
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0778, val=0.0750 (↓), lr=0.000001
   • Epoch   2/100: train=0.0778, val=0.0750, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0778, val=0.0750, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0778, val=0.0750, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0778, val=0.0750, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0777, val=0.0750, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0750)

============================================================
📊 Round 43 Summary - Client client_30
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0780, RMSE=0.2794, R²=0.0157
   Val:   Loss=0.0750, RMSE=0.2738, R²=0.0096
============================================================


📊 Round 43 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2510, R²: -0.0047

📊 Round 43 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2510, R²: -0.0047

============================================================
🔄 Round 49 - Client client_30
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0750, val=0.0868 (↓), lr=0.000001
   • Epoch   2/100: train=0.0750, val=0.0868, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0750, val=0.0868, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0749, val=0.0868, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0749, val=0.0868, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0749, val=0.0868, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0868)

============================================================
📊 Round 49 Summary - Client client_30
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0751, RMSE=0.2740, R²=0.0213
   Val:   Loss=0.0868, RMSE=0.2946, R²=-0.0012
============================================================


============================================================
🔄 Round 50 - Client client_30
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0767, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0767, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0767, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0767, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0767, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0766, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 50 Summary - Client client_30
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0768, RMSE=0.2771, R²=0.0123
   Val:   Loss=0.0801, RMSE=0.2829, R²=0.0301
============================================================


📊 Round 50 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2510, R²: -0.0047

============================================================
🔄 Round 51 - Client client_30
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0761, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0760, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0760, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0760, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0760, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0760, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 51 Summary - Client client_30
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0760, RMSE=0.2758, R²=0.0216
   Val:   Loss=0.0829, RMSE=0.2880, R²=-0.0091
============================================================


============================================================
🔄 Round 53 - Client client_30
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0723 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0723, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0723, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0723, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0723, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0724, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0723)

============================================================
📊 Round 53 Summary - Client client_30
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2805, R²=0.0144
   Val:   Loss=0.0723, RMSE=0.2689, R²=0.0042
============================================================


============================================================
🔄 Round 54 - Client client_30
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0750, val=0.0873 (↓), lr=0.000001
   • Epoch   2/100: train=0.0750, val=0.0873, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0750, val=0.0873, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0750, val=0.0873, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0749, val=0.0873, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0749, val=0.0873, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0873)

============================================================
📊 Round 54 Summary - Client client_30
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0750, RMSE=0.2738, R²=0.0173
   Val:   Loss=0.0873, RMSE=0.2954, R²=0.0059
============================================================


============================================================
🔄 Round 55 - Client client_30
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0699 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0700, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0700, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0700, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0700, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0702, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0699)

============================================================
📊 Round 55 Summary - Client client_30
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2816, R²=0.0076
   Val:   Loss=0.0699, RMSE=0.2645, R²=0.0202
============================================================


============================================================
🔄 Round 56 - Client client_30
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0770, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0770, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0770, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0770, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0770, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0769, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 56 Summary - Client client_30
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0768, RMSE=0.2771, R²=0.0250
   Val:   Loss=0.0800, RMSE=0.2829, R²=-0.0177
============================================================


📊 Round 56 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2510, R²: -0.0047

📊 Round 56 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2510, R²: -0.0047

============================================================
🔄 Round 60 - Client client_30
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0778, val=0.0748 (↓), lr=0.000001
   • Epoch   2/100: train=0.0778, val=0.0748, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0778, val=0.0748, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0778, val=0.0748, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0778, val=0.0748, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0778, val=0.0748, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0748)

============================================================
📊 Round 60 Summary - Client client_30
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0781, RMSE=0.2794, R²=0.0148
   Val:   Loss=0.0748, RMSE=0.2736, R²=0.0234
============================================================


📊 Round 60 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2510, R²: -0.0047

============================================================
🔄 Round 61 - Client client_30
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0778, val=0.0758 (↓), lr=0.000001
   • Epoch   2/100: train=0.0778, val=0.0758, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0778, val=0.0758, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0778, val=0.0758, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0778, val=0.0758, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0777, val=0.0758, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0758)

============================================================
📊 Round 61 Summary - Client client_30
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0778, RMSE=0.2790, R²=0.0131
   Val:   Loss=0.0758, RMSE=0.2753, R²=0.0253
============================================================


============================================================
🔄 Round 62 - Client client_30
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0758, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0758, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0758, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0758, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0758, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0758, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 62 Summary - Client client_30
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0758, RMSE=0.2753, R²=0.0161
   Val:   Loss=0.0838, RMSE=0.2896, R²=0.0140
============================================================


📊 Round 62 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2510, R²: -0.0047

📊 Round 62 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2510, R²: -0.0047

📊 Round 62 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2510, R²: -0.0047

📊 Round 62 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2510, R²: -0.0047

📊 Round 62 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2510, R²: -0.0046

📊 Round 62 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2510, R²: -0.0046

============================================================
🔄 Round 70 - Client client_30
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0779, val=0.0755 (↓), lr=0.000001
   • Epoch   2/100: train=0.0779, val=0.0755, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0778, val=0.0755, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0778, val=0.0755, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0778, val=0.0755, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0777, val=0.0756, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0755)

============================================================
📊 Round 70 Summary - Client client_30
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0779, RMSE=0.2791, R²=0.0196
   Val:   Loss=0.0755, RMSE=0.2748, R²=-0.0022
============================================================


📊 Round 70 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2510, R²: -0.0046

============================================================
🔄 Round 72 - Client client_30
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0756, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0756, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0756, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0756, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0755, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0755, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 72 Summary - Client client_30
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0755, RMSE=0.2748, R²=0.0142
   Val:   Loss=0.0851, RMSE=0.2917, R²=0.0145
============================================================


📊 Round 72 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2510, R²: -0.0046

============================================================
🔄 Round 73 - Client client_30
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0773, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0773, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0773, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0773, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0772, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0772, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 73 Summary - Client client_30
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0772, RMSE=0.2778, R²=0.0142
   Val:   Loss=0.0785, RMSE=0.2801, R²=0.0222
============================================================


============================================================
🔄 Round 76 - Client client_30
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0774, val=0.0777 (↓), lr=0.000001
   • Epoch   2/100: train=0.0774, val=0.0777, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0774, val=0.0777, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0774, val=0.0777, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0774, val=0.0777, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0773, val=0.0777, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 76 Summary - Client client_30
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0773, RMSE=0.2781, R²=0.0131
   Val:   Loss=0.0777, RMSE=0.2787, R²=0.0266
============================================================


============================================================
🔄 Round 78 - Client client_30
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0761, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0761, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0761, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0760, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0760, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0760, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 78 Summary - Client client_30
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0762, RMSE=0.2760, R²=0.0067
   Val:   Loss=0.0825, RMSE=0.2872, R²=0.0504
============================================================


📊 Round 78 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2510, R²: -0.0046

============================================================
🔄 Round 82 - Client client_30
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0774, val=0.0777 (↓), lr=0.000001
   • Epoch   2/100: train=0.0774, val=0.0777, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0774, val=0.0777, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0773, val=0.0777, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0773, val=0.0777, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0773, val=0.0777, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 82 Summary - Client client_30
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0773, RMSE=0.2781, R²=0.0141
   Val:   Loss=0.0777, RMSE=0.2788, R²=0.0261
============================================================


============================================================
🔄 Round 83 - Client client_30
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0758, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0758, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0758, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0758, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0758, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0758, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 83 Summary - Client client_30
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0759, RMSE=0.2755, R²=0.0194
   Val:   Loss=0.0835, RMSE=0.2890, R²=0.0053
============================================================


📊 Round 83 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2510, R²: -0.0046

============================================================
🔄 Round 84 - Client client_30
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0773, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0773, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0773, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0773, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0772, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0772, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 84 Summary - Client client_30
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0772, RMSE=0.2778, R²=0.0128
   Val:   Loss=0.0784, RMSE=0.2800, R²=0.0059
============================================================


============================================================
🔄 Round 86 - Client client_30
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0765, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0765, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0765, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0765, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0764, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0764, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 86 Summary - Client client_30
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0763, RMSE=0.2763, R²=0.0246
   Val:   Loss=0.0817, RMSE=0.2858, R²=-0.0195
============================================================


📊 Round 86 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2510, R²: -0.0046

📊 Round 86 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2510, R²: -0.0046

📊 Round 86 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2510, R²: -0.0046

📊 Round 86 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2510, R²: -0.0046

📊 Round 86 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2510, R²: -0.0046

============================================================
🔄 Round 94 - Client client_30
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0771, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0771, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0771, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0771, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0771, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0771, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 94 Summary - Client client_30
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0771, RMSE=0.2777, R²=0.0233
   Val:   Loss=0.0785, RMSE=0.2802, R²=-0.0124
============================================================


📊 Round 94 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2510, R²: -0.0046

============================================================
🔄 Round 95 - Client client_30
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0754, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0754, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0754, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0753, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0753, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0753, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 95 Summary - Client client_30
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0754, RMSE=0.2746, R²=0.0140
   Val:   Loss=0.0853, RMSE=0.2921, R²=0.0043
============================================================


📊 Round 95 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2510, R²: -0.0046

============================================================
🔄 Round 99 - Client client_30
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0770, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0770, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0770, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0769, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0769, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0769, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 99 Summary - Client client_30
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0769, RMSE=0.2773, R²=0.0157
   Val:   Loss=0.0795, RMSE=0.2819, R²=0.0191
============================================================


📊 Round 99 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2510, R²: -0.0046

📊 Round 99 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2510, R²: -0.0046

============================================================
🔄 Round 103 - Client client_30
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0763, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0763, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0763, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0763, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0763, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0762, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 103 Summary - Client client_30
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0763, RMSE=0.2762, R²=0.0177
   Val:   Loss=0.0819, RMSE=0.2861, R²=0.0121
============================================================


📊 Round 103 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2510, R²: -0.0046

📊 Round 103 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2510, R²: -0.0046

📊 Round 103 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2510, R²: -0.0046

============================================================
🔄 Round 107 - Client client_30
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0768, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0768, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0768, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0767, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0767, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0767, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 107 Summary - Client client_30
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0769, RMSE=0.2774, R²=0.0156
   Val:   Loss=0.0792, RMSE=0.2815, R²=0.0204
============================================================


📊 Round 107 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2510, R²: -0.0046

📊 Round 107 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2510, R²: -0.0046

📊 Round 107 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2510, R²: -0.0046

============================================================
🔄 Round 112 - Client client_30
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0777, val=0.0759 (↓), lr=0.000001
   • Epoch   2/100: train=0.0777, val=0.0759, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0777, val=0.0759, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0777, val=0.0759, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0777, val=0.0759, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0776, val=0.0759, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0759)

============================================================
📊 Round 112 Summary - Client client_30
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0778, RMSE=0.2789, R²=0.0140
   Val:   Loss=0.0759, RMSE=0.2755, R²=0.0272
============================================================


============================================================
🔄 Round 113 - Client client_30
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0719 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0719, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0719, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0719, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0719, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0719, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0719)

============================================================
📊 Round 113 Summary - Client client_30
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2806, R²=0.0223
   Val:   Loss=0.0719, RMSE=0.2682, R²=-0.0088
============================================================


============================================================
🔄 Round 114 - Client client_30
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0758, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0758, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0758, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0758, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0758, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0757, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 114 Summary - Client client_30
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0756, RMSE=0.2749, R²=0.0153
   Val:   Loss=0.0846, RMSE=0.2909, R²=0.0203
============================================================


📊 Round 114 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2510, R²: -0.0046

============================================================
🔄 Round 116 - Client client_30
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0774, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0774, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0774, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0774, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0774, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0773, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 116 Summary - Client client_30
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0772, RMSE=0.2778, R²=0.0216
   Val:   Loss=0.0783, RMSE=0.2798, R²=-0.0039
============================================================


============================================================
🔄 Round 117 - Client client_30
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0771, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0771, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0771, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0771, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0771, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0771, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 117 Summary - Client client_30
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0772, RMSE=0.2779, R²=0.0207
   Val:   Loss=0.0781, RMSE=0.2795, R²=-0.0049
============================================================


📊 Round 117 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2510, R²: -0.0046

============================================================
🔄 Round 118 - Client client_30
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0776, val=0.0768 (↓), lr=0.000001
   • Epoch   2/100: train=0.0776, val=0.0768, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0776, val=0.0768, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0776, val=0.0768, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0776, val=0.0768, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0775, val=0.0768, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0768)

============================================================
📊 Round 118 Summary - Client client_30
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0775, RMSE=0.2785, R²=0.0112
   Val:   Loss=0.0768, RMSE=0.2772, R²=0.0379
============================================================


📊 Round 118 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2510, R²: -0.0045

============================================================
🔄 Round 121 - Client client_30
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0740 (↓), lr=0.000001
   • Epoch   2/100: train=0.0785, val=0.0740, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0785, val=0.0740, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0740, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0740, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0740, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0740)

============================================================
📊 Round 121 Summary - Client client_30
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0783, RMSE=0.2798, R²=0.0151
   Val:   Loss=0.0740, RMSE=0.2719, R²=0.0228
============================================================


📊 Round 121 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2510, R²: -0.0046

📊 Round 121 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2510, R²: -0.0045

📊 Round 121 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2510, R²: -0.0046

============================================================
🔄 Round 125 - Client client_30
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0773, val=0.0776 (↓), lr=0.000001
   • Epoch   2/100: train=0.0773, val=0.0776, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0772, val=0.0776, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0772, val=0.0776, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0772, val=0.0776, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0772, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 125 Summary - Client client_30
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0773, RMSE=0.2781, R²=0.0153
   Val:   Loss=0.0776, RMSE=0.2786, R²=0.0211
============================================================


📊 Round 125 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2510, R²: -0.0045

============================================================
🔄 Round 126 - Client client_30
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0775, val=0.0774 (↓), lr=0.000001
   • Epoch   2/100: train=0.0774, val=0.0774, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0774, val=0.0774, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0774, val=0.0774, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0774, val=0.0774, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0773, val=0.0774, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0774)

============================================================
📊 Round 126 Summary - Client client_30
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0774, RMSE=0.2782, R²=0.0221
   Val:   Loss=0.0774, RMSE=0.2781, R²=-0.0138
============================================================


============================================================
🔄 Round 129 - Client client_30
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0776, val=0.0770 (↓), lr=0.000001
   • Epoch   2/100: train=0.0776, val=0.0771, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0776, val=0.0771, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0776, val=0.0771, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0776, val=0.0771, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0775, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0770)

============================================================
📊 Round 129 Summary - Client client_30
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0775, RMSE=0.2783, R²=0.0138
   Val:   Loss=0.0770, RMSE=0.2776, R²=0.0080
============================================================


============================================================
🔄 Round 131 - Client client_30
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0768, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0768, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0768, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0768, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0768, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0768, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 131 Summary - Client client_30
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0770, RMSE=0.2774, R²=0.0202
   Val:   Loss=0.0791, RMSE=0.2812, R²=0.0026
============================================================


📊 Round 131 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2510, R²: -0.0046

============================================================
🔄 Round 132 - Client client_30
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0748, val=0.0871 (↓), lr=0.000001
   • Epoch   2/100: train=0.0747, val=0.0871, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0747, val=0.0871, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0747, val=0.0871, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0747, val=0.0872, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0746, val=0.0873, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0871)

============================================================
📊 Round 132 Summary - Client client_30
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0750, RMSE=0.2738, R²=0.0140
   Val:   Loss=0.0871, RMSE=0.2951, R²=0.0049
============================================================


📊 Round 132 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2510, R²: -0.0046

📊 Round 132 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2510, R²: -0.0046

============================================================
🔄 Round 135 - Client client_30
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0783, val=0.0744 (↓), lr=0.000001
   • Epoch   2/100: train=0.0783, val=0.0744, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0783, val=0.0744, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0783, val=0.0744, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0783, val=0.0744, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0782, val=0.0744, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0744)

============================================================
📊 Round 135 Summary - Client client_30
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0781, RMSE=0.2795, R²=0.0121
   Val:   Loss=0.0744, RMSE=0.2728, R²=0.0365
============================================================


============================================================
🔄 Round 136 - Client client_30
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0782, val=0.0741 (↓), lr=0.000001
   • Epoch   2/100: train=0.0782, val=0.0741, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0782, val=0.0741, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0782, val=0.0741, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0782, val=0.0741, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0781, val=0.0741, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0741)

============================================================
📊 Round 136 Summary - Client client_30
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0782, RMSE=0.2796, R²=0.0179
   Val:   Loss=0.0741, RMSE=0.2723, R²=0.0076
============================================================


📊 Round 136 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2510, R²: -0.0046

============================================================
🔄 Round 138 - Client client_30
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0779, val=0.0757 (↓), lr=0.000001
   • Epoch   2/100: train=0.0779, val=0.0757, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0779, val=0.0757, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0779, val=0.0757, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0779, val=0.0757, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0778, val=0.0757, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0757)

============================================================
📊 Round 138 Summary - Client client_30
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0778, RMSE=0.2789, R²=0.0165
   Val:   Loss=0.0757, RMSE=0.2751, R²=0.0164
============================================================


============================================================
🔄 Round 140 - Client client_30
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0771, val=0.0777 (↓), lr=0.000001
   • Epoch   2/100: train=0.0771, val=0.0777, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0771, val=0.0777, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0771, val=0.0777, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0771, val=0.0777, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0770, val=0.0777, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 140 Summary - Client client_30
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0773, RMSE=0.2780, R²=0.0199
   Val:   Loss=0.0777, RMSE=0.2788, R²=0.0045
============================================================


============================================================
🔄 Round 141 - Client client_30
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0774, val=0.0779 (↓), lr=0.000001
   • Epoch   2/100: train=0.0774, val=0.0779, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0774, val=0.0779, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0774, val=0.0779, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0774, val=0.0779, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0774, val=0.0779, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0779)

============================================================
📊 Round 141 Summary - Client client_30
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0773, RMSE=0.2779, R²=0.0184
   Val:   Loss=0.0779, RMSE=0.2792, R²=-0.0149
============================================================


📊 Round 141 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2510, R²: -0.0046

📊 Round 141 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2510, R²: -0.0046

📊 Round 141 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2510, R²: -0.0046

============================================================
🔄 Round 147 - Client client_30
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0777, val=0.0762 (↓), lr=0.000001
   • Epoch   2/100: train=0.0777, val=0.0762, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0776, val=0.0762, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0776, val=0.0762, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0776, val=0.0762, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0776, val=0.0762, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0762)

============================================================
📊 Round 147 Summary - Client client_30
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0777, RMSE=0.2787, R²=0.0200
   Val:   Loss=0.0762, RMSE=0.2761, R²=0.0040
============================================================


📊 Round 147 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2510, R²: -0.0046

📊 Round 147 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2510, R²: -0.0046

============================================================
🔄 Round 152 - Client client_30
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0724 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0724, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0724, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0724, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0724, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0724, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0724)

============================================================
📊 Round 152 Summary - Client client_30
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2804, R²=0.0179
   Val:   Loss=0.0724, RMSE=0.2691, R²=0.0107
============================================================


============================================================
🔄 Round 153 - Client client_30
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0725 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0725, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0725, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0725, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0725, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0785, val=0.0724, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0725)

============================================================
📊 Round 153 Summary - Client client_30
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2803, R²=0.0236
   Val:   Loss=0.0725, RMSE=0.2693, R²=-0.0150
============================================================


============================================================
🔄 Round 154 - Client client_30
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0771, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0771, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0771, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0771, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0770, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0770, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 154 Summary - Client client_30
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0771, RMSE=0.2777, R²=0.0160
   Val:   Loss=0.0784, RMSE=0.2800, R²=0.0116
============================================================


📊 Round 154 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2510, R²: -0.0046

============================================================
🔄 Round 156 - Client client_30
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0734 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0734, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0734, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0785, val=0.0734, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0785, val=0.0734, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0735, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0734)

============================================================
📊 Round 156 Summary - Client client_30
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2800, R²=0.0104
   Val:   Loss=0.0734, RMSE=0.2709, R²=0.0326
============================================================


📊 Round 156 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2510, R²: -0.0046

============================================================
🔄 Round 158 - Client client_30
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0757, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0757, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0757, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0757, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0757, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0756, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 158 Summary - Client client_30
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0759, RMSE=0.2755, R²=0.0094
   Val:   Loss=0.0832, RMSE=0.2884, R²=0.0404
============================================================


📊 Round 158 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2510, R²: -0.0046

📊 Round 158 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2510, R²: -0.0046

📊 Round 158 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2510, R²: -0.0046

============================================================
🔄 Round 163 - Client client_30
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0767, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0767, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0767, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0767, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0766, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0766, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 163 Summary - Client client_30
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0764, RMSE=0.2764, R²=0.0101
   Val:   Loss=0.0813, RMSE=0.2852, R²=0.0421
============================================================


📊 Round 163 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2510, R²: -0.0046

============================================================
🔄 Round 164 - Client client_30
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0767, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0767, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0767, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0767, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0767, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0767, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 164 Summary - Client client_30
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0768, RMSE=0.2771, R²=0.0217
   Val:   Loss=0.0798, RMSE=0.2825, R²=-0.0038
============================================================


📊 Round 164 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2510, R²: -0.0047

📊 Round 164 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2510, R²: -0.0047

📊 Round 164 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2510, R²: -0.0047

📊 Round 164 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2510, R²: -0.0047

============================================================
🔄 Round 171 - Client client_30
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0775, val=0.0770 (↓), lr=0.000001
   • Epoch   2/100: train=0.0774, val=0.0770, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0774, val=0.0770, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0774, val=0.0770, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0774, val=0.0770, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0774, val=0.0770, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0770)

============================================================
📊 Round 171 Summary - Client client_30
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0775, RMSE=0.2783, R²=0.0259
   Val:   Loss=0.0770, RMSE=0.2775, R²=-0.0235
============================================================


📊 Round 171 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2510, R²: -0.0047

============================================================
🔄 Round 172 - Client client_30
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0687 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0687, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0687, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0687, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0687, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0687, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0687)

============================================================
📊 Round 172 Summary - Client client_30
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2820, R²=0.0246
   Val:   Loss=0.0687, RMSE=0.2621, R²=-0.0471
============================================================


📊 Round 172 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2510, R²: -0.0047

📊 Round 172 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2510, R²: -0.0047

📊 Round 172 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2510, R²: -0.0047

============================================================
🔄 Round 182 - Client client_30
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0782, val=0.0736 (↓), lr=0.000001
   • Epoch   2/100: train=0.0782, val=0.0736, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0782, val=0.0737, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0782, val=0.0737, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0782, val=0.0737, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0781, val=0.0737, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0736)

============================================================
📊 Round 182 Summary - Client client_30
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0783, RMSE=0.2798, R²=0.0100
   Val:   Loss=0.0736, RMSE=0.2714, R²=0.0321
============================================================


📊 Round 182 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2510, R²: -0.0047

📊 Round 182 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2510, R²: -0.0047

============================================================
🔄 Round 184 - Client client_30
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0779, val=0.0754 (↓), lr=0.000001
   • Epoch   2/100: train=0.0779, val=0.0754, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0779, val=0.0754, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0779, val=0.0754, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0778, val=0.0754, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0778, val=0.0754, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0754)

============================================================
📊 Round 184 Summary - Client client_30
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0779, RMSE=0.2790, R²=0.0213
   Val:   Loss=0.0754, RMSE=0.2746, R²=-0.0019
============================================================


📊 Round 184 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2510, R²: -0.0047

============================================================
🔄 Round 189 - Client client_30
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0777, val=0.0753 (↓), lr=0.000001
   • Epoch   2/100: train=0.0777, val=0.0753, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0777, val=0.0753, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0777, val=0.0752, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0777, val=0.0752, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0777, val=0.0752, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0753)

============================================================
📊 Round 189 Summary - Client client_30
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0779, RMSE=0.2791, R²=0.0233
   Val:   Loss=0.0753, RMSE=0.2743, R²=-0.0209
============================================================


============================================================
🔄 Round 190 - Client client_30
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0783, val=0.0733 (↓), lr=0.000001
   • Epoch   2/100: train=0.0783, val=0.0733, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0783, val=0.0733, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0783, val=0.0733, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0783, val=0.0733, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0733, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0733)

============================================================
📊 Round 190 Summary - Client client_30
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2799, R²=0.0174
   Val:   Loss=0.0733, RMSE=0.2708, R²=0.0163
============================================================


📊 Round 190 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2510, R²: -0.0048

📊 Round 190 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2510, R²: -0.0048

============================================================
🔄 Round 192 - Client client_30
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0770, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0770, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0770, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0770, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0770, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0769, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 192 Summary - Client client_30
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0770, RMSE=0.2776, R²=0.0145
   Val:   Loss=0.0786, RMSE=0.2804, R²=0.0142
============================================================


📊 Round 192 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2510, R²: -0.0048

📊 Round 192 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2510, R²: -0.0048

============================================================
🔄 Round 199 - Client client_30
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0780, val=0.0754 (↓), lr=0.000001
   • Epoch   2/100: train=0.0780, val=0.0754, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0780, val=0.0754, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0780, val=0.0754, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0780, val=0.0754, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0780, val=0.0754, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0754)

============================================================
📊 Round 199 Summary - Client client_30
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0779, RMSE=0.2790, R²=0.0155
   Val:   Loss=0.0754, RMSE=0.2746, R²=0.0240
============================================================


============================================================
🔄 Round 200 - Client client_30
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0689 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0689, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0689, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0689, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0689, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0688, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0689)

============================================================
📊 Round 200 Summary - Client client_30
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2819, R²=0.0171
   Val:   Loss=0.0689, RMSE=0.2625, R²=0.0164
============================================================


📊 Round 200 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2510, R²: -0.0048

📊 Round 200 Test Metrics:
   Loss: 0.0825, RMSE: 0.2871, MAE: 0.2510, R²: -0.0049

============================================================
🔄 Round 205 - Client client_30
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0761, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0761, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0761, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0760, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0760, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0760, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 205 Summary - Client client_30
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0760, RMSE=0.2756, R²=0.0201
   Val:   Loss=0.0830, RMSE=0.2880, R²=-0.0008
============================================================


============================================================
🔄 Round 206 - Client client_30
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0769, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0769, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0769, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0769, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0769, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0768, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 206 Summary - Client client_30
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0768, RMSE=0.2772, R²=0.0167
   Val:   Loss=0.0794, RMSE=0.2818, R²=0.0145
============================================================


============================================================
🔄 Round 207 - Client client_30
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0762, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0762, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0762, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0762, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0762, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0762, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 207 Summary - Client client_30
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0759, RMSE=0.2755, R²=0.0201
   Val:   Loss=0.0831, RMSE=0.2882, R²=0.0066
============================================================


📊 Round 207 Test Metrics:
   Loss: 0.0825, RMSE: 0.2871, MAE: 0.2510, R²: -0.0049

============================================================
🔄 Round 210 - Client client_30
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0727 (↓), lr=0.000001
   • Epoch   2/100: train=0.0783, val=0.0727, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0783, val=0.0727, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0783, val=0.0727, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0783, val=0.0727, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0727, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0727)

============================================================
📊 Round 210 Summary - Client client_30
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2802, R²=0.0118
   Val:   Loss=0.0727, RMSE=0.2697, R²=0.0377
============================================================


============================================================
🔄 Round 213 - Client client_30
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0770, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0770, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0769, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0769, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0769, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0769, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 213 Summary - Client client_30
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0771, RMSE=0.2776, R²=0.0136
   Val:   Loss=0.0785, RMSE=0.2802, R²=0.0312
============================================================


📊 Round 213 Test Metrics:
   Loss: 0.0825, RMSE: 0.2871, MAE: 0.2510, R²: -0.0049

============================================================
🔄 Round 214 - Client client_30
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0768, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0768, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0768, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0768, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0768, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0767, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 214 Summary - Client client_30
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0767, RMSE=0.2770, R²=0.0150
   Val:   Loss=0.0800, RMSE=0.2828, R²=-0.0076
============================================================


📊 Round 214 Test Metrics:
   Loss: 0.0825, RMSE: 0.2871, MAE: 0.2510, R²: -0.0049

============================================================
🔄 Round 216 - Client client_30
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0777, val=0.0755 (↓), lr=0.000001
   • Epoch   2/100: train=0.0777, val=0.0755, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0777, val=0.0755, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0777, val=0.0756, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0777, val=0.0756, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0776, val=0.0756, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0755)

============================================================
📊 Round 216 Summary - Client client_30
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0778, RMSE=0.2789, R²=0.0153
   Val:   Loss=0.0755, RMSE=0.2748, R²=0.0159
============================================================


============================================================
🔄 Round 217 - Client client_30
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0765, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0765, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0765, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0765, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0765, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0765, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 217 Summary - Client client_30
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0766, RMSE=0.2768, R²=0.0126
   Val:   Loss=0.0804, RMSE=0.2835, R²=0.0339
============================================================


📊 Round 217 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2510, R²: -0.0049

============================================================
🔄 Round 219 - Client client_30
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0781, val=0.0741 (↓), lr=0.000001
   • Epoch   2/100: train=0.0781, val=0.0741, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0781, val=0.0741, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0781, val=0.0741, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0781, val=0.0741, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0780, val=0.0740, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0741)

============================================================
📊 Round 219 Summary - Client client_30
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0782, RMSE=0.2796, R²=0.0164
   Val:   Loss=0.0741, RMSE=0.2722, R²=0.0199
============================================================


📊 Round 219 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2510, R²: -0.0049

============================================================
🔄 Round 222 - Client client_30
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0776, val=0.0758 (↓), lr=0.000001
   • Epoch   2/100: train=0.0776, val=0.0758, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0776, val=0.0758, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0776, val=0.0758, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0776, val=0.0758, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0776, val=0.0758, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0758)

============================================================
📊 Round 222 Summary - Client client_30
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0777, RMSE=0.2788, R²=0.0182
   Val:   Loss=0.0758, RMSE=0.2754, R²=0.0122
============================================================


📊 Round 222 Test Metrics:
   Loss: 0.0825, RMSE: 0.2871, MAE: 0.2510, R²: -0.0049

📊 Round 222 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2510, R²: -0.0049

============================================================
🔄 Round 224 - Client client_30
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0779, val=0.0751 (↓), lr=0.000001
   • Epoch   2/100: train=0.0779, val=0.0751, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0779, val=0.0751, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0779, val=0.0751, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0779, val=0.0751, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0779, val=0.0751, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0751)

============================================================
📊 Round 224 Summary - Client client_30
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0779, RMSE=0.2791, R²=0.0197
   Val:   Loss=0.0751, RMSE=0.2741, R²=0.0024
============================================================


📊 Round 224 Test Metrics:
   Loss: 0.0825, RMSE: 0.2871, MAE: 0.2510, R²: -0.0049

❌ Client client_30 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8687 {grpc_status:14, grpc_message:"Socket closed"}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8687 {grpc_status:14, grpc_message:"Socket closed"}"
>
