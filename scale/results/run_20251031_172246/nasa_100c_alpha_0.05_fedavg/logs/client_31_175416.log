[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dfac707c-228e-4b98-a20a-114d309a7421
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d33aa61f-99f4-40ac-8a27-8af0c98bdb93
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1fa5022a-8693-4630-9f95-f927bd52aef4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1f34c7bb-eb12-48f6-a6b6-f4a11dcc7323
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 26e457a3-b9af-4de9-8641-631169fecf90
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b806d56f-de25-4a7f-8f70-dd31e084f602
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bcef4842-0ab0-4f31-a5b0-bfcb1fea0fe6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 63bc208e-5fe6-44ea-b206-2f8fd1f4f60c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0fb3d01c-e562-4133-9383-2cd9d5a5a774
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a7703874-3d85-4cb2-b391-f5c2d1c1b20b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e88d182e-1d4d-4e7c-a73c-1993e541d96b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 46afdd41-f0d7-4b3a-b553-1abc9fe5c903
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5cf15b21-bac1-4cfc-9d58-f22402451ede
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2362c047-5e70-4ce7-9ee0-c0d854dda10a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ba829c3b-7344-406a-bccb-903c0d80b67f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d584f075-d640-416c-b87b-f88a3379220f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8e40c0b8-b114-4b85-a54a-60d0d58598db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 75c3b39b-f192-4401-8a2b-b9e6e6ed3b27
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 62075574-0be2-40c8-a69b-c4b2624755f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fe13256b-46fb-4783-9ff3-076d1af7369b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6fc3b927-7664-452c-a482-3d689172915a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0dae0ca9-eb00-4f54-b213-438eec9ba8f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f2a9a985-c7c4-4267-a2c2-22429b2528d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6d90f285-111e-4208-bd42-94e3a6d16712
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9e78fe71-be6d-40b4-a45e-702dcaa56b1b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 476146c7-99bd-4dcc-8ee7-d6b39b78555b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a911fd79-2498-4786-8590-29681aa9c04d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 88ded3b8-2a21-415a-ab35-8b8359a20119
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 22919fc8-0978-4af8-9d26-ff02f8ccee1b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3130bed1-7f2f-4867-b9db-b8b29f5dda13
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ff3bfcdc-1e8c-4a79-a9c6-d89666528722
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6df573b1-a7dc-4ab9-bada-a134d170e060
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8c1ad441-55c1-4dd9-9e08-de7b9c73b39a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8311e7d4-e765-4b5b-8272-601b4eff1be9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9d669bd8-45c6-435a-9b86-96144529777b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d0486ac4-000a-4e06-bfa3-ce7ac8f69fe0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 48fc2341-8b48-40d5-ab41-850014ee608b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eb59269b-76f6-46f9-881f-66c4b07bcad7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 02fa8057-f232-4b4f-bad4-a38fd8c49825
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2a4f8e43-0c54-4815-9383-201da9a13dd9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ba35549d-732f-48f1-b708-39f6a9a99f52
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fce2ee2a-f9ed-4bc4-8b2b-e8ac3050ecd5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2d41557e-88d9-4fba-a853-0a8e7da3866e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5d5d3097-30c0-44da-9ba7-fe9134d7bcb0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ad0a9c49-d42b-4893-b9e0-516ca9004e93
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fe6bb89e-264e-4d52-b39d-16faf8295e73
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1601ac12-6826-4969-b40b-307aeac62321
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 53522328-38bb-4192-bcdd-8a8430990ec5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ccb46d80-2333-435b-ae26-e67a987a8273
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 177c7618-be85-483e-a79a-42230b457ce0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3355390a-6939-47b7-b1a9-c78cddfbc36c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2934fbf8-8d87-43ee-9a1c-704f0ece293d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a1d0eec4-a902-4a37-90f5-8a0cd357660f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message be8f7799-9267-49d1-a72b-231f99034277
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 841766cd-d9d8-44ac-a4bf-22c8e6c467bc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 36642d3c-05ab-4975-9ea8-bfbf994520e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e84a1d2c-c2d1-48d8-9c64-d185c41c81ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7dde5f3c-a115-42b4-8e14-7ca6a90309bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1e5e91c0-c078-4ad1-84a0-72ddf7b593ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 96a3f01f-cbfb-4b7b-85d3-7943803409aa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e07e5c99-3f9f-499c-9ba1-6841c4754467
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 23cc57c2-a93c-49a8-a415-3e94e359aa3f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d29a3249-e38f-439b-b7c0-9ffcbbef8393
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6708954a-a4fe-432e-b856-cf4f0290e4c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a6b46917-03b9-4ceb-90ec-69d341a0e2cd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e6efefe4-10fe-488e-8075-60146bdf2d88
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 964b79bf-e7d2-402e-a14f-7ca1f11ef80d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6e008596-5aeb-44ae-ab3c-387ed865c89e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 57f83a17-572c-4fec-911b-e3eb8c40f72a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message da90d79c-fcd2-4159-8532-84a727e06e0a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 37ee0ccb-bdaa-4111-9778-8a63c55d4b35
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 559f665a-77d0-4d60-8979-5a592a7738ea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1ae93920-dae3-4017-b213-11fc732b0d85
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 22867453-d03b-49e2-838f-c0fe1ce18bf4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a4bc9862-22af-4bb7-8984-bf0ea8115b33
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 331574ec-9ce9-48dc-9957-024e30a0684a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e63d85f4-0ec0-4859-81fc-f1d1fb493900
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3de70267-8d64-4875-82e3-6622461a1086
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1f15851a-1ac0-4a23-a984-081f2e7755a7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2d1836ff-5f2a-4cfe-b8a4-d92705252949
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b3988471-28ac-4380-a374-9bba122bd3ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 418bb097-34c8-436c-b8d8-22a240920765
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dea9b224-de60-48f7-afc2-584513cc0f19
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6dc3e460-1e9b-42e0-81c1-423cf29952cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5014c9bd-1980-450f-a096-8760e23e9bc2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ee23701c-cc31-412c-a4fd-301097be52a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 05177775-9bbb-4b89-bf80-e16d343a98df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 89ba9407-1f9c-4036-a6b3-a17636504d83
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5032400e-5c75-448e-b90f-de66e75c014f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9aace579-d09a-4323-968e-13391fffc45b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message def638b9-8da4-4566-bf0a-2c329f80eb24
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 788a9070-f14d-4b31-a372-e1ba3bf34160
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a4caf38a-c88e-4e25-8bd2-4db23935e81e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 74839f2c-7041-42df-8254-f30d1a5674b9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fff7ca6e-11ab-4716-a72e-52fc105178d9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c60810c7-ff09-422a-917e-b51c3f768032
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 95f4aa64-260d-4206-9f7f-9dc157f3fe75
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3035e342-99c7-4dae-baac-cb1b66bc65d9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 55f1d91f-0024-40ca-9a67-1df153ee85f4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 78e831a5-5579-4aac-8f5b-3ca331af8f2e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bd268e80-8bcc-4882-a029-4cc7f029e335
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eb14c3ec-3c0c-4fdc-adc6-c488539fd58a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fc20c486-3f76-482f-8e02-a02229a7bd55
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 344ad545-5cf0-4b81-887c-76e30dc50359
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5d4c3e9e-06ca-473f-bf4f-f85a16b39661
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 099fd1d1-4d39-46a7-916b-4d703f7c6987
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5f5efe61-f072-4b79-8fdc-42ea6d0b1123
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cc824128-c8c4-4d1b-90fe-768a6ce9f9e0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8c5ed20a-65c2-4854-b591-c1bbfc6fc14e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f5e85650-003e-4bed-acc2-499c8911671e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 78686b7c-904f-434e-b349-179a49ee27ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6a481ba9-7463-4bf2-b5e0-c6643e3c7fa6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 551e21c8-b434-4ac5-8667-8e00b8726801
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7ba4ebee-cd06-44fb-963c-07271ae8778a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ad482654-a746-4580-990a-167d1a787928
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e3aecf1f-2d81-4a5c-b88a-45f13ac51bca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 30ae8a76-e101-434f-afd4-3de5c21619eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8b6301eb-06b1-4465-9751-06b15e27853d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message faf02b47-3a5f-4e8a-acae-56f98786b216
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b9121ed6-45ce-4dd2-a658-c99f50b96be5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 00621173-e973-4ec3-b475-646142e5ec24
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 40b500ac-0172-45dd-91c1-145725a4e2c4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9a95a851-02f0-4a44-a18b-90b9567568d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4f266661-591a-4e7a-b522-3d3dd1e5c295
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d4d5e338-db9a-4c88-ad93-c9c673823805
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message db7f81bb-5b64-43b6-a57f-9b796f6a77aa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e721ed50-c5e5-48fa-ab59-e55d0ef8bfc7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5a75377a-c279-4568-bbf1-6c46eddac1e0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d01a5956-7f9b-4aaf-9b66-6898a2d43825
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b64298e2-b900-43c3-852e-e427fffdced8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b2acffad-ab51-4fbe-b4fa-7514bb39ed5c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 18997193-28e7-4fbf-a083-5247af8b4e9f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9c417138-d02c-4e25-a3f4-7fb9aa10918e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e90ccb27-1737-414d-9a0b-e4e27b0ade84
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8148a257-f0ee-44fb-a72d-b5059326b927
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2b560e96-f821-45c4-91d5-1900af9014a9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8dab3c68-f3b1-4517-884d-9e2bfa5ca0aa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 01894b5e-e049-49d1-b19b-f1fba9f4225c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7f4f49cc-c7a0-4ec2-b82c-0a960f2beb36
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8ca13cd0-7d7a-4934-a249-897316a75d6e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6b843142-69dc-4b42-9acf-50532ac671ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9dd9d1ec-2660-4cd1-bdac-2b2d03a05ab2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ca24b611-6417-494f-b0d4-b269fcae57e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8d7af254-8b63-4839-95fa-399a23a91daa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 62acb641-0ff7-439e-bab8-0c1b32b961d5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 362cf0f7-ebf6-48cb-87ba-fa93101cf6d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 98627aa4-bf39-4caf-adad-afbc4ab41b7e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 45b5436c-5656-4f91-a31f-2287032fb296
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e88c141e-b973-49d5-842b-1052b167c1be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c78caf9d-ca3c-4909-9511-ea3a6f21b33b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message abaed1c0-4820-464e-96fe-740951e7a61a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 376eb63b-8cfd-4d6b-a8cc-3f9e5498f997
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 065e3b0c-e622-4594-bc68-639b09706e8b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 486b2ae3-714f-4814-85cc-bc0701cf2fa9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7a5ef7f0-2986-4f35-9c7f-6614bbb3f2ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 371b791a-2244-4ae4-844b-62f6f271e7c9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1e35cafb-fcf4-4c16-947c-af531b704471
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c23ed35c-d4ba-4442-86bd-c99af478f80b
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8687 {grpc_message:"Socket closed", grpc_status:14}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_31
Server: localhost:8687
Algorithm: FEDAVG
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_31
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_31/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_31/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_31/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_31/test_labels.txt

📊 Raw data loaded:
   Train: X=(1351, 24), y=(1351,)
   Test:  X=(338, 24), y=(338,)

⚠️  Limiting training data: 1351 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  329 samples, 5 features
✅ Client client_31 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

============================================================
🔄 Round 3 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0889, val=0.0704 (↓), lr=0.001000
   • Epoch   2/100: train=0.0874, val=0.0720, patience=1/15, lr=0.001000
   • Epoch   3/100: train=0.0869, val=0.0721, patience=2/15, lr=0.001000
   • Epoch   4/100: train=0.0864, val=0.0717, patience=3/15, lr=0.001000
   • Epoch   5/100: train=0.0859, val=0.0715, patience=4/15, lr=0.001000
   📉 Epoch 7: LR reduced 0.001000 → 0.000500
   ✓ Epoch  11/100: train=0.0824, val=0.0698 (↓), lr=0.000500
   • Epoch  21/100: train=0.0774, val=0.0701, patience=10/15, lr=0.000500
   📉 Epoch 22: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0698)

============================================================
📊 Round 3 Summary - Client client_31
   Epochs: 26/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0815, RMSE=0.2854, R²=0.0664
   Val:   Loss=0.0698, RMSE=0.2642, R²=-0.0121
============================================================


📊 Round 3 Test Metrics:
   Loss: 0.0833, RMSE: 0.2886, MAE: 0.2481, R²: 0.0063

============================================================
🔄 Round 4 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0929 (↓), lr=0.000250
   • Epoch   2/100: train=0.0800, val=0.0929, patience=1/15, lr=0.000250
   • Epoch   3/100: train=0.0799, val=0.0928, patience=2/15, lr=0.000250
   📉 Epoch 4: LR reduced 0.000250 → 0.000125
   • Epoch   4/100: train=0.0797, val=0.0929, patience=3/15, lr=0.000125
   • Epoch   5/100: train=0.0795, val=0.0926, patience=4/15, lr=0.000125
   • Epoch  11/100: train=0.0790, val=0.0926, patience=10/15, lr=0.000125
   📉 Epoch 12: LR reduced 0.000125 → 0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0929)

============================================================
📊 Round 4 Summary - Client client_31
   Epochs: 16/100 (early stopped)
   LR: 0.000250 → 0.000063 (2 reductions)
   Train: Loss=0.0800, RMSE=0.2829, R²=0.0140
   Val:   Loss=0.0929, RMSE=0.3047, R²=0.0115
============================================================


============================================================
🔄 Round 5 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0794 (↓), lr=0.000063
   • Epoch   2/100: train=0.0825, val=0.0793, patience=1/15, lr=0.000063
   • Epoch   3/100: train=0.0824, val=0.0793, patience=2/15, lr=0.000063
   📉 Epoch 4: LR reduced 0.000063 → 0.000031
   • Epoch   4/100: train=0.0824, val=0.0792, patience=3/15, lr=0.000031
   • Epoch   5/100: train=0.0823, val=0.0792, patience=4/15, lr=0.000031
   • Epoch  11/100: train=0.0821, val=0.0791, patience=10/15, lr=0.000031
   📉 Epoch 12: LR reduced 0.000031 → 0.000016

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 5 Summary - Client client_31
   Epochs: 16/100 (early stopped)
   LR: 0.000063 → 0.000016 (2 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=0.0252
   Val:   Loss=0.0794, RMSE=0.2818, R²=0.0119
============================================================


============================================================
🔄 Round 6 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.000016
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0822 (↓), lr=0.000016
   • Epoch   2/100: train=0.0805, val=0.0822, patience=1/15, lr=0.000016
   • Epoch   3/100: train=0.0804, val=0.0822, patience=2/15, lr=0.000016
   📉 Epoch 4: LR reduced 0.000016 → 0.000008
   • Epoch   4/100: train=0.0804, val=0.0823, patience=3/15, lr=0.000008
   • Epoch   5/100: train=0.0803, val=0.0823, patience=4/15, lr=0.000008
   • Epoch  11/100: train=0.0802, val=0.0823, patience=10/15, lr=0.000008
   📉 Epoch 12: LR reduced 0.000008 → 0.000004

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 6 Summary - Client client_31
   Epochs: 16/100 (early stopped)
   LR: 0.000016 → 0.000004 (2 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=0.0318
   Val:   Loss=0.0822, RMSE=0.2868, R²=0.0432
============================================================


📊 Round 6 Test Metrics:
   Loss: 0.0816, RMSE: 0.2856, MAE: 0.2457, R²: 0.0263

📊 Round 6 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2462, R²: 0.0218

============================================================
🔄 Round 11 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.000004
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0791 (↓), lr=0.000004
   • Epoch   2/100: train=0.0797, val=0.0791, patience=1/15, lr=0.000004
   • Epoch   3/100: train=0.0797, val=0.0791, patience=2/15, lr=0.000004
   📉 Epoch 4: LR reduced 0.000004 → 0.000002
   • Epoch   4/100: train=0.0796, val=0.0792, patience=3/15, lr=0.000002
   • Epoch   5/100: train=0.0796, val=0.0792, patience=4/15, lr=0.000002
   • Epoch  11/100: train=0.0795, val=0.0792, patience=10/15, lr=0.000002
   📉 Epoch 12: LR reduced 0.000002 → 0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 11 Summary - Client client_31
   Epochs: 16/100 (early stopped)
   LR: 0.000004 → 0.000001 (2 reductions)
   Train: Loss=0.0795, RMSE=0.2820, R²=0.0497
   Val:   Loss=0.0791, RMSE=0.2813, R²=0.0578
============================================================


📊 Round 11 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2467, R²: 0.0191

📊 Round 11 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2467, R²: 0.0191

📊 Round 11 Test Metrics:
   Loss: 0.0821, RMSE: 0.2865, MAE: 0.2465, R²: 0.0205

============================================================
🔄 Round 14 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0787, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 14 Summary - Client client_31
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2813, R²=0.0499
   Val:   Loss=0.0809, RMSE=0.2844, R²=0.0431
============================================================


📊 Round 14 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2463, R²: 0.0211

============================================================
🔄 Round 16 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0779, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0779, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0778, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0778, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0778, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0778, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 16 Summary - Client client_31
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0777, RMSE=0.2788, R²=0.0529
   Val:   Loss=0.0856, RMSE=0.2925, R²=0.0520
============================================================


📊 Round 16 Test Metrics:
   Loss: 0.0819, RMSE: 0.2863, MAE: 0.2461, R²: 0.0220

📊 Round 16 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2462, R²: 0.0216

============================================================
🔄 Round 22 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0763, val=0.0915 (↓), lr=0.000001
   • Epoch   2/100: train=0.0763, val=0.0915, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0763, val=0.0915, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0763, val=0.0915, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0763, val=0.0915, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0763, val=0.0915, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0915)

============================================================
📊 Round 22 Summary - Client client_31
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0761, RMSE=0.2759, R²=0.0617
   Val:   Loss=0.0915, RMSE=0.3026, R²=0.0322
============================================================


============================================================
🔄 Round 24 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 24 Summary - Client client_31
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2811, R²=0.0490
   Val:   Loss=0.0797, RMSE=0.2824, R²=0.0692
============================================================


============================================================
🔄 Round 26 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0776, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0776, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0776, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0776, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0776, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0776, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 26 Summary - Client client_31
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0777, RMSE=0.2788, R²=0.0529
   Val:   Loss=0.0850, RMSE=0.2915, R²=0.0619
============================================================


============================================================
🔄 Round 27 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 27 Summary - Client client_31
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2817, R²=0.0608
   Val:   Loss=0.0784, RMSE=0.2799, R²=0.0302
============================================================


📊 Round 27 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2456, R²: 0.0246

📊 Round 27 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2456, R²: 0.0247

============================================================
🔄 Round 35 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0782, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0782, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0782, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0782, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0782, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0782, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 35 Summary - Client client_31
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0782, RMSE=0.2796, R²=0.0590
   Val:   Loss=0.0831, RMSE=0.2883, R²=0.0397
============================================================


============================================================
🔄 Round 36 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0765 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0765, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0765, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0765, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0765, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0764, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0765)

============================================================
📊 Round 36 Summary - Client client_31
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2826, R²=0.0503
   Val:   Loss=0.0765, RMSE=0.2765, R²=0.0757
============================================================


============================================================
🔄 Round 38 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0776, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0776, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 38 Summary - Client client_31
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2821, R²=0.0589
   Val:   Loss=0.0775, RMSE=0.2784, R²=0.0306
============================================================


============================================================
🔄 Round 39 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0772, val=0.0874 (↓), lr=0.000001
   • Epoch   2/100: train=0.0772, val=0.0874, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0772, val=0.0874, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0772, val=0.0875, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0772, val=0.0875, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0771, val=0.0875, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0874)

============================================================
📊 Round 39 Summary - Client client_31
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0771, RMSE=0.2777, R²=0.0627
   Val:   Loss=0.0874, RMSE=0.2957, R²=0.0205
============================================================


============================================================
🔄 Round 40 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 40 Summary - Client client_31
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2821, R²=0.0488
   Val:   Loss=0.0775, RMSE=0.2785, R²=0.0810
============================================================


📊 Round 40 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2456, R²: 0.0248

📊 Round 40 Test Metrics:
   Loss: 0.0817, RMSE: 0.2858, MAE: 0.2456, R²: 0.0248

============================================================
🔄 Round 46 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0773, val=0.0869 (↓), lr=0.000001
   • Epoch   2/100: train=0.0773, val=0.0869, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0773, val=0.0869, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0773, val=0.0869, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0773, val=0.0869, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0773, val=0.0870, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 46 Summary - Client client_31
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0772, RMSE=0.2779, R²=0.0622
   Val:   Loss=0.0869, RMSE=0.2948, R²=0.0299
============================================================


============================================================
🔄 Round 48 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0728 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0728, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0728, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0728, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0728, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0728, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0728)

============================================================
📊 Round 48 Summary - Client client_31
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=0.0511
   Val:   Loss=0.0728, RMSE=0.2698, R²=0.0656
============================================================


📊 Round 48 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2456, R²: 0.0248

============================================================
🔄 Round 50 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0754 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0754, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0754, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0754, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0754, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0754, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0754)

============================================================
📊 Round 50 Summary - Client client_31
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=0.0616
   Val:   Loss=0.0754, RMSE=0.2745, R²=0.0275
============================================================


📊 Round 50 Test Metrics:
   Loss: 0.0817, RMSE: 0.2858, MAE: 0.2456, R²: 0.0248

📊 Round 50 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2456, R²: 0.0247

📊 Round 50 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2456, R²: 0.0247

📊 Round 50 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2456, R²: 0.0247

📊 Round 50 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2456, R²: 0.0246

============================================================
🔄 Round 58 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0724 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0724, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0724, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0724, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0724, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0724, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0724)

============================================================
📊 Round 58 Summary - Client client_31
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=0.0492
   Val:   Loss=0.0724, RMSE=0.2691, R²=0.0777
============================================================


📊 Round 58 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2456, R²: 0.0246

📊 Round 58 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2456, R²: 0.0247

============================================================
🔄 Round 64 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 64 Summary - Client client_31
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2807, R²=0.0602
   Val:   Loss=0.0808, RMSE=0.2842, R²=0.0352
============================================================


📊 Round 64 Test Metrics:
   Loss: 0.0817, RMSE: 0.2858, MAE: 0.2456, R²: 0.0248

============================================================
🔄 Round 66 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0750 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0750, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0750, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0750, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0750, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0751, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0750)

============================================================
📊 Round 66 Summary - Client client_31
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=0.0571
   Val:   Loss=0.0750, RMSE=0.2738, R²=0.0311
============================================================


📊 Round 66 Test Metrics:
   Loss: 0.0817, RMSE: 0.2858, MAE: 0.2456, R²: 0.0249

============================================================
🔄 Round 67 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0778, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0778, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0778, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0778, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0779, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 67 Summary - Client client_31
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2820, R²=0.0578
   Val:   Loss=0.0778, RMSE=0.2789, R²=0.0248
============================================================


📊 Round 67 Test Metrics:
   Loss: 0.0817, RMSE: 0.2858, MAE: 0.2456, R²: 0.0249

📊 Round 67 Test Metrics:
   Loss: 0.0817, RMSE: 0.2858, MAE: 0.2455, R²: 0.0250

============================================================
🔄 Round 70 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0711 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0711, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0711, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0711, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0711, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0711, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0711)

============================================================
📊 Round 70 Summary - Client client_31
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=0.0472
   Val:   Loss=0.0711, RMSE=0.2666, R²=0.0904
============================================================


============================================================
🔄 Round 71 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0764 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0764, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0764, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0764, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0764, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0764, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0764)

============================================================
📊 Round 71 Summary - Client client_31
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2826, R²=0.0571
   Val:   Loss=0.0764, RMSE=0.2764, R²=0.0480
============================================================


📊 Round 71 Test Metrics:
   Loss: 0.0817, RMSE: 0.2858, MAE: 0.2455, R²: 0.0251

📊 Round 71 Test Metrics:
   Loss: 0.0817, RMSE: 0.2858, MAE: 0.2455, R²: 0.0252

============================================================
🔄 Round 81 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0773, val=0.0869 (↓), lr=0.000001
   • Epoch   2/100: train=0.0773, val=0.0869, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0773, val=0.0869, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0773, val=0.0869, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0773, val=0.0869, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0773, val=0.0870, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 81 Summary - Client client_31
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0772, RMSE=0.2779, R²=0.0516
   Val:   Loss=0.0869, RMSE=0.2948, R²=0.0677
============================================================


============================================================
🔄 Round 82 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0670 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0670, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0670, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0670, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0670, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0670, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0670)

============================================================
📊 Round 82 Summary - Client client_31
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=0.0574
   Val:   Loss=0.0670, RMSE=0.2589, R²=0.0416
============================================================


📊 Round 82 Test Metrics:
   Loss: 0.0817, RMSE: 0.2858, MAE: 0.2455, R²: 0.0251

📊 Round 82 Test Metrics:
   Loss: 0.0817, RMSE: 0.2858, MAE: 0.2455, R²: 0.0251

📊 Round 82 Test Metrics:
   Loss: 0.0817, RMSE: 0.2858, MAE: 0.2455, R²: 0.0251

============================================================
🔄 Round 87 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0735 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0735, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0735, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0735, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0735, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0735, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0735)

============================================================
📊 Round 87 Summary - Client client_31
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=0.0525
   Val:   Loss=0.0735, RMSE=0.2710, R²=0.0676
============================================================


============================================================
🔄 Round 88 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0655 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0655, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0655, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0655, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0655, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0655, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0655)

============================================================
📊 Round 88 Summary - Client client_31
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=0.0541
   Val:   Loss=0.0655, RMSE=0.2559, R²=0.0569
============================================================


============================================================
🔄 Round 89 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0769 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0769, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0770, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0770, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0770, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0770, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0769)

============================================================
📊 Round 89 Summary - Client client_31
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=0.0604
   Val:   Loss=0.0769, RMSE=0.2774, R²=0.0266
============================================================


============================================================
🔄 Round 92 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0773, val=0.0877 (↓), lr=0.000001
   • Epoch   2/100: train=0.0773, val=0.0877, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0773, val=0.0877, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0773, val=0.0877, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0773, val=0.0877, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0773, val=0.0878, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0877)

============================================================
📊 Round 92 Summary - Client client_31
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0770, RMSE=0.2775, R²=0.0607
   Val:   Loss=0.0877, RMSE=0.2962, R²=0.0221
============================================================


📊 Round 92 Test Metrics:
   Loss: 0.0817, RMSE: 0.2858, MAE: 0.2455, R²: 0.0253

📊 Round 92 Test Metrics:
   Loss: 0.0817, RMSE: 0.2858, MAE: 0.2455, R²: 0.0252

============================================================
🔄 Round 94 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0772, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0772, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0771, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0771, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0771, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0771, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 94 Summary - Client client_31
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0774, RMSE=0.2782, R²=0.0553
   Val:   Loss=0.0862, RMSE=0.2937, R²=0.0555
============================================================


📊 Round 94 Test Metrics:
   Loss: 0.0817, RMSE: 0.2858, MAE: 0.2455, R²: 0.0252

============================================================
🔄 Round 95 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 95 Summary - Client client_31
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2821, R²=0.0552
   Val:   Loss=0.0775, RMSE=0.2783, R²=0.0563
============================================================


📊 Round 95 Test Metrics:
   Loss: 0.0817, RMSE: 0.2858, MAE: 0.2455, R²: 0.0252

📊 Round 95 Test Metrics:
   Loss: 0.0817, RMSE: 0.2858, MAE: 0.2455, R²: 0.0252

📊 Round 95 Test Metrics:
   Loss: 0.0817, RMSE: 0.2858, MAE: 0.2455, R²: 0.0253

============================================================
🔄 Round 99 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0738 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0738, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0738, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0738, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0738, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0738, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0738)

============================================================
📊 Round 99 Summary - Client client_31
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=0.0489
   Val:   Loss=0.0738, RMSE=0.2716, R²=0.0827
============================================================


📊 Round 99 Test Metrics:
   Loss: 0.0817, RMSE: 0.2858, MAE: 0.2455, R²: 0.0253

============================================================
🔄 Round 100 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0783, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0783, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0783, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0783, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0783, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0782, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 100 Summary - Client client_31
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0782, RMSE=0.2797, R²=0.0678
   Val:   Loss=0.0828, RMSE=0.2878, R²=0.0053
============================================================


📊 Round 100 Test Metrics:
   Loss: 0.0817, RMSE: 0.2858, MAE: 0.2455, R²: 0.0253

============================================================
🔄 Round 104 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0742 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0742, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0742, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0742, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0742, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0742, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0742)

============================================================
📊 Round 104 Summary - Client client_31
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=0.0524
   Val:   Loss=0.0742, RMSE=0.2724, R²=0.0658
============================================================


============================================================
🔄 Round 105 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 105 Summary - Client client_31
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2806, R²=0.0582
   Val:   Loss=0.0809, RMSE=0.2844, R²=0.0428
============================================================


📊 Round 105 Test Metrics:
   Loss: 0.0817, RMSE: 0.2858, MAE: 0.2455, R²: 0.0255

============================================================
🔄 Round 107 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0772 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0772, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0772, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0772, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0772, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0773, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 107 Summary - Client client_31
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2822, R²=0.0478
   Val:   Loss=0.0772, RMSE=0.2778, R²=0.0639
============================================================


============================================================
🔄 Round 108 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0717 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0717, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0717, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0717, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0717, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0717, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0717)

============================================================
📊 Round 108 Summary - Client client_31
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=0.0514
   Val:   Loss=0.0717, RMSE=0.2678, R²=0.0724
============================================================


📊 Round 108 Test Metrics:
   Loss: 0.0817, RMSE: 0.2858, MAE: 0.2455, R²: 0.0255

============================================================
🔄 Round 109 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 109 Summary - Client client_31
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2818, R²=0.0532
   Val:   Loss=0.0781, RMSE=0.2795, R²=0.0561
============================================================


📊 Round 109 Test Metrics:
   Loss: 0.0817, RMSE: 0.2858, MAE: 0.2455, R²: 0.0255

============================================================
🔄 Round 113 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0782, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0782, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0782, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0782, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0782, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0782, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 113 Summary - Client client_31
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0783, RMSE=0.2799, R²=0.0558
   Val:   Loss=0.0824, RMSE=0.2871, R²=0.0539
============================================================


============================================================
🔄 Round 117 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0773, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0773, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0773, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0773, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0773, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0773, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 117 Summary - Client client_31
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0774, RMSE=0.2782, R²=0.0654
   Val:   Loss=0.0862, RMSE=0.2936, R²=0.0181
============================================================


📊 Round 117 Test Metrics:
   Loss: 0.0816, RMSE: 0.2857, MAE: 0.2455, R²: 0.0256

📊 Round 117 Test Metrics:
   Loss: 0.0816, RMSE: 0.2857, MAE: 0.2455, R²: 0.0256

============================================================
🔄 Round 119 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 119 Summary - Client client_31
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2802, R²=0.0607
   Val:   Loss=0.0817, RMSE=0.2859, R²=0.0349
============================================================


📊 Round 119 Test Metrics:
   Loss: 0.0816, RMSE: 0.2857, MAE: 0.2455, R²: 0.0257

============================================================
🔄 Round 128 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 128 Summary - Client client_31
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2805, R²=0.0557
   Val:   Loss=0.0811, RMSE=0.2847, R²=0.0434
============================================================


📊 Round 128 Test Metrics:
   Loss: 0.0816, RMSE: 0.2857, MAE: 0.2455, R²: 0.0256

📊 Round 128 Test Metrics:
   Loss: 0.0817, RMSE: 0.2858, MAE: 0.2455, R²: 0.0254

============================================================
🔄 Round 132 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0787, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 132 Summary - Client client_31
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2802, R²=0.0488
   Val:   Loss=0.0818, RMSE=0.2860, R²=0.0768
============================================================


============================================================
🔄 Round 133 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 133 Summary - Client client_31
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2806, R²=0.0610
   Val:   Loss=0.0808, RMSE=0.2843, R²=0.0332
============================================================


============================================================
🔄 Round 135 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0759 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0759, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0759, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0759, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0759, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0759, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0759)

============================================================
📊 Round 135 Summary - Client client_31
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=0.0587
   Val:   Loss=0.0759, RMSE=0.2755, R²=0.0394
============================================================


📊 Round 135 Test Metrics:
   Loss: 0.0817, RMSE: 0.2858, MAE: 0.2455, R²: 0.0253

📊 Round 135 Test Metrics:
   Loss: 0.0817, RMSE: 0.2858, MAE: 0.2455, R²: 0.0254

📊 Round 135 Test Metrics:
   Loss: 0.0817, RMSE: 0.2858, MAE: 0.2455, R²: 0.0254

📊 Round 135 Test Metrics:
   Loss: 0.0817, RMSE: 0.2858, MAE: 0.2455, R²: 0.0254

📊 Round 135 Test Metrics:
   Loss: 0.0817, RMSE: 0.2858, MAE: 0.2455, R²: 0.0255

============================================================
🔄 Round 143 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0771 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0771, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0771, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0771, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0771, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0771, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0771)

============================================================
📊 Round 143 Summary - Client client_31
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2822, R²=0.0521
   Val:   Loss=0.0771, RMSE=0.2777, R²=0.0699
============================================================


============================================================
🔄 Round 144 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0746 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0746, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0746, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0746, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0746, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0746, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0746)

============================================================
📊 Round 144 Summary - Client client_31
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2833, R²=0.0593
   Val:   Loss=0.0746, RMSE=0.2732, R²=0.0389
============================================================


📊 Round 144 Test Metrics:
   Loss: 0.0817, RMSE: 0.2857, MAE: 0.2455, R²: 0.0255

============================================================
🔄 Round 149 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0787, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 149 Summary - Client client_31
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2803, R²=0.0556
   Val:   Loss=0.0814, RMSE=0.2852, R²=0.0548
============================================================


📊 Round 149 Test Metrics:
   Loss: 0.0817, RMSE: 0.2858, MAE: 0.2455, R²: 0.0255

📊 Round 149 Test Metrics:
   Loss: 0.0817, RMSE: 0.2857, MAE: 0.2455, R²: 0.0255

============================================================
🔄 Round 151 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0738 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0739, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0739, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0739, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0739, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0739, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0738)

============================================================
📊 Round 151 Summary - Client client_31
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=0.0465
   Val:   Loss=0.0738, RMSE=0.2717, R²=0.0787
============================================================


============================================================
🔄 Round 152 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0735 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0735, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0735, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0735, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0735, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0735, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0735)

============================================================
📊 Round 152 Summary - Client client_31
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2838, R²=0.0527
   Val:   Loss=0.0735, RMSE=0.2711, R²=0.0657
============================================================


📊 Round 152 Test Metrics:
   Loss: 0.0816, RMSE: 0.2857, MAE: 0.2455, R²: 0.0255

📊 Round 152 Test Metrics:
   Loss: 0.0816, RMSE: 0.2857, MAE: 0.2455, R²: 0.0256

============================================================
🔄 Round 155 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0770 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0770, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0770, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0770, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0770, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0770, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0770)

============================================================
📊 Round 155 Summary - Client client_31
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=0.0570
   Val:   Loss=0.0770, RMSE=0.2774, R²=0.0452
============================================================


============================================================
🔄 Round 156 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 156 Summary - Client client_31
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2810, R²=0.0503
   Val:   Loss=0.0798, RMSE=0.2824, R²=0.0712
============================================================


📊 Round 156 Test Metrics:
   Loss: 0.0816, RMSE: 0.2857, MAE: 0.2455, R²: 0.0256

============================================================
🔄 Round 160 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0768 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0769, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0769, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0769, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0769, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0769, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0768)

============================================================
📊 Round 160 Summary - Client client_31
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=0.0545
   Val:   Loss=0.0768, RMSE=0.2772, R²=0.0552
============================================================


📊 Round 160 Test Metrics:
   Loss: 0.0816, RMSE: 0.2857, MAE: 0.2455, R²: 0.0255

📊 Round 160 Test Metrics:
   Loss: 0.0816, RMSE: 0.2857, MAE: 0.2455, R²: 0.0255

📊 Round 160 Test Metrics:
   Loss: 0.0817, RMSE: 0.2858, MAE: 0.2455, R²: 0.0255

📊 Round 160 Test Metrics:
   Loss: 0.0817, RMSE: 0.2857, MAE: 0.2455, R²: 0.0255

📊 Round 160 Test Metrics:
   Loss: 0.0817, RMSE: 0.2858, MAE: 0.2455, R²: 0.0255

============================================================
🔄 Round 168 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 168 Summary - Client client_31
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2810, R²=0.0514
   Val:   Loss=0.0798, RMSE=0.2824, R²=0.0608
============================================================


📊 Round 168 Test Metrics:
   Loss: 0.0817, RMSE: 0.2857, MAE: 0.2455, R²: 0.0255

============================================================
🔄 Round 174 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0778, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0778, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0778, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0777, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0777, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0777, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 174 Summary - Client client_31
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0778, RMSE=0.2789, R²=0.0614
   Val:   Loss=0.0844, RMSE=0.2906, R²=0.0327
============================================================


📊 Round 174 Test Metrics:
   Loss: 0.0816, RMSE: 0.2857, MAE: 0.2455, R²: 0.0257

============================================================
🔄 Round 177 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0724 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0724, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0724, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0724, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0724, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0724, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0724)

============================================================
📊 Round 177 Summary - Client client_31
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=0.0564
   Val:   Loss=0.0724, RMSE=0.2690, R²=0.0419
============================================================


📊 Round 177 Test Metrics:
   Loss: 0.0816, RMSE: 0.2857, MAE: 0.2455, R²: 0.0256

📊 Round 177 Test Metrics:
   Loss: 0.0816, RMSE: 0.2857, MAE: 0.2455, R²: 0.0257

============================================================
🔄 Round 183 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0734 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0734, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0734, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0734, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0734, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0735, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0734)

============================================================
📊 Round 183 Summary - Client client_31
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2838, R²=0.0516
   Val:   Loss=0.0734, RMSE=0.2710, R²=0.0633
============================================================


📊 Round 183 Test Metrics:
   Loss: 0.0816, RMSE: 0.2857, MAE: 0.2455, R²: 0.0255

📊 Round 183 Test Metrics:
   Loss: 0.0817, RMSE: 0.2858, MAE: 0.2455, R²: 0.0254

============================================================
🔄 Round 187 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0782, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 187 Summary - Client client_31
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2817, R²=0.0573
   Val:   Loss=0.0782, RMSE=0.2796, R²=0.0447
============================================================


📊 Round 187 Test Metrics:
   Loss: 0.0817, RMSE: 0.2858, MAE: 0.2455, R²: 0.0254

============================================================
🔄 Round 190 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0769, val=0.0889 (↓), lr=0.000001
   • Epoch   2/100: train=0.0769, val=0.0889, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0769, val=0.0889, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0768, val=0.0889, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0768, val=0.0889, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0768, val=0.0889, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0889)

============================================================
📊 Round 190 Summary - Client client_31
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0767, RMSE=0.2770, R²=0.0613
   Val:   Loss=0.0889, RMSE=0.2981, R²=0.0340
============================================================


============================================================
🔄 Round 191 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0783, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0783, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0783, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0783, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0783, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 191 Summary - Client client_31
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2802, R²=0.0564
   Val:   Loss=0.0816, RMSE=0.2857, R²=0.0354
============================================================


📊 Round 191 Test Metrics:
   Loss: 0.0817, RMSE: 0.2858, MAE: 0.2455, R²: 0.0254

============================================================
🔄 Round 192 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0780, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0780, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0780, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0780, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0780, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0780, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 192 Summary - Client client_31
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0781, RMSE=0.2794, R²=0.0566
   Val:   Loss=0.0834, RMSE=0.2887, R²=0.0513
============================================================


============================================================
🔄 Round 196 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0785, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0785, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0785, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0785, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 196 Summary - Client client_31
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0783, RMSE=0.2798, R²=0.0529
   Val:   Loss=0.0825, RMSE=0.2872, R²=0.0567
============================================================


📊 Round 196 Test Metrics:
   Loss: 0.0817, RMSE: 0.2858, MAE: 0.2455, R²: 0.0254

============================================================
🔄 Round 200 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 200 Summary - Client client_31
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2809, R²=0.0586
   Val:   Loss=0.0800, RMSE=0.2828, R²=0.0444
============================================================


📊 Round 200 Test Metrics:
   Loss: 0.0817, RMSE: 0.2858, MAE: 0.2455, R²: 0.0254

============================================================
🔄 Round 202 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 202 Summary - Client client_31
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2809, R²=0.0580
   Val:   Loss=0.0801, RMSE=0.2830, R²=0.0466
============================================================


📊 Round 202 Test Metrics:
   Loss: 0.0817, RMSE: 0.2858, MAE: 0.2455, R²: 0.0255

============================================================
🔄 Round 203 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0771 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0771, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0771, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0771, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0771, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0771)

============================================================
📊 Round 203 Summary - Client client_31
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2822, R²=0.0576
   Val:   Loss=0.0771, RMSE=0.2776, R²=0.0312
============================================================


📊 Round 203 Test Metrics:
   Loss: 0.0817, RMSE: 0.2858, MAE: 0.2455, R²: 0.0254

📊 Round 203 Test Metrics:
   Loss: 0.0817, RMSE: 0.2858, MAE: 0.2455, R²: 0.0254

============================================================
🔄 Round 207 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0766 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0766, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0766, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0766, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0766, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0766, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0766)

============================================================
📊 Round 207 Summary - Client client_31
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2824, R²=0.0594
   Val:   Loss=0.0766, RMSE=0.2769, R²=0.0408
============================================================


📊 Round 207 Test Metrics:
   Loss: 0.0817, RMSE: 0.2858, MAE: 0.2455, R²: 0.0254

📊 Round 207 Test Metrics:
   Loss: 0.0817, RMSE: 0.2858, MAE: 0.2455, R²: 0.0255

============================================================
🔄 Round 211 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0783, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 211 Summary - Client client_31
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0783, RMSE=0.2799, R²=0.0570
   Val:   Loss=0.0822, RMSE=0.2867, R²=0.0494
============================================================


============================================================
🔄 Round 212 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0759 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0759, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0760, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0760, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0760, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0762, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0759)

============================================================
📊 Round 212 Summary - Client client_31
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=0.0634
   Val:   Loss=0.0759, RMSE=0.2755, R²=-0.0348
============================================================


============================================================
🔄 Round 214 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0781, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0781, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0781, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0781, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0781, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0780, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 214 Summary - Client client_31
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0779, RMSE=0.2791, R²=0.0617
   Val:   Loss=0.0841, RMSE=0.2900, R²=0.0270
============================================================


📊 Round 214 Test Metrics:
   Loss: 0.0817, RMSE: 0.2857, MAE: 0.2455, R²: 0.0255

============================================================
🔄 Round 216 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0702 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0702, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0702, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0702, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0702, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0702, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0702)

============================================================
📊 Round 216 Summary - Client client_31
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2852, R²=0.0546
   Val:   Loss=0.0702, RMSE=0.2649, R²=0.0610
============================================================


📊 Round 216 Test Metrics:
   Loss: 0.0817, RMSE: 0.2858, MAE: 0.2455, R²: 0.0254

📊 Round 216 Test Metrics:
   Loss: 0.0817, RMSE: 0.2858, MAE: 0.2455, R²: 0.0255

============================================================
🔄 Round 218 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0776 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0776, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0776, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0776, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0776, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 218 Summary - Client client_31
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2820, R²=0.0622
   Val:   Loss=0.0776, RMSE=0.2786, R²=0.0288
============================================================


============================================================
🔄 Round 219 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0765, val=0.0898 (↓), lr=0.000001
   • Epoch   2/100: train=0.0764, val=0.0898, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0764, val=0.0898, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0764, val=0.0898, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0764, val=0.0898, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0764, val=0.0899, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0898)

============================================================
📊 Round 219 Summary - Client client_31
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0764, RMSE=0.2765, R²=0.0591
   Val:   Loss=0.0898, RMSE=0.2997, R²=0.0363
============================================================


📊 Round 219 Test Metrics:
   Loss: 0.0816, RMSE: 0.2857, MAE: 0.2455, R²: 0.0256

============================================================
🔄 Round 221 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 221 Summary - Client client_31
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2808, R²=0.0497
   Val:   Loss=0.0802, RMSE=0.2831, R²=0.0731
============================================================


📊 Round 221 Test Metrics:
   Loss: 0.0816, RMSE: 0.2857, MAE: 0.2455, R²: 0.0256

============================================================
🔄 Round 223 - Client client_31
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0787, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 223 Summary - Client client_31
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2808, R²=0.0594
   Val:   Loss=0.0802, RMSE=0.2832, R²=0.0381
============================================================


❌ Client client_31 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8687 {grpc_message:"Socket closed", grpc_status:14}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8687 {grpc_message:"Socket closed", grpc_status:14}"
>
