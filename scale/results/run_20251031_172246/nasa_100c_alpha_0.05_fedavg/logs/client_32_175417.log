[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d2f2ed99-194e-4855-9f94-56b06dd43935
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e85b2d54-ed40-401c-98ec-762216ac0e4e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f3235c25-ce44-4a75-847f-9a5cf90829cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d9a42f70-1a90-497e-942b-b347eff11c15
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8059a38c-a879-494d-8fed-4a81baf63d38
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 977013e8-3429-41a0-8653-cd24d3544f47
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f0c15663-7371-4c77-8f71-08672a7104e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 412f9aa3-c221-4a86-8343-99509d02b29b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3edca63a-0a53-41dc-94dc-1a938f24b3f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2b5fcef6-d5ab-4c0e-a0bd-3614a74961ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 84009a69-6a29-4ac2-9781-b03b99799b0b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2776c55e-dc1e-4cb4-bca3-814896e42319
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3ecf026e-01ae-4dd0-b8ca-3eec55577909
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9ce104b3-e30f-4e93-af3c-a8036de5e120
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5df93be1-a5c4-4b9f-b393-b21eaa272d2f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7fe5c862-b179-43c3-9baf-f1f4891a428a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4f887761-b7fb-4d7d-b538-b565d41b41a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 544845b9-c7e5-4ad6-aa3f-ec47a2387141
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 14450985-cfd4-485b-a25d-42c3c52662f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a515aea1-597a-4683-8ef4-528bfbd679e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2c8d847d-a688-40d2-a617-4d2251a26dab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0f805ecd-96cc-4051-b6dd-a3c576c7f4e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 735b475d-6975-4927-8e45-94e1f90a5795
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d0e6bf41-6229-49a7-8463-1ebd2d286a7e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8ce92113-bfb9-4fa5-be41-dc4ce7f47817
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 45fa418e-cb5f-4313-bf77-4b84f3606523
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0d29b6ce-4d67-4326-81b8-9852303e43b1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b29f4d50-a0b6-41ec-9613-acb32f0be594
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bfd3de39-f25f-43e5-ac71-9dded683d30e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 293bd23d-856a-42b4-8e24-369d501e8c69
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 69d013c8-3ea5-4511-9a02-03dbd7450a96
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ed7196e3-2ab9-487e-9e4e-4678456af284
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eec19537-7903-4a66-8918-640925ad2cd2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 95c4c550-8dd2-4616-9422-2b9df711a11a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f613c042-cc38-494f-a7d1-d9b1c77759a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0ebf6642-416d-49f7-8da7-8bf67bfc8893
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 79e9576e-afd4-4372-8ab1-22315fe7e0dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b7fb5a31-da83-4caf-89b4-504d2c638294
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 40866cc6-0e03-41f6-aa1d-03007a4a1a43
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 93b898ad-244e-487d-9aef-70083aabfc03
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b2cdbf1f-dfee-41ac-8696-a3d7bb0d6582
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 79a092d8-40dc-4ce2-9926-c36d1a773b9f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b2214085-1701-4861-b8a0-ebc097486f05
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 221cea93-fcbb-4a0c-9f98-1c8572860dd9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f3c0243e-7417-4ef6-aab8-4c79e2d68a5d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9a0fe374-d880-434a-b92b-121027a9ebbb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f9889c61-f008-4311-bf0f-06fdd1fdccb3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e8bad100-1d0e-4a5b-b95f-99a5bb9e3b88
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e36af48b-89e9-484d-9812-b427a922a38c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0690c287-c615-4a82-b4cb-269110d6bd01
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 535458d6-0f60-4d80-bd5c-0ba0f58d1324
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 654940a3-9acf-42a3-8821-d018a13752b5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 811503ca-5b4f-4836-bd3c-868a096c14d8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 20aae7b1-09c6-4e02-8ba8-97f939bd0868
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9a517893-c853-4eb9-9f53-a2faf1ca1a41
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2c303b1c-db8b-475b-b394-707a6bd18fba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0ac3a751-e28e-4a46-a3bd-6c92d307f08a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6cc158e6-430b-470b-9e2a-78b0162e82bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 98cb3350-03f6-43ca-b1e7-93897b3bebbb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 745d523c-fd09-4776-9751-ce528cee1ee2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d70272e3-de62-45c7-a20c-a91186a1d40c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b6995ae5-8eaa-4a7c-8f9d-eb674351c137
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f23a1af0-8e0c-4e3b-b538-c5672981d9c5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 84147dd4-73ba-4d86-8b53-bf30438e7c9e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3e0e3ddd-6698-4895-9e71-b56462d1e5ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 14e63b05-90bf-4e3a-ae15-73ddebf313ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 164c7fa9-d5c6-41be-97fb-d99f874f2e80
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7314db4f-ce15-4607-8a3f-b5e43a0f1940
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ca9fd42a-7436-426c-92e4-17752fddd622
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 82040964-6112-4a44-9b29-1b3f0b5af0bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2befc607-f989-45f8-882f-059c485e22a8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 36efa897-ae6c-4e23-8ad8-9555d9cd4e0c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6fb59404-0229-4d97-a3de-af3a71f7bee4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c6ad8a14-750e-463a-93f2-47dcf5722e99
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 049a6cc6-2de8-486e-a220-94282641463f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a27bfdd8-9460-488e-846d-ec65a3ee42a8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 20f29ab4-a605-4db0-9fa2-331e4abd5fdf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ed92f24b-922d-44a1-9e46-092d38bb6ea1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f938e284-6322-433b-8585-f461d07744c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6c7f6e90-2354-428b-81fa-320392be8719
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 324435f6-c942-46fd-bba2-a3ebc172fe22
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message deb5a0f9-6710-42d5-b075-3fd8836f2914
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2ba3ec66-72ac-49f3-8c41-d340009646b0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9761a407-2435-4fb3-abea-1a46a224f475
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8dec5558-b236-4143-87dc-db51441906e9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 086e6255-43bd-49c6-9dd2-8be64d7d133a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 190ff823-b63e-46b2-99e8-d989a92e9315
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fe4cbeda-7c98-4b78-a829-dd96704fa397
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7d490a24-edd3-4302-8e67-b1dd800d16cb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1c976e8e-6b49-4c75-8d66-b2d2eb9e4952
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 08f3310c-3225-412a-8333-3e1cc243bef9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 520c666c-9a29-49b7-a331-f96a714d0fa9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b56b7762-dfdb-42dc-b587-efdc61992f47
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 130017bc-4604-4c18-8dfd-ed67e902053e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8dd2f876-5b12-40ca-862f-ff964b6ade7d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 59abec68-98b1-4035-8d8a-834ca1f91863
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9687e817-c741-4813-9ad7-acc6c631a32d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 06d12266-961c-47ac-81c6-4593f1aac4ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 665f734d-1077-476c-a48e-939bd3355931
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6aec5b99-8fe0-41e2-97e9-a727760aa666
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 26598203-544b-4f5f-b4e7-317d50e746b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b1ad5352-d546-4a0c-a718-43c855c8847f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ac9c0e17-0528-47a0-9be7-24fab20af0e1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 21cdf97c-ff14-419d-96bd-953a0e2ed0fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5556cbf8-ab47-40df-83a7-0dbbf3368e82
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1729db7e-ec29-4212-8557-166f3c712798
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fd77cc63-9b5d-458f-8016-3ef9dd2447fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e0817551-de1f-4f67-8983-b66d5cde5041
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4937cb84-d587-4e75-bdef-8a52a58d31e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a0152f00-e78b-4fc4-8519-0fc47bb35520
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c03dbbf8-1389-4820-9bc4-6d51d47d1a6c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 88ec106c-080b-48d3-85dd-1d19cdbb4ecb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 21516fef-fa56-4402-84ec-347a6c0ac806
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b88941a9-8634-4b77-a8f7-980bfaa8803a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6252a3e7-d220-413c-be9a-f4e256f9b27d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 81ab684a-876c-49a7-8d34-8bb7046e76f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 627f5f50-1734-4413-b54c-f9c5302e0614
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a3855ea6-c78a-4f5c-a227-8254f93fbd22
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f02abe34-b8c9-43d9-9a34-ef1fe7f3a752
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 47552017-85bd-4cee-9bfa-497ee29ffeb2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a9092f50-f4a4-44b3-9638-5ab84e2368bd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cdec865f-30f6-4a53-b635-39eea610903b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 42d51618-57e4-4554-9c67-0009ca4ffc60
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c274b087-3733-40ee-bc7e-dcdc15ea2214
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e954d086-80cd-4a28-8d88-dcd976aec160
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1f79fd53-7b45-4232-a9bf-7aba999aeff1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b3de8a75-9616-47e1-983d-97d7c261535d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 02ad1d1c-9c3f-47c5-a625-2a5e175e2eb8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3aac820e-081d-4abd-b06f-33f8ecac98db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2eff04e4-830c-4577-b658-528f43802eeb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d8f5ddad-e5b6-4093-9268-94abb67fe9d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4365d0b9-c567-4e83-93b3-398d9fc3fe50
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 23cc4fec-60cc-4d06-97fc-7a70be8e527a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6a498484-d1ec-423b-a964-017aa93533ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7f3f530a-38af-40d9-b17d-c1ef45f81b21
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9da76013-3487-43d0-882b-4bb2cfda63c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 865b0ead-5dcd-4b8e-a9ce-2b7947d50bbd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c9d99bde-5645-44fb-9ef5-4a63887bfabe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 56f1855b-a52a-40df-b00f-900d18725c34
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 86709867-7264-4d94-a7dc-b89d5a081328
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b0b206c9-1237-40ef-a4ee-10ac5d5b7cff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d50851e9-6564-461a-ac04-d43a6bd94564
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d5da8460-f0ec-4000-bae5-0b5b339264ce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 20f83793-451e-42eb-94de-85d4e7ee92ea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bba57dcc-47a9-4441-b21c-0dc61d577564
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 37b939f6-8f74-4089-bd5f-b3b7b136ef14
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 25651038-9398-44df-ac37-5af63961fc6d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 63f25217-e341-4e3f-ac6d-4c4e8fabad9e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b49d584b-42e3-447b-86e0-27ce37b06da3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 12765f40-4a8d-418d-bdca-036f02f3e56d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7be5acfa-a01b-4fb0-979a-48d1fd10cd82
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8e43c724-3896-407d-80e5-0a66fbfc9bd2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ce16b13f-908d-45ef-8af2-deb04e620fa8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7a671199-8b70-44a8-8a45-a54b7470d2fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d5998f01-c0a9-4df8-9356-93a3357169d1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 03e70a52-6e68-44bf-b0b3-dac37c9aa262
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d133156d-6abd-4d6e-b231-16e73e55d114
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 11a21fe3-ef34-4057-acbb-eda7e3c7f988
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6343b1c1-ac55-4206-8adb-073bc0ad3a9b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6643308c-aaa5-4393-8f64-f7de5908ad1a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7368423f-2a2e-48c9-9977-68667e8085fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 079f1fd2-1b8b-4363-8994-a0763b01d473
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message baf74db2-152d-4858-9ff1-8297842482c7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0f48b312-54dd-4bfa-83e1-34b5fdaa9cc5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cf75efd4-7f35-4454-98eb-43e0faef61cb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c1869460-680b-45bd-b500-8750640bb2fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d72242c8-1aa4-483d-9331-a15a020b7c06
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 741e8664-549b-43af-b5fd-9558a39e2ef7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a22c55d5-99ca-49a8-a441-5c4656a886aa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3d577a55-73cc-43ee-8e60-8cd33d0cc863
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 03d3ccbd-541c-4cac-bab1-baaaad63033b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 165d6fd2-5523-4bbb-b0f6-fa3f79e14bcb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c353890a-2a59-4e99-9434-5a438f27eb54
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ce19260a-e7e9-4523-abbb-261fec0a73fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e18de9b7-b6cb-401c-ba22-e6362e323f68
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4532fd1c-4af9-40cd-a0f2-8eda207ad19f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 14f57291-ca42-4145-b160-e0952372473b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c6569446-83a9-4c01-b9f2-e51c32eb86e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e2068aae-0044-4652-8df8-3925ee7d24d8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ae7b1aa4-f038-4098-9b72-94c92bb95b95
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 73e97a5f-69aa-4dfc-b089-6af184fe6086
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 444d28d8-bea5-41f4-b654-5c143a27bcfd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 39fc0ab0-a485-4cc3-aad7-d5812985d155
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c5021063-d5a5-4c64-b663-3a568f82bbe3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1695c491-9475-44e7-8e9e-4cdf80ab0c19
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9123d52d-106f-4ed6-81fc-8efd5667e3eb
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8687 {grpc_message:"Socket closed", grpc_status:14}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_32
Server: localhost:8687
Algorithm: FEDAVG
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_32
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_32/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_32/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_32/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_32/test_labels.txt

📊 Raw data loaded:
   Train: X=(620, 24), y=(620,)
   Test:  X=(155, 24), y=(155,)

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 611 samples, 5 features
   Test:  146 samples, 5 features
✅ Client client_32 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

📊 Round 0 Test Metrics:
   Loss: 0.0720, RMSE: 0.2684, MAE: 0.2297, R²: 0.0106

📊 Round 0 Test Metrics:
   Loss: 0.0719, RMSE: 0.2681, MAE: 0.2300, R²: 0.0123

============================================================
🔄 Round 5 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0935 (↓), lr=0.001000
   • Epoch   2/100: train=0.0838, val=0.0952, patience=1/15, lr=0.001000
   • Epoch   3/100: train=0.0841, val=0.0960, patience=2/15, lr=0.001000
   • Epoch   4/100: train=0.0836, val=0.0970, patience=3/15, lr=0.001000
   • Epoch   5/100: train=0.0829, val=0.0967, patience=4/15, lr=0.001000
   📉 Epoch 7: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0813, val=0.0976, patience=10/15, lr=0.000500
   📉 Epoch 15: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0935)

============================================================
📊 Round 5 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0848, RMSE=0.2913, R²=-0.0095
   Val:   Loss=0.0935, RMSE=0.3059, R²=-0.0200
============================================================


📊 Round 5 Test Metrics:
   Loss: 0.0713, RMSE: 0.2670, MAE: 0.2287, R²: 0.0207

============================================================
🔄 Round 7 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0876, val=0.0886 (↓), lr=0.000250
   • Epoch   2/100: train=0.0872, val=0.0883, patience=1/15, lr=0.000250
   ✓ Epoch   3/100: train=0.0867, val=0.0880 (↓), lr=0.000250
   • Epoch   4/100: train=0.0865, val=0.0881, patience=1/15, lr=0.000250
   • Epoch   5/100: train=0.0862, val=0.0879, patience=2/15, lr=0.000250
   • Epoch  11/100: train=0.0853, val=0.0874, patience=1/15, lr=0.000250
   • Epoch  21/100: train=0.0842, val=0.0872, patience=11/15, lr=0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0875)

============================================================
📊 Round 7 Summary - Client client_32
   Epochs: 25/100 (early stopped)
   LR: 0.000250 → 0.000250 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=0.0107
   Val:   Loss=0.0875, RMSE=0.2958, R²=0.0143
============================================================


============================================================
🔄 Round 8 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0877, val=0.0809 (↓), lr=0.000250
   • Epoch   2/100: train=0.0869, val=0.0810, patience=1/15, lr=0.000250
   • Epoch   3/100: train=0.0864, val=0.0810, patience=2/15, lr=0.000250
   • Epoch   4/100: train=0.0860, val=0.0812, patience=3/15, lr=0.000250
   • Epoch   5/100: train=0.0857, val=0.0813, patience=4/15, lr=0.000250
   📉 Epoch 7: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0847, val=0.0815, patience=10/15, lr=0.000125
   📉 Epoch 15: LR reduced 0.000125 → 0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 8 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000250 → 0.000063 (2 reductions)
   Train: Loss=0.0879, RMSE=0.2965, R²=-0.0110
   Val:   Loss=0.0809, RMSE=0.2845, R²=-0.0047
============================================================


📊 Round 8 Test Metrics:
   Loss: 0.0710, RMSE: 0.2665, MAE: 0.2279, R²: 0.0243

============================================================
🔄 Round 10 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0876, val=0.0824 (↓), lr=0.000063
   • Epoch   2/100: train=0.0871, val=0.0825, patience=1/15, lr=0.000063
   • Epoch   3/100: train=0.0866, val=0.0826, patience=2/15, lr=0.000063
   • Epoch   4/100: train=0.0863, val=0.0827, patience=3/15, lr=0.000063
   • Epoch   5/100: train=0.0861, val=0.0828, patience=4/15, lr=0.000063
   📉 Epoch 7: LR reduced 0.000063 → 0.000031
   • Epoch  11/100: train=0.0853, val=0.0828, patience=10/15, lr=0.000031
   📉 Epoch 15: LR reduced 0.000031 → 0.000016

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 10 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000063 → 0.000016 (2 reductions)
   Train: Loss=0.0881, RMSE=0.2969, R²=-0.0121
   Val:   Loss=0.0824, RMSE=0.2871, R²=-0.0301
============================================================


============================================================
🔄 Round 11 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000016
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0942 (↓), lr=0.000016
   • Epoch   2/100: train=0.0842, val=0.0941, patience=1/15, lr=0.000016
   • Epoch   3/100: train=0.0841, val=0.0941, patience=2/15, lr=0.000016
   • Epoch   4/100: train=0.0841, val=0.0940, patience=3/15, lr=0.000016
   • Epoch   5/100: train=0.0840, val=0.0940, patience=4/15, lr=0.000016
   📉 Epoch 7: LR reduced 0.000016 → 0.000008
   • Epoch  11/100: train=0.0837, val=0.0939, patience=10/15, lr=0.000008
   📉 Epoch 15: LR reduced 0.000008 → 0.000004

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0942)

============================================================
📊 Round 11 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000016 → 0.000004 (2 reductions)
   Train: Loss=0.0853, RMSE=0.2921, R²=-0.0217
   Val:   Loss=0.0942, RMSE=0.3068, R²=0.0008
============================================================


📊 Round 11 Test Metrics:
   Loss: 0.0713, RMSE: 0.2670, MAE: 0.2283, R²: 0.0204

============================================================
🔄 Round 14 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000004
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0889, val=0.0853 (↓), lr=0.000004
   • Epoch   2/100: train=0.0888, val=0.0853, patience=1/15, lr=0.000004
   • Epoch   3/100: train=0.0888, val=0.0853, patience=2/15, lr=0.000004
   • Epoch   4/100: train=0.0888, val=0.0853, patience=3/15, lr=0.000004
   • Epoch   5/100: train=0.0888, val=0.0852, patience=4/15, lr=0.000004
   📉 Epoch 7: LR reduced 0.000004 → 0.000002
   • Epoch  11/100: train=0.0887, val=0.0852, patience=10/15, lr=0.000002
   📉 Epoch 15: LR reduced 0.000002 → 0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 14 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000004 → 0.000001 (2 reductions)
   Train: Loss=0.0875, RMSE=0.2958, R²=-0.0197
   Val:   Loss=0.0853, RMSE=0.2921, R²=-0.0031
============================================================


📊 Round 14 Test Metrics:
   Loss: 0.0713, RMSE: 0.2671, MAE: 0.2284, R²: 0.0198

============================================================
🔄 Round 15 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0931 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0931, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0931, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0931, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0931, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0932, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0931)

============================================================
📊 Round 15 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2925, R²=-0.0273
   Val:   Loss=0.0931, RMSE=0.3051, R²=-0.0043
============================================================


📊 Round 15 Test Metrics:
   Loss: 0.0713, RMSE: 0.2670, MAE: 0.2284, R²: 0.0203

============================================================
🔄 Round 16 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0928 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0928, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0928, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0928, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0928, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0928, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0928)

============================================================
📊 Round 16 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2925, R²=-0.0214
   Val:   Loss=0.0928, RMSE=0.3046, R²=-0.0070
============================================================


📊 Round 16 Test Metrics:
   Loss: 0.0712, RMSE: 0.2669, MAE: 0.2283, R²: 0.0211

============================================================
🔄 Round 19 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0915 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0916, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0916, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0916, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0916, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0917, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0915)

============================================================
📊 Round 19 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2927, R²=-0.0124
   Val:   Loss=0.0915, RMSE=0.3026, R²=-0.0553
============================================================


============================================================
🔄 Round 22 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0896, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0896, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0896, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0896, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0895, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0895, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 22 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0884, RMSE=0.2973, R²=-0.0077
   Val:   Loss=0.0801, RMSE=0.2829, R²=-0.0490
============================================================


📊 Round 22 Test Metrics:
   Loss: 0.0713, RMSE: 0.2670, MAE: 0.2285, R²: 0.0206

============================================================
🔄 Round 23 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0927 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0927, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0927, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0927, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0927, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0927, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0927)

============================================================
📊 Round 23 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2920, R²=-0.0088
   Val:   Loss=0.0927, RMSE=0.3045, R²=-0.0270
============================================================


📊 Round 23 Test Metrics:
   Loss: 0.0713, RMSE: 0.2670, MAE: 0.2285, R²: 0.0203

============================================================
🔄 Round 24 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0908 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0908, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0908, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0908, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0908, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0908, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0908)

============================================================
📊 Round 24 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2928, R²=-0.0122
   Val:   Loss=0.0908, RMSE=0.3014, R²=-0.0147
============================================================


📊 Round 24 Test Metrics:
   Loss: 0.0713, RMSE: 0.2670, MAE: 0.2285, R²: 0.0203

📊 Round 24 Test Metrics:
   Loss: 0.0713, RMSE: 0.2670, MAE: 0.2285, R²: 0.0203

📊 Round 24 Test Metrics:
   Loss: 0.0713, RMSE: 0.2670, MAE: 0.2285, R²: 0.0203

============================================================
🔄 Round 31 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0917 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0917, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0917, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0917, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0917, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0917, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0917)

============================================================
📊 Round 31 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2924, R²=-0.0152
   Val:   Loss=0.0917, RMSE=0.3028, R²=-0.0047
============================================================


📊 Round 31 Test Metrics:
   Loss: 0.0713, RMSE: 0.2670, MAE: 0.2285, R²: 0.0204

============================================================
🔄 Round 32 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0956 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0956, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0956, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0956, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0956, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0956, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0956)

============================================================
📊 Round 32 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=-0.0048
   Val:   Loss=0.0956, RMSE=0.3092, R²=-0.0467
============================================================


📊 Round 32 Test Metrics:
   Loss: 0.0713, RMSE: 0.2670, MAE: 0.2285, R²: 0.0204

📊 Round 32 Test Metrics:
   Loss: 0.0713, RMSE: 0.2670, MAE: 0.2285, R²: 0.0204

📊 Round 32 Test Metrics:
   Loss: 0.0713, RMSE: 0.2670, MAE: 0.2285, R²: 0.0204

📊 Round 32 Test Metrics:
   Loss: 0.0713, RMSE: 0.2670, MAE: 0.2285, R²: 0.0205

============================================================
🔄 Round 39 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.1042 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.1042, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.1042, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.1042, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.1042, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.1042, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.1042)

============================================================
📊 Round 39 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=-0.0130
   Val:   Loss=0.1042, RMSE=0.3228, R²=-0.0113
============================================================


============================================================
🔄 Round 40 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0907 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0907, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0907, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0907, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0907, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0907, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0907)

============================================================
📊 Round 40 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2928, R²=-0.0123
   Val:   Loss=0.0907, RMSE=0.3012, R²=-0.0135
============================================================


📊 Round 40 Test Metrics:
   Loss: 0.0713, RMSE: 0.2670, MAE: 0.2285, R²: 0.0205

📊 Round 40 Test Metrics:
   Loss: 0.0713, RMSE: 0.2670, MAE: 0.2285, R²: 0.0205

============================================================
🔄 Round 42 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0871, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0871, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0871, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0871, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0871, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0871, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 42 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0869, RMSE=0.2948, R²=-0.0056
   Val:   Loss=0.0860, RMSE=0.2933, R²=-0.0412
============================================================


============================================================
🔄 Round 43 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0983 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0983, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0983, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0983, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0983, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0983, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0983)

============================================================
📊 Round 43 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=-0.0128
   Val:   Loss=0.0983, RMSE=0.3136, R²=-0.0113
============================================================


============================================================
🔄 Round 44 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0881, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0881, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0881, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0881, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0881, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0880, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 44 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0869, RMSE=0.2948, R²=-0.0121
   Val:   Loss=0.0860, RMSE=0.2932, R²=-0.0150
============================================================


============================================================
🔄 Round 45 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0871, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0871, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0871, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0871, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0871, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0870, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 45 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0879, RMSE=0.2965, R²=-0.0207
   Val:   Loss=0.0820, RMSE=0.2863, R²=0.0204
============================================================


============================================================
🔄 Round 46 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0903, val=0.0763 (↓), lr=0.000001
   • Epoch   2/100: train=0.0903, val=0.0763, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0903, val=0.0764, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0903, val=0.0764, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0903, val=0.0764, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0902, val=0.0764, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0763)

============================================================
📊 Round 46 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0893, RMSE=0.2989, R²=-0.0224
   Val:   Loss=0.0763, RMSE=0.2763, R²=0.0228
============================================================


📊 Round 46 Test Metrics:
   Loss: 0.0713, RMSE: 0.2670, MAE: 0.2285, R²: 0.0206

============================================================
🔄 Round 47 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.1002 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.1002, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.1002, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.1002, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.1002, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.1003, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.1002)

============================================================
📊 Round 47 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2887, R²=-0.0012
   Val:   Loss=0.1002, RMSE=0.3166, R²=-0.0956
============================================================


📊 Round 47 Test Metrics:
   Loss: 0.0713, RMSE: 0.2670, MAE: 0.2285, R²: 0.0206

============================================================
🔄 Round 49 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0961 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0961, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0961, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0961, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0961, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0961, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0961)

============================================================
📊 Round 49 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=-0.0235
   Val:   Loss=0.0961, RMSE=0.3100, R²=0.0203
============================================================


============================================================
🔄 Round 50 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0872, val=0.0875 (↓), lr=0.000001
   • Epoch   2/100: train=0.0872, val=0.0875, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0872, val=0.0875, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0872, val=0.0875, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0871, val=0.0875, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0871, val=0.0875, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0875)

============================================================
📊 Round 50 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2942, R²=0.0025
   Val:   Loss=0.0875, RMSE=0.2958, R²=-0.0759
============================================================


📊 Round 50 Test Metrics:
   Loss: 0.0713, RMSE: 0.2670, MAE: 0.2285, R²: 0.0207

📊 Round 50 Test Metrics:
   Loss: 0.0713, RMSE: 0.2670, MAE: 0.2285, R²: 0.0207

📊 Round 50 Test Metrics:
   Loss: 0.0713, RMSE: 0.2670, MAE: 0.2285, R²: 0.0207

📊 Round 50 Test Metrics:
   Loss: 0.0713, RMSE: 0.2670, MAE: 0.2285, R²: 0.0208

📊 Round 50 Test Metrics:
   Loss: 0.0713, RMSE: 0.2670, MAE: 0.2285, R²: 0.0208

📊 Round 50 Test Metrics:
   Loss: 0.0713, RMSE: 0.2670, MAE: 0.2285, R²: 0.0208

============================================================
🔄 Round 61 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0870, val=0.0866 (↓), lr=0.000001
   • Epoch   2/100: train=0.0870, val=0.0866, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0869, val=0.0866, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0869, val=0.0865, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0869, val=0.0865, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0869, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0866)

============================================================
📊 Round 61 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2946, R²=-0.0078
   Val:   Loss=0.0866, RMSE=0.2942, R²=-0.0317
============================================================


📊 Round 61 Test Metrics:
   Loss: 0.0713, RMSE: 0.2670, MAE: 0.2285, R²: 0.0208

📊 Round 61 Test Metrics:
   Loss: 0.0713, RMSE: 0.2670, MAE: 0.2285, R²: 0.0209

📊 Round 61 Test Metrics:
   Loss: 0.0713, RMSE: 0.2670, MAE: 0.2285, R²: 0.0209

📊 Round 61 Test Metrics:
   Loss: 0.0713, RMSE: 0.2669, MAE: 0.2285, R²: 0.0209

============================================================
🔄 Round 70 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0899 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0899, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0899, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0899, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0899, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0899, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0899)

============================================================
📊 Round 70 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2931, R²=-0.0047
   Val:   Loss=0.0899, RMSE=0.2998, R²=-0.0628
============================================================


📊 Round 70 Test Metrics:
   Loss: 0.0713, RMSE: 0.2669, MAE: 0.2285, R²: 0.0209

============================================================
🔄 Round 73 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0890, val=0.0768 (↓), lr=0.000001
   • Epoch   2/100: train=0.0890, val=0.0768, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0890, val=0.0768, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0890, val=0.0768, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0890, val=0.0768, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0889, val=0.0767, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0768)

============================================================
📊 Round 73 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0892, RMSE=0.2986, R²=-0.0194
   Val:   Loss=0.0768, RMSE=0.2771, R²=0.0160
============================================================


============================================================
🔄 Round 74 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0869, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0869, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0869, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0869, val=0.0859, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0869, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0868, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 74 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0869, RMSE=0.2948, R²=-0.0143
   Val:   Loss=0.0859, RMSE=0.2931, R²=-0.0032
============================================================


============================================================
🔄 Round 76 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0917 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0917, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0917, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0917, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0917, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0918, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0917)

============================================================
📊 Round 76 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2923, R²=-0.0093
   Val:   Loss=0.0917, RMSE=0.3028, R²=-0.0352
============================================================


📊 Round 76 Test Metrics:
   Loss: 0.0712, RMSE: 0.2669, MAE: 0.2284, R²: 0.0211

📊 Round 76 Test Metrics:
   Loss: 0.0712, RMSE: 0.2669, MAE: 0.2284, R²: 0.0211

📊 Round 76 Test Metrics:
   Loss: 0.0712, RMSE: 0.2669, MAE: 0.2284, R²: 0.0211

📊 Round 76 Test Metrics:
   Loss: 0.0712, RMSE: 0.2669, MAE: 0.2284, R²: 0.0211

📊 Round 76 Test Metrics:
   Loss: 0.0712, RMSE: 0.2669, MAE: 0.2284, R²: 0.0211

============================================================
🔄 Round 86 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0946 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0946, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0946, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0946, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0946, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0946, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0946)

============================================================
📊 Round 86 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2911, R²=-0.0145
   Val:   Loss=0.0946, RMSE=0.3075, R²=-0.0102
============================================================


📊 Round 86 Test Metrics:
   Loss: 0.0712, RMSE: 0.2669, MAE: 0.2284, R²: 0.0212

============================================================
🔄 Round 87 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0951 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0951, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0951, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0951, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0950, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0950, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0951)

============================================================
📊 Round 87 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=-0.0029
   Val:   Loss=0.0951, RMSE=0.3083, R²=-0.0526
============================================================


📊 Round 87 Test Metrics:
   Loss: 0.0712, RMSE: 0.2669, MAE: 0.2284, R²: 0.0212

📊 Round 87 Test Metrics:
   Loss: 0.0712, RMSE: 0.2669, MAE: 0.2284, R²: 0.0212

============================================================
🔄 Round 91 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0866 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0866, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0866, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0866, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0866, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0866, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0866)

============================================================
📊 Round 91 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0867, RMSE=0.2945, R²=-0.0082
   Val:   Loss=0.0866, RMSE=0.2943, R²=-0.0355
============================================================


📊 Round 91 Test Metrics:
   Loss: 0.0712, RMSE: 0.2669, MAE: 0.2284, R²: 0.0213

📊 Round 91 Test Metrics:
   Loss: 0.0712, RMSE: 0.2669, MAE: 0.2284, R²: 0.0213

============================================================
🔄 Round 93 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0876 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0876, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0876, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0876, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0876, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0876, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0876)

============================================================
📊 Round 93 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2940, R²=-0.0060
   Val:   Loss=0.0876, RMSE=0.2960, R²=-0.0382
============================================================


📊 Round 93 Test Metrics:
   Loss: 0.0712, RMSE: 0.2669, MAE: 0.2284, R²: 0.0213

📊 Round 93 Test Metrics:
   Loss: 0.0712, RMSE: 0.2669, MAE: 0.2284, R²: 0.0213

============================================================
🔄 Round 95 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0870 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0870, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0870, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0870, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0870, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0870, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 95 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2943, R²=-0.0206
   Val:   Loss=0.0870, RMSE=0.2950, R²=0.0211
============================================================


📊 Round 95 Test Metrics:
   Loss: 0.0712, RMSE: 0.2669, MAE: 0.2284, R²: 0.0213

============================================================
🔄 Round 98 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0964 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0964, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0964, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0964, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0964, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0964, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0964)

============================================================
📊 Round 98 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=0.0024
   Val:   Loss=0.0964, RMSE=0.3105, R²=-0.0661
============================================================


============================================================
🔄 Round 100 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0963 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0962, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0962, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0962, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0962, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0962, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0963)

============================================================
📊 Round 100 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=-0.0096
   Val:   Loss=0.0963, RMSE=0.3102, R²=-0.0204
============================================================


📊 Round 100 Test Metrics:
   Loss: 0.0712, RMSE: 0.2669, MAE: 0.2284, R²: 0.0215

============================================================
🔄 Round 108 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0876 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0876, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0876, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0876, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0875, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0875, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0876)

============================================================
📊 Round 108 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2940, R²=-0.0089
   Val:   Loss=0.0876, RMSE=0.2959, R²=-0.0234
============================================================


📊 Round 108 Test Metrics:
   Loss: 0.0712, RMSE: 0.2669, MAE: 0.2284, R²: 0.0215

📊 Round 108 Test Metrics:
   Loss: 0.0712, RMSE: 0.2669, MAE: 0.2284, R²: 0.0216

============================================================
🔄 Round 114 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0881, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0881, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0880, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0880, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0880, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0880, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 114 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2947, R²=-0.0152
   Val:   Loss=0.0860, RMSE=0.2933, R²=0.0010
============================================================


📊 Round 114 Test Metrics:
   Loss: 0.0712, RMSE: 0.2668, MAE: 0.2284, R²: 0.0217

============================================================
🔄 Round 116 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0880, val=0.0871 (↓), lr=0.000001
   • Epoch   2/100: train=0.0880, val=0.0871, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0879, val=0.0871, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0879, val=0.0871, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0879, val=0.0871, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0879, val=0.0871, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0871)

============================================================
📊 Round 116 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2942, R²=-0.0159
   Val:   Loss=0.0871, RMSE=0.2951, R²=-0.0150
============================================================


============================================================
🔄 Round 119 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0912 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0912, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0912, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0912, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0912, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0912, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0912)

============================================================
📊 Round 119 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2925, R²=-0.0143
   Val:   Loss=0.0912, RMSE=0.3020, R²=-0.0038
============================================================


============================================================
🔄 Round 121 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0867 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0867, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0867, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0867, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0866, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 121 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0867, RMSE=0.2944, R²=-0.0161
   Val:   Loss=0.0867, RMSE=0.2944, R²=0.0050
============================================================


============================================================
🔄 Round 122 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0970 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0970, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0969, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0969, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0969, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0969, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0970)

============================================================
📊 Round 122 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=-0.0159
   Val:   Loss=0.0970, RMSE=0.3114, R²=0.0026
============================================================


============================================================
🔄 Round 124 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0885, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0885, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0885, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0885, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0885, val=0.0864, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0884, val=0.0864, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 124 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0867, RMSE=0.2945, R²=-0.0088
   Val:   Loss=0.0864, RMSE=0.2939, R²=-0.0244
============================================================


============================================================
🔄 Round 125 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.1013 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.1013, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.1013, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.1013, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.1013, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.1012, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.1013)

============================================================
📊 Round 125 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=-0.0048
   Val:   Loss=0.1013, RMSE=0.3182, R²=-0.0350
============================================================


============================================================
🔄 Round 126 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0872 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0873, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0873, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0873, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0873, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0873, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0872)

============================================================
📊 Round 126 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2942, R²=-0.0025
   Val:   Loss=0.0872, RMSE=0.2954, R²=-0.0679
============================================================


📊 Round 126 Test Metrics:
   Loss: 0.0712, RMSE: 0.2668, MAE: 0.2284, R²: 0.0219

📊 Round 126 Test Metrics:
   Loss: 0.0712, RMSE: 0.2668, MAE: 0.2284, R²: 0.0219

============================================================
🔄 Round 130 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0892, val=0.0743 (↓), lr=0.000001
   • Epoch   2/100: train=0.0892, val=0.0743, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0892, val=0.0742, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0892, val=0.0742, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0892, val=0.0742, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0891, val=0.0742, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0743)

============================================================
📊 Round 130 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0898, RMSE=0.2996, R²=-0.0105
   Val:   Loss=0.0743, RMSE=0.2725, R²=-0.0255
============================================================


============================================================
🔄 Round 132 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0978 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0978, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0978, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0978, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0978, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0978, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0978)

============================================================
📊 Round 132 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2896, R²=-0.0141
   Val:   Loss=0.0978, RMSE=0.3127, R²=-0.0424
============================================================


============================================================
🔄 Round 133 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0910 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0910, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0910, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0910, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0910, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0910, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0910)

============================================================
📊 Round 133 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2926, R²=-0.0041
   Val:   Loss=0.0910, RMSE=0.3016, R²=-0.0419
============================================================


============================================================
🔄 Round 136 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0870 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0870, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0870, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0870, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0870, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0871, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 136 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2942, R²=-0.0107
   Val:   Loss=0.0870, RMSE=0.2949, R²=-0.0455
============================================================


📊 Round 136 Test Metrics:
   Loss: 0.0712, RMSE: 0.2668, MAE: 0.2283, R²: 0.0220

============================================================
🔄 Round 138 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0892, val=0.0751 (↓), lr=0.000001
   • Epoch   2/100: train=0.0892, val=0.0751, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0891, val=0.0751, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0891, val=0.0751, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0891, val=0.0751, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0891, val=0.0751, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0751)

============================================================
📊 Round 138 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0895, RMSE=0.2992, R²=-0.0050
   Val:   Loss=0.0751, RMSE=0.2741, R²=-0.0472
============================================================


📊 Round 138 Test Metrics:
   Loss: 0.0712, RMSE: 0.2668, MAE: 0.2283, R²: 0.0221

📊 Round 138 Test Metrics:
   Loss: 0.0712, RMSE: 0.2668, MAE: 0.2283, R²: 0.0221

============================================================
🔄 Round 141 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0869, val=0.0867 (↓), lr=0.000001
   • Epoch   2/100: train=0.0869, val=0.0867, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0869, val=0.0867, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0869, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0869, val=0.0867, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0868, val=0.0867, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 141 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2943, R²=-0.0191
   Val:   Loss=0.0867, RMSE=0.2945, R²=0.0139
============================================================


============================================================
🔄 Round 143 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0866, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 143 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0876, RMSE=0.2960, R²=-0.0090
   Val:   Loss=0.0829, RMSE=0.2879, R²=-0.0297
============================================================


📊 Round 143 Test Metrics:
   Loss: 0.0712, RMSE: 0.2668, MAE: 0.2283, R²: 0.0221

============================================================
🔄 Round 145 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0872, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0872, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0872, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0872, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0872, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0871, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 145 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0883, RMSE=0.2971, R²=-0.0176
   Val:   Loss=0.0802, RMSE=0.2832, R²=0.0134
============================================================


📊 Round 145 Test Metrics:
   Loss: 0.0712, RMSE: 0.2668, MAE: 0.2283, R²: 0.0221

============================================================
🔄 Round 146 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0874, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0874, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0874, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0874, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0873, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0873, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 146 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0870, RMSE=0.2950, R²=-0.0081
   Val:   Loss=0.0852, RMSE=0.2918, R²=-0.0273
============================================================


============================================================
🔄 Round 148 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0899, val=0.0776 (↓), lr=0.000001
   • Epoch   2/100: train=0.0899, val=0.0776, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0899, val=0.0776, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0899, val=0.0776, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0899, val=0.0776, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0898, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 148 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0889, RMSE=0.2982, R²=-0.0133
   Val:   Loss=0.0776, RMSE=0.2786, R²=-0.0031
============================================================


============================================================
🔄 Round 149 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0904, val=0.0714 (↓), lr=0.000001
   • Epoch   2/100: train=0.0904, val=0.0714, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0904, val=0.0714, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0904, val=0.0714, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0904, val=0.0714, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0903, val=0.0714, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0714)

============================================================
📊 Round 149 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0904, RMSE=0.3007, R²=-0.0187
   Val:   Loss=0.0714, RMSE=0.2673, R²=0.0146
============================================================


📊 Round 149 Test Metrics:
   Loss: 0.0712, RMSE: 0.2668, MAE: 0.2283, R²: 0.0222

📊 Round 149 Test Metrics:
   Loss: 0.0712, RMSE: 0.2668, MAE: 0.2283, R²: 0.0222

📊 Round 149 Test Metrics:
   Loss: 0.0712, RMSE: 0.2668, MAE: 0.2283, R²: 0.0222

📊 Round 149 Test Metrics:
   Loss: 0.0712, RMSE: 0.2668, MAE: 0.2283, R²: 0.0222

============================================================
🔄 Round 153 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0870, val=0.0870 (↓), lr=0.000001
   • Epoch   2/100: train=0.0869, val=0.0870, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0869, val=0.0870, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0869, val=0.0870, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0869, val=0.0870, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0868, val=0.0870, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 153 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2942, R²=-0.0070
   Val:   Loss=0.0870, RMSE=0.2950, R²=-0.0310
============================================================


📊 Round 153 Test Metrics:
   Loss: 0.0712, RMSE: 0.2668, MAE: 0.2283, R²: 0.0223

============================================================
🔄 Round 154 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0910 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0910, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0910, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0910, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0910, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0909, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0910)

============================================================
📊 Round 154 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2925, R²=-0.0096
   Val:   Loss=0.0910, RMSE=0.3016, R²=-0.0356
============================================================


============================================================
🔄 Round 155 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0883, val=0.0863 (↓), lr=0.000001
   • Epoch   2/100: train=0.0883, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0883, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0883, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0882, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0882, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 155 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0867, RMSE=0.2945, R²=0.0023
   Val:   Loss=0.0863, RMSE=0.2938, R²=-0.0707
============================================================


📊 Round 155 Test Metrics:
   Loss: 0.0712, RMSE: 0.2668, MAE: 0.2283, R²: 0.0223

📊 Round 155 Test Metrics:
   Loss: 0.0712, RMSE: 0.2668, MAE: 0.2283, R²: 0.0223

============================================================
🔄 Round 158 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0899 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0899, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0899, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0899, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0899, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0899, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0899)

============================================================
📊 Round 158 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2930, R²=-0.0119
   Val:   Loss=0.0899, RMSE=0.2998, R²=-0.0102
============================================================


============================================================
🔄 Round 160 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0876, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0876, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0876, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0876, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0876, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0875, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 160 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0874, RMSE=0.2956, R²=-0.0202
   Val:   Loss=0.0837, RMSE=0.2893, R²=0.0187
============================================================


📊 Round 160 Test Metrics:
   Loss: 0.0712, RMSE: 0.2668, MAE: 0.2283, R²: 0.0224

📊 Round 160 Test Metrics:
   Loss: 0.0712, RMSE: 0.2668, MAE: 0.2283, R²: 0.0224

============================================================
🔄 Round 163 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0880, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0880, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0880, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0880, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0880, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0879, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 163 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0885, RMSE=0.2976, R²=-0.0085
   Val:   Loss=0.0790, RMSE=0.2810, R²=-0.0239
============================================================


============================================================
🔄 Round 164 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0873, val=0.0878 (↓), lr=0.000001
   • Epoch   2/100: train=0.0873, val=0.0878, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0873, val=0.0879, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0872, val=0.0879, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0872, val=0.0879, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0871, val=0.0880, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0878)

============================================================
📊 Round 164 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2938, R²=-0.0135
   Val:   Loss=0.0878, RMSE=0.2963, R²=-0.0552
============================================================


📊 Round 164 Test Metrics:
   Loss: 0.0712, RMSE: 0.2667, MAE: 0.2283, R²: 0.0224

============================================================
🔄 Round 165 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0883, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0883, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0883, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0883, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0883, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0882, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 165 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0879, RMSE=0.2964, R²=-0.0280
   Val:   Loss=0.0816, RMSE=0.2857, R²=0.0352
============================================================


📊 Round 165 Test Metrics:
   Loss: 0.0712, RMSE: 0.2667, MAE: 0.2283, R²: 0.0224

============================================================
🔄 Round 166 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 166 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0867, RMSE=0.2945, R²=-0.0142
   Val:   Loss=0.0862, RMSE=0.2936, R²=-0.0058
============================================================


📊 Round 166 Test Metrics:
   Loss: 0.0712, RMSE: 0.2667, MAE: 0.2283, R²: 0.0224

============================================================
🔄 Round 167 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0892, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0892, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0892, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0892, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0892, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0891, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 167 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0867, RMSE=0.2945, R²=-0.0127
   Val:   Loss=0.0861, RMSE=0.2935, R²=-0.0069
============================================================


============================================================
🔄 Round 168 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0969 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0969, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0969, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0969, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0969, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0969, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0969)

============================================================
📊 Round 168 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2899, R²=-0.0065
   Val:   Loss=0.0969, RMSE=0.3113, R²=-0.0334
============================================================


📊 Round 168 Test Metrics:
   Loss: 0.0711, RMSE: 0.2667, MAE: 0.2283, R²: 0.0225

============================================================
🔄 Round 169 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0880, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0880, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0880, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0880, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0880, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0880, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 169 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0883, RMSE=0.2972, R²=-0.0065
   Val:   Loss=0.0798, RMSE=0.2825, R²=-0.0334
============================================================


============================================================
🔄 Round 170 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0871, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0870, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0870, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0870, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0870, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0869, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 170 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0869, RMSE=0.2949, R²=-0.0077
   Val:   Loss=0.0854, RMSE=0.2922, R²=-0.0373
============================================================


📊 Round 170 Test Metrics:
   Loss: 0.0711, RMSE: 0.2667, MAE: 0.2283, R²: 0.0225

============================================================
🔄 Round 173 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0878, val=0.0918 (↓), lr=0.000001
   • Epoch   2/100: train=0.0878, val=0.0918, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0878, val=0.0918, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0877, val=0.0918, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0877, val=0.0918, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0877, val=0.0918, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0918)

============================================================
📊 Round 173 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2921, R²=-0.0161
   Val:   Loss=0.0918, RMSE=0.3029, R²=0.0046
============================================================


📊 Round 173 Test Metrics:
   Loss: 0.0711, RMSE: 0.2667, MAE: 0.2283, R²: 0.0225

============================================================
🔄 Round 175 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0897 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0897, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0897, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0897, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0897, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0897, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0897)

============================================================
📊 Round 175 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2930, R²=-0.0113
   Val:   Loss=0.0897, RMSE=0.2995, R²=-0.0377
============================================================


📊 Round 175 Test Metrics:
   Loss: 0.0711, RMSE: 0.2667, MAE: 0.2283, R²: 0.0226

============================================================
🔄 Round 177 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0948 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0948, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0948, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0948, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0948, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0947, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0948)

============================================================
📊 Round 177 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2908, R²=-0.0093
   Val:   Loss=0.0948, RMSE=0.3079, R²=-0.0177
============================================================


============================================================
🔄 Round 178 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0871, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0871, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0871, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0871, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0871, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0870, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 178 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0877, RMSE=0.2961, R²=-0.0114
   Val:   Loss=0.0824, RMSE=0.2871, R²=-0.0101
============================================================


============================================================
🔄 Round 179 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0902 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0902, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0902, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0902, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0902, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0902, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0902)

============================================================
📊 Round 179 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2928, R²=-0.0070
   Val:   Loss=0.0902, RMSE=0.3003, R²=-0.0437
============================================================


📊 Round 179 Test Metrics:
   Loss: 0.0711, RMSE: 0.2667, MAE: 0.2283, R²: 0.0227

============================================================
🔄 Round 181 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0901, val=0.0738 (↓), lr=0.000001
   • Epoch   2/100: train=0.0901, val=0.0738, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0901, val=0.0738, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0901, val=0.0738, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0901, val=0.0738, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0900, val=0.0738, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0738)

============================================================
📊 Round 181 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0898, RMSE=0.2997, R²=-0.0186
   Val:   Loss=0.0738, RMSE=0.2718, R²=0.0215
============================================================


📊 Round 181 Test Metrics:
   Loss: 0.0711, RMSE: 0.2667, MAE: 0.2283, R²: 0.0227

============================================================
🔄 Round 182 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0905 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0905, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0905, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0905, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0905, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0904, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0905)

============================================================
📊 Round 182 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2926, R²=-0.0072
   Val:   Loss=0.0905, RMSE=0.3008, R²=-0.0262
============================================================


📊 Round 182 Test Metrics:
   Loss: 0.0711, RMSE: 0.2667, MAE: 0.2283, R²: 0.0227

============================================================
🔄 Round 183 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 183 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0872, RMSE=0.2954, R²=-0.0076
   Val:   Loss=0.0841, RMSE=0.2900, R²=-0.0353
============================================================


============================================================
🔄 Round 184 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0918, val=0.0723 (↓), lr=0.000001
   • Epoch   2/100: train=0.0918, val=0.0723, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0918, val=0.0723, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0917, val=0.0723, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0917, val=0.0723, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0917, val=0.0723, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0723)

============================================================
📊 Round 184 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0902, RMSE=0.3003, R²=-0.0152
   Val:   Loss=0.0723, RMSE=0.2689, R²=0.0034
============================================================


============================================================
🔄 Round 185 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0920 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0920, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0920, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0920, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0920, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0919, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0920)

============================================================
📊 Round 185 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2920, R²=-0.0124
   Val:   Loss=0.0920, RMSE=0.3033, R²=-0.0061
============================================================


📊 Round 185 Test Metrics:
   Loss: 0.0711, RMSE: 0.2667, MAE: 0.2283, R²: 0.0228

============================================================
🔄 Round 186 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0889, val=0.0759 (↓), lr=0.000001
   • Epoch   2/100: train=0.0888, val=0.0759, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0888, val=0.0759, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0888, val=0.0759, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0888, val=0.0759, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0887, val=0.0759, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0759)

============================================================
📊 Round 186 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0893, RMSE=0.2988, R²=-0.0151
   Val:   Loss=0.0759, RMSE=0.2756, R²=0.0036
============================================================


============================================================
🔄 Round 187 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0867, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0867, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0867, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0867, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0866, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 187 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2946, R²=-0.0078
   Val:   Loss=0.0858, RMSE=0.2929, R²=-0.0265
============================================================


📊 Round 187 Test Metrics:
   Loss: 0.0711, RMSE: 0.2667, MAE: 0.2283, R²: 0.0228

📊 Round 187 Test Metrics:
   Loss: 0.0711, RMSE: 0.2667, MAE: 0.2283, R²: 0.0228

============================================================
🔄 Round 194 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0871, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0871, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0871, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0871, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0871, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0871, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 194 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0871, RMSE=0.2951, R²=-0.0106
   Val:   Loss=0.0847, RMSE=0.2910, R²=-0.0142
============================================================


============================================================
🔄 Round 195 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0871, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0871, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0870, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0870, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0870, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0869, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 195 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0873, RMSE=0.2954, R²=-0.0113
   Val:   Loss=0.0838, RMSE=0.2895, R²=-0.0202
============================================================


📊 Round 195 Test Metrics:
   Loss: 0.0711, RMSE: 0.2667, MAE: 0.2282, R²: 0.0229

============================================================
🔄 Round 200 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0871, val=0.0883 (↓), lr=0.000001
   • Epoch   2/100: train=0.0871, val=0.0884, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0871, val=0.0884, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0871, val=0.0884, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0871, val=0.0884, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0870, val=0.0885, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0883)

============================================================
📊 Round 200 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2935, R²=-0.0142
   Val:   Loss=0.0883, RMSE=0.2972, R²=-0.0350
============================================================


📊 Round 200 Test Metrics:
   Loss: 0.0711, RMSE: 0.2667, MAE: 0.2282, R²: 0.0230

============================================================
🔄 Round 202 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0867, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0867, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0867, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0867, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0866, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 202 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0878, RMSE=0.2964, R²=-0.0180
   Val:   Loss=0.0816, RMSE=0.2857, R²=0.0082
============================================================


============================================================
🔄 Round 204 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0871, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0871, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0871, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0870, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0870, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0868, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 204 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0872, RMSE=0.2953, R²=-0.0164
   Val:   Loss=0.0840, RMSE=0.2899, R²=-0.0951
============================================================


📊 Round 204 Test Metrics:
   Loss: 0.0711, RMSE: 0.2667, MAE: 0.2282, R²: 0.0230

============================================================
🔄 Round 207 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 207 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0871, RMSE=0.2951, R²=-0.0070
   Val:   Loss=0.0846, RMSE=0.2909, R²=-0.0276
============================================================


📊 Round 207 Test Metrics:
   Loss: 0.0711, RMSE: 0.2667, MAE: 0.2282, R²: 0.0231

============================================================
🔄 Round 209 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.1003 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.1003, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.1003, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.1003, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.1003, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.1003, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.1003)

============================================================
📊 Round 209 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=-0.0157
   Val:   Loss=0.1003, RMSE=0.3166, R²=0.0008
============================================================


============================================================
🔄 Round 210 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0877, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0877, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0877, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0877, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0877, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0876, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 210 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2946, R²=-0.0128
   Val:   Loss=0.0858, RMSE=0.2930, R²=-0.0019
============================================================


============================================================
🔄 Round 211 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0935 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0935, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0935, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0935, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0935, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0935, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0935)

============================================================
📊 Round 211 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2913, R²=-0.0239
   Val:   Loss=0.0935, RMSE=0.3058, R²=0.0324
============================================================


📊 Round 211 Test Metrics:
   Loss: 0.0711, RMSE: 0.2666, MAE: 0.2282, R²: 0.0231

============================================================
🔄 Round 212 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0871, val=0.0888 (↓), lr=0.000001
   • Epoch   2/100: train=0.0871, val=0.0888, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0871, val=0.0888, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0871, val=0.0888, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0871, val=0.0888, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0870, val=0.0887, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0888)

============================================================
📊 Round 212 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2933, R²=-0.0117
   Val:   Loss=0.0888, RMSE=0.2980, R²=-0.0167
============================================================


============================================================
🔄 Round 214 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0914 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0914, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0914, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0914, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0914, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0914, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0914)

============================================================
📊 Round 214 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2922, R²=-0.0099
   Val:   Loss=0.0914, RMSE=0.3023, R²=-0.0184
============================================================


📊 Round 214 Test Metrics:
   Loss: 0.0711, RMSE: 0.2666, MAE: 0.2282, R²: 0.0232

📊 Round 214 Test Metrics:
   Loss: 0.0711, RMSE: 0.2666, MAE: 0.2282, R²: 0.0232

📊 Round 214 Test Metrics:
   Loss: 0.0711, RMSE: 0.2666, MAE: 0.2282, R²: 0.0232

============================================================
🔄 Round 220 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0947 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0947, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0947, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0947, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0947, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0947, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0947)

============================================================
📊 Round 220 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2908, R²=-0.0180
   Val:   Loss=0.0947, RMSE=0.3077, R²=0.0081
============================================================


📊 Round 220 Test Metrics:
   Loss: 0.0711, RMSE: 0.2666, MAE: 0.2282, R²: 0.0232

============================================================
🔄 Round 221 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0882, val=0.0872 (↓), lr=0.000001
   • Epoch   2/100: train=0.0882, val=0.0872, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0882, val=0.0872, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0882, val=0.0872, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0882, val=0.0872, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0881, val=0.0872, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0872)

============================================================
📊 Round 221 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2940, R²=-0.0094
   Val:   Loss=0.0872, RMSE=0.2953, R²=-0.0180
============================================================


📊 Round 221 Test Metrics:
   Loss: 0.0711, RMSE: 0.2666, MAE: 0.2282, R²: 0.0232

============================================================
🔄 Round 223 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0868 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0868, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0868, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0868, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0868, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0868, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0868)

============================================================
📊 Round 223 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2941, R²=-0.0089
   Val:   Loss=0.0868, RMSE=0.2946, R²=-0.0181
============================================================


📊 Round 223 Test Metrics:
   Loss: 0.0711, RMSE: 0.2666, MAE: 0.2282, R²: 0.0233

============================================================
🔄 Round 224 - Client client_32
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0875 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0875, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0875, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0875, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0875, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0874, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0875)

============================================================
📊 Round 224 Summary - Client client_32
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2938, R²=-0.0141
   Val:   Loss=0.0875, RMSE=0.2959, R²=-0.0024
============================================================


❌ Client client_32 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8687 {grpc_message:"Socket closed", grpc_status:14}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8687 {grpc_message:"Socket closed", grpc_status:14}"
>
