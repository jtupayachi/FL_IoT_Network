[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3d428c41-ee91-4e08-a03d-51e1544405ea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a8ce6de3-6d4e-4818-9014-a2f84e2c455c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 485147a6-bfea-4f6b-bad1-29795f8f5c81
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1bab2a68-c70e-473c-9efc-b818b60027c7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1b3793f4-29c6-4dc7-a2c4-1604bceb89ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7d15408e-4d5f-4bdf-819e-ded3bb3333cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 14fbf939-86bc-45f2-891e-150676713a8d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cab30138-6b72-466d-ad0f-a05700ae740c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3be9df81-1a8a-4fde-bcfb-9408d6359cb0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1c81fee7-460e-4532-87a6-e98809e40306
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f987ae82-bbff-4b3b-84b2-8ca93286da37
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a9c53363-e4a0-456d-bd5b-0acd9cb29517
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 843ed897-d1c4-4a74-860c-bcfe91af78fb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fe55470c-5df4-48a7-b8dd-bb5952bea63b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4da36e26-9712-4e80-a689-271ba2422d7c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b7d8acf7-5a71-472b-bcb3-98200456e289
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b5419daa-4582-45dd-bdae-e989f413411c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f6daf8d0-1d3d-4d19-abc7-ece5d19ad763
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ff3efbdf-f92c-49e2-aad3-d059a59c00ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0a4daca1-fbce-4468-bb7e-9e5df95f0fff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c7411b14-4bd4-4cbb-9a4a-3e855f3b6f82
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5e74e992-d812-4c9a-9b14-238e8f8fd55d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 40e04fa0-3139-4c21-84dd-5bd1914c5d77
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6ad64697-4c67-41b8-ac7b-cc265372df3a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 449ac713-deaf-4834-81e7-6938971a7e3d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 795e9828-19aa-4abd-829a-1b7356e8b056
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eed4d2f8-bf49-4ed2-94a7-707dc5114358
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f5ad9242-0e6a-451c-88fd-4184ebc3eaa1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2a314205-7216-4dc0-a346-6572c20d3dbb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 47b31748-9737-4858-9a31-ef91a018d7f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b4bc9540-0406-46cc-b7bd-75c2ea6b0531
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7a5615a1-c59b-4c0b-8d83-f04feff0677e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b0f04217-cfbc-4253-87d6-05f9ee26488a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 36089856-b80f-46d2-8538-beeac4f564ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b6e1b11d-fd5d-43a4-b9ce-f326a33cef93
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e4083bf7-7a12-4eab-93a9-023b40472210
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b9735893-eff9-4ba8-a7d7-98c2d35ae77d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 960644aa-2242-4d14-ae7f-bc2038ce34a0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c62aa443-6598-426e-a9e5-1a89c36362ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4f629e68-7c1b-46fc-ad3f-73c028e8c084
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 52df0692-f303-4fb2-af65-d350a5c39621
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5e398424-9dca-4e95-972a-1116668f31dd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ca5daa6e-3f9a-4c52-b060-1e084efc8497
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 664d47a4-7ada-4916-a4c9-2c4464c36ffc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b4143dd8-71c7-41a6-8e6b-89b42aae8ae3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8fd6ab10-779d-42ef-93aa-0f90c9a7735b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c89da267-b5f5-4c37-bac8-e0cdcbe1a0b5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 69f35a3d-6904-4995-b35a-c6e205f212fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f8783f39-12b8-448b-9dd8-2ee164353db8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d11ad016-a341-4342-825b-b7939224981e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6209d7ab-67d2-4d52-9348-e30eefdac638
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b514629a-c6ec-410d-889d-d51ec741af94
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4d3e33cb-efe6-4580-85fa-3c15539bbde2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 482a8b7f-ae38-4e94-b0dc-af8a44faa4c4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4c326cc3-12da-45d7-b322-1f90baec2508
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9033e4dd-f31e-4404-82c5-cb684fb1070a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 11a41989-3803-4967-95ba-801c8dde2d98
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9210c96c-91ec-4a4b-b08f-f160cfc01234
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 000674e3-1509-4001-a960-bcc213fac21b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 449e70c9-dbdf-419c-89b9-2671d382c64f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b8eac3e6-1dc9-48d4-99f8-bc85dd3423e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dd99cd50-3a75-4f7d-a1e3-54ed3d6f0516
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 90099260-c34a-42ab-9df9-f3ed02a9f41d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 87c5e3f1-e57c-4900-8253-d1f5f481ab54
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 73837715-a7a5-4513-a563-9ac998d41e31
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 68a13251-c6f8-4124-944e-c6ae40e7754a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ebe95200-5517-446a-a250-ad11e3bbe215
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d5d86a42-95a0-4167-ab8f-5d65cd273f90
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4f8fd98b-32cd-449c-8a84-65d1bb6666a9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3459ab84-ead7-4394-b5c7-61b8a9d299b6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0a5db18f-11e4-4303-8a77-42eda2875f72
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 56ffc5b1-6a04-44e4-a372-f9a9526e3baa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3d3721ff-61ef-461d-89b3-81ff72f66038
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3c827df9-e35c-4d79-af92-2b0a177a64ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 13a8cf50-9bfa-4df8-a832-7ca5d13439b0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4c04666a-72d9-4173-bbc1-9bf1fdff70bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 576375c7-d1d3-449c-a142-11f1d9adb321
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b09fd8e5-e5aa-4f3e-ada7-de8ead84e7b9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 240a1ece-cc90-43b6-9e95-287ae88995b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 22c3783a-86c8-4eca-8624-85ea9563685e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6648a4e4-414f-4b4c-ab43-a0aade2711bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 127a10c3-e6ba-4a34-8e2f-1422c83baef0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2dd69126-7afc-45ff-8452-0c93d32e1be2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 01a0ba86-2511-4bbb-ba11-51f360ddbff0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fb470728-d435-41a3-99e2-ff8395e220a3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eece24cb-d5ab-4ed9-983a-917c47cf9972
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message da7fc24f-c5fd-452b-997a-730d88d6ab42
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3c4b7fdd-8960-4dff-b77a-8f07d9f5405f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bcf764ee-890d-4162-8920-2725a515a560
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a2d74098-bb7c-4e5e-a47c-78d5b4032ba7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 271ae085-9ef3-4aeb-ad17-678fb6db314c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f13151e7-c20a-4fff-882a-40826024cd5e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 72de21d1-c703-4f3b-8e6a-bf7c97fa7ac0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 72aab326-9f8a-45c0-9fbb-50cbf0a14e69
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3f2d7f65-5885-4695-be9d-96db29b32fc6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2499f96a-5f74-4d9e-b0b2-06631bb908b6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ea7e206f-b1e6-44f9-959b-ae420d5f5c73
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 055eda28-b39d-4250-93a5-49d45d5cb26a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fede01cd-6050-42d7-b7ea-ca35d8a38c35
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c9de65f4-28f1-471e-96ca-edc2b4523cca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4b01cd17-cb82-45cd-b0a3-335193609118
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cdd540b0-4fe0-4490-9070-69cd4eb1bd9c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c0850932-f01b-41f0-889d-ad325cd12144
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 515a08f9-f99d-4570-80d7-a3f8aa02fc92
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 24c5bcfc-81fb-4486-a57c-aebe45aa348e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4844f3f0-a167-4bae-8f6c-1da14a02d27b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 32dddbb6-c249-4437-900d-17b0e4c8f0e1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c031d2b1-5f6e-4614-8639-6e5b649d3a8b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4590c263-a0ba-4af1-a2fd-0ee40401ec9e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 80826855-51c8-4eda-80b5-db4fad571559
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c57b4f0a-0b15-4589-9212-46aec0053dc0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 69d4fa10-1e1c-43ad-bda6-2a4c98fb80cb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d2d8d653-c0fa-4b01-9393-bd0da76a0ac3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 467f0b77-3c14-44cc-aa15-cc0d6704e4e1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1f994caf-a0fc-4cfe-ac48-3e0a4fe0839d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 829082d0-4b5b-4e12-b330-80c5a5ca348f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0a6d4e17-cfbf-4b21-9005-0bebdf74a591
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 278e1068-903e-4204-a3fd-8924113e78ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 10eaed5e-d0cb-4ae5-b183-7c06d6e47f91
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 03a08420-8422-4786-8b2c-96e73261f651
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b648ba4a-c4f0-4b70-99dd-20aa570a9e75
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 72c36f6a-5bda-4bd1-8f58-7af452201630
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f35c1d39-34ed-47b1-bc4e-2400dbbcd77e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eda1dd38-9561-42dc-a56e-ac88891026f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2802bc13-3430-4fb5-a994-be478bf8b248
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5e8ae1c4-0ec1-4375-b174-3a24238bbf96
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 98a1d923-8eb5-43ed-bf72-cfb9417dbae5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a791b696-e97f-40f7-983f-0656ea75e4b0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f3ac32ca-f7e6-4c8f-8a0d-4b09a99b9b8e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 210a642b-af89-4383-a3f0-fad6d89295e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 90d53776-3251-487a-aaa8-6ed2b1899537
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8053d692-d469-46e4-8300-8ddf7c168c59
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 34bd0f87-9391-4d98-86db-4f62453ae52d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 95713a2b-c400-4037-8bf8-4bd5df79e879
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f6a8e1cc-21d9-4d4a-8859-baeb2778ab37
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dc386b9e-fc54-4f5c-a11d-7ef13a01c142
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 266d9930-c3a0-4150-ab66-6117fe193d05
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eff03523-4f1e-4ec5-9796-bda1efe18e4d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b0121139-c87a-4cd1-b8d8-2ddde333f208
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cdf45bdf-4bc7-427b-a5a7-cfdaf97ae0e8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ee5fd2b5-305b-485a-8bc2-cdd3b082eb31
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4dd9da4e-bc4a-419f-b44a-4fa33de61e0b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 692cb73d-88bd-4e68-b173-4471d991a0ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 83a5e46d-dc47-49c0-90d6-5dbfc259d0c6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 24c22f54-8cb9-469c-bced-5d6cc4f307dd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 965a601f-c8f8-4899-bc25-17cca9330cb3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b19c1844-2eb7-4319-9ee2-54e7f9379190
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7275702f-e08e-48a9-8124-5302c01a8ea8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message caed4264-03ed-4250-9ec3-d97ba393a5c6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d5227daa-6306-4a82-82c1-017ebde11ea6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 228850a9-39aa-4ae6-8acc-6d1e584ce7af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9ca751b9-105a-4712-8448-723d7b8ae5b9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7e5614e2-e8ba-497c-9be5-e86dbcb9d0c4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 87e833fd-fc09-44ec-b2fc-0ea7c1a3e531
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 12f6f854-22d9-4007-b893-d2361f0504b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 84fd0a86-95f5-4220-85ff-9ce8759511cd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d58c57b1-31e9-4d59-a831-42147448a201
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 61f7e7b1-272d-463c-bec0-62b195c24c55
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f6e7b079-0562-41bb-9675-b4ac0671cba7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 19a56bff-8d69-4d7f-8448-f751ec0e66ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fedbe8c9-f720-41c7-aabf-16985dcf89ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 57a59461-1bd3-41c8-8f64-d43b25f6cbdb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4d13c81f-81f8-4244-adde-032bc3aa98fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9294be78-074b-4ae0-8422-77c5f70707d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8e44cddd-3e3f-4259-8655-df609086c91a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 468ee92d-3685-41f1-8909-be1f8a258450
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9376c8b8-e2ba-458f-b05c-1747143a4357
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message faafe75e-f12a-4ee6-8345-02f84a604b13
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8687 {grpc_message:"Socket closed", grpc_status:14}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_33
Server: localhost:8687
Algorithm: FEDAVG
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_33
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_33/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_33/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_33/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_33/test_labels.txt

📊 Raw data loaded:
   Train: X=(2282, 24), y=(2282,)
   Test:  X=(571, 24), y=(571,)

⚠️  Limiting training data: 2282 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  562 samples, 5 features
✅ Client client_33 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

============================================================
🔄 Round 3 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0825 (↓), lr=0.001000
   ✓ Epoch   2/100: train=0.0834, val=0.0798 (↓), lr=0.001000
   • Epoch   3/100: train=0.0824, val=0.0800, patience=1/15, lr=0.001000
   • Epoch   4/100: train=0.0811, val=0.0800, patience=2/15, lr=0.001000
   • Epoch   5/100: train=0.0803, val=0.0798, patience=3/15, lr=0.001000
   ✓ Epoch  11/100: train=0.0739, val=0.0750 (↓), lr=0.001000
   • Epoch  21/100: train=0.0643, val=0.0720, patience=6/15, lr=0.001000
   📉 Epoch 26: LR reduced 0.001000 → 0.000500

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0712)

============================================================
📊 Round 3 Summary - Client client_33
   Epochs: 30/100 (early stopped)
   LR: 0.001000 → 0.000500 (1 reductions)
   Train: Loss=0.0674, RMSE=0.2597, R²=0.1831
   Val:   Loss=0.0712, RMSE=0.2668, R²=0.1023
============================================================


============================================================
🔄 Round 4 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000500
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0729 (↓), lr=0.000500
   ✓ Epoch   2/100: train=0.0824, val=0.0715 (↓), lr=0.000500
   • Epoch   3/100: train=0.0817, val=0.0719, patience=1/15, lr=0.000500
   📉 Epoch 4: LR reduced 0.000500 → 0.000250
   • Epoch   4/100: train=0.0815, val=0.0719, patience=2/15, lr=0.000250
   ✓ Epoch   5/100: train=0.0812, val=0.0709 (↓), lr=0.000250
   • Epoch  11/100: train=0.0802, val=0.0708, patience=6/15, lr=0.000250
   📉 Epoch 12: LR reduced 0.000250 → 0.000125
   • Epoch  21/100: train=0.0790, val=0.0702, patience=4/15, lr=0.000125
   • Epoch  31/100: train=0.0778, val=0.0697, patience=3/15, lr=0.000125
   • Epoch  41/100: train=0.0762, val=0.0689, patience=5/15, lr=0.000125
   • Epoch  51/100: train=0.0744, val=0.0679, patience=4/15, lr=0.000125
   • Epoch  61/100: train=0.0726, val=0.0669, patience=3/15, lr=0.000125
   • Epoch  71/100: train=0.0709, val=0.0658, patience=3/15, lr=0.000125
   • Epoch  81/100: train=0.0694, val=0.0650, patience=2/15, lr=0.000125
   • Epoch  91/100: train=0.0683, val=0.0649, patience=12/15, lr=0.000125
   📉 Epoch 93: LR reduced 0.000125 → 0.000063

============================================================
📊 Round 4 Summary - Client client_33
   Epochs: 100/100
   LR: 0.000500 → 0.000063 (3 reductions)
   Train: Loss=0.0673, RMSE=0.2595, R²=0.2011
   Val:   Loss=0.0646, RMSE=0.2543, R²=0.0974
============================================================


📊 Round 4 Test Metrics:
   Loss: 0.0843, RMSE: 0.2903, MAE: 0.2545, R²: 0.0212

📊 Round 4 Test Metrics:
   Loss: 0.0828, RMSE: 0.2877, MAE: 0.2521, R²: 0.0386

📊 Round 4 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2485, R²: 0.0623

📊 Round 4 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2487, R²: 0.0610

============================================================
🔄 Round 9 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   📉 Epoch 1: LR reduced 0.000063 → 0.000031
   ✓ Epoch   1/100: train=0.0766, val=0.0732 (↓), lr=0.000031
   • Epoch   2/100: train=0.0762, val=0.0727, patience=1/15, lr=0.000031
   ✓ Epoch   3/100: train=0.0759, val=0.0724 (↓), lr=0.000031
   • Epoch   4/100: train=0.0757, val=0.0722, patience=1/15, lr=0.000031
   • Epoch   5/100: train=0.0756, val=0.0720, patience=2/15, lr=0.000031
   📉 Epoch 9: LR reduced 0.000031 → 0.000016
   • Epoch  11/100: train=0.0750, val=0.0717, patience=3/15, lr=0.000016
   📉 Epoch 17: LR reduced 0.000016 → 0.000008
   • Epoch  21/100: train=0.0746, val=0.0717, patience=13/15, lr=0.000008

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0718)

============================================================
📊 Round 9 Summary - Client client_33
   Epochs: 23/100 (early stopped)
   LR: 0.000063 → 0.000008 (3 reductions)
   Train: Loss=0.0752, RMSE=0.2742, R²=0.0892
   Val:   Loss=0.0718, RMSE=0.2680, R²=0.0864
============================================================


============================================================
🔄 Round 10 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000008
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0728, val=0.0865 (↓), lr=0.000008
   📉 Epoch 2: LR reduced 0.000008 → 0.000004
   • Epoch   2/100: train=0.0726, val=0.0863, patience=1/15, lr=0.000004
   • Epoch   3/100: train=0.0725, val=0.0862, patience=2/15, lr=0.000004
   • Epoch   4/100: train=0.0725, val=0.0862, patience=3/15, lr=0.000004
   • Epoch   5/100: train=0.0724, val=0.0861, patience=4/15, lr=0.000004
   📉 Epoch 10: LR reduced 0.000004 → 0.000002
   • Epoch  11/100: train=0.0722, val=0.0858, patience=4/15, lr=0.000002
   📉 Epoch 18: LR reduced 0.000002 → 0.000001
   • Epoch  21/100: train=0.0720, val=0.0856, patience=14/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 10 Summary - Client client_33
   Epochs: 22/100 (early stopped)
   LR: 0.000008 → 0.000001 (3 reductions)
   Train: Loss=0.0724, RMSE=0.2690, R²=0.0863
   Val:   Loss=0.0860, RMSE=0.2932, R²=0.0664
============================================================


📊 Round 10 Test Metrics:
   Loss: 0.0805, RMSE: 0.2838, MAE: 0.2482, R²: 0.0647

============================================================
🔄 Round 14 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0766, val=0.0701 (↓), lr=0.000001
   • Epoch   2/100: train=0.0766, val=0.0701, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0766, val=0.0701, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0766, val=0.0701, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0766, val=0.0701, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0765, val=0.0699, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0701)

============================================================
📊 Round 14 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0766, RMSE=0.2768, R²=0.0840
   Val:   Loss=0.0701, RMSE=0.2648, R²=0.0491
============================================================


============================================================
🔄 Round 18 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0740, val=0.0765 (↓), lr=0.000001
   • Epoch   2/100: train=0.0739, val=0.0765, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0739, val=0.0765, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0739, val=0.0765, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0738, val=0.0765, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0737, val=0.0765, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0765)

============================================================
📊 Round 18 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0742, RMSE=0.2723, R²=0.0889
   Val:   Loss=0.0765, RMSE=0.2765, R²=0.0683
============================================================


📊 Round 18 Test Metrics:
   Loss: 0.0795, RMSE: 0.2819, MAE: 0.2460, R²: 0.0770

📊 Round 18 Test Metrics:
   Loss: 0.0791, RMSE: 0.2812, MAE: 0.2453, R²: 0.0814

============================================================
🔄 Round 26 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0740, val=0.0734 (↓), lr=0.000001
   • Epoch   2/100: train=0.0740, val=0.0733, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0740, val=0.0733, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0740, val=0.0733, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0740, val=0.0733, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0739, val=0.0731, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0734)

============================================================
📊 Round 26 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0743, RMSE=0.2726, R²=0.0995
   Val:   Loss=0.0734, RMSE=0.2709, R²=0.0535
============================================================


📊 Round 26 Test Metrics:
   Loss: 0.0791, RMSE: 0.2812, MAE: 0.2452, R²: 0.0815

============================================================
🔄 Round 27 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0751, val=0.0710 (↓), lr=0.000001
   • Epoch   2/100: train=0.0750, val=0.0710, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0750, val=0.0710, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0750, val=0.0710, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0750, val=0.0709, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0749, val=0.0708, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0710)

============================================================
📊 Round 27 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0749, RMSE=0.2736, R²=0.1002
   Val:   Loss=0.0710, RMSE=0.2665, R²=0.0657
============================================================


============================================================
🔄 Round 28 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0729, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0729, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0729, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0729, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0728, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0728, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 28 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0729, RMSE=0.2701, R²=0.0906
   Val:   Loss=0.0788, RMSE=0.2808, R²=0.1031
============================================================


📊 Round 28 Test Metrics:
   Loss: 0.0791, RMSE: 0.2812, MAE: 0.2453, R²: 0.0814

📊 Round 28 Test Metrics:
   Loss: 0.0791, RMSE: 0.2812, MAE: 0.2452, R²: 0.0815

📊 Round 28 Test Metrics:
   Loss: 0.0791, RMSE: 0.2812, MAE: 0.2452, R²: 0.0815

============================================================
🔄 Round 33 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0740, val=0.0750 (↓), lr=0.000001
   • Epoch   2/100: train=0.0740, val=0.0750, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0739, val=0.0749, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0739, val=0.0749, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0739, val=0.0749, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0738, val=0.0748, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0750)

============================================================
📊 Round 33 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0739, RMSE=0.2718, R²=0.0814
   Val:   Loss=0.0750, RMSE=0.2738, R²=0.1449
============================================================


============================================================
🔄 Round 34 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0728, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0728, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0727, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0727, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0727, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0726, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 34 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0728, RMSE=0.2699, R²=0.0911
   Val:   Loss=0.0792, RMSE=0.2815, R²=0.1092
============================================================


============================================================
🔄 Round 36 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0754, val=0.0688 (↓), lr=0.000001
   • Epoch   2/100: train=0.0754, val=0.0688, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0754, val=0.0688, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0753, val=0.0688, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0753, val=0.0688, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0751, val=0.0689, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0688)

============================================================
📊 Round 36 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0754, RMSE=0.2746, R²=0.0906
   Val:   Loss=0.0688, RMSE=0.2623, R²=0.0843
============================================================


============================================================
🔄 Round 39 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0744, val=0.0724 (↓), lr=0.000001
   • Epoch   2/100: train=0.0744, val=0.0724, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0743, val=0.0724, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0743, val=0.0723, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0743, val=0.0723, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0741, val=0.0722, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0724)

============================================================
📊 Round 39 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0745, RMSE=0.2730, R²=0.0877
   Val:   Loss=0.0724, RMSE=0.2690, R²=0.1221
============================================================


============================================================
🔄 Round 40 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0750, val=0.0717 (↓), lr=0.000001
   • Epoch   2/100: train=0.0749, val=0.0716, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0749, val=0.0716, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0749, val=0.0716, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0748, val=0.0716, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0747, val=0.0715, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0717)

============================================================
📊 Round 40 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0747, RMSE=0.2733, R²=0.0982
   Val:   Loss=0.0717, RMSE=0.2677, R²=0.0817
============================================================


📊 Round 40 Test Metrics:
   Loss: 0.0791, RMSE: 0.2812, MAE: 0.2452, R²: 0.0817

📊 Round 40 Test Metrics:
   Loss: 0.0791, RMSE: 0.2812, MAE: 0.2452, R²: 0.0817

============================================================
🔄 Round 45 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0731, val=0.0779 (↓), lr=0.000001
   • Epoch   2/100: train=0.0731, val=0.0779, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0731, val=0.0779, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0730, val=0.0779, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0730, val=0.0778, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0729, val=0.0777, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0779)

============================================================
📊 Round 45 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0731, RMSE=0.2704, R²=0.1026
   Val:   Loss=0.0779, RMSE=0.2792, R²=0.0592
============================================================


📊 Round 45 Test Metrics:
   Loss: 0.0791, RMSE: 0.2812, MAE: 0.2452, R²: 0.0818

============================================================
🔄 Round 47 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0745, val=0.0721 (↓), lr=0.000001
   • Epoch   2/100: train=0.0745, val=0.0721, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0745, val=0.0721, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0745, val=0.0720, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0744, val=0.0720, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0743, val=0.0719, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0721)

============================================================
📊 Round 47 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0746, RMSE=0.2731, R²=0.0966
   Val:   Loss=0.0721, RMSE=0.2685, R²=0.0879
============================================================


📊 Round 47 Test Metrics:
   Loss: 0.0791, RMSE: 0.2812, MAE: 0.2452, R²: 0.0818

============================================================
🔄 Round 48 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0730, val=0.0779 (↓), lr=0.000001
   • Epoch   2/100: train=0.0729, val=0.0779, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0729, val=0.0779, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0729, val=0.0779, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0729, val=0.0778, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0728, val=0.0777, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0779)

============================================================
📊 Round 48 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0731, RMSE=0.2704, R²=0.0837
   Val:   Loss=0.0779, RMSE=0.2792, R²=0.1283
============================================================


📊 Round 48 Test Metrics:
   Loss: 0.0790, RMSE: 0.2812, MAE: 0.2452, R²: 0.0818

============================================================
🔄 Round 50 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0744, val=0.0726 (↓), lr=0.000001
   • Epoch   2/100: train=0.0744, val=0.0726, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0744, val=0.0726, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0743, val=0.0726, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0743, val=0.0726, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0742, val=0.0725, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0726)

============================================================
📊 Round 50 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0745, RMSE=0.2729, R²=0.0828
   Val:   Loss=0.0726, RMSE=0.2694, R²=0.1413
============================================================


============================================================
🔄 Round 52 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0737, val=0.0750 (↓), lr=0.000001
   • Epoch   2/100: train=0.0737, val=0.0749, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0737, val=0.0749, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0736, val=0.0749, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0736, val=0.0749, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0735, val=0.0748, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0750)

============================================================
📊 Round 52 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0739, RMSE=0.2718, R²=0.1004
   Val:   Loss=0.0750, RMSE=0.2738, R²=0.0725
============================================================


📊 Round 52 Test Metrics:
   Loss: 0.0790, RMSE: 0.2811, MAE: 0.2452, R²: 0.0819

============================================================
🔄 Round 53 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0760, val=0.0653 (↓), lr=0.000001
   • Epoch   2/100: train=0.0760, val=0.0653, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0760, val=0.0653, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0759, val=0.0653, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0759, val=0.0653, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0757, val=0.0653, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0653)

============================================================
📊 Round 53 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0763, RMSE=0.2762, R²=0.0897
   Val:   Loss=0.0653, RMSE=0.2555, R²=0.1127
============================================================


============================================================
🔄 Round 55 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0743, val=0.0734 (↓), lr=0.000001
   • Epoch   2/100: train=0.0742, val=0.0734, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0742, val=0.0734, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0742, val=0.0734, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0742, val=0.0733, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0741, val=0.0732, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0734)

============================================================
📊 Round 55 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0743, RMSE=0.2725, R²=0.1023
   Val:   Loss=0.0734, RMSE=0.2710, R²=0.0628
============================================================


============================================================
🔄 Round 56 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0732, val=0.0777 (↓), lr=0.000001
   • Epoch   2/100: train=0.0732, val=0.0777, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0731, val=0.0777, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0731, val=0.0778, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0731, val=0.0778, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0728, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 56 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0732, RMSE=0.2705, R²=0.0765
   Val:   Loss=0.0777, RMSE=0.2787, R²=0.1220
============================================================


📊 Round 56 Test Metrics:
   Loss: 0.0790, RMSE: 0.2811, MAE: 0.2452, R²: 0.0819

📊 Round 56 Test Metrics:
   Loss: 0.0790, RMSE: 0.2811, MAE: 0.2452, R²: 0.0819

============================================================
🔄 Round 60 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0735, val=0.0762 (↓), lr=0.000001
   • Epoch   2/100: train=0.0735, val=0.0762, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0734, val=0.0762, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0734, val=0.0762, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0734, val=0.0762, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0732, val=0.0761, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0762)

============================================================
📊 Round 60 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0736, RMSE=0.2712, R²=0.1002
   Val:   Loss=0.0762, RMSE=0.2761, R²=0.0692
============================================================


📊 Round 60 Test Metrics:
   Loss: 0.0790, RMSE: 0.2811, MAE: 0.2452, R²: 0.0820

============================================================
🔄 Round 62 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0757, val=0.0685 (↓), lr=0.000001
   • Epoch   2/100: train=0.0757, val=0.0685, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0756, val=0.0685, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0756, val=0.0685, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0756, val=0.0685, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0754, val=0.0685, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0685)

============================================================
📊 Round 62 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0755, RMSE=0.2747, R²=0.0803
   Val:   Loss=0.0685, RMSE=0.2618, R²=0.1543
============================================================


📊 Round 62 Test Metrics:
   Loss: 0.0790, RMSE: 0.2811, MAE: 0.2451, R²: 0.0821

📊 Round 62 Test Metrics:
   Loss: 0.0790, RMSE: 0.2811, MAE: 0.2451, R²: 0.0821

📊 Round 62 Test Metrics:
   Loss: 0.0790, RMSE: 0.2811, MAE: 0.2451, R²: 0.0821

============================================================
🔄 Round 67 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0715, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0715, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0715, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0715, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0715, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0714, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 67 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0716, RMSE=0.2677, R²=0.1035
   Val:   Loss=0.0838, RMSE=0.2894, R²=0.0568
============================================================


============================================================
🔄 Round 68 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0740, val=0.0747 (↓), lr=0.000001
   • Epoch   2/100: train=0.0739, val=0.0747, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0739, val=0.0746, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0739, val=0.0746, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0739, val=0.0746, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0738, val=0.0744, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0747)

============================================================
📊 Round 68 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0739, RMSE=0.2719, R²=0.1086
   Val:   Loss=0.0747, RMSE=0.2733, R²=0.0372
============================================================


📊 Round 68 Test Metrics:
   Loss: 0.0790, RMSE: 0.2811, MAE: 0.2451, R²: 0.0822

============================================================
🔄 Round 70 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0763, val=0.0651 (↓), lr=0.000001
   • Epoch   2/100: train=0.0763, val=0.0651, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0762, val=0.0650, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0762, val=0.0650, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0762, val=0.0650, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0761, val=0.0649, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0651)

============================================================
📊 Round 70 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0763, RMSE=0.2762, R²=0.0918
   Val:   Loss=0.0651, RMSE=0.2551, R²=0.0845
============================================================


============================================================
🔄 Round 71 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0723, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0723, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0723, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0723, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0723, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0722, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 71 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0725, RMSE=0.2692, R²=0.0867
   Val:   Loss=0.0804, RMSE=0.2836, R²=0.1255
============================================================


📊 Round 71 Test Metrics:
   Loss: 0.0790, RMSE: 0.2811, MAE: 0.2451, R²: 0.0823

📊 Round 71 Test Metrics:
   Loss: 0.0790, RMSE: 0.2811, MAE: 0.2451, R²: 0.0823

============================================================
🔄 Round 75 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0737, val=0.0753 (↓), lr=0.000001
   • Epoch   2/100: train=0.0737, val=0.0753, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0736, val=0.0753, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0736, val=0.0753, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0736, val=0.0753, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0734, val=0.0752, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0753)

============================================================
📊 Round 75 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0737, RMSE=0.2715, R²=0.0797
   Val:   Loss=0.0753, RMSE=0.2745, R²=0.1529
============================================================


============================================================
🔄 Round 77 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0738, val=0.0754 (↓), lr=0.000001
   • Epoch   2/100: train=0.0737, val=0.0754, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0737, val=0.0754, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0737, val=0.0754, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0737, val=0.0753, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0736, val=0.0752, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0754)

============================================================
📊 Round 77 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0737, RMSE=0.2715, R²=0.0970
   Val:   Loss=0.0754, RMSE=0.2747, R²=0.0860
============================================================


============================================================
🔄 Round 78 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0739, val=0.0740 (↓), lr=0.000001
   • Epoch   2/100: train=0.0739, val=0.0740, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0739, val=0.0740, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0739, val=0.0740, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0738, val=0.0739, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0737, val=0.0738, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0740)

============================================================
📊 Round 78 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0740, RMSE=0.2721, R²=0.0995
   Val:   Loss=0.0740, RMSE=0.2721, R²=0.0809
============================================================


============================================================
🔄 Round 79 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0732, val=0.0776 (↓), lr=0.000001
   • Epoch   2/100: train=0.0732, val=0.0776, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0732, val=0.0776, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0732, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0731, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0730, val=0.0774, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 79 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0731, RMSE=0.2705, R²=0.0966
   Val:   Loss=0.0776, RMSE=0.2785, R²=0.0905
============================================================


📊 Round 79 Test Metrics:
   Loss: 0.0790, RMSE: 0.2811, MAE: 0.2451, R²: 0.0825

============================================================
🔄 Round 83 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0735, val=0.0767 (↓), lr=0.000001
   • Epoch   2/100: train=0.0735, val=0.0767, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0735, val=0.0767, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0735, val=0.0767, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0734, val=0.0766, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0733, val=0.0765, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0767)

============================================================
📊 Round 83 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0734, RMSE=0.2709, R²=0.1015
   Val:   Loss=0.0767, RMSE=0.2770, R²=0.0725
============================================================


============================================================
🔄 Round 85 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0719, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0719, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0718, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0718, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0718, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0717, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 85 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0721, RMSE=0.2684, R²=0.1008
   Val:   Loss=0.0820, RMSE=0.2863, R²=0.0717
============================================================


📊 Round 85 Test Metrics:
   Loss: 0.0790, RMSE: 0.2810, MAE: 0.2450, R²: 0.0826

============================================================
🔄 Round 86 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0733, val=0.0779 (↓), lr=0.000001
   • Epoch   2/100: train=0.0733, val=0.0779, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0733, val=0.0779, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0733, val=0.0779, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0732, val=0.0779, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0731, val=0.0778, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0779)

============================================================
📊 Round 86 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0731, RMSE=0.2703, R²=0.0982
   Val:   Loss=0.0779, RMSE=0.2792, R²=0.0869
============================================================


📊 Round 86 Test Metrics:
   Loss: 0.0790, RMSE: 0.2810, MAE: 0.2450, R²: 0.0826

📊 Round 86 Test Metrics:
   Loss: 0.0790, RMSE: 0.2810, MAE: 0.2450, R²: 0.0826

============================================================
🔄 Round 89 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0744, val=0.0724 (↓), lr=0.000001
   • Epoch   2/100: train=0.0744, val=0.0724, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0744, val=0.0724, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0743, val=0.0723, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0743, val=0.0723, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0742, val=0.0722, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0724)

============================================================
📊 Round 89 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0744, RMSE=0.2728, R²=0.0963
   Val:   Loss=0.0724, RMSE=0.2691, R²=0.0853
============================================================


============================================================
🔄 Round 90 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0757, val=0.0671 (↓), lr=0.000001
   • Epoch   2/100: train=0.0757, val=0.0671, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0757, val=0.0671, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0756, val=0.0671, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0756, val=0.0670, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0754, val=0.0669, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0671)

============================================================
📊 Round 90 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0758, RMSE=0.2752, R²=0.1071
   Val:   Loss=0.0671, RMSE=0.2591, R²=0.0430
============================================================


📊 Round 90 Test Metrics:
   Loss: 0.0790, RMSE: 0.2810, MAE: 0.2450, R²: 0.0827

📊 Round 90 Test Metrics:
   Loss: 0.0790, RMSE: 0.2810, MAE: 0.2450, R²: 0.0827

📊 Round 90 Test Metrics:
   Loss: 0.0790, RMSE: 0.2810, MAE: 0.2450, R²: 0.0827

📊 Round 90 Test Metrics:
   Loss: 0.0790, RMSE: 0.2810, MAE: 0.2450, R²: 0.0828

📊 Round 90 Test Metrics:
   Loss: 0.0790, RMSE: 0.2810, MAE: 0.2450, R²: 0.0828

📊 Round 90 Test Metrics:
   Loss: 0.0790, RMSE: 0.2810, MAE: 0.2450, R²: 0.0829

📊 Round 90 Test Metrics:
   Loss: 0.0790, RMSE: 0.2810, MAE: 0.2450, R²: 0.0829

============================================================
🔄 Round 103 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0752, val=0.0695 (↓), lr=0.000001
   • Epoch   2/100: train=0.0751, val=0.0695, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0751, val=0.0694, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0751, val=0.0694, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0751, val=0.0694, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0750, val=0.0692, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0695)

============================================================
📊 Round 103 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0751, RMSE=0.2741, R²=0.0866
   Val:   Loss=0.0695, RMSE=0.2636, R²=0.1246
============================================================


============================================================
🔄 Round 104 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0750, val=0.0692 (↓), lr=0.000001
   • Epoch   2/100: train=0.0750, val=0.0692, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0750, val=0.0692, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0749, val=0.0692, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0749, val=0.0692, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0747, val=0.0691, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0692)

============================================================
📊 Round 104 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0752, RMSE=0.2742, R²=0.0958
   Val:   Loss=0.0692, RMSE=0.2631, R²=0.0983
============================================================


📊 Round 104 Test Metrics:
   Loss: 0.0789, RMSE: 0.2810, MAE: 0.2449, R²: 0.0831

📊 Round 104 Test Metrics:
   Loss: 0.0789, RMSE: 0.2810, MAE: 0.2449, R²: 0.0831

============================================================
🔄 Round 111 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0766, val=0.0632 (↓), lr=0.000001
   • Epoch   2/100: train=0.0766, val=0.0632, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0766, val=0.0632, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0765, val=0.0632, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0765, val=0.0632, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0763, val=0.0632, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0632)

============================================================
📊 Round 111 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0767, RMSE=0.2769, R²=0.0940
   Val:   Loss=0.0632, RMSE=0.2514, R²=0.0896
============================================================


📊 Round 111 Test Metrics:
   Loss: 0.0789, RMSE: 0.2810, MAE: 0.2449, R²: 0.0831

============================================================
🔄 Round 113 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0742, val=0.0731 (↓), lr=0.000001
   • Epoch   2/100: train=0.0742, val=0.0731, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0741, val=0.0731, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0741, val=0.0731, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0741, val=0.0731, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0739, val=0.0732, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0731)

============================================================
📊 Round 113 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0742, RMSE=0.2724, R²=0.0918
   Val:   Loss=0.0731, RMSE=0.2704, R²=0.0950
============================================================


📊 Round 113 Test Metrics:
   Loss: 0.0789, RMSE: 0.2810, MAE: 0.2449, R²: 0.0831

📊 Round 113 Test Metrics:
   Loss: 0.0789, RMSE: 0.2810, MAE: 0.2449, R²: 0.0832

============================================================
🔄 Round 115 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0718, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0718, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0718, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0718, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0717, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0716, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 115 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0718, RMSE=0.2679, R²=0.1034
   Val:   Loss=0.0828, RMSE=0.2877, R²=0.0726
============================================================


============================================================
🔄 Round 116 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0751, val=0.0696 (↓), lr=0.000001
   • Epoch   2/100: train=0.0751, val=0.0696, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0751, val=0.0695, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0750, val=0.0695, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0750, val=0.0695, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0749, val=0.0694, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0696)

============================================================
📊 Round 116 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0751, RMSE=0.2740, R²=0.0946
   Val:   Loss=0.0696, RMSE=0.2638, R²=0.1046
============================================================


============================================================
🔄 Round 117 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0753, val=0.0687 (↓), lr=0.000001
   • Epoch   2/100: train=0.0753, val=0.0686, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0753, val=0.0686, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0752, val=0.0686, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0752, val=0.0686, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0751, val=0.0684, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0687)

============================================================
📊 Round 117 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0753, RMSE=0.2744, R²=0.0928
   Val:   Loss=0.0687, RMSE=0.2620, R²=0.1132
============================================================


📊 Round 117 Test Metrics:
   Loss: 0.0789, RMSE: 0.2809, MAE: 0.2449, R²: 0.0833

============================================================
🔄 Round 120 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0735, val=0.0761 (↓), lr=0.000001
   • Epoch   2/100: train=0.0735, val=0.0761, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0735, val=0.0761, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0734, val=0.0761, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0734, val=0.0761, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0732, val=0.0761, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0761)

============================================================
📊 Round 120 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0734, RMSE=0.2710, R²=0.0964
   Val:   Loss=0.0761, RMSE=0.2759, R²=0.0888
============================================================


============================================================
🔄 Round 121 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0718, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0718, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0717, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0717, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0717, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0716, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 121 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0717, RMSE=0.2678, R²=0.1027
   Val:   Loss=0.0829, RMSE=0.2879, R²=0.0750
============================================================


📊 Round 121 Test Metrics:
   Loss: 0.0789, RMSE: 0.2809, MAE: 0.2449, R²: 0.0834

📊 Round 121 Test Metrics:
   Loss: 0.0789, RMSE: 0.2809, MAE: 0.2449, R²: 0.0834

📊 Round 121 Test Metrics:
   Loss: 0.0789, RMSE: 0.2809, MAE: 0.2449, R²: 0.0834

============================================================
🔄 Round 126 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0757, val=0.0670 (↓), lr=0.000001
   • Epoch   2/100: train=0.0757, val=0.0670, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0757, val=0.0670, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0756, val=0.0670, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0756, val=0.0670, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0755, val=0.0669, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0670)

============================================================
📊 Round 126 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0757, RMSE=0.2751, R²=0.1005
   Val:   Loss=0.0670, RMSE=0.2589, R²=0.0802
============================================================


============================================================
🔄 Round 127 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0749, val=0.0702 (↓), lr=0.000001
   • Epoch   2/100: train=0.0749, val=0.0702, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0749, val=0.0702, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0748, val=0.0702, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0748, val=0.0701, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0747, val=0.0700, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0702)

============================================================
📊 Round 127 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0749, RMSE=0.2736, R²=0.0961
   Val:   Loss=0.0702, RMSE=0.2650, R²=0.1010
============================================================


============================================================
🔄 Round 128 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0733, val=0.0776 (↓), lr=0.000001
   • Epoch   2/100: train=0.0732, val=0.0776, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0732, val=0.0776, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0732, val=0.0776, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0731, val=0.0776, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0729, val=0.0777, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 128 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0731, RMSE=0.2703, R²=0.0897
   Val:   Loss=0.0776, RMSE=0.2785, R²=0.1009
============================================================


📊 Round 128 Test Metrics:
   Loss: 0.0789, RMSE: 0.2809, MAE: 0.2449, R²: 0.0834

============================================================
🔄 Round 129 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0757, val=0.0665 (↓), lr=0.000001
   • Epoch   2/100: train=0.0757, val=0.0665, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0756, val=0.0664, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0756, val=0.0664, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0756, val=0.0664, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0755, val=0.0663, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0665)

============================================================
📊 Round 129 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0758, RMSE=0.2754, R²=0.1018
   Val:   Loss=0.0665, RMSE=0.2578, R²=0.0718
============================================================


============================================================
🔄 Round 130 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0746, val=0.0710 (↓), lr=0.000001
   • Epoch   2/100: train=0.0746, val=0.0710, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0746, val=0.0710, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0746, val=0.0710, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0746, val=0.0709, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0745, val=0.0708, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0710)

============================================================
📊 Round 130 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0747, RMSE=0.2733, R²=0.1017
   Val:   Loss=0.0710, RMSE=0.2665, R²=0.0590
============================================================


📊 Round 130 Test Metrics:
   Loss: 0.0789, RMSE: 0.2809, MAE: 0.2449, R²: 0.0834

============================================================
🔄 Round 131 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0743, val=0.0724 (↓), lr=0.000001
   • Epoch   2/100: train=0.0743, val=0.0724, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0743, val=0.0724, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0742, val=0.0724, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0742, val=0.0724, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0740, val=0.0725, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0724)

============================================================
📊 Round 131 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0744, RMSE=0.2727, R²=0.0984
   Val:   Loss=0.0724, RMSE=0.2691, R²=0.0674
============================================================


📊 Round 131 Test Metrics:
   Loss: 0.0789, RMSE: 0.2809, MAE: 0.2449, R²: 0.0835

============================================================
🔄 Round 134 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0734, val=0.0763 (↓), lr=0.000001
   • Epoch   2/100: train=0.0733, val=0.0763, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0733, val=0.0762, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0733, val=0.0762, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0733, val=0.0762, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0732, val=0.0760, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0763)

============================================================
📊 Round 134 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0734, RMSE=0.2709, R²=0.0920
   Val:   Loss=0.0763, RMSE=0.2762, R²=0.1057
============================================================


📊 Round 134 Test Metrics:
   Loss: 0.0789, RMSE: 0.2809, MAE: 0.2449, R²: 0.0835

📊 Round 134 Test Metrics:
   Loss: 0.0789, RMSE: 0.2809, MAE: 0.2449, R²: 0.0835

📊 Round 134 Test Metrics:
   Loss: 0.0789, RMSE: 0.2809, MAE: 0.2448, R²: 0.0836

📊 Round 134 Test Metrics:
   Loss: 0.0789, RMSE: 0.2809, MAE: 0.2448, R²: 0.0836

============================================================
🔄 Round 143 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0761, val=0.0647 (↓), lr=0.000001
   • Epoch   2/100: train=0.0761, val=0.0647, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0761, val=0.0647, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0760, val=0.0647, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0760, val=0.0647, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0758, val=0.0646, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0647)

============================================================
📊 Round 143 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0763, RMSE=0.2762, R²=0.0848
   Val:   Loss=0.0647, RMSE=0.2544, R²=0.1445
============================================================


📊 Round 143 Test Metrics:
   Loss: 0.0789, RMSE: 0.2809, MAE: 0.2448, R²: 0.0836

📊 Round 143 Test Metrics:
   Loss: 0.0789, RMSE: 0.2809, MAE: 0.2448, R²: 0.0836

============================================================
🔄 Round 145 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0751, val=0.0687 (↓), lr=0.000001
   • Epoch   2/100: train=0.0750, val=0.0687, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0750, val=0.0687, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0750, val=0.0686, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0750, val=0.0686, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0748, val=0.0685, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0687)

============================================================
📊 Round 145 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0753, RMSE=0.2743, R²=0.0938
   Val:   Loss=0.0687, RMSE=0.2621, R²=0.1100
============================================================


📊 Round 145 Test Metrics:
   Loss: 0.0789, RMSE: 0.2809, MAE: 0.2448, R²: 0.0836

============================================================
🔄 Round 147 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0733, val=0.0764 (↓), lr=0.000001
   • Epoch   2/100: train=0.0733, val=0.0764, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0732, val=0.0763, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0732, val=0.0763, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0732, val=0.0763, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0730, val=0.0763, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0764)

============================================================
📊 Round 147 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0733, RMSE=0.2708, R²=0.0909
   Val:   Loss=0.0764, RMSE=0.2763, R²=0.1104
============================================================


📊 Round 147 Test Metrics:
   Loss: 0.0789, RMSE: 0.2809, MAE: 0.2448, R²: 0.0837

📊 Round 147 Test Metrics:
   Loss: 0.0789, RMSE: 0.2809, MAE: 0.2448, R²: 0.0837

📊 Round 147 Test Metrics:
   Loss: 0.0789, RMSE: 0.2809, MAE: 0.2448, R²: 0.0837

============================================================
🔄 Round 150 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0740, val=0.0744 (↓), lr=0.000001
   • Epoch   2/100: train=0.0740, val=0.0744, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0739, val=0.0743, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0739, val=0.0743, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0739, val=0.0743, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0738, val=0.0741, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0744)

============================================================
📊 Round 150 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0738, RMSE=0.2717, R²=0.0994
   Val:   Loss=0.0744, RMSE=0.2728, R²=0.0600
============================================================


📊 Round 150 Test Metrics:
   Loss: 0.0789, RMSE: 0.2809, MAE: 0.2448, R²: 0.0837

📊 Round 150 Test Metrics:
   Loss: 0.0789, RMSE: 0.2809, MAE: 0.2448, R²: 0.0837

============================================================
🔄 Round 154 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0711, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0710, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0710, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0710, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0710, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0708, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 154 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0713, RMSE=0.2671, R²=0.0894
   Val:   Loss=0.0844, RMSE=0.2905, R²=0.1227
============================================================


📊 Round 154 Test Metrics:
   Loss: 0.0789, RMSE: 0.2809, MAE: 0.2448, R²: 0.0838

📊 Round 154 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2448, R²: 0.0838

============================================================
🔄 Round 156 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0726, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0725, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0725, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0725, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0725, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0724, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 156 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0727, RMSE=0.2696, R²=0.0974
   Val:   Loss=0.0789, RMSE=0.2810, R²=0.0926
============================================================


📊 Round 156 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2448, R²: 0.0839

📊 Round 156 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2448, R²: 0.0839

📊 Round 156 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2448, R²: 0.0839

============================================================
🔄 Round 165 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0742, val=0.0734 (↓), lr=0.000001
   • Epoch   2/100: train=0.0742, val=0.0734, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0741, val=0.0734, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0741, val=0.0734, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0741, val=0.0733, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0739, val=0.0733, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0734)

============================================================
📊 Round 165 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0741, RMSE=0.2722, R²=0.0961
   Val:   Loss=0.0734, RMSE=0.2709, R²=0.1017
============================================================


📊 Round 165 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2448, R²: 0.0839

📊 Round 165 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2448, R²: 0.0840

============================================================
🔄 Round 171 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0743, val=0.0719 (↓), lr=0.000001
   • Epoch   2/100: train=0.0743, val=0.0719, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0743, val=0.0719, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0743, val=0.0719, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0742, val=0.0719, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0741, val=0.0717, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0719)

============================================================
📊 Round 171 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0744, RMSE=0.2728, R²=0.1008
   Val:   Loss=0.0719, RMSE=0.2682, R²=0.0827
============================================================


📊 Round 171 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2448, R²: 0.0841

📊 Round 171 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2447, R²: 0.0841

📊 Round 171 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2447, R²: 0.0841

============================================================
🔄 Round 181 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0744, val=0.0715 (↓), lr=0.000001
   • Epoch   2/100: train=0.0744, val=0.0715, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0744, val=0.0715, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0743, val=0.0714, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0743, val=0.0714, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0742, val=0.0713, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0715)

============================================================
📊 Round 181 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0745, RMSE=0.2730, R²=0.0824
   Val:   Loss=0.0715, RMSE=0.2674, R²=0.1555
============================================================


📊 Round 181 Test Metrics:
   Loss: 0.0788, RMSE: 0.2808, MAE: 0.2447, R²: 0.0842

============================================================
🔄 Round 183 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0733, val=0.0757 (↓), lr=0.000001
   • Epoch   2/100: train=0.0733, val=0.0756, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0733, val=0.0756, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0733, val=0.0756, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0732, val=0.0756, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0731, val=0.0754, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0757)

============================================================
📊 Round 183 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0735, RMSE=0.2711, R²=0.0948
   Val:   Loss=0.0757, RMSE=0.2751, R²=0.1081
============================================================


============================================================
🔄 Round 185 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0732, val=0.0771 (↓), lr=0.000001
   • Epoch   2/100: train=0.0732, val=0.0771, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0732, val=0.0771, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0732, val=0.0771, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0731, val=0.0770, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0730, val=0.0769, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0771)

============================================================
📊 Round 185 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0731, RMSE=0.2704, R²=0.1066
   Val:   Loss=0.0771, RMSE=0.2777, R²=0.0603
============================================================


📊 Round 185 Test Metrics:
   Loss: 0.0788, RMSE: 0.2808, MAE: 0.2447, R²: 0.0842

📊 Round 185 Test Metrics:
   Loss: 0.0788, RMSE: 0.2808, MAE: 0.2447, R²: 0.0842

📊 Round 185 Test Metrics:
   Loss: 0.0788, RMSE: 0.2808, MAE: 0.2447, R²: 0.0842

============================================================
🔄 Round 188 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0718, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0718, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0718, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0717, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0717, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0715, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 188 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0717, RMSE=0.2677, R²=0.0941
   Val:   Loss=0.0829, RMSE=0.2880, R²=0.1027
============================================================


============================================================
🔄 Round 190 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0750, val=0.0704 (↓), lr=0.000001
   • Epoch   2/100: train=0.0750, val=0.0704, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0750, val=0.0704, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0749, val=0.0703, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0749, val=0.0703, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0748, val=0.0702, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0704)

============================================================
📊 Round 190 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0748, RMSE=0.2735, R²=0.1039
   Val:   Loss=0.0704, RMSE=0.2654, R²=0.0678
============================================================


📊 Round 190 Test Metrics:
   Loss: 0.0788, RMSE: 0.2808, MAE: 0.2447, R²: 0.0843

📊 Round 190 Test Metrics:
   Loss: 0.0788, RMSE: 0.2808, MAE: 0.2447, R²: 0.0843

============================================================
🔄 Round 194 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0743, val=0.0726 (↓), lr=0.000001
   • Epoch   2/100: train=0.0743, val=0.0726, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0742, val=0.0726, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0742, val=0.0725, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0742, val=0.0725, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0741, val=0.0724, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0726)

============================================================
📊 Round 194 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0742, RMSE=0.2725, R²=0.0982
   Val:   Loss=0.0726, RMSE=0.2695, R²=0.0945
============================================================


============================================================
🔄 Round 196 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0752, val=0.0688 (↓), lr=0.000001
   • Epoch   2/100: train=0.0752, val=0.0688, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0752, val=0.0688, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0752, val=0.0687, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0751, val=0.0687, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0750, val=0.0686, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0688)

============================================================
📊 Round 196 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0752, RMSE=0.2742, R²=0.0873
   Val:   Loss=0.0688, RMSE=0.2623, R²=0.1393
============================================================


📊 Round 196 Test Metrics:
   Loss: 0.0788, RMSE: 0.2808, MAE: 0.2447, R²: 0.0843

📊 Round 196 Test Metrics:
   Loss: 0.0788, RMSE: 0.2808, MAE: 0.2447, R²: 0.0844

============================================================
🔄 Round 198 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0755, val=0.0676 (↓), lr=0.000001
   • Epoch   2/100: train=0.0755, val=0.0676, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0755, val=0.0675, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0755, val=0.0675, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0754, val=0.0675, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0753, val=0.0674, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0676)

============================================================
📊 Round 198 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0755, RMSE=0.2747, R²=0.0993
   Val:   Loss=0.0676, RMSE=0.2600, R²=0.0754
============================================================


📊 Round 198 Test Metrics:
   Loss: 0.0788, RMSE: 0.2808, MAE: 0.2447, R²: 0.0844

📊 Round 198 Test Metrics:
   Loss: 0.0788, RMSE: 0.2808, MAE: 0.2447, R²: 0.0844

============================================================
🔄 Round 201 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0762, val=0.0646 (↓), lr=0.000001
   • Epoch   2/100: train=0.0762, val=0.0646, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0762, val=0.0646, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0761, val=0.0646, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0761, val=0.0646, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0759, val=0.0647, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0646)

============================================================
📊 Round 201 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0762, RMSE=0.2761, R²=0.0901
   Val:   Loss=0.0646, RMSE=0.2542, R²=0.1034
============================================================


============================================================
🔄 Round 203 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0738, val=0.0741 (↓), lr=0.000001
   • Epoch   2/100: train=0.0737, val=0.0740, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0737, val=0.0740, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0737, val=0.0740, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0737, val=0.0740, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0736, val=0.0738, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0741)

============================================================
📊 Round 203 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0739, RMSE=0.2718, R²=0.1035
   Val:   Loss=0.0741, RMSE=0.2722, R²=0.0728
============================================================


============================================================
🔄 Round 206 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0726, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0726, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0725, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0725, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0725, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0723, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 206 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0726, RMSE=0.2695, R²=0.0932
   Val:   Loss=0.0791, RMSE=0.2812, R²=0.1022
============================================================


============================================================
🔄 Round 208 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0744, val=0.0717 (↓), lr=0.000001
   • Epoch   2/100: train=0.0744, val=0.0717, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0744, val=0.0717, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0743, val=0.0718, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0743, val=0.0718, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0740, val=0.0719, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0717)

============================================================
📊 Round 208 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0744, RMSE=0.2728, R²=0.0965
   Val:   Loss=0.0717, RMSE=0.2678, R²=0.0677
============================================================


============================================================
🔄 Round 209 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0729, val=0.0768 (↓), lr=0.000001
   • Epoch   2/100: train=0.0729, val=0.0768, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0729, val=0.0768, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0728, val=0.0768, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0728, val=0.0767, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0727, val=0.0766, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0768)

============================================================
📊 Round 209 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0732, RMSE=0.2705, R²=0.1001
   Val:   Loss=0.0768, RMSE=0.2772, R²=0.0841
============================================================


📊 Round 209 Test Metrics:
   Loss: 0.0788, RMSE: 0.2807, MAE: 0.2447, R²: 0.0846

📊 Round 209 Test Metrics:
   Loss: 0.0788, RMSE: 0.2807, MAE: 0.2447, R²: 0.0846

📊 Round 209 Test Metrics:
   Loss: 0.0788, RMSE: 0.2807, MAE: 0.2447, R²: 0.0846

📊 Round 209 Test Metrics:
   Loss: 0.0788, RMSE: 0.2807, MAE: 0.2447, R²: 0.0846

📊 Round 209 Test Metrics:
   Loss: 0.0788, RMSE: 0.2807, MAE: 0.2447, R²: 0.0846

📊 Round 209 Test Metrics:
   Loss: 0.0788, RMSE: 0.2807, MAE: 0.2447, R²: 0.0846

============================================================
🔄 Round 217 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0735, val=0.0757 (↓), lr=0.000001
   • Epoch   2/100: train=0.0735, val=0.0757, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0734, val=0.0757, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0734, val=0.0757, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0734, val=0.0756, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0733, val=0.0755, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0757)

============================================================
📊 Round 217 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0734, RMSE=0.2710, R²=0.1072
   Val:   Loss=0.0757, RMSE=0.2752, R²=0.0585
============================================================


============================================================
🔄 Round 218 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0768, val=0.0628 (↓), lr=0.000001
   • Epoch   2/100: train=0.0767, val=0.0628, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0767, val=0.0628, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0767, val=0.0627, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0767, val=0.0627, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0765, val=0.0626, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0628)

============================================================
📊 Round 218 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0767, RMSE=0.2769, R²=0.0948
   Val:   Loss=0.0628, RMSE=0.2506, R²=0.1123
============================================================


📊 Round 218 Test Metrics:
   Loss: 0.0788, RMSE: 0.2807, MAE: 0.2446, R²: 0.0847

============================================================
🔄 Round 220 - Client client_33
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0748, val=0.0702 (↓), lr=0.000001
   • Epoch   2/100: train=0.0748, val=0.0702, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0748, val=0.0701, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0748, val=0.0701, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0748, val=0.0701, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0746, val=0.0700, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0702)

============================================================
📊 Round 220 Summary - Client client_33
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0748, RMSE=0.2735, R²=0.1022
   Val:   Loss=0.0702, RMSE=0.2650, R²=0.0788
============================================================


📊 Round 220 Test Metrics:
   Loss: 0.0788, RMSE: 0.2807, MAE: 0.2446, R²: 0.0847

📊 Round 220 Test Metrics:
   Loss: 0.0788, RMSE: 0.2807, MAE: 0.2446, R²: 0.0848

📊 Round 220 Test Metrics:
   Loss: 0.0788, RMSE: 0.2807, MAE: 0.2446, R²: 0.0848

❌ Client client_33 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8687 {grpc_message:"Socket closed", grpc_status:14}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8687 {grpc_message:"Socket closed", grpc_status:14}"
>
