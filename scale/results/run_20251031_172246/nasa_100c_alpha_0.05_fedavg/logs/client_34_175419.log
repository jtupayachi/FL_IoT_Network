[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3e613209-e65d-489a-b73a-f36c19997a12
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4a2d48cd-36b3-4fcb-9699-63f4ef0c6e47
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2e9286c7-ecfc-4f07-8d9a-cf6a1b889d7c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 361c5ba6-f2a9-4b53-8015-68e7d5913c3d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 70f6e89b-4b56-4d7c-b96b-0e4e804e8613
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f72f2624-9c40-462c-b925-26d4e2b514e6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6cdf12c0-e6ac-49e5-80d9-aefd3b425be9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a890f2b5-b81e-4503-ab35-42f4dd684bb9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c548bd21-cb97-42b8-b1af-cbc07ca8be77
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 55f42848-6309-420a-84b4-9259c4f63a8d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b309ef68-4c6d-4ccb-a786-aa7a29e4ab9e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8a7e394f-ecf9-4cde-93c8-be5b6aa1f12a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0ed5e4a3-b1d3-46ff-a15f-f42f60470cf6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1f27d055-6070-4d46-bc15-1607c30f7b4e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8f729c8d-9e51-4b93-a64b-d71c64d228be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 07600488-c9ee-4571-ae2d-16993511e905
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1461fa18-91a8-45cc-91d6-98e80bdf1ea7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c9a2a2c8-d663-4cac-b9af-c5398ca34f1c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f725e303-a727-4732-a120-bc0479b0e80b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f46f6269-ef8a-4e32-94c1-711f5013a044
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ac861f35-29ce-4d04-a2de-597ca539bbef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0038bb37-3e74-434a-a141-f598f660cfe2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a7c1587d-fa60-41b8-b30f-95e7cd4080bc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 13da8af0-707c-4b9d-b97f-bbf0772f088d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d8836875-6fd3-4422-b43f-7aa027a703a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d1aa1fd0-f156-4b6f-8baf-e3aa2873d328
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b965d533-4241-4179-918d-d45ac7a7bc25
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6675fbb3-3417-47ca-bcb0-018f72c45fff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 926e0e82-07e0-4c5b-a067-8f20f97950d9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a9891d0e-2751-40ff-88c3-3b3dd09651b8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 941c6aff-329c-4fd3-bc2c-71d5e691d54f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d39be6c3-49d9-408f-a332-65d164b3e0ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5c94bd30-5b92-4fa5-8410-ce076df85b12
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 32233fe6-5d4f-4dc3-a8f1-0cce6a080d6a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ed286801-268b-4029-9bd0-e551062c2831
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 60514bf2-bc00-49c3-8f5e-48744a7540ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 27a713e2-ed67-43c7-a177-60045fe840f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1157851b-0d47-4a8f-bdb9-fa0222069b05
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fdaa0a11-89d9-4d64-853a-310e22826e7d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c39c617f-d827-4ca9-9814-1722af64f15f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f8870484-c96b-4598-9e65-b48919647f8e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5949663d-e156-4102-8bf4-d3fd55d67c00
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 32215483-7a4e-406c-b59b-7e05424145b1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3203da8a-bc20-4c39-a85b-1655b25579ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8206a6ea-1034-436b-9b91-5582bb44c817
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 52e67713-9ee9-4e1b-baef-8e0dab42f577
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0c14a439-ec4d-4b5b-8555-696b13834b17
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0cf2a185-ef3c-49d7-a669-40a1e94e1895
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 49de468d-ad84-4d1b-bd9a-3ff6ac485118
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 86b44e99-6bba-4c93-b5da-7571ccee1c46
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5f0596d1-d2e7-414a-9b36-2e9973ef710a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3da773b7-ef14-443c-b426-9bae5119289e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5ad26542-f70d-49cd-bb0d-386d7d0d205c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bf9b15f1-df35-4c17-b5cb-42bcc1c21061
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 43706af0-1b25-48ad-90b1-2b848de2d0d9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f1771bfd-64e3-4bd1-92d4-9769159c91b7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0f6e47fb-0094-4f48-9e94-e80d6387dd32
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message af47a4e2-0d14-4fb8-b55d-d8f0fd8e7cc8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 028766bd-de91-4a07-8437-0edd22f6f065
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 338194e1-1eef-42db-8217-2c2cf4e9a1e0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 26c2c060-115e-4146-9920-a5f34f3e88fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 25ddc53e-7cee-4994-9097-0073d7bfadcf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c673b8f5-2636-48cc-8101-faf96e693b56
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8223834c-fae1-4996-8de4-9a66062c882f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ce74d065-6cad-4596-afa1-d7e3e2b76e7f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 866ea952-def6-4814-ad37-e55a3a6fe741
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 58098ddf-b3ee-4e2f-aa17-4ccb166ccf32
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2ffb5fdf-b074-4159-888f-9b2f0561d8c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 36a3d8e3-a429-40c4-bb51-243afafae742
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a9a59a60-efee-4213-961b-1fed010c51e1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message db3eb25c-bdde-4d6e-8ecc-0c25066173d1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4b770a2d-6025-449d-a485-1d2adf51e660
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message faad4043-dc2a-47a4-a359-9f355d5fcbaf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5262b9d4-cd2f-4b4f-8b12-43ed31dfd485
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f4d58a5f-d976-4185-932d-a53b85d05c1b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a6bf8bc8-6825-401e-8cd4-f8d495b2a275
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d5ca1e87-6105-4b68-b050-5529a5955d3b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4d0dd0dc-5f5a-4e7e-934b-c44f2cab5e48
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 24a4d2c2-5bfe-4b83-a8b8-5251720d4f9d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ca6473d2-074f-4e48-9990-33b391b0fa20
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 99c80616-2134-4638-ba91-7a615b5d9068
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ab73ada1-ef96-457a-9e66-5241e766c89f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 93e694ec-d9c5-44d2-bbb0-cd94f07ec4b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9ad2aae3-0287-4d74-8108-3eedb48c2195
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 53be1a89-331b-4a6a-982b-703df2f8e19b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b028b6f7-3625-4662-addb-5d7884aae7be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ee91e323-9738-435d-b779-73d07a279084
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 76a42ca2-65ed-4288-a1f2-7e277e15b768
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5b9a7c0c-df60-4e81-857d-6075d89931b5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6a249016-efeb-40d9-8b5c-07301ad2cf7d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0883709e-acc1-4ed9-bf43-8745aff41a14
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7ad3c1dc-6ca1-4a8a-84a5-492e395d9b67
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 795d620b-f71f-4db2-a2c2-532b0c8cc6da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9da5fa42-7fcc-453c-aa5b-860a9c9af6ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 22107d53-83fb-4bf4-9ea3-f5944b0cb65b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7fa4cadd-cc59-4b11-a819-2af43f3ccb8c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8262b0d2-de11-4f80-8a24-70e2a4c897e2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7cbbf03f-63c2-4b15-95de-c4adf8dcc127
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 07764b30-b602-41ae-bd94-5828af426d7c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4bdff3d9-6b92-4613-8115-bf7abc1ac6ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 69fb1722-c54f-4798-9d8d-99448ff361bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d3c03841-e1d3-4e92-a599-204ebebb1505
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8651df58-d87d-480d-a02d-39ee77976855
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b6ea5a3f-b2fe-46a1-be2b-e0307a7c74e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 82907813-b86b-4158-844f-d27d61fdacaf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0e704e7a-a993-479f-ab92-382409bda759
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b87d225f-f44e-4b09-a2f4-45df19b84adb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3174b0e8-e776-4228-b1ea-e4ed80151a57
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4abf11cf-4f8d-4c48-a031-e42fa707cac4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b5e78b66-6364-4004-9ca0-e489121acdbd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ffb7ced5-c58a-4a80-88d9-b15ca5595925
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 21eacc06-9186-4dbc-9bc3-a5a149540df5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 10714505-b5f7-4427-8995-a478994b0a1d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 02803396-2b66-4a2d-8ac4-f148b6b34f22
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0d16c354-15de-4c0c-8799-c512ecc9c737
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 549a0705-3c32-49f6-a5cd-d03ff9f00b95
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6247ac95-8956-456d-8a1a-051f37283c15
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 603849c3-3451-4436-897c-808e19a3d5dd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 73a043f6-ca17-43fe-aff1-0bd6cef53308
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 98d4f14f-8077-4691-a573-28eb93c141e9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d109f726-5416-40c1-b52b-56b24cc9bc0b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dcab6660-1552-4e97-8f4a-08e64f36fb22
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eeabf9c9-3552-4811-9d64-6e284d73f622
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3c5941d3-a685-44f3-82a1-0656fbee3a13
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7d4f60fd-806b-4c72-8ced-d34a0a4b8fb2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fc253d5e-0afe-4aaa-ac77-983b758184da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eb473688-fe72-4587-a6ea-5da04d66e885
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c622fe13-2479-4490-b33f-f8f458f7dd4f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 718f375e-c679-4974-9029-8f7e39b2ee32
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 28bc9e3d-0a24-470e-b65d-ecdb89ba09c9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b489658a-2ec0-4cca-b042-ffa93a77e73c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 45b26a6f-f5c6-40f8-a07c-7845c5d4ce3f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 90a0f0f3-6edc-47f0-828e-5d1b3726d694
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 93411a37-bdca-4cb0-8141-9af900f1e9d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fea916a0-18d0-42a5-8e9c-d4bef75415d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 31257ef5-249f-4a59-9394-f341140c939e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a69491e0-c61e-46dd-a0d8-83262a92d5ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 30770f17-fcfd-49ae-98f4-5de9cbf8afb5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 21b258ad-f3ef-46ef-afc6-1dd480f53fec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7c439603-4112-4cc0-9e52-feb0d71a2b05
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 015fb1a7-505f-46b9-9834-311f74838fbd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 202e3883-62ac-463a-8ed2-cca9254e9f9a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d01751bf-c82d-4f22-8ac1-3338b31e4d85
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dda2e49f-9d13-46b7-92ef-3b9b26939007
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7885ddca-9f0b-4b52-b80e-83fbd0c368ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cd3ae0f6-9652-448e-b287-1b9590353e23
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fb376b30-a67a-4977-9e3e-39cbb464a6d5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ff671a18-31ef-45e4-879c-bdefa429c35c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a971acf6-3a04-4c7b-8550-744c6f61d788
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3dcea5a4-6c86-44ec-8639-cf20153ec68d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 025bf103-5d31-4a90-9f47-15fd0ac5776d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1be6e179-6ec9-4a7e-9139-eb2a37e51d3f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 20aaa043-f35a-47ff-9ae5-5a4a24566abb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3ca23918-7d5f-44a1-af42-cc7d06768537
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7ab1f3d2-c870-4763-837a-f6ed4e4d074f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 050646c5-2fb9-4e55-b87f-ce37a92c049e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b57a0ac0-8a95-4a8e-9e0d-df4dbbbd68db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2f7c7462-b24f-46a3-8de2-61f0c24c2be0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6d0977f1-dfad-4ea5-8a8a-ffd0e779c84c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 59ecedfa-f4e0-4cf5-8190-bb559514cff5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 48614d75-7c04-4371-be09-73a77a98f09c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e90c3b5e-276e-4971-a994-8c69c44bd0d0
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8687 {grpc_status:14, grpc_message:"Socket closed"}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_34
Server: localhost:8687
Algorithm: FEDAVG
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_34
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_34/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_34/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_34/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_34/test_labels.txt

📊 Raw data loaded:
   Train: X=(1148, 24), y=(1148,)
   Test:  X=(287, 24), y=(287,)

⚠️  Limiting training data: 1148 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  278 samples, 5 features
✅ Client client_34 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

============================================================
🔄 Round 3 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0822 (↓), lr=0.001000
   • Epoch   2/100: train=0.0812, val=0.0821, patience=1/15, lr=0.001000
   • Epoch   3/100: train=0.0808, val=0.0819, patience=2/15, lr=0.001000
   • Epoch   4/100: train=0.0803, val=0.0818, patience=3/15, lr=0.001000
   • Epoch   5/100: train=0.0798, val=0.0817, patience=4/15, lr=0.001000
   ✓ Epoch  11/100: train=0.0723, val=0.0780 (↓), lr=0.001000
   📉 Epoch 18: LR reduced 0.001000 → 0.000500
   • Epoch  21/100: train=0.0634, val=0.0804, patience=10/15, lr=0.000500
   📉 Epoch 26: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 3 Summary - Client client_34
   Epochs: 26/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0698, RMSE=0.2641, R²=0.1538
   Val:   Loss=0.0780, RMSE=0.2793, R²=0.0651
============================================================


============================================================
🔄 Round 4 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0833 (↓), lr=0.000250
   • Epoch   2/100: train=0.0803, val=0.0828, patience=1/15, lr=0.000250
   • Epoch   3/100: train=0.0802, val=0.0829, patience=2/15, lr=0.000250
   • Epoch   4/100: train=0.0801, val=0.0828, patience=3/15, lr=0.000250
   • Epoch   5/100: train=0.0800, val=0.0828, patience=4/15, lr=0.000250
   📉 Epoch 8: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0792, val=0.0828, patience=2/15, lr=0.000125
   📉 Epoch 16: LR reduced 0.000125 → 0.000063
   • Epoch  21/100: train=0.0785, val=0.0826, patience=12/15, lr=0.000063
   📉 Epoch 24: LR reduced 0.000063 → 0.000031

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 4 Summary - Client client_34
   Epochs: 24/100 (early stopped)
   LR: 0.000250 → 0.000031 (3 reductions)
   Train: Loss=0.0791, RMSE=0.2813, R²=0.0388
   Val:   Loss=0.0828, RMSE=0.2877, R²=0.0104
============================================================


============================================================
🔄 Round 5 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000031
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0694 (↓), lr=0.000031
   • Epoch   2/100: train=0.0833, val=0.0695, patience=1/15, lr=0.000031
   • Epoch   3/100: train=0.0832, val=0.0696, patience=2/15, lr=0.000031
   • Epoch   4/100: train=0.0831, val=0.0697, patience=3/15, lr=0.000031
   • Epoch   5/100: train=0.0831, val=0.0697, patience=4/15, lr=0.000031
   📉 Epoch 8: LR reduced 0.000031 → 0.000016
   • Epoch  11/100: train=0.0829, val=0.0700, patience=10/15, lr=0.000016
   📉 Epoch 16: LR reduced 0.000016 → 0.000008

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0694)

============================================================
📊 Round 5 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000031 → 0.000008 (2 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=0.0268
   Val:   Loss=0.0694, RMSE=0.2634, R²=0.0465
============================================================


📊 Round 5 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2431, R²: 0.0582

📊 Round 5 Test Metrics:
   Loss: 0.0767, RMSE: 0.2769, MAE: 0.2405, R²: 0.0764

============================================================
🔄 Round 8 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000008
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0741 (↓), lr=0.000008
   • Epoch   2/100: train=0.0788, val=0.0741, patience=1/15, lr=0.000008
   • Epoch   3/100: train=0.0788, val=0.0741, patience=2/15, lr=0.000008
   • Epoch   4/100: train=0.0787, val=0.0741, patience=3/15, lr=0.000008
   • Epoch   5/100: train=0.0786, val=0.0740, patience=4/15, lr=0.000008
   📉 Epoch 8: LR reduced 0.000008 → 0.000004
   • Epoch  11/100: train=0.0784, val=0.0740, patience=10/15, lr=0.000004
   📉 Epoch 16: LR reduced 0.000004 → 0.000002

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0741)

============================================================
📊 Round 8 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000008 → 0.000002 (2 reductions)
   Train: Loss=0.0789, RMSE=0.2808, R²=0.0573
   Val:   Loss=0.0741, RMSE=0.2723, R²=0.0537
============================================================


============================================================
🔄 Round 10 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000002
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0778, val=0.0782 (↓), lr=0.000002
   • Epoch   2/100: train=0.0777, val=0.0782, patience=1/15, lr=0.000002
   • Epoch   3/100: train=0.0777, val=0.0782, patience=2/15, lr=0.000002
   • Epoch   4/100: train=0.0777, val=0.0782, patience=3/15, lr=0.000002
   • Epoch   5/100: train=0.0777, val=0.0782, patience=4/15, lr=0.000002
   📉 Epoch 8: LR reduced 0.000002 → 0.000001
   • Epoch  11/100: train=0.0776, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 10 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000002 → 0.000001 (1 reductions)
   Train: Loss=0.0777, RMSE=0.2788, R²=0.0569
   Val:   Loss=0.0782, RMSE=0.2797, R²=0.0631
============================================================


============================================================
🔄 Round 11 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0777, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0777, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0777, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0777, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0777, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0776, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 11 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0776, RMSE=0.2785, R²=0.0565
   Val:   Loss=0.0789, RMSE=0.2809, R²=0.0554
============================================================


📊 Round 11 Test Metrics:
   Loss: 0.0769, RMSE: 0.2772, MAE: 0.2406, R²: 0.0738

============================================================
🔄 Round 15 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0767, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0767, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0767, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0767, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0767, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0766, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 15 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0767, RMSE=0.2769, R²=0.0664
   Val:   Loss=0.0818, RMSE=0.2860, R²=0.0311
============================================================


============================================================
🔄 Round 16 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0781, val=0.0764 (↓), lr=0.000001
   • Epoch   2/100: train=0.0781, val=0.0764, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0781, val=0.0764, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0781, val=0.0764, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0781, val=0.0764, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0780, val=0.0764, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0764)

============================================================
📊 Round 16 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0780, RMSE=0.2793, R²=0.0552
   Val:   Loss=0.0764, RMSE=0.2764, R²=0.0756
============================================================


============================================================
🔄 Round 17 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0780, val=0.0764 (↓), lr=0.000001
   • Epoch   2/100: train=0.0780, val=0.0765, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0780, val=0.0765, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0780, val=0.0765, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0779, val=0.0765, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0779, val=0.0766, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0764)

============================================================
📊 Round 17 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0779, RMSE=0.2792, R²=0.0658
   Val:   Loss=0.0764, RMSE=0.2765, R²=0.0257
============================================================


📊 Round 17 Test Metrics:
   Loss: 0.0766, RMSE: 0.2767, MAE: 0.2401, R²: 0.0774

============================================================
🔄 Round 18 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0778, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0778, val=0.0778, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0778, val=0.0778, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0778, val=0.0777, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0778, val=0.0777, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0778, val=0.0777, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 18 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0776, RMSE=0.2786, R²=0.0576
   Val:   Loss=0.0778, RMSE=0.2789, R²=0.0545
============================================================


📊 Round 18 Test Metrics:
   Loss: 0.0765, RMSE: 0.2766, MAE: 0.2400, R²: 0.0779

📊 Round 18 Test Metrics:
   Loss: 0.0763, RMSE: 0.2762, MAE: 0.2395, R²: 0.0806

============================================================
🔄 Round 22 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0692 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0692, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0692, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0692, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0692, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0692, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0692)

============================================================
📊 Round 22 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=0.0616
   Val:   Loss=0.0692, RMSE=0.2631, R²=0.0584
============================================================


📊 Round 22 Test Metrics:
   Loss: 0.0763, RMSE: 0.2762, MAE: 0.2395, R²: 0.0809

📊 Round 22 Test Metrics:
   Loss: 0.0763, RMSE: 0.2762, MAE: 0.2395, R²: 0.0809

============================================================
🔄 Round 30 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0765, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0765, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0765, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0765, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0765, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0764, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 30 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0765, RMSE=0.2766, R²=0.0643
   Val:   Loss=0.0819, RMSE=0.2862, R²=0.0416
============================================================


============================================================
🔄 Round 32 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0736 (↓), lr=0.000001
   • Epoch   2/100: train=0.0785, val=0.0736, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0785, val=0.0736, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0785, val=0.0736, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0785, val=0.0736, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0785, val=0.0735, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0736)

============================================================
📊 Round 32 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2803, R²=0.0600
   Val:   Loss=0.0736, RMSE=0.2713, R²=0.0637
============================================================


============================================================
🔄 Round 36 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0739 (↓), lr=0.000001
   • Epoch   2/100: train=0.0787, val=0.0739, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0739, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0739, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0740, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0740, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0739)

============================================================
📊 Round 36 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2802, R²=0.0570
   Val:   Loss=0.0739, RMSE=0.2719, R²=0.0696
============================================================


============================================================
🔄 Round 37 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0768, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0768, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0768, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0768, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0768, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0767, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 37 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0766, RMSE=0.2768, R²=0.0637
   Val:   Loss=0.0816, RMSE=0.2856, R²=0.0459
============================================================


============================================================
🔄 Round 38 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0766, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0766, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0766, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0766, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0766, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0766, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 38 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0763, RMSE=0.2763, R²=0.0531
   Val:   Loss=0.0827, RMSE=0.2875, R²=0.0897
============================================================


============================================================
🔄 Round 41 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0769, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0769, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0769, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0769, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0769, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0768, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 41 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0770, RMSE=0.2774, R²=0.0695
   Val:   Loss=0.0801, RMSE=0.2830, R²=0.0264
============================================================


📊 Round 41 Test Metrics:
   Loss: 0.0763, RMSE: 0.2762, MAE: 0.2395, R²: 0.0809

============================================================
🔄 Round 44 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0755, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0755, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0755, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0755, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0755, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0754, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 44 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0757, RMSE=0.2752, R²=0.0677
   Val:   Loss=0.0851, RMSE=0.2917, R²=0.0373
============================================================


============================================================
🔄 Round 45 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0732 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0732, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0732, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0732, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0732, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0785, val=0.0731, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0732)

============================================================
📊 Round 45 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2805, R²=0.0637
   Val:   Loss=0.0732, RMSE=0.2706, R²=0.0506
============================================================


============================================================
🔄 Round 47 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0726 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0726, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0726, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0726, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0726, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0726, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0726)

============================================================
📊 Round 47 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2808, R²=0.0598
   Val:   Loss=0.0726, RMSE=0.2694, R²=0.0667
============================================================


============================================================
🔄 Round 48 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0774, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0774, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0774, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0774, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0773, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0773, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 48 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0774, RMSE=0.2782, R²=0.0655
   Val:   Loss=0.0783, RMSE=0.2799, R²=0.0401
============================================================


============================================================
🔄 Round 50 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0775, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0774, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0774, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0774, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0774, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0774, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 50 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0771, RMSE=0.2776, R²=0.0606
   Val:   Loss=0.0796, RMSE=0.2822, R²=0.0588
============================================================


📊 Round 50 Test Metrics:
   Loss: 0.0763, RMSE: 0.2762, MAE: 0.2395, R²: 0.0808

============================================================
🔄 Round 55 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0762, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0762, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0762, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0762, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0761, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0760, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 55 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0763, RMSE=0.2762, R²=0.0579
   Val:   Loss=0.0829, RMSE=0.2880, R²=0.0492
============================================================


📊 Round 55 Test Metrics:
   Loss: 0.0763, RMSE: 0.2762, MAE: 0.2395, R²: 0.0808

============================================================
🔄 Round 57 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0743, val=0.0911 (↓), lr=0.000001
   • Epoch   2/100: train=0.0743, val=0.0911, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0743, val=0.0911, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0743, val=0.0911, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0743, val=0.0911, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0742, val=0.0910, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0911)

============================================================
📊 Round 57 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0742, RMSE=0.2724, R²=0.0550
   Val:   Loss=0.0911, RMSE=0.3019, R²=0.0804
============================================================


📊 Round 57 Test Metrics:
   Loss: 0.0763, RMSE: 0.2762, MAE: 0.2395, R²: 0.0807

============================================================
🔄 Round 62 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0780, val=0.0770 (↓), lr=0.000001
   • Epoch   2/100: train=0.0779, val=0.0770, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0779, val=0.0769, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0779, val=0.0769, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0779, val=0.0769, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0779, val=0.0769, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0770)

============================================================
📊 Round 62 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0778, RMSE=0.2789, R²=0.0605
   Val:   Loss=0.0770, RMSE=0.2774, R²=0.0621
============================================================


📊 Round 62 Test Metrics:
   Loss: 0.0763, RMSE: 0.2762, MAE: 0.2395, R²: 0.0807

📊 Round 62 Test Metrics:
   Loss: 0.0763, RMSE: 0.2762, MAE: 0.2395, R²: 0.0807

============================================================
🔄 Round 64 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0775, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0775, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0775, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0775, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0775, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0774, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 64 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0774, RMSE=0.2782, R²=0.0614
   Val:   Loss=0.0784, RMSE=0.2799, R²=0.0599
============================================================


============================================================
🔄 Round 65 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0771, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0771, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0771, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0770, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0770, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0770, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 65 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0773, RMSE=0.2780, R²=0.0614
   Val:   Loss=0.0788, RMSE=0.2807, R²=0.0592
============================================================


📊 Round 65 Test Metrics:
   Loss: 0.0763, RMSE: 0.2762, MAE: 0.2395, R²: 0.0808

============================================================
🔄 Round 66 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0757, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0757, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0757, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0757, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0757, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0756, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 66 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0758, RMSE=0.2753, R²=0.0640
   Val:   Loss=0.0848, RMSE=0.2912, R²=0.0496
============================================================


📊 Round 66 Test Metrics:
   Loss: 0.0763, RMSE: 0.2762, MAE: 0.2395, R²: 0.0808

============================================================
🔄 Round 68 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0781, val=0.0747 (↓), lr=0.000001
   • Epoch   2/100: train=0.0781, val=0.0747, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0781, val=0.0747, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0781, val=0.0747, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0781, val=0.0747, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0780, val=0.0747, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0747)

============================================================
📊 Round 68 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0783, RMSE=0.2798, R²=0.0688
   Val:   Loss=0.0747, RMSE=0.2734, R²=0.0262
============================================================


============================================================
🔄 Round 70 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0754, val=0.0868 (↓), lr=0.000001
   • Epoch   2/100: train=0.0753, val=0.0868, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0753, val=0.0868, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0753, val=0.0868, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0753, val=0.0868, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0752, val=0.0868, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0868)

============================================================
📊 Round 70 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0753, RMSE=0.2744, R²=0.0629
   Val:   Loss=0.0868, RMSE=0.2946, R²=0.0491
============================================================


📊 Round 70 Test Metrics:
   Loss: 0.0763, RMSE: 0.2762, MAE: 0.2395, R²: 0.0808

============================================================
🔄 Round 71 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0776, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0776, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0776, val=0.0782, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0776, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0776, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0775, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 71 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0774, RMSE=0.2783, R²=0.0573
   Val:   Loss=0.0782, RMSE=0.2796, R²=0.0765
============================================================


📊 Round 71 Test Metrics:
   Loss: 0.0763, RMSE: 0.2762, MAE: 0.2395, R²: 0.0809

📊 Round 71 Test Metrics:
   Loss: 0.0763, RMSE: 0.2762, MAE: 0.2395, R²: 0.0809

============================================================
🔄 Round 75 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0765, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0765, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0765, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0764, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0764, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0764, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 75 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0761, RMSE=0.2759, R²=0.0644
   Val:   Loss=0.0835, RMSE=0.2889, R²=0.0480
============================================================


============================================================
🔄 Round 76 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0782, val=0.0756 (↓), lr=0.000001
   • Epoch   2/100: train=0.0782, val=0.0756, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0782, val=0.0756, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0781, val=0.0755, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0781, val=0.0755, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0781, val=0.0755, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0756)

============================================================
📊 Round 76 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0781, RMSE=0.2794, R²=0.0637
   Val:   Loss=0.0756, RMSE=0.2749, R²=0.0494
============================================================


📊 Round 76 Test Metrics:
   Loss: 0.0763, RMSE: 0.2762, MAE: 0.2395, R²: 0.0809

============================================================
🔄 Round 77 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0761, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0761, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0761, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0760, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0760, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0759, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 77 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0761, RMSE=0.2759, R²=0.0624
   Val:   Loss=0.0834, RMSE=0.2887, R²=0.0485
============================================================


============================================================
🔄 Round 79 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0782, val=0.0759 (↓), lr=0.000001
   • Epoch   2/100: train=0.0781, val=0.0759, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0781, val=0.0759, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0781, val=0.0759, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0781, val=0.0758, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0781, val=0.0758, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0759)

============================================================
📊 Round 79 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0780, RMSE=0.2793, R²=0.0554
   Val:   Loss=0.0759, RMSE=0.2755, R²=0.0516
============================================================


============================================================
🔄 Round 82 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0782, val=0.0756 (↓), lr=0.000001
   • Epoch   2/100: train=0.0782, val=0.0756, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0782, val=0.0757, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0781, val=0.0757, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0781, val=0.0757, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0780, val=0.0758, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0756)

============================================================
📊 Round 82 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0781, RMSE=0.2794, R²=0.0611
   Val:   Loss=0.0756, RMSE=0.2750, R²=0.0360
============================================================


📊 Round 82 Test Metrics:
   Loss: 0.0763, RMSE: 0.2762, MAE: 0.2395, R²: 0.0808

📊 Round 82 Test Metrics:
   Loss: 0.0763, RMSE: 0.2762, MAE: 0.2395, R²: 0.0808

============================================================
🔄 Round 86 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0723 (↓), lr=0.000001
   • Epoch   2/100: train=0.0787, val=0.0723, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0723, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0723, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0723, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0722, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0723)

============================================================
📊 Round 86 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2809, R²=0.0593
   Val:   Loss=0.0723, RMSE=0.2689, R²=0.0589
============================================================


📊 Round 86 Test Metrics:
   Loss: 0.0763, RMSE: 0.2762, MAE: 0.2395, R²: 0.0808

============================================================
🔄 Round 88 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0779, val=0.0748 (↓), lr=0.000001
   • Epoch   2/100: train=0.0779, val=0.0748, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0779, val=0.0748, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0779, val=0.0748, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0779, val=0.0748, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0778, val=0.0747, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0748)

============================================================
📊 Round 88 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0783, RMSE=0.2798, R²=0.0572
   Val:   Loss=0.0748, RMSE=0.2735, R²=0.0715
============================================================


📊 Round 88 Test Metrics:
   Loss: 0.0763, RMSE: 0.2762, MAE: 0.2395, R²: 0.0808

============================================================
🔄 Round 89 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0731 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0731, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0732, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0732, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0785, val=0.0732, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0733, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0731)

============================================================
📊 Round 89 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2805, R²=0.0605
   Val:   Loss=0.0731, RMSE=0.2704, R²=0.0437
============================================================


============================================================
🔄 Round 90 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0781, val=0.0752 (↓), lr=0.000001
   • Epoch   2/100: train=0.0781, val=0.0752, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0781, val=0.0752, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0781, val=0.0752, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0781, val=0.0752, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0780, val=0.0751, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0752)

============================================================
📊 Round 90 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0782, RMSE=0.2796, R²=0.0672
   Val:   Loss=0.0752, RMSE=0.2742, R²=0.0358
============================================================


📊 Round 90 Test Metrics:
   Loss: 0.0763, RMSE: 0.2762, MAE: 0.2395, R²: 0.0809

============================================================
🔄 Round 91 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0747, val=0.0877 (↓), lr=0.000001
   • Epoch   2/100: train=0.0747, val=0.0877, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0747, val=0.0877, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0747, val=0.0877, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0747, val=0.0877, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0747, val=0.0877, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0877)

============================================================
📊 Round 91 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0751, RMSE=0.2740, R²=0.0592
   Val:   Loss=0.0877, RMSE=0.2962, R²=0.0434
============================================================


📊 Round 91 Test Metrics:
   Loss: 0.0763, RMSE: 0.2762, MAE: 0.2395, R²: 0.0809

============================================================
🔄 Round 93 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0757, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0757, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0757, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0757, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0757, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0757, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 93 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0757, RMSE=0.2751, R²=0.0615
   Val:   Loss=0.0852, RMSE=0.2919, R²=0.0583
============================================================


============================================================
🔄 Round 94 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0775, val=0.0769 (↓), lr=0.000001
   • Epoch   2/100: train=0.0775, val=0.0769, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0774, val=0.0769, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0774, val=0.0769, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0774, val=0.0769, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0774, val=0.0769, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0769)

============================================================
📊 Round 94 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0778, RMSE=0.2789, R²=0.0560
   Val:   Loss=0.0769, RMSE=0.2773, R²=0.0788
============================================================


📊 Round 94 Test Metrics:
   Loss: 0.0763, RMSE: 0.2762, MAE: 0.2395, R²: 0.0808

============================================================
🔄 Round 96 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0772, val=0.0779 (↓), lr=0.000001
   • Epoch   2/100: train=0.0772, val=0.0779, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0772, val=0.0779, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0772, val=0.0779, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0772, val=0.0779, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0772, val=0.0778, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0779)

============================================================
📊 Round 96 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0775, RMSE=0.2784, R²=0.0537
   Val:   Loss=0.0779, RMSE=0.2792, R²=0.0843
============================================================


============================================================
🔄 Round 97 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0722 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0722, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0721, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0721, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0721, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0721, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0722)

============================================================
📊 Round 97 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2810, R²=0.0607
   Val:   Loss=0.0722, RMSE=0.2686, R²=0.0500
============================================================


📊 Round 97 Test Metrics:
   Loss: 0.0763, RMSE: 0.2762, MAE: 0.2395, R²: 0.0808

📊 Round 97 Test Metrics:
   Loss: 0.0763, RMSE: 0.2762, MAE: 0.2395, R²: 0.0809

📊 Round 97 Test Metrics:
   Loss: 0.0763, RMSE: 0.2762, MAE: 0.2395, R²: 0.0809

============================================================
🔄 Round 103 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0770, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0770, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0769, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0769, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0769, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0769, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 103 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0768, RMSE=0.2772, R²=0.0679
   Val:   Loss=0.0805, RMSE=0.2838, R²=0.0348
============================================================


📊 Round 103 Test Metrics:
   Loss: 0.0763, RMSE: 0.2762, MAE: 0.2395, R²: 0.0809

============================================================
🔄 Round 105 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0715 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0715, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0715, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0715, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0715, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0716, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0715)

============================================================
📊 Round 105 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2812, R²=0.0536
   Val:   Loss=0.0715, RMSE=0.2674, R²=0.0842
============================================================


============================================================
🔄 Round 106 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0726 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0726, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0726, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0726, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0726, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0726, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0726)

============================================================
📊 Round 106 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2807, R²=0.0594
   Val:   Loss=0.0726, RMSE=0.2694, R²=0.0657
============================================================


📊 Round 106 Test Metrics:
   Loss: 0.0763, RMSE: 0.2762, MAE: 0.2395, R²: 0.0809

============================================================
🔄 Round 109 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0780, val=0.0767 (↓), lr=0.000001
   • Epoch   2/100: train=0.0780, val=0.0767, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0780, val=0.0767, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0779, val=0.0767, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0779, val=0.0767, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0779, val=0.0766, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0767)

============================================================
📊 Round 109 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0778, RMSE=0.2789, R²=0.0570
   Val:   Loss=0.0767, RMSE=0.2769, R²=0.0788
============================================================


📊 Round 109 Test Metrics:
   Loss: 0.0763, RMSE: 0.2762, MAE: 0.2395, R²: 0.0809

============================================================
🔄 Round 111 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0780, val=0.0752 (↓), lr=0.000001
   • Epoch   2/100: train=0.0780, val=0.0752, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0780, val=0.0752, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0780, val=0.0752, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0780, val=0.0752, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0780, val=0.0751, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0752)

============================================================
📊 Round 111 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0782, RMSE=0.2796, R²=0.0665
   Val:   Loss=0.0752, RMSE=0.2742, R²=0.0392
============================================================


📊 Round 111 Test Metrics:
   Loss: 0.0763, RMSE: 0.2762, MAE: 0.2395, R²: 0.0809

📊 Round 111 Test Metrics:
   Loss: 0.0763, RMSE: 0.2762, MAE: 0.2395, R²: 0.0809

📊 Round 111 Test Metrics:
   Loss: 0.0763, RMSE: 0.2762, MAE: 0.2395, R²: 0.0809

============================================================
🔄 Round 117 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0777, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0777, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0777, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0777, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0777, val=0.0772, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0776, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 117 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0776, RMSE=0.2786, R²=0.0620
   Val:   Loss=0.0773, RMSE=0.2780, R²=0.0581
============================================================


============================================================
🔄 Round 118 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0774, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0774, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0774, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0774, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0773, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0773, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 118 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0773, RMSE=0.2781, R²=0.0639
   Val:   Loss=0.0786, RMSE=0.2803, R²=0.0429
============================================================


============================================================
🔄 Round 119 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0758, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0758, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0758, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0757, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0757, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0756, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 119 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0758, RMSE=0.2752, R²=0.0632
   Val:   Loss=0.0848, RMSE=0.2912, R²=0.0449
============================================================


📊 Round 119 Test Metrics:
   Loss: 0.0763, RMSE: 0.2762, MAE: 0.2395, R²: 0.0810

============================================================
🔄 Round 120 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0637 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0637, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0637, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0637, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0637, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0637, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0637)

============================================================
📊 Round 120 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=0.0606
   Val:   Loss=0.0637, RMSE=0.2525, R²=0.0659
============================================================


📊 Round 120 Test Metrics:
   Loss: 0.0763, RMSE: 0.2762, MAE: 0.2395, R²: 0.0810

============================================================
🔄 Round 122 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0773, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0773, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0773, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0773, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0773, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0772, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 122 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0772, RMSE=0.2778, R²=0.0671
   Val:   Loss=0.0791, RMSE=0.2813, R²=0.0390
============================================================


📊 Round 122 Test Metrics:
   Loss: 0.0763, RMSE: 0.2762, MAE: 0.2395, R²: 0.0809

📊 Round 122 Test Metrics:
   Loss: 0.0763, RMSE: 0.2762, MAE: 0.2395, R²: 0.0809

============================================================
🔄 Round 127 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0767, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0767, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0767, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0767, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0767, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0766, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 127 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0767, RMSE=0.2769, R²=0.0531
   Val:   Loss=0.0812, RMSE=0.2849, R²=0.0872
============================================================


📊 Round 127 Test Metrics:
   Loss: 0.0763, RMSE: 0.2762, MAE: 0.2395, R²: 0.0809

============================================================
🔄 Round 130 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0764, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0764, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0764, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0764, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0763, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0763, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 130 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0767, RMSE=0.2770, R²=0.0565
   Val:   Loss=0.0810, RMSE=0.2846, R²=0.0790
============================================================


📊 Round 130 Test Metrics:
   Loss: 0.0763, RMSE: 0.2762, MAE: 0.2395, R²: 0.0808

📊 Round 130 Test Metrics:
   Loss: 0.0763, RMSE: 0.2762, MAE: 0.2395, R²: 0.0808

📊 Round 130 Test Metrics:
   Loss: 0.0763, RMSE: 0.2762, MAE: 0.2395, R²: 0.0808

📊 Round 130 Test Metrics:
   Loss: 0.0763, RMSE: 0.2762, MAE: 0.2395, R²: 0.0808

============================================================
🔄 Round 135 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0767, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0767, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0767, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0767, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0767, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0767, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 135 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0767, RMSE=0.2769, R²=0.0615
   Val:   Loss=0.0812, RMSE=0.2850, R²=0.0505
============================================================


============================================================
🔄 Round 138 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0738 (↓), lr=0.000001
   • Epoch   2/100: train=0.0785, val=0.0738, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0785, val=0.0738, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0785, val=0.0738, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0785, val=0.0737, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0737, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0738)

============================================================
📊 Round 138 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2802, R²=0.0607
   Val:   Loss=0.0738, RMSE=0.2716, R²=0.0630
============================================================


============================================================
🔄 Round 139 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0746, val=0.0895 (↓), lr=0.000001
   • Epoch   2/100: train=0.0746, val=0.0895, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0745, val=0.0895, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0745, val=0.0895, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0745, val=0.0895, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0744, val=0.0896, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0895)

============================================================
📊 Round 139 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0746, RMSE=0.2731, R²=0.0602
   Val:   Loss=0.0895, RMSE=0.2992, R²=0.0585
============================================================


📊 Round 139 Test Metrics:
   Loss: 0.0763, RMSE: 0.2762, MAE: 0.2395, R²: 0.0807

============================================================
🔄 Round 140 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0770, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0770, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0770, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0770, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0770, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0769, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 140 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0772, RMSE=0.2778, R²=0.0620
   Val:   Loss=0.0792, RMSE=0.2815, R²=0.0546
============================================================


============================================================
🔄 Round 141 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0739 (↓), lr=0.000001
   • Epoch   2/100: train=0.0785, val=0.0739, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0785, val=0.0738, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0785, val=0.0738, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0785, val=0.0738, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0785, val=0.0738, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0739)

============================================================
📊 Round 141 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2802, R²=0.0642
   Val:   Loss=0.0739, RMSE=0.2718, R²=0.0449
============================================================


📊 Round 141 Test Metrics:
   Loss: 0.0763, RMSE: 0.2762, MAE: 0.2395, R²: 0.0807

============================================================
🔄 Round 145 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0777, val=0.0769 (↓), lr=0.000001
   • Epoch   2/100: train=0.0777, val=0.0768, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0777, val=0.0768, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0776, val=0.0768, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0776, val=0.0768, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0776, val=0.0768, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0769)

============================================================
📊 Round 145 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0778, RMSE=0.2788, R²=0.0636
   Val:   Loss=0.0769, RMSE=0.2772, R²=0.0522
============================================================


📊 Round 145 Test Metrics:
   Loss: 0.0763, RMSE: 0.2762, MAE: 0.2395, R²: 0.0807

📊 Round 145 Test Metrics:
   Loss: 0.0763, RMSE: 0.2762, MAE: 0.2395, R²: 0.0807

📊 Round 145 Test Metrics:
   Loss: 0.0763, RMSE: 0.2762, MAE: 0.2395, R²: 0.0807

============================================================
🔄 Round 148 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0775, val=0.0765 (↓), lr=0.000001
   • Epoch   2/100: train=0.0775, val=0.0764, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0775, val=0.0764, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0775, val=0.0764, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0775, val=0.0764, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0774, val=0.0764, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0765)

============================================================
📊 Round 148 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0779, RMSE=0.2790, R²=0.0606
   Val:   Loss=0.0765, RMSE=0.2765, R²=0.0643
============================================================


📊 Round 148 Test Metrics:
   Loss: 0.0763, RMSE: 0.2762, MAE: 0.2395, R²: 0.0807

============================================================
🔄 Round 149 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0765, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0765, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0765, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0765, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0765, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0764, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 149 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0766, RMSE=0.2768, R²=0.0629
   Val:   Loss=0.0814, RMSE=0.2853, R²=0.0553
============================================================


📊 Round 149 Test Metrics:
   Loss: 0.0763, RMSE: 0.2762, MAE: 0.2395, R²: 0.0807

============================================================
🔄 Round 151 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0698 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0698, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0698, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0698, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0698, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0699, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0698)

============================================================
📊 Round 151 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2820, R²=0.0589
   Val:   Loss=0.0698, RMSE=0.2642, R²=0.0378
============================================================


📊 Round 151 Test Metrics:
   Loss: 0.0763, RMSE: 0.2762, MAE: 0.2395, R²: 0.0807

============================================================
🔄 Round 152 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0769, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0769, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0769, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0769, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0768, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0768, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 152 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0769, RMSE=0.2773, R²=0.0570
   Val:   Loss=0.0803, RMSE=0.2834, R²=0.0770
============================================================


📊 Round 152 Test Metrics:
   Loss: 0.0763, RMSE: 0.2762, MAE: 0.2395, R²: 0.0807

============================================================
🔄 Round 158 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0776, val=0.0764 (↓), lr=0.000001
   • Epoch   2/100: train=0.0776, val=0.0763, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0775, val=0.0763, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0775, val=0.0763, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0775, val=0.0763, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0775, val=0.0763, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0764)

============================================================
📊 Round 158 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0779, RMSE=0.2791, R²=0.0633
   Val:   Loss=0.0764, RMSE=0.2763, R²=0.0533
============================================================


📊 Round 158 Test Metrics:
   Loss: 0.0763, RMSE: 0.2762, MAE: 0.2395, R²: 0.0807

📊 Round 158 Test Metrics:
   Loss: 0.0763, RMSE: 0.2762, MAE: 0.2395, R²: 0.0807

============================================================
🔄 Round 160 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0667 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0667, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0667, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0667, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0667, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0666, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0667)

============================================================
📊 Round 160 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=0.0596
   Val:   Loss=0.0667, RMSE=0.2583, R²=0.0696
============================================================


📊 Round 160 Test Metrics:
   Loss: 0.0763, RMSE: 0.2762, MAE: 0.2395, R²: 0.0807

📊 Round 160 Test Metrics:
   Loss: 0.0763, RMSE: 0.2762, MAE: 0.2395, R²: 0.0807

============================================================
🔄 Round 164 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0670 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0671, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0671, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0671, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0671, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0672, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0670)

============================================================
📊 Round 164 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=0.0535
   Val:   Loss=0.0670, RMSE=0.2589, R²=0.0830
============================================================


📊 Round 164 Test Metrics:
   Loss: 0.0763, RMSE: 0.2762, MAE: 0.2395, R²: 0.0806

📊 Round 164 Test Metrics:
   Loss: 0.0763, RMSE: 0.2762, MAE: 0.2396, R²: 0.0806

============================================================
🔄 Round 169 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0782, val=0.0744 (↓), lr=0.000001
   • Epoch   2/100: train=0.0782, val=0.0744, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0782, val=0.0744, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0782, val=0.0744, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0782, val=0.0744, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0781, val=0.0743, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0744)

============================================================
📊 Round 169 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2800, R²=0.0597
   Val:   Loss=0.0744, RMSE=0.2728, R²=0.0659
============================================================


============================================================
🔄 Round 170 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0757, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0756, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0756, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0756, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0756, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0755, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 170 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0757, RMSE=0.2751, R²=0.0674
   Val:   Loss=0.0851, RMSE=0.2918, R²=0.0385
============================================================


📊 Round 170 Test Metrics:
   Loss: 0.0763, RMSE: 0.2762, MAE: 0.2395, R²: 0.0806

============================================================
🔄 Round 174 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0778, val=0.0757 (↓), lr=0.000001
   • Epoch   2/100: train=0.0778, val=0.0757, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0777, val=0.0757, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0777, val=0.0757, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0777, val=0.0757, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0776, val=0.0758, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0757)

============================================================
📊 Round 174 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0780, RMSE=0.2794, R²=0.0612
   Val:   Loss=0.0757, RMSE=0.2751, R²=0.0414
============================================================


📊 Round 174 Test Metrics:
   Loss: 0.0763, RMSE: 0.2762, MAE: 0.2395, R²: 0.0806

📊 Round 174 Test Metrics:
   Loss: 0.0763, RMSE: 0.2762, MAE: 0.2396, R²: 0.0805

📊 Round 174 Test Metrics:
   Loss: 0.0763, RMSE: 0.2762, MAE: 0.2396, R²: 0.0805

📊 Round 174 Test Metrics:
   Loss: 0.0763, RMSE: 0.2762, MAE: 0.2396, R²: 0.0805

============================================================
🔄 Round 188 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0693 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0693, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0693, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0693, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0693, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0693, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0693)

============================================================
📊 Round 188 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2822, R²=0.0580
   Val:   Loss=0.0693, RMSE=0.2632, R²=0.0741
============================================================


📊 Round 188 Test Metrics:
   Loss: 0.0763, RMSE: 0.2763, MAE: 0.2396, R²: 0.0804

============================================================
🔄 Round 191 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0762, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0762, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0762, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0761, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0761, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0761, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 191 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0764, RMSE=0.2765, R²=0.0632
   Val:   Loss=0.0823, RMSE=0.2868, R²=0.0527
============================================================


============================================================
🔄 Round 192 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0774, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0774, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0774, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0774, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0773, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0772, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 192 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0775, RMSE=0.2783, R²=0.0555
   Val:   Loss=0.0781, RMSE=0.2795, R²=0.0412
============================================================


📊 Round 192 Test Metrics:
   Loss: 0.0763, RMSE: 0.2763, MAE: 0.2396, R²: 0.0804

============================================================
🔄 Round 193 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0737 (↓), lr=0.000001
   • Epoch   2/100: train=0.0787, val=0.0737, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0737, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0737, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0737, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0737, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0737)

============================================================
📊 Round 193 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2803, R²=0.0577
   Val:   Loss=0.0737, RMSE=0.2714, R²=0.0736
============================================================


📊 Round 193 Test Metrics:
   Loss: 0.0763, RMSE: 0.2763, MAE: 0.2396, R²: 0.0804

============================================================
🔄 Round 196 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0760, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0760, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0760, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0760, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0759, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0759, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 196 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0761, RMSE=0.2758, R²=0.0652
   Val:   Loss=0.0837, RMSE=0.2893, R²=0.0437
============================================================


📊 Round 196 Test Metrics:
   Loss: 0.0763, RMSE: 0.2763, MAE: 0.2396, R²: 0.0804

============================================================
🔄 Round 199 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0771, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0771, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0771, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0771, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0770, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0769, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 199 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0773, RMSE=0.2781, R²=0.0612
   Val:   Loss=0.0787, RMSE=0.2806, R²=0.0489
============================================================


============================================================
🔄 Round 200 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0764, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0764, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0764, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0764, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0764, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0763, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 200 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0764, RMSE=0.2765, R²=0.0594
   Val:   Loss=0.0822, RMSE=0.2868, R²=0.0679
============================================================


============================================================
🔄 Round 201 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0765, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0765, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0765, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0765, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0765, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0765, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 201 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0765, RMSE=0.2766, R²=0.0562
   Val:   Loss=0.0819, RMSE=0.2863, R²=0.0780
============================================================


📊 Round 201 Test Metrics:
   Loss: 0.0763, RMSE: 0.2763, MAE: 0.2396, R²: 0.0804

============================================================
🔄 Round 202 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0775, val=0.0774 (↓), lr=0.000001
   • Epoch   2/100: train=0.0775, val=0.0774, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0775, val=0.0774, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0775, val=0.0774, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0775, val=0.0774, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0774, val=0.0773, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0774)

============================================================
📊 Round 202 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0776, RMSE=0.2786, R²=0.0562
   Val:   Loss=0.0774, RMSE=0.2782, R²=0.0806
============================================================


📊 Round 202 Test Metrics:
   Loss: 0.0763, RMSE: 0.2763, MAE: 0.2396, R²: 0.0804

📊 Round 202 Test Metrics:
   Loss: 0.0763, RMSE: 0.2763, MAE: 0.2396, R²: 0.0803

============================================================
🔄 Round 205 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0774, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0774, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0774, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0774, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0773, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0773, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 205 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0774, RMSE=0.2782, R²=0.0677
   Val:   Loss=0.0784, RMSE=0.2801, R²=0.0325
============================================================


============================================================
🔄 Round 209 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0775, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0775, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0775, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0775, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0774, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0774, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 209 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0774, RMSE=0.2783, R²=0.0581
   Val:   Loss=0.0783, RMSE=0.2798, R²=0.0703
============================================================


============================================================
🔄 Round 213 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0695 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0695, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0695, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0695, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0695, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0694, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0695)

============================================================
📊 Round 213 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2821, R²=0.0638
   Val:   Loss=0.0695, RMSE=0.2636, R²=0.0484
============================================================


📊 Round 213 Test Metrics:
   Loss: 0.0763, RMSE: 0.2763, MAE: 0.2396, R²: 0.0804

============================================================
🔄 Round 220 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0738 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0738, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0785, val=0.0738, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0785, val=0.0738, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0785, val=0.0738, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0738, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0738)

============================================================
📊 Round 220 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2802, R²=0.0581
   Val:   Loss=0.0738, RMSE=0.2717, R²=0.0658
============================================================


============================================================
🔄 Round 223 - Client client_34
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0758, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0758, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0758, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0758, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0758, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0757, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 223 Summary - Client client_34
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0759, RMSE=0.2755, R²=0.0652
   Val:   Loss=0.0843, RMSE=0.2904, R²=0.0464
============================================================


📊 Round 223 Test Metrics:
   Loss: 0.0763, RMSE: 0.2763, MAE: 0.2396, R²: 0.0805

📊 Round 223 Test Metrics:
   Loss: 0.0763, RMSE: 0.2762, MAE: 0.2396, R²: 0.0805

❌ Client client_34 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8687 {grpc_status:14, grpc_message:"Socket closed"}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8687 {grpc_status:14, grpc_message:"Socket closed"}"
>
