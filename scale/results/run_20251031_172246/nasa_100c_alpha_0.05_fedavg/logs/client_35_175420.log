[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4dfbd624-64d9-4205-b9f6-f25bbe89105d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2c560f10-ca7d-43ea-8cb3-fffa810b6bd6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2cb2f0ed-c2a8-447d-9361-52e55a12632d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2c3ff79b-bb55-44dd-90b2-929f62df47da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b7fe4091-5fae-423b-b6d0-ecadfd89ac7d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e8fc6d32-04c4-4f49-be6b-8bd4e0088f33
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 80c95369-4168-491b-87ca-039261e988d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e30465eb-3715-47df-8e13-17495d169e3b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 847d3781-d07d-47b2-8ed4-d7e48de5cadb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f0489306-d40d-49f3-93c2-3a15912a2b04
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 843f729e-a9cb-4aa3-b34c-bd0eb97b87b6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d5d6dc4c-4fd6-4980-99a7-b78607032bcf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0dce90ae-8fb9-4f6d-a4f7-cef8fde4a5c3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ee18377b-dd32-4ffc-a2a5-0501afeef7e6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a13ddb49-f93c-4f18-9b3d-b6472289af40
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c40e7526-566b-4903-ba7b-2861206cd0f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4daee43c-7ca2-4eb4-8cfe-8255b3bf2b98
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1365daee-9101-4d12-9996-5d3f12b66378
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 20041ba3-3747-4e66-98c1-eaa6422880bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message de2e61e2-b456-45c9-ab8b-fdeddb24f136
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 51002a73-9a29-4294-891a-6aaed8c1634b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b4889cc2-8451-4214-bdea-4d34f7eac69e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7f2d910c-9b93-4b82-a345-b1bd91c6cd2e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 29bec561-b7f0-4076-9e9f-17b297d35b23
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0adb89a0-8584-4968-89f1-2c37e73877e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a92e99b8-5e58-418b-a335-b3f3e1d71d61
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 96911c59-d57e-4681-b10e-5b1377d5ea80
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e9d7d9b0-4373-4ad9-a228-c4187747e732
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 137053c1-650a-477d-b74e-d1ec3da27942
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 63787de4-2fdb-4bcf-b006-28183d82b25a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d217e560-080e-46a0-b0d3-e55db31dfc84
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 296fa96d-3f2f-46ac-af4b-68f1f871613a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 784ff4b3-2ff2-497b-892b-4fd26df3692b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 21095afb-46f9-48fc-9478-d9baf4b3f40a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 45a337d6-b01e-402a-976a-7d7fe7537ffe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8ba9d96a-d7df-4071-bd90-8217ed7ebd57
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b9841f9d-30ac-47ff-b782-6bacc1d5a8a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d91f664a-9847-42a0-8791-0393229c79b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d66a6a93-e396-41ab-b146-52d6eabb9c1c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message db0c9ffc-ce2f-48d4-b3aa-bd86683af66f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 152683ce-0db2-4ff9-a8c5-cab7530a50a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 67f902f7-d3a8-4445-9042-afc03051db99
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ab8a2700-555b-442d-a99f-ef2ab4380edd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7e35a893-f7d4-4b06-bd3c-4c1d01253030
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ab1ec3dd-eb04-4fa0-9e50-bac7e321c023
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f825f7b9-58db-4109-9cff-9f4663cf58cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 324b1368-e2e6-4178-8e3f-dda88f229019
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f3d094df-19ed-4f7b-a6a2-f64ae4780256
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d5aaf04a-6181-4f44-8652-6217005fa4dd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 632c5d02-8b7d-4775-a6eb-f384dce5b8da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 44824bb3-e6b1-4a56-8a4c-59c9bc4576e8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dbaa4596-c9e9-4a33-9c05-a07625f409f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1cc78aeb-f92c-43ff-8a3b-e639ce3774fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e3f71a94-4897-4665-9af3-572f0d34c1b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 913538d3-43a1-42e2-b102-cac7acb35d1b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b99a6d13-b7d1-4b03-a875-43d47150a741
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a95bc517-924e-446e-a5e4-94a9f74693fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c7ffcdaf-1845-4217-a17a-22b9b019aef5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 54ff746b-8f30-4db0-acf9-33b4941874fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d6e94908-e5f0-4b72-b6f8-7a9dfcb669a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cac67a30-f892-41fc-baff-0126af91dc9d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3fdc8950-5d7a-4697-8b2e-c1c6f25eb65d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d23b4d3c-8040-43cb-a665-da4a35fa5b3e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2a648d43-8f75-4c44-b6c2-858374c99db8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ec8e7232-1bf8-4d7d-b343-379eb63fe953
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 72ab2dfc-4ef8-493a-9952-8d8e3beb8f93
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 37428ef2-a731-4129-90a1-0835a3cc28d9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c95fbf69-1d42-4056-be9c-93fab7e09919
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2104824f-56c7-4045-b287-57b96099609d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 29dcfaf5-d049-43db-a977-444b7da851a3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c49b646c-20a7-475d-b213-c2e3ce82464c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e9a51657-b930-4738-93f8-04b3dbc8f5f7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e78380ea-2a88-400e-ae3a-b63be455578d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 21a32bf1-dc56-4094-a3ee-debd98945405
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ba2960ce-eec7-42e9-8c96-15bb6f325f20
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6ee7e0ae-48c1-4486-9263-0aad47dd4e73
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 57e8f229-fd9f-4ca5-855d-b65256179df9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 78aab521-8d19-4cb6-bb31-67a153813529
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 542446eb-dec4-4760-a339-7fd0d4b98e49
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5f6afe93-d490-4a1a-ae47-9b46e072d794
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 136a816a-d684-4ad4-ade1-df1f92c62ea3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 18d8c42b-4fad-426f-be8f-0b5cc1dd6700
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d7630f28-cfd1-4af8-a9ce-d8422e7bbb6b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 98693c95-02e5-42bf-b7e2-e0f1e2df43e1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f2de9073-2809-4dbd-aba3-6bf0c38c3d21
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e7019e68-63be-48aa-a9d1-902f00af6a37
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0984d991-a723-4590-b44c-9c416bbea895
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 485ceb51-b7a7-4372-8b48-7811eb9f217a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 79f24eb9-4b2b-4b25-a22f-861219b1f877
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 57b2ef59-fff3-4ec6-b6ab-9093dd6199a7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 933ecc5f-eea4-47ec-bf2f-159101601926
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c383618c-0aff-4e01-ad08-584b97977c66
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4fb06e6f-911e-486a-91a6-40d9d838a04d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fcda1f1b-67fc-4abe-aa2b-744776fab06a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dc6578f9-074f-43da-bf31-c9948f0fe05c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 35bd6334-277c-4f63-b63b-52525d8cde20
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8c89c2df-b706-4467-8b55-83b758a61bca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0210abce-f3b2-47bd-a7fc-e2e32cbe3f8a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c6053bc0-513b-40dd-a161-60a7327a808b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 52632a61-f9f5-49e2-8b68-74f9f1938baf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1eca899f-c332-441f-b863-9c53f801008e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 799a7623-da05-421a-9409-857d89055bea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 53c45f81-664f-44ae-978b-3ef891a10993
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0a6b3334-fb00-4444-af09-8ca3a1138967
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9e893123-8a8a-43a2-aef5-40d3faf347ea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 54f7716c-6ff1-442b-9102-37e62bc26ae0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 27b64142-2ede-49c3-a55b-db7b2838d329
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aed821ae-6f47-4ef9-800c-8d0ff838f02e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2961593a-3194-49cf-a287-e8a1ade43793
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c6b341d3-0613-404c-a8fc-5bca947bbaf7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4213b9a6-d450-434d-a528-aac6f1513714
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0d0f75e7-ab90-4990-bf2a-d04e7b7690aa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3d0192ef-d7e8-41b7-94db-3bf2c6a26c66
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f06b1ee0-5971-4ffa-a4d4-6658b4c9c9a7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f40fb908-4b01-44c6-88ca-177521c6058d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4146e236-29b5-4ec9-8d42-43c1fa63e22f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c3c7a0a4-0588-4e8b-abbb-f70edbb00d03
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a0e95e4e-82be-4778-8708-db1d91e9019c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 88d3d1d3-815f-46b3-8f45-87359a4caadf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 349b7f4b-3455-4407-b989-37cb8382d7c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d5b37432-1da5-4497-b0ed-afc00fb5ca9a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3a30f7b6-5db1-4c69-aa8c-092f6aeb2f9a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 21b34342-9b78-472f-b70b-89b29ee43eb0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b13d3896-7949-4890-99ba-ee5ca7912019
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c8b93730-c367-48d0-9c95-237b36883729
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 459c20cf-bc8c-4a20-8122-d88a76c97eea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 136158f9-7e3f-45f6-88bd-6f5645205ea2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 420b3e95-7e31-4c32-a605-d93f8325da0c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 33067ed1-6032-4898-951c-8bf52c87f5e6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e3ff5d0f-e446-4227-add9-77ffa088674d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f5fc9fc5-5474-4311-945e-1dc6ad752e43
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a8a8ce70-6847-438e-a3ef-e7e4d8bb5be7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 94b3fb78-7922-45f8-97b2-c3c03520c898
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7ac270b9-0f9a-4d2e-8d12-de332a39503c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aa08b935-c6db-48fb-a0db-137b58f194f4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f94f3036-b616-4049-8355-55dac409919c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f265b3e6-8743-404c-b5e0-088a93313be5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ca6e1476-4eb9-45e0-b43a-a50319132915
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 86cf38a7-0fa6-4c0b-b9b1-f1cccdbf2c19
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4c968d3a-f02c-4595-a832-4c87391eb2b0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1e11b596-cc4e-45ba-bb08-4491c150774f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 81298aad-eac3-4df7-9b91-43f45b3e1146
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 542cdd8b-7911-4350-9ee6-170b8b3e2add
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 78fe1aea-fa42-4709-a6b6-47df56da50e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5d7a430e-a3a5-451a-bc0f-499db87e7a26
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8c13911f-a48b-40a3-8a3d-7d2b0eb7ad26
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8b24d4c1-21f0-4256-83ec-a0ee1968d165
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7c4f16dc-27f0-44ef-a59e-9aff74d6f30a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 65595225-25c4-4c1e-bd26-8c7e67ffb80e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0299e39e-6e91-4bf9-ab81-3a3a4df11925
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dabc2682-0c3b-47ce-a2bf-b07a37cc8da4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 28cd1999-3314-4362-8671-09c027c0cc3f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fe737f13-a228-4503-a29c-d1fd3659694e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f5ed3c67-bae3-4456-9bf0-f5706f627aa5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9e45b312-b38c-4a58-9c6a-78b5e9a05522
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d3a30c24-287a-4e4a-b8c3-00176aa465b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2c3790cb-c627-4f79-a3a6-729800373954
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 865d238a-8111-4326-a462-1fae426066c9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5aa922ee-2db0-4635-9d7a-2d56b8302fd0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bdcd5285-25ad-4359-a601-6d8462fc4ec5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0981a50f-2629-46b3-9390-374e5865ddb0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b89d889a-6b5c-48ab-b2e3-a86f86ae37b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0ff06a49-e1dd-410f-a217-3636b46c5978
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c671bea4-e033-4457-91a3-9b31809577c7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a2270dc9-b589-41e8-a34c-51799d5f73c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 71cf12c0-4bcb-4b9c-8d0a-4e1ea852f2c5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e53d1878-4ea0-4bd2-a4f2-246fa7ea69d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 78a6bbed-04d2-40c1-98e2-0d4fdcef7c6a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 98944002-2a60-4e9b-97eb-a1d562311044
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0b4f571d-a12f-4527-889e-71f76e46d099
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c5d650cc-816a-4308-8eb8-723e5ae35e68
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b001763b-0fd5-4e48-a789-6374697ef5cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e991d4a2-39d4-4a43-a626-f1705491c8ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ba09e55c-87d7-4eb0-bd6f-85bc4dee3f3b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 011ba07a-9ccb-40c4-9dfb-38f881efec5a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e1922402-6db1-4dd7-bcbb-903a1454175a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4edfa294-9c15-435f-86bf-804f50a5c26c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 574a5779-1189-45d7-a174-4b30e17ff2db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f050d559-237a-417a-86fa-cee5a655e615
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ca5e6920-716b-4f8a-abf4-215e67059435
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 02af8f1e-05ce-476c-8ad6-24251165b76e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2881bd86-58d6-45b9-b4e0-e82c9632a06d
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8687 {grpc_message:"Socket closed", grpc_status:14}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_35
Server: localhost:8687
Algorithm: FEDAVG
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_35
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_35/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_35/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_35/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_35/test_labels.txt

📊 Raw data loaded:
   Train: X=(1627, 24), y=(1627,)
   Test:  X=(407, 24), y=(407,)

⚠️  Limiting training data: 1627 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  398 samples, 5 features
✅ Client client_35 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

📊 Round 0 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2464, R²: 0.0057

📊 Round 0 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2457, R²: 0.0116

📊 Round 0 Test Metrics:
   Loss: 0.0794, RMSE: 0.2817, MAE: 0.2452, R²: 0.0159

============================================================
🔄 Round 7 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0877, val=0.0859 (↓), lr=0.001000
   • Epoch   2/100: train=0.0857, val=0.0869, patience=1/15, lr=0.001000
   ✓ Epoch   3/100: train=0.0852, val=0.0852 (↓), lr=0.001000
   ✓ Epoch   4/100: train=0.0842, val=0.0845 (↓), lr=0.001000
   • Epoch   5/100: train=0.0834, val=0.0844, patience=1/15, lr=0.001000
   📉 Epoch 11: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0806, val=0.0859, patience=7/15, lr=0.000500
   📉 Epoch 19: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 7 Summary - Client client_35
   Epochs: 19/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0830, RMSE=0.2882, R²=0.0404
   Val:   Loss=0.0845, RMSE=0.2907, R²=-0.0229
============================================================


📊 Round 7 Test Metrics:
   Loss: 0.0785, RMSE: 0.2803, MAE: 0.2439, R²: 0.0262

📊 Round 7 Test Metrics:
   Loss: 0.0783, RMSE: 0.2798, MAE: 0.2436, R²: 0.0292

============================================================
🔄 Round 10 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0845 (↓), lr=0.000250
   • Epoch   2/100: train=0.0837, val=0.0844, patience=1/15, lr=0.000250
   • Epoch   3/100: train=0.0833, val=0.0844, patience=2/15, lr=0.000250
   • Epoch   4/100: train=0.0831, val=0.0845, patience=3/15, lr=0.000250
   • Epoch   5/100: train=0.0829, val=0.0845, patience=4/15, lr=0.000250
   📉 Epoch 8: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0820, val=0.0849, patience=10/15, lr=0.000125
   📉 Epoch 16: LR reduced 0.000125 → 0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 10 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000250 → 0.000063 (2 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=0.0222
   Val:   Loss=0.0845, RMSE=0.2907, R²=0.0296
============================================================


============================================================
🔄 Round 11 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0792 (↓), lr=0.000063
   • Epoch   2/100: train=0.0849, val=0.0791, patience=1/15, lr=0.000063
   • Epoch   3/100: train=0.0847, val=0.0791, patience=2/15, lr=0.000063
   • Epoch   4/100: train=0.0845, val=0.0791, patience=3/15, lr=0.000063
   • Epoch   5/100: train=0.0844, val=0.0792, patience=4/15, lr=0.000063
   📉 Epoch 9: LR reduced 0.000063 → 0.000031
   • Epoch  11/100: train=0.0838, val=0.0794, patience=10/15, lr=0.000031

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 11 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000063 → 0.000031 (1 reductions)
   Train: Loss=0.0850, RMSE=0.2916, R²=0.0243
   Val:   Loss=0.0792, RMSE=0.2814, R²=0.0078
============================================================


============================================================
🔄 Round 15 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000031
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   📉 Epoch 1: LR reduced 0.000031 → 0.000016
   ✓ Epoch   1/100: train=0.0837, val=0.0851 (↓), lr=0.000016
   • Epoch   2/100: train=0.0835, val=0.0851, patience=1/15, lr=0.000016
   • Epoch   3/100: train=0.0834, val=0.0852, patience=2/15, lr=0.000016
   • Epoch   4/100: train=0.0833, val=0.0853, patience=3/15, lr=0.000016
   • Epoch   5/100: train=0.0833, val=0.0853, patience=4/15, lr=0.000016
   📉 Epoch 9: LR reduced 0.000016 → 0.000008
   • Epoch  11/100: train=0.0829, val=0.0855, patience=10/15, lr=0.000008

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 15 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000031 → 0.000008 (2 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=0.0256
   Val:   Loss=0.0851, RMSE=0.2916, R²=0.0104
============================================================


📊 Round 15 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2433, R²: 0.0315

============================================================
🔄 Round 16 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000008
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0752 (↓), lr=0.000008
   • Epoch   2/100: train=0.0860, val=0.0752, patience=1/15, lr=0.000008
   • Epoch   3/100: train=0.0859, val=0.0752, patience=2/15, lr=0.000008
   • Epoch   4/100: train=0.0859, val=0.0753, patience=3/15, lr=0.000008
   • Epoch   5/100: train=0.0859, val=0.0753, patience=4/15, lr=0.000008
   📉 Epoch 7: LR reduced 0.000008 → 0.000004
   • Epoch  11/100: train=0.0857, val=0.0753, patience=10/15, lr=0.000004
   📉 Epoch 15: LR reduced 0.000004 → 0.000002

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0752)

============================================================
📊 Round 16 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000008 → 0.000002 (2 reductions)
   Train: Loss=0.0860, RMSE=0.2933, R²=0.0144
   Val:   Loss=0.0752, RMSE=0.2742, R²=0.0511
============================================================


📊 Round 16 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2433, R²: 0.0316

📊 Round 16 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2434, R²: 0.0314

============================================================
🔄 Round 18 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000002
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0775 (↓), lr=0.000002
   • Epoch   2/100: train=0.0855, val=0.0775, patience=1/15, lr=0.000002
   • Epoch   3/100: train=0.0855, val=0.0775, patience=2/15, lr=0.000002
   • Epoch   4/100: train=0.0855, val=0.0775, patience=3/15, lr=0.000002
   • Epoch   5/100: train=0.0855, val=0.0775, patience=4/15, lr=0.000002
   📉 Epoch 7: LR reduced 0.000002 → 0.000001
   • Epoch  11/100: train=0.0854, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 18 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000002 → 0.000001 (1 reductions)
   Train: Loss=0.0855, RMSE=0.2925, R²=0.0110
   Val:   Loss=0.0775, RMSE=0.2784, R²=0.0611
============================================================


📊 Round 18 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2433, R²: 0.0316

============================================================
🔄 Round 19 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0908 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0908, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0908, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0908, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0908, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0908, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0908)

============================================================
📊 Round 19 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2868, R²=0.0274
   Val:   Loss=0.0908, RMSE=0.3013, R²=-0.0048
============================================================


============================================================
🔄 Round 21 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0889 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0889, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0889, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0889, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0889, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0890, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0889)

============================================================
📊 Round 21 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=0.0176
   Val:   Loss=0.0889, RMSE=0.2982, R²=0.0296
============================================================


📊 Round 21 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2433, R²: 0.0316

============================================================
🔄 Round 22 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0940 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0940, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0940, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0940, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0940, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0940, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0940)

============================================================
📊 Round 22 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2854, R²=0.0246
   Val:   Loss=0.0940, RMSE=0.3066, R²=0.0084
============================================================


📊 Round 22 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2433, R²: 0.0317

📊 Round 22 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2433, R²: 0.0317

📊 Round 22 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2433, R²: 0.0317

============================================================
🔄 Round 28 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 28 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2916, R²=0.0228
   Val:   Loss=0.0796, RMSE=0.2821, R²=0.0132
============================================================


📊 Round 28 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2433, R²: 0.0315

📊 Round 28 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2433, R²: 0.0316

📊 Round 28 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2433, R²: 0.0316

============================================================
🔄 Round 32 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0762 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0762, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0762, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0761, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0761, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0761, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0762)

============================================================
📊 Round 32 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2931, R²=0.0194
   Val:   Loss=0.0762, RMSE=0.2760, R²=0.0281
============================================================


============================================================
🔄 Round 34 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0921 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0921, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0921, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0921, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0921, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0921, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0921)

============================================================
📊 Round 34 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=0.0209
   Val:   Loss=0.0921, RMSE=0.3035, R²=0.0194
============================================================


📊 Round 34 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2433, R²: 0.0316

============================================================
🔄 Round 35 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0891 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0891, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0891, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0891, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0891, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0891, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0891)

============================================================
📊 Round 35 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2875, R²=0.0168
   Val:   Loss=0.0891, RMSE=0.2985, R²=0.0331
============================================================


📊 Round 35 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2433, R²: 0.0316

📊 Round 35 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2433, R²: 0.0316

============================================================
🔄 Round 38 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 38 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=0.0214
   Val:   Loss=0.0818, RMSE=0.2859, R²=0.0182
============================================================


📊 Round 38 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2433, R²: 0.0316

📊 Round 38 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2433, R²: 0.0317

📊 Round 38 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2433, R²: 0.0317

📊 Round 38 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2433, R²: 0.0317

============================================================
🔄 Round 45 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0949 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0949, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0949, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0949, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0949, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0948, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0949)

============================================================
📊 Round 45 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=0.0173
   Val:   Loss=0.0949, RMSE=0.3080, R²=0.0336
============================================================


📊 Round 45 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2433, R²: 0.0317

📊 Round 45 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2433, R²: 0.0316

============================================================
🔄 Round 49 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 49 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=0.0208
   Val:   Loss=0.0810, RMSE=0.2846, R²=0.0120
============================================================


📊 Round 49 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2433, R²: 0.0316

📊 Round 49 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2433, R²: 0.0317

📊 Round 49 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2433, R²: 0.0316

📊 Round 49 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2433, R²: 0.0315

============================================================
🔄 Round 58 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 58 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=0.0198
   Val:   Loss=0.0857, RMSE=0.2927, R²=0.0199
============================================================


📊 Round 58 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2433, R²: 0.0315

============================================================
🔄 Round 60 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0915 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0915, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0915, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0915, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0915, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0915, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0915)

============================================================
📊 Round 60 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=0.0203
   Val:   Loss=0.0915, RMSE=0.3025, R²=0.0230
============================================================


============================================================
🔄 Round 61 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 61 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2906, R²=0.0209
   Val:   Loss=0.0820, RMSE=0.2863, R²=0.0218
============================================================


📊 Round 61 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2433, R²: 0.0315

📊 Round 61 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2433, R²: 0.0316

============================================================
🔄 Round 63 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0776 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0776, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0777, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0777, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0777, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0777, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 63 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2924, R²=0.0135
   Val:   Loss=0.0776, RMSE=0.2786, R²=0.0317
============================================================


📊 Round 63 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2433, R²: 0.0316

============================================================
🔄 Round 64 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 64 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2904, R²=0.0225
   Val:   Loss=0.0824, RMSE=0.2871, R²=0.0155
============================================================


📊 Round 64 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2433, R²: 0.0316

============================================================
🔄 Round 69 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 69 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2904, R²=0.0173
   Val:   Loss=0.0824, RMSE=0.2870, R²=0.0276
============================================================


📊 Round 69 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2433, R²: 0.0317

📊 Round 69 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2433, R²: 0.0318

============================================================
🔄 Round 73 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 73 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2920, R²=0.0227
   Val:   Loss=0.0787, RMSE=0.2805, R²=0.0076
============================================================


============================================================
🔄 Round 75 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0884 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0884, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0884, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0884, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0884, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0884, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0884)

============================================================
📊 Round 75 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=0.0188
   Val:   Loss=0.0884, RMSE=0.2973, R²=0.0276
============================================================


============================================================
🔄 Round 76 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0779 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0779, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0779, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0779, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0779, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0779, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0779)

============================================================
📊 Round 76 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2923, R²=0.0175
   Val:   Loss=0.0779, RMSE=0.2791, R²=0.0207
============================================================


============================================================
🔄 Round 77 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0749 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0749, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0749, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0749, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0749, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0750, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0749)

============================================================
📊 Round 77 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2936, R²=0.0207
   Val:   Loss=0.0749, RMSE=0.2737, R²=0.0112
============================================================


📊 Round 77 Test Metrics:
   Loss: 0.0781, RMSE: 0.2794, MAE: 0.2433, R²: 0.0318

📊 Round 77 Test Metrics:
   Loss: 0.0781, RMSE: 0.2794, MAE: 0.2433, R²: 0.0318

============================================================
🔄 Round 80 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0759 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0759, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0759, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0759, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0759, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0759, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0759)

============================================================
📊 Round 80 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2932, R²=0.0199
   Val:   Loss=0.0759, RMSE=0.2755, R²=0.0201
============================================================


============================================================
🔄 Round 83 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 83 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=0.0161
   Val:   Loss=0.0833, RMSE=0.2887, R²=0.0409
============================================================


📊 Round 83 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2433, R²: 0.0318

============================================================
🔄 Round 86 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0887 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0887, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0887, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0887, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0887, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0887, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0887)

============================================================
📊 Round 86 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=0.0146
   Val:   Loss=0.0887, RMSE=0.2978, R²=0.0403
============================================================


============================================================
🔄 Round 87 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0870 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0870, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0870, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0870, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0870, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0870, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 87 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=0.0224
   Val:   Loss=0.0870, RMSE=0.2950, R²=0.0017
============================================================


📊 Round 87 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2433, R²: 0.0318

📊 Round 87 Test Metrics:
   Loss: 0.0781, RMSE: 0.2794, MAE: 0.2433, R²: 0.0318

📊 Round 87 Test Metrics:
   Loss: 0.0781, RMSE: 0.2794, MAE: 0.2433, R²: 0.0318

📊 Round 87 Test Metrics:
   Loss: 0.0781, RMSE: 0.2794, MAE: 0.2433, R²: 0.0319

============================================================
🔄 Round 92 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 92 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2919, R²=0.0214
   Val:   Loss=0.0788, RMSE=0.2807, R²=0.0170
============================================================


============================================================
🔄 Round 93 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 93 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2896, R²=0.0237
   Val:   Loss=0.0843, RMSE=0.2904, R²=-0.0043
============================================================


📊 Round 93 Test Metrics:
   Loss: 0.0781, RMSE: 0.2794, MAE: 0.2433, R²: 0.0318

============================================================
🔄 Round 95 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0898 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0898, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0898, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0898, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0898, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0897, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0898)

============================================================
📊 Round 95 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=0.0244
   Val:   Loss=0.0898, RMSE=0.2996, R²=0.0080
============================================================


============================================================
🔄 Round 96 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0889 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0889, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0889, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0889, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0889, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0889, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0889)

============================================================
📊 Round 96 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=0.0264
   Val:   Loss=0.0889, RMSE=0.2982, R²=0.0005
============================================================


📊 Round 96 Test Metrics:
   Loss: 0.0781, RMSE: 0.2794, MAE: 0.2433, R²: 0.0319

============================================================
🔄 Round 97 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 97 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2894, R²=0.0223
   Val:   Loss=0.0846, RMSE=0.2909, R²=-0.0006
============================================================


📊 Round 97 Test Metrics:
   Loss: 0.0781, RMSE: 0.2794, MAE: 0.2433, R²: 0.0319

============================================================
🔄 Round 99 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0723 (↓), lr=0.000001
   • Epoch   2/100: train=0.0867, val=0.0723, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0867, val=0.0723, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0723, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0723, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0866, val=0.0723, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0723)

============================================================
📊 Round 99 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2947, R²=0.0153
   Val:   Loss=0.0723, RMSE=0.2690, R²=0.0413
============================================================


📊 Round 99 Test Metrics:
   Loss: 0.0781, RMSE: 0.2794, MAE: 0.2433, R²: 0.0319

============================================================
🔄 Round 100 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0882 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0882, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0882, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0882, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0882, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0882, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0882)

============================================================
📊 Round 100 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=0.0225
   Val:   Loss=0.0882, RMSE=0.2969, R²=-0.0018
============================================================


============================================================
🔄 Round 101 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0903 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0903, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0903, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0903, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0903, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0903, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0903)

============================================================
📊 Round 101 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=0.0235
   Val:   Loss=0.0903, RMSE=0.3004, R²=0.0064
============================================================


📊 Round 101 Test Metrics:
   Loss: 0.0781, RMSE: 0.2794, MAE: 0.2433, R²: 0.0319

============================================================
🔄 Round 103 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0916 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0916, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0917, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0917, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0917, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0917, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0916)

============================================================
📊 Round 103 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=0.0248
   Val:   Loss=0.0916, RMSE=0.3027, R²=-0.0145
============================================================


📊 Round 103 Test Metrics:
   Loss: 0.0781, RMSE: 0.2794, MAE: 0.2433, R²: 0.0320

============================================================
🔄 Round 104 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 104 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=0.0186
   Val:   Loss=0.0854, RMSE=0.2923, R²=0.0272
============================================================


📊 Round 104 Test Metrics:
   Loss: 0.0781, RMSE: 0.2794, MAE: 0.2433, R²: 0.0320

📊 Round 104 Test Metrics:
   Loss: 0.0781, RMSE: 0.2794, MAE: 0.2433, R²: 0.0320

============================================================
🔄 Round 111 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0885 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0885, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0885, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0885, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0885, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0886, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0885)

============================================================
📊 Round 111 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=0.0176
   Val:   Loss=0.0885, RMSE=0.2974, R²=0.0205
============================================================


============================================================
🔄 Round 112 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0924 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0924, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0924, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0924, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0924, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0924, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0924)

============================================================
📊 Round 112 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=0.0242
   Val:   Loss=0.0924, RMSE=0.3040, R²=0.0087
============================================================


============================================================
🔄 Round 114 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0887 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0887, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0887, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0888, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0888, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0889, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0887)

============================================================
📊 Round 114 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=0.0139
   Val:   Loss=0.0887, RMSE=0.2978, R²=0.0180
============================================================


============================================================
🔄 Round 115 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 115 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=0.0244
   Val:   Loss=0.0839, RMSE=0.2897, R²=-0.0040
============================================================


============================================================
🔄 Round 118 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 118 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2919, R²=0.0228
   Val:   Loss=0.0788, RMSE=0.2807, R²=0.0063
============================================================


📊 Round 118 Test Metrics:
   Loss: 0.0781, RMSE: 0.2794, MAE: 0.2432, R²: 0.0322

============================================================
🔄 Round 119 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 119 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=0.0213
   Val:   Loss=0.0811, RMSE=0.2849, R²=0.0091
============================================================


📊 Round 119 Test Metrics:
   Loss: 0.0781, RMSE: 0.2794, MAE: 0.2432, R²: 0.0322

============================================================
🔄 Round 120 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 120 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2903, R²=0.0237
   Val:   Loss=0.0827, RMSE=0.2876, R²=-0.0210
============================================================


📊 Round 120 Test Metrics:
   Loss: 0.0781, RMSE: 0.2794, MAE: 0.2432, R²: 0.0322

============================================================
🔄 Round 121 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0740 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0740, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0740, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0740, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0740, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0866, val=0.0740, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0740)

============================================================
📊 Round 121 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2940, R²=0.0252
   Val:   Loss=0.0740, RMSE=0.2720, R²=0.0027
============================================================


📊 Round 121 Test Metrics:
   Loss: 0.0781, RMSE: 0.2794, MAE: 0.2432, R²: 0.0322

============================================================
🔄 Round 123 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0753 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0753, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0753, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0753, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0753, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0754, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0753)

============================================================
📊 Round 123 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2934, R²=0.0206
   Val:   Loss=0.0753, RMSE=0.2745, R²=0.0228
============================================================


============================================================
🔄 Round 124 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0760 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0760, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0760, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0760, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0760, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0760, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0760)

============================================================
📊 Round 124 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2931, R²=0.0208
   Val:   Loss=0.0760, RMSE=0.2757, R²=0.0207
============================================================


============================================================
🔄 Round 126 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 126 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=0.0270
   Val:   Loss=0.0817, RMSE=0.2858, R²=-0.0050
============================================================


============================================================
🔄 Round 127 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0767 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0767, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0767, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0767, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0767, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0767, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0767)

============================================================
📊 Round 127 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2928, R²=0.0192
   Val:   Loss=0.0767, RMSE=0.2770, R²=0.0307
============================================================


============================================================
🔄 Round 128 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0740 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0740, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0740, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0740, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0740, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0740, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0740)

============================================================
📊 Round 128 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2940, R²=0.0227
   Val:   Loss=0.0740, RMSE=0.2720, R²=0.0074
============================================================


📊 Round 128 Test Metrics:
   Loss: 0.0781, RMSE: 0.2794, MAE: 0.2433, R²: 0.0320

============================================================
🔄 Round 132 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 132 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2920, R²=0.0193
   Val:   Loss=0.0786, RMSE=0.2804, R²=0.0265
============================================================


============================================================
🔄 Round 134 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 134 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2894, R²=0.0241
   Val:   Loss=0.0846, RMSE=0.2909, R²=0.0020
============================================================


============================================================
🔄 Round 138 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0780 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0780, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0780, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0780, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0780, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0779, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 138 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2922, R²=0.0234
   Val:   Loss=0.0780, RMSE=0.2792, R²=0.0121
============================================================


📊 Round 138 Test Metrics:
   Loss: 0.0781, RMSE: 0.2794, MAE: 0.2433, R²: 0.0320

============================================================
🔄 Round 139 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0902 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0902, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0902, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0902, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0902, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0902, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0902)

============================================================
📊 Round 139 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2870, R²=0.0248
   Val:   Loss=0.0902, RMSE=0.3004, R²=0.0083
============================================================


📊 Round 139 Test Metrics:
   Loss: 0.0781, RMSE: 0.2794, MAE: 0.2433, R²: 0.0320

============================================================
🔄 Round 140 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0776, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0776, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0777, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 140 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2924, R²=0.0181
   Val:   Loss=0.0775, RMSE=0.2784, R²=0.0022
============================================================


📊 Round 140 Test Metrics:
   Loss: 0.0781, RMSE: 0.2794, MAE: 0.2433, R²: 0.0320

============================================================
🔄 Round 141 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 141 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2917, R²=0.0221
   Val:   Loss=0.0793, RMSE=0.2816, R²=0.0185
============================================================


📊 Round 141 Test Metrics:
   Loss: 0.0781, RMSE: 0.2794, MAE: 0.2433, R²: 0.0321

============================================================
🔄 Round 144 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 144 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2918, R²=0.0257
   Val:   Loss=0.0791, RMSE=0.2812, R²=0.0013
============================================================


============================================================
🔄 Round 146 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 146 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2896, R²=0.0122
   Val:   Loss=0.0841, RMSE=0.2899, R²=0.0560
============================================================


📊 Round 146 Test Metrics:
   Loss: 0.0781, RMSE: 0.2794, MAE: 0.2433, R²: 0.0321

📊 Round 146 Test Metrics:
   Loss: 0.0781, RMSE: 0.2794, MAE: 0.2433, R²: 0.0321

============================================================
🔄 Round 148 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 148 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=0.0225
   Val:   Loss=0.0811, RMSE=0.2848, R²=0.0100
============================================================


📊 Round 148 Test Metrics:
   Loss: 0.0781, RMSE: 0.2794, MAE: 0.2432, R²: 0.0321

============================================================
🔄 Round 149 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 149 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2896, R²=0.0221
   Val:   Loss=0.0840, RMSE=0.2899, R²=0.0186
============================================================


📊 Round 149 Test Metrics:
   Loss: 0.0781, RMSE: 0.2794, MAE: 0.2433, R²: 0.0320

============================================================
🔄 Round 150 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 150 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=0.0198
   Val:   Loss=0.0861, RMSE=0.2934, R²=0.0268
============================================================


============================================================
🔄 Round 151 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0724 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0724, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0724, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0724, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0724, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0724, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0724)

============================================================
📊 Round 151 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2946, R²=0.0230
   Val:   Loss=0.0724, RMSE=0.2691, R²=0.0077
============================================================


============================================================
🔄 Round 152 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 152 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2917, R²=0.0166
   Val:   Loss=0.0792, RMSE=0.2813, R²=0.0387
============================================================


============================================================
🔄 Round 155 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0874 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0874, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0874, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0874, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0874, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0874, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0874)

============================================================
📊 Round 155 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2882, R²=0.0192
   Val:   Loss=0.0874, RMSE=0.2956, R²=0.0302
============================================================


📊 Round 155 Test Metrics:
   Loss: 0.0781, RMSE: 0.2794, MAE: 0.2433, R²: 0.0321

============================================================
🔄 Round 156 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0877 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0877, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0877, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0877, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0877, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0877, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0877)

============================================================
📊 Round 156 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2880, R²=0.0220
   Val:   Loss=0.0877, RMSE=0.2962, R²=0.0152
============================================================


📊 Round 156 Test Metrics:
   Loss: 0.0781, RMSE: 0.2794, MAE: 0.2432, R²: 0.0321

============================================================
🔄 Round 158 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0867 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0867, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0867, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0867, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0866, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 158 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=0.0176
   Val:   Loss=0.0867, RMSE=0.2944, R²=0.0343
============================================================


📊 Round 158 Test Metrics:
   Loss: 0.0781, RMSE: 0.2794, MAE: 0.2432, R²: 0.0321

============================================================
🔄 Round 159 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0902 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0902, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0902, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0902, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0902, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0902, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0902)

============================================================
📊 Round 159 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=0.0174
   Val:   Loss=0.0902, RMSE=0.3003, R²=0.0323
============================================================


📊 Round 159 Test Metrics:
   Loss: 0.0781, RMSE: 0.2794, MAE: 0.2433, R²: 0.0320

============================================================
🔄 Round 162 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0906 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0906, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0906, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0906, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0906, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0906, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0906)

============================================================
📊 Round 162 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2868, R²=0.0218
   Val:   Loss=0.0906, RMSE=0.3010, R²=0.0195
============================================================


============================================================
🔄 Round 163 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 163 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2922, R²=0.0151
   Val:   Loss=0.0781, RMSE=0.2795, R²=0.0356
============================================================


📊 Round 163 Test Metrics:
   Loss: 0.0781, RMSE: 0.2794, MAE: 0.2433, R²: 0.0320

============================================================
🔄 Round 166 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 166 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2904, R²=0.0205
   Val:   Loss=0.0823, RMSE=0.2868, R²=0.0209
============================================================


📊 Round 166 Test Metrics:
   Loss: 0.0781, RMSE: 0.2794, MAE: 0.2433, R²: 0.0320

📊 Round 166 Test Metrics:
   Loss: 0.0781, RMSE: 0.2794, MAE: 0.2433, R²: 0.0320

📊 Round 166 Test Metrics:
   Loss: 0.0781, RMSE: 0.2794, MAE: 0.2433, R²: 0.0320

📊 Round 166 Test Metrics:
   Loss: 0.0781, RMSE: 0.2794, MAE: 0.2433, R²: 0.0320

============================================================
🔄 Round 173 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0863 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 173 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=0.0204
   Val:   Loss=0.0863, RMSE=0.2937, R²=0.0258
============================================================


📊 Round 173 Test Metrics:
   Loss: 0.0781, RMSE: 0.2794, MAE: 0.2433, R²: 0.0320

============================================================
🔄 Round 177 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0757 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0757, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0757, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0757, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0757, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0756, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0757)

============================================================
📊 Round 177 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2932, R²=0.0230
   Val:   Loss=0.0757, RMSE=0.2751, R²=0.0103
============================================================


📊 Round 177 Test Metrics:
   Loss: 0.0781, RMSE: 0.2794, MAE: 0.2433, R²: 0.0320

============================================================
🔄 Round 181 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0870 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0870, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0870, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0870, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0870, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0870, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 181 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=0.0241
   Val:   Loss=0.0870, RMSE=0.2949, R²=0.0077
============================================================


📊 Round 181 Test Metrics:
   Loss: 0.0781, RMSE: 0.2794, MAE: 0.2433, R²: 0.0319

📊 Round 181 Test Metrics:
   Loss: 0.0781, RMSE: 0.2794, MAE: 0.2433, R²: 0.0319

============================================================
🔄 Round 183 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0888 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0888, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0888, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0888, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0888, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0888, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0888)

============================================================
📊 Round 183 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2875, R²=0.0219
   Val:   Loss=0.0888, RMSE=0.2980, R²=0.0202
============================================================


📊 Round 183 Test Metrics:
   Loss: 0.0781, RMSE: 0.2794, MAE: 0.2433, R²: 0.0319

============================================================
🔄 Round 187 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0913 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0914, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0914, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0914, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0914, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0916, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0913)

============================================================
📊 Round 187 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=0.0158
   Val:   Loss=0.0913, RMSE=0.3022, R²=-0.0029
============================================================


📊 Round 187 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2433, R²: 0.0317

📊 Round 187 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2433, R²: 0.0317

============================================================
🔄 Round 193 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 193 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=0.0205
   Val:   Loss=0.0824, RMSE=0.2871, R²=0.0262
============================================================


============================================================
🔄 Round 195 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 195 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=0.0144
   Val:   Loss=0.0806, RMSE=0.2840, R²=0.0499
============================================================


📊 Round 195 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2433, R²: 0.0317

📊 Round 195 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2433, R²: 0.0317

============================================================
🔄 Round 197 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 197 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2921, R²=0.0182
   Val:   Loss=0.0782, RMSE=0.2797, R²=0.0193
============================================================


📊 Round 197 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2433, R²: 0.0318

============================================================
🔄 Round 201 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 201 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=0.0225
   Val:   Loss=0.0819, RMSE=0.2862, R²=0.0162
============================================================


📊 Round 201 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2433, R²: 0.0317

============================================================
🔄 Round 202 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0928 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0928, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0928, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0928, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0928, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0927, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0928)

============================================================
📊 Round 202 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=0.0213
   Val:   Loss=0.0928, RMSE=0.3046, R²=0.0201
============================================================


📊 Round 202 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2433, R²: 0.0316

============================================================
🔄 Round 205 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 205 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=0.0274
   Val:   Loss=0.0837, RMSE=0.2892, R²=-0.0037
============================================================


📊 Round 205 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2433, R²: 0.0316

============================================================
🔄 Round 206 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0873 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0873, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0873, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0873, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0873, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0873, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0873)

============================================================
📊 Round 206 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2882, R²=0.0206
   Val:   Loss=0.0873, RMSE=0.2955, R²=0.0263
============================================================


============================================================
🔄 Round 208 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 208 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=0.0235
   Val:   Loss=0.0809, RMSE=0.2845, R²=0.0145
============================================================


============================================================
🔄 Round 209 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 209 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=0.0203
   Val:   Loss=0.0826, RMSE=0.2875, R²=-0.0035
============================================================


============================================================
🔄 Round 210 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0891 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0891, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0891, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0891, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0891, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0891, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0891)

============================================================
📊 Round 210 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=0.0193
   Val:   Loss=0.0891, RMSE=0.2985, R²=0.0145
============================================================


============================================================
🔄 Round 215 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0864, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 215 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=0.0206
   Val:   Loss=0.0864, RMSE=0.2939, R²=0.0261
============================================================


📊 Round 215 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2433, R²: 0.0317

============================================================
🔄 Round 217 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0920 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0920, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0920, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0920, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0920, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0920, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0920)

============================================================
📊 Round 217 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2861, R²=0.0214
   Val:   Loss=0.0920, RMSE=0.3034, R²=0.0218
============================================================


📊 Round 217 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2433, R²: 0.0317

============================================================
🔄 Round 220 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0891 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0891, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0891, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0891, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0891, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0891, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0891)

============================================================
📊 Round 220 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=0.0213
   Val:   Loss=0.0891, RMSE=0.2985, R²=0.0218
============================================================


📊 Round 220 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2433, R²: 0.0317

📊 Round 220 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2433, R²: 0.0318

============================================================
🔄 Round 224 - Client client_35
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 224 Summary - Client client_35
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2920, R²=0.0289
   Val:   Loss=0.0784, RMSE=0.2800, R²=-0.0165
============================================================


❌ Client client_35 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8687 {grpc_message:"Socket closed", grpc_status:14}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8687 {grpc_message:"Socket closed", grpc_status:14}"
>
