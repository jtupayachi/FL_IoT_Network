[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5b3cd92c-7e41-4925-b9d0-fb362eabb996
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6b1fbf07-6723-46c5-b14e-d34da7bccf0a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 76f08b20-0801-4515-9e8a-1a125b9ae034
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bbc781ee-c79f-4b9a-9840-c1e5f344947c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 42c3c872-2f6a-45d9-8126-d8d696e2027b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2abc4053-c865-4853-afca-818e6a72cb53
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1f9e890d-e206-41e7-aab3-22b727f49f44
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d0234a94-cd3f-4edb-a2b2-52638f66999a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8a2f2c53-47fb-415c-b93b-1c3facc32015
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ad8c7782-9cc8-408c-824f-259f6d4a8bcd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7c8b0eaa-7e08-409e-b940-ecb1eb2ada15
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a76a9b7f-3efd-479d-81ed-ed913f479686
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8625c56b-c3ec-4cbe-8077-b8d076a52b78
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7d199fb6-7f56-41ac-888f-09356372a6ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f926cf02-63b5-40f9-9067-16337d71d933
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 59816cd1-f761-4ff2-8b1e-69512ceeb152
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8bd0b662-25ff-4f91-9f2d-ce50e7490c2c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 319615e2-32d7-49c0-a6df-15b229fbfbff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dd4d2a35-48d8-494a-8dac-09bf8daedafd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 17c68ec5-7462-4a66-b492-a6d3f862f0e8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f1d049ec-b268-4d93-a845-c7d4ac9db1de
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7e47b2e7-8e24-4d22-b314-f582673bea7e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 59350406-1db0-4284-abcb-a89224718d41
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 641f292c-733e-45a0-984f-c344ee7b73b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0b36b035-fdf5-4c07-835e-c24095b56b59
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 163b67bd-c155-4648-b495-9f58e84a1b0c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4cd5358d-0b42-4fb9-9cbe-faf1af41e284
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b36e6838-9030-4fcf-8246-38ca6d21ef8d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7b4a1895-f871-4e38-9d11-6c061e6749cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b918bd17-74c9-44fa-80f3-2385f9ce4362
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a4ef503a-9202-4707-862a-68eb904677b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eaf52fb0-2362-4c08-81e0-ea2733f302f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 54c21b12-f4ed-4829-89d8-456aa0df0ec0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 95225668-338c-4e3f-b7b0-79a7d4ea9260
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message de5be4cb-5e5b-48c9-8d6e-07564b24f9f6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 155881b3-2d57-4d47-9b0e-f1c7ec01b997
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0df52927-f6d4-44bd-9630-4abce6e71e32
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a82f085d-bc74-4eda-bf5c-d22b0d811fa8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cb8982d9-c7a9-4a6b-8d6d-6d2eeba5b5ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message acb224fc-b74f-47ff-8f70-fffb1931fecc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ddf59802-e5a4-44ee-b1c1-c3f9ddb1fca8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d30d059e-8806-4f41-a17a-0821bba54801
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8e25018b-4300-4116-8e55-84fa712684c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eb770470-a3dc-436c-a613-beb30f8b7a04
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e064680c-69cd-4f9a-a701-ea01b49f4fe4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 614ac95c-c4b1-4d06-a147-353f44aa4b8d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a87dc0cd-cd38-4322-877e-e9cfea4ec7be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fe4ddf76-3cb2-4852-aed4-b9555d93c93c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 536fa5f9-37d4-44dc-9ede-565c830a6262
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message da3f2455-6962-433d-943d-433d6251c041
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e2e89bf8-6fa1-40bf-ae0a-93d4b208c4b5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e4b1d945-3d10-4fcb-92a8-97f5b73a5761
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6e994c84-6b75-4e95-a27b-e45689b67d2b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 71485b9f-7646-4a8f-a9fe-6c8ff4aa8785
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 046ac10b-ffa6-4fc6-ad6f-60311c772963
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bed54f0a-bd67-4111-bbb3-4c8ebd5d20ea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d9f1d9cb-eca5-4933-8990-bb53b84706f7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8fbbf97b-0343-4a55-a847-8b733d0ad94d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 506cc507-ddd2-41ea-bda5-cb512d7b62aa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9d1b5eff-db9a-4f55-882d-d0697caa3469
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 99701728-ac40-4814-b5cc-62fe089db26f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 615bdce0-2295-4505-9883-6522e7bb4d93
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b03cb978-7503-43f3-9d6e-defcbb287349
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d629d33b-7bac-4fde-94a3-5d90f8125da5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 15ab9281-d045-47d6-b822-a482fc0fcab4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 026dd7f9-d36a-4757-bad4-304886123b00
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 41520b33-01e7-46e4-a892-8e7331ff6928
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9f02d424-124f-4d54-8e3f-d9d0a1753f0e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2633cf9b-2144-43c8-a6a3-e40e19f5aa7b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message abae723d-8850-4c73-9e13-f30c14289e1b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c467b82d-65ff-4a19-9c5e-ca030766a21c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 264ed7d3-9c28-443e-b2b0-e8eab66e8a26
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 323f6cef-e30e-42f0-9717-6674761a36b5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4b7246d1-f8b4-496e-8230-3f8dc34916b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0fd9254f-8f2a-4c95-95e1-da83d2bca679
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7de36c95-9378-4465-9477-c46d20844e29
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 30f264ce-73f1-44d1-991d-d3db0ab54273
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6dd3bcd0-a036-4a16-892f-e80319799c55
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1e4acb4d-d2e0-4234-87e2-cb1c65eb9f14
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3691baac-d9f8-486b-ae80-7644cb2941bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6ae56552-5030-4229-935b-74ca793e878e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aa8cd2bc-cba3-49e6-8860-e52073ea80e9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6a8a2397-beb6-44f5-87b8-abc067adb8bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 44ddf8cd-2677-4a6a-82f5-5b0e8de78284
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 86e03fb3-b679-4279-9169-1cba9e1dab5e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 63f8708f-e491-453b-9a6e-d36c4ff9e5ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e04da893-7b8c-412e-93a6-0893ce5117cb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e6c78f42-6f15-4b2e-a538-ddaaeadf2ce5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d749c99f-2d0b-4752-a207-3e617290da4d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 74bd6e36-bafd-44ad-a3ad-fdb743fe366b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1effb3f9-92da-41c6-a1a4-1c42ed4ac1be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 53a8c7d8-6f4a-4cae-a5f3-13b6837cc98d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8fb5daff-d670-4e14-b848-f6f07d5053f6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5e2bee82-32f6-46b7-bd9f-d8b3e6df8e85
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d12325aa-664c-4242-9908-d7fd7aedb52e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message befd605e-5e1c-4240-adfd-5f2338c812bc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bafa38c3-a3f3-4d55-8dbe-c1fc29f2e8a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 87b468f4-6d96-4368-bf23-114916e5895c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1d562fe9-60ef-41be-9681-363b5b0c225e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e0452e2d-77ab-45b5-a511-1614dea4715d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6e8af60c-dfcd-474a-bcef-ecafd1ff31d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 56df945b-fb44-4499-8b00-800ad953b8ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ce39210e-8e68-40c7-b1fe-7de9d9011367
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c62771bc-9513-44fa-ae43-c788e2ee9160
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d69dd2b1-d324-44a7-9d79-4fa1b565ab15
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ef4575da-f7c2-49d6-aa11-5c13107bf7f7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 93da183f-e8ea-4616-bcc2-d29d449750e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0f4baa68-99d5-4836-883d-a47214399570
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bffe7a45-10cc-4c79-8ca9-8c52b8673724
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a9404ade-1afe-4bad-a0df-b31641c2dd0e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d9015130-ae2e-4e24-bdae-904b01161723
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e067b69b-c3a6-4f8d-8357-28034a6757fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9ccd5c00-7567-4646-b5ca-31f6b68387fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6d294caa-8aef-40f9-9221-40025fd0d532
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6b13338c-c02b-4bdf-8835-10c864e14b11
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 00eb7404-38f6-40c2-8876-2bf359909473
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8be766d6-6b18-4caf-829a-7e76315cd981
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ef6fbe56-21b6-4847-8aa8-35ed294010c9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 47f8a4c9-4a22-4313-b56d-1f457447b13f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c1d05bd4-3963-45fe-94c2-4b7750aca748
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c86bd250-2a28-4276-aa56-88b178f49358
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message de59aa76-13d6-4fa6-a29e-5fe4343322a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ce96fe5c-190a-4908-b1f2-71e3395fcad9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d8bc3bf9-4506-4b67-8ac1-7f2195869fc8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4120c84c-ca68-4293-8e0b-7478b9bca52c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b952ce48-a8cd-4aab-bb79-0c61fb41620a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 983edd7d-d92a-48c6-8d5e-d518b31b2ea3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 853424e0-0162-476d-a3df-3637ed49495c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c8e7f595-742e-4a3f-8c50-ac7a747d82ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ddf354cc-efab-4f63-9b96-709b25fa2ebd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 76518360-3b3b-4250-9b04-5aa52ec6c50d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 76d93a2e-8d8c-4cd4-a32d-a3ae64b0adf7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 83c37b4d-8546-46ad-98ec-cf1e5d6fba99
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d3970389-1578-4121-8e97-6b054fd0b318
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0141b310-3663-433a-b5a9-7656def4d991
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 676a67f5-29f7-416a-b348-155f36dd3f72
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 77b50d83-80c2-44a0-8cb0-f1a71fa42bb3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a2ccf5fc-0651-4e3a-8029-0345dfcee6df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f5b7eabe-7971-4891-914f-aa12f81e9efe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e44ea46e-21bf-4394-b1d0-7f143d2c53f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b4fe5931-e4b9-4127-99c5-2220b86537a8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e5e734ba-b72c-40dd-8148-d50701fb13e8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 524bd184-c63e-4e7b-935e-e10856c1ee08
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0867ceb8-1399-4a3f-b18c-7c5bd0d0caae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 79c24110-07be-4064-9ddd-3dbdb949e3ea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6ba0313b-8c1d-473f-8f89-aa51676fcf8b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a9386444-84d2-434d-a924-ae31e6f67243
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3df6c494-33e7-46f9-9123-b22c659a2956
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7f05965b-a505-4129-a16e-d7f5061e2c9f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 77ac9b72-ac26-41ed-b559-5978b73bf8fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1710f625-719f-4ac9-b1e7-6227a507d84b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b695a4bd-1fd7-4954-b68b-1aa4e0512792
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8e16cb3c-b7e5-4507-b44c-e84f7c7085b0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2fbdd395-f067-495a-aac1-d735800b3338
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ccb3ca0b-03e6-4ccd-927b-f04e8e596b89
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dabd2f5c-48c3-4884-8de9-524dbdeca387
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f2f80e69-5893-44ee-8a89-6b33ec24f56f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 12e3a8cc-f8bf-4d93-8546-1bf9ab76a1be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5bde88fa-99cd-45ce-a43c-fbe0090596ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1a2311f7-7950-4b3d-984c-dce827ee20fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dd665a97-ad16-45ab-a88e-c407398576a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8d1bb8b4-d17f-4cce-9224-699f564cacb5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7531886c-a6e8-4fce-880a-5feb58a05864
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e16f75a0-3f3a-4f1e-932c-22f9a119610a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 81c3428d-37d7-4a35-8572-05799038dde5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 518dc3ef-eaaa-48b3-aa92-799493686e34
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 60bc40b5-3501-4619-b678-725dbcf070b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 438ed4be-3383-45d6-9ad6-b60443112ae0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a3ce020e-6101-4d74-9f2a-f69afa537896
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b5e08e64-7873-49a6-bd06-1c3766a9c2cd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5d22cc60-4e14-4210-a071-d76167b59770
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c55b148e-7c28-4908-9d14-bb3e6acaa00a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b10993ba-cb15-4ee5-8487-e1fe0f5edd3b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 09a9c753-3524-425c-9588-788a5d28a41b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5e446c5f-c3ea-44cd-bfd0-a44a1afaefc7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7596a67f-4636-4da2-beaf-8ea86dfacdd9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 11f46ae6-fb27-4aa4-b750-b80d585909fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3a8dc9c2-bee6-4fc1-a9e4-4b41469a1e04
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 60f8640e-9fed-47b6-a766-d9819d857270
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0622a88a-36b9-47d2-bfde-ae4231ea4d5e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3453108a-5406-4e00-96f1-9b1b69fbf6ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d7361de0-2e0f-46ca-8e58-f4f0b53c206c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 71cae7ca-1d40-41a1-8823-b88a178f1d52
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8687 {grpc_message:"Socket closed", grpc_status:14}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_36
Server: localhost:8687
Algorithm: FEDAVG
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_36
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_36/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_36/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_36/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_36/test_labels.txt

📊 Raw data loaded:
   Train: X=(1354, 24), y=(1354,)
   Test:  X=(339, 24), y=(339,)

⚠️  Limiting training data: 1354 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  330 samples, 5 features
✅ Client client_36 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

============================================================
🔄 Round 4 - Client client_36
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0813 (↓), lr=0.001000
   • Epoch   2/100: train=0.0815, val=0.0817, patience=1/15, lr=0.001000
   • Epoch   3/100: train=0.0830, val=0.0820, patience=2/15, lr=0.001000
   ✓ Epoch   4/100: train=0.0832, val=0.0807 (↓), lr=0.001000
   • Epoch   5/100: train=0.0809, val=0.0804, patience=1/15, lr=0.001000
   ✓ Epoch  11/100: train=0.0740, val=0.0778 (↓), lr=0.001000
   • Epoch  21/100: train=0.0676, val=0.0763, patience=5/15, lr=0.001000
   📉 Epoch 24: LR reduced 0.001000 → 0.000500
   • Epoch  31/100: train=0.0597, val=0.0812, patience=15/15, lr=0.000500

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0765)

============================================================
📊 Round 4 Summary - Client client_36
   Epochs: 31/100 (early stopped)
   LR: 0.001000 → 0.000500 (1 reductions)
   Train: Loss=0.0685, RMSE=0.2617, R²=0.1567
   Val:   Loss=0.0765, RMSE=0.2766, R²=0.0606
============================================================


📊 Round 4 Test Metrics:
   Loss: 0.0810, RMSE: 0.2846, MAE: 0.2448, R²: 0.0304

============================================================
🔄 Round 6 - Client client_36
   Epochs: 100, Batch: 32, LR: 0.000500
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   📉 Epoch 1: LR reduced 0.000500 → 0.000250
   ✓ Epoch   1/100: train=0.0791, val=0.0816 (↓), lr=0.000250
   ✓ Epoch   2/100: train=0.0784, val=0.0809 (↓), lr=0.000250
   • Epoch   3/100: train=0.0779, val=0.0808, patience=1/15, lr=0.000250
   • Epoch   4/100: train=0.0777, val=0.0806, patience=2/15, lr=0.000250
   • Epoch   5/100: train=0.0774, val=0.0804, patience=3/15, lr=0.000250
   📉 Epoch 9: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0758, val=0.0793, patience=1/15, lr=0.000125
   📉 Epoch 17: LR reduced 0.000125 → 0.000063
   • Epoch  21/100: train=0.0747, val=0.0783, patience=5/15, lr=0.000063
   📉 Epoch 25: LR reduced 0.000063 → 0.000031
   • Epoch  31/100: train=0.0741, val=0.0779, patience=9/15, lr=0.000031
   📉 Epoch 33: LR reduced 0.000031 → 0.000016
   📉 Epoch 41: LR reduced 0.000016 → 0.000008
   • Epoch  41/100: train=0.0739, val=0.0777, patience=7/15, lr=0.000008
   📉 Epoch 49: LR reduced 0.000008 → 0.000004

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 6 Summary - Client client_36
   Epochs: 49/100 (early stopped)
   LR: 0.000500 → 0.000004 (7 reductions)
   Train: Loss=0.0741, RMSE=0.2722, R²=0.0907
   Val:   Loss=0.0778, RMSE=0.2789, R²=0.0428
============================================================


============================================================
🔄 Round 9 - Client client_36
   Epochs: 100, Batch: 32, LR: 0.000004
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0767, val=0.0847 (↓), lr=0.000004
   • Epoch   2/100: train=0.0766, val=0.0847, patience=1/15, lr=0.000004
   • Epoch   3/100: train=0.0766, val=0.0846, patience=2/15, lr=0.000004
   • Epoch   4/100: train=0.0766, val=0.0846, patience=3/15, lr=0.000004
   • Epoch   5/100: train=0.0766, val=0.0846, patience=4/15, lr=0.000004
   📉 Epoch 8: LR reduced 0.000004 → 0.000002
   • Epoch  11/100: train=0.0765, val=0.0845, patience=10/15, lr=0.000002
   📉 Epoch 16: LR reduced 0.000002 → 0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 9 Summary - Client client_36
   Epochs: 16/100 (early stopped)
   LR: 0.000004 → 0.000001 (2 reductions)
   Train: Loss=0.0767, RMSE=0.2770, R²=0.0403
   Val:   Loss=0.0847, RMSE=0.2910, R²=0.0392
============================================================


📊 Round 9 Test Metrics:
   Loss: 0.0795, RMSE: 0.2820, MAE: 0.2419, R²: 0.0482

============================================================
🔄 Round 11 - Client client_36
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0755, val=0.0876 (↓), lr=0.000001
   • Epoch   2/100: train=0.0755, val=0.0876, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0755, val=0.0876, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0755, val=0.0876, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0755, val=0.0876, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0754, val=0.0876, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0876)

============================================================
📊 Round 11 Summary - Client client_36
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0756, RMSE=0.2750, R²=0.0418
   Val:   Loss=0.0876, RMSE=0.2960, R²=0.0361
============================================================


============================================================
🔄 Round 12 - Client client_36
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0741 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0741, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0741, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0741, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0741, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0742, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0741)

============================================================
📊 Round 12 Summary - Client client_36
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2817, R²=0.0365
   Val:   Loss=0.0741, RMSE=0.2723, R²=0.0511
============================================================


============================================================
🔄 Round 13 - Client client_36
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0781, val=0.0780 (↓), lr=0.000001
   • Epoch   2/100: train=0.0781, val=0.0780, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0781, val=0.0780, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0781, val=0.0780, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0780, val=0.0780, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0780, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 13 Summary - Client client_36
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0783, RMSE=0.2799, R²=0.0316
   Val:   Loss=0.0780, RMSE=0.2794, R²=0.0742
============================================================


📊 Round 13 Test Metrics:
   Loss: 0.0794, RMSE: 0.2818, MAE: 0.2417, R²: 0.0492

============================================================
🔄 Round 17 - Client client_36
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0753 (↓), lr=0.000001
   • Epoch   2/100: train=0.0785, val=0.0753, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0753, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0753, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0753, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0753, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0753)

============================================================
📊 Round 17 Summary - Client client_36
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2804, R²=0.0427
   Val:   Loss=0.0753, RMSE=0.2744, R²=0.0521
============================================================


📊 Round 17 Test Metrics:
   Loss: 0.0794, RMSE: 0.2818, MAE: 0.2418, R²: 0.0491

============================================================
🔄 Round 21 - Client client_36
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0746 (↓), lr=0.000001
   • Epoch   2/100: train=0.0787, val=0.0746, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0746, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0746, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0745, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0745, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0746)

============================================================
📊 Round 21 Summary - Client client_36
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2805, R²=0.0435
   Val:   Loss=0.0746, RMSE=0.2731, R²=0.0551
============================================================


📊 Round 21 Test Metrics:
   Loss: 0.0794, RMSE: 0.2818, MAE: 0.2417, R²: 0.0494

============================================================
🔄 Round 25 - Client client_36
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0770, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0770, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0770, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0769, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0769, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0769, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 25 Summary - Client client_36
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0770, RMSE=0.2775, R²=0.0476
   Val:   Loss=0.0810, RMSE=0.2847, R²=0.0352
============================================================


============================================================
🔄 Round 27 - Client client_36
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0758, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0757, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0757, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0757, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0757, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0756, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 27 Summary - Client client_36
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0758, RMSE=0.2753, R²=0.0424
   Val:   Loss=0.0860, RMSE=0.2932, R²=0.0558
============================================================


📊 Round 27 Test Metrics:
   Loss: 0.0794, RMSE: 0.2818, MAE: 0.2417, R²: 0.0494

📊 Round 27 Test Metrics:
   Loss: 0.0794, RMSE: 0.2818, MAE: 0.2417, R²: 0.0494

📊 Round 27 Test Metrics:
   Loss: 0.0794, RMSE: 0.2818, MAE: 0.2417, R²: 0.0494

📊 Round 27 Test Metrics:
   Loss: 0.0794, RMSE: 0.2818, MAE: 0.2417, R²: 0.0494

📊 Round 27 Test Metrics:
   Loss: 0.0794, RMSE: 0.2818, MAE: 0.2417, R²: 0.0494

📊 Round 27 Test Metrics:
   Loss: 0.0794, RMSE: 0.2818, MAE: 0.2417, R²: 0.0495

📊 Round 27 Test Metrics:
   Loss: 0.0794, RMSE: 0.2818, MAE: 0.2417, R²: 0.0495

============================================================
🔄 Round 40 - Client client_36
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0668 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0668, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0668, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0668, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0668, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0669, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0668)

============================================================
📊 Round 40 Summary - Client client_36
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=0.0421
   Val:   Loss=0.0668, RMSE=0.2585, R²=0.0584
============================================================


============================================================
🔄 Round 42 - Client client_36
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0779, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0779, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0779, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0779, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0779, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0778, val=0.0774, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 42 Summary - Client client_36
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0779, RMSE=0.2791, R²=0.0451
   Val:   Loss=0.0775, RMSE=0.2784, R²=0.0485
============================================================


============================================================
🔄 Round 43 - Client client_36
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0695 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0695, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0695, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0695, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0695, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0694, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0695)

============================================================
📊 Round 43 Summary - Client client_36
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=0.0469
   Val:   Loss=0.0695, RMSE=0.2636, R²=0.0418
============================================================


============================================================
🔄 Round 44 - Client client_36
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0669 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0669, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0669, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0669, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0669, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0669, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0669)

============================================================
📊 Round 44 Summary - Client client_36
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2838, R²=0.0437
   Val:   Loss=0.0669, RMSE=0.2587, R²=0.0572
============================================================


============================================================
🔄 Round 45 - Client client_36
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0768, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0767, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0767, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0767, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0767, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0767, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 45 Summary - Client client_36
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0771, RMSE=0.2776, R²=0.0523
   Val:   Loss=0.0809, RMSE=0.2844, R²=0.0214
============================================================


📊 Round 45 Test Metrics:
   Loss: 0.0794, RMSE: 0.2818, MAE: 0.2417, R²: 0.0495

📊 Round 45 Test Metrics:
   Loss: 0.0794, RMSE: 0.2818, MAE: 0.2417, R²: 0.0495

============================================================
🔄 Round 48 - Client client_36
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0772, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0772, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0772, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0772, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0772, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0771, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 48 Summary - Client client_36
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0774, RMSE=0.2783, R²=0.0456
   Val:   Loss=0.0794, RMSE=0.2818, R²=0.0450
============================================================


📊 Round 48 Test Metrics:
   Loss: 0.0794, RMSE: 0.2818, MAE: 0.2417, R²: 0.0495

📊 Round 48 Test Metrics:
   Loss: 0.0794, RMSE: 0.2818, MAE: 0.2417, R²: 0.0495

============================================================
🔄 Round 53 - Client client_36
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0693 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0692, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0692, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0692, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0692, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0692, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0693)

============================================================
📊 Round 53 Summary - Client client_36
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=0.0404
   Val:   Loss=0.0693, RMSE=0.2632, R²=0.0707
============================================================


============================================================
🔄 Round 55 - Client client_36
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0715 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0715, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0715, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0715, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0715, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0715, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0715)

============================================================
📊 Round 55 Summary - Client client_36
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2818, R²=0.0522
   Val:   Loss=0.0715, RMSE=0.2675, R²=0.0165
============================================================


📊 Round 55 Test Metrics:
   Loss: 0.0794, RMSE: 0.2818, MAE: 0.2417, R²: 0.0495

============================================================
🔄 Round 57 - Client client_36
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0742 (↓), lr=0.000001
   • Epoch   2/100: train=0.0787, val=0.0742, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0742, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0742, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0742, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0742, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0742)

============================================================
📊 Round 57 Summary - Client client_36
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2806, R²=0.0388
   Val:   Loss=0.0742, RMSE=0.2724, R²=0.0732
============================================================


============================================================
🔄 Round 60 - Client client_36
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0782, val=0.0766 (↓), lr=0.000001
   • Epoch   2/100: train=0.0782, val=0.0766, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0781, val=0.0766, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0781, val=0.0766, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0781, val=0.0766, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0781, val=0.0766, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0766)

============================================================
📊 Round 60 Summary - Client client_36
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0781, RMSE=0.2795, R²=0.0545
   Val:   Loss=0.0766, RMSE=0.2768, R²=0.0085
============================================================


📊 Round 60 Test Metrics:
   Loss: 0.0794, RMSE: 0.2818, MAE: 0.2417, R²: 0.0495

============================================================
🔄 Round 62 - Client client_36
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0740 (↓), lr=0.000001
   • Epoch   2/100: train=0.0787, val=0.0740, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0740, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0740, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0740, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0739, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0740)

============================================================
📊 Round 62 Summary - Client client_36
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2807, R²=0.0397
   Val:   Loss=0.0740, RMSE=0.2720, R²=0.0552
============================================================


📊 Round 62 Test Metrics:
   Loss: 0.0794, RMSE: 0.2818, MAE: 0.2417, R²: 0.0495

============================================================
🔄 Round 63 - Client client_36
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0759, val=0.0869 (↓), lr=0.000001
   • Epoch   2/100: train=0.0758, val=0.0869, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0758, val=0.0869, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0758, val=0.0869, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0758, val=0.0869, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0757, val=0.0870, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 63 Summary - Client client_36
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0756, RMSE=0.2749, R²=0.0495
   Val:   Loss=0.0869, RMSE=0.2947, R²=0.0181
============================================================


📊 Round 63 Test Metrics:
   Loss: 0.0794, RMSE: 0.2818, MAE: 0.2417, R²: 0.0495

============================================================
🔄 Round 67 - Client client_36
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0733 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0733, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0733, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0733, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0733, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0733, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0733)

============================================================
📊 Round 67 Summary - Client client_36
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2810, R²=0.0478
   Val:   Loss=0.0733, RMSE=0.2708, R²=0.0354
============================================================


============================================================
🔄 Round 68 - Client client_36
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0678 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0678, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0678, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0678, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0678, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0677, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0678)

============================================================
📊 Round 68 Summary - Client client_36
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=0.0350
   Val:   Loss=0.0678, RMSE=0.2604, R²=0.0938
============================================================


📊 Round 68 Test Metrics:
   Loss: 0.0794, RMSE: 0.2818, MAE: 0.2417, R²: 0.0495

============================================================
🔄 Round 69 - Client client_36
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0770, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0770, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0770, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0770, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0770, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0769, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 69 Summary - Client client_36
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0772, RMSE=0.2778, R²=0.0445
   Val:   Loss=0.0803, RMSE=0.2834, R²=0.0508
============================================================


📊 Round 69 Test Metrics:
   Loss: 0.0794, RMSE: 0.2818, MAE: 0.2417, R²: 0.0495

============================================================
🔄 Round 70 - Client client_36
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0771, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0771, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0771, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0771, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0771, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0770, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 70 Summary - Client client_36
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0772, RMSE=0.2779, R²=0.0455
   Val:   Loss=0.0801, RMSE=0.2830, R²=0.0422
============================================================


📊 Round 70 Test Metrics:
   Loss: 0.0794, RMSE: 0.2818, MAE: 0.2417, R²: 0.0495

============================================================
🔄 Round 71 - Client client_36
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0765, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0765, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0765, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0765, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0765, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0764, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 71 Summary - Client client_36
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0769, RMSE=0.2773, R²=0.0462
   Val:   Loss=0.0816, RMSE=0.2856, R²=0.0287
============================================================


📊 Round 71 Test Metrics:
   Loss: 0.0794, RMSE: 0.2818, MAE: 0.2417, R²: 0.0495

📊 Round 71 Test Metrics:
   Loss: 0.0794, RMSE: 0.2818, MAE: 0.2417, R²: 0.0495

📊 Round 71 Test Metrics:
   Loss: 0.0794, RMSE: 0.2818, MAE: 0.2417, R²: 0.0495

============================================================
🔄 Round 77 - Client client_36
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0772, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0772, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0772, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0772, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0772, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0771, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 77 Summary - Client client_36
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0771, RMSE=0.2776, R²=0.0396
   Val:   Loss=0.0808, RMSE=0.2842, R²=0.0646
============================================================


📊 Round 77 Test Metrics:
   Loss: 0.0794, RMSE: 0.2818, MAE: 0.2417, R²: 0.0495

============================================================
🔄 Round 78 - Client client_36
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0735 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0735, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0735, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0734, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0734, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0734, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0735)

============================================================
📊 Round 78 Summary - Client client_36
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2809, R²=0.0457
   Val:   Loss=0.0735, RMSE=0.2711, R²=0.0422
============================================================


📊 Round 78 Test Metrics:
   Loss: 0.0794, RMSE: 0.2818, MAE: 0.2417, R²: 0.0495

============================================================
🔄 Round 79 - Client client_36
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0741 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0741, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0741, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0741, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0741, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0740, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0741)

============================================================
📊 Round 79 Summary - Client client_36
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2806, R²=0.0460
   Val:   Loss=0.0741, RMSE=0.2723, R²=0.0469
============================================================


📊 Round 79 Test Metrics:
   Loss: 0.0794, RMSE: 0.2818, MAE: 0.2417, R²: 0.0495

📊 Round 79 Test Metrics:
   Loss: 0.0794, RMSE: 0.2818, MAE: 0.2417, R²: 0.0494

============================================================
🔄 Round 82 - Client client_36
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0742 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0742, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0742, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0742, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0785, val=0.0742, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0785, val=0.0742, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0742)

============================================================
📊 Round 82 Summary - Client client_36
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2806, R²=0.0453
   Val:   Loss=0.0742, RMSE=0.2723, R²=0.0446
============================================================


📊 Round 82 Test Metrics:
   Loss: 0.0794, RMSE: 0.2818, MAE: 0.2417, R²: 0.0495

📊 Round 82 Test Metrics:
   Loss: 0.0794, RMSE: 0.2818, MAE: 0.2417, R²: 0.0495

============================================================
🔄 Round 85 - Client client_36
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0776, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0776, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0776, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0775, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0775, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0775, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 85 Summary - Client client_36
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0774, RMSE=0.2782, R²=0.0476
   Val:   Loss=0.0794, RMSE=0.2818, R²=0.0398
============================================================


📊 Round 85 Test Metrics:
   Loss: 0.0794, RMSE: 0.2818, MAE: 0.2417, R²: 0.0495

📊 Round 85 Test Metrics:
   Loss: 0.0794, RMSE: 0.2818, MAE: 0.2417, R²: 0.0495

============================================================
🔄 Round 87 - Client client_36
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0648 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0648, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0647, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0647, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0647, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0647, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0648)

============================================================
📊 Round 87 Summary - Client client_36
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2847, R²=0.0432
   Val:   Loss=0.0648, RMSE=0.2545, R²=0.0519
============================================================


📊 Round 87 Test Metrics:
   Loss: 0.0794, RMSE: 0.2818, MAE: 0.2417, R²: 0.0495

📊 Round 87 Test Metrics:
   Loss: 0.0794, RMSE: 0.2818, MAE: 0.2417, R²: 0.0495

============================================================
🔄 Round 93 - Client client_36
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0773, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0773, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0773, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0773, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0773, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0772, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 93 Summary - Client client_36
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0776, RMSE=0.2785, R²=0.0465
   Val:   Loss=0.0787, RMSE=0.2805, R²=0.0460
============================================================


============================================================
🔄 Round 94 - Client client_36
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0753, val=0.0880 (↓), lr=0.000001
   • Epoch   2/100: train=0.0753, val=0.0880, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0753, val=0.0880, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0753, val=0.0880, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0753, val=0.0880, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0752, val=0.0880, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0880)

============================================================
📊 Round 94 Summary - Client client_36
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0753, RMSE=0.2743, R²=0.0440
   Val:   Loss=0.0880, RMSE=0.2967, R²=0.0494
============================================================


📊 Round 94 Test Metrics:
   Loss: 0.0794, RMSE: 0.2818, MAE: 0.2417, R²: 0.0495

============================================================
🔄 Round 99 - Client client_36
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0780, val=0.0766 (↓), lr=0.000001
   • Epoch   2/100: train=0.0780, val=0.0766, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0780, val=0.0766, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0779, val=0.0766, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0779, val=0.0766, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0779, val=0.0766, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0766)

============================================================
📊 Round 99 Summary - Client client_36
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0781, RMSE=0.2794, R²=0.0410
   Val:   Loss=0.0766, RMSE=0.2768, R²=0.0679
============================================================


📊 Round 99 Test Metrics:
   Loss: 0.0794, RMSE: 0.2818, MAE: 0.2417, R²: 0.0495

============================================================
🔄 Round 100 - Client client_36
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0770, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0770, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0770, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0770, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0770, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0769, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 100 Summary - Client client_36
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0773, RMSE=0.2780, R²=0.0479
   Val:   Loss=0.0798, RMSE=0.2824, R²=0.0388
============================================================


📊 Round 100 Test Metrics:
   Loss: 0.0794, RMSE: 0.2818, MAE: 0.2417, R²: 0.0495

============================================================
🔄 Round 101 - Client client_36
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0768, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0768, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0768, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0768, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0768, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0767, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 101 Summary - Client client_36
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0768, RMSE=0.2771, R²=0.0453
   Val:   Loss=0.0819, RMSE=0.2862, R²=0.0508
============================================================


📊 Round 101 Test Metrics:
   Loss: 0.0794, RMSE: 0.2818, MAE: 0.2417, R²: 0.0495

📊 Round 101 Test Metrics:
   Loss: 0.0794, RMSE: 0.2818, MAE: 0.2417, R²: 0.0495

============================================================
🔄 Round 103 - Client client_36
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0762, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0762, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0762, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0762, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0762, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0761, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 103 Summary - Client client_36
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0764, RMSE=0.2764, R²=0.0490
   Val:   Loss=0.0833, RMSE=0.2887, R²=0.0373
============================================================


============================================================
🔄 Round 104 - Client client_36
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0776, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0775, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0775, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0775, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0775, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0775, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 104 Summary - Client client_36
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0775, RMSE=0.2783, R²=0.0487
   Val:   Loss=0.0791, RMSE=0.2813, R²=0.0345
============================================================


📊 Round 104 Test Metrics:
   Loss: 0.0794, RMSE: 0.2818, MAE: 0.2417, R²: 0.0495

📊 Round 104 Test Metrics:
   Loss: 0.0794, RMSE: 0.2818, MAE: 0.2417, R²: 0.0495

============================================================
🔄 Round 115 - Client client_36
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0767, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0767, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0767, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0767, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0767, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0766, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 115 Summary - Client client_36
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0768, RMSE=0.2771, R²=0.0461
   Val:   Loss=0.0817, RMSE=0.2859, R²=0.0456
============================================================


📊 Round 115 Test Metrics:
   Loss: 0.0794, RMSE: 0.2818, MAE: 0.2417, R²: 0.0496

📊 Round 115 Test Metrics:
   Loss: 0.0794, RMSE: 0.2818, MAE: 0.2417, R²: 0.0495

============================================================
🔄 Round 118 - Client client_36
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0708 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0708, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0708, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0708, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0708, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0708, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0708)

============================================================
📊 Round 118 Summary - Client client_36
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2820, R²=0.0530
   Val:   Loss=0.0708, RMSE=0.2660, R²=0.0154
============================================================


============================================================
🔄 Round 119 - Client client_36
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0702 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0702, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0702, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0702, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0702, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0702, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0702)

============================================================
📊 Round 119 Summary - Client client_36
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2822, R²=0.0465
   Val:   Loss=0.0702, RMSE=0.2650, R²=0.0479
============================================================


📊 Round 119 Test Metrics:
   Loss: 0.0794, RMSE: 0.2818, MAE: 0.2417, R²: 0.0495

============================================================
🔄 Round 121 - Client client_36
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0782, val=0.0760 (↓), lr=0.000001
   • Epoch   2/100: train=0.0782, val=0.0760, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0782, val=0.0760, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0782, val=0.0760, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0782, val=0.0760, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0782, val=0.0759, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0760)

============================================================
📊 Round 121 Summary - Client client_36
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0782, RMSE=0.2797, R²=0.0343
   Val:   Loss=0.0760, RMSE=0.2757, R²=0.0690
============================================================


📊 Round 121 Test Metrics:
   Loss: 0.0794, RMSE: 0.2818, MAE: 0.2417, R²: 0.0495

============================================================
🔄 Round 123 - Client client_36
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0770, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0770, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0770, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0770, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0769, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0769, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 123 Summary - Client client_36
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0769, RMSE=0.2773, R²=0.0451
   Val:   Loss=0.0813, RMSE=0.2852, R²=0.0487
============================================================


============================================================
🔄 Round 124 - Client client_36
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0752 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0752, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0752, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0752, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0752, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0752, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0752)

============================================================
📊 Round 124 Summary - Client client_36
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2800, R²=0.0456
   Val:   Loss=0.0752, RMSE=0.2742, R²=0.0479
============================================================


📊 Round 124 Test Metrics:
   Loss: 0.0794, RMSE: 0.2818, MAE: 0.2417, R²: 0.0495

📊 Round 124 Test Metrics:
   Loss: 0.0794, RMSE: 0.2818, MAE: 0.2417, R²: 0.0496

============================================================
🔄 Round 129 - Client client_36
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0776, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0776, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0776, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0776, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0776, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0775, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 129 Summary - Client client_36
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0776, RMSE=0.2785, R²=0.0497
   Val:   Loss=0.0785, RMSE=0.2802, R²=0.0344
============================================================


📊 Round 129 Test Metrics:
   Loss: 0.0794, RMSE: 0.2818, MAE: 0.2417, R²: 0.0496

============================================================
🔄 Round 130 - Client client_36
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0779, val=0.0774 (↓), lr=0.000001
   • Epoch   2/100: train=0.0779, val=0.0774, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0779, val=0.0774, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0778, val=0.0774, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0778, val=0.0774, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0777, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0774)

============================================================
📊 Round 130 Summary - Client client_36
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0779, RMSE=0.2791, R²=0.0381
   Val:   Loss=0.0774, RMSE=0.2782, R²=0.0669
============================================================


============================================================
🔄 Round 133 - Client client_36
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0759, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0759, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0759, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0759, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0759, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0758, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 133 Summary - Client client_36
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0761, RMSE=0.2758, R²=0.0485
   Val:   Loss=0.0845, RMSE=0.2908, R²=0.0374
============================================================


📊 Round 133 Test Metrics:
   Loss: 0.0794, RMSE: 0.2818, MAE: 0.2417, R²: 0.0497

============================================================
🔄 Round 136 - Client client_36
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0778, val=0.0780 (↓), lr=0.000001
   • Epoch   2/100: train=0.0778, val=0.0780, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0778, val=0.0780, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0777, val=0.0780, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0777, val=0.0780, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0777, val=0.0779, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 136 Summary - Client client_36
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0777, RMSE=0.2788, R²=0.0386
   Val:   Loss=0.0780, RMSE=0.2793, R²=0.0775
============================================================


============================================================
🔄 Round 137 - Client client_36
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0781, val=0.0769 (↓), lr=0.000001
   • Epoch   2/100: train=0.0781, val=0.0769, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0781, val=0.0769, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0781, val=0.0769, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0781, val=0.0769, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0780, val=0.0768, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0769)

============================================================
📊 Round 137 Summary - Client client_36
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0780, RMSE=0.2793, R²=0.0396
   Val:   Loss=0.0769, RMSE=0.2773, R²=0.0735
============================================================


📊 Round 137 Test Metrics:
   Loss: 0.0794, RMSE: 0.2818, MAE: 0.2417, R²: 0.0497

============================================================
🔄 Round 139 - Client client_36
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0779, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0779, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0778, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0778, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0778, val=0.0773, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0777, val=0.0774, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 139 Summary - Client client_36
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0779, RMSE=0.2791, R²=0.0468
   Val:   Loss=0.0773, RMSE=0.2779, R²=0.0277
============================================================


📊 Round 139 Test Metrics:
   Loss: 0.0794, RMSE: 0.2818, MAE: 0.2417, R²: 0.0497

📊 Round 139 Test Metrics:
   Loss: 0.0794, RMSE: 0.2818, MAE: 0.2417, R²: 0.0497

📊 Round 139 Test Metrics:
   Loss: 0.0794, RMSE: 0.2818, MAE: 0.2417, R²: 0.0497

============================================================
🔄 Round 144 - Client client_36
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0771, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0771, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0771, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0770, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0770, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0770, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 144 Summary - Client client_36
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0771, RMSE=0.2777, R²=0.0439
   Val:   Loss=0.0805, RMSE=0.2836, R²=0.0490
============================================================


============================================================
🔄 Round 145 - Client client_36
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0775, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0775, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0775, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0774, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0774, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0774, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 145 Summary - Client client_36
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0774, RMSE=0.2782, R²=0.0534
   Val:   Loss=0.0792, RMSE=0.2815, R²=0.0112
============================================================


============================================================
🔄 Round 146 - Client client_36
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0780, val=0.0770 (↓), lr=0.000001
   • Epoch   2/100: train=0.0780, val=0.0770, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0779, val=0.0770, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0779, val=0.0770, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0779, val=0.0770, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0779, val=0.0769, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0770)

============================================================
📊 Round 146 Summary - Client client_36
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0780, RMSE=0.2792, R²=0.0451
   Val:   Loss=0.0770, RMSE=0.2775, R²=0.0536
============================================================


============================================================
🔄 Round 148 - Client client_36
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0772, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0772, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0771, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0771, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0771, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0770, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 148 Summary - Client client_36
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0773, RMSE=0.2780, R²=0.0395
   Val:   Loss=0.0797, RMSE=0.2824, R²=0.0702
============================================================


📊 Round 148 Test Metrics:
   Loss: 0.0794, RMSE: 0.2818, MAE: 0.2417, R²: 0.0496

============================================================
🔄 Round 150 - Client client_36
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0780, val=0.0763 (↓), lr=0.000001
   • Epoch   2/100: train=0.0780, val=0.0762, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0780, val=0.0762, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0780, val=0.0762, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0779, val=0.0762, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0779, val=0.0762, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0763)

============================================================
📊 Round 150 Summary - Client client_36
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0782, RMSE=0.2796, R²=0.0519
   Val:   Loss=0.0763, RMSE=0.2761, R²=0.0232
============================================================


📊 Round 150 Test Metrics:
   Loss: 0.0794, RMSE: 0.2818, MAE: 0.2417, R²: 0.0497

============================================================
🔄 Round 151 - Client client_36
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0780, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0780, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0780, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0780, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0779, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0779, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 151 Summary - Client client_36
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0776, RMSE=0.2786, R²=0.0508
   Val:   Loss=0.0784, RMSE=0.2800, R²=0.0302
============================================================


📊 Round 151 Test Metrics:
   Loss: 0.0794, RMSE: 0.2818, MAE: 0.2417, R²: 0.0497

============================================================
🔄 Round 152 - Client client_36
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0710 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0710, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0710, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0710, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0710, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0709, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0710)

============================================================
📊 Round 152 Summary - Client client_36
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2819, R²=0.0481
   Val:   Loss=0.0710, RMSE=0.2665, R²=0.0349
============================================================


📊 Round 152 Test Metrics:
   Loss: 0.0794, RMSE: 0.2818, MAE: 0.2417, R²: 0.0497

============================================================
🔄 Round 153 - Client client_36
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0768, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0768, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0768, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0767, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0767, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0767, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 153 Summary - Client client_36
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0766, RMSE=0.2768, R²=0.0433
   Val:   Loss=0.0824, RMSE=0.2871, R²=0.0594
============================================================


📊 Round 153 Test Metrics:
   Loss: 0.0794, RMSE: 0.2818, MAE: 0.2417, R²: 0.0496

============================================================
🔄 Round 159 - Client client_36
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0764, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0764, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0764, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0764, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0764, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0763, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 159 Summary - Client client_36
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0764, RMSE=0.2763, R²=0.0434
   Val:   Loss=0.0834, RMSE=0.2887, R²=0.0561
============================================================


============================================================
🔄 Round 160 - Client client_36
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0717 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0717, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0717, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0717, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0717, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0716, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0717)

============================================================
📊 Round 160 Summary - Client client_36
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2816, R²=0.0503
   Val:   Loss=0.0717, RMSE=0.2678, R²=0.0302
============================================================


📊 Round 160 Test Metrics:
   Loss: 0.0794, RMSE: 0.2818, MAE: 0.2417, R²: 0.0497

============================================================
🔄 Round 161 - Client client_36
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0778, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0778, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0778, val=0.0782, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0778, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0778, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0777, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 161 Summary - Client client_36
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0777, RMSE=0.2787, R²=0.0466
   Val:   Loss=0.0782, RMSE=0.2796, R²=0.0468
============================================================


📊 Round 161 Test Metrics:
   Loss: 0.0794, RMSE: 0.2818, MAE: 0.2417, R²: 0.0497

============================================================
🔄 Round 162 - Client client_36
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0771, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0771, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0771, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0771, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0771, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0771, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 162 Summary - Client client_36
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0772, RMSE=0.2778, R²=0.0451
   Val:   Loss=0.0802, RMSE=0.2832, R²=0.0476
============================================================


============================================================
🔄 Round 163 - Client client_36
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0762, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0762, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0762, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0762, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0762, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0761, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 163 Summary - Client client_36
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0759, RMSE=0.2756, R²=0.0578
   Val:   Loss=0.0850, RMSE=0.2916, R²=0.0052
============================================================


============================================================
🔄 Round 165 - Client client_36
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0700 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0700, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0700, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0700, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0700, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0700, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0700)

============================================================
📊 Round 165 Summary - Client client_36
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=0.0466
   Val:   Loss=0.0700, RMSE=0.2646, R²=0.0472
============================================================


📊 Round 165 Test Metrics:
   Loss: 0.0794, RMSE: 0.2818, MAE: 0.2417, R²: 0.0497

📊 Round 165 Test Metrics:
   Loss: 0.0794, RMSE: 0.2818, MAE: 0.2417, R²: 0.0497

📊 Round 165 Test Metrics:
   Loss: 0.0794, RMSE: 0.2818, MAE: 0.2417, R²: 0.0497

📊 Round 165 Test Metrics:
   Loss: 0.0794, RMSE: 0.2818, MAE: 0.2417, R²: 0.0497

============================================================
🔄 Round 170 - Client client_36
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0719 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0719, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0719, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0719, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0719, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0719, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0719)

============================================================
📊 Round 170 Summary - Client client_36
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2815, R²=0.0481
   Val:   Loss=0.0719, RMSE=0.2681, R²=0.0368
============================================================


📊 Round 170 Test Metrics:
   Loss: 0.0794, RMSE: 0.2818, MAE: 0.2417, R²: 0.0497

============================================================
🔄 Round 171 - Client client_36
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0770, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0770, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0770, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0770, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0770, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0769, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 171 Summary - Client client_36
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0767, RMSE=0.2769, R²=0.0464
   Val:   Loss=0.0821, RMSE=0.2866, R²=0.0481
============================================================


============================================================
🔄 Round 172 - Client client_36
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0738 (↓), lr=0.000001
   • Epoch   2/100: train=0.0785, val=0.0738, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0785, val=0.0738, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0785, val=0.0738, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0785, val=0.0738, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0738, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0738)

============================================================
📊 Round 172 Summary - Client client_36
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2806, R²=0.0409
   Val:   Loss=0.0738, RMSE=0.2716, R²=0.0702
============================================================


============================================================
🔄 Round 173 - Client client_36
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0766, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0766, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0766, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0766, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0766, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0766, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 173 Summary - Client client_36
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0768, RMSE=0.2771, R²=0.0442
   Val:   Loss=0.0816, RMSE=0.2857, R²=0.0382
============================================================


📊 Round 173 Test Metrics:
   Loss: 0.0794, RMSE: 0.2818, MAE: 0.2417, R²: 0.0496

============================================================
🔄 Round 174 - Client client_36
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0712 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0712, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0712, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0712, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0712, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0712, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0712)

============================================================
📊 Round 174 Summary - Client client_36
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2818, R²=0.0465
   Val:   Loss=0.0712, RMSE=0.2669, R²=0.0417
============================================================


📊 Round 174 Test Metrics:
   Loss: 0.0794, RMSE: 0.2818, MAE: 0.2417, R²: 0.0496

📊 Round 174 Test Metrics:
   Loss: 0.0794, RMSE: 0.2818, MAE: 0.2417, R²: 0.0496

============================================================
🔄 Round 178 - Client client_36
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0767, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0767, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0767, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0767, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0767, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0766, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 178 Summary - Client client_36
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0766, RMSE=0.2768, R²=0.0396
   Val:   Loss=0.0824, RMSE=0.2870, R²=0.0722
============================================================


📊 Round 178 Test Metrics:
   Loss: 0.0794, RMSE: 0.2818, MAE: 0.2417, R²: 0.0496

============================================================
🔄 Round 180 - Client client_36
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0777, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0776, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0776, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0776, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0776, val=0.0780, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0776, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 180 Summary - Client client_36
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0777, RMSE=0.2787, R²=0.0540
   Val:   Loss=0.0781, RMSE=0.2794, R²=0.0145
============================================================


📊 Round 180 Test Metrics:
   Loss: 0.0794, RMSE: 0.2818, MAE: 0.2417, R²: 0.0497

📊 Round 180 Test Metrics:
   Loss: 0.0794, RMSE: 0.2818, MAE: 0.2417, R²: 0.0497

============================================================
🔄 Round 186 - Client client_36
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0631 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0631, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0631, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0631, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0631, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0630, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0631)

============================================================
📊 Round 186 Summary - Client client_36
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=0.0445
   Val:   Loss=0.0631, RMSE=0.2512, R²=0.0343
============================================================


📊 Round 186 Test Metrics:
   Loss: 0.0794, RMSE: 0.2817, MAE: 0.2417, R²: 0.0497

📊 Round 186 Test Metrics:
   Loss: 0.0794, RMSE: 0.2818, MAE: 0.2417, R²: 0.0497

============================================================
🔄 Round 189 - Client client_36
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0709 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0709, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0709, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0709, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0709, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0709, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0709)

============================================================
📊 Round 189 Summary - Client client_36
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2819, R²=0.0453
   Val:   Loss=0.0709, RMSE=0.2662, R²=0.0484
============================================================


============================================================
🔄 Round 190 - Client client_36
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0756, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0756, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0756, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0756, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0756, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0755, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 190 Summary - Client client_36
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0758, RMSE=0.2753, R²=0.0517
   Val:   Loss=0.0857, RMSE=0.2928, R²=0.0250
============================================================


📊 Round 190 Test Metrics:
   Loss: 0.0794, RMSE: 0.2817, MAE: 0.2417, R²: 0.0497

============================================================
🔄 Round 192 - Client client_36
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0749, val=0.0886 (↓), lr=0.000001
   • Epoch   2/100: train=0.0749, val=0.0886, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0749, val=0.0886, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0749, val=0.0886, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0748, val=0.0886, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0748, val=0.0887, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0886)

============================================================
📊 Round 192 Summary - Client client_36
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0751, RMSE=0.2740, R²=0.0526
   Val:   Loss=0.0886, RMSE=0.2977, R²=0.0127
============================================================


📊 Round 192 Test Metrics:
   Loss: 0.0794, RMSE: 0.2817, MAE: 0.2417, R²: 0.0497

📊 Round 192 Test Metrics:
   Loss: 0.0794, RMSE: 0.2817, MAE: 0.2417, R²: 0.0497

📊 Round 192 Test Metrics:
   Loss: 0.0794, RMSE: 0.2817, MAE: 0.2417, R²: 0.0497

📊 Round 192 Test Metrics:
   Loss: 0.0794, RMSE: 0.2817, MAE: 0.2417, R²: 0.0497

📊 Round 192 Test Metrics:
   Loss: 0.0794, RMSE: 0.2817, MAE: 0.2417, R²: 0.0497

============================================================
🔄 Round 197 - Client client_36
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0710 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0710, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0710, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0710, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0710, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0709, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0710)

============================================================
📊 Round 197 Summary - Client client_36
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2819, R²=0.0388
   Val:   Loss=0.0710, RMSE=0.2664, R²=0.0809
============================================================


============================================================
🔄 Round 198 - Client client_36
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0765, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0765, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0765, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0765, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0765, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0764, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 198 Summary - Client client_36
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0766, RMSE=0.2768, R²=0.0507
   Val:   Loss=0.0823, RMSE=0.2869, R²=0.0056
============================================================


📊 Round 198 Test Metrics:
   Loss: 0.0794, RMSE: 0.2818, MAE: 0.2417, R²: 0.0497

📊 Round 198 Test Metrics:
   Loss: 0.0794, RMSE: 0.2817, MAE: 0.2417, R²: 0.0497

============================================================
🔄 Round 202 - Client client_36
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0766, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0766, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0766, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0765, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0765, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0765, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 202 Summary - Client client_36
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0764, RMSE=0.2764, R²=0.0497
   Val:   Loss=0.0833, RMSE=0.2885, R²=0.0361
============================================================


============================================================
🔄 Round 203 - Client client_36
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0752 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0752, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0751, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0751, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0751, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0785, val=0.0751, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0752)

============================================================
📊 Round 203 Summary - Client client_36
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2800, R²=0.0478
   Val:   Loss=0.0752, RMSE=0.2742, R²=0.0347
============================================================


📊 Round 203 Test Metrics:
   Loss: 0.0794, RMSE: 0.2817, MAE: 0.2417, R²: 0.0498

============================================================
🔄 Round 204 - Client client_36
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0774, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0774, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0774, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0774, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0773, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0773, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 204 Summary - Client client_36
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0775, RMSE=0.2783, R²=0.0472
   Val:   Loss=0.0790, RMSE=0.2811, R²=0.0370
============================================================


📊 Round 204 Test Metrics:
   Loss: 0.0794, RMSE: 0.2817, MAE: 0.2417, R²: 0.0498

============================================================
🔄 Round 207 - Client client_36
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0766, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0766, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0766, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0766, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0766, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0765, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 207 Summary - Client client_36
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0766, RMSE=0.2768, R²=0.0530
   Val:   Loss=0.0823, RMSE=0.2868, R²=0.0136
============================================================


📊 Round 207 Test Metrics:
   Loss: 0.0794, RMSE: 0.2817, MAE: 0.2417, R²: 0.0498

============================================================
🔄 Round 208 - Client client_36
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0745 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0745, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0745, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0745, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0745, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0745, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0745)

============================================================
📊 Round 208 Summary - Client client_36
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2803, R²=0.0473
   Val:   Loss=0.0745, RMSE=0.2730, R²=0.0422
============================================================


📊 Round 208 Test Metrics:
   Loss: 0.0794, RMSE: 0.2817, MAE: 0.2417, R²: 0.0497

============================================================
🔄 Round 210 - Client client_36
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0705 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0705, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0705, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0704, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0704, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0704, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0705)

============================================================
📊 Round 210 Summary - Client client_36
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2821, R²=0.0434
   Val:   Loss=0.0705, RMSE=0.2655, R²=0.0557
============================================================


📊 Round 210 Test Metrics:
   Loss: 0.0794, RMSE: 0.2817, MAE: 0.2417, R²: 0.0497

============================================================
🔄 Round 212 - Client client_36
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0707 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0707, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0706, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0706, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0706, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0706, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0707)

============================================================
📊 Round 212 Summary - Client client_36
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2820, R²=0.0493
   Val:   Loss=0.0707, RMSE=0.2658, R²=0.0315
============================================================


============================================================
🔄 Round 213 - Client client_36
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0766, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0766, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0766, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0766, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0766, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0765, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 213 Summary - Client client_36
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0766, RMSE=0.2767, R²=0.0394
   Val:   Loss=0.0825, RMSE=0.2871, R²=0.0584
============================================================


📊 Round 213 Test Metrics:
   Loss: 0.0794, RMSE: 0.2817, MAE: 0.2417, R²: 0.0497

============================================================
🔄 Round 214 - Client client_36
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0769, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0769, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0769, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0769, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0769, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0768, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 214 Summary - Client client_36
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0767, RMSE=0.2769, R²=0.0445
   Val:   Loss=0.0821, RMSE=0.2866, R²=0.0529
============================================================


============================================================
🔄 Round 215 - Client client_36
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0758 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0758, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0783, val=0.0758, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0783, val=0.0759, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0783, val=0.0759, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0782, val=0.0760, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0758)

============================================================
📊 Round 215 Summary - Client client_36
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0782, RMSE=0.2797, R²=0.0377
   Val:   Loss=0.0758, RMSE=0.2753, R²=0.0538
============================================================


📊 Round 215 Test Metrics:
   Loss: 0.0794, RMSE: 0.2817, MAE: 0.2417, R²: 0.0497

============================================================
🔄 Round 217 - Client client_36
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0779, val=0.0769 (↓), lr=0.000001
   • Epoch   2/100: train=0.0778, val=0.0769, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0778, val=0.0769, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0778, val=0.0769, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0778, val=0.0769, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0777, val=0.0769, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0769)

============================================================
📊 Round 217 Summary - Client client_36
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0780, RMSE=0.2792, R²=0.0411
   Val:   Loss=0.0769, RMSE=0.2774, R²=0.0615
============================================================


📊 Round 217 Test Metrics:
   Loss: 0.0794, RMSE: 0.2817, MAE: 0.2417, R²: 0.0497

📊 Round 217 Test Metrics:
   Loss: 0.0794, RMSE: 0.2817, MAE: 0.2417, R²: 0.0497

📊 Round 217 Test Metrics:
   Loss: 0.0794, RMSE: 0.2817, MAE: 0.2417, R²: 0.0497

❌ Client client_36 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8687 {grpc_message:"Socket closed", grpc_status:14}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8687 {grpc_message:"Socket closed", grpc_status:14}"
>
