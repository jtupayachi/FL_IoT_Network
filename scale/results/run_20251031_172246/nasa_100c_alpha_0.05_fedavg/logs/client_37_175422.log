[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 36eb61af-6b68-47fa-a57c-3172466e6cb6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 06b87025-d19b-437f-911a-a55116f28510
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9b5d7198-2f84-4133-a091-e7efa00d4dd2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d5c5ad58-5ce9-4ff3-b10c-fc23911e2e06
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 379867da-4165-4f06-854b-380b10d3a479
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c0266385-9ed3-4c6f-858b-9297ea89845d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e2f4cf6f-28ba-4f7c-8318-99a7e3a36594
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eacfd517-bf12-42dc-a001-b7f5a3717e0f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 491ac669-4c76-4679-bf85-23c3807162d8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5376b4f0-7096-497e-9260-8843922a3614
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2a0cfc6d-7080-41df-8e20-8a04bf4934c9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c078a42c-a70c-488f-9067-ee7054a44d6f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aa06f84c-d7e8-462f-9ec4-0375d8a3207a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9e8b8bf2-93eb-4e43-8ec5-62e4563bf746
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8ea21ee5-230b-4576-a1f5-56a4632a50ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1974a4c4-b07f-424c-b43e-495ecec93fc3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 41acdfb8-f092-4e84-9428-0d8b09d5b682
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2410a7c5-ad13-4e67-b9e1-cc76213be848
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c4a32bd2-ab12-47d2-9862-6fd6f709e00e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 577b895b-b8e0-4a01-8271-0078c3983469
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2400c322-08b9-4bf9-a121-6a02312a8a43
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 64f6e495-eebb-40c2-bed7-24520e77c687
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bf483f42-8884-4f85-8264-c61b0bcefce3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cf099ab9-132d-461d-861e-0030ad998171
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3455ff1b-47ef-4a4c-9353-a80cb83bb747
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5d57cf48-f382-4422-bf1d-d5d1125f6946
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f13ba739-25b9-4e60-bc74-99084a4c108d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c2279253-791c-4cf5-8e9d-8268a12bd830
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f7aa392b-310b-4119-8297-01a9cb93f92d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7fa790ac-c69b-485e-9172-3971f2cfea89
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 56d7dc67-5d2b-4a45-bb75-8d7e939788ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b8f0c302-a416-47bf-a8e7-c5d8189b747f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c4aba7a7-9864-412a-a798-675a4e7870b6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 66eddb75-874f-4fd2-89dd-83f4f6611ae3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3b517657-0030-48bd-970f-fd352b354fa7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b2515d9d-1857-4cb0-80e3-81a246e2aa07
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e3313302-13b7-498c-aaa1-160da2d5344e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fc65ae3d-ea5c-48d5-b800-8c3f41a9920a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8c9ca7cc-f9fe-47d6-b600-517428a0e40a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f345640c-4d6e-404f-b690-76670680e0f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 81646d09-9c55-4002-9b5e-7141ed4b9187
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fab20d0a-16d3-47e5-b22c-da4fb6ed1b62
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2c2a5277-845e-46af-8e91-96442a3b2469
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a260e037-c534-4355-b7a8-1c85dc00a486
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2dbf90ba-a773-4f91-8bdd-6ec605db338e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9dd5182d-34dd-48ba-9bfb-e793c67b7e23
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 792174a9-0a9c-4a9d-ad3d-0f731bbe122f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ba967dfd-9111-402b-a50e-ef80c38a8ce0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3252bec3-89d9-413a-bc2b-8d398f1be979
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b6d32c56-2cc6-4a19-805a-8037b52cfee0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0e362ad3-74b1-4851-a558-033abea9306a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b66650bf-6717-4168-816a-51d8c31c1835
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 27f88ca5-44be-484b-b384-20f9d0300707
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8ca03ace-7a49-4e42-89ef-6952deda135f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 495ea38c-149b-43ec-9e5f-6f32fd814104
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f109deb2-4355-4f60-aae1-dd18d807983c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ef2d6c02-c9fd-475d-83bd-77a71767b57d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3adc0ac8-2674-4d2a-a4bf-0973b918c3bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 88a0ccaa-142f-4477-8881-a1791453da5c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 683b43b9-0c39-4b83-bfc8-9618e037e979
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b6bf2fd7-9cf8-4384-af5c-5a2d69a00740
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d467dbaa-e214-4e76-b5ef-e09c7d7d6dcf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message acfa5012-7902-4ec9-ac4a-ae0e91abd7f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6d944db3-3ea8-4758-9097-808849e6c748
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 80f32516-d1fe-4a1f-8866-a9f4b9e9ce44
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0f3d0e1e-edeb-4ee6-b3cd-d79888293b79
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 589e9934-04d5-4607-b8d5-e16b8e24f428
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1b49d03e-acc7-4b2e-ae13-a116e10a396b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c94c44c1-dcd1-46e7-91e0-bc5dc1495979
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2c0892ff-ccae-48b0-9212-acaa625e3ae4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bcf6cade-50d9-4b77-b2f8-ac498cb2b38d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 99aec32b-50a4-45ed-8c77-a5c7c6846159
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 21d71fd1-a0a8-4f9a-9d67-e12351f9db9c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8c7f4a56-283a-4d7d-9ddf-2da7c6a745f6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 42d5085e-eb3b-4ed7-8dcb-f973abcb7dac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4985ccc6-4bdc-42eb-8b5a-22c7d7103208
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 562526d0-681c-4fcd-8c4d-f9b78daffdd0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 91074618-c334-4011-bce9-5019bba252ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e94949fb-4ce4-4ce3-9985-6b401bb28edc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f75f8b09-f662-491c-a099-64f7d877d8ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f8b9bac3-921d-49a3-bda3-022c2ddb99bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1ab2fe75-c60f-4968-8be4-eb0fccfe46d5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4bf090b5-0a20-4842-87d9-7e631b3c8746
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 50107631-320c-4bcb-a604-b2337a2fbf2f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 89be71b3-3060-462f-912a-2263fded489f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 655b1081-61ee-4c36-aaea-eb691843ed91
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a5b21baf-db2c-434f-9cb7-6816fc646d59
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cf454e64-a52c-4b98-b140-3542498362f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 941c885e-78ae-4f25-a238-572f7f410cf4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1907ddc8-cf9b-415a-8ef8-f5fd1b30ec44
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ec3ae317-7992-47c1-87ad-66b0362d1dff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 52e6bbc4-00dc-49e5-8914-ba89a0db9e64
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 79bfb1ae-7a23-451d-8fc3-b36649423661
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b45d6656-6791-4942-b90d-59747a92aa6a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ca10d886-ef2b-4df7-acde-494404d331f9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 87047dd0-ff67-4bc3-9c45-9c546e35fe2f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 890175ab-29a0-429c-b89e-9aabc9134491
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 509aacf0-63b3-4fa2-9dc7-86061ed57b73
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b8d8cd9c-0fef-4c0a-b469-19f33f828c98
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b5d70808-d864-40f8-bb57-2cc8607df42e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ae70d63e-50b1-4100-8146-b0005c3ae098
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ab5daafa-471d-41f1-9241-5156cccd8dd9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message da1f06be-bcb9-4ffd-97e9-dfc184158db6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5ab0f801-876a-466d-ba85-e9e7faca40b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 855bcadc-8239-4852-92c5-02327b087ca7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 78bd2875-538f-4c48-93ff-3673c3b3cd48
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d2dcc0e8-63a7-4b74-b469-250f43971669
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7896ec53-9a8a-495e-bf60-f62379f89b75
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c1a67046-4a0a-4b17-b9ac-b5c881a67a05
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d639049e-40c7-47d2-aca4-ff786f6dcc71
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 54595b29-2997-402f-91b2-c87a63b78505
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dc2134fa-f94d-4288-94f0-fbe6e2a8712d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8de89eb4-8de2-4516-ac8d-9ef0e7648f4d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cd19e4af-5096-42fa-a1fc-635e3a559dab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 478675b6-3a94-4067-bcbf-e570e250091e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8670d28c-683f-4da5-a3ae-85b9d4f04c23
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 244ce6e2-73fc-498a-90c4-59cf24c376ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message adcab15a-3204-44f7-829d-e776bf323b1c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d7f6ab06-b401-498c-a5ac-003929c2cea6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6405ff6b-e74b-4752-af92-0474a230eb70
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0b9449e4-c774-422d-82cc-6ae33eb11bf6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 573c1f53-e9c1-4656-a8d2-a92019c4cd71
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 707370d5-c23b-4827-8fdf-c221064be09a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 68e57eec-dca6-429b-8bee-23807907e974
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message edf74130-c389-4392-823a-28461e624f27
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 94bc63a7-e5b5-4be5-96fb-5faf3d11ed09
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 54d020ed-42f8-4fc5-bbff-44dea096c436
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0eba4007-d47d-4188-8dfa-5f6de22bd70d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0f59e2e3-ec6f-4fa5-9c41-29e28e5710d9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9b1babd1-49fd-4539-99fe-ba664dcf24e6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0bdadc59-9fda-4dd7-b39d-1f4278a6cf7e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eae726a9-9c33-4414-8530-aad3a01e07d8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a5badcc3-1d4f-4714-836f-a2adfcca3f23
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9ab7cd93-2fad-42dc-a584-df5c03b51b22
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message da53fe95-aadd-4ec4-9509-e8007b2e7e46
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 57495c96-de05-4971-92a1-4511bfbcd3b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7d68cb8b-5ff2-42df-9cfe-433c5c51a6ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 38b6d109-bc09-4171-8ad2-52060c47696c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3630d9dd-b854-49a2-a851-a808f8f42809
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 56e493e0-343f-4caa-9219-bb0c8c9faa37
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4e976327-a194-42e7-9571-d44d59b7781a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a2eccb02-b9f2-4ba9-9e30-e179ff516f10
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8b144136-112d-48b0-84db-be5d951ef353
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 84187a0e-84ef-4a2d-891e-8e3fa94d74b6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ea562c43-c8b9-48dd-b70f-625f90403362
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b0a18635-d634-4802-9b48-e2716aceef96
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 41f208b1-76ea-4c71-bf7a-08a391b0b353
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b9c2521c-b325-4d82-a245-f3a11509f683
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2dce3e82-a809-4bfb-bf6f-dfedb9ee0f33
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 81cdeffa-6696-4305-bc92-671620024dcb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2b1fdee9-5fcc-43fb-a76f-4d4c0a2ffd3e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ee4adef5-a9e1-4f84-91b3-abf1775488e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a88f6fe0-0630-4566-8fac-8e5c2e2ed1ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0e3123bc-32c0-45d1-8309-a5828af61839
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 84ed1dea-9587-4de8-b561-18105549113f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e8f1da42-4a89-4430-ba66-5dd182c899cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0b58707e-747e-4149-9f01-3c0375932472
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 606993e4-b449-41f4-a2af-cbc302b0a0d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 42840740-5f98-48b2-8525-f1c4f73e632e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 94e3bf21-a2f0-4790-a985-fcddd5bff7e9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message be279692-8c62-4f07-8045-a64d351e30dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2fc9ec78-614e-4773-b263-a19c95509114
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4d31474e-02f6-4f51-b6fd-7b4baa828fbf
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8687 {grpc_status:14, grpc_message:"Socket closed"}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_37
Server: localhost:8687
Algorithm: FEDAVG
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_37
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_37/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_37/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_37/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_37/test_labels.txt

📊 Raw data loaded:
   Train: X=(1276, 24), y=(1276,)
   Test:  X=(319, 24), y=(319,)

⚠️  Limiting training data: 1276 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  310 samples, 5 features
✅ Client client_37 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

📊 Round 0 Test Metrics:
   Loss: 0.0803, RMSE: 0.2834, MAE: 0.2434, R²: 0.0002

📊 Round 0 Test Metrics:
   Loss: 0.0792, RMSE: 0.2815, MAE: 0.2414, R²: 0.0136

📊 Round 0 Test Metrics:
   Loss: 0.0788, RMSE: 0.2806, MAE: 0.2405, R²: 0.0197

📊 Round 0 Test Metrics:
   Loss: 0.0784, RMSE: 0.2801, MAE: 0.2399, R²: 0.0236

============================================================
🔄 Round 9 - Client client_37
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0817 (↓), lr=0.001000
   • Epoch   2/100: train=0.0813, val=0.0829, patience=1/15, lr=0.001000
   • Epoch   3/100: train=0.0819, val=0.0821, patience=2/15, lr=0.001000
   ✓ Epoch   4/100: train=0.0815, val=0.0804 (↓), lr=0.001000
   • Epoch   5/100: train=0.0800, val=0.0803, patience=1/15, lr=0.001000
   • Epoch  11/100: train=0.0752, val=0.0809, patience=7/15, lr=0.001000
   📉 Epoch 13: LR reduced 0.001000 → 0.000500

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 9 Summary - Client client_37
   Epochs: 19/100 (early stopped)
   LR: 0.001000 → 0.000500 (1 reductions)
   Train: Loss=0.0789, RMSE=0.2809, R²=0.0553
   Val:   Loss=0.0804, RMSE=0.2835, R²=0.0165
============================================================


============================================================
🔄 Round 10 - Client client_37
   Epochs: 100, Batch: 32, LR: 0.000500
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0781 (↓), lr=0.000500
   ✓ Epoch   2/100: train=0.0831, val=0.0752 (↓), lr=0.000500
   • Epoch   3/100: train=0.0820, val=0.0758, patience=1/15, lr=0.000500
   • Epoch   4/100: train=0.0817, val=0.0757, patience=2/15, lr=0.000500
   • Epoch   5/100: train=0.0813, val=0.0758, patience=3/15, lr=0.000500
   • Epoch  11/100: train=0.0789, val=0.0753, patience=9/15, lr=0.000500
   📉 Epoch 15: LR reduced 0.000500 → 0.000250
   • Epoch  21/100: train=0.0753, val=0.0738, patience=5/15, lr=0.000250
   📉 Epoch 23: LR reduced 0.000250 → 0.000125
   📉 Epoch 31: LR reduced 0.000125 → 0.000063
   • Epoch  31/100: train=0.0735, val=0.0737, patience=15/15, lr=0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0736)

============================================================
📊 Round 10 Summary - Client client_37
   Epochs: 31/100 (early stopped)
   LR: 0.000500 → 0.000063 (3 reductions)
   Train: Loss=0.0756, RMSE=0.2749, R²=0.1056
   Val:   Loss=0.0736, RMSE=0.2713, R²=0.0301
============================================================


============================================================
🔄 Round 11 - Client client_37
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0911 (↓), lr=0.000063
   • Epoch   2/100: train=0.0783, val=0.0911, patience=1/15, lr=0.000063
   • Epoch   3/100: train=0.0782, val=0.0912, patience=2/15, lr=0.000063
   • Epoch   4/100: train=0.0780, val=0.0912, patience=3/15, lr=0.000063
   • Epoch   5/100: train=0.0779, val=0.0913, patience=4/15, lr=0.000063
   📉 Epoch 8: LR reduced 0.000063 → 0.000031
   • Epoch  11/100: train=0.0774, val=0.0916, patience=10/15, lr=0.000031
   📉 Epoch 16: LR reduced 0.000031 → 0.000016

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0911)

============================================================
📊 Round 11 Summary - Client client_37
   Epochs: 16/100 (early stopped)
   LR: 0.000063 → 0.000016 (2 reductions)
   Train: Loss=0.0783, RMSE=0.2798, R²=0.0333
   Val:   Loss=0.0911, RMSE=0.3018, R²=0.0081
============================================================


📊 Round 11 Test Metrics:
   Loss: 0.0785, RMSE: 0.2801, MAE: 0.2400, R²: 0.0234

============================================================
🔄 Round 12 - Client client_37
   Epochs: 100, Batch: 32, LR: 0.000016
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0682 (↓), lr=0.000016
   • Epoch   2/100: train=0.0841, val=0.0682, patience=1/15, lr=0.000016
   • Epoch   3/100: train=0.0841, val=0.0682, patience=2/15, lr=0.000016
   • Epoch   4/100: train=0.0841, val=0.0682, patience=3/15, lr=0.000016
   • Epoch   5/100: train=0.0840, val=0.0682, patience=4/15, lr=0.000016
   • Epoch  11/100: train=0.0838, val=0.0681, patience=10/15, lr=0.000016

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0682)

============================================================
📊 Round 12 Summary - Client client_37
   Epochs: 16/100 (early stopped)
   LR: 0.000016 → 0.000016 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=0.0231
   Val:   Loss=0.0682, RMSE=0.2612, R²=0.0381
============================================================


============================================================
🔄 Round 16 - Client client_37
   Epochs: 100, Batch: 32, LR: 0.000016
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0807 (↓), lr=0.000016
   • Epoch   2/100: train=0.0810, val=0.0808, patience=1/15, lr=0.000016
   • Epoch   3/100: train=0.0809, val=0.0808, patience=2/15, lr=0.000016
   • Epoch   4/100: train=0.0808, val=0.0808, patience=3/15, lr=0.000016
   • Epoch   5/100: train=0.0807, val=0.0808, patience=4/15, lr=0.000016
   📉 Epoch 6: LR reduced 0.000016 → 0.000008
   • Epoch  11/100: train=0.0805, val=0.0809, patience=10/15, lr=0.000008
   📉 Epoch 14: LR reduced 0.000008 → 0.000004

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 16 Summary - Client client_37
   Epochs: 16/100 (early stopped)
   LR: 0.000016 → 0.000004 (2 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=0.0305
   Val:   Loss=0.0807, RMSE=0.2841, R²=0.0124
============================================================


📊 Round 16 Test Metrics:
   Loss: 0.0783, RMSE: 0.2799, MAE: 0.2397, R²: 0.0249

============================================================
🔄 Round 18 - Client client_37
   Epochs: 100, Batch: 32, LR: 0.000004
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0897 (↓), lr=0.000004
   • Epoch   2/100: train=0.0787, val=0.0897, patience=1/15, lr=0.000004
   • Epoch   3/100: train=0.0787, val=0.0897, patience=2/15, lr=0.000004
   • Epoch   4/100: train=0.0787, val=0.0897, patience=3/15, lr=0.000004
   • Epoch   5/100: train=0.0787, val=0.0898, patience=4/15, lr=0.000004
   📉 Epoch 6: LR reduced 0.000004 → 0.000002
   • Epoch  11/100: train=0.0786, val=0.0898, patience=10/15, lr=0.000002
   📉 Epoch 14: LR reduced 0.000002 → 0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0897)

============================================================
📊 Round 18 Summary - Client client_37
   Epochs: 16/100 (early stopped)
   LR: 0.000004 → 0.000001 (2 reductions)
   Train: Loss=0.0787, RMSE=0.2805, R²=0.0290
   Val:   Loss=0.0897, RMSE=0.2995, R²=0.0033
============================================================


📊 Round 18 Test Metrics:
   Loss: 0.0783, RMSE: 0.2798, MAE: 0.2396, R²: 0.0252

============================================================
🔄 Round 19 - Client client_37
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0781, val=0.0911 (↓), lr=0.000001
   • Epoch   2/100: train=0.0781, val=0.0911, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0781, val=0.0911, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0781, val=0.0911, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0781, val=0.0911, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0781, val=0.0911, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0911)

============================================================
📊 Round 19 Summary - Client client_37
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2799, R²=0.0301
   Val:   Loss=0.0911, RMSE=0.3018, R²=0.0170
============================================================


📊 Round 19 Test Metrics:
   Loss: 0.0783, RMSE: 0.2799, MAE: 0.2396, R²: 0.0249

📊 Round 19 Test Metrics:
   Loss: 0.0783, RMSE: 0.2797, MAE: 0.2394, R²: 0.0259

📊 Round 19 Test Metrics:
   Loss: 0.0783, RMSE: 0.2798, MAE: 0.2394, R²: 0.0259

📊 Round 19 Test Metrics:
   Loss: 0.0782, RMSE: 0.2797, MAE: 0.2394, R²: 0.0260

============================================================
🔄 Round 28 - Client client_37
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 28 Summary - Client client_37
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2852, R²=0.0240
   Val:   Loss=0.0788, RMSE=0.2807, R²=0.0436
============================================================


============================================================
🔄 Round 29 - Client client_37
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0886 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0886, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0886, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0886, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0886, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0886, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0886)

============================================================
📊 Round 29 Summary - Client client_37
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2809, R²=0.0269
   Val:   Loss=0.0886, RMSE=0.2977, R²=0.0322
============================================================


📊 Round 29 Test Metrics:
   Loss: 0.0782, RMSE: 0.2797, MAE: 0.2394, R²: 0.0260

============================================================
🔄 Round 32 - Client client_37
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 32 Summary - Client client_37
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=0.0277
   Val:   Loss=0.0792, RMSE=0.2814, R²=0.0297
============================================================


============================================================
🔄 Round 33 - Client client_37
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0863 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 33 Summary - Client client_37
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2819, R²=0.0279
   Val:   Loss=0.0863, RMSE=0.2937, R²=0.0264
============================================================


============================================================
🔄 Round 34 - Client client_37
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0763 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0763, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0763, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0763, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0763, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0763, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0763)

============================================================
📊 Round 34 Summary - Client client_37
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=0.0297
   Val:   Loss=0.0763, RMSE=0.2763, R²=0.0151
============================================================


📊 Round 34 Test Metrics:
   Loss: 0.0782, RMSE: 0.2797, MAE: 0.2394, R²: 0.0262

📊 Round 34 Test Metrics:
   Loss: 0.0782, RMSE: 0.2797, MAE: 0.2394, R²: 0.0261

============================================================
🔄 Round 37 - Client client_37
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 37 Summary - Client client_37
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2829, R²=0.0286
   Val:   Loss=0.0839, RMSE=0.2897, R²=0.0169
============================================================


============================================================
🔄 Round 38 - Client client_37
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0880 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0880, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0880, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0880, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0880, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0880, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0880)

============================================================
📊 Round 38 Summary - Client client_37
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2811, R²=0.0307
   Val:   Loss=0.0880, RMSE=0.2966, R²=0.0174
============================================================


📊 Round 38 Test Metrics:
   Loss: 0.0782, RMSE: 0.2797, MAE: 0.2394, R²: 0.0262

============================================================
🔄 Round 39 - Client client_37
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 39 Summary - Client client_37
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=0.0246
   Val:   Loss=0.0808, RMSE=0.2843, R²=0.0239
============================================================


📊 Round 39 Test Metrics:
   Loss: 0.0782, RMSE: 0.2797, MAE: 0.2394, R²: 0.0262

============================================================
🔄 Round 40 - Client client_37
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 40 Summary - Client client_37
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=0.0310
   Val:   Loss=0.0808, RMSE=0.2842, R²=0.0168
============================================================


============================================================
🔄 Round 41 - Client client_37
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0746 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0746, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0746, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0746, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0746, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0746, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0746)

============================================================
📊 Round 41 Summary - Client client_37
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=0.0217
   Val:   Loss=0.0746, RMSE=0.2731, R²=0.0511
============================================================


============================================================
🔄 Round 44 - Client client_37
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 44 Summary - Client client_37
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=0.0307
   Val:   Loss=0.0806, RMSE=0.2840, R²=0.0165
============================================================


📊 Round 44 Test Metrics:
   Loss: 0.0782, RMSE: 0.2797, MAE: 0.2394, R²: 0.0263

============================================================
🔄 Round 45 - Client client_37
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 45 Summary - Client client_37
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=0.0263
   Val:   Loss=0.0822, RMSE=0.2867, R²=0.0280
============================================================


📊 Round 45 Test Metrics:
   Loss: 0.0782, RMSE: 0.2797, MAE: 0.2394, R²: 0.0263

📊 Round 45 Test Metrics:
   Loss: 0.0782, RMSE: 0.2797, MAE: 0.2394, R²: 0.0262

============================================================
🔄 Round 48 - Client client_37
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 48 Summary - Client client_37
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2822, R²=0.0230
   Val:   Loss=0.0857, RMSE=0.2927, R²=0.0474
============================================================


============================================================
🔄 Round 49 - Client client_37
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0707 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0707, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0707, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0706, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0706, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0706, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0707)

============================================================
📊 Round 49 Summary - Client client_37
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2887, R²=0.0268
   Val:   Loss=0.0707, RMSE=0.2658, R²=0.0342
============================================================


📊 Round 49 Test Metrics:
   Loss: 0.0782, RMSE: 0.2797, MAE: 0.2394, R²: 0.0263

📊 Round 49 Test Metrics:
   Loss: 0.0782, RMSE: 0.2797, MAE: 0.2394, R²: 0.0263

============================================================
🔄 Round 52 - Client client_37
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 52 Summary - Client client_37
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=0.0257
   Val:   Loss=0.0823, RMSE=0.2868, R²=0.0378
============================================================


📊 Round 52 Test Metrics:
   Loss: 0.0782, RMSE: 0.2797, MAE: 0.2394, R²: 0.0264

📊 Round 52 Test Metrics:
   Loss: 0.0782, RMSE: 0.2797, MAE: 0.2394, R²: 0.0262

📊 Round 52 Test Metrics:
   Loss: 0.0782, RMSE: 0.2797, MAE: 0.2394, R²: 0.0262

📊 Round 52 Test Metrics:
   Loss: 0.0782, RMSE: 0.2797, MAE: 0.2394, R²: 0.0264

============================================================
🔄 Round 67 - Client client_37
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 67 Summary - Client client_37
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2852, R²=0.0320
   Val:   Loss=0.0788, RMSE=0.2807, R²=0.0013
============================================================


📊 Round 67 Test Metrics:
   Loss: 0.0782, RMSE: 0.2797, MAE: 0.2393, R²: 0.0265

📊 Round 67 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2393, R²: 0.0266

============================================================
🔄 Round 77 - Client client_37
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 77 Summary - Client client_37
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=0.0311
   Val:   Loss=0.0793, RMSE=0.2815, R²=0.0167
============================================================


📊 Round 77 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2393, R²: 0.0267

============================================================
🔄 Round 79 - Client client_37
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 79 Summary - Client client_37
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2829, R²=0.0293
   Val:   Loss=0.0839, RMSE=0.2897, R²=0.0210
============================================================


📊 Round 79 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2393, R²: 0.0268

📊 Round 79 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2393, R²: 0.0268

📊 Round 79 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2393, R²: 0.0268

📊 Round 79 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2393, R²: 0.0267

📊 Round 79 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2393, R²: 0.0268

📊 Round 79 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2393, R²: 0.0267

============================================================
🔄 Round 89 - Client client_37
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 89 Summary - Client client_37
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=0.0285
   Val:   Loss=0.0795, RMSE=0.2820, R²=0.0187
============================================================


📊 Round 89 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2393, R²: 0.0268

📊 Round 89 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2393, R²: 0.0268

============================================================
🔄 Round 91 - Client client_37
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 91 Summary - Client client_37
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2840, R²=0.0241
   Val:   Loss=0.0814, RMSE=0.2853, R²=0.0417
============================================================


📊 Round 91 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2393, R²: 0.0269

============================================================
🔄 Round 93 - Client client_37
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0778, val=0.0924 (↓), lr=0.000001
   • Epoch   2/100: train=0.0778, val=0.0924, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0778, val=0.0924, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0778, val=0.0924, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0778, val=0.0924, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0778, val=0.0925, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0924)

============================================================
📊 Round 93 Summary - Client client_37
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0779, RMSE=0.2791, R²=0.0219
   Val:   Loss=0.0924, RMSE=0.3040, R²=0.0435
============================================================


📊 Round 93 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2393, R²: 0.0269

📊 Round 93 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2393, R²: 0.0270

============================================================
🔄 Round 99 - Client client_37
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 99 Summary - Client client_37
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=0.0309
   Val:   Loss=0.0795, RMSE=0.2820, R²=0.0180
============================================================


📊 Round 99 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2393, R²: 0.0271

📊 Round 99 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2393, R²: 0.0272

📊 Round 99 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2393, R²: 0.0272

============================================================
🔄 Round 108 - Client client_37
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0905 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0905, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0905, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0905, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0905, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0905, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0905)

============================================================
📊 Round 108 Summary - Client client_37
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2800, R²=0.0338
   Val:   Loss=0.0905, RMSE=0.3008, R²=0.0079
============================================================


📊 Round 108 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2393, R²: 0.0272

📊 Round 108 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2393, R²: 0.0272

============================================================
🔄 Round 112 - Client client_37
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0781, val=0.0917 (↓), lr=0.000001
   • Epoch   2/100: train=0.0781, val=0.0917, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0780, val=0.0917, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0780, val=0.0918, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0780, val=0.0918, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0780, val=0.0918, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0917)

============================================================
📊 Round 112 Summary - Client client_37
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0781, RMSE=0.2794, R²=0.0338
   Val:   Loss=0.0917, RMSE=0.3029, R²=-0.0050
============================================================


📊 Round 112 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2393, R²: 0.0272

============================================================
🔄 Round 113 - Client client_37
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 113 Summary - Client client_37
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=0.0287
   Val:   Loss=0.0842, RMSE=0.2902, R²=0.0162
============================================================


📊 Round 113 Test Metrics:
   Loss: 0.0781, RMSE: 0.2796, MAE: 0.2393, R²: 0.0273

📊 Round 113 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2393, R²: 0.0273

============================================================
🔄 Round 116 - Client client_37
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 116 Summary - Client client_37
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=0.0282
   Val:   Loss=0.0793, RMSE=0.2817, R²=0.0289
============================================================


📊 Round 116 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2392, R²: 0.0274

============================================================
🔄 Round 119 - Client client_37
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0736 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0736, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0736, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0736, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0736, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0736, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0736)

============================================================
📊 Round 119 Summary - Client client_37
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=0.0217
   Val:   Loss=0.0736, RMSE=0.2712, R²=0.0490
============================================================


📊 Round 119 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2392, R²: 0.0276

============================================================
🔄 Round 123 - Client client_37
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0730 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0730, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0730, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0730, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0730, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0730, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0730)

============================================================
📊 Round 123 Summary - Client client_37
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=0.0254
   Val:   Loss=0.0730, RMSE=0.2702, R²=0.0411
============================================================


📊 Round 123 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2392, R²: 0.0275

============================================================
🔄 Round 125 - Client client_37
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0731 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0731, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0731, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0731, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0731, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0731, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0731)

============================================================
📊 Round 125 Summary - Client client_37
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=0.0334
   Val:   Loss=0.0731, RMSE=0.2705, R²=0.0056
============================================================


📊 Round 125 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2392, R²: 0.0275

📊 Round 125 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2392, R²: 0.0274

============================================================
🔄 Round 131 - Client client_37
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 131 Summary - Client client_37
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2820, R²=0.0271
   Val:   Loss=0.0858, RMSE=0.2929, R²=0.0333
============================================================


📊 Round 131 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2392, R²: 0.0274

============================================================
🔄 Round 133 - Client client_37
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 133 Summary - Client client_37
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=0.0254
   Val:   Loss=0.0804, RMSE=0.2836, R²=0.0394
============================================================


============================================================
🔄 Round 134 - Client client_37
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 134 Summary - Client client_37
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=0.0264
   Val:   Loss=0.0847, RMSE=0.2910, R²=0.0284
============================================================


📊 Round 134 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2392, R²: 0.0274

============================================================
🔄 Round 140 - Client client_37
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 140 Summary - Client client_37
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=0.0291
   Val:   Loss=0.0805, RMSE=0.2836, R²=0.0135
============================================================


📊 Round 140 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2392, R²: 0.0274

============================================================
🔄 Round 141 - Client client_37
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 141 Summary - Client client_37
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2847, R²=0.0260
   Val:   Loss=0.0797, RMSE=0.2822, R²=0.0273
============================================================


============================================================
🔄 Round 142 - Client client_37
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0752 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0752, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0752, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0752, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0752, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0753, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0752)

============================================================
📊 Round 142 Summary - Client client_37
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=0.0281
   Val:   Loss=0.0752, RMSE=0.2743, R²=0.0303
============================================================


📊 Round 142 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2392, R²: 0.0275

📊 Round 142 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2392, R²: 0.0275

📊 Round 142 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2392, R²: 0.0275

============================================================
🔄 Round 147 - Client client_37
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 147 Summary - Client client_37
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=0.0290
   Val:   Loss=0.0809, RMSE=0.2845, R²=0.0241
============================================================


📊 Round 147 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2392, R²: 0.0276

📊 Round 147 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2392, R²: 0.0276

============================================================
🔄 Round 149 - Client client_37
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 149 Summary - Client client_37
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2838, R²=0.0262
   Val:   Loss=0.0818, RMSE=0.2860, R²=0.0245
============================================================


📊 Round 149 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2392, R²: 0.0275

📊 Round 149 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2392, R²: 0.0275

============================================================
🔄 Round 151 - Client client_37
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 151 Summary - Client client_37
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=0.0265
   Val:   Loss=0.0815, RMSE=0.2854, R²=0.0335
============================================================


📊 Round 151 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2392, R²: 0.0276

📊 Round 151 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2392, R²: 0.0276

📊 Round 151 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2392, R²: 0.0276

============================================================
🔄 Round 154 - Client client_37
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0764 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0764, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0764, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0764, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0764, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0764, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0764)

============================================================
📊 Round 154 Summary - Client client_37
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2861, R²=0.0269
   Val:   Loss=0.0764, RMSE=0.2764, R²=0.0335
============================================================


📊 Round 154 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2392, R²: 0.0276

📊 Round 154 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2392, R²: 0.0276

============================================================
🔄 Round 158 - Client client_37
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0765 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0765, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0765, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0765, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0765, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0766, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0765)

============================================================
📊 Round 158 Summary - Client client_37
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2861, R²=0.0282
   Val:   Loss=0.0765, RMSE=0.2766, R²=0.0109
============================================================


📊 Round 158 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2392, R²: 0.0277

📊 Round 158 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2392, R²: 0.0276

📊 Round 158 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2392, R²: 0.0276

============================================================
🔄 Round 162 - Client client_37
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0877 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0877, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0877, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0877, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0877, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0877, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0877)

============================================================
📊 Round 162 Summary - Client client_37
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2812, R²=0.0330
   Val:   Loss=0.0877, RMSE=0.2961, R²=0.0096
============================================================


📊 Round 162 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2392, R²: 0.0277

📊 Round 162 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2392, R²: 0.0277

📊 Round 162 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2392, R²: 0.0276

📊 Round 162 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2392, R²: 0.0276

📊 Round 162 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2392, R²: 0.0276

📊 Round 162 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2392, R²: 0.0277

============================================================
🔄 Round 172 - Client client_37
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 172 Summary - Client client_37
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=0.0301
   Val:   Loss=0.0842, RMSE=0.2902, R²=0.0181
============================================================


📊 Round 172 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2392, R²: 0.0277

📊 Round 172 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2392, R²: 0.0277

============================================================
🔄 Round 174 - Client client_37
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0767, val=0.0975 (↓), lr=0.000001
   • Epoch   2/100: train=0.0767, val=0.0975, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0767, val=0.0975, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0767, val=0.0975, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0766, val=0.0975, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0766, val=0.0975, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0975)

============================================================
📊 Round 174 Summary - Client client_37
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0766, RMSE=0.2768, R²=0.0255
   Val:   Loss=0.0975, RMSE=0.3123, R²=0.0377
============================================================


============================================================
🔄 Round 176 - Client client_37
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 176 Summary - Client client_37
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2831, R²=0.0308
   Val:   Loss=0.0834, RMSE=0.2887, R²=0.0206
============================================================


📊 Round 176 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2392, R²: 0.0278

📊 Round 176 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2392, R²: 0.0277

📊 Round 176 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2392, R²: 0.0277

============================================================
🔄 Round 183 - Client client_37
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0863 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0864, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 183 Summary - Client client_37
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2818, R²=0.0336
   Val:   Loss=0.0863, RMSE=0.2938, R²=-0.0005
============================================================


============================================================
🔄 Round 185 - Client client_37
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0751 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0751, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0751, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0751, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0751, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0751, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0751)

============================================================
📊 Round 185 Summary - Client client_37
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=0.0322
   Val:   Loss=0.0751, RMSE=0.2740, R²=0.0105
============================================================


============================================================
🔄 Round 186 - Client client_37
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 186 Summary - Client client_37
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2845, R²=0.0288
   Val:   Loss=0.0801, RMSE=0.2830, R²=0.0078
============================================================


📊 Round 186 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2392, R²: 0.0276

============================================================
🔄 Round 187 - Client client_37
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 187 Summary - Client client_37
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=0.0295
   Val:   Loss=0.0805, RMSE=0.2837, R²=0.0207
============================================================


============================================================
🔄 Round 188 - Client client_37
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 188 Summary - Client client_37
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=0.0254
   Val:   Loss=0.0791, RMSE=0.2813, R²=0.0099
============================================================


📊 Round 188 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2392, R²: 0.0276

📊 Round 188 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2392, R²: 0.0276

📊 Round 188 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2392, R²: 0.0276

============================================================
🔄 Round 192 - Client client_37
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0769 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0769, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0770, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0770, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0770, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0769)

============================================================
📊 Round 192 Summary - Client client_37
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2859, R²=0.0215
   Val:   Loss=0.0769, RMSE=0.2773, R²=0.0026
============================================================


============================================================
🔄 Round 193 - Client client_37
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0758 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0758, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0758, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0758, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0758, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0757, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0758)

============================================================
📊 Round 193 Summary - Client client_37
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=0.0291
   Val:   Loss=0.0758, RMSE=0.2752, R²=0.0266
============================================================


📊 Round 193 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2392, R²: 0.0276

📊 Round 193 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2392, R²: 0.0276

============================================================
🔄 Round 195 - Client client_37
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 195 Summary - Client client_37
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=0.0329
   Val:   Loss=0.0831, RMSE=0.2883, R²=0.0071
============================================================


📊 Round 195 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2392, R²: 0.0276

📊 Round 195 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2392, R²: 0.0277

============================================================
🔄 Round 202 - Client client_37
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0769 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0769, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0769, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0769, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0769, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0769, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0769)

============================================================
📊 Round 202 Summary - Client client_37
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2859, R²=0.0315
   Val:   Loss=0.0769, RMSE=0.2773, R²=0.0164
============================================================


============================================================
🔄 Round 203 - Client client_37
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 203 Summary - Client client_37
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=0.0209
   Val:   Loss=0.0848, RMSE=0.2911, R²=0.0497
============================================================


📊 Round 203 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2392, R²: 0.0276

============================================================
🔄 Round 208 - Client client_37
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 208 Summary - Client client_37
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=0.0296
   Val:   Loss=0.0822, RMSE=0.2867, R²=0.0159
============================================================


📊 Round 208 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2392, R²: 0.0278

📊 Round 208 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2392, R²: 0.0278

============================================================
🔄 Round 212 - Client client_37
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 212 Summary - Client client_37
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2845, R²=0.0313
   Val:   Loss=0.0800, RMSE=0.2829, R²=0.0181
============================================================


📊 Round 212 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2392, R²: 0.0279

📊 Round 212 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2392, R²: 0.0278

============================================================
🔄 Round 216 - Client client_37
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 216 Summary - Client client_37
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2821, R²=0.0248
   Val:   Loss=0.0857, RMSE=0.2928, R²=0.0421
============================================================


📊 Round 216 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2392, R²: 0.0277

📊 Round 216 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2392, R²: 0.0278

============================================================
🔄 Round 221 - Client client_37
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 221 Summary - Client client_37
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=0.0297
   Val:   Loss=0.0791, RMSE=0.2813, R²=0.0248
============================================================


============================================================
🔄 Round 222 - Client client_37
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 222 Summary - Client client_37
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2842, R²=0.0304
   Val:   Loss=0.0809, RMSE=0.2845, R²=0.0218
============================================================


============================================================
🔄 Round 223 - Client client_37
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0754 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0754, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0754, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0754, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0754, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0754, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0754)

============================================================
📊 Round 223 Summary - Client client_37
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2866, R²=0.0213
   Val:   Loss=0.0754, RMSE=0.2746, R²=0.0474
============================================================


❌ Client client_37 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8687 {grpc_status:14, grpc_message:"Socket closed"}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8687 {grpc_status:14, grpc_message:"Socket closed"}"
>
