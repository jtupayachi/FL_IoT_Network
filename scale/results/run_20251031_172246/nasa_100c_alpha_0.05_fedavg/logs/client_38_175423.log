[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: train message abe52360-0aa3-4b57-8f1c-c011ec36de7c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0576a0f1-f0ac-4f35-9843-e7a430742a53
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 09f1c46f-1da0-4a14-a285-b8a4e8ce70d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 59574f80-d254-46c9-ac48-3e5e9897cdc9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a3ed27cb-afbb-472f-a28b-ab0f709db6b8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c19bad63-d8ec-4ae3-aa68-6473d1cbccdb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f99d070f-9db6-484b-a4e9-eec34dc14ddd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 81ce6e8f-d27e-4d65-8ef0-d9199b2cd136
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ccf27d33-6784-4d9b-ae2c-4c56ad1bf193
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9c96a1ae-c6a4-4fe4-b614-86058da45057
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0f93da1e-5899-41c5-90db-5c1ccb1e0394
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 69e31df1-74d2-4dc5-b642-3893611ffc98
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8becb8e5-66e5-4ed3-b5d2-f0012e2cfa53
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 832242a7-76f3-4ab3-8e1b-319249cdb69b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f6d983c0-42cf-481b-bebe-e3f0fbc832df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e93abe72-2328-46ee-8021-09d94d7d6688
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3ba5b098-5028-4c32-99e1-2cf4e1ead937
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b5ae7eb6-afb1-4c25-b4b9-f77e63a5c698
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 96c9fef5-0020-4f78-986d-d10a8d144c1c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bcc2c6d7-7e12-494b-aa5d-8aed3c988954
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 600570bc-4ff1-4c3b-8a03-4b0459711cd0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f22b1296-8533-4b30-98fc-187b85646b86
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 50143f49-d2fe-4e7f-aa2d-f94a25505555
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 610868aa-ed41-4bed-a4cb-5f6a58bed59e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 57b831be-73de-4558-a7d6-149b41712a76
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 89a52675-4900-42f1-b484-2aa0276788b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b03e544c-1984-4371-8d24-0468db189a89
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 22d13452-31b9-47de-8694-e40fa0b754cd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 130e3cea-6a21-4ff8-9646-967202839a78
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 09c1863c-c932-4809-adea-1d26a0caef73
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5e65857a-4e51-4df4-a1c2-e213c8f1a2cb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f8ca1999-dc34-4901-b12f-43730a3b2772
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7ef28a43-cb9e-4e0f-85d8-16f2aee4f839
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 96ee44b7-c8b3-4e8d-8de4-b44581cceeb7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8a9cde2b-08b6-4d32-89d0-31cafaec5726
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2ca7410d-8001-44ca-af71-7b4c3c3cb4b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b39c2bd6-a99d-401b-8e6f-f86c324b4fef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 328523ec-cc59-4453-9fb8-c0b8f2690a39
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f4c4e98d-18c0-498e-a951-bea104b16681
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 697699b6-541c-4b80-8654-91bc7559f03b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 47be5529-10b7-40d3-b02b-3cf0d2133d50
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7280c1ab-93fc-4b15-a001-5815b3a50208
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7b9416d2-c802-4bfa-b114-8ce8f7e597b8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b76a8d47-56cb-4a28-8e35-15316215ae11
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 351288de-795b-4eb6-9028-a653e7422c42
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5dcae6fe-740a-44f0-99fe-5f017c903aad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0ecd06a9-8372-487d-803d-5517a92539e1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0ee9045c-d3ba-4a4e-86b7-7fff10e8fbf8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3fbdbb39-11c9-4fe3-9538-4dfd8856a2c4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7cfc29eb-83b5-420b-8ee9-672d433a16c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 589998e4-cb82-422c-b88b-3e5b55616717
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1eae231c-b96d-4a8c-ada9-76252e93af8e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4bb64af6-27c7-43be-b40d-089bb9e5727d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a58eac38-62e3-4181-9295-ae58378468fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0dd6bdac-8ca8-44b6-9956-6a7cdd579148
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 59ac0ced-a3a4-4efc-9a58-318a5bd10019
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d52dcf00-9884-400a-9bce-685c23ce26fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4efd2e2c-c42b-4951-bee8-46437ca2e680
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6812fd07-9503-4a33-9286-e5c7fe8f481b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4de1747a-4521-4b46-aac1-2b709449be38
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 31314d2e-c6ae-4bd4-9b5c-4c27aeb902ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f3caebc6-4ec5-4d8d-bec1-8bed123ee655
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d3bffe15-8a74-446d-9d5b-5169ad427c43
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fe9dbf10-1e2f-4129-96a2-0fa33438b95e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 51a18aed-7a96-4bf3-8398-18a0cedb4211
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0e8b6c06-36e2-4e20-b0bb-cbd76ffd4b98
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 678a0747-ed48-4cc2-a8a8-9c1f97f40efc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 854b445b-a45d-4d4c-80a9-e3fa2adbb3de
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1422393f-189b-4ec9-9a48-69b164cc6455
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8f5283b7-7924-44fe-b511-fda9c3150ec5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6243bf2f-4f0c-44db-ba15-97e6f07f1052
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 710e532d-26be-41e6-91af-f0554262a09d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 648e3643-7ccf-476e-814e-c0036312602f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6b064a99-0f37-4b61-8aa4-fdfa4e76fa07
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1ace62a2-ca4f-44f8-aa2a-be13753dfbaf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cd23f22e-47df-4600-a5d5-65bdc7ebee85
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 91b324ae-415d-4e1a-9c6e-3a256903a005
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fcfdc746-a241-456b-a784-6345b471c19e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d6c1b6a3-e941-463e-a070-cc0ec9bfb94b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7ac3f1d0-0672-4601-bcc0-6d864790d1bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f57fdc8e-d368-41dc-8cfb-8aca4a0bc51f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 68628be9-ea8c-4172-adff-820c5c7c0d93
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8709e1ab-eddc-43b4-b4f7-4b7e43d9a303
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e1336dae-f8a2-4ed6-a2ef-dc8ba2ab4016
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message affad0be-4547-492e-a54d-fca390f054e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1004af1f-e2dd-45a0-a628-04fc825fbbd4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 730c622c-97d7-4fcd-8b6b-b8a6c66fb990
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8b420c4e-c0e3-4a9c-b532-354c6ba421fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2c5aa81f-7a2e-4f06-9c96-254da33972d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b8e590ef-3848-4207-bfbf-b1a2715de542
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f7c9816d-d14a-4bb6-886f-a8b78d5c89ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4747be9c-08b2-416e-ad70-fffbfa4ad8d8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 64be52f5-5b5e-41b0-8c39-eae0d04691a0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 48763364-ffd3-4d75-8d86-808d430454d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c5898a7b-3379-4397-8847-3d419299e73f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4567fd23-e4ea-4d0a-b9f6-9d5a167cfa8d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fad16794-0079-431d-b82e-a8714eb58595
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1de7261b-0de5-4b9c-817f-0e3c6bfdeef6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3ecbe43b-11bf-42a6-9d36-00dcdb937c1e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 235bf615-ba69-4409-86e7-dd7e318fd4f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0aa945e5-0133-43d9-af89-c9037e937313
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e8224f39-4c81-4ab8-b5d8-35ba7e7dd8e0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 72e33975-b2a9-4897-815a-194219447d93
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 34b9a00e-95df-45c9-86d5-0dc2cc41d86b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e950bf1d-1f6a-4b7d-8c0a-cf5c9677675e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8a4b2c1b-7574-4db1-8686-ee81084f24d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message de68186e-e58c-4c85-9087-f7ede88d5b4d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b3d72532-5e80-47d7-bc65-4cc21b78ddf5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ca4d6a82-f979-4b8c-86fc-7a63b52c8d0c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2b341d66-33d7-429c-91dd-e1309a406726
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c5cf0f3a-0b33-46a7-8019-79f5491661cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9eb271e9-b018-4593-9d18-08d06fcd093a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8fe7a2d7-324e-4e1a-bf36-4a11e57b08e2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ab8bd8d9-9390-42aa-8452-2eb6963fa7b0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c047683b-cf25-47bc-aba1-ea03c3bc041d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 16a7d3ac-cfd6-4610-b6fb-c2b3047bda92
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c3bf35ff-6a7a-4ac2-b2de-bf889bedebeb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 85cd80b4-1056-4fd6-80d4-36cf982393a7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dc2f9256-e4b5-4d40-861e-d65899d7b4d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c3785b79-0b61-421f-b040-07d67ee113ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2fa93b9a-1962-43fc-8a2b-c2fde00c6886
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 27478f02-b35c-49a8-97dc-d8a7144c54aa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dac060b8-4dfe-4f2d-b294-76192cb7bcf0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e8d55dab-ceec-430c-b1b0-950b7d6d7587
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 92655f86-2eff-44e3-bf5e-51e65497829f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 31e806ab-c666-4667-8409-9caa4b181ed1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b9dd54ab-ccd5-4539-89f1-16e3bb89da5e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1cca3a83-c72b-40f3-9bfe-be57bec76d70
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message db441664-25da-4697-8caa-b90302b9fdab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message edf0528d-4ff5-4dc1-a636-558d57525a6b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ea8cc7d2-c2ff-403f-a8d8-0e97832f8fc8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 823ef9d8-1a0a-4fc2-80c9-63920b7b2dbc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ca87743d-341c-4742-b30e-dd929d745cb4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4b972f7f-72ce-4674-afa3-6786dfbfd25c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9e1d7069-af1c-411f-b7d7-22c920c0a956
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8bd76fc5-5987-4620-a5fe-3f061c593063
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 12b96c33-f43a-438d-83c2-3f3c38a7f42a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0dfe848d-91b2-4690-8f65-4573100cee5e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fc2b6c1a-e174-45e9-89e5-0294c19cd28f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 775fae9c-0c86-4484-a495-f36fe6d529a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 03594f01-fb0b-4ba1-a95f-06234c66aded
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1d97e474-4cbc-4fe3-b54f-1096d5817e65
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1d2a65b7-20b6-415d-a2a1-da8419aa02d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 26ce6438-ba3b-4fca-a306-459d6572aa62
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 08aaf65f-aba4-4f11-82fc-cbc1faae1f58
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d1f21ab0-990e-4f07-b612-6e162e0f7fba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c23cec9d-b962-49cd-bbc3-3b4b0e85d5a3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7bc74f55-2d8f-4d6e-9e3b-7b979fa832ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3d52981e-0418-4720-93e6-430a429a0a25
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 832ddd8a-b505-42b6-8b22-14ae15cf9f23
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fdd4cadc-5bed-498a-b30b-aebaa1077fe3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 01fd1c74-7387-4a2e-a169-26ed1a237011
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 85d9b881-0f90-4a02-971e-9529941f4b22
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ac8f5593-f3dc-4004-b721-ca561780b8c4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 90ce5eb2-4e68-4429-b0c0-0bd0af721b37
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 88544d68-f6b9-43f9-b228-580d1172fe40
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8ab4ec3e-d1be-4356-8978-23ff666d0bba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e1c0eaed-1906-4fee-8487-db2ecd2349b8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9e67c04b-5512-44e8-991d-c56cbef8a942
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7db82d3c-3f30-457f-b61d-758c9a3afb74
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4ba54eb6-964b-43c4-8604-8ba1f1687074
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b5aebe75-0bc7-4873-8abe-0dc4184dc24d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 09ab8a20-2467-4df3-a3f6-e064349608d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 036fb8eb-43df-4f1f-89da-0a3506fdde37
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a3f40dbe-21e5-468e-aac0-287feea7966a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dee7a392-22ef-49a0-b525-ebe0c249ad1e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eff9a252-857b-40ae-bca2-6236c878ac5e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cf8442a3-9b3b-4faa-89f7-2951b4cd01f6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9053285f-747d-4436-850c-b4089b13aea2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message de47701d-f94d-4739-84be-a257d253dfb6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3f891d4e-750f-4c83-aad4-f4b0a3772bd0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 272ccde4-1f32-4960-85ed-ccab551dd71c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fb93e21f-f1b7-4256-a463-9f04f188b508
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8a65d291-bc0d-4848-91db-e30c3eb13197
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2434b49e-1094-4e0e-b211-12816cceec13
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1dae1b4f-c27e-4042-86c3-2191f7037932
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f6a7de34-d279-430f-83ca-7b660323221a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 89db626c-b8b0-4161-982d-57dbeb709800
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 36918dfa-94e7-4555-a993-bdb801c7310d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0e7f63b1-cbfd-4dd2-bb6b-8b3b15e17c64
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7c321eb7-afca-4968-80dd-ed1c3989d49d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6d35f2e6-a375-43ca-8f44-5660176c0363
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e6f45c94-1dca-4497-8127-8f1feeb88ca2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2cc5f5c8-77a0-4de7-b06d-52d8c33eb656
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c4f978e8-a89a-467d-aa92-9dce9342c86f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message adfae267-1c0b-4b74-9051-e125bdcf8fef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 85b63bb5-4b0e-49ab-be02-93fc09e1944d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 968ea911-a82c-4cae-be98-e446cf93ad89
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 328ffc87-8250-4917-ba53-4321d5ce993a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 13714fa6-1f91-47ae-b5f8-0f6cc7da2cd4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 27eb3f7c-c1cb-49c2-a3b0-8c4f8233f728
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7d4c05d9-1785-4950-a168-d44aa691b976
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 22c2f719-ceda-475e-9f3b-8a1004fec696
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cf975854-18a0-4ab6-bfe6-2d02edaacad2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7ea5cec3-891c-4204-ac56-fa95f61a5ee5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c6a47489-e539-4bb0-a6f8-8c50445c5943
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 06bdb516-66f5-4d0b-9d24-aee72d5c703a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 46eb9767-3b66-4ad1-a00f-43a4ce7313dd
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8687 {grpc_message:"Socket closed", grpc_status:14}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_38
Server: localhost:8687
Algorithm: FEDAVG
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_38
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_38/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_38/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_38/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_38/test_labels.txt

📊 Raw data loaded:
   Train: X=(847, 24), y=(847,)
   Test:  X=(212, 24), y=(212,)

⚠️  Limiting training data: 847 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  203 samples, 5 features
✅ Client client_38 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

============================================================
🔄 Round 4 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0744 (↓), lr=0.001000
   • Epoch   2/100: train=0.0819, val=0.0744, patience=1/15, lr=0.001000
   • Epoch   3/100: train=0.0813, val=0.0746, patience=2/15, lr=0.001000
   • Epoch   4/100: train=0.0804, val=0.0749, patience=3/15, lr=0.001000
   • Epoch   5/100: train=0.0794, val=0.0754, patience=4/15, lr=0.001000
   📉 Epoch 8: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0730, val=0.0784, patience=10/15, lr=0.000500
   📉 Epoch 16: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0744)

============================================================
📊 Round 4 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=0.0202
   Val:   Loss=0.0744, RMSE=0.2728, R²=0.0256
============================================================


📊 Round 4 Test Metrics:
   Loss: 0.0878, RMSE: 0.2962, MAE: 0.2583, R²: -0.0031

============================================================
🔄 Round 5 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0794 (↓), lr=0.000250
   • Epoch   2/100: train=0.0813, val=0.0796, patience=1/15, lr=0.000250
   • Epoch   3/100: train=0.0808, val=0.0796, patience=2/15, lr=0.000250
   • Epoch   4/100: train=0.0806, val=0.0796, patience=3/15, lr=0.000250
   • Epoch   5/100: train=0.0804, val=0.0795, patience=4/15, lr=0.000250
   📉 Epoch 8: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0793, val=0.0794, patience=10/15, lr=0.000125
   📉 Epoch 16: LR reduced 0.000125 → 0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 5 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000250 → 0.000063 (2 reductions)
   Train: Loss=0.0813, RMSE=0.2852, R²=0.0194
   Val:   Loss=0.0794, RMSE=0.2817, R²=0.0057
============================================================


📊 Round 5 Test Metrics:
   Loss: 0.0873, RMSE: 0.2955, MAE: 0.2568, R²: 0.0017

============================================================
🔄 Round 9 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0871 (↓), lr=0.000063
   • Epoch   2/100: train=0.0788, val=0.0867, patience=1/15, lr=0.000063
   ✓ Epoch   3/100: train=0.0783, val=0.0863 (↓), lr=0.000063
   • Epoch   4/100: train=0.0779, val=0.0860, patience=1/15, lr=0.000063
   ✓ Epoch   5/100: train=0.0776, val=0.0857 (↓), lr=0.000063
   📉 Epoch 8: LR reduced 0.000063 → 0.000031
   ✓ Epoch  11/100: train=0.0764, val=0.0852 (↓), lr=0.000031
   📉 Epoch 16: LR reduced 0.000031 → 0.000016
   • Epoch  21/100: train=0.0757, val=0.0850, patience=10/15, lr=0.000016
   📉 Epoch 24: LR reduced 0.000016 → 0.000008

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 9 Summary - Client client_38
   Epochs: 26/100 (early stopped)
   LR: 0.000063 → 0.000008 (3 reductions)
   Train: Loss=0.0763, RMSE=0.2763, R²=0.0582
   Val:   Loss=0.0852, RMSE=0.2919, R²=0.0280
============================================================


============================================================
🔄 Round 10 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000008
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0781, val=0.0904 (↓), lr=0.000008
   • Epoch   2/100: train=0.0780, val=0.0903, patience=1/15, lr=0.000008
   • Epoch   3/100: train=0.0779, val=0.0902, patience=2/15, lr=0.000008
   • Epoch   4/100: train=0.0779, val=0.0900, patience=3/15, lr=0.000008
   • Epoch   5/100: train=0.0778, val=0.0899, patience=4/15, lr=0.000008
   📉 Epoch 6: LR reduced 0.000008 → 0.000004
   • Epoch  11/100: train=0.0775, val=0.0896, patience=5/15, lr=0.000004
   📉 Epoch 14: LR reduced 0.000004 → 0.000002
   • Epoch  21/100: train=0.0773, val=0.0894, patience=15/15, lr=0.000002

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0899)

============================================================
📊 Round 10 Summary - Client client_38
   Epochs: 21/100 (early stopped)
   LR: 0.000008 → 0.000002 (2 reductions)
   Train: Loss=0.0778, RMSE=0.2790, R²=0.0269
   Val:   Loss=0.0899, RMSE=0.2998, R²=0.0136
============================================================


============================================================
🔄 Round 11 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000002
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   📉 Epoch 1: LR reduced 0.000002 → 0.000001
   ✓ Epoch   1/100: train=0.0808, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 11 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000002 → 0.000001 (1 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=0.0185
   Val:   Loss=0.0818, RMSE=0.2860, R²=0.0164
============================================================


📊 Round 11 Test Metrics:
   Loss: 0.0872, RMSE: 0.2953, MAE: 0.2563, R²: 0.0036

📊 Round 11 Test Metrics:
   Loss: 0.0872, RMSE: 0.2953, MAE: 0.2564, R²: 0.0033

============================================================
🔄 Round 13 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 13 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2854, R²=0.0151
   Val:   Loss=0.0786, RMSE=0.2804, R²=0.0248
============================================================


📊 Round 13 Test Metrics:
   Loss: 0.0872, RMSE: 0.2954, MAE: 0.2560, R²: 0.0030

============================================================
🔄 Round 15 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0772 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0771, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0771, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0771, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0771, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0771, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 15 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2863, R²=0.0193
   Val:   Loss=0.0772, RMSE=0.2778, R²=0.0058
============================================================


📊 Round 15 Test Metrics:
   Loss: 0.0873, RMSE: 0.2955, MAE: 0.2561, R²: 0.0019

============================================================
🔄 Round 20 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0755 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0755, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0755, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0755, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0755, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0755, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0755)

============================================================
📊 Round 20 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2873, R²=0.0016
   Val:   Loss=0.0755, RMSE=0.2748, R²=0.0585
============================================================


📊 Round 20 Test Metrics:
   Loss: 0.0874, RMSE: 0.2957, MAE: 0.2560, R²: 0.0010

📊 Round 20 Test Metrics:
   Loss: 0.0874, RMSE: 0.2956, MAE: 0.2559, R²: 0.0013

📊 Round 20 Test Metrics:
   Loss: 0.0874, RMSE: 0.2956, MAE: 0.2559, R²: 0.0012

📊 Round 20 Test Metrics:
   Loss: 0.0874, RMSE: 0.2956, MAE: 0.2559, R²: 0.0013

============================================================
🔄 Round 25 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 25 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=0.0225
   Val:   Loss=0.0861, RMSE=0.2935, R²=-0.0347
============================================================


📊 Round 25 Test Metrics:
   Loss: 0.0874, RMSE: 0.2956, MAE: 0.2559, R²: 0.0013

============================================================
🔄 Round 26 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0764 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0764, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0764, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0764, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0764, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0763, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0764)

============================================================
📊 Round 26 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=0.0037
   Val:   Loss=0.0764, RMSE=0.2764, R²=0.0523
============================================================


📊 Round 26 Test Metrics:
   Loss: 0.0874, RMSE: 0.2956, MAE: 0.2559, R²: 0.0013

============================================================
🔄 Round 27 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0719 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0719, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0719, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0719, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0719, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0718, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0719)

============================================================
📊 Round 27 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2892, R²=0.0098
   Val:   Loss=0.0719, RMSE=0.2682, R²=0.0278
============================================================


📊 Round 27 Test Metrics:
   Loss: 0.0874, RMSE: 0.2956, MAE: 0.2559, R²: 0.0014

============================================================
🔄 Round 29 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0864, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 29 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2829, R²=0.0054
   Val:   Loss=0.0864, RMSE=0.2939, R²=0.0390
============================================================


📊 Round 29 Test Metrics:
   Loss: 0.0874, RMSE: 0.2956, MAE: 0.2558, R²: 0.0014

============================================================
🔄 Round 31 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 31 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=0.0023
   Val:   Loss=0.0851, RMSE=0.2916, R²=0.0275
============================================================


📊 Round 31 Test Metrics:
   Loss: 0.0874, RMSE: 0.2956, MAE: 0.2559, R²: 0.0014

============================================================
🔄 Round 33 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 33 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=0.0102
   Val:   Loss=0.0800, RMSE=0.2828, R²=0.0017
============================================================


📊 Round 33 Test Metrics:
   Loss: 0.0874, RMSE: 0.2956, MAE: 0.2559, R²: 0.0014

============================================================
🔄 Round 34 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 34 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=0.0162
   Val:   Loss=0.0796, RMSE=0.2822, R²=-0.0026
============================================================


📊 Round 34 Test Metrics:
   Loss: 0.0874, RMSE: 0.2956, MAE: 0.2559, R²: 0.0014

📊 Round 34 Test Metrics:
   Loss: 0.0874, RMSE: 0.2956, MAE: 0.2559, R²: 0.0014

📊 Round 34 Test Metrics:
   Loss: 0.0874, RMSE: 0.2956, MAE: 0.2558, R²: 0.0015

============================================================
🔄 Round 37 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 37 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=0.0111
   Val:   Loss=0.0785, RMSE=0.2801, R²=0.0214
============================================================


📊 Round 37 Test Metrics:
   Loss: 0.0874, RMSE: 0.2956, MAE: 0.2558, R²: 0.0015

============================================================
🔄 Round 38 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0687 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0686, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0686, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0686, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0686, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0685, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0687)

============================================================
📊 Round 38 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2906, R²=0.0116
   Val:   Loss=0.0687, RMSE=0.2620, R²=0.0046
============================================================


📊 Round 38 Test Metrics:
   Loss: 0.0874, RMSE: 0.2956, MAE: 0.2559, R²: 0.0014

📊 Round 38 Test Metrics:
   Loss: 0.0874, RMSE: 0.2956, MAE: 0.2559, R²: 0.0014

📊 Round 38 Test Metrics:
   Loss: 0.0874, RMSE: 0.2956, MAE: 0.2559, R²: 0.0014

============================================================
🔄 Round 45 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0755 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0755, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0755, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0755, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0755, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0754, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0755)

============================================================
📊 Round 45 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=0.0136
   Val:   Loss=0.0755, RMSE=0.2748, R²=0.0115
============================================================


============================================================
🔄 Round 46 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0874 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0874, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0874, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0874, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0874, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0874, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0874)

============================================================
📊 Round 46 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2824, R²=0.0044
   Val:   Loss=0.0874, RMSE=0.2956, R²=0.0412
============================================================


============================================================
🔄 Round 47 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0880 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0880, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0880, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0880, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0880, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0879, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0880)

============================================================
📊 Round 47 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2821, R²=0.0273
   Val:   Loss=0.0880, RMSE=0.2967, R²=-0.0424
============================================================


============================================================
🔄 Round 48 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 48 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=0.0197
   Val:   Loss=0.0835, RMSE=0.2890, R²=-0.0353
============================================================


📊 Round 48 Test Metrics:
   Loss: 0.0874, RMSE: 0.2956, MAE: 0.2558, R²: 0.0015

============================================================
🔄 Round 49 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0709 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0709, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0709, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0709, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0709, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0708, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0709)

============================================================
📊 Round 49 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2896, R²=0.0119
   Val:   Loss=0.0709, RMSE=0.2662, R²=0.0108
============================================================


📊 Round 49 Test Metrics:
   Loss: 0.0874, RMSE: 0.2956, MAE: 0.2558, R²: 0.0015

============================================================
🔄 Round 50 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0750 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0750, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0750, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0749, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0749, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0749, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0750)

============================================================
📊 Round 50 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=0.0133
   Val:   Loss=0.0750, RMSE=0.2738, R²=0.0117
============================================================


============================================================
🔄 Round 51 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0726 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0726, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0726, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0726, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0726, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0725, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0726)

============================================================
📊 Round 51 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2889, R²=0.0108
   Val:   Loss=0.0726, RMSE=0.2694, R²=0.0139
============================================================


📊 Round 51 Test Metrics:
   Loss: 0.0874, RMSE: 0.2956, MAE: 0.2558, R²: 0.0015

============================================================
🔄 Round 52 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 52 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=0.0153
   Val:   Loss=0.0835, RMSE=0.2889, R²=-0.0138
============================================================


📊 Round 52 Test Metrics:
   Loss: 0.0874, RMSE: 0.2956, MAE: 0.2558, R²: 0.0015

📊 Round 52 Test Metrics:
   Loss: 0.0874, RMSE: 0.2956, MAE: 0.2558, R²: 0.0016

============================================================
🔄 Round 54 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 54 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=0.0158
   Val:   Loss=0.0820, RMSE=0.2863, R²=0.0026
============================================================


============================================================
🔄 Round 55 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0782, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 55 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=0.0070
   Val:   Loss=0.0782, RMSE=0.2797, R²=0.0324
============================================================


📊 Round 55 Test Metrics:
   Loss: 0.0874, RMSE: 0.2956, MAE: 0.2558, R²: 0.0016

📊 Round 55 Test Metrics:
   Loss: 0.0873, RMSE: 0.2955, MAE: 0.2558, R²: 0.0017

============================================================
🔄 Round 58 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0776 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0776, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0776, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0776, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0776, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 58 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=0.0074
   Val:   Loss=0.0776, RMSE=0.2785, R²=0.0268
============================================================


============================================================
🔄 Round 59 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 59 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2857, R²=0.0033
   Val:   Loss=0.0798, RMSE=0.2825, R²=0.0484
============================================================


📊 Round 59 Test Metrics:
   Loss: 0.0873, RMSE: 0.2956, MAE: 0.2558, R²: 0.0017

============================================================
🔄 Round 64 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0713 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0713, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0713, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0712, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0712, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0711, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0713)

============================================================
📊 Round 64 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2894, R²=0.0101
   Val:   Loss=0.0713, RMSE=0.2670, R²=0.0266
============================================================


📊 Round 64 Test Metrics:
   Loss: 0.0874, RMSE: 0.2956, MAE: 0.2558, R²: 0.0016

📊 Round 64 Test Metrics:
   Loss: 0.0874, RMSE: 0.2956, MAE: 0.2558, R²: 0.0016

============================================================
🔄 Round 67 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0894 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0894, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0894, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0894, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0894, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0894, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0894)

============================================================
📊 Round 67 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2815, R²=0.0200
   Val:   Loss=0.0894, RMSE=0.2990, R²=-0.0143
============================================================


📊 Round 67 Test Metrics:
   Loss: 0.0874, RMSE: 0.2956, MAE: 0.2558, R²: 0.0016

📊 Round 67 Test Metrics:
   Loss: 0.0874, RMSE: 0.2956, MAE: 0.2558, R²: 0.0016

============================================================
🔄 Round 73 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0916 (↓), lr=0.000001
   • Epoch   2/100: train=0.0785, val=0.0916, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0916, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0916, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0916, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0916, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0916)

============================================================
📊 Round 73 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2805, R²=0.0144
   Val:   Loss=0.0916, RMSE=0.3027, R²=0.0060
============================================================


📊 Round 73 Test Metrics:
   Loss: 0.0874, RMSE: 0.2956, MAE: 0.2558, R²: 0.0016

============================================================
🔄 Round 75 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 75 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2849, R²=0.0040
   Val:   Loss=0.0817, RMSE=0.2859, R²=0.0416
============================================================


📊 Round 75 Test Metrics:
   Loss: 0.0874, RMSE: 0.2956, MAE: 0.2558, R²: 0.0016

📊 Round 75 Test Metrics:
   Loss: 0.0874, RMSE: 0.2956, MAE: 0.2558, R²: 0.0016

============================================================
🔄 Round 79 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0887 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0887, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0887, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0887, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0887, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0886, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0887)

============================================================
📊 Round 79 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2818, R²=0.0201
   Val:   Loss=0.0887, RMSE=0.2979, R²=-0.0126
============================================================


============================================================
🔄 Round 80 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0735 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0735, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0735, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0735, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0735, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0734, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0735)

============================================================
📊 Round 80 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=0.0143
   Val:   Loss=0.0735, RMSE=0.2711, R²=0.0097
============================================================


============================================================
🔄 Round 81 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0741 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0741, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0741, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0741, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0741, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0742, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0741)

============================================================
📊 Round 81 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2882, R²=0.0108
   Val:   Loss=0.0741, RMSE=0.2722, R²=0.0130
============================================================


📊 Round 81 Test Metrics:
   Loss: 0.0874, RMSE: 0.2956, MAE: 0.2558, R²: 0.0017

📊 Round 81 Test Metrics:
   Loss: 0.0874, RMSE: 0.2956, MAE: 0.2558, R²: 0.0016

📊 Round 81 Test Metrics:
   Loss: 0.0874, RMSE: 0.2956, MAE: 0.2558, R²: 0.0016

============================================================
🔄 Round 89 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 89 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=0.0166
   Val:   Loss=0.0793, RMSE=0.2816, R²=0.0005
============================================================


📊 Round 89 Test Metrics:
   Loss: 0.0874, RMSE: 0.2956, MAE: 0.2558, R²: 0.0016

📊 Round 89 Test Metrics:
   Loss: 0.0874, RMSE: 0.2956, MAE: 0.2558, R²: 0.0017

============================================================
🔄 Round 96 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 96 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=0.0094
   Val:   Loss=0.0858, RMSE=0.2928, R²=0.0276
============================================================


============================================================
🔄 Round 98 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 98 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=0.0162
   Val:   Loss=0.0822, RMSE=0.2867, R²=0.0007
============================================================


📊 Round 98 Test Metrics:
   Loss: 0.0874, RMSE: 0.2956, MAE: 0.2558, R²: 0.0016

📊 Round 98 Test Metrics:
   Loss: 0.0874, RMSE: 0.2956, MAE: 0.2558, R²: 0.0016

============================================================
🔄 Round 106 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 106 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2863, R²=0.0132
   Val:   Loss=0.0784, RMSE=0.2799, R²=0.0151
============================================================


📊 Round 106 Test Metrics:
   Loss: 0.0874, RMSE: 0.2956, MAE: 0.2558, R²: 0.0016

============================================================
🔄 Round 108 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 108 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=0.0089
   Val:   Loss=0.0850, RMSE=0.2915, R²=0.0161
============================================================


============================================================
🔄 Round 110 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 110 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2845, R²=0.0079
   Val:   Loss=0.0825, RMSE=0.2872, R²=0.0364
============================================================


📊 Round 110 Test Metrics:
   Loss: 0.0873, RMSE: 0.2955, MAE: 0.2558, R²: 0.0017

============================================================
🔄 Round 113 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0777, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0777, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0777, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0777, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 113 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=0.0139
   Val:   Loss=0.0778, RMSE=0.2788, R²=0.0098
============================================================


📊 Round 113 Test Metrics:
   Loss: 0.0874, RMSE: 0.2956, MAE: 0.2558, R²: 0.0017

============================================================
🔄 Round 114 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 114 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=0.0262
   Val:   Loss=0.0842, RMSE=0.2902, R²=-0.0399
============================================================


============================================================
🔄 Round 116 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0780, val=0.0940 (↓), lr=0.000001
   • Epoch   2/100: train=0.0780, val=0.0940, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0780, val=0.0940, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0779, val=0.0940, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0779, val=0.0940, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0778, val=0.0939, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0940)

============================================================
📊 Round 116 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0780, RMSE=0.2793, R²=0.0285
   Val:   Loss=0.0940, RMSE=0.3066, R²=-0.0381
============================================================


📊 Round 116 Test Metrics:
   Loss: 0.0874, RMSE: 0.2956, MAE: 0.2558, R²: 0.0016

============================================================
🔄 Round 117 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 117 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=0.0185
   Val:   Loss=0.0805, RMSE=0.2837, R²=-0.0055
============================================================


📊 Round 117 Test Metrics:
   Loss: 0.0874, RMSE: 0.2956, MAE: 0.2558, R²: 0.0016

============================================================
🔄 Round 118 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0919 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0919, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0785, val=0.0919, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0785, val=0.0919, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0785, val=0.0919, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0918, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0919)

============================================================
📊 Round 118 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2803, R²=0.0382
   Val:   Loss=0.0919, RMSE=0.3031, R²=-0.0871
============================================================


============================================================
🔄 Round 119 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0702 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0702, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0702, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0702, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0702, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0702, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0702)

============================================================
📊 Round 119 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=0.0130
   Val:   Loss=0.0702, RMSE=0.2649, R²=0.0144
============================================================


📊 Round 119 Test Metrics:
   Loss: 0.0874, RMSE: 0.2956, MAE: 0.2558, R²: 0.0016

📊 Round 119 Test Metrics:
   Loss: 0.0874, RMSE: 0.2956, MAE: 0.2558, R²: 0.0016

============================================================
🔄 Round 121 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0776 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0776, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0776, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0776, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0776, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 121 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=0.0192
   Val:   Loss=0.0776, RMSE=0.2786, R²=-0.0309
============================================================


============================================================
🔄 Round 122 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0884 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0884, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0884, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0884, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0884, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0883, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0884)

============================================================
📊 Round 122 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2818, R²=0.0020
   Val:   Loss=0.0884, RMSE=0.2974, R²=0.0539
============================================================


📊 Round 122 Test Metrics:
   Loss: 0.0874, RMSE: 0.2956, MAE: 0.2558, R²: 0.0016

============================================================
🔄 Round 123 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 123 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2845, R²=0.0231
   Val:   Loss=0.0824, RMSE=0.2870, R²=-0.0264
============================================================


📊 Round 123 Test Metrics:
   Loss: 0.0874, RMSE: 0.2956, MAE: 0.2558, R²: 0.0017

============================================================
🔄 Round 124 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 124 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=0.0166
   Val:   Loss=0.0820, RMSE=0.2863, R²=-0.0053
============================================================


============================================================
🔄 Round 125 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 125 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=0.0254
   Val:   Loss=0.0826, RMSE=0.2875, R²=-0.0339
============================================================


📊 Round 125 Test Metrics:
   Loss: 0.0874, RMSE: 0.2956, MAE: 0.2558, R²: 0.0016

============================================================
🔄 Round 126 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0779 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0779, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0779, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0779, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0779, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0778, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0779)

============================================================
📊 Round 126 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=0.0092
   Val:   Loss=0.0779, RMSE=0.2792, R²=0.0336
============================================================


📊 Round 126 Test Metrics:
   Loss: 0.0873, RMSE: 0.2955, MAE: 0.2558, R²: 0.0018

============================================================
🔄 Round 129 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 129 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2852, R²=0.0179
   Val:   Loss=0.0807, RMSE=0.2840, R²=-0.0229
============================================================


📊 Round 129 Test Metrics:
   Loss: 0.0873, RMSE: 0.2955, MAE: 0.2558, R²: 0.0018

📊 Round 129 Test Metrics:
   Loss: 0.0873, RMSE: 0.2955, MAE: 0.2558, R²: 0.0019

============================================================
🔄 Round 131 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0779 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0778, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0778, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0778, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0778, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0778, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0779)

============================================================
📊 Round 131 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=0.0186
   Val:   Loss=0.0779, RMSE=0.2790, R²=-0.0089
============================================================


📊 Round 131 Test Metrics:
   Loss: 0.0873, RMSE: 0.2955, MAE: 0.2558, R²: 0.0019

============================================================
🔄 Round 132 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0710 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0710, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0710, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0710, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0710, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0709, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0710)

============================================================
📊 Round 132 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2894, R²=-0.0045
   Val:   Loss=0.0710, RMSE=0.2665, R²=0.0924
============================================================


📊 Round 132 Test Metrics:
   Loss: 0.0873, RMSE: 0.2955, MAE: 0.2557, R²: 0.0020

============================================================
🔄 Round 137 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 137 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=0.0101
   Val:   Loss=0.0811, RMSE=0.2847, R²=0.0280
============================================================


📊 Round 137 Test Metrics:
   Loss: 0.0873, RMSE: 0.2955, MAE: 0.2557, R²: 0.0021

============================================================
🔄 Round 138 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0762 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0761, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0761, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0761, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0761, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0760, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0762)

============================================================
📊 Round 138 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=0.0191
   Val:   Loss=0.0762, RMSE=0.2760, R²=-0.0154
============================================================


📊 Round 138 Test Metrics:
   Loss: 0.0873, RMSE: 0.2955, MAE: 0.2557, R²: 0.0021

============================================================
🔄 Round 141 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0763 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0763, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0763, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0763, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0762, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0762, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0763)

============================================================
📊 Round 141 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=-0.0005
   Val:   Loss=0.0763, RMSE=0.2762, R²=0.0718
============================================================


📊 Round 141 Test Metrics:
   Loss: 0.0873, RMSE: 0.2955, MAE: 0.2557, R²: 0.0020

============================================================
🔄 Round 143 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0778, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0777, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0777, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0777, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 143 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=0.0105
   Val:   Loss=0.0778, RMSE=0.2789, R²=0.0280
============================================================


📊 Round 143 Test Metrics:
   Loss: 0.0873, RMSE: 0.2955, MAE: 0.2558, R²: 0.0020

📊 Round 143 Test Metrics:
   Loss: 0.0873, RMSE: 0.2955, MAE: 0.2558, R²: 0.0020

============================================================
🔄 Round 146 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0754 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0754, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0754, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0753, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0753, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0753, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0754)

============================================================
📊 Round 146 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2875, R²=0.0110
   Val:   Loss=0.0754, RMSE=0.2746, R²=0.0169
============================================================


📊 Round 146 Test Metrics:
   Loss: 0.0873, RMSE: 0.2955, MAE: 0.2558, R²: 0.0020

============================================================
🔄 Round 147 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 147 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=0.0191
   Val:   Loss=0.0852, RMSE=0.2918, R²=-0.0060
============================================================


📊 Round 147 Test Metrics:
   Loss: 0.0873, RMSE: 0.2955, MAE: 0.2558, R²: 0.0020

📊 Round 147 Test Metrics:
   Loss: 0.0873, RMSE: 0.2955, MAE: 0.2557, R²: 0.0021

📊 Round 147 Test Metrics:
   Loss: 0.0873, RMSE: 0.2955, MAE: 0.2557, R²: 0.0021

============================================================
🔄 Round 151 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0765 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0765, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0765, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0765, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0764, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0763, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0765)

============================================================
📊 Round 151 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=0.0200
   Val:   Loss=0.0765, RMSE=0.2766, R²=-0.0272
============================================================


📊 Round 151 Test Metrics:
   Loss: 0.0873, RMSE: 0.2955, MAE: 0.2557, R²: 0.0021

📊 Round 151 Test Metrics:
   Loss: 0.0873, RMSE: 0.2955, MAE: 0.2557, R²: 0.0021

📊 Round 151 Test Metrics:
   Loss: 0.0873, RMSE: 0.2955, MAE: 0.2557, R²: 0.0021

📊 Round 151 Test Metrics:
   Loss: 0.0873, RMSE: 0.2955, MAE: 0.2557, R²: 0.0021

============================================================
🔄 Round 157 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0777 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0777, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0777, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0777, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0777, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0777, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 157 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=0.0021
   Val:   Loss=0.0777, RMSE=0.2788, R²=0.0569
============================================================


============================================================
🔄 Round 158 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0874 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0874, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0874, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0874, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0874, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0874, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0874)

============================================================
📊 Round 158 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=0.0078
   Val:   Loss=0.0874, RMSE=0.2956, R²=0.0289
============================================================


📊 Round 158 Test Metrics:
   Loss: 0.0873, RMSE: 0.2955, MAE: 0.2557, R²: 0.0021

📊 Round 158 Test Metrics:
   Loss: 0.0873, RMSE: 0.2955, MAE: 0.2557, R²: 0.0021

📊 Round 158 Test Metrics:
   Loss: 0.0873, RMSE: 0.2955, MAE: 0.2557, R²: 0.0021

📊 Round 158 Test Metrics:
   Loss: 0.0873, RMSE: 0.2955, MAE: 0.2557, R²: 0.0022

============================================================
🔄 Round 165 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0876 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0876, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0876, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0876, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0876, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0876, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0876)

============================================================
📊 Round 165 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2822, R²=0.0192
   Val:   Loss=0.0876, RMSE=0.2960, R²=-0.0065
============================================================


📊 Round 165 Test Metrics:
   Loss: 0.0873, RMSE: 0.2955, MAE: 0.2557, R²: 0.0022

============================================================
🔄 Round 166 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0726 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0726, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0726, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0726, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0726, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0726, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0726)

============================================================
📊 Round 166 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2887, R²=0.0149
   Val:   Loss=0.0726, RMSE=0.2695, R²=0.0053
============================================================


📊 Round 166 Test Metrics:
   Loss: 0.0873, RMSE: 0.2955, MAE: 0.2557, R²: 0.0022

📊 Round 166 Test Metrics:
   Loss: 0.0873, RMSE: 0.2955, MAE: 0.2557, R²: 0.0023

============================================================
🔄 Round 171 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 171 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=0.0226
   Val:   Loss=0.0853, RMSE=0.2920, R²=-0.0211
============================================================


📊 Round 171 Test Metrics:
   Loss: 0.0873, RMSE: 0.2955, MAE: 0.2557, R²: 0.0022

============================================================
🔄 Round 174 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 174 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2852, R²=0.0117
   Val:   Loss=0.0808, RMSE=0.2842, R²=0.0234
============================================================


============================================================
🔄 Round 176 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 176 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2847, R²=0.0154
   Val:   Loss=0.0818, RMSE=0.2861, R²=0.0080
============================================================


📊 Round 176 Test Metrics:
   Loss: 0.0873, RMSE: 0.2955, MAE: 0.2557, R²: 0.0023

============================================================
🔄 Round 178 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 178 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=0.0133
   Val:   Loss=0.0843, RMSE=0.2903, R²=0.0118
============================================================


============================================================
🔄 Round 179 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 179 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=0.0130
   Val:   Loss=0.0793, RMSE=0.2815, R²=0.0174
============================================================


📊 Round 179 Test Metrics:
   Loss: 0.0873, RMSE: 0.2955, MAE: 0.2557, R²: 0.0023

📊 Round 179 Test Metrics:
   Loss: 0.0873, RMSE: 0.2954, MAE: 0.2557, R²: 0.0024

============================================================
🔄 Round 183 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 183 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=0.0239
   Val:   Loss=0.0832, RMSE=0.2884, R²=-0.0267
============================================================


📊 Round 183 Test Metrics:
   Loss: 0.0873, RMSE: 0.2954, MAE: 0.2557, R²: 0.0024

============================================================
🔄 Round 185 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 185 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=0.0231
   Val:   Loss=0.0816, RMSE=0.2856, R²=-0.0241
============================================================


📊 Round 185 Test Metrics:
   Loss: 0.0873, RMSE: 0.2954, MAE: 0.2557, R²: 0.0024

============================================================
🔄 Round 186 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 186 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=0.0158
   Val:   Loss=0.0838, RMSE=0.2894, R²=0.0058
============================================================


============================================================
🔄 Round 187 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 187 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2829, R²=0.0137
   Val:   Loss=0.0860, RMSE=0.2933, R²=-0.0023
============================================================


📊 Round 187 Test Metrics:
   Loss: 0.0873, RMSE: 0.2954, MAE: 0.2556, R²: 0.0025

============================================================
🔄 Round 188 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0865 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0865, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0865, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0865, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0865, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0864, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0865)

============================================================
📊 Round 188 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=0.0221
   Val:   Loss=0.0865, RMSE=0.2941, R²=-0.0175
============================================================


📊 Round 188 Test Metrics:
   Loss: 0.0873, RMSE: 0.2954, MAE: 0.2556, R²: 0.0026

📊 Round 188 Test Metrics:
   Loss: 0.0873, RMSE: 0.2954, MAE: 0.2556, R²: 0.0026

📊 Round 188 Test Metrics:
   Loss: 0.0873, RMSE: 0.2954, MAE: 0.2556, R²: 0.0026

📊 Round 188 Test Metrics:
   Loss: 0.0873, RMSE: 0.2954, MAE: 0.2556, R²: 0.0026

============================================================
🔄 Round 192 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0719 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0719, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0719, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0719, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0719, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0719, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0719)

============================================================
📊 Round 192 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=0.0174
   Val:   Loss=0.0719, RMSE=0.2681, R²=-0.0166
============================================================


📊 Round 192 Test Metrics:
   Loss: 0.0873, RMSE: 0.2954, MAE: 0.2556, R²: 0.0026

📊 Round 192 Test Metrics:
   Loss: 0.0873, RMSE: 0.2954, MAE: 0.2556, R²: 0.0026

============================================================
🔄 Round 197 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 197 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=0.0083
   Val:   Loss=0.0848, RMSE=0.2912, R²=0.0221
============================================================


📊 Round 197 Test Metrics:
   Loss: 0.0873, RMSE: 0.2954, MAE: 0.2556, R²: 0.0026

📊 Round 197 Test Metrics:
   Loss: 0.0873, RMSE: 0.2954, MAE: 0.2556, R²: 0.0026

============================================================
🔄 Round 199 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 199 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=0.0144
   Val:   Loss=0.0801, RMSE=0.2831, R²=0.0117
============================================================


📊 Round 199 Test Metrics:
   Loss: 0.0873, RMSE: 0.2954, MAE: 0.2556, R²: 0.0026

============================================================
🔄 Round 200 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 200 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=0.0099
   Val:   Loss=0.0784, RMSE=0.2799, R²=0.0108
============================================================


============================================================
🔄 Round 201 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0770 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0770, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0770, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0770, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0770, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0769, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0770)

============================================================
📊 Round 201 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2868, R²=0.0055
   Val:   Loss=0.0770, RMSE=0.2775, R²=0.0481
============================================================


============================================================
🔄 Round 202 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0763 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0763, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0763, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0763, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0763, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0762, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0763)

============================================================
📊 Round 202 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=0.0059
   Val:   Loss=0.0763, RMSE=0.2763, R²=0.0444
============================================================


============================================================
🔄 Round 203 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 203 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2847, R²=0.0169
   Val:   Loss=0.0818, RMSE=0.2861, R²=-0.0065
============================================================


============================================================
🔄 Round 204 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0774 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0774, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0774, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0774, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0774, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0773, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0774)

============================================================
📊 Round 204 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2866, R²=0.0101
   Val:   Loss=0.0774, RMSE=0.2783, R²=0.0284
============================================================


============================================================
🔄 Round 207 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 207 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2861, R²=0.0133
   Val:   Loss=0.0786, RMSE=0.2803, R²=0.0011
============================================================


📊 Round 207 Test Metrics:
   Loss: 0.0873, RMSE: 0.2954, MAE: 0.2556, R²: 0.0028

📊 Round 207 Test Metrics:
   Loss: 0.0873, RMSE: 0.2954, MAE: 0.2556, R²: 0.0028

============================================================
🔄 Round 210 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 210 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=0.0141
   Val:   Loss=0.0805, RMSE=0.2838, R²=0.0101
============================================================


============================================================
🔄 Round 211 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0868 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0868, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0868, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0868, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0868, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0868, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0868)

============================================================
📊 Round 211 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=0.0198
   Val:   Loss=0.0868, RMSE=0.2947, R²=-0.0084
============================================================


============================================================
🔄 Round 212 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 212 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=0.0163
   Val:   Loss=0.0862, RMSE=0.2936, R²=0.0034
============================================================


📊 Round 212 Test Metrics:
   Loss: 0.0873, RMSE: 0.2954, MAE: 0.2556, R²: 0.0028

============================================================
🔄 Round 216 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0765 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0765, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0765, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0764, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0764, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0763, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0765)

============================================================
📊 Round 216 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=0.0091
   Val:   Loss=0.0765, RMSE=0.2766, R²=0.0342
============================================================


============================================================
🔄 Round 218 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 218 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=0.0145
   Val:   Loss=0.0809, RMSE=0.2845, R²=0.0066
============================================================


📊 Round 218 Test Metrics:
   Loss: 0.0872, RMSE: 0.2954, MAE: 0.2556, R²: 0.0029

📊 Round 218 Test Metrics:
   Loss: 0.0872, RMSE: 0.2954, MAE: 0.2556, R²: 0.0028

============================================================
🔄 Round 220 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 220 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=0.0065
   Val:   Loss=0.0837, RMSE=0.2893, R²=0.0391
============================================================


📊 Round 220 Test Metrics:
   Loss: 0.0872, RMSE: 0.2954, MAE: 0.2556, R²: 0.0028

📊 Round 220 Test Metrics:
   Loss: 0.0872, RMSE: 0.2954, MAE: 0.2556, R²: 0.0028

📊 Round 220 Test Metrics:
   Loss: 0.0873, RMSE: 0.2954, MAE: 0.2556, R²: 0.0028

============================================================
🔄 Round 223 - Client client_38
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 223 Summary - Client client_38
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=0.0268
   Val:   Loss=0.0828, RMSE=0.2878, R²=-0.0474
============================================================


❌ Client client_38 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8687 {grpc_message:"Socket closed", grpc_status:14}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8687 {grpc_message:"Socket closed", grpc_status:14}"
>
