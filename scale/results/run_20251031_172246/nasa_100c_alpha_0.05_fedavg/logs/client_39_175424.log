[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ab1f4f90-cd3a-45c2-ac8a-c8d00331046e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9a3102bd-9224-4803-a765-abc344f7af3c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eab23e1e-99db-40a9-805a-90b6a2a69a81
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a7a59e3c-ddec-4b69-96ee-f87aa5286976
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e0b41761-ba5b-416c-9e02-709fa61daee8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e89ae059-26d0-4464-bd31-1f6e5d507027
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7e7c254b-9423-493c-8275-dabebe65299f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ec2b84e9-6801-4bda-b939-f18d87be90ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a3a4fe0c-9493-4f6a-829f-2e6d0ae4c4ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a4db9cf5-fb0c-4b93-b301-9bbeb49be982
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b847a51f-9707-4560-90ad-c93108beb17f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ea2817e1-09ec-470d-8a6f-894cfa18b55e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cf702fec-776b-433e-bb16-a819df004080
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dcde08a7-be10-4c94-9c9f-624527cd9c9d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4e155030-c24b-45f4-84e6-0b207b4d9276
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dc39ef5c-3cce-41e9-ab74-069562993ebe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fa465ad6-0bbb-401b-a80d-956e533d088a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 78021370-cee3-4c82-b190-77c41e991720
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c4c18136-1b52-48a4-8f05-91dc5ef360c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6fad4598-b530-4b5f-8482-ebecb86c5ccd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 17ca2cad-973a-4340-ab92-2f65111962b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 39888de2-1e85-4faa-ae4d-299c9dc28e22
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7e0ed9f6-3c4a-4276-b163-2ee186f60abe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 28d86d40-e2ce-4d04-86c4-e34c4b477824
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 079adb41-92ed-4b7a-886b-f06fe227111b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ab4867dc-0597-4178-b85a-f00bd8dd6ef3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f6665165-8053-47fb-8591-1da6c60b6d19
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c3348663-7a7c-4784-be18-1aa8e8bed326
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a8c48aaa-9cc9-49d8-bbda-97e987da4954
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 02460e41-058c-4c96-bcfe-be6c0bd1e816
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e22ea6af-2ed7-4e9e-8ae2-9d912cfc47db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 29070441-0739-4b60-8f4e-c1393a135d65
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 434c8af2-0da9-4aa9-8407-347119f6aad8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2629e92c-9282-423a-8333-56f649f69856
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 21d3d857-c7cd-42a0-99a4-2f864478017b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4bb57d47-9035-4a5a-bf69-2d2f5d347afa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 43f273c6-96e3-442b-bceb-d3b19872b7ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ef4191a3-d36a-4eec-9d4b-980618bb1916
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0c69307b-fed6-475b-bf31-6dc2e91ff539
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f8823b84-5da3-4a4f-96df-ac8b595f0b06
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message da418f9c-925d-4e21-8d44-2dda65f0f6c7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a1acaf3f-557e-4d16-8913-2e298bf3405e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 932b5be9-84ba-4bde-9592-b691720a41e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b6b6e2d6-cd4f-4044-864b-b0dee7f458ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 916d0827-8f8e-41b1-8f5c-8a73d12a68a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 12f5a7bd-21a8-49e3-a88e-6f308e3d57bd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 16c0c128-422a-4460-9e24-3eb47ac635ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a7fb9c86-ccf6-43c6-b6b3-1e3e2fbea7d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2075526e-17ba-46b9-9dda-5a9721154301
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 214b8b8d-53c9-4b39-a2b8-7fc0d3de4b98
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 40cead6a-d33f-4551-a3fb-b6883ec55a65
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 56544d13-76f5-4ba0-899c-0dd95489997b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 13136a75-fb76-49cc-8333-0b5cd97d5035
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 124772f5-4baf-4883-a194-95acb8936ee9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f6636fea-6055-4ca7-b9ac-4b4b3223dad8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 958eab23-5ab6-4ea9-8f38-4334bca3dee0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 608bf314-046d-4752-ba94-a76289b0214a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 326dbcf8-4985-4101-8453-9892f9e59b81
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 81749527-e958-4038-b9bc-261562f51572
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 219c86a7-9590-4eb9-a932-aff8665c83a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1e0e1960-9b6e-4091-a70c-8a5573bc03c4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0bac7e43-176d-4c2b-b754-8a28fcfb7cd7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2083e5e7-f5bc-4f56-b219-3c87fdc86bd6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e3e5e2c3-acce-43c6-875c-cf538fe24d27
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d66faa1c-3206-4765-9083-dd99a5510301
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 16d69b2d-71b8-469f-aa4c-c2e060823455
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4d3132f1-1c86-4a9a-ac4b-ae84368877e5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 346ec943-07d2-49c8-87e5-ef5c077a6a8e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ec84ca8d-c201-4917-aad7-1ffc10b50b4c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 569725ed-8766-4475-b10a-2e1776520a00
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message adbc0761-6082-48de-91fe-f3284d09e56c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c845e4bc-f52c-4bf8-9ce6-2aa427bd6700
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 47da6300-8241-4b93-bf0b-21da001a37bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 623448c6-e966-4d5b-8340-79b4e2d3c9da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 380ceaca-9f04-406f-af84-18ed3d0b6053
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 82c80250-c959-4c01-a589-0f42da32c936
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 37be8a7c-a71d-4a8d-940f-38bce37f01b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b427130c-9b90-4631-893d-8eefac059fba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a1df93b8-cf06-4e96-8746-7bc38c9e8c0d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3f0d3e3c-8fb8-4852-9b97-dd61ae890d86
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f5736008-3064-4e57-a4c3-07ebf49784ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3d051349-184a-40ae-86a2-d1555b0f78aa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cb1dfdb0-9617-413c-b111-a28379bd17aa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 664fcc5d-c129-494c-bc2f-179e1eaba98b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0f632b63-7e0e-4656-9ecd-ab385a2e24f4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b8360b45-fc35-44ec-a151-f2afbff7c7fb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5961eba2-6613-4fdc-a766-9c0227245c29
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1d7e73d0-a642-4932-9f60-9c99d7c64c00
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d278fc2e-ecc2-448c-bdc6-a49fffcfcdc9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5c0aeedc-d76f-4ddc-bcf7-6ea63f80f145
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6884182f-9496-488f-a58a-cdfea824deea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bffd94c3-86d1-48c1-b9e6-ab0c14009faf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6fd4fe92-98bd-49a6-9fff-c37a496e5c3e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0fc565ca-89ac-42bd-b4a0-0eeb8d03d8db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cbc152a8-bbb6-4303-81c0-f525a204d2f7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 47bb8e50-3a57-471a-9b87-b0929c22919a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e59b076f-b541-4e2d-9b08-32e7c2362843
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3007910f-0221-42a2-930d-1a9be9efeaed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7ca5927b-04bd-430c-ab64-8f7dfabb0756
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1cc74896-61f0-416b-8b3e-03d9cbe4e3e5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7d56c3d6-01df-4693-8a2e-e9814b006e62
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a7157753-65f3-4fb5-a45f-d67cecbec589
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7f920b01-5a2c-402f-b3e8-cda844eceb51
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b507860a-a480-40f7-a5b5-3c640545f2e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 25e9deb9-3609-49d3-b880-5a69bf9fbc99
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d48a7df4-6a58-4834-b5df-c93e4e8ba775
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b28a8ed5-1b36-4a85-b992-f40bc9888b21
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5c5ed238-0bec-4ef3-b9bb-3f2b541d929c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 30dba3c1-2410-40dd-96c5-1fe5cb884e5e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 620a62ca-862c-4d56-a2cf-3496dcc7051f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 924fa2e1-228a-444a-a92b-1014b22cefec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dde46efc-90a3-49f2-9730-8db9376bacdc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dd908bbf-b83e-4f24-af4d-c159c17b54cd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 77de244c-1f32-426c-a0cc-f90bff261f57
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 277cb263-c89e-4d12-bca5-156ef948d72a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 78156af5-282d-4251-a459-bfc344692145
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dca6ad3d-14fd-462a-9c55-fc8d503c150a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bb7f9358-4268-4014-a340-0d7383e5e93d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 758d9e17-daae-4c73-969d-e522e518747a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0b27b2a3-d185-43f7-9bb2-fa76665c9798
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b3b05421-e9d5-4113-8be2-101210686bd5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d6ce67f3-5c3e-43f9-bd0f-32015d0082b5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f5c1ed6a-d9a1-481f-a111-fab019ba340e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ccd210b5-56af-480b-bfd1-e6c50e2f7a1c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 709685d1-901d-43e2-b3b7-bdd9fd9f1a94
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message abfd9526-b265-4c65-8f79-c9aedefffed7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c2430ae4-f5a8-4c2d-a4ec-5ec8ebd0384a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1f3fbfcd-3ea3-4d01-bd97-a6a64f1a10ea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 00f40d6f-8d83-4dbb-9995-6149231416e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a9b77a3e-867a-4137-920d-8e579d8511be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8fd877a0-2940-45ee-a42b-a4af7bb02552
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4e29131e-ec8e-4b24-a34c-a634628d279c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6a373593-f3bc-4255-9416-99349bcf3a37
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4fe3c92e-4b2a-4357-afbf-0c0dcc699698
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 085e07d9-473b-4349-b7ac-f038901184c6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4a90af84-61af-4dde-81d9-698bcb79118c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 27a42fc3-0672-449f-8d2b-d814cd11b81c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 27abf091-10f4-47fc-b071-fd2effbe4873
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7601266d-d051-4670-938c-c9152e0e459e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e65356fd-f9df-4db3-9fae-da9ca1eb4d49
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d28e02c8-cd7b-429b-9aca-e1f8d58f4142
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 488ed475-b476-4bfa-8b43-654d75bb3109
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ab86286f-6afc-4cdb-88c7-8d7db8b031db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 674beb45-5172-4734-aadc-9534b468ca6c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2178e92b-bbe6-4d66-a887-d920f795b942
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bf7dbdee-91a9-41ee-92bf-7bb679f6d32e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d4df8365-e0a5-4822-a7e8-9d25fb3cc539
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 87e0d6ba-014f-4135-a7a3-6b42cafe7e8b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 229c2f92-29b0-4b41-8b7f-847690bedd4e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f367201c-fc47-4235-9509-7975f3f44aec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6c107f73-1d2f-40e0-892e-c44b2861d9fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message db05801f-3ba1-4205-be50-7716be086545
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7dcd6bfc-d0af-4ed2-af63-542e14a90e5c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5addfbb8-60fd-4033-9fad-09fcadc7dab4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5bee67ae-f0e9-4e20-8ad2-5807464513dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6573154a-72f0-4e01-943d-d3ae2bb5ec1f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 012d0e87-c614-4f66-ad14-ce18fc9901de
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3d48857a-4d32-4f41-8aa0-9363a090ae67
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8161149e-f221-4eef-8f49-df45cfda7643
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "recvmsg:Connection reset by peer"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8687 {grpc_message:"recvmsg:Connection reset by peer", grpc_status:14}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_39
Server: localhost:8687
Algorithm: FEDAVG
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_39
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_39/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_39/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_39/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_39/test_labels.txt

📊 Raw data loaded:
   Train: X=(1819, 24), y=(1819,)
   Test:  X=(455, 24), y=(455,)

⚠️  Limiting training data: 1819 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  446 samples, 5 features
✅ Client client_39 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

📊 Round 0 Test Metrics:
   Loss: 0.0787, RMSE: 0.2804, MAE: 0.2414, R²: 0.0063

📊 Round 0 Test Metrics:
   Loss: 0.0778, RMSE: 0.2790, MAE: 0.2400, R²: 0.0164

📊 Round 0 Test Metrics:
   Loss: 0.0764, RMSE: 0.2764, MAE: 0.2378, R²: 0.0349

============================================================
🔄 Round 9 - Client client_39
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0891, val=0.0770 (↓), lr=0.001000
   • Epoch   2/100: train=0.0892, val=0.0773, patience=1/15, lr=0.001000
   • Epoch   3/100: train=0.0885, val=0.0779, patience=2/15, lr=0.001000
   • Epoch   4/100: train=0.0862, val=0.0771, patience=3/15, lr=0.001000
   ✓ Epoch   5/100: train=0.0857, val=0.0761 (↓), lr=0.001000
   • Epoch  11/100: train=0.0820, val=0.0761, patience=6/15, lr=0.001000
   📉 Epoch 14: LR reduced 0.001000 → 0.000500

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0761)

============================================================
📊 Round 9 Summary - Client client_39
   Epochs: 20/100 (early stopped)
   LR: 0.001000 → 0.000500 (1 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=0.0862
   Val:   Loss=0.0761, RMSE=0.2759, R²=0.0221
============================================================


📊 Round 9 Test Metrics:
   Loss: 0.0764, RMSE: 0.2764, MAE: 0.2380, R²: 0.0345

📊 Round 9 Test Metrics:
   Loss: 0.0766, RMSE: 0.2767, MAE: 0.2382, R²: 0.0329

============================================================
🔄 Round 14 - Client client_39
   Epochs: 100, Batch: 32, LR: 0.000500
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0893 (↓), lr=0.000500
   📉 Epoch 2: LR reduced 0.000500 → 0.000250
   • Epoch   2/100: train=0.0837, val=0.0896, patience=1/15, lr=0.000250
   • Epoch   3/100: train=0.0821, val=0.0894, patience=2/15, lr=0.000250
   • Epoch   4/100: train=0.0817, val=0.0895, patience=3/15, lr=0.000250
   • Epoch   5/100: train=0.0813, val=0.0896, patience=4/15, lr=0.000250
   📉 Epoch 10: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0791, val=0.0898, patience=10/15, lr=0.000125

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0893)

============================================================
📊 Round 14 Summary - Client client_39
   Epochs: 16/100 (early stopped)
   LR: 0.000500 → 0.000125 (2 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=0.0436
   Val:   Loss=0.0893, RMSE=0.2988, R²=0.0456
============================================================


📊 Round 14 Test Metrics:
   Loss: 0.0764, RMSE: 0.2763, MAE: 0.2378, R²: 0.0353

📊 Round 14 Test Metrics:
   Loss: 0.0763, RMSE: 0.2763, MAE: 0.2377, R²: 0.0357

============================================================
🔄 Round 19 - Client client_39
   Epochs: 100, Batch: 32, LR: 0.000125
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0824 (↓), lr=0.000125
   📉 Epoch 2: LR reduced 0.000125 → 0.000063
   ✓ Epoch   2/100: train=0.0858, val=0.0819 (↓), lr=0.000063
   • Epoch   3/100: train=0.0854, val=0.0817, patience=1/15, lr=0.000063
   • Epoch   4/100: train=0.0852, val=0.0816, patience=2/15, lr=0.000063
   • Epoch   5/100: train=0.0850, val=0.0815, patience=3/15, lr=0.000063
   📉 Epoch 10: LR reduced 0.000063 → 0.000031
   • Epoch  11/100: train=0.0840, val=0.0808, patience=1/15, lr=0.000031
   📉 Epoch 18: LR reduced 0.000031 → 0.000016
   • Epoch  21/100: train=0.0835, val=0.0805, patience=11/15, lr=0.000016

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 19 Summary - Client client_39
   Epochs: 25/100 (early stopped)
   LR: 0.000125 → 0.000016 (3 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=0.0540
   Val:   Loss=0.0808, RMSE=0.2843, R²=0.0605
============================================================


📊 Round 19 Test Metrics:
   Loss: 0.0764, RMSE: 0.2764, MAE: 0.2378, R²: 0.0351

============================================================
🔄 Round 20 - Client client_39
   Epochs: 100, Batch: 32, LR: 0.000016
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   📉 Epoch 1: LR reduced 0.000016 → 0.000008
   ✓ Epoch   1/100: train=0.0866, val=0.0806 (↓), lr=0.000008
   • Epoch   2/100: train=0.0865, val=0.0806, patience=1/15, lr=0.000008
   • Epoch   3/100: train=0.0865, val=0.0806, patience=2/15, lr=0.000008
   • Epoch   4/100: train=0.0864, val=0.0806, patience=3/15, lr=0.000008
   • Epoch   5/100: train=0.0863, val=0.0805, patience=4/15, lr=0.000008
   📉 Epoch 9: LR reduced 0.000008 → 0.000004
   • Epoch  11/100: train=0.0860, val=0.0805, patience=10/15, lr=0.000004

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 20 Summary - Client client_39
   Epochs: 16/100 (early stopped)
   LR: 0.000016 → 0.000004 (2 reductions)
   Train: Loss=0.0866, RMSE=0.2942, R²=0.0308
   Val:   Loss=0.0806, RMSE=0.2838, R²=0.0226
============================================================


============================================================
🔄 Round 21 - Client client_39
   Epochs: 100, Batch: 32, LR: 0.000004
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   📉 Epoch 1: LR reduced 0.000004 → 0.000002
   ✓ Epoch   1/100: train=0.0865, val=0.0801 (↓), lr=0.000002
   • Epoch   2/100: train=0.0865, val=0.0801, patience=1/15, lr=0.000002
   • Epoch   3/100: train=0.0865, val=0.0801, patience=2/15, lr=0.000002
   • Epoch   4/100: train=0.0865, val=0.0801, patience=3/15, lr=0.000002
   • Epoch   5/100: train=0.0865, val=0.0801, patience=4/15, lr=0.000002
   📉 Epoch 9: LR reduced 0.000002 → 0.000001
   • Epoch  11/100: train=0.0864, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 21 Summary - Client client_39
   Epochs: 16/100 (early stopped)
   LR: 0.000004 → 0.000001 (2 reductions)
   Train: Loss=0.0865, RMSE=0.2942, R²=0.0286
   Val:   Loss=0.0801, RMSE=0.2831, R²=0.0342
============================================================


📊 Round 21 Test Metrics:
   Loss: 0.0763, RMSE: 0.2762, MAE: 0.2377, R²: 0.0361

============================================================
🔄 Round 23 - Client client_39
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0910 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0910, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0910, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0910, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0910, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0909, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0910)

============================================================
📊 Round 23 Summary - Client client_39
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=0.0384
   Val:   Loss=0.0910, RMSE=0.3016, R²=0.0110
============================================================


============================================================
🔄 Round 24 - Client client_39
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0876 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0876, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0876, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0876, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0876, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0877, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0876)

============================================================
📊 Round 24 Summary - Client client_39
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=0.0339
   Val:   Loss=0.0876, RMSE=0.2960, R²=0.0119
============================================================


📊 Round 24 Test Metrics:
   Loss: 0.0763, RMSE: 0.2762, MAE: 0.2376, R²: 0.0363

📊 Round 24 Test Metrics:
   Loss: 0.0763, RMSE: 0.2762, MAE: 0.2376, R²: 0.0361

============================================================
🔄 Round 29 - Client client_39
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0906 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0906, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0906, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0906, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0906, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0906, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0906)

============================================================
📊 Round 29 Summary - Client client_39
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2896, R²=0.0300
   Val:   Loss=0.0906, RMSE=0.3010, R²=0.0361
============================================================


📊 Round 29 Test Metrics:
   Loss: 0.0763, RMSE: 0.2762, MAE: 0.2376, R²: 0.0362

📊 Round 29 Test Metrics:
   Loss: 0.0763, RMSE: 0.2762, MAE: 0.2376, R²: 0.0362

============================================================
🔄 Round 33 - Client client_39
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0868, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0868, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0868, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0868, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0867, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 33 Summary - Client client_39
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0870, RMSE=0.2950, R²=0.0296
   Val:   Loss=0.0781, RMSE=0.2794, R²=0.0230
============================================================


📊 Round 33 Test Metrics:
   Loss: 0.0763, RMSE: 0.2762, MAE: 0.2376, R²: 0.0363

📊 Round 33 Test Metrics:
   Loss: 0.0763, RMSE: 0.2762, MAE: 0.2376, R²: 0.0364

📊 Round 33 Test Metrics:
   Loss: 0.0763, RMSE: 0.2762, MAE: 0.2376, R²: 0.0364

============================================================
🔄 Round 45 - Client client_39
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 45 Summary - Client client_39
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2930, R²=0.0342
   Val:   Loss=0.0826, RMSE=0.2874, R²=0.0229
============================================================


📊 Round 45 Test Metrics:
   Loss: 0.0763, RMSE: 0.2762, MAE: 0.2376, R²: 0.0364

============================================================
🔄 Round 46 - Client client_39
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0885 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0884, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0884, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0884, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0884, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0884, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0885)

============================================================
📊 Round 46 Summary - Client client_39
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=0.0388
   Val:   Loss=0.0885, RMSE=0.2974, R²=0.0046
============================================================


============================================================
🔄 Round 50 - Client client_39
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 50 Summary - Client client_39
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2918, R²=0.0321
   Val:   Loss=0.0854, RMSE=0.2923, R²=0.0353
============================================================


============================================================
🔄 Round 51 - Client client_39
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0899 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0899, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0899, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0899, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0899, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0898, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0899)

============================================================
📊 Round 51 Summary - Client client_39
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2899, R²=0.0340
   Val:   Loss=0.0899, RMSE=0.2998, R²=0.0293
============================================================


📊 Round 51 Test Metrics:
   Loss: 0.0763, RMSE: 0.2762, MAE: 0.2376, R²: 0.0365

============================================================
🔄 Round 53 - Client client_39
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0867, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0867, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0867, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0867, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0866, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 53 Summary - Client client_39
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2942, R²=0.0310
   Val:   Loss=0.0799, RMSE=0.2826, R²=0.0417
============================================================


📊 Round 53 Test Metrics:
   Loss: 0.0763, RMSE: 0.2762, MAE: 0.2376, R²: 0.0363

============================================================
🔄 Round 56 - Client client_39
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0954 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0954, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0954, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0954, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0954, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0955, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0954)

============================================================
📊 Round 56 Summary - Client client_39
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2875, R²=0.0347
   Val:   Loss=0.0954, RMSE=0.3088, R²=0.0050
============================================================


============================================================
🔄 Round 59 - Client client_39
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 59 Summary - Client client_39
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2921, R²=0.0363
   Val:   Loss=0.0848, RMSE=0.2912, R²=0.0195
============================================================


============================================================
🔄 Round 61 - Client client_39
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0885, val=0.0720 (↓), lr=0.000001
   • Epoch   2/100: train=0.0884, val=0.0720, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0884, val=0.0720, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0884, val=0.0720, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0884, val=0.0720, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0884, val=0.0720, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0720)

============================================================
📊 Round 61 Summary - Client client_39
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0885, RMSE=0.2975, R²=0.0341
   Val:   Loss=0.0720, RMSE=0.2684, R²=0.0282
============================================================


📊 Round 61 Test Metrics:
   Loss: 0.0763, RMSE: 0.2762, MAE: 0.2376, R²: 0.0363

============================================================
🔄 Round 62 - Client client_39
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.0777 (↓), lr=0.000001
   • Epoch   2/100: train=0.0868, val=0.0777, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0868, val=0.0777, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0868, val=0.0777, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0868, val=0.0777, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0868, val=0.0777, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 62 Summary - Client client_39
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0871, RMSE=0.2951, R²=0.0335
   Val:   Loss=0.0777, RMSE=0.2787, R²=0.0260
============================================================


📊 Round 62 Test Metrics:
   Loss: 0.0763, RMSE: 0.2762, MAE: 0.2376, R²: 0.0364

📊 Round 62 Test Metrics:
   Loss: 0.0763, RMSE: 0.2762, MAE: 0.2376, R²: 0.0365

📊 Round 62 Test Metrics:
   Loss: 0.0763, RMSE: 0.2762, MAE: 0.2376, R²: 0.0365

📊 Round 62 Test Metrics:
   Loss: 0.0763, RMSE: 0.2761, MAE: 0.2376, R²: 0.0366

📊 Round 62 Test Metrics:
   Loss: 0.0763, RMSE: 0.2761, MAE: 0.2376, R²: 0.0366

📊 Round 62 Test Metrics:
   Loss: 0.0762, RMSE: 0.2761, MAE: 0.2376, R²: 0.0367

📊 Round 62 Test Metrics:
   Loss: 0.0762, RMSE: 0.2761, MAE: 0.2376, R²: 0.0367

============================================================
🔄 Round 77 - Client client_39
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0872 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0872, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0872, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0872, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0872, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0872, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0872)

============================================================
📊 Round 77 Summary - Client client_39
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2911, R²=0.0378
   Val:   Loss=0.0872, RMSE=0.2953, R²=0.0025
============================================================


============================================================
🔄 Round 78 - Client client_39
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0900 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0900, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0900, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0900, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0900, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0899, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0900)

============================================================
📊 Round 78 Summary - Client client_39
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2899, R²=0.0347
   Val:   Loss=0.0900, RMSE=0.3000, R²=0.0275
============================================================


📊 Round 78 Test Metrics:
   Loss: 0.0762, RMSE: 0.2761, MAE: 0.2376, R²: 0.0368

============================================================
🔄 Round 79 - Client client_39
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0906 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0906, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0906, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0906, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0906, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0906, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0906)

============================================================
📊 Round 79 Summary - Client client_39
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2896, R²=0.0317
   Val:   Loss=0.0906, RMSE=0.3010, R²=0.0360
============================================================


📊 Round 79 Test Metrics:
   Loss: 0.0762, RMSE: 0.2761, MAE: 0.2376, R²: 0.0368

📊 Round 79 Test Metrics:
   Loss: 0.0762, RMSE: 0.2761, MAE: 0.2376, R²: 0.0367

📊 Round 79 Test Metrics:
   Loss: 0.0762, RMSE: 0.2761, MAE: 0.2376, R²: 0.0367

============================================================
🔄 Round 84 - Client client_39
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0881 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0881, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0881, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0881, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0881, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0882, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0881)

============================================================
📊 Round 84 Summary - Client client_39
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2906, R²=0.0330
   Val:   Loss=0.0881, RMSE=0.2969, R²=0.0295
============================================================


============================================================
🔄 Round 85 - Client client_39
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0914 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0914, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0914, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0914, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0914, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0913, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0914)

============================================================
📊 Round 85 Summary - Client client_39
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=0.0354
   Val:   Loss=0.0914, RMSE=0.3023, R²=0.0156
============================================================


📊 Round 85 Test Metrics:
   Loss: 0.0762, RMSE: 0.2761, MAE: 0.2376, R²: 0.0368

📊 Round 85 Test Metrics:
   Loss: 0.0762, RMSE: 0.2761, MAE: 0.2376, R²: 0.0368

📊 Round 85 Test Metrics:
   Loss: 0.0762, RMSE: 0.2761, MAE: 0.2376, R²: 0.0368

============================================================
🔄 Round 90 - Client client_39
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0879 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0878, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0878, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0878, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0878, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0878, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0879)

============================================================
📊 Round 90 Summary - Client client_39
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2908, R²=0.0310
   Val:   Loss=0.0879, RMSE=0.2964, R²=0.0413
============================================================


📊 Round 90 Test Metrics:
   Loss: 0.0762, RMSE: 0.2761, MAE: 0.2376, R²: 0.0369

📊 Round 90 Test Metrics:
   Loss: 0.0762, RMSE: 0.2761, MAE: 0.2375, R²: 0.0369

============================================================
🔄 Round 94 - Client client_39
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0895 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0895, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0895, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0895, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0895, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0895, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0895)

============================================================
📊 Round 94 Summary - Client client_39
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2901, R²=0.0312
   Val:   Loss=0.0895, RMSE=0.2991, R²=0.0357
============================================================


============================================================
🔄 Round 95 - Client client_39
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0885, val=0.0721 (↓), lr=0.000001
   • Epoch   2/100: train=0.0884, val=0.0721, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0884, val=0.0721, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0884, val=0.0721, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0884, val=0.0721, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0884, val=0.0721, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0721)

============================================================
📊 Round 95 Summary - Client client_39
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0885, RMSE=0.2975, R²=0.0362
   Val:   Loss=0.0721, RMSE=0.2684, R²=0.0148
============================================================


📊 Round 95 Test Metrics:
   Loss: 0.0762, RMSE: 0.2761, MAE: 0.2375, R²: 0.0369

============================================================
🔄 Round 97 - Client client_39
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 97 Summary - Client client_39
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2919, R²=0.0363
   Val:   Loss=0.0851, RMSE=0.2917, R²=0.0205
============================================================


============================================================
🔄 Round 98 - Client client_39
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0868, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0868, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0868, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0868, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0867, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 98 Summary - Client client_39
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0867, RMSE=0.2944, R²=0.0319
   Val:   Loss=0.0793, RMSE=0.2816, R²=0.0378
============================================================


============================================================
🔄 Round 99 - Client client_39
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 99 Summary - Client client_39
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2923, R²=0.0313
   Val:   Loss=0.0843, RMSE=0.2904, R²=0.0395
============================================================


📊 Round 99 Test Metrics:
   Loss: 0.0762, RMSE: 0.2761, MAE: 0.2375, R²: 0.0370

============================================================
🔄 Round 100 - Client client_39
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0902 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0902, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0902, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0901, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0901, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0901, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0902)

============================================================
📊 Round 100 Summary - Client client_39
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=0.0355
   Val:   Loss=0.0902, RMSE=0.3003, R²=0.0206
============================================================


📊 Round 100 Test Metrics:
   Loss: 0.0762, RMSE: 0.2761, MAE: 0.2375, R²: 0.0370

📊 Round 100 Test Metrics:
   Loss: 0.0762, RMSE: 0.2761, MAE: 0.2375, R²: 0.0371

📊 Round 100 Test Metrics:
   Loss: 0.0762, RMSE: 0.2761, MAE: 0.2375, R²: 0.0371

============================================================
🔄 Round 104 - Client client_39
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 104 Summary - Client client_39
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2917, R²=0.0334
   Val:   Loss=0.0856, RMSE=0.2926, R²=0.0308
============================================================


📊 Round 104 Test Metrics:
   Loss: 0.0762, RMSE: 0.2761, MAE: 0.2375, R²: 0.0371

============================================================
🔄 Round 105 - Client client_39
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 105 Summary - Client client_39
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2932, R²=0.0296
   Val:   Loss=0.0823, RMSE=0.2868, R²=0.0416
============================================================


============================================================
🔄 Round 107 - Client client_39
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 107 Summary - Client client_39
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2934, R²=0.0319
   Val:   Loss=0.0816, RMSE=0.2856, R²=0.0380
============================================================


📊 Round 107 Test Metrics:
   Loss: 0.0762, RMSE: 0.2761, MAE: 0.2375, R²: 0.0372

📊 Round 107 Test Metrics:
   Loss: 0.0762, RMSE: 0.2761, MAE: 0.2375, R²: 0.0372

============================================================
🔄 Round 110 - Client client_39
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0887 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0887, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0887, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0887, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0887, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0887, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0887)

============================================================
📊 Round 110 Summary - Client client_39
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2904, R²=0.0321
   Val:   Loss=0.0887, RMSE=0.2979, R²=0.0373
============================================================


📊 Round 110 Test Metrics:
   Loss: 0.0762, RMSE: 0.2761, MAE: 0.2375, R²: 0.0371

============================================================
🔄 Round 112 - Client client_39
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0873 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0873, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0873, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0873, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0873, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0873, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0873)

============================================================
📊 Round 112 Summary - Client client_39
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=0.0333
   Val:   Loss=0.0873, RMSE=0.2955, R²=0.0331
============================================================


📊 Round 112 Test Metrics:
   Loss: 0.0762, RMSE: 0.2761, MAE: 0.2375, R²: 0.0372

📊 Round 112 Test Metrics:
   Loss: 0.0762, RMSE: 0.2760, MAE: 0.2375, R²: 0.0373

============================================================
🔄 Round 116 - Client client_39
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 116 Summary - Client client_39
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2919, R²=0.0296
   Val:   Loss=0.0851, RMSE=0.2918, R²=0.0475
============================================================


📊 Round 116 Test Metrics:
   Loss: 0.0762, RMSE: 0.2760, MAE: 0.2375, R²: 0.0373

📊 Round 116 Test Metrics:
   Loss: 0.0762, RMSE: 0.2760, MAE: 0.2375, R²: 0.0374

📊 Round 116 Test Metrics:
   Loss: 0.0762, RMSE: 0.2760, MAE: 0.2375, R²: 0.0375

📊 Round 116 Test Metrics:
   Loss: 0.0762, RMSE: 0.2760, MAE: 0.2375, R²: 0.0375

============================================================
🔄 Round 127 - Client client_39
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 127 Summary - Client client_39
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2929, R²=0.0289
   Val:   Loss=0.0828, RMSE=0.2878, R²=0.0512
============================================================


📊 Round 127 Test Metrics:
   Loss: 0.0762, RMSE: 0.2760, MAE: 0.2375, R²: 0.0374

📊 Round 127 Test Metrics:
   Loss: 0.0762, RMSE: 0.2760, MAE: 0.2375, R²: 0.0373

📊 Round 127 Test Metrics:
   Loss: 0.0762, RMSE: 0.2760, MAE: 0.2375, R²: 0.0373

📊 Round 127 Test Metrics:
   Loss: 0.0762, RMSE: 0.2760, MAE: 0.2375, R²: 0.0373

============================================================
🔄 Round 136 - Client client_39
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 136 Summary - Client client_39
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2920, R²=0.0358
   Val:   Loss=0.0851, RMSE=0.2917, R²=0.0228
============================================================


📊 Round 136 Test Metrics:
   Loss: 0.0762, RMSE: 0.2761, MAE: 0.2375, R²: 0.0372

============================================================
🔄 Round 137 - Client client_39
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 137 Summary - Client client_39
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2925, R²=0.0309
   Val:   Loss=0.0838, RMSE=0.2895, R²=0.0428
============================================================


============================================================
🔄 Round 139 - Client client_39
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 139 Summary - Client client_39
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2936, R²=0.0339
   Val:   Loss=0.0811, RMSE=0.2847, R²=0.0292
============================================================


============================================================
🔄 Round 143 - Client client_39
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 143 Summary - Client client_39
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2930, R²=0.0306
   Val:   Loss=0.0827, RMSE=0.2876, R²=0.0038
============================================================


📊 Round 143 Test Metrics:
   Loss: 0.0762, RMSE: 0.2760, MAE: 0.2375, R²: 0.0374

============================================================
🔄 Round 147 - Client client_39
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0859, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 147 Summary - Client client_39
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2916, R²=0.0363
   Val:   Loss=0.0859, RMSE=0.2931, R²=0.0199
============================================================


============================================================
🔄 Round 148 - Client client_39
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 148 Summary - Client client_39
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2934, R²=0.0337
   Val:   Loss=0.0817, RMSE=0.2858, R²=0.0310
============================================================


📊 Round 148 Test Metrics:
   Loss: 0.0762, RMSE: 0.2760, MAE: 0.2375, R²: 0.0374

📊 Round 148 Test Metrics:
   Loss: 0.0762, RMSE: 0.2760, MAE: 0.2375, R²: 0.0375

📊 Round 148 Test Metrics:
   Loss: 0.0762, RMSE: 0.2760, MAE: 0.2375, R²: 0.0375

📊 Round 148 Test Metrics:
   Loss: 0.0762, RMSE: 0.2760, MAE: 0.2375, R²: 0.0375

============================================================
🔄 Round 156 - Client client_39
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 156 Summary - Client client_39
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2928, R²=0.0385
   Val:   Loss=0.0831, RMSE=0.2883, R²=-0.0042
============================================================


📊 Round 156 Test Metrics:
   Loss: 0.0762, RMSE: 0.2760, MAE: 0.2375, R²: 0.0375

📊 Round 156 Test Metrics:
   Loss: 0.0762, RMSE: 0.2760, MAE: 0.2375, R²: 0.0375

============================================================
🔄 Round 159 - Client client_39
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0867 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0867, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0866, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0866, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0866, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0866, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 159 Summary - Client client_39
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2913, R²=0.0306
   Val:   Loss=0.0867, RMSE=0.2944, R²=0.0427
============================================================


============================================================
🔄 Round 160 - Client client_39
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0911 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0911, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0911, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0911, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0911, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0912, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0911)

============================================================
📊 Round 160 Summary - Client client_39
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=0.0310
   Val:   Loss=0.0911, RMSE=0.3018, R²=0.0298
============================================================


📊 Round 160 Test Metrics:
   Loss: 0.0762, RMSE: 0.2760, MAE: 0.2375, R²: 0.0375

============================================================
🔄 Round 162 - Client client_39
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0908 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0908, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0908, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0908, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0908, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0907, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0908)

============================================================
📊 Round 162 Summary - Client client_39
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=0.0367
   Val:   Loss=0.0908, RMSE=0.3013, R²=0.0207
============================================================


============================================================
🔄 Round 163 - Client client_39
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 163 Summary - Client client_39
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2937, R²=0.0338
   Val:   Loss=0.0809, RMSE=0.2844, R²=0.0280
============================================================


📊 Round 163 Test Metrics:
   Loss: 0.0762, RMSE: 0.2760, MAE: 0.2375, R²: 0.0375

============================================================
🔄 Round 164 - Client client_39
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 164 Summary - Client client_39
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2928, R²=0.0340
   Val:   Loss=0.0830, RMSE=0.2881, R²=0.0161
============================================================


📊 Round 164 Test Metrics:
   Loss: 0.0762, RMSE: 0.2760, MAE: 0.2375, R²: 0.0375

============================================================
🔄 Round 167 - Client client_39
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 167 Summary - Client client_39
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2928, R²=0.0366
   Val:   Loss=0.0830, RMSE=0.2881, R²=0.0124
============================================================


📊 Round 167 Test Metrics:
   Loss: 0.0762, RMSE: 0.2760, MAE: 0.2375, R²: 0.0374

============================================================
🔄 Round 170 - Client client_39
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 170 Summary - Client client_39
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2922, R²=0.0386
   Val:   Loss=0.0846, RMSE=0.2908, R²=0.0109
============================================================


============================================================
🔄 Round 171 - Client client_39
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0868 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0868, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0868, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0868, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0868, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0868, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0868)

============================================================
📊 Round 171 Summary - Client client_39
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=0.0328
   Val:   Loss=0.0868, RMSE=0.2946, R²=0.0240
============================================================


📊 Round 171 Test Metrics:
   Loss: 0.0762, RMSE: 0.2760, MAE: 0.2375, R²: 0.0375

============================================================
🔄 Round 173 - Client client_39
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0867, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0867, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0867, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0867, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0866, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 173 Summary - Client client_39
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2941, R²=0.0326
   Val:   Loss=0.0799, RMSE=0.2827, R²=0.0342
============================================================


📊 Round 173 Test Metrics:
   Loss: 0.0762, RMSE: 0.2760, MAE: 0.2375, R²: 0.0376

📊 Round 173 Test Metrics:
   Loss: 0.0762, RMSE: 0.2760, MAE: 0.2375, R²: 0.0376

============================================================
🔄 Round 179 - Client client_39
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0877, val=0.0755 (↓), lr=0.000001
   • Epoch   2/100: train=0.0877, val=0.0755, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0877, val=0.0756, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0877, val=0.0756, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0877, val=0.0756, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0876, val=0.0756, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0755)

============================================================
📊 Round 179 Summary - Client client_39
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0876, RMSE=0.2960, R²=0.0301
   Val:   Loss=0.0755, RMSE=0.2748, R²=0.0238
============================================================


📊 Round 179 Test Metrics:
   Loss: 0.0762, RMSE: 0.2760, MAE: 0.2375, R²: 0.0375

============================================================
🔄 Round 186 - Client client_39
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0887 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0886, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0886, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0886, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0886, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0886, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0887)

============================================================
📊 Round 186 Summary - Client client_39
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2904, R²=0.0308
   Val:   Loss=0.0887, RMSE=0.2978, R²=0.0416
============================================================


📊 Round 186 Test Metrics:
   Loss: 0.0762, RMSE: 0.2760, MAE: 0.2375, R²: 0.0374

📊 Round 186 Test Metrics:
   Loss: 0.0762, RMSE: 0.2760, MAE: 0.2375, R²: 0.0374

📊 Round 186 Test Metrics:
   Loss: 0.0762, RMSE: 0.2760, MAE: 0.2375, R²: 0.0374

============================================================
🔄 Round 189 - Client client_39
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0889 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0889, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0889, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0889, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0889, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0889, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0889)

============================================================
📊 Round 189 Summary - Client client_39
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=0.0410
   Val:   Loss=0.0889, RMSE=0.2982, R²=0.0026
============================================================


📊 Round 189 Test Metrics:
   Loss: 0.0762, RMSE: 0.2760, MAE: 0.2375, R²: 0.0374

============================================================
🔄 Round 191 - Client client_39
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0905 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0905, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0905, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0905, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0905, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0905, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0905)

============================================================
📊 Round 191 Summary - Client client_39
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2896, R²=0.0376
   Val:   Loss=0.0905, RMSE=0.3008, R²=0.0080
============================================================


📊 Round 191 Test Metrics:
   Loss: 0.0762, RMSE: 0.2760, MAE: 0.2375, R²: 0.0374

============================================================
🔄 Round 193 - Client client_39
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0874 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0874, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0874, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0874, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0874, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0876, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0874)

============================================================
📊 Round 193 Summary - Client client_39
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=0.0350
   Val:   Loss=0.0874, RMSE=0.2956, R²=-0.0148
============================================================


📊 Round 193 Test Metrics:
   Loss: 0.0762, RMSE: 0.2760, MAE: 0.2375, R²: 0.0374

============================================================
🔄 Round 196 - Client client_39
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0928 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0928, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0928, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0928, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0928, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0928, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0928)

============================================================
📊 Round 196 Summary - Client client_39
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=0.0384
   Val:   Loss=0.0928, RMSE=0.3046, R²=0.0070
============================================================


📊 Round 196 Test Metrics:
   Loss: 0.0762, RMSE: 0.2760, MAE: 0.2375, R²: 0.0374

============================================================
🔄 Round 199 - Client client_39
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 199 Summary - Client client_39
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2936, R²=0.0292
   Val:   Loss=0.0812, RMSE=0.2849, R²=0.0454
============================================================


📊 Round 199 Test Metrics:
   Loss: 0.0762, RMSE: 0.2760, MAE: 0.2375, R²: 0.0375

============================================================
🔄 Round 201 - Client client_39
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 201 Summary - Client client_39
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2943, R²=0.0368
   Val:   Loss=0.0796, RMSE=0.2821, R²=0.0071
============================================================


============================================================
🔄 Round 202 - Client client_39
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 202 Summary - Client client_39
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2933, R²=0.0291
   Val:   Loss=0.0820, RMSE=0.2863, R²=0.0481
============================================================


📊 Round 202 Test Metrics:
   Loss: 0.0762, RMSE: 0.2760, MAE: 0.2375, R²: 0.0374

============================================================
🔄 Round 204 - Client client_39
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0874 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0874, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0874, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0874, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0874, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0874, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0874)

============================================================
📊 Round 204 Summary - Client client_39
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=0.0370
   Val:   Loss=0.0874, RMSE=0.2957, R²=0.0182
============================================================


📊 Round 204 Test Metrics:
   Loss: 0.0762, RMSE: 0.2760, MAE: 0.2375, R²: 0.0374

============================================================
🔄 Round 205 - Client client_39
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 205 Summary - Client client_39
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2929, R²=0.0367
   Val:   Loss=0.0827, RMSE=0.2876, R²=0.0172
============================================================


============================================================
🔄 Round 208 - Client client_39
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0881 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0881, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0881, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0881, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0882, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0883, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0881)

============================================================
📊 Round 208 Summary - Client client_39
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2906, R²=0.0315
   Val:   Loss=0.0881, RMSE=0.2968, R²=0.0160
============================================================


============================================================
🔄 Round 210 - Client client_39
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 210 Summary - Client client_39
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2922, R²=0.0357
   Val:   Loss=0.0843, RMSE=0.2904, R²=0.0171
============================================================


📊 Round 210 Test Metrics:
   Loss: 0.0762, RMSE: 0.2760, MAE: 0.2375, R²: 0.0376

============================================================
🔄 Round 212 - Client client_39
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 212 Summary - Client client_39
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2917, R²=0.0315
   Val:   Loss=0.0855, RMSE=0.2925, R²=0.0404
============================================================


============================================================
🔄 Round 213 - Client client_39
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0922 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0922, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0922, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0922, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0922, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0922, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0922)

============================================================
📊 Round 213 Summary - Client client_39
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=0.0315
   Val:   Loss=0.0922, RMSE=0.3037, R²=0.0336
============================================================


============================================================
🔄 Round 215 - Client client_39
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0871, val=0.0780 (↓), lr=0.000001
   • Epoch   2/100: train=0.0871, val=0.0780, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0871, val=0.0780, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0871, val=0.0780, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0871, val=0.0780, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0870, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 215 Summary - Client client_39
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0870, RMSE=0.2949, R²=0.0303
   Val:   Loss=0.0780, RMSE=0.2793, R²=0.0412
============================================================


📊 Round 215 Test Metrics:
   Loss: 0.0762, RMSE: 0.2760, MAE: 0.2375, R²: 0.0375

============================================================
🔄 Round 219 - Client client_39
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 219 Summary - Client client_39
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2932, R²=0.0333
   Val:   Loss=0.0821, RMSE=0.2865, R²=0.0203
============================================================


📊 Round 219 Test Metrics:
   Loss: 0.0762, RMSE: 0.2760, MAE: 0.2375, R²: 0.0376

============================================================
🔄 Round 221 - Client client_39
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0900 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0900, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0900, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0900, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0900, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0900, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0900)

============================================================
📊 Round 221 Summary - Client client_39
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=0.0352
   Val:   Loss=0.0900, RMSE=0.3001, R²=0.0265
============================================================


============================================================
🔄 Round 222 - Client client_39
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0873, val=0.0771 (↓), lr=0.000001
   • Epoch   2/100: train=0.0873, val=0.0771, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0873, val=0.0771, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0873, val=0.0771, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0873, val=0.0771, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0872, val=0.0771, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0771)

============================================================
📊 Round 222 Summary - Client client_39
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0872, RMSE=0.2953, R²=0.0314
   Val:   Loss=0.0771, RMSE=0.2777, R²=0.0414
============================================================


============================================================
🔄 Round 223 - Client client_39
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 223 Summary - Client client_39
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2929, R²=0.0291
   Val:   Loss=0.0828, RMSE=0.2877, R²=0.0418
============================================================


============================================================
🔄 Round 224 - Client client_39
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0911 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0911, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0911, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0911, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0911, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0910, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0911)

============================================================
📊 Round 224 Summary - Client client_39
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=0.0323
   Val:   Loss=0.0911, RMSE=0.3018, R²=0.0376
============================================================


============================================================
🔄 Round 225 - Client client_39
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 225 Summary - Client client_39
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2922, R²=0.0330
   Val:   Loss=0.0844, RMSE=0.2904, R²=0.0325
============================================================


❌ Client client_39 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "recvmsg:Connection reset by peer"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8687 {grpc_message:"recvmsg:Connection reset by peer", grpc_status:14}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "recvmsg:Connection reset by peer"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8687 {grpc_message:"recvmsg:Connection reset by peer", grpc_status:14}"
>
