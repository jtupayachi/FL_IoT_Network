[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9e8c7216-86bd-4a2a-b2a7-480ab553cbe9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1fb7ba73-63cc-4154-b8a3-8782fa0f980c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dda0535e-0860-4e63-a49f-e907c86fcb30
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cbcde200-87b6-4b9c-abb0-1de57e5bea7a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a3b330a1-6dce-4e53-9a0f-2cda07ce7f20
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 664a0025-a4bf-43e1-98c9-bab56b61a798
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6013ec31-4722-4ebb-83fb-50344bd2a47e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 17655aec-af63-45ae-9922-396e7508d872
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 58d7e6fa-c30f-49c9-9d29-9e9c6e9faf8b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5eaaafa1-2e18-4286-9ccb-e8b5f02359eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 03892339-c4ec-445f-b7e8-4e6da7bd32ce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6694f823-edc3-4dea-9890-21ae4ce933f4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b33633af-1bb2-4b0d-8676-866d0824bb6c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 971b607a-8f98-4918-b8f2-c98802b8db59
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message efe37a5e-1a62-40ed-9a21-9ae644f501f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ed7fb74e-b24b-4f66-9da9-30866c3f748a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5dd39f94-135e-426e-ae47-65a9b137a016
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 21bb3a90-62c9-434a-8546-28d1718ea74d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8f0022db-70f9-4145-a8ae-f8b4bb776c11
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 97c5147b-92e9-4622-a18b-c80e7afc3dea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 92c596ba-0305-42b4-a3ca-95889f72fbe3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 33950085-fe16-4f44-82df-0f5db13a9da9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 486b0b5b-8300-428a-9646-cd58bf08187a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3394d36e-8989-4f63-aa4f-a5df3009fe06
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0f06dfbe-8607-4c54-aad0-6aee52c59e6a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a5689dfe-380f-4a28-997a-c1faae30a86f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ce5ef3f5-0923-47e0-97f1-7416d8b05e04
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 565d785a-2c41-46d5-bbb9-cccdf8562c30
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a2e65e81-cf65-4468-826e-8fc5b8de711a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5d828f3a-baf1-44b2-ae29-aff29a088d18
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9f34bab4-adb1-4986-8fa9-548dc6a33d3a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0c92bf69-608b-4b8f-a669-39cd162ef25d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4dfc0b19-653c-4fac-bf22-c8dbfb066c27
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b4d81c4e-d056-4229-b878-2a12db0d8a38
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7ba7bd7e-dd64-4171-a657-e3456f6a1612
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c781cbab-579b-49c0-96dc-75c628f768dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8215bca3-3dab-4e58-b4b0-60059a1237e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ae14a280-aa85-4345-aaa7-8f06a31ee950
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 77839759-7442-4ac3-817f-8f6b984690cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 75d571a2-cf52-4b85-b359-f7dceca1a857
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5b76ac28-3d3e-4de8-8bee-fb175425bb56
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 86f6fa2d-64a5-4c6b-820b-5ed4591f2587
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dc854a5a-3854-4ffc-ab9a-92a8a149e1fb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cb08de6d-cf8b-45d7-a778-a79c1af065dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b73d45ff-8ef4-467f-9806-a3c2946aac75
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5f75116e-7bab-44ab-aaaa-2cbd20ae49cb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8a376264-a471-4e27-9b09-a6c4cf37d07d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 87e500ed-e405-4e0c-a34d-c066747f248d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ec02fd6c-2e5a-4a6d-8020-8194177265e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1e973cf9-e02a-4cb7-bbee-2fd725bda8e8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d2c2715f-dc09-4f5c-ad79-80b79a2cde31
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4e986377-e3cb-4e7d-a9ab-f12e29ca2470
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4edf39d7-f2f4-4464-a296-5ae2a6fc175c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3ee577fb-3692-4e5c-b66d-be2368c90da6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message da401e18-3d9c-4c92-96ef-86c306f6d037
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7079a9de-b34a-4314-9f44-edbbb3b89f58
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 63c64d3f-adf6-4308-a077-9165cf34aee1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d9d6d88d-6716-4858-b353-d39838f8332e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 085c51f2-090e-4ef6-9e28-635a2f2edf17
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e911588f-20c4-4731-bca8-825efcfc6901
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d163c2be-323a-49fe-9d9c-4b19467fad4f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 69c552af-7add-40f6-965d-5df181e87404
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d6e362f8-4a66-4a40-9698-8c497ce32a2c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 69ff2b7a-8dc3-4390-ab3c-e611d5e2672a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3c5840e7-92b5-4329-974b-7d748511380e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 113aba63-8735-43ad-8def-bfb39d786677
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 86aed7c9-4c8b-4d55-a1ab-f1f980734daa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c9ec0507-9a59-493b-9551-a98f5371e83f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e03ddb79-e3ad-4038-908b-e6d846089850
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 712afd90-4bfe-453a-ab43-2560e5adc835
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b7a20c64-589e-4920-b0e7-17fd42fb108e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c8a5144d-0fc0-465f-91ea-0ff134f329db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4d0cef7f-14a8-4b27-9e34-cb9f3d0a6f1a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5ff243a5-e519-4789-a7d5-c2dd68d4683d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 72ddcde7-fdbf-408e-bb45-de0e05a0f4ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6a204182-259c-4030-9e58-b83b53b8f27b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bc05d910-f652-4213-8635-b21a58f9cdaa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 179eea7a-9bcd-49d1-b51d-e5147439b15a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 96e00dd5-5ff5-4bb0-9cf0-31add3a3b2f2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 73fa91fb-13ca-4251-8159-fde09534591b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d0a04966-1d2b-468f-8dbe-122e34ddc6fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3aae6867-b11b-4563-a40f-120d76751b2a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e0852d9c-6974-43eb-a238-c4111e6239fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0aed4254-a176-4cf1-b55e-fc486a627d31
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f0562e84-e129-44f9-ac1d-722b829ebfb9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3bd3f64f-327c-427a-8662-5631f14a31cb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 68ab9cfd-c080-4bda-a40e-c974eedf6c10
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c21601ca-a4b8-4550-b591-dc72829c8eb7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9722977c-b1ff-4a3f-b67f-5466ac2d22b8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 38593b88-d269-455f-bbd2-bf0f37cb9b2d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 62ce8180-b40b-4a66-bf49-2c2fd153258c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 25a95c5e-60c5-4576-a405-d2ac35a40818
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 07d1c56d-936d-4cfe-9f5e-bafc9733d8c5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5515488e-bfb7-4753-b026-df9768517ce8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 026a3f10-8995-4aff-b4d9-b7580946e740
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 11e6aea8-ce04-4d77-b18e-0f16ffbd7db0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d3926cc8-dbc6-4205-887a-0b3ef0bc4d66
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1e2b08aa-cbf7-45ce-ac06-4d4d16a195da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e4ed1326-bc15-4588-86f6-7ea9cc19255d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8fbd9ede-049a-4547-958f-8bd2a792a5cb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3b4c9789-06d1-46fb-9ef0-925997002741
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 38745d0c-343a-4655-828a-0fa3fc80fc10
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6be99511-2136-465e-8eea-d07c9dd0128b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7ae0cf2c-37ff-4c1a-825e-80511b12a321
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aaeaf442-9f71-4e14-9c4a-1152d548b541
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4baadcfa-f1cf-4f2c-b391-d9912030218f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4f4c1d76-8241-40cb-8dd7-41f135836bce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3f9b10ca-6f03-4294-bc45-16d6c323a0fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8a19b948-c906-4969-a630-c8290af2fce6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 41bc74f0-7b07-4e3c-ad88-fc5ad64ec59e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 90a1477d-25f0-4004-8448-707988da997a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b37e648c-1645-45bf-9bb2-74387d1201c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d8dbd8ca-7dfc-4b97-81f6-a93a867020f8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 42ac3325-031c-4c39-945d-70cbb6475900
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dc9e4e12-d29d-47a8-aa0b-2e087bccc23b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 823be84e-b078-4085-a0d8-c5de7fc09542
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b1329846-6677-42e8-8200-92815cb2d771
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 98a8663f-4304-4834-872f-b24dbd7a9bb6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9d71e881-406b-4f42-bd4c-6054fb5800cd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f27daa8e-e3ed-4169-ac6c-a77b813ce88b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6921cfe8-044b-4b0d-b0a0-eb5d26bc9cc2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f7568261-48ae-4852-bdc7-9fa4fdffa282
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 67919970-b4bc-4918-b7df-d4adadbc5dac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3d5f4079-75b4-4cf5-873a-b6dae0ccc1af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 34785fc9-f2af-452c-880a-0b692037f52d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0c4a75c1-8454-4248-9398-a443058044f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2f16085c-9746-4366-84c0-5f98666a7c00
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e6d2f464-4e1b-42aa-b0e2-a4e1471f3bc7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 58f876e0-7957-45a2-88dc-d1ce42f9ea5c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6ef471f5-e34c-49f7-9987-33ebc7543edf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cf32c77a-ca0d-465f-9520-cf773e64ee91
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8cdee0a5-95b8-488d-9383-ea2400829fdf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 24937c43-fac1-4292-8c09-f9a06552edc4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f7e4ab4a-b01b-44c2-aa1d-44464f35b094
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 76f67784-b0e0-4d9b-8f9f-775251a3e687
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 419f7e75-4fa6-495e-92f4-167ff25b9e11
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cc203293-7a0a-4592-9ddf-84e9220fecc5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 06565f37-8791-4258-9b7a-f41e522f70f2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 620c9523-4f75-4163-adce-795d9a50ee30
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8b6b9e8e-e190-4247-bc4b-2a1868db7b6c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 08e5babb-0714-4c2a-b714-a1a150a33c31
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 71a366ce-fa7e-46d5-aa0c-d1a2b0c02d9b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 41c94938-bfab-40f1-bbcb-250223fad411
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 16a9fcdb-d82c-45d8-b4d8-0973b349c053
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 80851dfe-b0d7-4e8b-ad82-4bf217a8d40d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c2140a0d-6b31-42b5-a414-1459e8bc3118
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 74e9675a-eaad-4722-bbfd-97f624d6f0c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a19b6a8a-b9ff-41d1-ac4f-e5ebd04c9560
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 55cc35e9-67f4-4110-8e6d-f37765e26816
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3ba6f6bd-9300-44a9-b3c8-b9d36dda1772
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 48f328af-0123-4715-a942-7265a1b0e35f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b5fb469b-f714-491c-a55e-a96092b13a9f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f5e8daf3-a9a2-42f7-afb2-3bd830cb27db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e6774cf5-2e39-4fa9-aa1e-ac7682fe9a97
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ef340945-bce3-4c7b-89cf-ae29f4f11cd7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 073bcbf2-4bb5-4ee6-87fb-99cd7d2657f3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cc27654c-7bf5-49a2-8ba4-76a95c10bef5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c62f7634-d376-4362-9163-4cae3dcc6f6a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 051c28e1-92b8-4f5d-8a16-ade06274a20a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 52f49d6a-4c5c-45da-a696-41a74991e5f4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 507e88f2-654f-4b97-852b-e0281f52aa7e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8c7fc668-d959-4935-b026-ee2ff09a8390
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c2fb2601-5e8a-4966-8a90-939750d1f783
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5908d33c-2f17-480c-bb33-760b634a1847
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0d1a58f5-46fb-4668-a00f-bbe5aa77937a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ee276f37-1f74-4989-bdcc-2323f552a2f8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dbaf046b-9446-4964-b12b-5f8073277a6a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c964cac0-71c8-491b-acf4-b240f336b4bc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2509c886-c3ae-44e8-bdac-5476007deac2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 67ff7a94-23ef-453f-a330-c2b6d95ee4d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cded8158-0e58-48fb-a6cb-85d342f8eb8c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c913afff-b538-48b3-bc5d-d1c6f755044d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c4051a51-77ff-45dc-9b0a-5733eeaa6707
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f460781b-90e4-4906-b75c-c93b46129693
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b4faef96-9dd5-4034-a660-3d061936ccd3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0b0c3e90-9f31-4e72-aaf8-b53266ff18e0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8989312d-358f-470d-8f41-2555f4ed2cad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0a5461ee-a4c9-43ba-b5dd-14698d354581
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 25f117f7-0388-4960-99f9-9517fac674cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3938c535-3664-4c8d-8165-97360c16b433
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 373f74e7-2905-44b0-b139-0288c163828a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0182761b-9e30-42df-ba37-7a424dddf6f7
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "recvmsg:Connection reset by peer"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8687 {grpc_message:"recvmsg:Connection reset by peer", grpc_status:14}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_40
Server: localhost:8687
Algorithm: FEDAVG
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_40
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_40/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_40/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_40/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_40/test_labels.txt

📊 Raw data loaded:
   Train: X=(1839, 24), y=(1839,)
   Test:  X=(460, 24), y=(460,)

⚠️  Limiting training data: 1839 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  451 samples, 5 features
✅ Client client_40 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

📊 Round 0 Test Metrics:
   Loss: 0.0901, RMSE: 0.3001, MAE: 0.2605, R²: 0.0013

📊 Round 0 Test Metrics:
   Loss: 0.0899, RMSE: 0.2999, MAE: 0.2603, R²: 0.0029

📊 Round 0 Test Metrics:
   Loss: 0.0895, RMSE: 0.2991, MAE: 0.2596, R²: 0.0078

📊 Round 0 Test Metrics:
   Loss: 0.0879, RMSE: 0.2965, MAE: 0.2572, R²: 0.0253

============================================================
🔄 Round 12 - Client client_40
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0772 (↓), lr=0.001000
   • Epoch   2/100: train=0.0785, val=0.0767, patience=1/15, lr=0.001000
   ✓ Epoch   3/100: train=0.0781, val=0.0762 (↓), lr=0.001000
   • Epoch   4/100: train=0.0771, val=0.0760, patience=1/15, lr=0.001000
   ✓ Epoch   5/100: train=0.0758, val=0.0756 (↓), lr=0.001000
   • Epoch  11/100: train=0.0710, val=0.0762, patience=4/15, lr=0.001000
   📉 Epoch 13: LR reduced 0.001000 → 0.000500
   📉 Epoch 21: LR reduced 0.000500 → 0.000250
   • Epoch  21/100: train=0.0632, val=0.0806, patience=14/15, lr=0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0749)

============================================================
📊 Round 12 Summary - Client client_40
   Epochs: 22/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0714, RMSE=0.2671, R²=0.1285
   Val:   Loss=0.0749, RMSE=0.2737, R²=0.0846
============================================================


📊 Round 12 Test Metrics:
   Loss: 0.0876, RMSE: 0.2960, MAE: 0.2567, R²: 0.0286

============================================================
🔄 Round 15 - Client client_40
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0748, val=0.0949 (↓), lr=0.000250
   ✓ Epoch   2/100: train=0.0738, val=0.0942 (↓), lr=0.000250
   • Epoch   3/100: train=0.0731, val=0.0938, patience=1/15, lr=0.000250
   ✓ Epoch   4/100: train=0.0725, val=0.0935 (↓), lr=0.000250
   • Epoch   5/100: train=0.0720, val=0.0935, patience=1/15, lr=0.000250
   📉 Epoch 7: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0703, val=0.0940, patience=7/15, lr=0.000125
   📉 Epoch 15: LR reduced 0.000125 → 0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0935)

============================================================
📊 Round 15 Summary - Client client_40
   Epochs: 19/100 (early stopped)
   LR: 0.000250 → 0.000063 (2 reductions)
   Train: Loss=0.0720, RMSE=0.2684, R²=0.0790
   Val:   Loss=0.0935, RMSE=0.3058, R²=0.0288
============================================================


📊 Round 15 Test Metrics:
   Loss: 0.0875, RMSE: 0.2958, MAE: 0.2565, R²: 0.0300

📊 Round 15 Test Metrics:
   Loss: 0.0875, RMSE: 0.2958, MAE: 0.2565, R²: 0.0297

============================================================
🔄 Round 19 - Client client_40
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0719 (↓), lr=0.000063
   • Epoch   2/100: train=0.0801, val=0.0717, patience=1/15, lr=0.000063
   • Epoch   3/100: train=0.0798, val=0.0716, patience=2/15, lr=0.000063
   • Epoch   4/100: train=0.0796, val=0.0715, patience=3/15, lr=0.000063
   • Epoch   5/100: train=0.0794, val=0.0714, patience=4/15, lr=0.000063
   • Epoch  11/100: train=0.0782, val=0.0712, patience=5/15, lr=0.000063
   ✓ Epoch  21/100: train=0.0771, val=0.0709 (↓), lr=0.000063
   • Epoch  31/100: train=0.0764, val=0.0708, patience=10/15, lr=0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0709)

============================================================
📊 Round 19 Summary - Client client_40
   Epochs: 36/100 (early stopped)
   LR: 0.000063 → 0.000063 (0 reductions)
   Train: Loss=0.0770, RMSE=0.2776, R²=0.0792
   Val:   Loss=0.0709, RMSE=0.2662, R²=0.0495
============================================================


============================================================
🔄 Round 20 - Client client_40
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0636 (↓), lr=0.000063
   • Epoch   2/100: train=0.0819, val=0.0641, patience=1/15, lr=0.000063
   • Epoch   3/100: train=0.0816, val=0.0643, patience=2/15, lr=0.000063
   • Epoch   4/100: train=0.0814, val=0.0641, patience=3/15, lr=0.000063
   • Epoch   5/100: train=0.0812, val=0.0639, patience=4/15, lr=0.000063
   • Epoch  11/100: train=0.0801, val=0.0630, patience=1/15, lr=0.000063
   • Epoch  21/100: train=0.0791, val=0.0623, patience=5/15, lr=0.000063
   • Epoch  31/100: train=0.0782, val=0.0620, patience=2/15, lr=0.000063
   • Epoch  41/100: train=0.0771, val=0.0617, patience=12/15, lr=0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0621)

============================================================
📊 Round 20 Summary - Client client_40
   Epochs: 44/100 (early stopped)
   LR: 0.000063 → 0.000063 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2801, R²=0.0838
   Val:   Loss=0.0621, RMSE=0.2492, R²=0.0544
============================================================


📊 Round 20 Test Metrics:
   Loss: 0.0875, RMSE: 0.2958, MAE: 0.2564, R²: 0.0297

============================================================
🔄 Round 23 - Client client_40
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0771, val=0.0845 (↓), lr=0.000063
   • Epoch   2/100: train=0.0768, val=0.0841, patience=1/15, lr=0.000063
   ✓ Epoch   3/100: train=0.0766, val=0.0840 (↓), lr=0.000063
   • Epoch   4/100: train=0.0764, val=0.0838, patience=1/15, lr=0.000063
   📉 Epoch 5: LR reduced 0.000063 → 0.000031
   • Epoch   5/100: train=0.0762, val=0.0837, patience=2/15, lr=0.000031
   • Epoch  11/100: train=0.0756, val=0.0833, patience=2/15, lr=0.000031
   📉 Epoch 13: LR reduced 0.000031 → 0.000016
   📉 Epoch 21: LR reduced 0.000016 → 0.000008
   • Epoch  21/100: train=0.0751, val=0.0831, patience=12/15, lr=0.000008

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 23 Summary - Client client_40
   Epochs: 24/100 (early stopped)
   LR: 0.000063 → 0.000008 (3 reductions)
   Train: Loss=0.0759, RMSE=0.2756, R²=0.0486
   Val:   Loss=0.0834, RMSE=0.2888, R²=0.0653
============================================================


============================================================
🔄 Round 25 - Client client_40
   Epochs: 100, Batch: 32, LR: 0.000008
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0774, val=0.0854 (↓), lr=0.000008
   • Epoch   2/100: train=0.0773, val=0.0852, patience=1/15, lr=0.000008
   • Epoch   3/100: train=0.0773, val=0.0851, patience=2/15, lr=0.000008
   • Epoch   4/100: train=0.0772, val=0.0850, patience=3/15, lr=0.000008
   📉 Epoch 5: LR reduced 0.000008 → 0.000004
   • Epoch   5/100: train=0.0772, val=0.0849, patience=4/15, lr=0.000004
   • Epoch  11/100: train=0.0770, val=0.0847, patience=5/15, lr=0.000004
   📉 Epoch 13: LR reduced 0.000004 → 0.000002
   📉 Epoch 21: LR reduced 0.000002 → 0.000001
   • Epoch  21/100: train=0.0769, val=0.0845, patience=15/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 25 Summary - Client client_40
   Epochs: 21/100 (early stopped)
   LR: 0.000008 → 0.000001 (3 reductions)
   Train: Loss=0.0769, RMSE=0.2774, R²=0.0406
   Val:   Loss=0.0848, RMSE=0.2913, R²=0.0400
============================================================


============================================================
🔄 Round 26 - Client client_40
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0770, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0770, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0769, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0769, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0769, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0768, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 26 Summary - Client client_40
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0771, RMSE=0.2776, R²=0.0294
   Val:   Loss=0.0861, RMSE=0.2934, R²=0.0607
============================================================


============================================================
🔄 Round 27 - Client client_40
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0776, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0776, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0776, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0775, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0775, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0775, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 27 Summary - Client client_40
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0775, RMSE=0.2784, R²=0.0403
   Val:   Loss=0.0842, RMSE=0.2902, R²=-0.0129
============================================================


============================================================
🔄 Round 28 - Client client_40
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0774, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0774, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0774, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0774, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0774, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0773, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 28 Summary - Client client_40
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0774, RMSE=0.2782, R²=0.0349
   Val:   Loss=0.0848, RMSE=0.2912, R²=0.0429
============================================================


============================================================
🔄 Round 29 - Client client_40
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0753 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0752, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0752, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0752, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0752, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0752, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0753)

============================================================
📊 Round 29 Summary - Client client_40
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2824, R²=0.0324
   Val:   Loss=0.0753, RMSE=0.2743, R²=0.0532
============================================================


📊 Round 29 Test Metrics:
   Loss: 0.0875, RMSE: 0.2958, MAE: 0.2564, R²: 0.0295

============================================================
🔄 Round 30 - Client client_40
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0779 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0779, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0779, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0778, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0778, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0777, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0779)

============================================================
📊 Round 30 Summary - Client client_40
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2813, R²=0.0332
   Val:   Loss=0.0779, RMSE=0.2791, R²=0.0292
============================================================


📊 Round 30 Test Metrics:
   Loss: 0.0875, RMSE: 0.2958, MAE: 0.2564, R²: 0.0295

📊 Round 30 Test Metrics:
   Loss: 0.0875, RMSE: 0.2958, MAE: 0.2564, R²: 0.0295

============================================================
🔄 Round 33 - Client client_40
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0778, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0778, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0778, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0778, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0778, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0777, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 33 Summary - Client client_40
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0778, RMSE=0.2789, R²=0.0404
   Val:   Loss=0.0832, RMSE=0.2885, R²=0.0225
============================================================


📊 Round 33 Test Metrics:
   Loss: 0.0875, RMSE: 0.2958, MAE: 0.2564, R²: 0.0295

============================================================
🔄 Round 34 - Client client_40
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0756 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0756, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0756, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0756, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0756, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0755, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0756)

============================================================
📊 Round 34 Summary - Client client_40
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=0.0319
   Val:   Loss=0.0756, RMSE=0.2750, R²=0.0553
============================================================


📊 Round 34 Test Metrics:
   Loss: 0.0875, RMSE: 0.2958, MAE: 0.2564, R²: 0.0295

============================================================
🔄 Round 36 - Client client_40
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0781, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0781, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0781, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0781, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0781, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0780, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 36 Summary - Client client_40
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0781, RMSE=0.2794, R²=0.0328
   Val:   Loss=0.0820, RMSE=0.2863, R²=0.0516
============================================================


📊 Round 36 Test Metrics:
   Loss: 0.0875, RMSE: 0.2958, MAE: 0.2564, R²: 0.0296

============================================================
🔄 Round 38 - Client client_40
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0748 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0748, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0748, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0748, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0748, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0747, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0748)

============================================================
📊 Round 38 Summary - Client client_40
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2826, R²=0.0392
   Val:   Loss=0.0748, RMSE=0.2735, R²=-0.0020
============================================================


📊 Round 38 Test Metrics:
   Loss: 0.0875, RMSE: 0.2958, MAE: 0.2564, R²: 0.0296

📊 Round 38 Test Metrics:
   Loss: 0.0875, RMSE: 0.2958, MAE: 0.2564, R²: 0.0296

============================================================
🔄 Round 42 - Client client_40
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 42 Summary - Client client_40
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2810, R²=0.0339
   Val:   Loss=0.0784, RMSE=0.2800, R²=0.0370
============================================================


📊 Round 42 Test Metrics:
   Loss: 0.0875, RMSE: 0.2958, MAE: 0.2564, R²: 0.0296

📊 Round 42 Test Metrics:
   Loss: 0.0875, RMSE: 0.2958, MAE: 0.2564, R²: 0.0296

============================================================
🔄 Round 45 - Client client_40
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 45 Summary - Client client_40
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2810, R²=0.0408
   Val:   Loss=0.0783, RMSE=0.2799, R²=0.0205
============================================================


============================================================
🔄 Round 46 - Client client_40
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0726 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0726, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0726, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0726, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0726, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0725, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0726)

============================================================
📊 Round 46 Summary - Client client_40
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=0.0352
   Val:   Loss=0.0726, RMSE=0.2695, R²=0.0436
============================================================


============================================================
🔄 Round 47 - Client client_40
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0782, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0782, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0782, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0781, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0781, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0781, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 47 Summary - Client client_40
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0781, RMSE=0.2796, R²=0.0333
   Val:   Loss=0.0817, RMSE=0.2858, R²=0.0490
============================================================


📊 Round 47 Test Metrics:
   Loss: 0.0875, RMSE: 0.2958, MAE: 0.2564, R²: 0.0296

📊 Round 47 Test Metrics:
   Loss: 0.0875, RMSE: 0.2958, MAE: 0.2564, R²: 0.0296

============================================================
🔄 Round 50 - Client client_40
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0717 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0717, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0717, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0717, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0717, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0717, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0717)

============================================================
📊 Round 50 Summary - Client client_40
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2840, R²=0.0350
   Val:   Loss=0.0717, RMSE=0.2679, R²=0.0435
============================================================


📊 Round 50 Test Metrics:
   Loss: 0.0875, RMSE: 0.2958, MAE: 0.2564, R²: 0.0296

============================================================
🔄 Round 52 - Client client_40
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0779, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0779, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0779, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0779, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0779, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0778, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 52 Summary - Client client_40
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0779, RMSE=0.2791, R²=0.0367
   Val:   Loss=0.0827, RMSE=0.2875, R²=0.0373
============================================================


📊 Round 52 Test Metrics:
   Loss: 0.0875, RMSE: 0.2958, MAE: 0.2564, R²: 0.0296

📊 Round 52 Test Metrics:
   Loss: 0.0875, RMSE: 0.2958, MAE: 0.2564, R²: 0.0296

============================================================
🔄 Round 54 - Client client_40
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0782, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 54 Summary - Client client_40
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2811, R²=0.0345
   Val:   Loss=0.0782, RMSE=0.2797, R²=0.0399
============================================================


📊 Round 54 Test Metrics:
   Loss: 0.0875, RMSE: 0.2958, MAE: 0.2564, R²: 0.0297

📊 Round 54 Test Metrics:
   Loss: 0.0875, RMSE: 0.2958, MAE: 0.2564, R²: 0.0297

============================================================
🔄 Round 58 - Client client_40
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0764 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0764, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0763, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0763, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0763, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0762, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0764)

============================================================
📊 Round 58 Summary - Client client_40
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2820, R²=0.0420
   Val:   Loss=0.0764, RMSE=0.2764, R²=0.0088
============================================================


📊 Round 58 Test Metrics:
   Loss: 0.0875, RMSE: 0.2958, MAE: 0.2564, R²: 0.0297

============================================================
🔄 Round 61 - Client client_40
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 61 Summary - Client client_40
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2804, R²=0.0356
   Val:   Loss=0.0798, RMSE=0.2825, R²=0.0287
============================================================


📊 Round 61 Test Metrics:
   Loss: 0.0875, RMSE: 0.2958, MAE: 0.2564, R²: 0.0297

============================================================
🔄 Round 64 - Client client_40
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0779 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0779, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0779, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0779, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0779, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0778, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0779)

============================================================
📊 Round 64 Summary - Client client_40
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2813, R²=0.0433
   Val:   Loss=0.0779, RMSE=0.2792, R²=0.0081
============================================================


📊 Round 64 Test Metrics:
   Loss: 0.0875, RMSE: 0.2958, MAE: 0.2564, R²: 0.0297

============================================================
🔄 Round 69 - Client client_40
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0764, val=0.0880 (↓), lr=0.000001
   • Epoch   2/100: train=0.0764, val=0.0880, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0764, val=0.0880, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0764, val=0.0880, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0764, val=0.0880, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0763, val=0.0880, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0880)

============================================================
📊 Round 69 Summary - Client client_40
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0766, RMSE=0.2767, R²=0.0461
   Val:   Loss=0.0880, RMSE=0.2967, R²=0.0026
============================================================


📊 Round 69 Test Metrics:
   Loss: 0.0875, RMSE: 0.2958, MAE: 0.2564, R²: 0.0297

============================================================
🔄 Round 70 - Client client_40
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0779, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0778, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0778, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0778, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0778, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0777, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 70 Summary - Client client_40
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0776, RMSE=0.2786, R²=0.0373
   Val:   Loss=0.0837, RMSE=0.2894, R²=0.0325
============================================================


📊 Round 70 Test Metrics:
   Loss: 0.0875, RMSE: 0.2958, MAE: 0.2564, R²: 0.0297

============================================================
🔄 Round 71 - Client client_40
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 71 Summary - Client client_40
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2806, R²=0.0322
   Val:   Loss=0.0792, RMSE=0.2815, R²=0.0463
============================================================


============================================================
🔄 Round 72 - Client client_40
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0721 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0721, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0721, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0720, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0720, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0720, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0721)

============================================================
📊 Round 72 Summary - Client client_40
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2838, R²=0.0363
   Val:   Loss=0.0721, RMSE=0.2685, R²=0.0384
============================================================


📊 Round 72 Test Metrics:
   Loss: 0.0875, RMSE: 0.2958, MAE: 0.2564, R²: 0.0297

============================================================
🔄 Round 78 - Client client_40
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0706 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0706, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0706, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0706, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0705, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0705, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0706)

============================================================
📊 Round 78 Summary - Client client_40
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=0.0358
   Val:   Loss=0.0706, RMSE=0.2657, R²=0.0416
============================================================


============================================================
🔄 Round 82 - Client client_40
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0779, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0779, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0779, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0779, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0779, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0779, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 82 Summary - Client client_40
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0777, RMSE=0.2787, R²=0.0388
   Val:   Loss=0.0834, RMSE=0.2889, R²=0.0061
============================================================


📊 Round 82 Test Metrics:
   Loss: 0.0875, RMSE: 0.2958, MAE: 0.2564, R²: 0.0297

📊 Round 82 Test Metrics:
   Loss: 0.0875, RMSE: 0.2958, MAE: 0.2564, R²: 0.0297

============================================================
🔄 Round 86 - Client client_40
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0787, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 86 Summary - Client client_40
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2806, R²=0.0386
   Val:   Loss=0.0794, RMSE=0.2818, R²=0.0271
============================================================


============================================================
🔄 Round 87 - Client client_40
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0779, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0779, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0779, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0779, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0779, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0778, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 87 Summary - Client client_40
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0778, RMSE=0.2789, R²=0.0365
   Val:   Loss=0.0830, RMSE=0.2882, R²=0.0339
============================================================


📊 Round 87 Test Metrics:
   Loss: 0.0875, RMSE: 0.2958, MAE: 0.2564, R²: 0.0298

============================================================
🔄 Round 89 - Client client_40
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0750 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0750, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0749, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0749, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0749, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0748, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0750)

============================================================
📊 Round 89 Summary - Client client_40
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=0.0335
   Val:   Loss=0.0750, RMSE=0.2738, R²=0.0253
============================================================


📊 Round 89 Test Metrics:
   Loss: 0.0875, RMSE: 0.2958, MAE: 0.2564, R²: 0.0298

============================================================
🔄 Round 93 - Client client_40
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0756 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0756, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0757, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0757, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0757, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0757, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0756)

============================================================
📊 Round 93 Summary - Client client_40
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2822, R²=0.0331
   Val:   Loss=0.0756, RMSE=0.2750, R²=0.0416
============================================================


📊 Round 93 Test Metrics:
   Loss: 0.0875, RMSE: 0.2958, MAE: 0.2564, R²: 0.0298

============================================================
🔄 Round 95 - Client client_40
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0783, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 95 Summary - Client client_40
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2804, R²=0.0356
   Val:   Loss=0.0799, RMSE=0.2826, R²=0.0397
============================================================


📊 Round 95 Test Metrics:
   Loss: 0.0875, RMSE: 0.2958, MAE: 0.2564, R²: 0.0298

📊 Round 95 Test Metrics:
   Loss: 0.0875, RMSE: 0.2958, MAE: 0.2564, R²: 0.0298

📊 Round 95 Test Metrics:
   Loss: 0.0875, RMSE: 0.2958, MAE: 0.2564, R²: 0.0298

📊 Round 95 Test Metrics:
   Loss: 0.0875, RMSE: 0.2958, MAE: 0.2564, R²: 0.0298

============================================================
🔄 Round 106 - Client client_40
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0771 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0771, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0770, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0770, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0770, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0770, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0771)

============================================================
📊 Round 106 Summary - Client client_40
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2816, R²=0.0341
   Val:   Loss=0.0771, RMSE=0.2776, R²=0.0478
============================================================


============================================================
🔄 Round 107 - Client client_40
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0780, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0780, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0780, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0780, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0780, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0779, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 107 Summary - Client client_40
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0782, RMSE=0.2797, R²=0.0420
   Val:   Loss=0.0812, RMSE=0.2850, R²=0.0174
============================================================


📊 Round 107 Test Metrics:
   Loss: 0.0875, RMSE: 0.2958, MAE: 0.2564, R²: 0.0298

📊 Round 107 Test Metrics:
   Loss: 0.0875, RMSE: 0.2958, MAE: 0.2564, R²: 0.0298

📊 Round 107 Test Metrics:
   Loss: 0.0875, RMSE: 0.2958, MAE: 0.2564, R²: 0.0299

📊 Round 107 Test Metrics:
   Loss: 0.0875, RMSE: 0.2958, MAE: 0.2564, R²: 0.0299

============================================================
🔄 Round 113 - Client client_40
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0634 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0634, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0634, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0634, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0634, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0634, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0634)

============================================================
📊 Round 113 Summary - Client client_40
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2875, R²=0.0337
   Val:   Loss=0.0634, RMSE=0.2519, R²=0.0472
============================================================


📊 Round 113 Test Metrics:
   Loss: 0.0875, RMSE: 0.2958, MAE: 0.2564, R²: 0.0299

============================================================
🔄 Round 115 - Client client_40
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0756 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0756, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0756, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0756, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0756, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0756, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0756)

============================================================
📊 Round 115 Summary - Client client_40
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2822, R²=0.0372
   Val:   Loss=0.0756, RMSE=0.2749, R²=0.0299
============================================================


📊 Round 115 Test Metrics:
   Loss: 0.0875, RMSE: 0.2958, MAE: 0.2564, R²: 0.0298

============================================================
🔄 Round 118 - Client client_40
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0785, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0785, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0785, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0785, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 118 Summary - Client client_40
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0783, RMSE=0.2799, R²=0.0403
   Val:   Loss=0.0809, RMSE=0.2843, R²=0.0241
============================================================


============================================================
🔄 Round 119 - Client client_40
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0763 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0762, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0762, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0762, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0762, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0761, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0763)

============================================================
📊 Round 119 Summary - Client client_40
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2819, R²=0.0397
   Val:   Loss=0.0763, RMSE=0.2761, R²=0.0248
============================================================


📊 Round 119 Test Metrics:
   Loss: 0.0875, RMSE: 0.2958, MAE: 0.2564, R²: 0.0298

============================================================
🔄 Round 121 - Client client_40
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 121 Summary - Client client_40
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2810, R²=0.0394
   Val:   Loss=0.0784, RMSE=0.2800, R²=0.0278
============================================================


📊 Round 121 Test Metrics:
   Loss: 0.0875, RMSE: 0.2958, MAE: 0.2564, R²: 0.0298

============================================================
🔄 Round 123 - Client client_40
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0779 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0779, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0779, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0779, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0779, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0779, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0779)

============================================================
📊 Round 123 Summary - Client client_40
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2811, R²=0.0388
   Val:   Loss=0.0779, RMSE=0.2792, R²=0.0303
============================================================


📊 Round 123 Test Metrics:
   Loss: 0.0875, RMSE: 0.2958, MAE: 0.2564, R²: 0.0299

📊 Round 123 Test Metrics:
   Loss: 0.0875, RMSE: 0.2958, MAE: 0.2564, R²: 0.0299

============================================================
🔄 Round 125 - Client client_40
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0785, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0785, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0785, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0785, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 125 Summary - Client client_40
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2800, R²=0.0352
   Val:   Loss=0.0806, RMSE=0.2839, R²=0.0440
============================================================


📊 Round 125 Test Metrics:
   Loss: 0.0875, RMSE: 0.2958, MAE: 0.2564, R²: 0.0299

============================================================
🔄 Round 126 - Client client_40
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0770 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0771, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0771, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0771, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0771, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0770)

============================================================
📊 Round 126 Summary - Client client_40
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2815, R²=0.0267
   Val:   Loss=0.0770, RMSE=0.2776, R²=0.0655
============================================================


📊 Round 126 Test Metrics:
   Loss: 0.0875, RMSE: 0.2958, MAE: 0.2564, R²: 0.0299

📊 Round 126 Test Metrics:
   Loss: 0.0875, RMSE: 0.2958, MAE: 0.2564, R²: 0.0299

============================================================
🔄 Round 130 - Client client_40
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 130 Summary - Client client_40
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2810, R²=0.0393
   Val:   Loss=0.0783, RMSE=0.2799, R²=0.0162
============================================================


============================================================
🔄 Round 131 - Client client_40
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0779 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0779, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0779, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0779, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0779, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0779, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0779)

============================================================
📊 Round 131 Summary - Client client_40
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2812, R²=0.0338
   Val:   Loss=0.0779, RMSE=0.2792, R²=0.0466
============================================================


============================================================
🔄 Round 132 - Client client_40
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0754 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0754, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0754, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0753, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0753, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0752, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0754)

============================================================
📊 Round 132 Summary - Client client_40
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=0.0398
   Val:   Loss=0.0754, RMSE=0.2746, R²=0.0133
============================================================


📊 Round 132 Test Metrics:
   Loss: 0.0875, RMSE: 0.2958, MAE: 0.2564, R²: 0.0300

📊 Round 132 Test Metrics:
   Loss: 0.0875, RMSE: 0.2958, MAE: 0.2564, R²: 0.0300

============================================================
🔄 Round 135 - Client client_40
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0694 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0694, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0694, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0694, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0694, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0694, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0694)

============================================================
📊 Round 135 Summary - Client client_40
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=0.0373
   Val:   Loss=0.0694, RMSE=0.2635, R²=0.0308
============================================================


============================================================
🔄 Round 136 - Client client_40
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0765 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0765, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0765, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0765, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0765, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0764, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0765)

============================================================
📊 Round 136 Summary - Client client_40
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2818, R²=0.0339
   Val:   Loss=0.0765, RMSE=0.2766, R²=0.0490
============================================================


============================================================
🔄 Round 138 - Client client_40
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0776, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0776, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0776, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0776, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0775, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0774, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 138 Summary - Client client_40
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0777, RMSE=0.2787, R²=0.0332
   Val:   Loss=0.0835, RMSE=0.2890, R²=0.0346
============================================================


📊 Round 138 Test Metrics:
   Loss: 0.0875, RMSE: 0.2958, MAE: 0.2564, R²: 0.0300

============================================================
🔄 Round 139 - Client client_40
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 139 Summary - Client client_40
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2809, R²=0.0350
   Val:   Loss=0.0787, RMSE=0.2806, R²=0.0412
============================================================


📊 Round 139 Test Metrics:
   Loss: 0.0875, RMSE: 0.2958, MAE: 0.2564, R²: 0.0300

============================================================
🔄 Round 141 - Client client_40
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0732 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0732, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0732, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0732, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0732, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0732, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0732)

============================================================
📊 Round 141 Summary - Client client_40
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2833, R²=0.0328
   Val:   Loss=0.0732, RMSE=0.2705, R²=0.0501
============================================================


📊 Round 141 Test Metrics:
   Loss: 0.0875, RMSE: 0.2958, MAE: 0.2564, R²: 0.0300

============================================================
🔄 Round 142 - Client client_40
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0780, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0779, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0779, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0779, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0779, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0778, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 142 Summary - Client client_40
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0781, RMSE=0.2794, R²=0.0415
   Val:   Loss=0.0820, RMSE=0.2863, R²=0.0191
============================================================


📊 Round 142 Test Metrics:
   Loss: 0.0875, RMSE: 0.2958, MAE: 0.2564, R²: 0.0300

📊 Round 142 Test Metrics:
   Loss: 0.0875, RMSE: 0.2958, MAE: 0.2564, R²: 0.0300

📊 Round 142 Test Metrics:
   Loss: 0.0875, RMSE: 0.2958, MAE: 0.2564, R²: 0.0300

============================================================
🔄 Round 146 - Client client_40
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0782, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0782, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0781, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0781, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0781, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0780, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 146 Summary - Client client_40
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0783, RMSE=0.2799, R²=0.0397
   Val:   Loss=0.0809, RMSE=0.2844, R²=0.0178
============================================================


📊 Round 146 Test Metrics:
   Loss: 0.0875, RMSE: 0.2958, MAE: 0.2564, R²: 0.0300

============================================================
🔄 Round 151 - Client client_40
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0782, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0782, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0782, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0782, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0782, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0781, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 151 Summary - Client client_40
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0783, RMSE=0.2798, R²=0.0389
   Val:   Loss=0.0811, RMSE=0.2848, R²=0.0275
============================================================


📊 Round 151 Test Metrics:
   Loss: 0.0875, RMSE: 0.2958, MAE: 0.2564, R²: 0.0300

📊 Round 151 Test Metrics:
   Loss: 0.0875, RMSE: 0.2958, MAE: 0.2564, R²: 0.0300

📊 Round 151 Test Metrics:
   Loss: 0.0875, RMSE: 0.2958, MAE: 0.2564, R²: 0.0300

============================================================
🔄 Round 158 - Client client_40
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0782, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0781, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0781, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0781, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0781, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0781, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 158 Summary - Client client_40
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0782, RMSE=0.2797, R²=0.0425
   Val:   Loss=0.0813, RMSE=0.2852, R²=-0.0233
============================================================


============================================================
🔄 Round 159 - Client client_40
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0748 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0748, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0748, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0748, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0748, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0748, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0748)

============================================================
📊 Round 159 Summary - Client client_40
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2826, R²=0.0373
   Val:   Loss=0.0748, RMSE=0.2736, R²=0.0348
============================================================


============================================================
🔄 Round 160 - Client client_40
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0723 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0723, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0723, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0723, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0723, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0722, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0723)

============================================================
📊 Round 160 Summary - Client client_40
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=0.0304
   Val:   Loss=0.0723, RMSE=0.2690, R²=0.0535
============================================================


📊 Round 160 Test Metrics:
   Loss: 0.0875, RMSE: 0.2958, MAE: 0.2564, R²: 0.0300

============================================================
🔄 Round 162 - Client client_40
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0750 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0750, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0750, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0750, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0749, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0748, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0750)

============================================================
📊 Round 162 Summary - Client client_40
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=0.0303
   Val:   Loss=0.0750, RMSE=0.2739, R²=0.0630
============================================================


============================================================
🔄 Round 163 - Client client_40
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 163 Summary - Client client_40
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2808, R²=0.0340
   Val:   Loss=0.0788, RMSE=0.2808, R²=0.0478
============================================================


============================================================
🔄 Round 164 - Client client_40
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0777, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0777, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0777, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0777, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0777, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0776, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 164 Summary - Client client_40
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0777, RMSE=0.2787, R²=0.0384
   Val:   Loss=0.0835, RMSE=0.2889, R²=0.0243
============================================================


============================================================
🔄 Round 165 - Client client_40
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0782, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0782, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0782, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0782, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0781, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0780, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 165 Summary - Client client_40
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0783, RMSE=0.2797, R²=0.0311
   Val:   Loss=0.0813, RMSE=0.2851, R²=0.0567
============================================================


📊 Round 165 Test Metrics:
   Loss: 0.0875, RMSE: 0.2958, MAE: 0.2564, R²: 0.0300

============================================================
🔄 Round 167 - Client client_40
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0757 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0757, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0757, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0757, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0756, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0755, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0757)

============================================================
📊 Round 167 Summary - Client client_40
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2822, R²=0.0380
   Val:   Loss=0.0757, RMSE=0.2752, R²=0.0142
============================================================


📊 Round 167 Test Metrics:
   Loss: 0.0875, RMSE: 0.2958, MAE: 0.2564, R²: 0.0300

============================================================
🔄 Round 168 - Client client_40
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0780, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0780, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0780, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0779, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0779, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0778, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 168 Summary - Client client_40
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0778, RMSE=0.2790, R²=0.0355
   Val:   Loss=0.0829, RMSE=0.2880, R²=0.0393
============================================================


📊 Round 168 Test Metrics:
   Loss: 0.0875, RMSE: 0.2958, MAE: 0.2564, R²: 0.0300

============================================================
🔄 Round 171 - Client client_40
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0780, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0780, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0779, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0779, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0779, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0778, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 171 Summary - Client client_40
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0780, RMSE=0.2793, R²=0.0313
   Val:   Loss=0.0824, RMSE=0.2870, R²=0.0494
============================================================


📊 Round 171 Test Metrics:
   Loss: 0.0875, RMSE: 0.2958, MAE: 0.2564, R²: 0.0300

============================================================
🔄 Round 175 - Client client_40
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0777, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0777, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0777, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0777, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0776, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0776, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 175 Summary - Client client_40
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0777, RMSE=0.2788, R²=0.0404
   Val:   Loss=0.0833, RMSE=0.2887, R²=0.0207
============================================================


📊 Round 175 Test Metrics:
   Loss: 0.0875, RMSE: 0.2958, MAE: 0.2564, R²: 0.0300

============================================================
🔄 Round 176 - Client client_40
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0738 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0738, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0738, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0738, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0738, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0738, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0738)

============================================================
📊 Round 176 Summary - Client client_40
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=0.0297
   Val:   Loss=0.0738, RMSE=0.2717, R²=0.0625
============================================================


📊 Round 176 Test Metrics:
   Loss: 0.0875, RMSE: 0.2958, MAE: 0.2564, R²: 0.0300

============================================================
🔄 Round 178 - Client client_40
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0769, val=0.0868 (↓), lr=0.000001
   • Epoch   2/100: train=0.0769, val=0.0868, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0769, val=0.0868, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0769, val=0.0868, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0769, val=0.0868, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0768, val=0.0867, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0868)

============================================================
📊 Round 178 Summary - Client client_40
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0769, RMSE=0.2773, R²=0.0289
   Val:   Loss=0.0868, RMSE=0.2946, R²=0.0636
============================================================


============================================================
🔄 Round 179 - Client client_40
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0775, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0775, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0774, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0774, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0774, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0773, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 179 Summary - Client client_40
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0777, RMSE=0.2787, R²=0.0306
   Val:   Loss=0.0836, RMSE=0.2892, R²=0.0593
============================================================


📊 Round 179 Test Metrics:
   Loss: 0.0875, RMSE: 0.2958, MAE: 0.2564, R²: 0.0300

============================================================
🔄 Round 182 - Client client_40
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 182 Summary - Client client_40
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2804, R²=0.0382
   Val:   Loss=0.0799, RMSE=0.2826, R²=0.0301
============================================================


============================================================
🔄 Round 183 - Client client_40
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0779 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0779, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0778, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0778, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0778, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0778, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0779)

============================================================
📊 Round 183 Summary - Client client_40
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2813, R²=0.0344
   Val:   Loss=0.0779, RMSE=0.2791, R²=0.0457
============================================================


📊 Round 183 Test Metrics:
   Loss: 0.0875, RMSE: 0.2958, MAE: 0.2564, R²: 0.0300

📊 Round 183 Test Metrics:
   Loss: 0.0875, RMSE: 0.2958, MAE: 0.2564, R²: 0.0301

============================================================
🔄 Round 192 - Client client_40
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 192 Summary - Client client_40
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2805, R²=0.0422
   Val:   Loss=0.0796, RMSE=0.2822, R²=0.0050
============================================================


============================================================
🔄 Round 193 - Client client_40
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0787, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0785, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 193 Summary - Client client_40
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2805, R²=0.0313
   Val:   Loss=0.0797, RMSE=0.2822, R²=0.0544
============================================================


============================================================
🔄 Round 194 - Client client_40
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0754 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0754, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0754, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0754, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0754, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0754, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0754)

============================================================
📊 Round 194 Summary - Client client_40
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2824, R²=0.0349
   Val:   Loss=0.0754, RMSE=0.2746, R²=0.0368
============================================================


📊 Round 194 Test Metrics:
   Loss: 0.0875, RMSE: 0.2957, MAE: 0.2564, R²: 0.0301

📊 Round 194 Test Metrics:
   Loss: 0.0875, RMSE: 0.2957, MAE: 0.2564, R²: 0.0301

📊 Round 194 Test Metrics:
   Loss: 0.0875, RMSE: 0.2957, MAE: 0.2564, R²: 0.0301

============================================================
🔄 Round 198 - Client client_40
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0758 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0758, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0758, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0758, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0758, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0759, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0758)

============================================================
📊 Round 198 Summary - Client client_40
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2822, R²=0.0347
   Val:   Loss=0.0758, RMSE=0.2753, R²=0.0284
============================================================


📊 Round 198 Test Metrics:
   Loss: 0.0875, RMSE: 0.2958, MAE: 0.2564, R²: 0.0301

============================================================
🔄 Round 199 - Client client_40
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0773, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 199 Summary - Client client_40
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2815, R²=0.0401
   Val:   Loss=0.0773, RMSE=0.2781, R²=0.0193
============================================================


📊 Round 199 Test Metrics:
   Loss: 0.0875, RMSE: 0.2958, MAE: 0.2564, R²: 0.0301

📊 Round 199 Test Metrics:
   Loss: 0.0875, RMSE: 0.2957, MAE: 0.2564, R²: 0.0301

📊 Round 199 Test Metrics:
   Loss: 0.0875, RMSE: 0.2957, MAE: 0.2564, R²: 0.0301

📊 Round 199 Test Metrics:
   Loss: 0.0875, RMSE: 0.2957, MAE: 0.2564, R²: 0.0301

📊 Round 199 Test Metrics:
   Loss: 0.0875, RMSE: 0.2957, MAE: 0.2564, R²: 0.0301

============================================================
🔄 Round 206 - Client client_40
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0747, val=0.0944 (↓), lr=0.000001
   • Epoch   2/100: train=0.0747, val=0.0944, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0747, val=0.0944, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0747, val=0.0944, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0747, val=0.0944, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0746, val=0.0943, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0944)

============================================================
📊 Round 206 Summary - Client client_40
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0750, RMSE=0.2739, R²=0.0388
   Val:   Loss=0.0944, RMSE=0.3073, R²=0.0170
============================================================


📊 Round 206 Test Metrics:
   Loss: 0.0875, RMSE: 0.2957, MAE: 0.2564, R²: 0.0301

============================================================
🔄 Round 207 - Client client_40
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0780 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0780, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0780, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0779, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0779, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0778, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 207 Summary - Client client_40
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2813, R²=0.0312
   Val:   Loss=0.0780, RMSE=0.2793, R²=0.0564
============================================================


============================================================
🔄 Round 208 - Client client_40
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0758, val=0.0907 (↓), lr=0.000001
   • Epoch   2/100: train=0.0758, val=0.0906, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0758, val=0.0906, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0758, val=0.0906, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0758, val=0.0906, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0758, val=0.0904, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0907)

============================================================
📊 Round 208 Summary - Client client_40
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0759, RMSE=0.2756, R²=0.0304
   Val:   Loss=0.0907, RMSE=0.3011, R²=0.0381
============================================================


============================================================
🔄 Round 209 - Client client_40
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0737 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0737, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0736, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0736, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0736, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0735, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0737)

============================================================
📊 Round 209 Summary - Client client_40
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=0.0380
   Val:   Loss=0.0737, RMSE=0.2714, R²=0.0161
============================================================


📊 Round 209 Test Metrics:
   Loss: 0.0875, RMSE: 0.2957, MAE: 0.2564, R²: 0.0301

📊 Round 209 Test Metrics:
   Loss: 0.0875, RMSE: 0.2957, MAE: 0.2564, R²: 0.0301

============================================================
🔄 Round 214 - Client client_40
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0767, val=0.0879 (↓), lr=0.000001
   • Epoch   2/100: train=0.0767, val=0.0879, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0767, val=0.0878, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0767, val=0.0878, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0767, val=0.0878, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0766, val=0.0877, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0879)

============================================================
📊 Round 214 Summary - Client client_40
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0766, RMSE=0.2768, R²=0.0339
   Val:   Loss=0.0879, RMSE=0.2964, R²=0.0457
============================================================


📊 Round 214 Test Metrics:
   Loss: 0.0875, RMSE: 0.2957, MAE: 0.2564, R²: 0.0301

============================================================
🔄 Round 215 - Client client_40
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0765, val=0.0878 (↓), lr=0.000001
   • Epoch   2/100: train=0.0765, val=0.0877, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0764, val=0.0877, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0764, val=0.0877, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0764, val=0.0877, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0763, val=0.0876, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0878)

============================================================
📊 Round 215 Summary - Client client_40
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0767, RMSE=0.2769, R²=0.0362
   Val:   Loss=0.0878, RMSE=0.2963, R²=0.0375
============================================================


📊 Round 215 Test Metrics:
   Loss: 0.0875, RMSE: 0.2957, MAE: 0.2564, R²: 0.0301

============================================================
🔄 Round 219 - Client client_40
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 219 Summary - Client client_40
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2807, R²=0.0364
   Val:   Loss=0.0792, RMSE=0.2814, R²=0.0201
============================================================


📊 Round 219 Test Metrics:
   Loss: 0.0875, RMSE: 0.2957, MAE: 0.2564, R²: 0.0301

============================================================
🔄 Round 220 - Client client_40
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0751 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0751, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0751, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0751, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0751, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0750, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0751)

============================================================
📊 Round 220 Summary - Client client_40
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=0.0336
   Val:   Loss=0.0751, RMSE=0.2741, R²=0.0488
============================================================


📊 Round 220 Test Metrics:
   Loss: 0.0875, RMSE: 0.2957, MAE: 0.2564, R²: 0.0301

============================================================
🔄 Round 222 - Client client_40
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0751 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0751, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0751, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0751, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0751, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0752, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0751)

============================================================
📊 Round 222 Summary - Client client_40
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=0.0248
   Val:   Loss=0.0751, RMSE=0.2740, R²=0.0632
============================================================


📊 Round 222 Test Metrics:
   Loss: 0.0875, RMSE: 0.2957, MAE: 0.2564, R²: 0.0301

📊 Round 222 Test Metrics:
   Loss: 0.0875, RMSE: 0.2957, MAE: 0.2564, R²: 0.0301

============================================================
🔄 Round 224 - Client client_40
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0787, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0785, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 224 Summary - Client client_40
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2807, R²=0.0277
   Val:   Loss=0.0791, RMSE=0.2813, R²=0.0503
============================================================


============================================================
🔄 Round 225 - Client client_40
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0738 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0738, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0738, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0738, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0738, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0738, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0738)

============================================================
📊 Round 225 Summary - Client client_40
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2831, R²=0.0253
   Val:   Loss=0.0738, RMSE=0.2717, R²=0.0776
============================================================


❌ Client client_40 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "recvmsg:Connection reset by peer"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8687 {grpc_message:"recvmsg:Connection reset by peer", grpc_status:14}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "recvmsg:Connection reset by peer"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8687 {grpc_message:"recvmsg:Connection reset by peer", grpc_status:14}"
>
