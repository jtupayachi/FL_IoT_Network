[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ae46ddb5-88f0-497e-a0fa-a1e31c750bf5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ecd26332-f5af-4cb1-8b18-c5ad26b8c165
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 79aed2fd-c6be-4f95-b4d6-e92bd3bad9fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 98cea010-42d7-47ba-93ca-668e1cee040c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f3912ddd-3257-4ad7-ae85-8e04423b61ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d59ea0a8-b672-4858-bc4b-947c52b98095
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 721ec363-fe86-4d0a-90b5-d7591695508a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 09ccc06a-46ee-4f3d-8cea-25ba8b894a90
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4334d398-17bf-455a-bb84-f00d371330e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dfcbff06-4470-4a19-a67e-6353d9e4d5b5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 071bc3f0-b1bd-473d-99a3-50a8eee8f010
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 30240f24-bff2-4f2c-8cdf-b64fefb6ba5e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e5d25d26-7696-4368-aa99-c26e39f12dbe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 079f9fef-48c7-429e-80d2-104f7f971f10
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8ac241b7-4e75-4064-9fe6-00d189eb4951
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 349bd848-60b1-433c-b29f-9703f9a4e02f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message df498a6f-6935-4d25-8e39-7c1c31e574fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1dde40ef-257d-416a-b01a-7e685622b282
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9b81f84e-ebde-4ec8-8531-0fec9154d52a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f5212e69-1b28-48f1-88c8-f4db82731bc6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 14cade1b-96e4-42e1-9043-d78e85a95b67
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 078ece93-8bfc-4325-834b-112145ace434
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1dfdebf4-1d86-4df4-8bef-2096cc20aadf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9ca70436-de75-4ffd-9c54-492323766e6a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 49ebac4d-e69f-4b7a-b971-068b1844d793
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7d963204-3c1e-44d8-b38b-10b4ca671357
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5ea75248-6a37-4de3-a20c-6d503ef252c4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 87cd1ba7-edf0-414a-ac35-950385734bdf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 929dc89f-2058-4f03-ae5a-d736fd42a5ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6a1007a6-3e82-4505-8080-b5eed1ff13b5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 248b1c11-0560-4902-92b2-d2816fc20f46
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 58c0fe65-be5d-41a9-8cb6-5aaaa5974661
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 649a2346-958e-4cdf-8ba9-3509b29e6561
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3425e72a-93a5-4623-9a00-1f96800aa9a9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5deff1fd-0945-4894-9551-dcb9e01b2ee3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bd02fef8-9864-41b7-84cb-5764fa2ba373
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bb5b9007-d887-4f15-a404-39806ad32155
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 181f48b6-20eb-40d0-9da5-34e75ba4b4b9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a952c1e6-74ca-4e0b-87c9-e11eabaf04de
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4a2c4bf6-bd96-42a9-9e83-49ab74f348cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d785f40d-666d-4b31-b1f8-f5f500c120e5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6d506bbd-5c85-4bbf-be99-8cf0fe422adf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2a0e4fa6-a2a3-43f1-a628-1def053098fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 82521f90-7ceb-48e8-b088-25581142a142
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ab7e355d-e965-49af-a219-cc8160e6ae43
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5b6c0953-e91d-482a-9a3a-d1f764e344b7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 680e8ae7-70f6-4240-b240-c038f0d2e05f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e7103786-5369-42e9-9cf2-4f20d698c479
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3d0c2572-1567-47dc-88bf-300d7d8c5f24
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 34620b82-3068-4a9e-af12-c8b875ead9d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bc8ad1e2-51f5-4d0e-a03f-bed9c8ac3648
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b99e0bdc-5e93-442a-9908-6a00b14baa43
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7ab47a98-7362-4054-a08e-83f7bfbf4521
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f70c4477-b712-44ec-b913-8f5d327a5374
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 168c1f50-d79d-4db8-8c41-b1c947a25fd3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6b7724a2-ca35-496f-b6ab-d88e5e210b10
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message baa8039d-81e7-4dc9-8c78-2686b8ea1d0e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8e6cc9c2-6444-4caa-9775-9604566d04b5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c8ec24b9-d34f-4ccd-bc53-696fa27ed3d8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8adcc817-74a0-49d1-ac58-13fcd7ebf99b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 01ad2055-b683-45d6-aa73-9ec4c0ad049b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b3af4e90-aac5-45ae-b7a5-e471a50f9fdf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4e52ac2e-5a01-46a0-af0d-f0c9f22b5af8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 51d04139-14ca-4bf6-8960-bfebfc89ed75
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 03d88fb8-7969-47e3-9b62-cfe21baf2144
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fce937a1-9ac8-4219-b10c-41e5be0497ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dc6fe069-d9d3-45de-84a7-3e982d644060
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cf47f4d0-fef8-43e9-8712-250b0fbebf6f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fcfb649b-de69-4fc2-89ad-2e3176b0bd03
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 269401ba-89fb-4cea-bb2a-d00ee20ad7b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cc168b6e-cc4e-44e4-bb34-8ca77a23153b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 14ddf2b1-9042-4c38-bc60-827508aa7591
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5a81e7bd-e0d9-4f87-91c4-d104ebd2b369
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d5384183-b872-4b3c-a8dd-70da2070da94
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6fd64abd-cd88-46ea-b0f9-8580388422e1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9682545f-e7f5-42e0-a13d-9f4b24ae187d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dda3bc1f-2140-443b-8eb5-d4df64d70f50
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 194f21bc-0ef2-4de4-bf62-7226b9fdaa44
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1e8d1312-0c1a-48f7-95c8-8c1ad80ff7ea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bd7eb39b-470f-44fc-a0ce-164e42d5b37e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8cf7196d-0ff0-49d0-abd7-58ecd915819c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2995f495-70cf-4df1-a72d-45b9b8281d95
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 590045f0-2d46-4c4c-9c03-33f43f03e34c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4d8d683b-7171-4a0e-93a2-a1a797529780
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a5f1251e-fae5-4b0e-83f7-4039d1ae50ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a19526cc-06ea-4c24-99d9-7eda2fc58703
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a2a66132-ca4a-467e-823f-0fb9ebea77db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 443e3877-dd61-45a8-84bf-00cff8e8a70b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dda40cc3-e401-4c69-8a5e-28ab65ad0e26
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5a7a9e41-4081-499b-8c33-96ed7ae82978
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dddaded4-4e4b-4999-a659-7f576012ab6e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fa8aadf5-f213-4011-bd6e-9cf6a9d40ca3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3df27239-7440-4ff3-a9e4-557d6cf4647d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 87542efe-2e0f-4d97-aba6-fbbb114eacf3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cf462a9f-70cf-4aca-afd9-97fabc846814
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 945d2e97-86c3-4de9-8f1a-73169bd5bafc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 64c74d4b-e152-4028-a5ed-e88e19185034
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 445f0496-2e40-4a40-9e34-76d121a71e21
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message be193ba3-f24a-4367-8656-ff651a248879
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 440a524b-9981-48c5-a55d-0643c7dc0049
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cf22d2ef-9490-4098-b5b6-79b3ad444c9d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 83e4f158-3284-4acb-ae7a-28568cf32292
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 58276544-ee7a-4c8a-a1f2-b49044bbf8fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 78819a0b-6208-4898-8758-2c30737209ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 43d0e8f8-968a-498d-96f1-67d721b4ea76
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message deb1c5bc-87f7-4e88-9d9c-4546adc9874b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3608cc4c-9cda-4a16-a265-4fc48150ba06
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 47565b9f-2f3e-4a49-9e82-501e6054de48
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a4d960e1-2b16-4154-a5b9-c96b9d8cf4ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a2f0ccad-ebdc-443f-b26e-a75a470ca353
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c0205984-d463-43dd-b9ae-4ac9f515a736
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c5a0cc56-a037-4888-9c1d-a4b4645c815f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 60f4332a-0b0c-410a-9d93-2b5edf693a6a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5902ee74-137b-4976-8845-269aca539ba4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b472f146-a0e0-4f87-99e4-52d1f4e66727
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 08405e9e-51f9-4ce9-b4b7-2fee125825d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9062fd46-a1cf-4db4-8c3f-705c06fb64d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 96b225be-e87b-4c75-b138-60e101caa42e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 05faa2d3-8d48-4cbb-944f-4cdd59f00c86
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message abdbb5c9-0d9a-4860-91fc-a0440951466a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bae78429-90a8-4f7e-a38a-cc661b9696a7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 60b8da07-d813-47e3-8682-26d3e57d689d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message be595f8c-b8f5-4524-b6f0-31d39b9f6ded
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 97006267-a824-44b8-8d1f-ba025a09a943
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 99a064a2-8f85-46dc-9947-5ccf6d30e299
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 095f5992-f35d-4095-822c-a882c5cbb293
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d938e6b8-b8f9-4e1f-aee6-1b5c941d1de9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5e300cce-90c0-463b-9429-bf6d97265468
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d0f015eb-4e22-4c32-92ed-530aa7cf7aa0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7ab8f045-cecf-41ea-b3b7-ff3b21e5edb8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 12a80975-ebc0-47a3-b6ae-73633296e768
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0d4d98d8-973d-4be1-a9ef-d8a79f5af398
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 536b78d9-b0cb-4164-80c1-fbb63b2673cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 90719b1b-657e-4d73-9a18-43ac6b959670
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 666e1666-916c-455b-b3fd-a6d9e513e788
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4c8db29d-4119-4eb5-8281-b0b2fb60fccb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e07b6df5-2351-4636-bbf6-723e88faee1e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 56b85ff4-8361-408b-96b7-26fa9262b0b5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 63146965-f6a8-45cf-b64b-6bad6567afd7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ab24ec82-9fe9-4210-b374-8e63b727d2e9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9558080c-5fb5-4133-a6f1-62d7fe506ce3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6b818eb0-2268-4f87-b0b8-252dcaab4c85
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 091ed56a-4183-48f1-8517-f7e8a74bc26e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0d312b35-0715-4d57-8421-5265acdb7f43
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fcaaf326-aaf1-40e9-a3c3-c55de23be959
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c930d673-2f50-4fd0-aef3-143f8bd349e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 79a3ddba-5c5b-4142-b992-6ce2d0a0ee8c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6b4d4d41-7fce-44e1-92b7-1a8d93680444
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 886e0a72-5fb9-44dd-a9e0-b9f94ce3bef1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2dda249f-5e42-418f-9a25-adfb7977b24c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 03a59eca-5584-4016-a9c8-65a61dd74747
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b9419e33-b88e-425c-907a-11de782c0483
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 682c6499-6611-4672-92f0-009e3df40f57
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a6f89c6b-38fd-4f42-baae-c1e03bc89dd8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e2b461e4-bd8e-4c3c-b495-cdc04d0a0a24
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0ab2e049-3ccf-41c5-aaf4-6e2cc556f9fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 71c70e72-94b4-4227-acca-0f25d929d0e1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 530e50bf-a509-457c-ac67-510323ec639c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 17001635-6aa2-4309-a695-001d6ed2a3bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5ef77ada-45cb-4beb-9e89-ab5da7100ec2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ceedc15e-d74f-4a4e-8295-48abcc6122d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aff08191-a10d-4feb-8f5f-ccb2f539d125
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9c48bda1-2881-4a05-a7b5-f4567d3d54ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 960a9e92-f45b-43eb-82c4-daf0a13d890d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bfaf2228-2a44-49f6-8fcf-7dfeb4bfda23
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 40200687-7787-400d-8b04-1e45b465ba05
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4e366f73-4634-4ea9-814f-7b4057485c99
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8748110d-4c7c-4f36-a514-5d8f969e3d9a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 961fb762-1a34-422a-8042-df80308e9360
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5c312986-1623-4a46-90d9-9854a6fbf3be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 089fcc89-5ed1-4cc4-8ebd-63fc3650dc28
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 17c1f1b7-3f8e-44ea-849a-b659fa2dc5bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 62a6a411-388f-454a-96b0-ca3be7f42667
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8e13b72c-a4a7-45bf-811b-5db994602707
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6b573dc0-4bf8-4e47-8209-c8aa3dba9c42
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f29b84e7-1d00-47de-9f44-0438bc311752
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8687 {grpc_message:"Socket closed", grpc_status:14}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_41
Server: localhost:8687
Algorithm: FEDAVG
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_41
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_41/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_41/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_41/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_41/test_labels.txt

📊 Raw data loaded:
   Train: X=(527, 24), y=(527,)
   Test:  X=(132, 24), y=(132,)

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 518 samples, 5 features
   Test:  123 samples, 5 features
✅ Client client_41 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

📊 Round 0 Test Metrics:
   Loss: 0.0795, RMSE: 0.2820, MAE: 0.2385, R²: -0.0223

============================================================
🔄 Round 8 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0913 (↓), lr=0.001000
   • Epoch   2/100: train=0.0831, val=0.0918, patience=1/15, lr=0.001000
   • Epoch   3/100: train=0.0824, val=0.0921, patience=2/15, lr=0.001000
   • Epoch   4/100: train=0.0819, val=0.0919, patience=3/15, lr=0.001000
   • Epoch   5/100: train=0.0816, val=0.0919, patience=4/15, lr=0.001000
   📉 Epoch 7: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0799, val=0.0921, patience=10/15, lr=0.000500
   📉 Epoch 15: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0913)

============================================================
📊 Round 8 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=-0.0066
   Val:   Loss=0.0913, RMSE=0.3022, R²=-0.0054
============================================================


============================================================
🔄 Round 9 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0916 (↓), lr=0.000250
   ✓ Epoch   2/100: train=0.0846, val=0.0909 (↓), lr=0.000250
   ✓ Epoch   3/100: train=0.0843, val=0.0902 (↓), lr=0.000250
   • Epoch   4/100: train=0.0840, val=0.0898, patience=1/15, lr=0.000250
   ✓ Epoch   5/100: train=0.0838, val=0.0895 (↓), lr=0.000250
   ✓ Epoch  11/100: train=0.0830, val=0.0884 (↓), lr=0.000250
   • Epoch  21/100: train=0.0821, val=0.0877, patience=4/15, lr=0.000250
   • Epoch  31/100: train=0.0812, val=0.0875, patience=14/15, lr=0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0879)

============================================================
📊 Round 9 Summary - Client client_41
   Epochs: 32/100 (early stopped)
   LR: 0.000250 → 0.000250 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=0.0107
   Val:   Loss=0.0879, RMSE=0.2965, R²=0.0037
============================================================


📊 Round 9 Test Metrics:
   Loss: 0.0795, RMSE: 0.2819, MAE: 0.2385, R²: -0.0214

📊 Round 9 Test Metrics:
   Loss: 0.0794, RMSE: 0.2818, MAE: 0.2385, R²: -0.0204

📊 Round 9 Test Metrics:
   Loss: 0.0793, RMSE: 0.2816, MAE: 0.2386, R²: -0.0191

============================================================
🔄 Round 12 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0897, val=0.0727 (↓), lr=0.000250
   • Epoch   2/100: train=0.0887, val=0.0733, patience=1/15, lr=0.000250
   • Epoch   3/100: train=0.0880, val=0.0731, patience=2/15, lr=0.000250
   • Epoch   4/100: train=0.0876, val=0.0731, patience=3/15, lr=0.000250
   • Epoch   5/100: train=0.0872, val=0.0732, patience=4/15, lr=0.000250
   📉 Epoch 7: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0862, val=0.0732, patience=10/15, lr=0.000125
   📉 Epoch 15: LR reduced 0.000125 → 0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0727)

============================================================
📊 Round 12 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000250 → 0.000063 (2 reductions)
   Train: Loss=0.0887, RMSE=0.2978, R²=-0.0176
   Val:   Loss=0.0727, RMSE=0.2696, R²=-0.0316
============================================================


📊 Round 12 Test Metrics:
   Loss: 0.0793, RMSE: 0.2816, MAE: 0.2387, R²: -0.0190

============================================================
🔄 Round 14 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0975 (↓), lr=0.000063
   • Epoch   2/100: train=0.0831, val=0.0975, patience=1/15, lr=0.000063
   • Epoch   3/100: train=0.0827, val=0.0975, patience=2/15, lr=0.000063
   • Epoch   4/100: train=0.0824, val=0.0975, patience=3/15, lr=0.000063
   • Epoch   5/100: train=0.0822, val=0.0975, patience=4/15, lr=0.000063
   📉 Epoch 7: LR reduced 0.000063 → 0.000031
   • Epoch  11/100: train=0.0814, val=0.0977, patience=10/15, lr=0.000031
   📉 Epoch 15: LR reduced 0.000031 → 0.000016

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0975)

============================================================
📊 Round 14 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000063 → 0.000016 (2 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=-0.0361
   Val:   Loss=0.0975, RMSE=0.3122, R²=0.0153
============================================================


============================================================
🔄 Round 15 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000016
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0875, val=0.0833 (↓), lr=0.000016
   • Epoch   2/100: train=0.0874, val=0.0832, patience=1/15, lr=0.000016
   • Epoch   3/100: train=0.0872, val=0.0831, patience=2/15, lr=0.000016
   • Epoch   4/100: train=0.0871, val=0.0830, patience=3/15, lr=0.000016
   • Epoch   5/100: train=0.0869, val=0.0830, patience=4/15, lr=0.000016
   📉 Epoch 7: LR reduced 0.000016 → 0.000008
   • Epoch  11/100: train=0.0866, val=0.0828, patience=2/15, lr=0.000008
   📉 Epoch 15: LR reduced 0.000008 → 0.000004
   • Epoch  21/100: train=0.0864, val=0.0826, patience=12/15, lr=0.000004
   📉 Epoch 23: LR reduced 0.000004 → 0.000002

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 15 Summary - Client client_41
   Epochs: 24/100 (early stopped)
   LR: 0.000016 → 0.000002 (3 reductions)
   Train: Loss=0.0866, RMSE=0.2943, R²=-0.0202
   Val:   Loss=0.0828, RMSE=0.2878, R²=-0.0226
============================================================


============================================================
🔄 Round 18 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000002
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0954 (↓), lr=0.000002
   • Epoch   2/100: train=0.0844, val=0.0954, patience=1/15, lr=0.000002
   • Epoch   3/100: train=0.0843, val=0.0954, patience=2/15, lr=0.000002
   • Epoch   4/100: train=0.0843, val=0.0954, patience=3/15, lr=0.000002
   • Epoch   5/100: train=0.0843, val=0.0954, patience=4/15, lr=0.000002
   📉 Epoch 7: LR reduced 0.000002 → 0.000001
   • Epoch  11/100: train=0.0842, val=0.0953, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0954)

============================================================
📊 Round 18 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000002 → 0.000001 (1 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=-0.0289
   Val:   Loss=0.0954, RMSE=0.3089, R²=-0.0371
============================================================


📊 Round 18 Test Metrics:
   Loss: 0.0794, RMSE: 0.2818, MAE: 0.2385, R²: -0.0209

📊 Round 18 Test Metrics:
   Loss: 0.0794, RMSE: 0.2819, MAE: 0.2384, R²: -0.0211

============================================================
🔄 Round 20 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0903 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0903, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0903, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0903, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0903, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0903, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0903)

============================================================
📊 Round 20 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2928, R²=-0.0314
   Val:   Loss=0.0903, RMSE=0.3005, R²=-0.0294
============================================================


📊 Round 20 Test Metrics:
   Loss: 0.0795, RMSE: 0.2819, MAE: 0.2383, R²: -0.0212

============================================================
🔄 Round 23 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0876, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0876, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0876, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0876, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0876, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0875, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 23 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0877, RMSE=0.2961, R²=-0.0278
   Val:   Loss=0.0832, RMSE=0.2885, R²=-0.0532
============================================================


============================================================
🔄 Round 25 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0877, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0877, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0876, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0876, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0876, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0876, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 25 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0877, RMSE=0.2961, R²=-0.0328
   Val:   Loss=0.0833, RMSE=0.2886, R²=-0.0354
============================================================


📊 Round 25 Test Metrics:
   Loss: 0.0795, RMSE: 0.2819, MAE: 0.2383, R²: -0.0211

============================================================
🔄 Round 26 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.1004 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.1004, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.1004, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.1004, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.1004, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.1004, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.1004)

============================================================
📊 Round 26 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=-0.0363
   Val:   Loss=0.1004, RMSE=0.3168, R²=-0.0287
============================================================


📊 Round 26 Test Metrics:
   Loss: 0.0794, RMSE: 0.2819, MAE: 0.2383, R²: -0.0211

📊 Round 26 Test Metrics:
   Loss: 0.0795, RMSE: 0.2819, MAE: 0.2383, R²: -0.0213

============================================================
🔄 Round 31 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0921 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0921, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0921, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0921, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0921, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0921, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0921)

============================================================
📊 Round 31 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2924, R²=-0.0351
   Val:   Loss=0.0921, RMSE=0.3036, R²=-0.0246
============================================================


📊 Round 31 Test Metrics:
   Loss: 0.0794, RMSE: 0.2819, MAE: 0.2383, R²: -0.0211

============================================================
🔄 Round 33 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0945 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0945, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0945, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0945, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0945, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0944, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0945)

============================================================
📊 Round 33 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=-0.0276
   Val:   Loss=0.0945, RMSE=0.3074, R²=-0.0607
============================================================


============================================================
🔄 Round 35 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0895, val=0.0760 (↓), lr=0.000001
   • Epoch   2/100: train=0.0895, val=0.0760, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0895, val=0.0760, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0895, val=0.0760, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0895, val=0.0760, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0894, val=0.0760, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0760)

============================================================
📊 Round 35 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0895, RMSE=0.2992, R²=-0.0314
   Val:   Loss=0.0760, RMSE=0.2757, R²=-0.0414
============================================================


📊 Round 35 Test Metrics:
   Loss: 0.0794, RMSE: 0.2819, MAE: 0.2383, R²: -0.0211

📊 Round 35 Test Metrics:
   Loss: 0.0794, RMSE: 0.2819, MAE: 0.2383, R²: -0.0211

============================================================
🔄 Round 38 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0950 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0950, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0950, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0950, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0950, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0949, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0950)

============================================================
📊 Round 38 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=-0.0305
   Val:   Loss=0.0950, RMSE=0.3083, R²=-0.0410
============================================================


📊 Round 38 Test Metrics:
   Loss: 0.0794, RMSE: 0.2819, MAE: 0.2383, R²: -0.0210

============================================================
🔄 Round 40 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0872, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0872, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0872, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0872, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0872, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0871, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 40 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0873, RMSE=0.2954, R²=-0.0357
   Val:   Loss=0.0851, RMSE=0.2917, R²=-0.0692
============================================================


📊 Round 40 Test Metrics:
   Loss: 0.0794, RMSE: 0.2818, MAE: 0.2383, R²: -0.0210

============================================================
🔄 Round 41 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0987 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0987, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0987, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0987, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0987, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0987, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0987)

============================================================
📊 Round 41 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2896, R²=-0.0323
   Val:   Loss=0.0987, RMSE=0.3142, R²=-0.0368
============================================================


📊 Round 41 Test Metrics:
   Loss: 0.0794, RMSE: 0.2818, MAE: 0.2383, R²: -0.0210

📊 Round 41 Test Metrics:
   Loss: 0.0794, RMSE: 0.2818, MAE: 0.2383, R²: -0.0209

============================================================
🔄 Round 46 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0879, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0879, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0879, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0879, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0879, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0878, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 46 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0879, RMSE=0.2965, R²=-0.0345
   Val:   Loss=0.0825, RMSE=0.2873, R²=-0.0277
============================================================


============================================================
🔄 Round 48 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0902, val=0.0732 (↓), lr=0.000001
   • Epoch   2/100: train=0.0902, val=0.0732, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0902, val=0.0732, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0902, val=0.0732, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0902, val=0.0732, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0901, val=0.0731, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0732)

============================================================
📊 Round 48 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0902, RMSE=0.3004, R²=-0.0359
   Val:   Loss=0.0732, RMSE=0.2705, R²=-0.0155
============================================================


📊 Round 48 Test Metrics:
   Loss: 0.0794, RMSE: 0.2818, MAE: 0.2383, R²: -0.0210

📊 Round 48 Test Metrics:
   Loss: 0.0794, RMSE: 0.2818, MAE: 0.2383, R²: -0.0209

============================================================
🔄 Round 51 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0902, val=0.0735 (↓), lr=0.000001
   • Epoch   2/100: train=0.0902, val=0.0735, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0902, val=0.0735, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0902, val=0.0734, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0902, val=0.0734, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0901, val=0.0734, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0735)

============================================================
📊 Round 51 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0902, RMSE=0.3003, R²=-0.0276
   Val:   Loss=0.0735, RMSE=0.2711, R²=-0.0572
============================================================


📊 Round 51 Test Metrics:
   Loss: 0.0794, RMSE: 0.2818, MAE: 0.2383, R²: -0.0209

============================================================
🔄 Round 52 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0901 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0901, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0901, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0901, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0901, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0900, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0901)

============================================================
📊 Round 52 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2933, R²=-0.0329
   Val:   Loss=0.0901, RMSE=0.3001, R²=-0.0326
============================================================


📊 Round 52 Test Metrics:
   Loss: 0.0794, RMSE: 0.2818, MAE: 0.2383, R²: -0.0209

============================================================
🔄 Round 53 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0938 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0938, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0938, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0938, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0938, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0938, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0938)

============================================================
📊 Round 53 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2917, R²=-0.0346
   Val:   Loss=0.0938, RMSE=0.3063, R²=-0.0427
============================================================


📊 Round 53 Test Metrics:
   Loss: 0.0794, RMSE: 0.2819, MAE: 0.2383, R²: -0.0210

============================================================
🔄 Round 54 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0876, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0876, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0876, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0876, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0876, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0875, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 54 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0876, RMSE=0.2960, R²=-0.0352
   Val:   Loss=0.0838, RMSE=0.2895, R²=-0.0244
============================================================


============================================================
🔄 Round 55 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.1004 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.1004, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.1004, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.1004, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.1004, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.1004, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.1004)

============================================================
📊 Round 55 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=-0.0355
   Val:   Loss=0.1004, RMSE=0.3168, R²=-0.0307
============================================================


📊 Round 55 Test Metrics:
   Loss: 0.0794, RMSE: 0.2818, MAE: 0.2383, R²: -0.0210

📊 Round 55 Test Metrics:
   Loss: 0.0794, RMSE: 0.2819, MAE: 0.2383, R²: -0.0211

📊 Round 55 Test Metrics:
   Loss: 0.0794, RMSE: 0.2819, MAE: 0.2383, R²: -0.0210

============================================================
🔄 Round 62 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0877, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0877, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0877, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0877, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0877, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0877, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 62 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0877, RMSE=0.2961, R²=-0.0268
   Val:   Loss=0.0834, RMSE=0.2888, R²=-0.0568
============================================================


============================================================
🔄 Round 64 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0886, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0886, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0886, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0886, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0886, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0885, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 64 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0886, RMSE=0.2976, R²=-0.0351
   Val:   Loss=0.0798, RMSE=0.2825, R²=-0.0216
============================================================


📊 Round 64 Test Metrics:
   Loss: 0.0794, RMSE: 0.2818, MAE: 0.2383, R²: -0.0208

============================================================
🔄 Round 67 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0891, val=0.0776 (↓), lr=0.000001
   • Epoch   2/100: train=0.0891, val=0.0776, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0891, val=0.0776, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0891, val=0.0776, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0891, val=0.0776, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0890, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 67 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0891, RMSE=0.2985, R²=-0.0386
   Val:   Loss=0.0776, RMSE=0.2786, R²=-0.0104
============================================================


📊 Round 67 Test Metrics:
   Loss: 0.0794, RMSE: 0.2818, MAE: 0.2383, R²: -0.0208

============================================================
🔄 Round 68 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0869, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0869, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0869, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0869, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0869, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0868, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 68 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0870, RMSE=0.2949, R²=-0.0378
   Val:   Loss=0.0862, RMSE=0.2937, R²=-0.0824
============================================================


📊 Round 68 Test Metrics:
   Loss: 0.0794, RMSE: 0.2818, MAE: 0.2383, R²: -0.0207

============================================================
🔄 Round 69 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0888 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0888, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0888, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0888, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0888, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0888, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0888)

============================================================
📊 Round 69 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2938, R²=-0.0316
   Val:   Loss=0.0888, RMSE=0.2981, R²=-0.0357
============================================================


📊 Round 69 Test Metrics:
   Loss: 0.0794, RMSE: 0.2818, MAE: 0.2383, R²: -0.0207

============================================================
🔄 Round 73 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0892, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0892, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0892, val=0.0772, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0892, val=0.0772, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0892, val=0.0772, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0892, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 73 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0892, RMSE=0.2987, R²=-0.0331
   Val:   Loss=0.0773, RMSE=0.2780, R²=-0.0300
============================================================


📊 Round 73 Test Metrics:
   Loss: 0.0794, RMSE: 0.2818, MAE: 0.2383, R²: -0.0207

============================================================
🔄 Round 75 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0878, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0878, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0878, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0878, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0878, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0877, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 75 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0878, RMSE=0.2963, R²=-0.0365
   Val:   Loss=0.0830, RMSE=0.2881, R²=-0.0158
============================================================


📊 Round 75 Test Metrics:
   Loss: 0.0794, RMSE: 0.2818, MAE: 0.2383, R²: -0.0206

📊 Round 75 Test Metrics:
   Loss: 0.0794, RMSE: 0.2818, MAE: 0.2383, R²: -0.0206

============================================================
🔄 Round 79 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0886, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0886, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0886, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0886, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0886, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0885, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 79 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0886, RMSE=0.2977, R²=-0.0361
   Val:   Loss=0.0796, RMSE=0.2822, R²=-0.0167
============================================================


============================================================
🔄 Round 81 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0880 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0880, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0880, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0880, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0880, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0880, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0880)

============================================================
📊 Round 81 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2942, R²=-0.0284
   Val:   Loss=0.0880, RMSE=0.2966, R²=-0.0560
============================================================


📊 Round 81 Test Metrics:
   Loss: 0.0794, RMSE: 0.2818, MAE: 0.2382, R²: -0.0204

📊 Round 81 Test Metrics:
   Loss: 0.0794, RMSE: 0.2818, MAE: 0.2383, R²: -0.0206

📊 Round 81 Test Metrics:
   Loss: 0.0794, RMSE: 0.2818, MAE: 0.2382, R²: -0.0205

📊 Round 81 Test Metrics:
   Loss: 0.0794, RMSE: 0.2818, MAE: 0.2382, R²: -0.0205

============================================================
🔄 Round 86 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0873, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0873, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0873, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0873, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0873, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0872, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 86 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0873, RMSE=0.2955, R²=-0.0316
   Val:   Loss=0.0849, RMSE=0.2914, R²=-0.0372
============================================================


============================================================
🔄 Round 88 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0920 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0920, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0920, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0920, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0920, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0920, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0920)

============================================================
📊 Round 88 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2925, R²=-0.0372
   Val:   Loss=0.0920, RMSE=0.3034, R²=-0.0267
============================================================


📊 Round 88 Test Metrics:
   Loss: 0.0794, RMSE: 0.2818, MAE: 0.2382, R²: -0.0204

📊 Round 88 Test Metrics:
   Loss: 0.0794, RMSE: 0.2818, MAE: 0.2382, R²: -0.0204

============================================================
🔄 Round 96 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0943 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0943, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0943, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0943, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0943, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0943, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0943)

============================================================
📊 Round 96 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2915, R²=-0.0331
   Val:   Loss=0.0943, RMSE=0.3071, R²=-0.0313
============================================================


============================================================
🔄 Round 98 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0873, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0873, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0873, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0873, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0873, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0872, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 98 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0873, RMSE=0.2955, R²=-0.0242
   Val:   Loss=0.0849, RMSE=0.2914, R²=-0.0800
============================================================


📊 Round 98 Test Metrics:
   Loss: 0.0794, RMSE: 0.2817, MAE: 0.2382, R²: -0.0203

📊 Round 98 Test Metrics:
   Loss: 0.0794, RMSE: 0.2817, MAE: 0.2382, R²: -0.0203

============================================================
🔄 Round 102 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0922 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0922, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0922, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0922, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0922, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0921, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0922)

============================================================
📊 Round 102 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2924, R²=-0.0309
   Val:   Loss=0.0922, RMSE=0.3036, R²=-0.0388
============================================================


📊 Round 102 Test Metrics:
   Loss: 0.0794, RMSE: 0.2817, MAE: 0.2382, R²: -0.0202

📊 Round 102 Test Metrics:
   Loss: 0.0794, RMSE: 0.2817, MAE: 0.2382, R²: -0.0202

📊 Round 102 Test Metrics:
   Loss: 0.0794, RMSE: 0.2817, MAE: 0.2382, R²: -0.0202

============================================================
🔄 Round 106 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0906 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0906, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0906, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0906, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0906, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0906, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0906)

============================================================
📊 Round 106 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2931, R²=-0.0243
   Val:   Loss=0.0906, RMSE=0.3010, R²=-0.0663
============================================================


============================================================
🔄 Round 112 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0912 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0912, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0912, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0912, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0912, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0912, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0912)

============================================================
📊 Round 112 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2929, R²=-0.0339
   Val:   Loss=0.0912, RMSE=0.3020, R²=-0.0330
============================================================


============================================================
🔄 Round 116 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0904, val=0.0726 (↓), lr=0.000001
   • Epoch   2/100: train=0.0904, val=0.0726, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0903, val=0.0726, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0903, val=0.0726, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0903, val=0.0726, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0903, val=0.0726, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0726)

============================================================
📊 Round 116 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0904, RMSE=0.3007, R²=-0.0344
   Val:   Loss=0.0726, RMSE=0.2694, R²=-0.0616
============================================================


📊 Round 116 Test Metrics:
   Loss: 0.0794, RMSE: 0.2817, MAE: 0.2382, R²: -0.0200

============================================================
🔄 Round 120 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0878, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0878, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0878, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0877, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0877, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0877, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 120 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0877, RMSE=0.2962, R²=-0.0326
   Val:   Loss=0.0832, RMSE=0.2885, R²=-0.0365
============================================================


📊 Round 120 Test Metrics:
   Loss: 0.0794, RMSE: 0.2817, MAE: 0.2382, R²: -0.0200

============================================================
🔄 Round 122 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0872, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0872, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0872, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0872, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0871, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0871, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 122 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0872, RMSE=0.2953, R²=-0.0290
   Val:   Loss=0.0854, RMSE=0.2922, R²=-0.0475
============================================================


📊 Round 122 Test Metrics:
   Loss: 0.0794, RMSE: 0.2817, MAE: 0.2382, R²: -0.0200

📊 Round 122 Test Metrics:
   Loss: 0.0794, RMSE: 0.2817, MAE: 0.2382, R²: -0.0200

📊 Round 122 Test Metrics:
   Loss: 0.0794, RMSE: 0.2817, MAE: 0.2382, R²: -0.0200

============================================================
🔄 Round 126 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0925 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0925, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0925, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0925, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0925, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0924, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0925)

============================================================
📊 Round 126 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2923, R²=-0.0327
   Val:   Loss=0.0925, RMSE=0.3042, R²=-0.0328
============================================================


📊 Round 126 Test Metrics:
   Loss: 0.0794, RMSE: 0.2817, MAE: 0.2382, R²: -0.0200

📊 Round 126 Test Metrics:
   Loss: 0.0794, RMSE: 0.2817, MAE: 0.2382, R²: -0.0201

============================================================
🔄 Round 132 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0872, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0872, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0872, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0872, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0872, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0871, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 132 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0872, RMSE=0.2954, R²=-0.0337
   Val:   Loss=0.0853, RMSE=0.2921, R²=-0.0281
============================================================


📊 Round 132 Test Metrics:
   Loss: 0.0794, RMSE: 0.2817, MAE: 0.2382, R²: -0.0201

============================================================
🔄 Round 134 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0979 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0979, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0979, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0979, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0979, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0979, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0979)

============================================================
📊 Round 134 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=-0.0346
   Val:   Loss=0.0979, RMSE=0.3129, R²=-0.0328
============================================================


============================================================
🔄 Round 135 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0887, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0887, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0886, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0886, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0886, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0886, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 135 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0887, RMSE=0.2979, R²=-0.0368
   Val:   Loss=0.0793, RMSE=0.2817, R²=-0.0177
============================================================


📊 Round 135 Test Metrics:
   Loss: 0.0794, RMSE: 0.2817, MAE: 0.2382, R²: -0.0202

============================================================
🔄 Round 136 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0919 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0919, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0919, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0919, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0919, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0919, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0919)

============================================================
📊 Round 136 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2926, R²=-0.0315
   Val:   Loss=0.0919, RMSE=0.3032, R²=-0.0401
============================================================


📊 Round 136 Test Metrics:
   Loss: 0.0794, RMSE: 0.2817, MAE: 0.2382, R²: -0.0202

============================================================
🔄 Round 137 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0991 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0991, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0991, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0991, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0991, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0992, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0991)

============================================================
📊 Round 137 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=-0.0294
   Val:   Loss=0.0991, RMSE=0.3149, R²=-0.0648
============================================================


============================================================
🔄 Round 138 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0886, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0886, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0886, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0886, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0886, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0885, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 138 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0887, RMSE=0.2978, R²=-0.0394
   Val:   Loss=0.0796, RMSE=0.2821, R²=-0.0035
============================================================


📊 Round 138 Test Metrics:
   Loss: 0.0794, RMSE: 0.2817, MAE: 0.2382, R²: -0.0202

============================================================
🔄 Round 139 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0873, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0873, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0873, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0872, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0872, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0872, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 139 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0873, RMSE=0.2954, R²=-0.0406
   Val:   Loss=0.0852, RMSE=0.2918, R²=-0.0334
============================================================


📊 Round 139 Test Metrics:
   Loss: 0.0794, RMSE: 0.2817, MAE: 0.2382, R²: -0.0201

============================================================
🔄 Round 141 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0913 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0913, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0913, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0913, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0913, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0913, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0913)

============================================================
📊 Round 141 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2928, R²=-0.0335
   Val:   Loss=0.0913, RMSE=0.3022, R²=-0.0343
============================================================


============================================================
🔄 Round 142 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0876, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0876, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0876, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0876, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0876, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0875, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 142 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0877, RMSE=0.2961, R²=-0.0397
   Val:   Loss=0.0835, RMSE=0.2890, R²=-0.0037
============================================================


============================================================
🔄 Round 144 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0884, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0884, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0884, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0884, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0883, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0883, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 144 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0884, RMSE=0.2973, R²=-0.0363
   Val:   Loss=0.0807, RMSE=0.2841, R²=-0.0645
============================================================


📊 Round 144 Test Metrics:
   Loss: 0.0794, RMSE: 0.2817, MAE: 0.2382, R²: -0.0200

📊 Round 144 Test Metrics:
   Loss: 0.0794, RMSE: 0.2817, MAE: 0.2382, R²: -0.0200

📊 Round 144 Test Metrics:
   Loss: 0.0794, RMSE: 0.2817, MAE: 0.2382, R²: -0.0201

============================================================
🔄 Round 150 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0909 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0909, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0909, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0909, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0909, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0908, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0909)

============================================================
📊 Round 150 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2930, R²=-0.0356
   Val:   Loss=0.0909, RMSE=0.3015, R²=-0.0222
============================================================


📊 Round 150 Test Metrics:
   Loss: 0.0794, RMSE: 0.2817, MAE: 0.2382, R²: -0.0201

📊 Round 150 Test Metrics:
   Loss: 0.0794, RMSE: 0.2817, MAE: 0.2382, R²: -0.0201

============================================================
🔄 Round 154 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0885, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0885, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0884, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0884, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0884, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0884, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 154 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0885, RMSE=0.2974, R²=-0.0282
   Val:   Loss=0.0804, RMSE=0.2835, R²=-0.0530
============================================================


📊 Round 154 Test Metrics:
   Loss: 0.0794, RMSE: 0.2817, MAE: 0.2382, R²: -0.0201

📊 Round 154 Test Metrics:
   Loss: 0.0794, RMSE: 0.2817, MAE: 0.2382, R²: -0.0201

============================================================
🔄 Round 157 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0887, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0887, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0887, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0887, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0887, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0886, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 157 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0887, RMSE=0.2979, R²=-0.0325
   Val:   Loss=0.0793, RMSE=0.2817, R²=-0.0379
============================================================


============================================================
🔄 Round 158 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0903, val=0.0731 (↓), lr=0.000001
   • Epoch   2/100: train=0.0902, val=0.0731, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0902, val=0.0731, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0902, val=0.0731, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0902, val=0.0731, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0902, val=0.0732, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0731)

============================================================
📊 Round 158 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0903, RMSE=0.3004, R²=-0.0344
   Val:   Loss=0.0731, RMSE=0.2704, R²=-0.0418
============================================================


📊 Round 158 Test Metrics:
   Loss: 0.0794, RMSE: 0.2817, MAE: 0.2382, R²: -0.0200

============================================================
🔄 Round 159 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0950 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0950, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0950, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0950, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0950, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0950, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0950)

============================================================
📊 Round 159 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2913, R²=-0.0372
   Val:   Loss=0.0950, RMSE=0.3082, R²=-0.0363
============================================================


📊 Round 159 Test Metrics:
   Loss: 0.0794, RMSE: 0.2817, MAE: 0.2382, R²: -0.0201

============================================================
🔄 Round 161 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0880, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0880, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0880, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0880, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0880, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0879, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 161 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0880, RMSE=0.2966, R²=-0.0266
   Val:   Loss=0.0823, RMSE=0.2870, R²=-0.0795
============================================================


============================================================
🔄 Round 162 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0893 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0893, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0893, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0893, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0893, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0893, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0893)

============================================================
📊 Round 162 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2937, R²=-0.0280
   Val:   Loss=0.0893, RMSE=0.2989, R²=-0.0613
============================================================


============================================================
🔄 Round 163 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0874, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0874, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0874, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0874, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0874, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0873, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 163 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0874, RMSE=0.2956, R²=-0.0342
   Val:   Loss=0.0848, RMSE=0.2912, R²=-0.0269
============================================================


📊 Round 163 Test Metrics:
   Loss: 0.0794, RMSE: 0.2817, MAE: 0.2382, R²: -0.0201

============================================================
🔄 Round 164 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0883, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0883, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0882, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0882, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0882, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0882, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 164 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0882, RMSE=0.2971, R²=-0.0317
   Val:   Loss=0.0813, RMSE=0.2851, R²=-0.0395
============================================================


📊 Round 164 Test Metrics:
   Loss: 0.0794, RMSE: 0.2817, MAE: 0.2382, R²: -0.0201

📊 Round 164 Test Metrics:
   Loss: 0.0794, RMSE: 0.2817, MAE: 0.2382, R²: -0.0202

📊 Round 164 Test Metrics:
   Loss: 0.0794, RMSE: 0.2817, MAE: 0.2382, R²: -0.0202

============================================================
🔄 Round 171 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0876 (↓), lr=0.000001
   • Epoch   2/100: train=0.0867, val=0.0876, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0867, val=0.0876, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0867, val=0.0876, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0876, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0866, val=0.0876, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0876)

============================================================
📊 Round 171 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0867, RMSE=0.2944, R²=-0.0394
   Val:   Loss=0.0876, RMSE=0.2960, R²=-0.0119
============================================================


============================================================
🔄 Round 174 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0894 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0894, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0893, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0893, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0893, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0893, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0894)

============================================================
📊 Round 174 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2937, R²=-0.0203
   Val:   Loss=0.0894, RMSE=0.2989, R²=-0.0846
============================================================


📊 Round 174 Test Metrics:
   Loss: 0.0794, RMSE: 0.2817, MAE: 0.2383, R²: -0.0202

============================================================
🔄 Round 175 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0891 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0891, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0891, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0891, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0891, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0891, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0891)

============================================================
📊 Round 175 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2938, R²=-0.0239
   Val:   Loss=0.0891, RMSE=0.2985, R²=-0.0722
============================================================


📊 Round 175 Test Metrics:
   Loss: 0.0794, RMSE: 0.2817, MAE: 0.2383, R²: -0.0202

============================================================
🔄 Round 181 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0932 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0932, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0932, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0932, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0932, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0932, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0932)

============================================================
📊 Round 181 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2920, R²=-0.0379
   Val:   Loss=0.0932, RMSE=0.3053, R²=-0.0264
============================================================


📊 Round 181 Test Metrics:
   Loss: 0.0794, RMSE: 0.2817, MAE: 0.2383, R²: -0.0203

📊 Round 181 Test Metrics:
   Loss: 0.0794, RMSE: 0.2818, MAE: 0.2383, R²: -0.0203

============================================================
🔄 Round 185 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0891 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0891, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0891, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0891, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0891, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0891, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0891)

============================================================
📊 Round 185 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2938, R²=-0.0281
   Val:   Loss=0.0891, RMSE=0.2986, R²=-0.0531
============================================================


📊 Round 185 Test Metrics:
   Loss: 0.0794, RMSE: 0.2818, MAE: 0.2383, R²: -0.0204

📊 Round 185 Test Metrics:
   Loss: 0.0794, RMSE: 0.2818, MAE: 0.2383, R²: -0.0204

============================================================
🔄 Round 188 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0898 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0898, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0898, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0898, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0898, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0898, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0898)

============================================================
📊 Round 188 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2935, R²=-0.0308
   Val:   Loss=0.0898, RMSE=0.2997, R²=-0.0638
============================================================


📊 Round 188 Test Metrics:
   Loss: 0.0794, RMSE: 0.2818, MAE: 0.2383, R²: -0.0205

📊 Round 188 Test Metrics:
   Loss: 0.0794, RMSE: 0.2818, MAE: 0.2383, R²: -0.0204

============================================================
🔄 Round 192 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0878, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0878, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0878, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0878, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0878, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0877, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 192 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0878, RMSE=0.2964, R²=-0.0365
   Val:   Loss=0.0830, RMSE=0.2881, R²=-0.0317
============================================================


============================================================
🔄 Round 193 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0969 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0969, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0969, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0969, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0969, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0969, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0969)

============================================================
📊 Round 193 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=-0.0294
   Val:   Loss=0.0969, RMSE=0.3113, R²=-0.0561
============================================================


📊 Round 193 Test Metrics:
   Loss: 0.0794, RMSE: 0.2818, MAE: 0.2383, R²: -0.0205

============================================================
🔄 Round 194 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0878, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0878, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0878, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0877, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0877, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0877, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 194 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0878, RMSE=0.2963, R²=-0.0329
   Val:   Loss=0.0832, RMSE=0.2884, R²=-0.0347
============================================================


============================================================
🔄 Round 197 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0938 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0938, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0938, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0938, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0938, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0937, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0938)

============================================================
📊 Round 197 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2918, R²=-0.0237
   Val:   Loss=0.0938, RMSE=0.3063, R²=-0.0683
============================================================


============================================================
🔄 Round 198 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0898 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0898, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0898, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0898, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0898, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0898, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0898)

============================================================
📊 Round 198 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2935, R²=-0.0320
   Val:   Loss=0.0898, RMSE=0.2997, R²=-0.0401
============================================================


📊 Round 198 Test Metrics:
   Loss: 0.0794, RMSE: 0.2818, MAE: 0.2383, R²: -0.0204

📊 Round 198 Test Metrics:
   Loss: 0.0794, RMSE: 0.2818, MAE: 0.2383, R²: -0.0205

============================================================
🔄 Round 201 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0904, val=0.0726 (↓), lr=0.000001
   • Epoch   2/100: train=0.0904, val=0.0726, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0904, val=0.0726, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0904, val=0.0726, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0904, val=0.0726, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0903, val=0.0726, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0726)

============================================================
📊 Round 201 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0904, RMSE=0.3007, R²=-0.0395
   Val:   Loss=0.0726, RMSE=0.2695, R²=-0.0076
============================================================


📊 Round 201 Test Metrics:
   Loss: 0.0794, RMSE: 0.2818, MAE: 0.2383, R²: -0.0205

📊 Round 201 Test Metrics:
   Loss: 0.0794, RMSE: 0.2818, MAE: 0.2383, R²: -0.0206

============================================================
🔄 Round 204 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0877, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0876, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0876, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0876, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0876, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0876, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 204 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0876, RMSE=0.2960, R²=-0.0366
   Val:   Loss=0.0838, RMSE=0.2895, R²=-0.0203
============================================================


📊 Round 204 Test Metrics:
   Loss: 0.0794, RMSE: 0.2818, MAE: 0.2383, R²: -0.0206

📊 Round 204 Test Metrics:
   Loss: 0.0794, RMSE: 0.2818, MAE: 0.2383, R²: -0.0206

📊 Round 204 Test Metrics:
   Loss: 0.0794, RMSE: 0.2818, MAE: 0.2383, R²: -0.0206

📊 Round 204 Test Metrics:
   Loss: 0.0794, RMSE: 0.2818, MAE: 0.2383, R²: -0.0206

📊 Round 204 Test Metrics:
   Loss: 0.0794, RMSE: 0.2818, MAE: 0.2383, R²: -0.0205

============================================================
🔄 Round 211 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0880, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0879, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0879, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0879, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0879, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0879, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 211 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0879, RMSE=0.2965, R²=-0.0312
   Val:   Loss=0.0826, RMSE=0.2874, R²=-0.0501
============================================================


📊 Round 211 Test Metrics:
   Loss: 0.0794, RMSE: 0.2818, MAE: 0.2383, R²: -0.0205

============================================================
🔄 Round 212 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0885, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0885, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0885, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0885, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0885, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0884, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 212 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0885, RMSE=0.2975, R²=-0.0319
   Val:   Loss=0.0804, RMSE=0.2835, R²=-0.0462
============================================================


📊 Round 212 Test Metrics:
   Loss: 0.0794, RMSE: 0.2818, MAE: 0.2383, R²: -0.0205

📊 Round 212 Test Metrics:
   Loss: 0.0794, RMSE: 0.2818, MAE: 0.2383, R²: -0.0205

📊 Round 212 Test Metrics:
   Loss: 0.0794, RMSE: 0.2818, MAE: 0.2383, R²: -0.0205

============================================================
🔄 Round 215 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0873, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0873, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0873, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0873, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0872, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0872, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 215 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0873, RMSE=0.2955, R²=-0.0393
   Val:   Loss=0.0852, RMSE=0.2918, R²=-0.0069
============================================================


📊 Round 215 Test Metrics:
   Loss: 0.0794, RMSE: 0.2818, MAE: 0.2383, R²: -0.0206

============================================================
🔄 Round 217 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0971 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0971, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0970, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0970, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0970, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0970, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0971)

============================================================
📊 Round 217 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2904, R²=-0.0312
   Val:   Loss=0.0971, RMSE=0.3115, R²=-0.0398
============================================================


============================================================
🔄 Round 218 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0924 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0924, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0924, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0924, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0924, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0923, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0924)

============================================================
📊 Round 218 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2924, R²=-0.0352
   Val:   Loss=0.0924, RMSE=0.3039, R²=-0.0263
============================================================


============================================================
🔄 Round 221 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0880 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0880, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0880, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0880, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0880, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0880, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0880)

============================================================
📊 Round 221 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2943, R²=-0.0347
   Val:   Loss=0.0880, RMSE=0.2966, R²=-0.0354
============================================================


============================================================
🔄 Round 222 - Client client_41
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0902, val=0.0733 (↓), lr=0.000001
   • Epoch   2/100: train=0.0902, val=0.0733, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0902, val=0.0733, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0902, val=0.0733, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0902, val=0.0733, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0901, val=0.0734, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0733)

============================================================
📊 Round 222 Summary - Client client_41
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0902, RMSE=0.3004, R²=-0.0434
   Val:   Loss=0.0733, RMSE=0.2708, R²=0.0059
============================================================


📊 Round 222 Test Metrics:
   Loss: 0.0794, RMSE: 0.2818, MAE: 0.2383, R²: -0.0205

📊 Round 222 Test Metrics:
   Loss: 0.0794, RMSE: 0.2818, MAE: 0.2383, R²: -0.0205

❌ Client client_41 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8687 {grpc_message:"Socket closed", grpc_status:14}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8687 {grpc_message:"Socket closed", grpc_status:14}"
>
