[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9c715732-4768-4dbb-88d7-913dc7602ce6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6552684e-0550-4bbd-afa1-a87a39a3196e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 31fc79d1-eb2a-4999-943b-9dee8ef301d1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5ab0911a-73ad-4e77-a0fa-a532d587835b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c7bfa0c6-b3c4-41a4-8599-a6c0b6a700bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 79ee015f-dd65-484f-9a52-553105ba1938
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 905e6601-8ef1-4084-b7f1-06313c84f10c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e82e38fe-82fc-4a11-994a-11dc9080af37
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6c3b3e00-31c4-4aaa-b709-fd1519958112
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d33c6ea9-bf55-42b7-88d4-a667306f14d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f47be949-c31f-4d5e-b388-9ede05ff6467
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5b75678c-7765-48e0-893a-3af187a3954d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 13b537fa-51e8-414d-8755-4ebe4c92890c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7cdf0387-979d-40f8-b43c-ddcd3e16a35a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7e6df846-6a21-4bf9-8f15-4255036d91e2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f52a44ed-1a19-4887-b8e2-f907b027082a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 095725eb-bfe2-48ce-930c-272086f13e6b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 346d51d8-0bf5-44cd-8356-6beb5132c722
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0533dcf0-d0b6-4773-8ba3-109e7a89ca66
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bb7d3d47-6b58-47d5-b774-451622b2766b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 900a1f0a-b0cc-4e38-81d4-68839e9ab027
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ef64e58c-5689-4cb1-a95e-e9de3981b2d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 52c5623b-a999-4331-8224-87851ec2c234
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 89596cd5-8eeb-437e-b286-77aa93b71cc3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9da36bfd-87e7-4bec-b5ab-cfa0f86b5346
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message af000ccc-5129-4ede-a911-467a45ebce25
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d81b7040-fa80-4778-ab6d-bbd2ef4b7b2d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 92f04231-c082-43b0-8e67-e69ffa93f1a8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4daae16a-293e-48a3-9442-949b937085ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dccfe81a-ad6f-499b-b22d-850a6d31f828
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8c1f5a1d-0b74-41e5-9886-0d0204cae570
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 34d977f0-b302-4a2c-86f7-a3bf071b6026
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 64144cce-736d-4fbb-a34d-d88f0c15a26b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ee60d11d-84d0-44fe-b9b6-e06fa3973d63
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 62adc694-06b3-4850-a4a3-4ce9fe07b121
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 948b5585-dd24-428d-a0f8-3d9f64dbb629
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 44b035e5-c412-4503-96ee-345cd5f64528
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 940c8f79-cb23-4aa1-a646-3b537df94ce2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2e8b76ff-cb16-4222-b4f5-6f4a4a5d6f93
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1c4a1b9d-0338-4fee-be31-56e53957257f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3969648e-3d9e-4b52-bde5-fcc3b9cb6bf4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eae6032b-933d-4e51-b741-97443d243170
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 469c0910-de3b-445c-8605-d8a3e54b4f60
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cac4922a-5d6f-454a-a439-1a784354e57b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a31fa7c3-c55b-4331-aea0-e4784576e57b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 236463ff-bf4d-4a22-91ce-4eb0f8e9d05e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 73ecbd15-b767-42e1-995c-d753600c5eda
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0a5312eb-13a5-4111-82d8-dceaca810c47
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0c2c7ca4-a8ea-4bce-bd48-168c22a052ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7c762a78-ad0a-428b-8a2e-8116dda2fbf2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9568c59e-166d-49d8-bb59-94bdba815113
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bce0b688-f142-4a1b-a50e-3fe868cbe513
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 052aa1d9-e6e4-415a-9c40-ac4e1728bb93
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fc32b861-2e10-44b9-b65d-fb90e161f6eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d95aed3e-17ca-4617-b3fc-3cfd5801567d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 60fe549f-b4ae-4c82-9cd5-b07cb44574b8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cbb4c79d-8829-4466-9e48-951f95a86494
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b6f27067-9811-4c06-aa72-39f06a399dfc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 069705b2-928a-4485-b4da-4dab4c22fbd3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message be41d974-6070-4f1c-9a1b-942e48b4f8f9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 75b9d8b6-07b7-41fd-968c-eafbf2509dd5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c73cae09-5e39-42cb-93e0-86063adc68ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cbdc8457-deaf-4075-8599-1a236c2aa63d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 36680a6d-2cb7-42ec-877c-db8bdc9ab994
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a08300c4-10b7-4426-a9de-e85966eecf10
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fbbcd5fe-814a-4408-8b13-da0112051622
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 463221c9-59b3-49ca-a829-0a16e0888967
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3abbe492-0d1b-4194-805d-ad57e8236296
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 36874bd0-9b5d-4179-94cd-752339edc9b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 64aab485-5d38-4ec2-a952-eda5b8e1d5aa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3cf9bcf3-0bb6-4567-8944-188c9cac5486
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 05f9ee1e-21b0-4c43-8571-4af5cc38384c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a6bbacf2-5046-4546-a528-ebdd8852c5b0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b4c9b315-efc6-4922-9aa6-be0a8522e4fb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c30d004f-b248-4767-b994-76dfd81cf0b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 80c9dbb0-b6e5-4977-b5b6-60122c1fae5b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eb301bac-a011-4887-8df4-e40e869ddc65
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c856b693-00f1-4ce3-9ae5-c72431b1d95e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fc14701d-4220-4862-b1af-8d290c0a4e26
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2e852593-255b-4697-98e6-347a7281c01a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ffe99ab1-cd49-4a2e-b668-83d4e92415c4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0ac194d9-98b8-47a1-94bf-e9645c15377c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 606f772d-6419-422c-9da2-506bc95c1b38
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9635c0a2-99cc-4975-aab1-2a46ac3e674c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e2f5eaf5-19d1-4f57-8246-a88ebc8948be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8fc4e1c3-e7e2-44a7-b083-3fdeccb7307d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7c2f8d14-14c7-42a2-8482-551882d6eab8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8f06521d-4cdf-4547-8266-1d0d4c1a2cdf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d31bc994-bab0-4a05-b7cb-06b11c0cf004
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b66c8dd3-5908-424a-b61b-793141ce5609
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 263d8d15-fe16-4544-b3c3-756362f5b4e6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5436fe8a-6843-4aff-8471-0e892a128f63
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a479f248-515d-4809-bb7c-34d19103020d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9d2d954f-aa0e-4c6e-bade-74e6671ed28a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b6bfb8cc-c77b-443c-923a-950fbfe6d890
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c8b8e36f-0c68-47d2-8605-9c6e7a3f8085
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a1906b8b-6a26-4085-90a2-9395595cf88b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b553faff-055d-4451-afb1-05ea5c940e2d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 628ccd83-1718-4d1b-a4a9-0dc6ca7abd8d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 363df4d8-9c51-427a-b7eb-08fae2f8c1b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3cf41a0c-6d20-4aab-8623-2e2ae9034d51
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bfb0ba7d-4e4f-4161-8e55-50dcca301d55
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ecc98aad-b1a7-4dc0-8c08-4461751eaf02
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 05c8eba0-44da-44ca-bf21-754055e93616
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 541dfe12-faf4-46fc-9bbc-4a4019e1ed71
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c40d26d3-5d6b-457f-baf7-36a0cca98af8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c044cde7-d2fb-41a9-8e27-b37cfb5b6fce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 531a1b96-02c8-4f03-9a63-82ddfdf9f1fb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 716444a7-21d7-441d-88ef-4e465b7d8c04
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3055c93a-943a-44c3-bf79-01eb9d07f1a0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b2adc5e4-445e-4b3e-af11-07b6629d9992
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e76b3d13-7359-4f6a-9448-59d1be0381a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b61a87c2-b039-401d-b824-42d5a0f27d82
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 66c3fd61-f36d-49c6-bb88-69b546312aa3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a25ef08e-b2b2-4369-af96-855c28dfbe1c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 105707eb-ff32-4690-a201-5ef42815ea04
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a8ac42e6-0a02-4610-83c8-2fc19b5c33d9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 67f1635f-8b3b-421e-9d86-b4fe26bb78b9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1ff14bab-c576-4e67-ad48-d3eecc8ae201
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 54906bd8-16dc-4ba8-b317-612c34b0b386
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 827ffd78-63e8-451b-8a23-bf4116e701bc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cde5f084-d5d1-49f2-88ab-1ac68f8341a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c81312fa-c6ea-485f-a42b-97b16138e0dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dbb21588-1e84-478d-a2eb-0bb6c57a830f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f94c763f-7b23-47ea-9b6f-35f420b1e2ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1e70b5ff-aa81-4dcf-993a-0bfb93a6373c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 30295fcf-b5dc-4ff4-b597-2e0d67cbf3dd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message da60a0ce-ad3e-48a6-aaec-39ea6e1bc5c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1a55c079-da14-4029-98ee-120a8208a509
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7c92df17-2c8c-4af6-8774-c983f6a46557
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d2fde24c-b998-4ef3-80f1-c710e0189b3e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f44f4f11-415e-450f-8222-e3dc0c3fdfe7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 60eb770a-6c1f-481e-a804-80dbf0d9b87c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 787ac85f-a134-44fa-8ada-1d7434c27215
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 25394159-af01-409c-97e8-e81af277e0df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b17bf070-5a15-4385-916e-9315d417ce16
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 766a72e7-a176-43b8-a9ca-5ee58c89456c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1a303798-2c52-4da2-a743-481fd8b97c60
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8adcce87-cd55-4f70-b942-882f21e563c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ab3f752b-d585-45e0-91de-020dcf2d1b87
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fad73512-9d66-4d74-9b17-6d491a113ca5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 18057210-3f80-47ac-946b-60bac5e512d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a6f1d0b1-42a8-4f9f-bb21-a6c5adbc000b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dd8910a5-c182-44f4-a476-2f99e9e76fb6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2fe9fdc7-2929-4e80-ae0d-33793684be10
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 26321b6e-a86d-4d05-b893-2c6540de1ad1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e3861866-9b58-44d5-a5f3-86724a5e3917
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a0cdae81-a7c3-4ef2-bc42-4e9bb459ee2b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5a18120a-1c62-4614-9c85-1bd0610bbf00
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a5d491c3-61de-46d3-8435-ce978f4293fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 84302d9a-0557-4219-b9b8-9756eb653177
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 675ce3cd-36c9-443d-b693-8282553525a3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4adbe707-9926-4275-9f6c-c021707908f9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3c25479b-24c4-4e87-9fb3-7b8c77eddd1d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 88439b3a-5497-4664-85ed-5fc6c7414c45
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 72fd76fc-9d7a-4dff-b03c-decfae6ae6d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 72b45fd6-cb67-4c58-9893-9b12229ec83b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a6e5cb97-cd28-4cba-b16c-62c0a9510c61
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2fb037fb-c152-4049-906c-1003fe13a92a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8dc95aff-3000-443f-a78f-0fc99e308d13
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1f95cd4e-b4a2-4eb5-870b-8095729a5def
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 05b070bf-821f-4742-a000-51f4311565e9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 75ed311f-2168-4e2f-98f6-1ebadca3b03b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4e2b2e26-6fc9-4f2e-9a79-da74a5795e82
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 30933cf0-72bf-46bf-a391-0f8b68bfb248
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9f571283-ee51-4b62-a706-4b6d25c9eb6c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0e2add6f-89c0-423a-963c-8f9a72d59485
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ac6ec5ca-f1d6-4cbe-b5d8-04213235971d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e1fe31a2-e62a-4987-8a82-5416baf41398
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0bc2597e-86c8-45bd-9a95-efc33698f55b
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8687 {grpc_message:"Socket closed", grpc_status:14}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_42
Server: localhost:8687
Algorithm: FEDAVG
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_42
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_42/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_42/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_42/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_42/test_labels.txt

📊 Raw data loaded:
   Train: X=(1319, 24), y=(1319,)
   Test:  X=(330, 24), y=(330,)

⚠️  Limiting training data: 1319 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  321 samples, 5 features
✅ Client client_42 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

============================================================
🔄 Round 5 - Client client_42
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0787 (↓), lr=0.001000
   ✓ Epoch   2/100: train=0.0803, val=0.0769 (↓), lr=0.001000
   ✓ Epoch   3/100: train=0.0798, val=0.0763 (↓), lr=0.001000
   ✓ Epoch   4/100: train=0.0788, val=0.0755 (↓), lr=0.001000
   ✓ Epoch   5/100: train=0.0774, val=0.0744 (↓), lr=0.001000
   ✓ Epoch  11/100: train=0.0709, val=0.0703 (↓), lr=0.001000
   📉 Epoch 21: LR reduced 0.001000 → 0.000500
   • Epoch  21/100: train=0.0661, val=0.0701, patience=10/15, lr=0.000500

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0703)

============================================================
📊 Round 5 Summary - Client client_42
   Epochs: 26/100 (early stopped)
   LR: 0.001000 → 0.000500 (1 reductions)
   Train: Loss=0.0699, RMSE=0.2644, R²=0.1521
   Val:   Loss=0.0703, RMSE=0.2651, R²=0.1253
============================================================


============================================================
🔄 Round 7 - Client client_42
   Epochs: 100, Batch: 32, LR: 0.000500
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0761, val=0.0749 (↓), lr=0.000500
   • Epoch   2/100: train=0.0750, val=0.0752, patience=1/15, lr=0.000500
   📉 Epoch 3: LR reduced 0.000500 → 0.000250
   • Epoch   3/100: train=0.0739, val=0.0750, patience=2/15, lr=0.000250
   • Epoch   4/100: train=0.0728, val=0.0748, patience=3/15, lr=0.000250
   • Epoch   5/100: train=0.0722, val=0.0747, patience=4/15, lr=0.000250
   📉 Epoch 11: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0694, val=0.0738, patience=1/15, lr=0.000125
   📉 Epoch 19: LR reduced 0.000125 → 0.000063
   • Epoch  21/100: train=0.0675, val=0.0742, patience=11/15, lr=0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0738)

============================================================
📊 Round 7 Summary - Client client_42
   Epochs: 25/100 (early stopped)
   LR: 0.000500 → 0.000063 (3 reductions)
   Train: Loss=0.0694, RMSE=0.2634, R²=0.1634
   Val:   Loss=0.0738, RMSE=0.2716, R²=0.0657
============================================================


📊 Round 7 Test Metrics:
   Loss: 0.0785, RMSE: 0.2803, MAE: 0.2442, R²: 0.0746

============================================================
🔄 Round 10 - Client client_42
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0752, val=0.0758 (↓), lr=0.000063
   📉 Epoch 2: LR reduced 0.000063 → 0.000031
   ✓ Epoch   2/100: train=0.0746, val=0.0751 (↓), lr=0.000031
   • Epoch   3/100: train=0.0742, val=0.0748, patience=1/15, lr=0.000031
   • Epoch   4/100: train=0.0740, val=0.0747, patience=2/15, lr=0.000031
   ✓ Epoch   5/100: train=0.0738, val=0.0745 (↓), lr=0.000031
   📉 Epoch 10: LR reduced 0.000031 → 0.000016
   • Epoch  11/100: train=0.0732, val=0.0743, patience=6/15, lr=0.000016
   📉 Epoch 18: LR reduced 0.000016 → 0.000008

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0745)

============================================================
📊 Round 10 Summary - Client client_42
   Epochs: 20/100 (early stopped)
   LR: 0.000063 → 0.000008 (3 reductions)
   Train: Loss=0.0739, RMSE=0.2718, R²=0.0917
   Val:   Loss=0.0745, RMSE=0.2730, R²=0.1294
============================================================


📊 Round 10 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2442, R²: 0.0740

📊 Round 10 Test Metrics:
   Loss: 0.0788, RMSE: 0.2808, MAE: 0.2447, R²: 0.0713

============================================================
🔄 Round 13 - Client client_42
   Epochs: 100, Batch: 32, LR: 0.000008
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0765, val=0.0725 (↓), lr=0.000008
   • Epoch   2/100: train=0.0764, val=0.0725, patience=1/15, lr=0.000008
   • Epoch   3/100: train=0.0763, val=0.0724, patience=2/15, lr=0.000008
   • Epoch   4/100: train=0.0761, val=0.0724, patience=3/15, lr=0.000008
   • Epoch   5/100: train=0.0760, val=0.0723, patience=4/15, lr=0.000008
   📉 Epoch 6: LR reduced 0.000008 → 0.000004
   • Epoch  11/100: train=0.0756, val=0.0721, patience=10/15, lr=0.000004
   📉 Epoch 14: LR reduced 0.000004 → 0.000002

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0725)

============================================================
📊 Round 13 Summary - Client client_42
   Epochs: 16/100 (early stopped)
   LR: 0.000008 → 0.000002 (2 reductions)
   Train: Loss=0.0766, RMSE=0.2768, R²=0.0730
   Val:   Loss=0.0725, RMSE=0.2692, R²=0.0933
============================================================


📊 Round 13 Test Metrics:
   Loss: 0.0784, RMSE: 0.2801, MAE: 0.2440, R²: 0.0757

📊 Round 13 Test Metrics:
   Loss: 0.0780, RMSE: 0.2793, MAE: 0.2430, R²: 0.0806

📊 Round 13 Test Metrics:
   Loss: 0.0779, RMSE: 0.2791, MAE: 0.2428, R²: 0.0823

📊 Round 13 Test Metrics:
   Loss: 0.0779, RMSE: 0.2791, MAE: 0.2428, R²: 0.0821

📊 Round 13 Test Metrics:
   Loss: 0.0779, RMSE: 0.2791, MAE: 0.2427, R²: 0.0824

📊 Round 13 Test Metrics:
   Loss: 0.0776, RMSE: 0.2785, MAE: 0.2421, R²: 0.0861

📊 Round 13 Test Metrics:
   Loss: 0.0775, RMSE: 0.2785, MAE: 0.2420, R²: 0.0863

============================================================
🔄 Round 26 - Client client_42
   Epochs: 100, Batch: 32, LR: 0.000002
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0757, val=0.0702 (↓), lr=0.000002
   • Epoch   2/100: train=0.0756, val=0.0702, patience=1/15, lr=0.000002
   • Epoch   3/100: train=0.0756, val=0.0702, patience=2/15, lr=0.000002
   • Epoch   4/100: train=0.0756, val=0.0702, patience=3/15, lr=0.000002
   • Epoch   5/100: train=0.0755, val=0.0701, patience=4/15, lr=0.000002
   📉 Epoch 6: LR reduced 0.000002 → 0.000001
   • Epoch  11/100: train=0.0754, val=0.0700, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0702)

============================================================
📊 Round 26 Summary - Client client_42
   Epochs: 16/100 (early stopped)
   LR: 0.000002 → 0.000001 (1 reductions)
   Train: Loss=0.0753, RMSE=0.2745, R²=0.0950
   Val:   Loss=0.0702, RMSE=0.2650, R²=0.0991
============================================================


📊 Round 26 Test Metrics:
   Loss: 0.0775, RMSE: 0.2785, MAE: 0.2420, R²: 0.0863

============================================================
🔄 Round 31 - Client client_42
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0742, val=0.0754 (↓), lr=0.000001
   • Epoch   2/100: train=0.0742, val=0.0754, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0742, val=0.0754, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0742, val=0.0754, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0741, val=0.0754, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0740, val=0.0753, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0754)

============================================================
📊 Round 31 Summary - Client client_42
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0741, RMSE=0.2721, R²=0.1001
   Val:   Loss=0.0754, RMSE=0.2746, R²=0.0687
============================================================


============================================================
🔄 Round 33 - Client client_42
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0740, val=0.0761 (↓), lr=0.000001
   • Epoch   2/100: train=0.0740, val=0.0761, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0740, val=0.0761, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0739, val=0.0761, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0739, val=0.0761, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0738, val=0.0762, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0761)

============================================================
📊 Round 33 Summary - Client client_42
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0739, RMSE=0.2718, R²=0.0963
   Val:   Loss=0.0761, RMSE=0.2759, R²=0.0651
============================================================


============================================================
🔄 Round 35 - Client client_42
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0752, val=0.0716 (↓), lr=0.000001
   • Epoch   2/100: train=0.0752, val=0.0716, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0752, val=0.0716, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0752, val=0.0716, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0751, val=0.0716, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0751, val=0.0715, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0716)

============================================================
📊 Round 35 Summary - Client client_42
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0750, RMSE=0.2738, R²=0.0940
   Val:   Loss=0.0716, RMSE=0.2677, R²=0.1015
============================================================


============================================================
🔄 Round 36 - Client client_42
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0751, val=0.0705 (↓), lr=0.000001
   • Epoch   2/100: train=0.0751, val=0.0705, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0751, val=0.0705, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0750, val=0.0704, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0750, val=0.0704, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0749, val=0.0703, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0705)

============================================================
📊 Round 36 Summary - Client client_42
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0753, RMSE=0.2744, R²=0.0980
   Val:   Loss=0.0705, RMSE=0.2655, R²=0.0847
============================================================


============================================================
🔄 Round 40 - Client client_42
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0745, val=0.0733 (↓), lr=0.000001
   • Epoch   2/100: train=0.0745, val=0.0732, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0745, val=0.0732, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0745, val=0.0732, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0745, val=0.0732, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0744, val=0.0730, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0733)

============================================================
📊 Round 40 Summary - Client client_42
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0746, RMSE=0.2731, R²=0.0859
   Val:   Loss=0.0733, RMSE=0.2707, R²=0.1309
============================================================


📊 Round 40 Test Metrics:
   Loss: 0.0775, RMSE: 0.2784, MAE: 0.2420, R²: 0.0865

============================================================
🔄 Round 41 - Client client_42
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0749, val=0.0715 (↓), lr=0.000001
   • Epoch   2/100: train=0.0749, val=0.0715, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0749, val=0.0715, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0748, val=0.0714, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0748, val=0.0714, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0747, val=0.0713, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0715)

============================================================
📊 Round 41 Summary - Client client_42
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0750, RMSE=0.2739, R²=0.0979
   Val:   Loss=0.0715, RMSE=0.2674, R²=0.0880
============================================================


============================================================
🔄 Round 43 - Client client_42
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0750, val=0.0718 (↓), lr=0.000001
   • Epoch   2/100: train=0.0750, val=0.0718, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0750, val=0.0717, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0749, val=0.0717, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0749, val=0.0717, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0748, val=0.0716, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0718)

============================================================
📊 Round 43 Summary - Client client_42
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0749, RMSE=0.2737, R²=0.0948
   Val:   Loss=0.0718, RMSE=0.2679, R²=0.0987
============================================================


📊 Round 43 Test Metrics:
   Loss: 0.0775, RMSE: 0.2784, MAE: 0.2420, R²: 0.0865

============================================================
🔄 Round 44 - Client client_42
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0717, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0717, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0717, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0717, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0717, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0716, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 44 Summary - Client client_42
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0720, RMSE=0.2683, R²=0.0997
   Val:   Loss=0.0836, RMSE=0.2891, R²=0.0826
============================================================


📊 Round 44 Test Metrics:
   Loss: 0.0775, RMSE: 0.2784, MAE: 0.2420, R²: 0.0866

📊 Round 44 Test Metrics:
   Loss: 0.0775, RMSE: 0.2784, MAE: 0.2420, R²: 0.0866

📊 Round 44 Test Metrics:
   Loss: 0.0775, RMSE: 0.2784, MAE: 0.2420, R²: 0.0866

📊 Round 44 Test Metrics:
   Loss: 0.0775, RMSE: 0.2784, MAE: 0.2420, R²: 0.0866

============================================================
🔄 Round 49 - Client client_42
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0743, val=0.0739 (↓), lr=0.000001
   • Epoch   2/100: train=0.0743, val=0.0739, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0743, val=0.0738, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0743, val=0.0738, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0742, val=0.0738, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0741, val=0.0738, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0739)

============================================================
📊 Round 49 Summary - Client client_42
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0744, RMSE=0.2728, R²=0.1055
   Val:   Loss=0.0739, RMSE=0.2718, R²=0.0547
============================================================


============================================================
🔄 Round 52 - Client client_42
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0754, val=0.0709 (↓), lr=0.000001
   • Epoch   2/100: train=0.0754, val=0.0709, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0754, val=0.0709, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0754, val=0.0708, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0754, val=0.0708, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0752, val=0.0707, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0709)

============================================================
📊 Round 52 Summary - Client client_42
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0751, RMSE=0.2741, R²=0.0819
   Val:   Loss=0.0709, RMSE=0.2663, R²=0.1519
============================================================


============================================================
🔄 Round 54 - Client client_42
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0725, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0725, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0725, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0724, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0724, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0723, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 54 Summary - Client client_42
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0726, RMSE=0.2694, R²=0.0894
   Val:   Loss=0.0811, RMSE=0.2847, R²=0.1192
============================================================


============================================================
🔄 Round 55 - Client client_42
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0762, val=0.0672 (↓), lr=0.000001
   • Epoch   2/100: train=0.0761, val=0.0672, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0761, val=0.0672, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0761, val=0.0672, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0761, val=0.0671, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0759, val=0.0671, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0672)

============================================================
📊 Round 55 Summary - Client client_42
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0761, RMSE=0.2758, R²=0.0913
   Val:   Loss=0.0672, RMSE=0.2592, R²=0.1148
============================================================


📊 Round 55 Test Metrics:
   Loss: 0.0775, RMSE: 0.2784, MAE: 0.2420, R²: 0.0867

============================================================
🔄 Round 59 - Client client_42
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0724, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0724, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0724, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0723, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0723, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0722, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 59 Summary - Client client_42
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0727, RMSE=0.2697, R²=0.1007
   Val:   Loss=0.0806, RMSE=0.2838, R²=0.0783
============================================================


============================================================
🔄 Round 60 - Client client_42
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0748, val=0.0723 (↓), lr=0.000001
   • Epoch   2/100: train=0.0748, val=0.0723, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0748, val=0.0722, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0748, val=0.0722, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0748, val=0.0722, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0746, val=0.0721, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0723)

============================================================
📊 Round 60 Summary - Client client_42
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0748, RMSE=0.2735, R²=0.0979
   Val:   Loss=0.0723, RMSE=0.2688, R²=0.0841
============================================================


📊 Round 60 Test Metrics:
   Loss: 0.0775, RMSE: 0.2784, MAE: 0.2419, R²: 0.0868

============================================================
🔄 Round 62 - Client client_42
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0753, val=0.0695 (↓), lr=0.000001
   • Epoch   2/100: train=0.0753, val=0.0695, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0753, val=0.0695, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0753, val=0.0695, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0753, val=0.0695, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0752, val=0.0694, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0695)

============================================================
📊 Round 62 Summary - Client client_42
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0755, RMSE=0.2747, R²=0.0912
   Val:   Loss=0.0695, RMSE=0.2637, R²=0.1167
============================================================


📊 Round 62 Test Metrics:
   Loss: 0.0775, RMSE: 0.2784, MAE: 0.2419, R²: 0.0868

============================================================
🔄 Round 63 - Client client_42
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0746, val=0.0729 (↓), lr=0.000001
   • Epoch   2/100: train=0.0745, val=0.0729, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0745, val=0.0729, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0745, val=0.0728, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0745, val=0.0728, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0744, val=0.0727, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0729)

============================================================
📊 Round 63 Summary - Client client_42
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0746, RMSE=0.2732, R²=0.1026
   Val:   Loss=0.0729, RMSE=0.2700, R²=0.0639
============================================================


============================================================
🔄 Round 65 - Client client_42
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0751, val=0.0705 (↓), lr=0.000001
   • Epoch   2/100: train=0.0751, val=0.0705, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0751, val=0.0705, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0751, val=0.0705, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0751, val=0.0704, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0749, val=0.0704, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0705)

============================================================
📊 Round 65 Summary - Client client_42
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0752, RMSE=0.2743, R²=0.0962
   Val:   Loss=0.0705, RMSE=0.2655, R²=0.0931
============================================================


============================================================
🔄 Round 66 - Client client_42
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0749, val=0.0714 (↓), lr=0.000001
   • Epoch   2/100: train=0.0749, val=0.0714, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0749, val=0.0714, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0749, val=0.0713, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0749, val=0.0713, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0747, val=0.0713, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0714)

============================================================
📊 Round 66 Summary - Client client_42
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0750, RMSE=0.2738, R²=0.1030
   Val:   Loss=0.0714, RMSE=0.2672, R²=0.0672
============================================================


📊 Round 66 Test Metrics:
   Loss: 0.0775, RMSE: 0.2784, MAE: 0.2419, R²: 0.0869

============================================================
🔄 Round 67 - Client client_42
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0728, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0728, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0728, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0728, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0728, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0727, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 67 Summary - Client client_42
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0729, RMSE=0.2699, R²=0.0895
   Val:   Loss=0.0799, RMSE=0.2827, R²=0.1158
============================================================


📊 Round 67 Test Metrics:
   Loss: 0.0775, RMSE: 0.2784, MAE: 0.2419, R²: 0.0869

============================================================
🔄 Round 68 - Client client_42
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0719, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0719, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0719, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0718, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0718, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0717, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 68 Summary - Client client_42
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0717, RMSE=0.2678, R²=0.1070
   Val:   Loss=0.0844, RMSE=0.2905, R²=0.0588
============================================================


============================================================
🔄 Round 69 - Client client_42
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0765, val=0.0659 (↓), lr=0.000001
   • Epoch   2/100: train=0.0765, val=0.0659, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0764, val=0.0659, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0764, val=0.0659, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0764, val=0.0659, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0763, val=0.0658, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0659)

============================================================
📊 Round 69 Summary - Client client_42
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0763, RMSE=0.2763, R²=0.0996
   Val:   Loss=0.0659, RMSE=0.2567, R²=0.0780
============================================================


📊 Round 69 Test Metrics:
   Loss: 0.0775, RMSE: 0.2784, MAE: 0.2419, R²: 0.0870

============================================================
🔄 Round 70 - Client client_42
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0743, val=0.0740 (↓), lr=0.000001
   • Epoch   2/100: train=0.0743, val=0.0740, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0743, val=0.0739, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0742, val=0.0739, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0742, val=0.0739, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0741, val=0.0738, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0740)

============================================================
📊 Round 70 Summary - Client client_42
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0743, RMSE=0.2726, R²=0.0920
   Val:   Loss=0.0740, RMSE=0.2720, R²=0.1130
============================================================


📊 Round 70 Test Metrics:
   Loss: 0.0775, RMSE: 0.2784, MAE: 0.2419, R²: 0.0870

============================================================
🔄 Round 71 - Client client_42
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0746, val=0.0730 (↓), lr=0.000001
   • Epoch   2/100: train=0.0746, val=0.0730, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0746, val=0.0729, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0746, val=0.0729, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0746, val=0.0729, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0745, val=0.0728, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0730)

============================================================
📊 Round 71 Summary - Client client_42
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0746, RMSE=0.2731, R²=0.0949
   Val:   Loss=0.0730, RMSE=0.2701, R²=0.1024
============================================================


📊 Round 71 Test Metrics:
   Loss: 0.0775, RMSE: 0.2784, MAE: 0.2419, R²: 0.0870

============================================================
🔄 Round 72 - Client client_42
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0730, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0730, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0729, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0729, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0729, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0728, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 72 Summary - Client client_42
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0731, RMSE=0.2704, R²=0.0953
   Val:   Loss=0.0789, RMSE=0.2808, R²=0.0615
============================================================


📊 Round 72 Test Metrics:
   Loss: 0.0775, RMSE: 0.2784, MAE: 0.2419, R²: 0.0870

📊 Round 72 Test Metrics:
   Loss: 0.0775, RMSE: 0.2784, MAE: 0.2419, R²: 0.0870

============================================================
🔄 Round 75 - Client client_42
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0753, val=0.0701 (↓), lr=0.000001
   • Epoch   2/100: train=0.0753, val=0.0700, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0752, val=0.0700, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0752, val=0.0700, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0752, val=0.0700, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0751, val=0.0699, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0701)

============================================================
📊 Round 75 Summary - Client client_42
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0753, RMSE=0.2744, R²=0.0954
   Val:   Loss=0.0701, RMSE=0.2647, R²=0.1020
============================================================


📊 Round 75 Test Metrics:
   Loss: 0.0775, RMSE: 0.2783, MAE: 0.2419, R²: 0.0871

============================================================
🔄 Round 78 - Client client_42
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0763, val=0.0659 (↓), lr=0.000001
   • Epoch   2/100: train=0.0763, val=0.0658, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0763, val=0.0658, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0762, val=0.0658, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0762, val=0.0658, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0761, val=0.0657, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0659)

============================================================
📊 Round 78 Summary - Client client_42
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0763, RMSE=0.2763, R²=0.0913
   Val:   Loss=0.0659, RMSE=0.2566, R²=0.1197
============================================================


============================================================
🔄 Round 79 - Client client_42
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0734, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0734, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0734, val=0.0782, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0733, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0733, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0732, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 79 Summary - Client client_42
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0732, RMSE=0.2706, R²=0.0872
   Val:   Loss=0.0782, RMSE=0.2797, R²=0.1287
============================================================


============================================================
🔄 Round 80 - Client client_42
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0736, val=0.0763 (↓), lr=0.000001
   • Epoch   2/100: train=0.0736, val=0.0763, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0736, val=0.0763, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0735, val=0.0762, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0735, val=0.0762, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0734, val=0.0762, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0763)

============================================================
📊 Round 80 Summary - Client client_42
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0737, RMSE=0.2715, R²=0.0998
   Val:   Loss=0.0763, RMSE=0.2762, R²=0.0778
============================================================


📊 Round 80 Test Metrics:
   Loss: 0.0775, RMSE: 0.2783, MAE: 0.2418, R²: 0.0872

📊 Round 80 Test Metrics:
   Loss: 0.0775, RMSE: 0.2783, MAE: 0.2419, R²: 0.0872

============================================================
🔄 Round 84 - Client client_42
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0740, val=0.0742 (↓), lr=0.000001
   • Epoch   2/100: train=0.0740, val=0.0742, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0740, val=0.0741, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0740, val=0.0741, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0739, val=0.0741, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0738, val=0.0740, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0742)

============================================================
📊 Round 84 Summary - Client client_42
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0743, RMSE=0.2725, R²=0.0888
   Val:   Loss=0.0742, RMSE=0.2723, R²=0.1278
============================================================


📊 Round 84 Test Metrics:
   Loss: 0.0775, RMSE: 0.2783, MAE: 0.2418, R²: 0.0872

📊 Round 84 Test Metrics:
   Loss: 0.0775, RMSE: 0.2783, MAE: 0.2418, R²: 0.0872

============================================================
🔄 Round 87 - Client client_42
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0724, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0723, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0723, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0723, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0723, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0722, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 87 Summary - Client client_42
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0725, RMSE=0.2692, R²=0.1024
   Val:   Loss=0.0813, RMSE=0.2852, R²=0.0748
============================================================


📊 Round 87 Test Metrics:
   Loss: 0.0775, RMSE: 0.2783, MAE: 0.2418, R²: 0.0872

============================================================
🔄 Round 88 - Client client_42
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0752, val=0.0703 (↓), lr=0.000001
   • Epoch   2/100: train=0.0752, val=0.0703, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0752, val=0.0703, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0751, val=0.0703, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0751, val=0.0703, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0750, val=0.0702, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0703)

============================================================
📊 Round 88 Summary - Client client_42
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0752, RMSE=0.2742, R²=0.0987
   Val:   Loss=0.0703, RMSE=0.2652, R²=0.0820
============================================================


📊 Round 88 Test Metrics:
   Loss: 0.0775, RMSE: 0.2783, MAE: 0.2418, R²: 0.0873

📊 Round 88 Test Metrics:
   Loss: 0.0775, RMSE: 0.2783, MAE: 0.2418, R²: 0.0874

📊 Round 88 Test Metrics:
   Loss: 0.0775, RMSE: 0.2783, MAE: 0.2418, R²: 0.0874

📊 Round 88 Test Metrics:
   Loss: 0.0775, RMSE: 0.2783, MAE: 0.2418, R²: 0.0874

📊 Round 88 Test Metrics:
   Loss: 0.0774, RMSE: 0.2783, MAE: 0.2418, R²: 0.0874

============================================================
🔄 Round 99 - Client client_42
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0750, val=0.0710 (↓), lr=0.000001
   • Epoch   2/100: train=0.0749, val=0.0710, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0749, val=0.0710, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0749, val=0.0710, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0749, val=0.0710, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0748, val=0.0709, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0710)

============================================================
📊 Round 99 Summary - Client client_42
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0750, RMSE=0.2739, R²=0.1012
   Val:   Loss=0.0710, RMSE=0.2665, R²=0.0703
============================================================


📊 Round 99 Test Metrics:
   Loss: 0.0774, RMSE: 0.2783, MAE: 0.2418, R²: 0.0875

============================================================
🔄 Round 103 - Client client_42
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0718, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0718, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0718, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0717, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0717, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0716, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 103 Summary - Client client_42
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0718, RMSE=0.2679, R²=0.0954
   Val:   Loss=0.0840, RMSE=0.2898, R²=0.1036
============================================================


📊 Round 103 Test Metrics:
   Loss: 0.0774, RMSE: 0.2783, MAE: 0.2418, R²: 0.0875

📊 Round 103 Test Metrics:
   Loss: 0.0774, RMSE: 0.2783, MAE: 0.2418, R²: 0.0876

============================================================
🔄 Round 108 - Client client_42
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0770, val=0.0633 (↓), lr=0.000001
   • Epoch   2/100: train=0.0770, val=0.0633, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0770, val=0.0632, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0770, val=0.0632, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0770, val=0.0632, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0768, val=0.0631, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0633)

============================================================
📊 Round 108 Summary - Client client_42
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0769, RMSE=0.2773, R²=0.0934
   Val:   Loss=0.0633, RMSE=0.2515, R²=0.1126
============================================================


📊 Round 108 Test Metrics:
   Loss: 0.0774, RMSE: 0.2783, MAE: 0.2417, R²: 0.0877

📊 Round 108 Test Metrics:
   Loss: 0.0774, RMSE: 0.2783, MAE: 0.2418, R²: 0.0876

📊 Round 108 Test Metrics:
   Loss: 0.0774, RMSE: 0.2783, MAE: 0.2417, R²: 0.0877

============================================================
🔄 Round 112 - Client client_42
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0739, val=0.0751 (↓), lr=0.000001
   • Epoch   2/100: train=0.0739, val=0.0750, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0739, val=0.0750, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0739, val=0.0750, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0739, val=0.0750, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0737, val=0.0749, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0751)

============================================================
📊 Round 112 Summary - Client client_42
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0740, RMSE=0.2720, R²=0.1047
   Val:   Loss=0.0751, RMSE=0.2740, R²=0.0662
============================================================


📊 Round 112 Test Metrics:
   Loss: 0.0774, RMSE: 0.2783, MAE: 0.2417, R²: 0.0877

============================================================
🔄 Round 113 - Client client_42
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0726, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0726, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0726, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0726, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0726, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0725, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 113 Summary - Client client_42
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0724, RMSE=0.2691, R²=0.0934
   Val:   Loss=0.0814, RMSE=0.2853, R²=0.1110
============================================================


============================================================
🔄 Round 114 - Client client_42
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0761, val=0.0673 (↓), lr=0.000001
   • Epoch   2/100: train=0.0760, val=0.0673, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0760, val=0.0673, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0760, val=0.0673, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0760, val=0.0673, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0759, val=0.0672, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0673)

============================================================
📊 Round 114 Summary - Client client_42
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0759, RMSE=0.2755, R²=0.0899
   Val:   Loss=0.0673, RMSE=0.2595, R²=0.1232
============================================================


============================================================
🔄 Round 117 - Client client_42
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0765, val=0.0660 (↓), lr=0.000001
   • Epoch   2/100: train=0.0765, val=0.0660, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0765, val=0.0659, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0765, val=0.0659, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0764, val=0.0659, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0763, val=0.0659, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0660)

============================================================
📊 Round 117 Summary - Client client_42
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0762, RMSE=0.2761, R²=0.0980
   Val:   Loss=0.0660, RMSE=0.2568, R²=0.0957
============================================================


============================================================
🔄 Round 119 - Client client_42
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0745, val=0.0729 (↓), lr=0.000001
   • Epoch   2/100: train=0.0745, val=0.0729, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0745, val=0.0729, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0744, val=0.0729, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0744, val=0.0729, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0743, val=0.0728, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0729)

============================================================
📊 Round 119 Summary - Client client_42
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0745, RMSE=0.2729, R²=0.0975
   Val:   Loss=0.0729, RMSE=0.2701, R²=0.0968
============================================================


📊 Round 119 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2417, R²: 0.0879

============================================================
🔄 Round 122 - Client client_42
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0745, val=0.0729 (↓), lr=0.000001
   • Epoch   2/100: train=0.0745, val=0.0729, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0745, val=0.0729, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0745, val=0.0729, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0745, val=0.0728, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0744, val=0.0727, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0729)

============================================================
📊 Round 122 Summary - Client client_42
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0745, RMSE=0.2729, R²=0.0991
   Val:   Loss=0.0729, RMSE=0.2700, R²=0.0917
============================================================


============================================================
🔄 Round 125 - Client client_42
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0761, val=0.0663 (↓), lr=0.000001
   • Epoch   2/100: train=0.0761, val=0.0663, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0760, val=0.0663, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0760, val=0.0663, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0760, val=0.0663, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0759, val=0.0662, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0663)

============================================================
📊 Round 125 Summary - Client client_42
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0761, RMSE=0.2759, R²=0.0992
   Val:   Loss=0.0663, RMSE=0.2575, R²=0.0821
============================================================


📊 Round 125 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2417, R²: 0.0880

📊 Round 125 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2417, R²: 0.0880

📊 Round 125 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2417, R²: 0.0880

============================================================
🔄 Round 131 - Client client_42
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0737, val=0.0764 (↓), lr=0.000001
   • Epoch   2/100: train=0.0737, val=0.0764, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0737, val=0.0763, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0736, val=0.0763, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0736, val=0.0763, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0735, val=0.0762, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0764)

============================================================
📊 Round 131 Summary - Client client_42
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0736, RMSE=0.2713, R²=0.0992
   Val:   Loss=0.0764, RMSE=0.2764, R²=0.0920
============================================================


============================================================
🔄 Round 132 - Client client_42
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0755, val=0.0684 (↓), lr=0.000001
   • Epoch   2/100: train=0.0755, val=0.0684, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0755, val=0.0683, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0755, val=0.0683, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0755, val=0.0683, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0754, val=0.0683, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0684)

============================================================
📊 Round 132 Summary - Client client_42
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0756, RMSE=0.2750, R²=0.0943
   Val:   Loss=0.0684, RMSE=0.2615, R²=0.0810
============================================================


📊 Round 132 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2417, R²: 0.0881

📊 Round 132 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2417, R²: 0.0881

📊 Round 132 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2417, R²: 0.0880

📊 Round 132 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2417, R²: 0.0881

============================================================
🔄 Round 140 - Client client_42
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0744, val=0.0732 (↓), lr=0.000001
   • Epoch   2/100: train=0.0743, val=0.0732, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0743, val=0.0732, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0743, val=0.0732, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0743, val=0.0731, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0742, val=0.0731, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0732)

============================================================
📊 Round 140 Summary - Client client_42
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0744, RMSE=0.2727, R²=0.1012
   Val:   Loss=0.0732, RMSE=0.2706, R²=0.0775
============================================================


📊 Round 140 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2417, R²: 0.0881

📊 Round 140 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2416, R²: 0.0882

============================================================
🔄 Round 146 - Client client_42
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0738, val=0.0752 (↓), lr=0.000001
   • Epoch   2/100: train=0.0738, val=0.0752, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0737, val=0.0752, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0737, val=0.0752, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0737, val=0.0752, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0736, val=0.0751, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0752)

============================================================
📊 Round 146 Summary - Client client_42
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0739, RMSE=0.2718, R²=0.1028
   Val:   Loss=0.0752, RMSE=0.2742, R²=0.0778
============================================================


📊 Round 146 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2416, R²: 0.0882

📊 Round 146 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2416, R²: 0.0882

============================================================
🔄 Round 152 - Client client_42
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0734, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0733, val=0.0777, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0733, val=0.0777, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0733, val=0.0777, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0733, val=0.0777, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0732, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 152 Summary - Client client_42
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0732, RMSE=0.2706, R²=0.1079
   Val:   Loss=0.0778, RMSE=0.2788, R²=0.0586
============================================================


============================================================
🔄 Round 153 - Client client_42
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0749, val=0.0712 (↓), lr=0.000001
   • Epoch   2/100: train=0.0749, val=0.0712, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0749, val=0.0711, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0749, val=0.0711, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0749, val=0.0711, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0748, val=0.0710, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0712)

============================================================
📊 Round 153 Summary - Client client_42
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0749, RMSE=0.2736, R²=0.0960
   Val:   Loss=0.0712, RMSE=0.2668, R²=0.1047
============================================================


📊 Round 153 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2416, R²: 0.0884

📊 Round 153 Test Metrics:
   Loss: 0.0774, RMSE: 0.2782, MAE: 0.2416, R²: 0.0884

📊 Round 153 Test Metrics:
   Loss: 0.0774, RMSE: 0.2781, MAE: 0.2416, R²: 0.0884

📊 Round 153 Test Metrics:
   Loss: 0.0774, RMSE: 0.2781, MAE: 0.2416, R²: 0.0884

============================================================
🔄 Round 164 - Client client_42
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0729, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0728, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0728, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0728, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0728, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0727, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 164 Summary - Client client_42
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0728, RMSE=0.2699, R²=0.1102
   Val:   Loss=0.0792, RMSE=0.2815, R²=0.0445
============================================================


============================================================
🔄 Round 166 - Client client_42
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0757, val=0.0670 (↓), lr=0.000001
   • Epoch   2/100: train=0.0757, val=0.0670, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0757, val=0.0670, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0757, val=0.0670, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0757, val=0.0670, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0756, val=0.0669, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0670)

============================================================
📊 Round 166 Summary - Client client_42
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0759, RMSE=0.2755, R²=0.1033
   Val:   Loss=0.0670, RMSE=0.2589, R²=0.0615
============================================================


============================================================
🔄 Round 168 - Client client_42
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0730, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0730, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0729, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0729, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0729, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0728, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 168 Summary - Client client_42
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0730, RMSE=0.2701, R²=0.0964
   Val:   Loss=0.0787, RMSE=0.2806, R²=0.1045
============================================================


📊 Round 168 Test Metrics:
   Loss: 0.0774, RMSE: 0.2781, MAE: 0.2416, R²: 0.0885

============================================================
🔄 Round 170 - Client client_42
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0730, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0730, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0730, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0730, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0730, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0729, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 170 Summary - Client client_42
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0730, RMSE=0.2703, R²=0.0894
   Val:   Loss=0.0784, RMSE=0.2800, R²=0.1278
============================================================


============================================================
🔄 Round 171 - Client client_42
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0754, val=0.0686 (↓), lr=0.000001
   • Epoch   2/100: train=0.0754, val=0.0686, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0754, val=0.0685, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0754, val=0.0685, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0754, val=0.0685, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0753, val=0.0684, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0686)

============================================================
📊 Round 171 Summary - Client client_42
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0755, RMSE=0.2748, R²=0.0910
   Val:   Loss=0.0686, RMSE=0.2619, R²=0.0882
============================================================


📊 Round 171 Test Metrics:
   Loss: 0.0774, RMSE: 0.2781, MAE: 0.2416, R²: 0.0886

============================================================
🔄 Round 173 - Client client_42
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0740, val=0.0757 (↓), lr=0.000001
   • Epoch   2/100: train=0.0740, val=0.0756, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0739, val=0.0756, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0739, val=0.0756, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0739, val=0.0756, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0738, val=0.0755, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0757)

============================================================
📊 Round 173 Summary - Client client_42
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0737, RMSE=0.2715, R²=0.0916
   Val:   Loss=0.0757, RMSE=0.2750, R²=0.1196
============================================================


============================================================
🔄 Round 174 - Client client_42
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0740, val=0.0741 (↓), lr=0.000001
   • Epoch   2/100: train=0.0740, val=0.0741, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0740, val=0.0741, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0740, val=0.0741, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0739, val=0.0741, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0738, val=0.0741, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0741)

============================================================
📊 Round 174 Summary - Client client_42
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0741, RMSE=0.2722, R²=0.1051
   Val:   Loss=0.0741, RMSE=0.2722, R²=0.0420
============================================================


📊 Round 174 Test Metrics:
   Loss: 0.0773, RMSE: 0.2781, MAE: 0.2416, R²: 0.0887

📊 Round 174 Test Metrics:
   Loss: 0.0773, RMSE: 0.2781, MAE: 0.2416, R²: 0.0886

============================================================
🔄 Round 177 - Client client_42
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0741, val=0.0741 (↓), lr=0.000001
   • Epoch   2/100: train=0.0741, val=0.0741, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0741, val=0.0741, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0740, val=0.0740, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0740, val=0.0740, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0739, val=0.0739, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0741)

============================================================
📊 Round 177 Summary - Client client_42
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0741, RMSE=0.2722, R²=0.0896
   Val:   Loss=0.0741, RMSE=0.2722, R²=0.1296
============================================================


============================================================
🔄 Round 178 - Client client_42
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0731, val=0.0777 (↓), lr=0.000001
   • Epoch   2/100: train=0.0731, val=0.0777, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0731, val=0.0777, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0731, val=0.0777, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0731, val=0.0777, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0729, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 178 Summary - Client client_42
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0732, RMSE=0.2706, R²=0.1073
   Val:   Loss=0.0777, RMSE=0.2788, R²=0.0625
============================================================


📊 Round 178 Test Metrics:
   Loss: 0.0773, RMSE: 0.2781, MAE: 0.2415, R²: 0.0887

============================================================
🔄 Round 181 - Client client_42
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0738, val=0.0743 (↓), lr=0.000001
   • Epoch   2/100: train=0.0738, val=0.0743, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0738, val=0.0743, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0738, val=0.0743, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0737, val=0.0743, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0736, val=0.0742, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0743)

============================================================
📊 Round 181 Summary - Client client_42
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0741, RMSE=0.2721, R²=0.0994
   Val:   Loss=0.0743, RMSE=0.2726, R²=0.0936
============================================================


📊 Round 181 Test Metrics:
   Loss: 0.0773, RMSE: 0.2781, MAE: 0.2415, R²: 0.0887

============================================================
🔄 Round 183 - Client client_42
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0757, val=0.0681 (↓), lr=0.000001
   • Epoch   2/100: train=0.0757, val=0.0681, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0757, val=0.0680, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0756, val=0.0680, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0756, val=0.0680, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0755, val=0.0680, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0681)

============================================================
📊 Round 183 Summary - Client client_42
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0756, RMSE=0.2750, R²=0.0897
   Val:   Loss=0.0681, RMSE=0.2609, R²=0.1321
============================================================


============================================================
🔄 Round 184 - Client client_42
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0747, val=0.0720 (↓), lr=0.000001
   • Epoch   2/100: train=0.0747, val=0.0720, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0746, val=0.0720, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0746, val=0.0720, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0746, val=0.0720, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0744, val=0.0719, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0720)

============================================================
📊 Round 184 Summary - Client client_42
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0746, RMSE=0.2732, R²=0.1096
   Val:   Loss=0.0720, RMSE=0.2684, R²=0.0496
============================================================


============================================================
🔄 Round 185 - Client client_42
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0749, val=0.0721 (↓), lr=0.000001
   • Epoch   2/100: train=0.0749, val=0.0720, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0748, val=0.0720, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0748, val=0.0720, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0748, val=0.0720, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0747, val=0.0719, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0721)

============================================================
📊 Round 185 Summary - Client client_42
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0746, RMSE=0.2731, R²=0.0998
   Val:   Loss=0.0721, RMSE=0.2684, R²=0.0928
============================================================


📊 Round 185 Test Metrics:
   Loss: 0.0773, RMSE: 0.2781, MAE: 0.2415, R²: 0.0888

============================================================
🔄 Round 186 - Client client_42
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0727, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0726, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0726, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0726, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0726, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0724, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 186 Summary - Client client_42
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0726, RMSE=0.2695, R²=0.0976
   Val:   Loss=0.0800, RMSE=0.2829, R²=0.0949
============================================================


📊 Round 186 Test Metrics:
   Loss: 0.0773, RMSE: 0.2781, MAE: 0.2415, R²: 0.0888

============================================================
🔄 Round 188 - Client client_42
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0757, val=0.0677 (↓), lr=0.000001
   • Epoch   2/100: train=0.0757, val=0.0677, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0757, val=0.0677, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0757, val=0.0677, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0757, val=0.0677, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0756, val=0.0675, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0677)

============================================================
📊 Round 188 Summary - Client client_42
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0757, RMSE=0.2751, R²=0.0872
   Val:   Loss=0.0677, RMSE=0.2602, R²=0.1452
============================================================


📊 Round 188 Test Metrics:
   Loss: 0.0773, RMSE: 0.2781, MAE: 0.2415, R²: 0.0888

📊 Round 188 Test Metrics:
   Loss: 0.0773, RMSE: 0.2781, MAE: 0.2415, R²: 0.0888

📊 Round 188 Test Metrics:
   Loss: 0.0773, RMSE: 0.2781, MAE: 0.2415, R²: 0.0888

📊 Round 188 Test Metrics:
   Loss: 0.0773, RMSE: 0.2781, MAE: 0.2415, R²: 0.0888

============================================================
🔄 Round 193 - Client client_42
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0738, val=0.0758 (↓), lr=0.000001
   • Epoch   2/100: train=0.0737, val=0.0758, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0737, val=0.0758, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0737, val=0.0758, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0737, val=0.0758, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0736, val=0.0757, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0758)

============================================================
📊 Round 193 Summary - Client client_42
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0737, RMSE=0.2714, R²=0.0960
   Val:   Loss=0.0758, RMSE=0.2754, R²=0.1072
============================================================


📊 Round 193 Test Metrics:
   Loss: 0.0773, RMSE: 0.2781, MAE: 0.2415, R²: 0.0888

============================================================
🔄 Round 196 - Client client_42
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0745, val=0.0726 (↓), lr=0.000001
   • Epoch   2/100: train=0.0745, val=0.0726, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0745, val=0.0726, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0745, val=0.0725, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0744, val=0.0725, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0743, val=0.0724, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0726)

============================================================
📊 Round 196 Summary - Client client_42
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0745, RMSE=0.2729, R²=0.0927
   Val:   Loss=0.0726, RMSE=0.2694, R²=0.1204
============================================================


============================================================
🔄 Round 197 - Client client_42
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0742, val=0.0732 (↓), lr=0.000001
   • Epoch   2/100: train=0.0742, val=0.0732, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0741, val=0.0731, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0741, val=0.0731, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0741, val=0.0731, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0740, val=0.0730, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0732)

============================================================
📊 Round 197 Summary - Client client_42
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0743, RMSE=0.2726, R²=0.1034
   Val:   Loss=0.0732, RMSE=0.2705, R²=0.0761
============================================================


📊 Round 197 Test Metrics:
   Loss: 0.0773, RMSE: 0.2781, MAE: 0.2415, R²: 0.0889

📊 Round 197 Test Metrics:
   Loss: 0.0773, RMSE: 0.2781, MAE: 0.2415, R²: 0.0889

📊 Round 197 Test Metrics:
   Loss: 0.0773, RMSE: 0.2781, MAE: 0.2415, R²: 0.0890

📊 Round 197 Test Metrics:
   Loss: 0.0773, RMSE: 0.2781, MAE: 0.2415, R²: 0.0890

📊 Round 197 Test Metrics:
   Loss: 0.0773, RMSE: 0.2781, MAE: 0.2415, R²: 0.0890

============================================================
🔄 Round 206 - Client client_42
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0731, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0730, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0730, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0730, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0730, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0728, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 206 Summary - Client client_42
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0730, RMSE=0.2702, R²=0.1004
   Val:   Loss=0.0784, RMSE=0.2800, R²=0.0703
============================================================


============================================================
🔄 Round 207 - Client client_42
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0747, val=0.0723 (↓), lr=0.000001
   • Epoch   2/100: train=0.0747, val=0.0722, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0747, val=0.0722, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0747, val=0.0722, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0746, val=0.0722, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0745, val=0.0721, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0723)

============================================================
📊 Round 207 Summary - Client client_42
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0745, RMSE=0.2730, R²=0.0984
   Val:   Loss=0.0723, RMSE=0.2688, R²=0.1001
============================================================


============================================================
🔄 Round 209 - Client client_42
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0731, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0731, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0730, val=0.0782, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0730, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0730, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0729, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 209 Summary - Client client_42
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0730, RMSE=0.2703, R²=0.1096
   Val:   Loss=0.0782, RMSE=0.2797, R²=0.0559
============================================================


📊 Round 209 Test Metrics:
   Loss: 0.0773, RMSE: 0.2780, MAE: 0.2415, R²: 0.0891

============================================================
🔄 Round 210 - Client client_42
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0741, val=0.0743 (↓), lr=0.000001
   • Epoch   2/100: train=0.0741, val=0.0742, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0741, val=0.0742, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0741, val=0.0742, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0741, val=0.0742, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0739, val=0.0741, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0743)

============================================================
📊 Round 210 Summary - Client client_42
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0740, RMSE=0.2721, R²=0.0971
   Val:   Loss=0.0743, RMSE=0.2725, R²=0.0903
============================================================


============================================================
🔄 Round 211 - Client client_42
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0745, val=0.0732 (↓), lr=0.000001
   • Epoch   2/100: train=0.0745, val=0.0732, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0745, val=0.0731, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0744, val=0.0731, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0744, val=0.0731, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0743, val=0.0731, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0732)

============================================================
📊 Round 211 Summary - Client client_42
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0743, RMSE=0.2726, R²=0.1034
   Val:   Loss=0.0732, RMSE=0.2705, R²=0.0782
============================================================


📊 Round 211 Test Metrics:
   Loss: 0.0773, RMSE: 0.2780, MAE: 0.2415, R²: 0.0891

📊 Round 211 Test Metrics:
   Loss: 0.0773, RMSE: 0.2780, MAE: 0.2415, R²: 0.0892

📊 Round 211 Test Metrics:
   Loss: 0.0773, RMSE: 0.2780, MAE: 0.2415, R²: 0.0892

📊 Round 211 Test Metrics:
   Loss: 0.0773, RMSE: 0.2780, MAE: 0.2415, R²: 0.0892

📊 Round 211 Test Metrics:
   Loss: 0.0773, RMSE: 0.2780, MAE: 0.2415, R²: 0.0892

============================================================
🔄 Round 217 - Client client_42
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0735, val=0.0762 (↓), lr=0.000001
   • Epoch   2/100: train=0.0735, val=0.0762, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0735, val=0.0762, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0735, val=0.0762, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0735, val=0.0762, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0733, val=0.0761, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0762)

============================================================
📊 Round 217 Summary - Client client_42
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0735, RMSE=0.2712, R²=0.0973
   Val:   Loss=0.0762, RMSE=0.2761, R²=0.1042
============================================================


============================================================
🔄 Round 218 - Client client_42
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0725, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0724, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0724, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0724, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0724, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0723, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 218 Summary - Client client_42
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0724, RMSE=0.2690, R²=0.0982
   Val:   Loss=0.0809, RMSE=0.2844, R²=0.0890
============================================================


📊 Round 218 Test Metrics:
   Loss: 0.0773, RMSE: 0.2780, MAE: 0.2414, R²: 0.0893

📊 Round 218 Test Metrics:
   Loss: 0.0773, RMSE: 0.2780, MAE: 0.2414, R²: 0.0893

📊 Round 218 Test Metrics:
   Loss: 0.0773, RMSE: 0.2780, MAE: 0.2414, R²: 0.0893

============================================================
🔄 Round 222 - Client client_42
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0756, val=0.0686 (↓), lr=0.000001
   • Epoch   2/100: train=0.0755, val=0.0685, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0755, val=0.0685, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0755, val=0.0685, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0755, val=0.0685, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0754, val=0.0684, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0686)

============================================================
📊 Round 222 Summary - Client client_42
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0754, RMSE=0.2746, R²=0.0942
   Val:   Loss=0.0686, RMSE=0.2618, R²=0.1193
============================================================


📊 Round 222 Test Metrics:
   Loss: 0.0773, RMSE: 0.2780, MAE: 0.2414, R²: 0.0893

============================================================
🔄 Round 223 - Client client_42
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0746, val=0.0711 (↓), lr=0.000001
   • Epoch   2/100: train=0.0746, val=0.0711, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0746, val=0.0711, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0746, val=0.0710, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0746, val=0.0710, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0745, val=0.0709, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0711)

============================================================
📊 Round 223 Summary - Client client_42
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0748, RMSE=0.2735, R²=0.0965
   Val:   Loss=0.0711, RMSE=0.2667, R²=0.0997
============================================================


============================================================
🔄 Round 224 - Client client_42
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0749, val=0.0706 (↓), lr=0.000001
   • Epoch   2/100: train=0.0749, val=0.0706, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0749, val=0.0706, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0749, val=0.0706, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0748, val=0.0706, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0747, val=0.0705, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0706)

============================================================
📊 Round 224 Summary - Client client_42
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0749, RMSE=0.2737, R²=0.0987
   Val:   Loss=0.0706, RMSE=0.2658, R²=0.0990
============================================================


📊 Round 224 Test Metrics:
   Loss: 0.0773, RMSE: 0.2780, MAE: 0.2414, R²: 0.0894

❌ Client client_42 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8687 {grpc_message:"Socket closed", grpc_status:14}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8687 {grpc_message:"Socket closed", grpc_status:14}"
>
