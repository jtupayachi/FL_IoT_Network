[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e9326903-cf05-480a-86f1-9927b0750bcf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9b1df47b-6152-408c-8d3d-d8024441edfe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a21be8a0-1dc1-4425-84f4-25169b90866f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eb7c981b-8cde-4959-a01b-e50a8e831d37
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eb3bb9cf-7b60-4a28-9d80-8c24dce9cb7f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 976886c8-5892-4846-94c6-22fb00dce473
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2aee6987-bcf4-47ad-92ce-9c11e64931df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message abdd09b2-7590-49a5-9a5a-b5a9d9c3a313
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8246f383-1ae0-4201-80fd-2c020107305b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b098d8cf-eb4e-4315-8c1d-4ee3add72420
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5672e9b1-c131-4d31-a99b-4a6d90e0d4dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 20bd98b4-3eb5-46b7-9548-149527addc0f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a60125c0-e0e9-480e-8146-b40e6e6b5869
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eee26b49-b768-474a-a04b-4cac2f607def
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 75e1e74f-d2df-411a-85af-780a440b464d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d8c73dd0-1a9c-46d9-99e9-281b0055e9d9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1c721302-25f9-491e-95c3-6d8956b6bc1d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 34470265-030d-42e8-aa0b-f021a0882530
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3576c4b0-cb32-4811-95e4-84e15d8ae694
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cace99bc-2bb1-465a-9184-5a245a72203f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b911e72f-688f-45c1-a546-d280e33e9984
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 101c763a-6a2a-412a-ba5a-c5d33fbdc17a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2a61c41a-86eb-4b86-aff2-0289e04bb0b7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9ffaaac0-4887-447d-b692-68df9040ee15
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 24cb9971-615d-4340-beb9-aa72b3b81087
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 328edebe-ce4e-4f89-ba2a-c3368643db2c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9b8dcf24-5dbf-4412-8a27-a7f33a49eef7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7d99410b-3bcd-4885-8be9-bc612ddd7437
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 42f7e1bc-79d3-4511-99eb-2e790247ed53
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 90e655e0-7624-45dc-a42a-cc53bb6eabe6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3d171a75-b6e3-4151-b55b-02e64375a890
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9f83be95-dc4b-405f-a929-8a8ce4ef2170
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b6b155d4-e7b5-47e0-854c-711298d267d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 29f85b4e-578e-47b5-93d6-afc0d1ced7ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 14e00aed-6595-45b6-bf15-de8a44872c3a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cc84d429-c603-4ec2-af26-239d31196df5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0dd01b13-6b9a-4092-8cde-c8153b8ef531
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message db9f630e-c682-470e-937d-b937579e439b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 954b7926-bd02-41cc-9d2a-a308c53dfebb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a2cb5084-6761-4f5e-95a9-8dfeb73b02bd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 425dc878-92ea-49cb-888a-d45c7cc03c64
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3a95e900-875c-4cb5-9439-81e483a4f885
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 88a26a69-4e0b-43be-b4c9-4fb4e0393119
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5a5acc77-5a0e-4eb0-bc57-6c05f16b8d93
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 43e36035-b439-4c6d-95be-7449897618e0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9cd9e66a-5a4a-4135-89a5-357f2ab80a47
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9c2d3d93-7bb3-439c-a621-36315ea92bf0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bbdbaeca-c2bd-4d8e-b421-e2ab818cb9fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fb2ea49a-ac69-4312-8572-faa5defbd58e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f702e435-3c48-4821-8586-77493efca8dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 394f9408-6428-48fb-88b7-8071a4a2f33f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2d49c7b8-158d-4f1f-8fc6-cd20b6d0d0cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 90575c0e-e81b-4dfc-8fe5-56a349df3754
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ff8527a0-612c-4180-b6eb-b0e04e3320d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1e66058f-025c-4dba-b328-0a10c5908c5b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d28d5a88-0236-43e1-ada9-b660796c7e04
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message db9781e2-2ad4-42b7-8d95-7e3de0458e32
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c681075e-6503-451c-a485-e434c2685c38
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ef34a1ae-f2b7-427b-a9ea-86b8c7f6d807
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 15af60c5-1693-4d89-8dfb-619cdd9f74f8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 04e54633-08fd-4582-9979-f775dcb657a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 99f7a3c5-a091-4f35-9f49-ccc52aee9f8d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4736c982-9f43-417c-8253-6b58fa75705b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0021084e-4c92-438e-a69d-df03ce670a91
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0b38d773-25a0-4f1e-9e12-04adde8d8b05
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2528132b-d300-4b71-9546-aaa58da84492
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cc3392b0-ac92-4b1b-8db0-c80f28cb7499
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fbd28105-99fc-42e7-858a-bf536c85bc71
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 612e1f16-2ec7-450a-bb7f-4b27b7b604a3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c7e62fdc-1414-405a-8e29-c5d46cc13ce9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f73440e5-d99b-4912-80c4-44ee0b18a484
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 76b19539-267e-47c4-9070-9ee2d38fadaf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a56716d9-1b5b-4654-9cc8-9e819e6e06d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b972d5d1-0a76-46d6-bb1b-ff2de14dc526
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 982c92bb-9833-428e-90a1-ae47d921b8d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f16c22ba-4844-4445-a2e8-ac57b2c2f83e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8bd9ee83-d4ec-42db-bbac-229fa68ab413
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c5d2b031-fd15-4437-8a1a-22049ebb97a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 533dd5ac-78fb-4324-ad36-8a0a836ef7dd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 49b832e4-0529-4c7e-bf37-606320ff53e9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6724ed76-07a9-4891-93c9-96f3964c65fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dd5a438f-07e1-45bb-acf9-649098d6a26d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 46cf0155-ec94-4cf4-88e6-b8c405b3b456
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d413b23f-dc6d-4e78-9d9c-8d3ea0f29e38
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e72c53fc-b41d-40a7-a9ca-8f5594dd8c27
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3d32e76e-683c-4619-adb4-99b62fc76f9a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 622d5859-76b1-414e-9644-a4e044bb4988
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e3877745-65c5-47bc-b53c-07c262806f3a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aed3e97d-98a7-4459-9b77-21433e8a1553
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fdc4c46e-0f05-4583-adf3-702e65af0d82
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 54d6a412-feef-4c95-9cdb-9f181c3bc3bd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 119f8025-f8ad-4fe0-8a0d-30d6cac82fd4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2a113336-b81c-483c-966d-d71edf06deac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 12c6b29b-fde9-4046-bca9-e5f4c059e46e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d689c15e-ce8b-4586-8e03-18408a4ab471
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 74688055-51d7-478a-8a05-c17ed294a739
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fd1d6165-fb78-41db-a2e0-f93a4292224e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d02c1aa5-8985-4d28-b145-cc05e1e480bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 733adfb4-8128-419e-90b0-9845a92b2acc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0f1d6b2b-b8c5-4bcb-a85b-22ca7b9b032a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9fdcf54c-f006-492f-bf00-59190f3ceded
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e6c39d59-207d-44d8-a4b1-3075b4e2880f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 81b1002a-a6b1-40bf-9823-ef4617bdb6fb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 495e9294-08d0-491d-bddf-0c5c3c577e46
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message edae4700-05c6-4760-9e43-e0295a399cff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 99cdd8fb-6ded-47c4-8014-0dc55b7032e9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message beead2d1-1efd-4de6-a4b1-a57883c64c37
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ce1b0fd8-17b4-40c6-8868-597a250ca179
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ec352d11-6bf9-4a59-af6b-f57ada7c9f2d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 22739421-4692-438e-a960-b4a7a8a20372
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d23335ed-da1f-48b6-9736-e1aea5b3b755
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f2748348-a773-4c53-adde-1e5b053af758
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aa4b2723-bb41-4105-9ccc-98592859ed4a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9c8ac2a5-412b-4291-9b4a-f2602e2c3a84
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9ad57ec8-c3aa-42b7-ba00-7141239703ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0635e266-0b6a-484f-8a4d-806ca983c97e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4cfd3a79-23ba-4d8d-b8de-a05a7d765f25
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dac79b38-b342-4f88-9310-f49f8a331e13
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1bd3deae-ec55-4db2-ab6c-a4726c4a8fbd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e9213235-b83d-41a7-bf95-e2e15607914c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 805f05ef-02f0-4677-9e29-18d1409ca0e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4d0c7262-eb09-4de8-a2a1-69ea624378d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 49d7bb16-e131-4651-812d-2027d85b3cbc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 46efd625-ed44-4bb0-b7ed-c330138b47c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6fc7aca3-6c71-48d7-b3aa-124cd7149414
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5421a1e5-0016-4dab-8717-780a6f8d9549
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4a48fd5d-9c98-43d7-8417-5e443b024493
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 81202f8f-9bcd-4998-a72f-142ab983b378
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4bd31e8c-c483-4e8c-ab3e-d86ab5d3b8a0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message efdce686-a392-4ac0-9745-5c57a8bb1143
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 861f062c-8bd6-4ea4-981a-b3f5292e180d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e70dbf4b-0cd9-4133-957b-77ab8e593f4f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 01e24660-ceac-4d2b-ac6d-6e8516723d3d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 852c252b-11fd-4254-a1d5-3de4823c7244
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6146cc20-c63d-4db0-9329-84d687541768
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 39f7a949-b566-4ed8-af2b-578b51261001
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1da41aac-67e9-44aa-9460-26b02916b955
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4023ce38-a1c1-4910-81a5-34c4b358a666
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 417b1c50-5767-4b5c-b1c4-5fbf3e8aa67f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ab23dc11-0fbc-4184-b624-d3db9608dfcf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f5468f79-dcb2-4fbb-965a-14c3deadbadb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a3f16228-483f-4d28-ae7b-8e6c00348af6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 170947c7-589d-4e7e-8755-69462843e626
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e4d41151-f798-4103-b413-2e372acc674f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 98e5c8f5-350d-4f8b-8228-3b8693b6e07a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 700bac40-fc8f-47e5-adda-3d3c7ce4a667
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0edd5bf3-8733-4d81-9d47-8e375b2cadb4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 41082b35-9de2-427b-9e48-989230aa76df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8ee7498c-c313-4d71-a8fe-44df6e005d40
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cf575213-6746-4242-bf53-543d75c8e86b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7ac4c1ff-3e6c-4b35-b33c-a928334e41dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 86381c01-d2d4-4616-aa5e-8ad205684219
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2a749a89-bc67-4b23-aadd-2ce33c6b73d9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f729837d-1b82-4d61-b399-6593fa2874b1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fe64fab4-0fb6-453f-adeb-4abba2c1ef7f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 14862fe3-6146-4d25-8989-5cbdce859f10
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 54dfeb55-ece8-4cc2-a8b4-5b4d790b7277
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 598801ba-0b6b-41d3-9f32-5d7fb3bcd924
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6f7790e1-d561-4049-b391-4041e2b6ae5f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aabbd9d7-b90c-4e67-ae19-9970ddba05b6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 00699ec1-cb00-4a3d-b482-ca6a0ae78961
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f6906b9b-9bc8-44ec-acde-15b72f6453e0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ef9eebd1-1588-4531-818b-1473a3b3c685
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 945d6942-4cb3-4460-bbe3-fc40f12145ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b2097975-483c-42ba-81d4-e6baed749f3f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 62a64234-4949-4dbb-8eb1-40707e643928
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8cf02338-6955-4755-b0dd-d74eea512eef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 940ee87b-c545-43d5-945d-27f2fa37fa79
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3130de5c-3ee3-433f-826f-e9d999595947
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e03c74fe-b690-4872-b29c-400074e94e59
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message babd5d8a-9869-4776-9782-a5d24f5f5830
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 48b94901-a68a-4ff7-a37b-52e072b1ce21
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a2fd6c02-3513-4650-bbfd-ddd89aa776a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message efff7f08-9a7b-429c-9142-437bba07999d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5cdf9c2c-1183-4895-84eb-d5ce4468cd83
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e0b1e649-2c1d-4c83-95b1-be11dca7d459
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 49efa007-eaba-414b-b372-d755f5f1dccb
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8687 {grpc_message:"Socket closed", grpc_status:14}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_43
Server: localhost:8687
Algorithm: FEDAVG
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_43
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_43/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_43/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_43/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_43/test_labels.txt

📊 Raw data loaded:
   Train: X=(877, 24), y=(877,)
   Test:  X=(220, 24), y=(220,)

⚠️  Limiting training data: 877 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  211 samples, 5 features
✅ Client client_43 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

============================================================
🔄 Round 5 - Client client_43
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0874 (↓), lr=0.001000
   • Epoch   2/100: train=0.0807, val=0.0872, patience=1/15, lr=0.001000
   • Epoch   3/100: train=0.0806, val=0.0872, patience=2/15, lr=0.001000
   • Epoch   4/100: train=0.0804, val=0.0872, patience=3/15, lr=0.001000
   • Epoch   5/100: train=0.0802, val=0.0873, patience=4/15, lr=0.001000
   📉 Epoch 8: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0774, val=0.0884, patience=10/15, lr=0.000500
   📉 Epoch 16: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0874)

============================================================
📊 Round 5 Summary - Client client_43
   Epochs: 16/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=0.0085
   Val:   Loss=0.0874, RMSE=0.2957, R²=-0.0084
============================================================


📊 Round 5 Test Metrics:
   Loss: 0.0865, RMSE: 0.2941, MAE: 0.2529, R²: -0.0122

============================================================
🔄 Round 7 - Client client_43
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0778 (↓), lr=0.000250
   ✓ Epoch   2/100: train=0.0839, val=0.0771 (↓), lr=0.000250
   • Epoch   3/100: train=0.0836, val=0.0770, patience=1/15, lr=0.000250
   • Epoch   4/100: train=0.0834, val=0.0768, patience=2/15, lr=0.000250
   • Epoch   5/100: train=0.0832, val=0.0767, patience=3/15, lr=0.000250
   • Epoch  11/100: train=0.0823, val=0.0765, patience=3/15, lr=0.000250
   📉 Epoch 18: LR reduced 0.000250 → 0.000125
   • Epoch  21/100: train=0.0811, val=0.0763, patience=13/15, lr=0.000125

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0766)

============================================================
📊 Round 7 Summary - Client client_43
   Epochs: 23/100 (early stopped)
   LR: 0.000250 → 0.000125 (1 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=0.0172
   Val:   Loss=0.0766, RMSE=0.2768, R²=-0.0163
============================================================


📊 Round 7 Test Metrics:
   Loss: 0.0865, RMSE: 0.2940, MAE: 0.2521, R²: -0.0117

============================================================
🔄 Round 8 - Client client_43
   Epochs: 100, Batch: 32, LR: 0.000125
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0814 (↓), lr=0.000125
   • Epoch   2/100: train=0.0832, val=0.0812, patience=1/15, lr=0.000125
   📉 Epoch 3: LR reduced 0.000125 → 0.000063
   • Epoch   3/100: train=0.0830, val=0.0815, patience=2/15, lr=0.000063
   • Epoch   4/100: train=0.0827, val=0.0815, patience=3/15, lr=0.000063
   • Epoch   5/100: train=0.0826, val=0.0816, patience=4/15, lr=0.000063
   📉 Epoch 11: LR reduced 0.000063 → 0.000031
   • Epoch  11/100: train=0.0822, val=0.0819, patience=10/15, lr=0.000031

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 8 Summary - Client client_43
   Epochs: 16/100 (early stopped)
   LR: 0.000125 → 0.000031 (2 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=-0.0091
   Val:   Loss=0.0814, RMSE=0.2853, R²=0.0006
============================================================


📊 Round 8 Test Metrics:
   Loss: 0.0867, RMSE: 0.2945, MAE: 0.2524, R²: -0.0147

============================================================
🔄 Round 10 - Client client_43
   Epochs: 100, Batch: 32, LR: 0.000031
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0865 (↓), lr=0.000031
   • Epoch   2/100: train=0.0821, val=0.0866, patience=1/15, lr=0.000031
   📉 Epoch 3: LR reduced 0.000031 → 0.000016
   • Epoch   3/100: train=0.0820, val=0.0868, patience=2/15, lr=0.000016
   • Epoch   4/100: train=0.0818, val=0.0868, patience=3/15, lr=0.000016
   • Epoch   5/100: train=0.0818, val=0.0869, patience=4/15, lr=0.000016
   📉 Epoch 11: LR reduced 0.000016 → 0.000008
   • Epoch  11/100: train=0.0816, val=0.0869, patience=10/15, lr=0.000008

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0865)

============================================================
📊 Round 10 Summary - Client client_43
   Epochs: 16/100 (early stopped)
   LR: 0.000031 → 0.000008 (2 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=-0.0020
   Val:   Loss=0.0865, RMSE=0.2941, R²=-0.0592
============================================================


📊 Round 10 Test Metrics:
   Loss: 0.0866, RMSE: 0.2942, MAE: 0.2523, R²: -0.0128

============================================================
🔄 Round 11 - Client client_43
   Epochs: 100, Batch: 32, LR: 0.000008
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0780 (↓), lr=0.000008
   • Epoch   2/100: train=0.0842, val=0.0780, patience=1/15, lr=0.000008
   📉 Epoch 3: LR reduced 0.000008 → 0.000004
   • Epoch   3/100: train=0.0842, val=0.0780, patience=2/15, lr=0.000004
   • Epoch   4/100: train=0.0841, val=0.0780, patience=3/15, lr=0.000004
   • Epoch   5/100: train=0.0841, val=0.0781, patience=4/15, lr=0.000004
   📉 Epoch 11: LR reduced 0.000004 → 0.000002
   • Epoch  11/100: train=0.0840, val=0.0781, patience=10/15, lr=0.000002

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 11 Summary - Client client_43
   Epochs: 16/100 (early stopped)
   LR: 0.000008 → 0.000002 (2 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=-0.0088
   Val:   Loss=0.0780, RMSE=0.2793, R²=-0.0127
============================================================


============================================================
🔄 Round 12 - Client client_43
   Epochs: 100, Batch: 32, LR: 0.000002
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0936 (↓), lr=0.000002
   • Epoch   2/100: train=0.0805, val=0.0936, patience=1/15, lr=0.000002
   📉 Epoch 3: LR reduced 0.000002 → 0.000001
   • Epoch   3/100: train=0.0805, val=0.0937, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0937, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0937, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0937, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0936)

============================================================
📊 Round 12 Summary - Client client_43
   Epochs: 16/100 (early stopped)
   LR: 0.000002 → 0.000001 (1 reductions)
   Train: Loss=0.0803, RMSE=0.2833, R²=-0.0068
   Val:   Loss=0.0936, RMSE=0.3060, R²=-0.0193
============================================================


📊 Round 12 Test Metrics:
   Loss: 0.0866, RMSE: 0.2943, MAE: 0.2525, R²: -0.0138

📊 Round 12 Test Metrics:
   Loss: 0.0866, RMSE: 0.2943, MAE: 0.2525, R²: -0.0135

📊 Round 12 Test Metrics:
   Loss: 0.0865, RMSE: 0.2942, MAE: 0.2526, R²: -0.0127

📊 Round 12 Test Metrics:
   Loss: 0.0866, RMSE: 0.2943, MAE: 0.2527, R²: -0.0137

============================================================
🔄 Round 20 - Client client_43
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0778, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0777, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0777, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0777, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0777, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 20 Summary - Client client_43
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=-0.0088
   Val:   Loss=0.0778, RMSE=0.2789, R²=-0.0127
============================================================


============================================================
🔄 Round 21 - Client client_43
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 21 Summary - Client client_43
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2894, R²=-0.0068
   Val:   Loss=0.0794, RMSE=0.2818, R²=-0.0248
============================================================


============================================================
🔄 Round 24 - Client client_43
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0868 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0868, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0868, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0868, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0868, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0868, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0868)

============================================================
📊 Round 24 Summary - Client client_43
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2861, R²=-0.0096
   Val:   Loss=0.0868, RMSE=0.2947, R²=-0.0157
============================================================


============================================================
🔄 Round 25 - Client client_43
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 25 Summary - Client client_43
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=-0.0062
   Val:   Loss=0.0819, RMSE=0.2862, R²=-0.0162
============================================================


📊 Round 25 Test Metrics:
   Loss: 0.0866, RMSE: 0.2942, MAE: 0.2527, R²: -0.0130

📊 Round 25 Test Metrics:
   Loss: 0.0866, RMSE: 0.2942, MAE: 0.2527, R²: -0.0130

============================================================
🔄 Round 28 - Client client_43
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 28 Summary - Client client_43
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=-0.0060
   Val:   Loss=0.0814, RMSE=0.2854, R²=-0.0270
============================================================


📊 Round 28 Test Metrics:
   Loss: 0.0866, RMSE: 0.2942, MAE: 0.2527, R²: -0.0131

============================================================
🔄 Round 29 - Client client_43
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0950 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0950, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0950, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0950, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0950, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0950, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0950)

============================================================
📊 Round 29 Summary - Client client_43
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2826, R²=-0.0144
   Val:   Loss=0.0950, RMSE=0.3081, R²=0.0131
============================================================


📊 Round 29 Test Metrics:
   Loss: 0.0866, RMSE: 0.2942, MAE: 0.2527, R²: -0.0130

============================================================
🔄 Round 31 - Client client_43
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0770 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0770, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0770, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0770, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0770, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0770, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0770)

============================================================
📊 Round 31 Summary - Client client_43
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2904, R²=-0.0094
   Val:   Loss=0.0770, RMSE=0.2776, R²=-0.0020
============================================================


============================================================
🔄 Round 33 - Client client_43
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0863 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 33 Summary - Client client_43
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=-0.0061
   Val:   Loss=0.0863, RMSE=0.2938, R²=-0.0150
============================================================


📊 Round 33 Test Metrics:
   Loss: 0.0866, RMSE: 0.2942, MAE: 0.2527, R²: -0.0129

============================================================
🔄 Round 36 - Client client_43
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 36 Summary - Client client_43
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=-0.0117
   Val:   Loss=0.0783, RMSE=0.2798, R²=0.0072
============================================================


📊 Round 36 Test Metrics:
   Loss: 0.0866, RMSE: 0.2942, MAE: 0.2527, R²: -0.0129

📊 Round 36 Test Metrics:
   Loss: 0.0866, RMSE: 0.2942, MAE: 0.2527, R²: -0.0129

📊 Round 36 Test Metrics:
   Loss: 0.0866, RMSE: 0.2942, MAE: 0.2526, R²: -0.0128

📊 Round 36 Test Metrics:
   Loss: 0.0866, RMSE: 0.2942, MAE: 0.2526, R²: -0.0128

============================================================
🔄 Round 41 - Client client_43
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 41 Summary - Client client_43
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=-0.0071
   Val:   Loss=0.0819, RMSE=0.2862, R²=-0.0160
============================================================


============================================================
🔄 Round 42 - Client client_43
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0887 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0887, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0887, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0887, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0887, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0887, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0887)

============================================================
📊 Round 42 Summary - Client client_43
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=-0.0076
   Val:   Loss=0.0887, RMSE=0.2979, R²=-0.0114
============================================================


📊 Round 42 Test Metrics:
   Loss: 0.0865, RMSE: 0.2942, MAE: 0.2526, R²: -0.0127

============================================================
🔄 Round 44 - Client client_43
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 44 Summary - Client client_43
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=-0.0106
   Val:   Loss=0.0803, RMSE=0.2835, R²=0.0023
============================================================


📊 Round 44 Test Metrics:
   Loss: 0.0865, RMSE: 0.2942, MAE: 0.2526, R²: -0.0127

============================================================
🔄 Round 46 - Client client_43
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 46 Summary - Client client_43
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2875, R²=-0.0078
   Val:   Loss=0.0836, RMSE=0.2891, R²=-0.0096
============================================================


📊 Round 46 Test Metrics:
   Loss: 0.0865, RMSE: 0.2942, MAE: 0.2526, R²: -0.0126

============================================================
🔄 Round 52 - Client client_43
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 52 Summary - Client client_43
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=-0.0110
   Val:   Loss=0.0818, RMSE=0.2860, R²=-0.0016
============================================================


📊 Round 52 Test Metrics:
   Loss: 0.0865, RMSE: 0.2942, MAE: 0.2526, R²: -0.0126

============================================================
🔄 Round 54 - Client client_43
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0876 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0876, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0876, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0876, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0875, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0875, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0876)

============================================================
📊 Round 54 Summary - Client client_43
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=-0.0031
   Val:   Loss=0.0876, RMSE=0.2959, R²=-0.0260
============================================================


📊 Round 54 Test Metrics:
   Loss: 0.0865, RMSE: 0.2942, MAE: 0.2526, R²: -0.0126

============================================================
🔄 Round 57 - Client client_43
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0778, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0778, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0778, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0778, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0778, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 57 Summary - Client client_43
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=-0.0079
   Val:   Loss=0.0778, RMSE=0.2789, R²=-0.0086
============================================================


============================================================
🔄 Round 58 - Client client_43
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 58 Summary - Client client_43
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2875, R²=-0.0088
   Val:   Loss=0.0835, RMSE=0.2890, R²=-0.0039
============================================================


============================================================
🔄 Round 60 - Client client_43
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 60 Summary - Client client_43
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2880, R²=-0.0078
   Val:   Loss=0.0824, RMSE=0.2870, R²=-0.0077
============================================================


📊 Round 60 Test Metrics:
   Loss: 0.0865, RMSE: 0.2942, MAE: 0.2526, R²: -0.0126

📊 Round 60 Test Metrics:
   Loss: 0.0865, RMSE: 0.2942, MAE: 0.2526, R²: -0.0126

============================================================
🔄 Round 65 - Client client_43
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 65 Summary - Client client_43
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=-0.0120
   Val:   Loss=0.0833, RMSE=0.2886, R²=-0.0072
============================================================


============================================================
🔄 Round 66 - Client client_43
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 66 Summary - Client client_43
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=-0.0052
   Val:   Loss=0.0815, RMSE=0.2855, R²=-0.0292
============================================================


📊 Round 66 Test Metrics:
   Loss: 0.0865, RMSE: 0.2941, MAE: 0.2526, R²: -0.0124

📊 Round 66 Test Metrics:
   Loss: 0.0865, RMSE: 0.2941, MAE: 0.2526, R²: -0.0124

============================================================
🔄 Round 68 - Client client_43
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0885 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0884, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0884, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0884, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0884, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0884, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0885)

============================================================
📊 Round 68 Summary - Client client_43
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2854, R²=-0.0050
   Val:   Loss=0.0885, RMSE=0.2974, R²=-0.0203
============================================================


============================================================
🔄 Round 69 - Client client_43
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 69 Summary - Client client_43
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=-0.0130
   Val:   Loss=0.0860, RMSE=0.2933, R²=0.0059
============================================================


📊 Round 69 Test Metrics:
   Loss: 0.0865, RMSE: 0.2941, MAE: 0.2526, R²: -0.0123

📊 Round 69 Test Metrics:
   Loss: 0.0865, RMSE: 0.2941, MAE: 0.2526, R²: -0.0123

============================================================
🔄 Round 71 - Client client_43
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0771 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0771, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0771, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0771, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0771, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0771, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0771)

============================================================
📊 Round 71 Summary - Client client_43
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=-0.0097
   Val:   Loss=0.0771, RMSE=0.2776, R²=-0.0005
============================================================


============================================================
🔄 Round 72 - Client client_43
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 72 Summary - Client client_43
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=-0.0057
   Val:   Loss=0.0846, RMSE=0.2909, R²=-0.0169
============================================================


============================================================
🔄 Round 74 - Client client_43
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 74 Summary - Client client_43
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2882, R²=-0.0101
   Val:   Loss=0.0820, RMSE=0.2864, R²=-0.0073
============================================================


📊 Round 74 Test Metrics:
   Loss: 0.0865, RMSE: 0.2941, MAE: 0.2525, R²: -0.0121

📊 Round 74 Test Metrics:
   Loss: 0.0865, RMSE: 0.2941, MAE: 0.2525, R²: -0.0121

============================================================
🔄 Round 81 - Client client_43
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 81 Summary - Client client_43
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=-0.0094
   Val:   Loss=0.0854, RMSE=0.2922, R²=-0.0109
============================================================


============================================================
🔄 Round 83 - Client client_43
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0774 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0774, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0774, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0774, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0774, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0774, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0774)

============================================================
📊 Round 83 Summary - Client client_43
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2901, R²=-0.0030
   Val:   Loss=0.0774, RMSE=0.2782, R²=-0.0325
============================================================


📊 Round 83 Test Metrics:
   Loss: 0.0865, RMSE: 0.2941, MAE: 0.2525, R²: -0.0120

📊 Round 83 Test Metrics:
   Loss: 0.0865, RMSE: 0.2941, MAE: 0.2525, R²: -0.0120

============================================================
🔄 Round 87 - Client client_43
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 87 Summary - Client client_43
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=-0.0079
   Val:   Loss=0.0861, RMSE=0.2934, R²=-0.0087
============================================================


📊 Round 87 Test Metrics:
   Loss: 0.0865, RMSE: 0.2941, MAE: 0.2525, R²: -0.0119

============================================================
🔄 Round 90 - Client client_43
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0728 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0728, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0728, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0728, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0728, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0728, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0728)

============================================================
📊 Round 90 Summary - Client client_43
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2921, R²=-0.0127
   Val:   Loss=0.0728, RMSE=0.2699, R²=0.0148
============================================================


📊 Round 90 Test Metrics:
   Loss: 0.0865, RMSE: 0.2941, MAE: 0.2525, R²: -0.0118

============================================================
🔄 Round 95 - Client client_43
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 95 Summary - Client client_43
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=-0.0075
   Val:   Loss=0.0832, RMSE=0.2884, R²=-0.0117
============================================================


📊 Round 95 Test Metrics:
   Loss: 0.0865, RMSE: 0.2940, MAE: 0.2525, R²: -0.0117

📊 Round 95 Test Metrics:
   Loss: 0.0865, RMSE: 0.2940, MAE: 0.2525, R²: -0.0117

============================================================
🔄 Round 97 - Client client_43
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 97 Summary - Client client_43
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=-0.0051
   Val:   Loss=0.0832, RMSE=0.2885, R²=-0.0177
============================================================


============================================================
🔄 Round 99 - Client client_43
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0933 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0933, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0933, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0933, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0933, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0933, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0933)

============================================================
📊 Round 99 Summary - Client client_43
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=-0.0123
   Val:   Loss=0.0933, RMSE=0.3055, R²=0.0051
============================================================


📊 Round 99 Test Metrics:
   Loss: 0.0864, RMSE: 0.2940, MAE: 0.2524, R²: -0.0115

============================================================
🔄 Round 104 - Client client_43
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0876 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0876, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0876, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0876, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0876, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0875, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0876)

============================================================
📊 Round 104 Summary - Client client_43
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=-0.0111
   Val:   Loss=0.0876, RMSE=0.2959, R²=0.0008
============================================================


📊 Round 104 Test Metrics:
   Loss: 0.0864, RMSE: 0.2940, MAE: 0.2524, R²: -0.0115

============================================================
🔄 Round 105 - Client client_43
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 105 Summary - Client client_43
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=-0.0077
   Val:   Loss=0.0800, RMSE=0.2829, R²=-0.0189
============================================================


📊 Round 105 Test Metrics:
   Loss: 0.0864, RMSE: 0.2940, MAE: 0.2524, R²: -0.0115

📊 Round 105 Test Metrics:
   Loss: 0.0864, RMSE: 0.2940, MAE: 0.2524, R²: -0.0114

📊 Round 105 Test Metrics:
   Loss: 0.0864, RMSE: 0.2940, MAE: 0.2524, R²: -0.0114

============================================================
🔄 Round 108 - Client client_43
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0772 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0772, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0772, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0772, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0772, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0773, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 108 Summary - Client client_43
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=0.0004
   Val:   Loss=0.0772, RMSE=0.2778, R²=-0.0861
============================================================


📊 Round 108 Test Metrics:
   Loss: 0.0864, RMSE: 0.2940, MAE: 0.2524, R²: -0.0114

============================================================
🔄 Round 109 - Client client_43
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 109 Summary - Client client_43
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=-0.0047
   Val:   Loss=0.0853, RMSE=0.2921, R²=-0.0252
============================================================


📊 Round 109 Test Metrics:
   Loss: 0.0864, RMSE: 0.2940, MAE: 0.2524, R²: -0.0114

📊 Round 109 Test Metrics:
   Loss: 0.0864, RMSE: 0.2940, MAE: 0.2524, R²: -0.0114

📊 Round 109 Test Metrics:
   Loss: 0.0864, RMSE: 0.2940, MAE: 0.2524, R²: -0.0113

============================================================
🔄 Round 114 - Client client_43
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 114 Summary - Client client_43
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=-0.0080
   Val:   Loss=0.0826, RMSE=0.2873, R²=-0.0051
============================================================


============================================================
🔄 Round 116 - Client client_43
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 116 Summary - Client client_43
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=-0.0082
   Val:   Loss=0.0843, RMSE=0.2904, R²=-0.0035
============================================================


============================================================
🔄 Round 117 - Client client_43
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 117 Summary - Client client_43
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=-0.0127
   Val:   Loss=0.0827, RMSE=0.2876, R²=0.0024
============================================================


============================================================
🔄 Round 118 - Client client_43
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 118 Summary - Client client_43
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=-0.0086
   Val:   Loss=0.0808, RMSE=0.2842, R²=-0.0096
============================================================


============================================================
🔄 Round 119 - Client client_43
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0877 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0877, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0877, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0877, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0876, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0876, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0877)

============================================================
📊 Round 119 Summary - Client client_43
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=-0.0168
   Val:   Loss=0.0877, RMSE=0.2961, R²=0.0250
============================================================


📊 Round 119 Test Metrics:
   Loss: 0.0864, RMSE: 0.2939, MAE: 0.2524, R²: -0.0111

============================================================
🔄 Round 124 - Client client_43
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 124 Summary - Client client_43
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=-0.0065
   Val:   Loss=0.0802, RMSE=0.2831, R²=-0.0099
============================================================


📊 Round 124 Test Metrics:
   Loss: 0.0864, RMSE: 0.2939, MAE: 0.2524, R²: -0.0111

============================================================
🔄 Round 125 - Client client_43
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0913 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0913, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0913, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0913, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0913, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0913, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0913)

============================================================
📊 Round 125 Summary - Client client_43
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2840, R²=-0.0073
   Val:   Loss=0.0913, RMSE=0.3022, R²=-0.0082
============================================================


📊 Round 125 Test Metrics:
   Loss: 0.0864, RMSE: 0.2939, MAE: 0.2523, R²: -0.0110

============================================================
🔄 Round 127 - Client client_43
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0755 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0755, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0755, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0755, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0755, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0754, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0755)

============================================================
📊 Round 127 Summary - Client client_43
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=-0.0096
   Val:   Loss=0.0755, RMSE=0.2748, R²=0.0011
============================================================


📊 Round 127 Test Metrics:
   Loss: 0.0864, RMSE: 0.2939, MAE: 0.2523, R²: -0.0110

📊 Round 127 Test Metrics:
   Loss: 0.0864, RMSE: 0.2939, MAE: 0.2523, R²: -0.0110

============================================================
🔄 Round 130 - Client client_43
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 130 Summary - Client client_43
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=-0.0096
   Val:   Loss=0.0824, RMSE=0.2870, R²=0.0004
============================================================


============================================================
🔄 Round 133 - Client client_43
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 133 Summary - Client client_43
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=-0.0041
   Val:   Loss=0.0805, RMSE=0.2837, R²=-0.0249
============================================================


============================================================
🔄 Round 137 - Client client_43
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0866 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0865, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0865, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0865, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0865, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0866)

============================================================
📊 Round 137 Summary - Client client_43
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2861, R²=-0.0072
   Val:   Loss=0.0866, RMSE=0.2942, R²=-0.0089
============================================================


============================================================
🔄 Round 138 - Client client_43
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0752 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0752, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0752, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0752, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0752, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0752, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0752)

============================================================
📊 Round 138 Summary - Client client_43
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=-0.0138
   Val:   Loss=0.0752, RMSE=0.2742, R²=0.0194
============================================================


============================================================
🔄 Round 140 - Client client_43
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 140 Summary - Client client_43
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=-0.0117
   Val:   Loss=0.0781, RMSE=0.2794, R²=0.0104
============================================================


📊 Round 140 Test Metrics:
   Loss: 0.0864, RMSE: 0.2939, MAE: 0.2523, R²: -0.0109

📊 Round 140 Test Metrics:
   Loss: 0.0864, RMSE: 0.2939, MAE: 0.2523, R²: -0.0108

============================================================
🔄 Round 145 - Client client_43
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 145 Summary - Client client_43
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=-0.0031
   Val:   Loss=0.0799, RMSE=0.2826, R²=-0.0255
============================================================


📊 Round 145 Test Metrics:
   Loss: 0.0864, RMSE: 0.2939, MAE: 0.2523, R²: -0.0108

============================================================
🔄 Round 147 - Client client_43
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0873 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0873, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0873, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0873, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0873, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0872, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0873)

============================================================
📊 Round 147 Summary - Client client_43
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=-0.0050
   Val:   Loss=0.0873, RMSE=0.2954, R²=-0.0159
============================================================


============================================================
🔄 Round 149 - Client client_43
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 149 Summary - Client client_43
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=-0.0060
   Val:   Loss=0.0803, RMSE=0.2834, R²=-0.0211
============================================================


============================================================
🔄 Round 154 - Client client_43
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 154 Summary - Client client_43
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2866, R²=-0.0070
   Val:   Loss=0.0854, RMSE=0.2923, R²=-0.0183
============================================================


============================================================
🔄 Round 156 - Client client_43
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 156 Summary - Client client_43
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=-0.0031
   Val:   Loss=0.0787, RMSE=0.2806, R²=-0.0273
============================================================


📊 Round 156 Test Metrics:
   Loss: 0.0864, RMSE: 0.2939, MAE: 0.2522, R²: -0.0106

============================================================
🔄 Round 157 - Client client_43
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 157 Summary - Client client_43
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=-0.0047
   Val:   Loss=0.0823, RMSE=0.2869, R²=-0.0191
============================================================


📊 Round 157 Test Metrics:
   Loss: 0.0864, RMSE: 0.2939, MAE: 0.2522, R²: -0.0106

📊 Round 157 Test Metrics:
   Loss: 0.0864, RMSE: 0.2939, MAE: 0.2522, R²: -0.0106

============================================================
🔄 Round 162 - Client client_43
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 162 Summary - Client client_43
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=-0.0031
   Val:   Loss=0.0827, RMSE=0.2875, R²=-0.0234
============================================================


============================================================
🔄 Round 164 - Client client_43
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0886 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0886, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0886, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0886, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0886, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0887, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0886)

============================================================
📊 Round 164 Summary - Client client_43
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2852, R²=-0.0059
   Val:   Loss=0.0886, RMSE=0.2977, R²=-0.0187
============================================================


📊 Round 164 Test Metrics:
   Loss: 0.0864, RMSE: 0.2939, MAE: 0.2522, R²: -0.0106

============================================================
🔄 Round 166 - Client client_43
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0778, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0778, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0778, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0778, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0778, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 166 Summary - Client client_43
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2899, R²=0.0003
   Val:   Loss=0.0778, RMSE=0.2789, R²=-0.0433
============================================================


📊 Round 166 Test Metrics:
   Loss: 0.0864, RMSE: 0.2939, MAE: 0.2522, R²: -0.0105

📊 Round 166 Test Metrics:
   Loss: 0.0864, RMSE: 0.2939, MAE: 0.2522, R²: -0.0105

============================================================
🔄 Round 169 - Client client_43
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 169 Summary - Client client_43
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=-0.0146
   Val:   Loss=0.0818, RMSE=0.2860, R²=0.0012
============================================================


============================================================
🔄 Round 172 - Client client_43
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 172 Summary - Client client_43
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=-0.0046
   Val:   Loss=0.0834, RMSE=0.2889, R²=-0.0391
============================================================


📊 Round 172 Test Metrics:
   Loss: 0.0863, RMSE: 0.2939, MAE: 0.2522, R²: -0.0104

============================================================
🔄 Round 176 - Client client_43
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 176 Summary - Client client_43
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=-0.0038
   Val:   Loss=0.0787, RMSE=0.2805, R²=-0.0200
============================================================


============================================================
🔄 Round 178 - Client client_43
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 178 Summary - Client client_43
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=-0.0059
   Val:   Loss=0.0861, RMSE=0.2935, R²=-0.0139
============================================================


📊 Round 178 Test Metrics:
   Loss: 0.0863, RMSE: 0.2938, MAE: 0.2522, R²: -0.0103

============================================================
🔄 Round 180 - Client client_43
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 180 Summary - Client client_43
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=-0.0061
   Val:   Loss=0.0836, RMSE=0.2891, R²=-0.0125
============================================================


============================================================
🔄 Round 181 - Client client_43
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0773, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0773, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 181 Summary - Client client_43
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2901, R²=-0.0108
   Val:   Loss=0.0773, RMSE=0.2780, R²=0.0104
============================================================


📊 Round 181 Test Metrics:
   Loss: 0.0863, RMSE: 0.2938, MAE: 0.2522, R²: -0.0103

============================================================
🔄 Round 182 - Client client_43
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0770 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0770, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0770, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0769, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0769, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0769, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0770)

============================================================
📊 Round 182 Summary - Client client_43
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=-0.0098
   Val:   Loss=0.0770, RMSE=0.2774, R²=-0.0001
============================================================


📊 Round 182 Test Metrics:
   Loss: 0.0863, RMSE: 0.2938, MAE: 0.2522, R²: -0.0103

============================================================
🔄 Round 183 - Client client_43
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0898 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0898, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0898, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0898, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0898, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0897, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0898)

============================================================
📊 Round 183 Summary - Client client_43
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=-0.0080
   Val:   Loss=0.0898, RMSE=0.2996, R²=-0.0037
============================================================


📊 Round 183 Test Metrics:
   Loss: 0.0863, RMSE: 0.2938, MAE: 0.2522, R²: -0.0103

============================================================
🔄 Round 184 - Client client_43
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0774 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0774, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0774, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0774, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0774, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0774, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0774)

============================================================
📊 Round 184 Summary - Client client_43
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=-0.0074
   Val:   Loss=0.0774, RMSE=0.2782, R²=-0.0060
============================================================


============================================================
🔄 Round 185 - Client client_43
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 185 Summary - Client client_43
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2891, R²=-0.0136
   Val:   Loss=0.0796, RMSE=0.2822, R²=0.0151
============================================================


============================================================
🔄 Round 186 - Client client_43
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 186 Summary - Client client_43
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=-0.0045
   Val:   Loss=0.0847, RMSE=0.2910, R²=-0.0158
============================================================


📊 Round 186 Test Metrics:
   Loss: 0.0863, RMSE: 0.2938, MAE: 0.2522, R²: -0.0103

============================================================
🔄 Round 188 - Client client_43
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0944 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0944, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0944, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0944, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0944, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0944, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0944)

============================================================
📊 Round 188 Summary - Client client_43
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2826, R²=-0.0076
   Val:   Loss=0.0944, RMSE=0.3072, R²=-0.0066
============================================================


============================================================
🔄 Round 190 - Client client_43
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 190 Summary - Client client_43
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=-0.0082
   Val:   Loss=0.0803, RMSE=0.2834, R²=-0.0102
============================================================


============================================================
🔄 Round 191 - Client client_43
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0874 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0873, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0873, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0873, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0873, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0873, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0874)

============================================================
📊 Round 191 Summary - Client client_43
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=-0.0122
   Val:   Loss=0.0874, RMSE=0.2956, R²=0.0088
============================================================


📊 Round 191 Test Metrics:
   Loss: 0.0863, RMSE: 0.2938, MAE: 0.2521, R²: -0.0103

============================================================
🔄 Round 194 - Client client_43
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 194 Summary - Client client_43
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2868, R²=-0.0116
   Val:   Loss=0.0847, RMSE=0.2911, R²=0.0105
============================================================


📊 Round 194 Test Metrics:
   Loss: 0.0863, RMSE: 0.2938, MAE: 0.2521, R²: -0.0102

============================================================
🔄 Round 196 - Client client_43
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 196 Summary - Client client_43
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=-0.0069
   Val:   Loss=0.0807, RMSE=0.2841, R²=-0.0097
============================================================


📊 Round 196 Test Metrics:
   Loss: 0.0863, RMSE: 0.2938, MAE: 0.2521, R²: -0.0102

============================================================
🔄 Round 197 - Client client_43
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 197 Summary - Client client_43
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=-0.0108
   Val:   Loss=0.0831, RMSE=0.2882, R²=-0.0001
============================================================


📊 Round 197 Test Metrics:
   Loss: 0.0863, RMSE: 0.2938, MAE: 0.2521, R²: -0.0102

============================================================
🔄 Round 198 - Client client_43
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 198 Summary - Client client_43
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=-0.0064
   Val:   Loss=0.0794, RMSE=0.2818, R²=-0.0267
============================================================


📊 Round 198 Test Metrics:
   Loss: 0.0863, RMSE: 0.2938, MAE: 0.2521, R²: -0.0101

============================================================
🔄 Round 199 - Client client_43
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 199 Summary - Client client_43
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=-0.0039
   Val:   Loss=0.0781, RMSE=0.2794, R²=-0.0219
============================================================


📊 Round 199 Test Metrics:
   Loss: 0.0863, RMSE: 0.2938, MAE: 0.2521, R²: -0.0101

============================================================
🔄 Round 200 - Client client_43
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0887 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0887, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0887, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0887, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0887, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0887, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0887)

============================================================
📊 Round 200 Summary - Client client_43
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=-0.0023
   Val:   Loss=0.0887, RMSE=0.2978, R²=-0.0251
============================================================


📊 Round 200 Test Metrics:
   Loss: 0.0863, RMSE: 0.2938, MAE: 0.2521, R²: -0.0101

📊 Round 200 Test Metrics:
   Loss: 0.0863, RMSE: 0.2938, MAE: 0.2521, R²: -0.0101

============================================================
🔄 Round 202 - Client client_43
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 202 Summary - Client client_43
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2892, R²=-0.0095
   Val:   Loss=0.0792, RMSE=0.2815, R²=0.0042
============================================================


📊 Round 202 Test Metrics:
   Loss: 0.0863, RMSE: 0.2938, MAE: 0.2521, R²: -0.0101

============================================================
🔄 Round 204 - Client client_43
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 204 Summary - Client client_43
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=-0.0045
   Val:   Loss=0.0825, RMSE=0.2872, R²=-0.0196
============================================================


📊 Round 204 Test Metrics:
   Loss: 0.0863, RMSE: 0.2938, MAE: 0.2521, R²: -0.0102

============================================================
🔄 Round 205 - Client client_43
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 205 Summary - Client client_43
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=-0.0048
   Val:   Loss=0.0828, RMSE=0.2877, R²=-0.0336
============================================================


============================================================
🔄 Round 206 - Client client_43
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 206 Summary - Client client_43
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=-0.0079
   Val:   Loss=0.0861, RMSE=0.2935, R²=-0.0069
============================================================


📊 Round 206 Test Metrics:
   Loss: 0.0863, RMSE: 0.2938, MAE: 0.2521, R²: -0.0101

============================================================
🔄 Round 207 - Client client_43
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0726 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0726, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0726, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0726, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0727, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0727, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0726)

============================================================
📊 Round 207 Summary - Client client_43
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2921, R²=-0.0059
   Val:   Loss=0.0726, RMSE=0.2694, R²=-0.0292
============================================================


📊 Round 207 Test Metrics:
   Loss: 0.0863, RMSE: 0.2938, MAE: 0.2521, R²: -0.0101

📊 Round 207 Test Metrics:
   Loss: 0.0863, RMSE: 0.2938, MAE: 0.2521, R²: -0.0100

============================================================
🔄 Round 209 - Client client_43
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0899 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0898, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0898, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0898, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0898, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0898, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0899)

============================================================
📊 Round 209 Summary - Client client_43
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=-0.0138
   Val:   Loss=0.0899, RMSE=0.2998, R²=0.0153
============================================================


============================================================
🔄 Round 212 - Client client_43
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0730 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0730, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0730, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0730, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0730, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0730, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0730)

============================================================
📊 Round 212 Summary - Client client_43
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2919, R²=-0.0030
   Val:   Loss=0.0730, RMSE=0.2703, R²=-0.0312
============================================================


============================================================
🔄 Round 213 - Client client_43
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 213 Summary - Client client_43
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=-0.0068
   Val:   Loss=0.0802, RMSE=0.2832, R²=-0.0169
============================================================


📊 Round 213 Test Metrics:
   Loss: 0.0863, RMSE: 0.2938, MAE: 0.2521, R²: -0.0099

============================================================
🔄 Round 217 - Client client_43
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0728 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0728, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0728, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0728, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0728, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0728, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0728)

============================================================
📊 Round 217 Summary - Client client_43
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2920, R²=-0.0118
   Val:   Loss=0.0728, RMSE=0.2698, R²=0.0116
============================================================


📊 Round 217 Test Metrics:
   Loss: 0.0863, RMSE: 0.2938, MAE: 0.2521, R²: -0.0098

============================================================
🔄 Round 220 - Client client_43
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 220 Summary - Client client_43
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=-0.0044
   Val:   Loss=0.0818, RMSE=0.2859, R²=-0.0154
============================================================


📊 Round 220 Test Metrics:
   Loss: 0.0863, RMSE: 0.2938, MAE: 0.2521, R²: -0.0098

📊 Round 220 Test Metrics:
   Loss: 0.0863, RMSE: 0.2938, MAE: 0.2521, R²: -0.0098

============================================================
🔄 Round 224 - Client client_43
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 224 Summary - Client client_43
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=-0.0024
   Val:   Loss=0.0798, RMSE=0.2825, R²=-0.0257
============================================================


❌ Client client_43 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8687 {grpc_message:"Socket closed", grpc_status:14}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8687 {grpc_message:"Socket closed", grpc_status:14}"
>
