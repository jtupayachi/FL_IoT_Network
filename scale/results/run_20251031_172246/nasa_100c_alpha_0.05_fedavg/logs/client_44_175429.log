[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 078cf3c9-362b-4ee3-828c-7c7949c1c1f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5f32983c-d8ff-40ed-a8e0-227b25b7756e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e9bbea73-7b5c-44e9-a8f8-c8376f6e5613
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0a074963-789a-4f2a-999e-3fa9fa0f189d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 934b04de-be18-41d1-b2f1-f3bffa674175
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 79278111-fc69-404d-b705-128ced989e6c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fc0727ee-aacc-479e-9f23-2b5cde990446
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2174eeb5-294b-4a1a-a37e-80b125b3ff03
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fbfe77e3-5e43-4c4e-b811-01e41f4a4a56
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 14aff5ea-9dcc-46fd-8e18-8adac81b9454
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0aa47d06-dfd7-4927-8f9e-ec510f11b7da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 628801ed-2e1c-4739-92fb-4b9146a7552d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 551c4c34-d391-4527-a2b4-816632a72ef2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 98836fc2-1d9e-4e80-9780-8b3f6ed57fa9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8a88e041-693f-4f40-a163-a7641cc10f3f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 77a12fed-2785-4809-922c-d0c7eb85fe35
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f7a22f18-8300-49ac-baa5-95b6c28398e2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 46c87a60-1c00-4cb0-a274-2d67523a1055
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9ac02470-bc87-4c13-9725-7359203c028a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fd471c99-3c64-4967-9ee2-1ada07e1a1dd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 71afdf44-500b-4fb4-8ea8-11ce49a096f4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 45cd1709-2643-4434-be3f-865d4283e5f6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 88f8e158-4cb9-4be3-b7c5-b1fd6a1f2141
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5ebd866e-a84f-4c1c-8b10-6bbec34394cd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 86badcec-dd2c-4e8a-9619-58a2f14b6093
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3366dea9-886a-45eb-a480-3cf517e78354
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3d13d800-ec61-474a-9e03-b1af281f1953
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 887b5f87-40b4-4af8-8672-82a5dfa76a2e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 79796fc2-f883-4373-9615-c58c38b9efd7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 44d3f2b0-dbc6-4228-9416-00df5331924c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d9326315-c104-48fb-b8d3-8a9450d6fb6b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e0aad1f7-bc56-4be5-994b-98418998dadd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 64deb8c1-d3ba-44ef-a368-60836e6722a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0a0f2eb2-4fcd-474e-b4b8-cb61e24f9812
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 96e04a85-4003-44ae-9532-403278f53fd6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 95f4db19-b2a1-4f63-9718-8591ccf57267
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 579141b4-74a3-48db-90eb-e56c6d4c8281
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e81e4617-710f-4b1a-8a0a-7b34b1159551
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1ffd3772-4b82-40b0-a193-43ef42f89b94
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 460f1316-8895-4bcf-9478-f78699389695
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5bb9435e-eebe-4dac-b229-a7ece6b3702c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dbafd7bb-c00a-4819-9c84-fd1727549246
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 118abfe7-d0d5-4d64-b6ba-18383e1f2929
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b4210b80-ae59-43c1-84a5-e3b1a8a136cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9a76450a-03f8-48a6-b961-c3e11786a2c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 01d74c61-701f-4513-b511-a52ecf25f534
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9a3d9616-b364-4800-a8cc-4ae5c5c8849f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cfce29a6-d8ab-4837-a4f1-350163280ace
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a8433315-00b7-4d72-b3f4-f5c3b3b5729e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message baea6d41-e595-4f7b-8499-405aa06164af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 54f02091-0476-4cfa-a52a-a3a60ba28bbf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1f408565-b310-4ce8-a603-d305bbd9d5c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9c41db38-2ea6-41dc-94a6-b6b7e19328a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 516e575f-9036-4372-9a72-04b15294468d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f8af9c0f-6bea-43d1-b982-5aee3fcfed16
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 28de600f-c49a-4d1d-89da-0f06a8d8b4c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9422ddd1-5cf1-4c76-8a4d-6eddd4f98a8c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2e144cfa-ecaf-4124-a3cf-48c9d0d80d7f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 59c03176-0506-413e-994f-a68a145d539d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a5679a71-22f7-44a6-b23d-4cc50ff70811
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 24b4bb90-cc0c-4b15-a1bd-f1cb4ed02741
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message efed7643-f1d8-4c9a-acb0-7d56b3c6f2e8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c7efbffc-1a48-46ff-906e-da985311c56f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1f6f8f5e-8a1d-432c-8c3c-081c94d03520
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 32f3b15d-1f2e-42d0-a109-8a34a5f9dd2e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3b47f64d-7320-4ab9-a38a-1944fe4fcda9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b98ef056-88bd-48da-9fab-c04c6467411a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5b05413f-74bd-4815-a077-6b29345deab9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 391de7fe-739e-4b7e-bcfa-7b1927698bcc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3cb28f3e-a6a5-4063-8a9a-cf2e6edd7a10
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6f6917a9-c74e-4468-9372-2d4235aad67e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a9401c26-c503-4714-a60a-5020c0608058
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 25202bb8-a119-4878-8bfb-0ddb2b008f1b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9d25e3c3-1b04-4924-8103-11a344ffdcd5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7f0b755e-8c18-42da-a8a9-b419e6ccc376
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 46a71f25-1e22-4f80-8160-3882c516133a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a19dc66c-7a1b-4e7f-8ca0-4e1f49cb595a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0e8646af-eae8-445f-b503-15554a2e49f8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b719770f-a910-42e0-bb1b-01bee4f6bc52
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f338f42c-f186-4039-92fc-5d98b5e91470
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6f3ed234-9740-489e-8197-c7dc05d027a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d5e3e6e5-c81a-4e8d-bdaa-24b8b716abc2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5a767ab5-53b3-4d99-9b59-37bed2817c9d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 56d30582-4d04-4ac6-828e-cef5388ea5a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c5a388e6-7196-4cbc-80a7-4ce611a89cd8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0408dd38-6e88-4407-9d96-3216e41e05d9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b2e09742-ee91-4b9b-a123-f7e557bbf8e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fb6cb0de-9d75-4cf4-8d00-2eecd2ce6604
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f234f999-b398-4767-91d9-3c5cb10bba5a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 65d11c67-4d7f-4c38-9938-f42dc08caf0c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bc4e2ffa-0b1d-4cfe-ba65-067c98d05873
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a448b05f-b84b-453e-9447-ddec63ea98e0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 20a13aa8-02ca-44ff-b039-c20ddec46b03
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4f327de1-e1a0-4900-a8cf-a07d9a15f8c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9429925e-9cba-43b5-a30b-b36fec0dbff1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ced4a57b-6b7c-43bb-afcf-04ba11de66c5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c2703487-3bd8-450c-ac82-500ee1f8198f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3a5e5474-b68a-4191-ba85-21f0b270c222
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b17c20a7-21a0-463f-8f4e-79c67508d779
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 617e45c8-6c1f-4c01-bfce-07cd4ac8ce1b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3f3e0e7a-f9ac-457b-ae53-bc1a8ae19820
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b21301d4-b4e5-4e11-bacb-5fd2aa7b1b51
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7764f139-4da5-4105-89fc-77452732345a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 089de45c-8f17-4063-872c-b2d920b2b101
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c62c5e79-05e5-41b8-aee7-6149059c190c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 636877a8-61a8-4acb-a94b-0bb1d7c5bcb3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 29f0aadc-8ca1-4b06-919e-a4298ff97a07
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 778e1706-e32a-4a80-a62a-10874934275e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ea1c10a7-fa8b-493b-af0a-cc2f6538faff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ba0094e4-eee2-4789-bb8e-eed0bd9148fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4ce86311-7629-4598-95de-c52725305651
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0e6fabd0-8249-482a-9fe1-cd65153b6076
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e91c42f1-30bb-4ce5-b21e-05f5c3283d3a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6c2d985c-7d9e-4437-a42e-1e1a182353d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b1d77233-f409-4689-a898-ec0b04a201c4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 97167df2-e9ff-4bdc-b61d-c9537069d24f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 48ef18d1-f5e9-4012-8b1c-d03eef0275e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 405ac6ea-6342-4b52-8f47-52e7d7dec1bd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6187af23-c8e0-4a42-b100-b2ee57c24e80
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 10780f3a-cde0-42e5-9f4e-8b23c9668359
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7b597f1a-92ab-4a00-b1b5-27c64144850e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5fe35a46-3603-42f9-a72f-70f6006a5aac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8bf07d95-a035-43f6-96d7-4b9e63413ef4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d0683fc1-2dcc-48d5-9826-0128208fba75
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 95b736e9-5135-4b73-b061-f60aef7ca72f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f6ca5790-f5c1-4ce5-bcb1-35c2d3f4f612
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5d37c700-6466-45c4-807e-f2705b43462e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b77dd758-0f6b-4348-8b42-36cf40dff124
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 87ffad50-f611-485b-b6df-99e83bb06a39
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4f07c8de-2a2c-442e-a7bc-86ea29d87a7d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message edb283a8-2914-4b52-89c6-c581c109d79a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 83ce423a-eb09-45d8-9b14-d053da73e085
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bde83aa3-467b-4fb5-b230-5c80d4c0b45c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ff86de16-d2cd-47c3-9e2d-19431d646d7e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9f745835-613f-4e92-8d5f-31710b4e8067
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9a42ddda-b412-4aad-b6b9-b545c529e5c4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0e886204-f800-44fc-8cf8-b48a94faa802
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3c6a54a3-884e-452a-abf8-ed9677902db5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 92ab895b-302a-4a50-9255-ac451db5adc5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 04d22e55-5ae0-40d0-83ae-b8935ec44cad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3b661415-1d5b-4616-b305-52ae6bd2099e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e6336f19-57dc-408e-b837-e8b203e26336
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 55e1d531-f4fe-4b89-8a59-32bae66393d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4e85b0f5-6f76-4fc9-833b-5f4d017c34ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f8de217c-5614-4e15-a83a-eaa7cd762d74
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8c2e2c14-dab3-4d39-bf1a-fcdcb16a9364
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 707ecb79-f030-4786-bf36-cfb44ec3090e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 304cfb55-1f3b-4599-8793-1bdfeaade48b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0e028527-259a-400c-a233-e2dfc8ea7589
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1e7dff60-7a02-4326-9ca5-b07a0c117fad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 33133dea-b9b1-48f1-ac85-3ba9aa9dbe5e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e6308280-02f8-4205-8ad2-599d41345317
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 47151f6b-1964-4832-bf56-4c0f1905cca7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c741390e-f478-4951-aeda-58d6ede4cc30
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1a9a5319-2561-44a0-81cd-0de62128dd46
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ece4cc4a-72f9-45e6-85b5-c7d4a7d4aba2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message df828e59-544b-4918-a89f-f97d893782fb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5a445685-e1d9-4a3c-af9b-98a00dc3f9a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 51ad4e96-00f5-404a-a1e3-d0a4ac7041f8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3e28933a-9d87-4153-a240-86609cc526a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b61f9682-5132-41bc-a896-07d7de829c33
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 74a9ea55-1473-4b9e-bd29-d06a624de4a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9e915e16-2262-447a-8187-843e047c4a39
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 75f1f844-7af0-457c-acfc-1b384d9d204b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5f941e26-5e5a-45d7-a8f6-0d7b431f548d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b0cf1a51-2b97-4370-9cb1-57eec8f5de5c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3ad86724-d7c4-41eb-ba8d-04d25836cfb9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 370cfd97-d720-48d6-8905-4641a0318176
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 13d2a2e4-b64b-4b47-9698-da153d21ab46
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ca018bba-aa5b-4523-9a55-74b20a6a5b87
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bd456eb8-2831-4a0e-8950-962a88b5f46f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 56479087-db9d-4a30-8a4e-58afc611cf4e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 89437958-af2c-43ca-a2f7-a970f55479aa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ca0bad59-86b5-42d8-a9e4-1cc1d03f2859
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 28b6deab-e91f-44f7-a550-fddaa5aaa0e8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 898e4273-d328-4f72-bbe9-39bfa6e2d4c3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ae6d321d-f684-47be-9eaa-2f2dee254e09
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9617b6d2-4cba-4a8d-a764-2aea2f439283
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dc6528d4-c18a-401f-b48e-3de0873ccbe7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7069bb9e-13f4-428b-a22f-5892873082cd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 150072eb-a452-4c6c-a63f-01902dba0904
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 10f89fff-a3bd-489c-8132-6ac708b18f1c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 94baefce-93c8-476d-89a3-66de2d82d08b
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8687 {grpc_status:14, grpc_message:"Socket closed"}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_44
Server: localhost:8687
Algorithm: FEDAVG
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_44
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_44/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_44/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_44/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_44/test_labels.txt

📊 Raw data loaded:
   Train: X=(1072, 24), y=(1072,)
   Test:  X=(268, 24), y=(268,)

⚠️  Limiting training data: 1072 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  259 samples, 5 features
✅ Client client_44 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

📊 Round 0 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2464, R²: 0.0269

============================================================
🔄 Round 6 - Client client_44
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0697 (↓), lr=0.001000
   • Epoch   2/100: train=0.0796, val=0.0695, patience=1/15, lr=0.001000
   ✓ Epoch   3/100: train=0.0789, val=0.0674 (↓), lr=0.001000
   • Epoch   4/100: train=0.0774, val=0.0671, patience=1/15, lr=0.001000
   ✓ Epoch   5/100: train=0.0764, val=0.0661 (↓), lr=0.001000
   • Epoch  11/100: train=0.0710, val=0.0661, patience=5/15, lr=0.001000
   📉 Epoch 13: LR reduced 0.001000 → 0.000500
   📉 Epoch 21: LR reduced 0.000500 → 0.000250
   • Epoch  21/100: train=0.0650, val=0.0705, patience=15/15, lr=0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0655)

============================================================
📊 Round 6 Summary - Client client_44
   Epochs: 21/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0725, RMSE=0.2693, R²=0.1406
   Val:   Loss=0.0655, RMSE=0.2560, R²=0.1057
============================================================


📊 Round 6 Test Metrics:
   Loss: 0.0815, RMSE: 0.2855, MAE: 0.2449, R²: 0.0363

============================================================
🔄 Round 7 - Client client_44
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0771, val=0.0767 (↓), lr=0.000250
   • Epoch   2/100: train=0.0764, val=0.0763, patience=1/15, lr=0.000250
   ✓ Epoch   3/100: train=0.0759, val=0.0761 (↓), lr=0.000250
   • Epoch   4/100: train=0.0754, val=0.0758, patience=1/15, lr=0.000250
   ✓ Epoch   5/100: train=0.0750, val=0.0756 (↓), lr=0.000250
   📉 Epoch 8: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0730, val=0.0745, patience=3/15, lr=0.000125
   📉 Epoch 16: LR reduced 0.000125 → 0.000063
   • Epoch  21/100: train=0.0714, val=0.0738, patience=8/15, lr=0.000063
   📉 Epoch 24: LR reduced 0.000063 → 0.000031
   • Epoch  31/100: train=0.0706, val=0.0736, patience=9/15, lr=0.000031
   📉 Epoch 32: LR reduced 0.000031 → 0.000016

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0738)

============================================================
📊 Round 7 Summary - Client client_44
   Epochs: 37/100 (early stopped)
   LR: 0.000250 → 0.000016 (4 reductions)
   Train: Loss=0.0711, RMSE=0.2666, R²=0.1335
   Val:   Loss=0.0738, RMSE=0.2716, R²=0.1074
============================================================


============================================================
🔄 Round 9 - Client client_44
   Epochs: 100, Batch: 32, LR: 0.000016
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0776, val=0.0720 (↓), lr=0.000016
   • Epoch   2/100: train=0.0775, val=0.0719, patience=1/15, lr=0.000016
   📉 Epoch 3: LR reduced 0.000016 → 0.000008
   • Epoch   3/100: train=0.0775, val=0.0719, patience=2/15, lr=0.000008
   • Epoch   4/100: train=0.0774, val=0.0718, patience=3/15, lr=0.000008
   • Epoch   5/100: train=0.0774, val=0.0718, patience=4/15, lr=0.000008
   📉 Epoch 11: LR reduced 0.000008 → 0.000004
   • Epoch  11/100: train=0.0772, val=0.0716, patience=10/15, lr=0.000004

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0720)

============================================================
📊 Round 9 Summary - Client client_44
   Epochs: 16/100 (early stopped)
   LR: 0.000016 → 0.000004 (2 reductions)
   Train: Loss=0.0777, RMSE=0.2788, R²=0.0638
   Val:   Loss=0.0720, RMSE=0.2683, R²=0.0831
============================================================


============================================================
🔄 Round 11 - Client client_44
   Epochs: 100, Batch: 32, LR: 0.000004
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0756, val=0.0786 (↓), lr=0.000004
   • Epoch   2/100: train=0.0756, val=0.0786, patience=1/15, lr=0.000004
   📉 Epoch 3: LR reduced 0.000004 → 0.000002
   • Epoch   3/100: train=0.0756, val=0.0786, patience=2/15, lr=0.000002
   • Epoch   4/100: train=0.0756, val=0.0786, patience=3/15, lr=0.000002
   • Epoch   5/100: train=0.0756, val=0.0786, patience=4/15, lr=0.000002
   📉 Epoch 11: LR reduced 0.000002 → 0.000001
   • Epoch  11/100: train=0.0755, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 11 Summary - Client client_44
   Epochs: 16/100 (early stopped)
   LR: 0.000004 → 0.000001 (2 reductions)
   Train: Loss=0.0757, RMSE=0.2752, R²=0.0638
   Val:   Loss=0.0786, RMSE=0.2804, R²=0.0881
============================================================


============================================================
🔄 Round 12 - Client client_44
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0748, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0748, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0748, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0748, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0748, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0747, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 12 Summary - Client client_44
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0749, RMSE=0.2737, R²=0.0747
   Val:   Loss=0.0832, RMSE=0.2885, R²=0.0446
============================================================


============================================================
🔄 Round 13 - Client client_44
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0672 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0672, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0672, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0672, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0672, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0673, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0672)

============================================================
📊 Round 13 Summary - Client client_44
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2808, R²=0.0672
   Val:   Loss=0.0672, RMSE=0.2592, R²=0.0430
============================================================


============================================================
🔄 Round 14 - Client client_44
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0772, val=0.0733 (↓), lr=0.000001
   • Epoch   2/100: train=0.0772, val=0.0733, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0772, val=0.0733, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0772, val=0.0733, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0772, val=0.0733, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0771, val=0.0733, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0733)

============================================================
📊 Round 14 Summary - Client client_44
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0771, RMSE=0.2777, R²=0.0772
   Val:   Loss=0.0733, RMSE=0.2707, R²=0.0404
============================================================


📊 Round 14 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2443, R²: 0.0332

============================================================
🔄 Round 20 - Client client_44
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0758, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0758, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0758, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0758, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0758, val=0.0774, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0758, val=0.0774, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 20 Summary - Client client_44
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0758, RMSE=0.2753, R²=0.0742
   Val:   Loss=0.0775, RMSE=0.2783, R²=0.0693
============================================================


============================================================
🔄 Round 21 - Client client_44
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0764, val=0.0761 (↓), lr=0.000001
   • Epoch   2/100: train=0.0764, val=0.0761, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0764, val=0.0761, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0764, val=0.0761, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0764, val=0.0761, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0763, val=0.0761, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0761)

============================================================
📊 Round 21 Summary - Client client_44
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0760, RMSE=0.2756, R²=0.0831
   Val:   Loss=0.0761, RMSE=0.2758, R²=0.0378
============================================================


============================================================
🔄 Round 22 - Client client_44
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0765, val=0.0737 (↓), lr=0.000001
   • Epoch   2/100: train=0.0765, val=0.0737, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0765, val=0.0737, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0765, val=0.0737, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0765, val=0.0737, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0764, val=0.0736, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0737)

============================================================
📊 Round 22 Summary - Client client_44
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0766, RMSE=0.2767, R²=0.0652
   Val:   Loss=0.0737, RMSE=0.2715, R²=0.1153
============================================================


============================================================
🔄 Round 24 - Client client_44
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0771, val=0.0723 (↓), lr=0.000001
   • Epoch   2/100: train=0.0770, val=0.0723, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0770, val=0.0723, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0770, val=0.0722, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0770, val=0.0722, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0770, val=0.0722, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0723)

============================================================
📊 Round 24 Summary - Client client_44
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0769, RMSE=0.2773, R²=0.0744
   Val:   Loss=0.0723, RMSE=0.2688, R²=0.0797
============================================================


📊 Round 24 Test Metrics:
   Loss: 0.0818, RMSE: 0.2861, MAE: 0.2441, R²: 0.0327

📊 Round 24 Test Metrics:
   Loss: 0.0818, RMSE: 0.2861, MAE: 0.2441, R²: 0.0327

============================================================
🔄 Round 28 - Client client_44
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0780, val=0.0673 (↓), lr=0.000001
   • Epoch   2/100: train=0.0780, val=0.0673, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0780, val=0.0673, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0780, val=0.0673, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0780, val=0.0673, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0779, val=0.0672, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0673)

============================================================
📊 Round 28 Summary - Client client_44
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0782, RMSE=0.2796, R²=0.0709
   Val:   Loss=0.0673, RMSE=0.2593, R²=0.0926
============================================================


📊 Round 28 Test Metrics:
   Loss: 0.0818, RMSE: 0.2861, MAE: 0.2441, R²: 0.0327

📊 Round 28 Test Metrics:
   Loss: 0.0818, RMSE: 0.2861, MAE: 0.2441, R²: 0.0327

📊 Round 28 Test Metrics:
   Loss: 0.0818, RMSE: 0.2861, MAE: 0.2441, R²: 0.0327

📊 Round 28 Test Metrics:
   Loss: 0.0818, RMSE: 0.2861, MAE: 0.2441, R²: 0.0328

============================================================
🔄 Round 35 - Client client_44
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0746, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0745, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0745, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0745, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0745, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0744, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 35 Summary - Client client_44
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0744, RMSE=0.2728, R²=0.0823
   Val:   Loss=0.0822, RMSE=0.2867, R²=0.0439
============================================================


📊 Round 35 Test Metrics:
   Loss: 0.0818, RMSE: 0.2861, MAE: 0.2441, R²: 0.0328

============================================================
🔄 Round 36 - Client client_44
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0751, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0751, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0751, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0751, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0751, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0750, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 36 Summary - Client client_44
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0751, RMSE=0.2740, R²=0.0766
   Val:   Loss=0.0796, RMSE=0.2821, R²=0.0692
============================================================


📊 Round 36 Test Metrics:
   Loss: 0.0818, RMSE: 0.2861, MAE: 0.2441, R²: 0.0327

📊 Round 36 Test Metrics:
   Loss: 0.0818, RMSE: 0.2861, MAE: 0.2441, R²: 0.0328

📊 Round 36 Test Metrics:
   Loss: 0.0818, RMSE: 0.2861, MAE: 0.2441, R²: 0.0328

============================================================
🔄 Round 41 - Client client_44
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0736, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0736, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0736, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0736, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0735, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0735, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 41 Summary - Client client_44
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0736, RMSE=0.2712, R²=0.0710
   Val:   Loss=0.0856, RMSE=0.2925, R²=0.0913
============================================================


📊 Round 41 Test Metrics:
   Loss: 0.0818, RMSE: 0.2861, MAE: 0.2441, R²: 0.0328

📊 Round 41 Test Metrics:
   Loss: 0.0818, RMSE: 0.2861, MAE: 0.2441, R²: 0.0328

============================================================
🔄 Round 45 - Client client_44
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0752, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0752, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0752, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0752, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0752, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0751, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 45 Summary - Client client_44
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0751, RMSE=0.2741, R²=0.0721
   Val:   Loss=0.0793, RMSE=0.2815, R²=0.0869
============================================================


📊 Round 45 Test Metrics:
   Loss: 0.0818, RMSE: 0.2861, MAE: 0.2441, R²: 0.0328

============================================================
🔄 Round 47 - Client client_44
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0643 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0643, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0643, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0643, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0643, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0643, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0643)

============================================================
📊 Round 47 Summary - Client client_44
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2808, R²=0.0710
   Val:   Loss=0.0643, RMSE=0.2536, R²=0.0960
============================================================


📊 Round 47 Test Metrics:
   Loss: 0.0818, RMSE: 0.2861, MAE: 0.2441, R²: 0.0328

============================================================
🔄 Round 48 - Client client_44
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0766, val=0.0730 (↓), lr=0.000001
   • Epoch   2/100: train=0.0765, val=0.0730, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0765, val=0.0729, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0765, val=0.0729, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0765, val=0.0729, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0765, val=0.0729, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0730)

============================================================
📊 Round 48 Summary - Client client_44
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0767, RMSE=0.2770, R²=0.0689
   Val:   Loss=0.0730, RMSE=0.2701, R²=0.1009
============================================================


📊 Round 48 Test Metrics:
   Loss: 0.0818, RMSE: 0.2861, MAE: 0.2441, R²: 0.0328

📊 Round 48 Test Metrics:
   Loss: 0.0818, RMSE: 0.2861, MAE: 0.2441, R²: 0.0328

📊 Round 48 Test Metrics:
   Loss: 0.0818, RMSE: 0.2861, MAE: 0.2441, R²: 0.0328

📊 Round 48 Test Metrics:
   Loss: 0.0818, RMSE: 0.2861, MAE: 0.2441, R²: 0.0328

============================================================
🔄 Round 54 - Client client_44
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0766, val=0.0737 (↓), lr=0.000001
   • Epoch   2/100: train=0.0766, val=0.0737, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0766, val=0.0737, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0766, val=0.0737, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0765, val=0.0737, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0765, val=0.0736, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0737)

============================================================
📊 Round 54 Summary - Client client_44
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0765, RMSE=0.2766, R²=0.0734
   Val:   Loss=0.0737, RMSE=0.2715, R²=0.0776
============================================================


📊 Round 54 Test Metrics:
   Loss: 0.0818, RMSE: 0.2861, MAE: 0.2441, R²: 0.0328

============================================================
🔄 Round 57 - Client client_44
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0769, val=0.0725 (↓), lr=0.000001
   • Epoch   2/100: train=0.0769, val=0.0725, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0769, val=0.0725, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0769, val=0.0725, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0769, val=0.0725, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0768, val=0.0724, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0725)

============================================================
📊 Round 57 Summary - Client client_44
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0768, RMSE=0.2772, R²=0.0811
   Val:   Loss=0.0725, RMSE=0.2692, R²=0.0482
============================================================


============================================================
🔄 Round 58 - Client client_44
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0754, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0754, val=0.0778, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0754, val=0.0778, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0754, val=0.0778, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0754, val=0.0778, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0753, val=0.0777, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 58 Summary - Client client_44
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0755, RMSE=0.2748, R²=0.0835
   Val:   Loss=0.0778, RMSE=0.2789, R²=0.0423
============================================================


📊 Round 58 Test Metrics:
   Loss: 0.0818, RMSE: 0.2861, MAE: 0.2441, R²: 0.0327

📊 Round 58 Test Metrics:
   Loss: 0.0818, RMSE: 0.2861, MAE: 0.2441, R²: 0.0327

📊 Round 58 Test Metrics:
   Loss: 0.0818, RMSE: 0.2861, MAE: 0.2441, R²: 0.0328

📊 Round 58 Test Metrics:
   Loss: 0.0818, RMSE: 0.2861, MAE: 0.2441, R²: 0.0328

============================================================
🔄 Round 64 - Client client_44
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0763, val=0.0746 (↓), lr=0.000001
   • Epoch   2/100: train=0.0763, val=0.0746, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0763, val=0.0746, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0763, val=0.0746, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0763, val=0.0746, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0762, val=0.0745, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0746)

============================================================
📊 Round 64 Summary - Client client_44
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0763, RMSE=0.2762, R²=0.0737
   Val:   Loss=0.0746, RMSE=0.2732, R²=0.0811
============================================================


📊 Round 64 Test Metrics:
   Loss: 0.0818, RMSE: 0.2861, MAE: 0.2441, R²: 0.0328

============================================================
🔄 Round 65 - Client client_44
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0766, val=0.0729 (↓), lr=0.000001
   • Epoch   2/100: train=0.0766, val=0.0729, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0766, val=0.0729, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0766, val=0.0729, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0766, val=0.0729, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0765, val=0.0728, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0729)

============================================================
📊 Round 65 Summary - Client client_44
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0767, RMSE=0.2770, R²=0.0717
   Val:   Loss=0.0729, RMSE=0.2700, R²=0.0923
============================================================


============================================================
🔄 Round 67 - Client client_44
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0748, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0747, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0747, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0747, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0747, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0747, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 67 Summary - Client client_44
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0744, RMSE=0.2728, R²=0.0798
   Val:   Loss=0.0820, RMSE=0.2864, R²=0.0612
============================================================


============================================================
🔄 Round 69 - Client client_44
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0778, val=0.0689 (↓), lr=0.000001
   • Epoch   2/100: train=0.0778, val=0.0689, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0778, val=0.0689, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0778, val=0.0689, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0777, val=0.0689, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0777, val=0.0688, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0689)

============================================================
📊 Round 69 Summary - Client client_44
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0777, RMSE=0.2788, R²=0.0658
   Val:   Loss=0.0689, RMSE=0.2625, R²=0.1186
============================================================


📊 Round 69 Test Metrics:
   Loss: 0.0818, RMSE: 0.2861, MAE: 0.2441, R²: 0.0329

============================================================
🔄 Round 71 - Client client_44
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0782, val=0.0670 (↓), lr=0.000001
   • Epoch   2/100: train=0.0782, val=0.0670, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0782, val=0.0670, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0782, val=0.0670, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0782, val=0.0670, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0781, val=0.0670, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0670)

============================================================
📊 Round 71 Summary - Client client_44
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0782, RMSE=0.2796, R²=0.0775
   Val:   Loss=0.0670, RMSE=0.2589, R²=0.0684
============================================================


============================================================
🔄 Round 73 - Client client_44
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0759, val=0.0756 (↓), lr=0.000001
   • Epoch   2/100: train=0.0758, val=0.0756, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0758, val=0.0756, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0758, val=0.0756, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0758, val=0.0756, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0758, val=0.0756, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0756)

============================================================
📊 Round 73 Summary - Client client_44
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0760, RMSE=0.2757, R²=0.0636
   Val:   Loss=0.0756, RMSE=0.2750, R²=0.1216
============================================================


📊 Round 73 Test Metrics:
   Loss: 0.0818, RMSE: 0.2861, MAE: 0.2441, R²: 0.0328

============================================================
🔄 Round 77 - Client client_44
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0751, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0751, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0750, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0750, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0750, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0750, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 77 Summary - Client client_44
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0753, RMSE=0.2744, R²=0.0746
   Val:   Loss=0.0786, RMSE=0.2804, R²=0.0802
============================================================


📊 Round 77 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2441, R²: 0.0329

📊 Round 77 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2440, R²: 0.0329

============================================================
🔄 Round 79 - Client client_44
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0770, val=0.0722 (↓), lr=0.000001
   • Epoch   2/100: train=0.0770, val=0.0722, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0770, val=0.0722, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0770, val=0.0722, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0770, val=0.0722, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0769, val=0.0723, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0722)

============================================================
📊 Round 79 Summary - Client client_44
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0769, RMSE=0.2772, R²=0.0802
   Val:   Loss=0.0722, RMSE=0.2687, R²=0.0500
============================================================


============================================================
🔄 Round 80 - Client client_44
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0760, val=0.0761 (↓), lr=0.000001
   • Epoch   2/100: train=0.0760, val=0.0761, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0760, val=0.0761, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0760, val=0.0761, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0760, val=0.0761, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0759, val=0.0761, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0761)

============================================================
📊 Round 80 Summary - Client client_44
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0759, RMSE=0.2755, R²=0.0671
   Val:   Loss=0.0761, RMSE=0.2760, R²=0.1101
============================================================


📊 Round 80 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2440, R²: 0.0329

📊 Round 80 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2440, R²: 0.0329

============================================================
🔄 Round 84 - Client client_44
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0758, val=0.0772 (↓), lr=0.000001
   • Epoch   2/100: train=0.0758, val=0.0772, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0757, val=0.0772, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0757, val=0.0772, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0757, val=0.0772, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0757, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 84 Summary - Client client_44
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0756, RMSE=0.2750, R²=0.0709
   Val:   Loss=0.0772, RMSE=0.2779, R²=0.0919
============================================================


📊 Round 84 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2440, R²: 0.0329

============================================================
🔄 Round 87 - Client client_44
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0651 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0651, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0651, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0651, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0651, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0785, val=0.0651, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0651)

============================================================
📊 Round 87 Summary - Client client_44
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2804, R²=0.0771
   Val:   Loss=0.0651, RMSE=0.2552, R²=0.0544
============================================================


📊 Round 87 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2440, R²: 0.0330

📊 Round 87 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2440, R²: 0.0330

============================================================
🔄 Round 90 - Client client_44
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0735, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0734, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0734, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0734, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0734, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0733, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 90 Summary - Client client_44
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0736, RMSE=0.2713, R²=0.0852
   Val:   Loss=0.0853, RMSE=0.2920, R²=0.0431
============================================================


============================================================
🔄 Round 91 - Client client_44
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0754, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0754, val=0.0778, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0754, val=0.0778, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0754, val=0.0778, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0754, val=0.0778, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0753, val=0.0777, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 91 Summary - Client client_44
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0755, RMSE=0.2747, R²=0.0747
   Val:   Loss=0.0778, RMSE=0.2789, R²=0.0811
============================================================


============================================================
🔄 Round 95 - Client client_44
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0780, val=0.0681 (↓), lr=0.000001
   • Epoch   2/100: train=0.0779, val=0.0681, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0779, val=0.0681, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0779, val=0.0681, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0779, val=0.0681, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0778, val=0.0682, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0681)

============================================================
📊 Round 95 Summary - Client client_44
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0779, RMSE=0.2791, R²=0.0802
   Val:   Loss=0.0681, RMSE=0.2610, R²=0.0446
============================================================


📊 Round 95 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2440, R²: 0.0329

============================================================
🔄 Round 97 - Client client_44
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0625 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0625, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0625, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0625, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0625, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0625, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0625)

============================================================
📊 Round 97 Summary - Client client_44
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2816, R²=0.0710
   Val:   Loss=0.0625, RMSE=0.2500, R²=0.0836
============================================================


📊 Round 97 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2440, R²: 0.0330

============================================================
🔄 Round 99 - Client client_44
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0764, val=0.0754 (↓), lr=0.000001
   • Epoch   2/100: train=0.0764, val=0.0754, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0764, val=0.0754, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0764, val=0.0754, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0763, val=0.0754, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0763, val=0.0754, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0754)

============================================================
📊 Round 99 Summary - Client client_44
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0761, RMSE=0.2758, R²=0.0832
   Val:   Loss=0.0754, RMSE=0.2745, R²=0.0194
============================================================


📊 Round 99 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2440, R²: 0.0330

============================================================
🔄 Round 100 - Client client_44
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0742, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0742, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0742, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0742, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0742, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0741, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 100 Summary - Client client_44
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0742, RMSE=0.2725, R²=0.0757
   Val:   Loss=0.0827, RMSE=0.2875, R²=0.0768
============================================================


📊 Round 100 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2440, R²: 0.0330

============================================================
🔄 Round 101 - Client client_44
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0760, val=0.0754 (↓), lr=0.000001
   • Epoch   2/100: train=0.0760, val=0.0754, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0760, val=0.0754, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0760, val=0.0754, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0760, val=0.0754, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0759, val=0.0753, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0754)

============================================================
📊 Round 101 Summary - Client client_44
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0761, RMSE=0.2758, R²=0.0709
   Val:   Loss=0.0754, RMSE=0.2746, R²=0.0885
============================================================


📊 Round 101 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2440, R²: 0.0330

📊 Round 101 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2440, R²: 0.0330

============================================================
🔄 Round 104 - Client client_44
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0767, val=0.0723 (↓), lr=0.000001
   • Epoch   2/100: train=0.0767, val=0.0723, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0767, val=0.0723, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0767, val=0.0723, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0767, val=0.0723, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0766, val=0.0723, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0723)

============================================================
📊 Round 104 Summary - Client client_44
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0768, RMSE=0.2772, R²=0.0807
   Val:   Loss=0.0723, RMSE=0.2689, R²=0.0565
============================================================


============================================================
🔄 Round 105 - Client client_44
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0780, val=0.0673 (↓), lr=0.000001
   • Epoch   2/100: train=0.0780, val=0.0673, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0780, val=0.0673, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0780, val=0.0673, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0779, val=0.0673, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0779, val=0.0672, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0673)

============================================================
📊 Round 105 Summary - Client client_44
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0781, RMSE=0.2794, R²=0.0686
   Val:   Loss=0.0673, RMSE=0.2595, R²=0.1098
============================================================


📊 Round 105 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2440, R²: 0.0330

============================================================
🔄 Round 106 - Client client_44
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0770, val=0.0718 (↓), lr=0.000001
   • Epoch   2/100: train=0.0770, val=0.0718, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0770, val=0.0718, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0770, val=0.0718, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0770, val=0.0718, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0769, val=0.0717, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0718)

============================================================
📊 Round 106 Summary - Client client_44
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0769, RMSE=0.2774, R²=0.0682
   Val:   Loss=0.0718, RMSE=0.2679, R²=0.1078
============================================================


📊 Round 106 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2440, R²: 0.0330

============================================================
🔄 Round 108 - Client client_44
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0770, val=0.0722 (↓), lr=0.000001
   • Epoch   2/100: train=0.0770, val=0.0722, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0770, val=0.0722, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0770, val=0.0721, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0770, val=0.0721, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0769, val=0.0721, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0722)

============================================================
📊 Round 108 Summary - Client client_44
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0769, RMSE=0.2772, R²=0.0687
   Val:   Loss=0.0722, RMSE=0.2687, R²=0.1042
============================================================


📊 Round 108 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2440, R²: 0.0330

📊 Round 108 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2440, R²: 0.0330

============================================================
🔄 Round 111 - Client client_44
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0744, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0744, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0744, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0744, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0744, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0743, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 111 Summary - Client client_44
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0742, RMSE=0.2724, R²=0.0858
   Val:   Loss=0.0828, RMSE=0.2878, R²=0.0403
============================================================


============================================================
🔄 Round 112 - Client client_44
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0758, val=0.0770 (↓), lr=0.000001
   • Epoch   2/100: train=0.0758, val=0.0770, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0758, val=0.0770, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0758, val=0.0770, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0758, val=0.0770, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0757, val=0.0769, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0770)

============================================================
📊 Round 112 Summary - Client client_44
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0756, RMSE=0.2750, R²=0.0620
   Val:   Loss=0.0770, RMSE=0.2775, R²=0.1219
============================================================


📊 Round 112 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2440, R²: 0.0330

📊 Round 112 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2440, R²: 0.0330

📊 Round 112 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2440, R²: 0.0330

============================================================
🔄 Round 115 - Client client_44
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0753, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0753, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0753, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0752, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0752, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0752, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 115 Summary - Client client_44
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0753, RMSE=0.2743, R²=0.0728
   Val:   Loss=0.0785, RMSE=0.2802, R²=0.0896
============================================================


============================================================
🔄 Round 116 - Client client_44
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0766, val=0.0732 (↓), lr=0.000001
   • Epoch   2/100: train=0.0766, val=0.0732, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0766, val=0.0732, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0766, val=0.0732, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0766, val=0.0732, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0765, val=0.0731, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0732)

============================================================
📊 Round 116 Summary - Client client_44
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0766, RMSE=0.2767, R²=0.0791
   Val:   Loss=0.0732, RMSE=0.2705, R²=0.0649
============================================================


============================================================
🔄 Round 117 - Client client_44
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0777, val=0.0689 (↓), lr=0.000001
   • Epoch   2/100: train=0.0777, val=0.0689, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0777, val=0.0689, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0777, val=0.0689, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0777, val=0.0689, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0776, val=0.0689, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0689)

============================================================
📊 Round 117 Summary - Client client_44
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0776, RMSE=0.2787, R²=0.0778
   Val:   Loss=0.0689, RMSE=0.2626, R²=0.0698
============================================================


============================================================
🔄 Round 118 - Client client_44
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0771, val=0.0709 (↓), lr=0.000001
   • Epoch   2/100: train=0.0771, val=0.0709, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0771, val=0.0709, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0771, val=0.0709, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0771, val=0.0709, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0770, val=0.0708, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0709)

============================================================
📊 Round 118 Summary - Client client_44
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0772, RMSE=0.2778, R²=0.0852
   Val:   Loss=0.0709, RMSE=0.2662, R²=0.0361
============================================================


📊 Round 118 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2440, R²: 0.0331

📊 Round 118 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2440, R²: 0.0331

============================================================
🔄 Round 120 - Client client_44
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0760, val=0.0750 (↓), lr=0.000001
   • Epoch   2/100: train=0.0760, val=0.0750, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0760, val=0.0750, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0760, val=0.0750, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0759, val=0.0750, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0759, val=0.0749, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0750)

============================================================
📊 Round 120 Summary - Client client_44
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0761, RMSE=0.2759, R²=0.0817
   Val:   Loss=0.0750, RMSE=0.2739, R²=0.0546
============================================================


============================================================
🔄 Round 123 - Client client_44
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0775, val=0.0698 (↓), lr=0.000001
   • Epoch   2/100: train=0.0775, val=0.0698, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0775, val=0.0698, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0774, val=0.0698, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0774, val=0.0698, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0774, val=0.0697, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0698)

============================================================
📊 Round 123 Summary - Client client_44
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0774, RMSE=0.2783, R²=0.0830
   Val:   Loss=0.0698, RMSE=0.2642, R²=0.0395
============================================================


📊 Round 123 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2440, R²: 0.0331

============================================================
🔄 Round 125 - Client client_44
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0753, val=0.0779 (↓), lr=0.000001
   • Epoch   2/100: train=0.0753, val=0.0779, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0753, val=0.0779, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0753, val=0.0779, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0753, val=0.0778, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0752, val=0.0778, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0779)

============================================================
📊 Round 125 Summary - Client client_44
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0754, RMSE=0.2746, R²=0.0793
   Val:   Loss=0.0779, RMSE=0.2791, R²=0.0647
============================================================


📊 Round 125 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2440, R²: 0.0332

============================================================
🔄 Round 127 - Client client_44
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0765, val=0.0744 (↓), lr=0.000001
   • Epoch   2/100: train=0.0765, val=0.0744, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0765, val=0.0744, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0765, val=0.0744, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0764, val=0.0744, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0764, val=0.0744, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0744)

============================================================
📊 Round 127 Summary - Client client_44
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0763, RMSE=0.2762, R²=0.0746
   Val:   Loss=0.0744, RMSE=0.2728, R²=0.0804
============================================================


============================================================
🔄 Round 128 - Client client_44
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0779, val=0.0682 (↓), lr=0.000001
   • Epoch   2/100: train=0.0779, val=0.0682, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0779, val=0.0682, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0779, val=0.0682, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0779, val=0.0682, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0778, val=0.0682, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0682)

============================================================
📊 Round 128 Summary - Client client_44
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0778, RMSE=0.2790, R²=0.0685
   Val:   Loss=0.0682, RMSE=0.2612, R²=0.1098
============================================================


📊 Round 128 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2440, R²: 0.0331

============================================================
🔄 Round 129 - Client client_44
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0758, val=0.0759 (↓), lr=0.000001
   • Epoch   2/100: train=0.0758, val=0.0759, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0757, val=0.0759, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0757, val=0.0759, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0757, val=0.0759, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0757, val=0.0759, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0759)

============================================================
📊 Round 129 Summary - Client client_44
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0759, RMSE=0.2755, R²=0.0750
   Val:   Loss=0.0759, RMSE=0.2755, R²=0.0817
============================================================


📊 Round 129 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2440, R²: 0.0331

============================================================
🔄 Round 132 - Client client_44
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0636 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0636, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0636, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0636, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0636, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0635, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0636)

============================================================
📊 Round 132 Summary - Client client_44
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2810, R²=0.0701
   Val:   Loss=0.0636, RMSE=0.2522, R²=0.1062
============================================================


============================================================
🔄 Round 133 - Client client_44
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0746, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0746, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0746, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0746, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0746, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0745, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 133 Summary - Client client_44
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0746, RMSE=0.2731, R²=0.0839
   Val:   Loss=0.0811, RMSE=0.2848, R²=0.0415
============================================================


📊 Round 133 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2440, R²: 0.0331

📊 Round 133 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2440, R²: 0.0331

============================================================
🔄 Round 140 - Client client_44
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0750, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0749, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0749, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0749, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0749, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0749, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 140 Summary - Client client_44
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0750, RMSE=0.2738, R²=0.0740
   Val:   Loss=0.0795, RMSE=0.2820, R²=0.0849
============================================================


📊 Round 140 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2440, R²: 0.0331

📊 Round 140 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2440, R²: 0.0331

📊 Round 140 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2440, R²: 0.0332

============================================================
🔄 Round 145 - Client client_44
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0752, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0752, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0752, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0752, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0752, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0751, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 145 Summary - Client client_44
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0752, RMSE=0.2742, R²=0.0829
   Val:   Loss=0.0786, RMSE=0.2804, R²=0.0480
============================================================


============================================================
🔄 Round 146 - Client client_44
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0763, val=0.0737 (↓), lr=0.000001
   • Epoch   2/100: train=0.0763, val=0.0737, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0762, val=0.0737, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0762, val=0.0737, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0762, val=0.0737, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0762, val=0.0736, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0737)

============================================================
📊 Round 146 Summary - Client client_44
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0764, RMSE=0.2765, R²=0.0771
   Val:   Loss=0.0737, RMSE=0.2715, R²=0.0704
============================================================


============================================================
🔄 Round 148 - Client client_44
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0763, val=0.0740 (↓), lr=0.000001
   • Epoch   2/100: train=0.0762, val=0.0740, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0762, val=0.0740, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0762, val=0.0740, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0762, val=0.0740, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0761, val=0.0740, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0740)

============================================================
📊 Round 148 Summary - Client client_44
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0764, RMSE=0.2763, R²=0.0768
   Val:   Loss=0.0740, RMSE=0.2720, R²=0.0647
============================================================


============================================================
🔄 Round 150 - Client client_44
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0752, val=0.0776 (↓), lr=0.000001
   • Epoch   2/100: train=0.0752, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0752, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0752, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0752, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0751, val=0.0774, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 150 Summary - Client client_44
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0755, RMSE=0.2747, R²=0.0707
   Val:   Loss=0.0776, RMSE=0.2785, R²=0.0984
============================================================


📊 Round 150 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2440, R²: 0.0331

📊 Round 150 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2440, R²: 0.0331

📊 Round 150 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2440, R²: 0.0332

============================================================
🔄 Round 158 - Client client_44
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0770, val=0.0714 (↓), lr=0.000001
   • Epoch   2/100: train=0.0770, val=0.0714, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0770, val=0.0714, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0770, val=0.0714, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0769, val=0.0714, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0769, val=0.0714, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0714)

============================================================
📊 Round 158 Summary - Client client_44
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0770, RMSE=0.2775, R²=0.0753
   Val:   Loss=0.0714, RMSE=0.2673, R²=0.0793
============================================================


📊 Round 158 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2440, R²: 0.0332

============================================================
🔄 Round 159 - Client client_44
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0766, val=0.0736 (↓), lr=0.000001
   • Epoch   2/100: train=0.0766, val=0.0736, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0766, val=0.0736, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0765, val=0.0736, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0765, val=0.0736, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0765, val=0.0735, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0736)

============================================================
📊 Round 159 Summary - Client client_44
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0765, RMSE=0.2765, R²=0.0778
   Val:   Loss=0.0736, RMSE=0.2713, R²=0.0686
============================================================


============================================================
🔄 Round 162 - Client client_44
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0777, val=0.0694 (↓), lr=0.000001
   • Epoch   2/100: train=0.0776, val=0.0694, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0776, val=0.0694, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0776, val=0.0694, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0776, val=0.0694, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0775, val=0.0694, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0694)

============================================================
📊 Round 162 Summary - Client client_44
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0775, RMSE=0.2784, R²=0.0786
   Val:   Loss=0.0694, RMSE=0.2634, R²=0.0567
============================================================


📊 Round 162 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2440, R²: 0.0332

📊 Round 162 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2440, R²: 0.0331

📊 Round 162 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2440, R²: 0.0331

============================================================
🔄 Round 166 - Client client_44
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0759, val=0.0755 (↓), lr=0.000001
   • Epoch   2/100: train=0.0759, val=0.0755, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0759, val=0.0755, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0759, val=0.0755, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0759, val=0.0755, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0758, val=0.0755, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0755)

============================================================
📊 Round 166 Summary - Client client_44
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0760, RMSE=0.2756, R²=0.0799
   Val:   Loss=0.0755, RMSE=0.2748, R²=0.0565
============================================================


📊 Round 166 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2440, R²: 0.0332

============================================================
🔄 Round 167 - Client client_44
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0759, val=0.0757 (↓), lr=0.000001
   • Epoch   2/100: train=0.0759, val=0.0757, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0759, val=0.0757, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0759, val=0.0757, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0759, val=0.0757, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0758, val=0.0756, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0757)

============================================================
📊 Round 167 Summary - Client client_44
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0759, RMSE=0.2756, R²=0.0738
   Val:   Loss=0.0757, RMSE=0.2751, R²=0.0774
============================================================


============================================================
🔄 Round 168 - Client client_44
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0774, val=0.0697 (↓), lr=0.000001
   • Epoch   2/100: train=0.0774, val=0.0697, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0774, val=0.0697, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0773, val=0.0697, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0773, val=0.0697, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0772, val=0.0698, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0697)

============================================================
📊 Round 168 Summary - Client client_44
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0774, RMSE=0.2783, R²=0.0803
   Val:   Loss=0.0697, RMSE=0.2640, R²=0.0429
============================================================


📊 Round 168 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2440, R²: 0.0332

============================================================
🔄 Round 170 - Client client_44
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0737, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0737, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0737, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0737, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0737, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0736, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 170 Summary - Client client_44
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0738, RMSE=0.2716, R²=0.0730
   Val:   Loss=0.0843, RMSE=0.2903, R²=0.0897
============================================================


============================================================
🔄 Round 172 - Client client_44
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0754, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0754, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0754, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0754, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0754, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0753, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 172 Summary - Client client_44
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0750, RMSE=0.2739, R²=0.0810
   Val:   Loss=0.0793, RMSE=0.2816, R²=0.0549
============================================================


📊 Round 172 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2440, R²: 0.0332

============================================================
🔄 Round 174 - Client client_44
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0750, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0749, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0749, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0749, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0749, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0749, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 174 Summary - Client client_44
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0746, RMSE=0.2731, R²=0.0813
   Val:   Loss=0.0810, RMSE=0.2847, R²=0.0584
============================================================


📊 Round 174 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2440, R²: 0.0332

============================================================
🔄 Round 176 - Client client_44
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0744, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0744, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0744, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0744, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0743, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0743, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 176 Summary - Client client_44
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0744, RMSE=0.2727, R²=0.0775
   Val:   Loss=0.0819, RMSE=0.2861, R²=0.0592
============================================================


📊 Round 176 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2440, R²: 0.0332

============================================================
🔄 Round 177 - Client client_44
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0763, val=0.0746 (↓), lr=0.000001
   • Epoch   2/100: train=0.0762, val=0.0746, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0762, val=0.0746, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0762, val=0.0746, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0762, val=0.0746, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0761, val=0.0746, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0746)

============================================================
📊 Round 177 Summary - Client client_44
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0762, RMSE=0.2760, R²=0.0764
   Val:   Loss=0.0746, RMSE=0.2732, R²=0.0783
============================================================


============================================================
🔄 Round 179 - Client client_44
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0749, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0749, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0749, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0749, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0749, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0749, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 179 Summary - Client client_44
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0745, RMSE=0.2730, R²=0.0736
   Val:   Loss=0.0812, RMSE=0.2850, R²=0.0882
============================================================


📊 Round 179 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2440, R²: 0.0332

============================================================
🔄 Round 180 - Client client_44
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0766, val=0.0728 (↓), lr=0.000001
   • Epoch   2/100: train=0.0766, val=0.0728, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0766, val=0.0728, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0766, val=0.0728, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0766, val=0.0728, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0765, val=0.0728, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0728)

============================================================
📊 Round 180 Summary - Client client_44
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0766, RMSE=0.2768, R²=0.0802
   Val:   Loss=0.0728, RMSE=0.2699, R²=0.0599
============================================================


============================================================
🔄 Round 181 - Client client_44
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0774, val=0.0701 (↓), lr=0.000001
   • Epoch   2/100: train=0.0774, val=0.0701, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0774, val=0.0701, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0773, val=0.0701, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0773, val=0.0701, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0773, val=0.0701, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0701)

============================================================
📊 Round 181 Summary - Client client_44
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0773, RMSE=0.2781, R²=0.0714
   Val:   Loss=0.0701, RMSE=0.2647, R²=0.0901
============================================================


📊 Round 181 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2440, R²: 0.0331

📊 Round 181 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2440, R²: 0.0331

📊 Round 181 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2440, R²: 0.0331

============================================================
🔄 Round 189 - Client client_44
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0758, val=0.0768 (↓), lr=0.000001
   • Epoch   2/100: train=0.0758, val=0.0768, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0758, val=0.0768, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0757, val=0.0768, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0757, val=0.0768, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0756, val=0.0768, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0768)

============================================================
📊 Round 189 Summary - Client client_44
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0756, RMSE=0.2750, R²=0.0767
   Val:   Loss=0.0768, RMSE=0.2771, R²=0.0473
============================================================


============================================================
🔄 Round 191 - Client client_44
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0743, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0743, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0743, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0743, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0742, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0742, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 191 Summary - Client client_44
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0743, RMSE=0.2726, R²=0.0805
   Val:   Loss=0.0821, RMSE=0.2866, R²=0.0467
============================================================


============================================================
🔄 Round 192 - Client client_44
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0756, val=0.0772 (↓), lr=0.000001
   • Epoch   2/100: train=0.0756, val=0.0772, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0755, val=0.0772, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0755, val=0.0772, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0755, val=0.0772, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0755, val=0.0771, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 192 Summary - Client client_44
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0755, RMSE=0.2748, R²=0.0812
   Val:   Loss=0.0772, RMSE=0.2779, R²=0.0573
============================================================


📊 Round 192 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2440, R²: 0.0331

📊 Round 192 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2440, R²: 0.0331

📊 Round 192 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2440, R²: 0.0331

📊 Round 192 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2440, R²: 0.0332

📊 Round 192 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2440, R²: 0.0331

============================================================
🔄 Round 201 - Client client_44
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0753, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0753, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0753, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0752, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0752, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0751, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 201 Summary - Client client_44
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0752, RMSE=0.2742, R²=0.0772
   Val:   Loss=0.0786, RMSE=0.2804, R²=0.0416
============================================================


============================================================
🔄 Round 202 - Client client_44
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0584 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0584, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0583, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0583, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0583, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0583, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0584)

============================================================
📊 Round 202 Summary - Client client_44
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=0.0800
   Val:   Loss=0.0584, RMSE=0.2416, R²=0.0584
============================================================


============================================================
🔄 Round 203 - Client client_44
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0756, val=0.0764 (↓), lr=0.000001
   • Epoch   2/100: train=0.0756, val=0.0764, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0756, val=0.0764, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0756, val=0.0764, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0756, val=0.0764, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0755, val=0.0764, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0764)

============================================================
📊 Round 203 Summary - Client client_44
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0757, RMSE=0.2752, R²=0.0792
   Val:   Loss=0.0764, RMSE=0.2765, R²=0.0654
============================================================


📊 Round 203 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2440, R²: 0.0331

============================================================
🔄 Round 206 - Client client_44
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0778, val=0.0690 (↓), lr=0.000001
   • Epoch   2/100: train=0.0777, val=0.0690, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0777, val=0.0690, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0777, val=0.0690, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0777, val=0.0690, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0776, val=0.0689, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0690)

============================================================
📊 Round 206 Summary - Client client_44
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0776, RMSE=0.2785, R²=0.0766
   Val:   Loss=0.0690, RMSE=0.2627, R²=0.0780
============================================================


📊 Round 206 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2440, R²: 0.0331

============================================================
🔄 Round 207 - Client client_44
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0748, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0748, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0747, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0747, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0747, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0747, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 207 Summary - Client client_44
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0750, RMSE=0.2738, R²=0.0666
   Val:   Loss=0.0794, RMSE=0.2817, R²=0.1131
============================================================


============================================================
🔄 Round 208 - Client client_44
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0773, val=0.0701 (↓), lr=0.000001
   • Epoch   2/100: train=0.0772, val=0.0701, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0772, val=0.0701, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0772, val=0.0701, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0772, val=0.0701, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0771, val=0.0701, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0701)

============================================================
📊 Round 208 Summary - Client client_44
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0773, RMSE=0.2780, R²=0.0793
   Val:   Loss=0.0701, RMSE=0.2648, R²=0.0597
============================================================


📊 Round 208 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2440, R²: 0.0332

============================================================
🔄 Round 211 - Client client_44
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0753, val=0.0780 (↓), lr=0.000001
   • Epoch   2/100: train=0.0753, val=0.0780, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0753, val=0.0780, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0752, val=0.0780, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0752, val=0.0780, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0752, val=0.0779, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 211 Summary - Client client_44
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0753, RMSE=0.2744, R²=0.0856
   Val:   Loss=0.0780, RMSE=0.2793, R²=0.0408
============================================================


📊 Round 211 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2440, R²: 0.0332

📊 Round 211 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2440, R²: 0.0332

============================================================
🔄 Round 214 - Client client_44
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0761, val=0.0744 (↓), lr=0.000001
   • Epoch   2/100: train=0.0761, val=0.0744, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0761, val=0.0744, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0761, val=0.0744, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0761, val=0.0744, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0760, val=0.0743, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0744)

============================================================
📊 Round 214 Summary - Client client_44
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0762, RMSE=0.2761, R²=0.0808
   Val:   Loss=0.0744, RMSE=0.2728, R²=0.0609
============================================================


📊 Round 214 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2440, R²: 0.0332

============================================================
🔄 Round 216 - Client client_44
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0762, val=0.0733 (↓), lr=0.000001
   • Epoch   2/100: train=0.0762, val=0.0733, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0762, val=0.0733, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0762, val=0.0733, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0762, val=0.0733, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0761, val=0.0732, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0733)

============================================================
📊 Round 216 Summary - Client client_44
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0765, RMSE=0.2766, R²=0.0647
   Val:   Loss=0.0733, RMSE=0.2707, R²=0.1222
============================================================


📊 Round 216 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2440, R²: 0.0331

============================================================
🔄 Round 217 - Client client_44
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0770, val=0.0715 (↓), lr=0.000001
   • Epoch   2/100: train=0.0770, val=0.0715, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0770, val=0.0715, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0769, val=0.0715, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0769, val=0.0715, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0768, val=0.0715, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0715)

============================================================
📊 Round 217 Summary - Client client_44
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0769, RMSE=0.2774, R²=0.0791
   Val:   Loss=0.0715, RMSE=0.2674, R²=0.0668
============================================================


📊 Round 217 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2440, R²: 0.0331

============================================================
🔄 Round 218 - Client client_44
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0765, val=0.0733 (↓), lr=0.000001
   • Epoch   2/100: train=0.0765, val=0.0732, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0765, val=0.0732, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0765, val=0.0732, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0764, val=0.0732, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0764, val=0.0732, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0733)

============================================================
📊 Round 218 Summary - Client client_44
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0765, RMSE=0.2766, R²=0.0777
   Val:   Loss=0.0733, RMSE=0.2707, R²=0.0729
============================================================


📊 Round 218 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2440, R²: 0.0332

📊 Round 218 Test Metrics:
   Loss: 0.0818, RMSE: 0.2860, MAE: 0.2440, R²: 0.0332

============================================================
🔄 Round 222 - Client client_44
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0759, val=0.0757 (↓), lr=0.000001
   • Epoch   2/100: train=0.0759, val=0.0757, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0759, val=0.0757, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0759, val=0.0757, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0758, val=0.0757, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0758, val=0.0757, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0757)

============================================================
📊 Round 222 Summary - Client client_44
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0759, RMSE=0.2755, R²=0.0767
   Val:   Loss=0.0757, RMSE=0.2751, R²=0.0420
============================================================


============================================================
🔄 Round 223 - Client client_44
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0761, val=0.0748 (↓), lr=0.000001
   • Epoch   2/100: train=0.0761, val=0.0748, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0761, val=0.0748, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0761, val=0.0748, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0761, val=0.0748, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0760, val=0.0748, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0748)

============================================================
📊 Round 223 Summary - Client client_44
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0761, RMSE=0.2759, R²=0.0800
   Val:   Loss=0.0748, RMSE=0.2735, R²=0.0606
============================================================


❌ Client client_44 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8687 {grpc_status:14, grpc_message:"Socket closed"}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8687 {grpc_status:14, grpc_message:"Socket closed"}"
>
