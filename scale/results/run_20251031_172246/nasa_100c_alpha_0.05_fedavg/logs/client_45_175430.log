[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3f32dd48-d27b-4fb0-b299-71e92262ae96
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 396ae4a4-816f-41bc-886a-63145568af02
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7fc9e2db-2d6e-4c82-9b7a-131bd3207419
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 071df0cc-0b33-4bc6-9e3b-5bb4d2ac310e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1e66d200-2798-4684-a428-461d6739b745
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c4be0e4d-3bea-4e99-9f9b-2288186a40ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8b9dce24-ab31-4e35-b621-0f6e9d0ee0d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b37fec26-d77b-4b44-b58e-dee59537eb8a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a61820c3-3919-41a2-a20b-afe60db52c8d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a25130c6-fe1a-42e4-a2d9-37d72a72f179
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 49df59a7-72b9-4b34-a8b6-f45a6f9c8c6c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 384c80e5-09c8-475c-b7ab-249cc10a22a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d1fd95f6-8c5b-414c-9746-0b19f5bf716a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 468d4e53-ef91-489a-ae82-f9b838b109f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e863e9db-e55c-4254-95f8-17c635c1f71c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6dccb8aa-b9de-4f61-b946-e75075c6bea9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 503c2fbe-ccd2-4d06-891a-d5b3edad4ee1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 69776c72-7f59-472a-9f87-f001c52f4171
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 104c6a04-3663-434e-b70c-715b947da862
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7fcc597e-ad83-42e0-880f-15b55d46e1a0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 95a544bc-2c95-4c33-8a16-fe609a92c17a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 39e616de-9db8-4438-94b4-412497155315
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e7fa673f-ce03-4b5e-94c2-5f91c8875133
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 791f7937-1ce2-444c-8789-d2d4dd4b9650
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b0dfdb58-0f9a-4892-88e4-c8d9be3d6e42
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bafb0c0c-988f-44ea-ad85-753be3d6953a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5d056903-9e98-4f84-9edb-d63f84fa65d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 391e2caa-b080-4140-904e-417deb287f8a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f7bd2ca9-af3e-4b9d-a5ef-971589ad9721
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 59b4203c-aa97-411a-b791-8ad3dcd3e5da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ec4a74c0-96e5-43f4-8a51-9ee683501a7b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e50dbc6e-65b1-4412-9891-c750c8797038
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7e5200f8-d64d-4805-baec-8816d6d8aea0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 963f8b75-0d5a-4850-90db-b8cc06118d82
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3d28ce73-91aa-4bfe-af6e-9e90d6588595
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b33ebd9f-94be-4087-8bed-33e31c21f48a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7a9c74ea-cc76-442c-9fe7-0ffd588a57f3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9bb561b1-28fc-4bd8-839f-6f333c1783d8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d2a46905-edcd-4d7e-92f2-da1c8ffd907f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fdea70df-88db-4871-a325-bc1b19ef831a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message da280b08-7b27-408a-a04b-b30fdd34ebda
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b121faa2-d93b-431b-acd0-2eb3cd289dd0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cb735494-6eae-437d-a4b1-f691d67fc436
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 05468513-8c11-4e68-813e-86b71821d5ea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 92c140eb-ad86-4763-ba39-7b0f2f0238a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eff1e097-7d46-47aa-8c71-469bc11233a8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 604db8e2-d1d9-47a5-a89f-17addd623c29
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e3fd7204-79a7-4d3e-9b45-8987cd9dfbe9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4df817c0-50ea-4c5f-812d-ae5b604efb2a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f86c201d-f582-4cc5-bcf7-133dfc0f33a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 02f429c1-d613-4445-a86b-5b67d39567d9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 26cdd37f-7a92-4ea5-93c6-4a091a04ef84
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fbeb9058-af0d-4e17-a196-5d635c7d1996
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message adf973ae-f753-4f33-bed7-36a675ff8928
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6422968d-b0b4-4733-b1e7-2f2b3ae3a7e2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3aafb315-3769-4409-97d9-ef260b5b90ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2d935d60-af61-4464-a5f5-c95b6ca5af31
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5c38e615-8ad6-4687-b4d9-7e9c76525880
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 760150cd-b366-4527-8f90-055205ec8127
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7308da8a-01ec-40ae-8155-37f012b7174e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bf210fab-d2c8-43d1-8c9a-8896e6b137d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c254a3ac-b5d0-4ba7-ad68-5584cccf9756
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 667e605f-2e00-484d-8559-964f64c545a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d6549850-378e-462e-ac56-c9910dd8f6ce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0863edfa-b23e-4210-b1b8-31b9dac9573c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b83038d2-ca8c-4ede-9ba4-bfac84230db3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9b887671-4dca-41e0-b6e1-fbbb3d99ba8d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3d8032d0-e527-4b9c-b532-dedbab3e82f2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dd69a3a1-c734-4092-8a61-3aa87bf9e559
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 58740e4c-bd81-4d7f-a7a7-005df8bb740c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ba32c323-6415-4698-9dc9-64aff3104ca3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b2805508-d1d9-4387-a371-91498218cc12
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8f00e4df-441e-4a35-9777-020ac93499a0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 29072913-aafc-4afe-8b69-6c202f90748a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 763ed1e6-ea4a-4910-9644-d73739afa25b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 904dd021-0d51-4119-abde-1cce15338681
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e2dfbeeb-c182-4159-8f55-9660850fdc47
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e9403da0-b985-4479-b1c1-8777f7f3cf78
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e1b90547-2cd5-404e-be73-ca4b9c79cc42
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7ddf5ebf-dfeb-4bbe-8fb0-72e870144abc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fac6c063-150c-40d6-b267-0a1d88cb1e91
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ef17a8ac-9256-4abd-99e3-eb46b8d83bcd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a62f69c9-af77-4661-9705-509884ceb61e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0d96dba6-97be-4754-90c3-4b5a94f0b10a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 709e2176-72bd-4761-8a96-e011346ac296
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1272f178-c1f2-47e3-a803-79c3f777c757
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d23a5b0c-e4cd-4cc8-b036-c6679eb03da1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f023c9c1-104c-4813-9766-2712c7d7fd14
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 45492f83-beef-4b69-ab15-06f07e9e0aec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d2f62a13-cf53-4d48-a9b2-e82df3e22b03
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d432e131-74af-4b9e-8802-a213aefa648d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0f005292-ba72-4a9c-9ee7-36b944048877
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1981b9bf-39e0-48bd-9a34-44437cfa5317
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b7cc8b23-1cd2-47ae-ab65-d5cc204bb240
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5f8ffe92-f01b-4bec-8a83-4951910aa1c6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 88de613f-2121-4cff-9726-5a6359d39475
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aa20d612-5df3-4760-96e5-ebf55a5aa7e2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b93a4d5f-c83f-4e2b-a729-b893a846401a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message abb5253b-2316-477d-a8f9-cc662b4f034f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5e17ed84-697f-47e1-8095-288e786add53
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d26b50b1-e5f2-400e-8e8d-06c6c4032313
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7588e8ec-4b23-4a9b-bcd1-a3145f4ec9e9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6ed9266d-9563-491c-acf0-61cffd1f17c6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3fe1a8d1-6657-485a-a7a8-cdda968eff6a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f80a1d2b-4701-4dcb-97c8-53936581b42e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ebc05bf3-aa16-469e-a5ae-68b06d7de468
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 60996047-de0e-4181-a5de-90e4f384c558
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0cb3899a-996f-4d66-8cd2-41add61e0887
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 89edcfcd-9a1d-4c0a-b046-50f8a6b8ed30
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a2dacdc1-b90d-4874-9627-b4b2d20eb1c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dbcbe3f4-fcf2-4169-b09c-5b483d4e61fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8f8a9e19-3976-4ea7-9b58-a4667e8ef24a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1a9beeb2-e2bf-4f9f-b3aa-cb0c4bf084d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 617622ad-850a-459b-88cc-4766cc93afaf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e2a36040-e0a9-4cf4-bdf2-b354d486a0f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 29287d5b-7d0e-4592-b201-fe8ada66c990
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f12d791c-a1e7-4133-8a4f-7ce24dbf9530
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2d721654-50dc-48e8-97b4-aec53d75f046
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 70586eb1-c9f0-49fe-917d-342adc482f4a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 43a3ced9-8e35-4569-9fbf-684723d13d3c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3f944cf0-5e29-4bf1-8e95-b583fec560d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 11b61ff3-728e-45c0-b3b4-5c0f309e2685
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e64373d1-21ba-453f-b083-da81fd2f64e0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0c98267a-c630-4352-b199-6929e4581d05
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3512cae8-a580-4add-8989-40d542766cc8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 15b39cf4-ab29-4fe1-ae7e-b120bb93680d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 561461f3-6b59-4388-8e92-7c9c55aaa83c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0a364da4-e183-47e8-aaac-1685f2d927a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 87e1cdca-15eb-4fff-9e83-8bd24446f53c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 09e0b21f-0411-4cba-91d1-752d22356bdb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 455e276d-8dcd-4cdc-a741-744ecdf39746
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 34dac8f4-0a41-43a7-a807-a5fbc63704e8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8a4c3889-7d92-46e8-88e0-5c83ee838816
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3b5b0bb4-b606-48b1-8823-c2512491c6ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d3be4c26-8c27-42e0-aff2-a344394e0f6d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c6c0639b-66fd-43bd-bc55-3e79ee417521
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cee749c2-c983-4f9c-8d0e-1d2d28bfc533
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ee1dfb13-d293-4321-9ea7-2974ce1cd75a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9f092ae0-7571-4555-a60e-edfbcabc7e00
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 166386c8-42ee-4424-911c-7a6d2796d4a9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3a4bf530-0eda-4d52-9f2a-9be5d91cd580
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 751f28cb-0e77-400a-9560-6e7aaa11a7ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bb712ce5-bd12-4125-8d91-518b7b84e797
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8fc5af60-e7e5-4c53-8d6a-24f79c2eae1f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6859d286-02a5-4616-9a86-3281b9d57a54
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8983bd54-4f23-4b24-9b92-88509bd0e255
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d9da3747-1628-4261-9248-879257a79efd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message da768536-f6ee-4b3e-93cd-74db8f6a11ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 93995060-2458-47f3-8f91-ab30aafde5e8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f5e1d740-78a6-46fd-9d79-2bcaa5f0196c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ef8f694a-eb41-47ee-a423-66e80c880b6c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 71f210cb-26cb-4434-848b-324936a0fe2d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2be3788b-e8df-4e1e-9452-51aa460a848f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9e016952-da1c-406c-8f53-1573113fc975
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7c218dbe-1f50-4d5b-8416-635dc1179a01
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 044cf768-0d3d-4c8a-8c85-972ac3a5fac4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8e82b7b0-c261-4c49-a132-5009d3fce3e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5e83bc1f-49b6-415c-8128-90585070ef72
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 869a8db4-4aee-4b02-976d-b309cc096a6d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 41a4a6f0-fa29-4f74-bdc0-0f93727e64ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a07e0554-0205-4cb9-869d-5adb82efe79a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 964a62ae-78d0-40c2-9440-80321571655b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7baf3059-71f2-40d3-bdee-1a5b4497c193
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 491a09b9-8988-4ee4-9091-c2beb4aec63a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a531246f-67b6-4c09-957f-f5e07933f226
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 01a462ca-7ad8-41ca-9c38-f6c6a64b7a87
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f7b77ba5-15f5-413f-a2cf-8989f85a0e5b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c18402b9-d12f-43b3-8782-3f595dd2945a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7a92a29f-8981-4131-bd80-6da9a2589a7c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ea3e4161-7cda-4427-a0cd-50685a000845
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 30365640-c4b7-40cb-9bf8-3de4ad14bce5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 76db1959-59c6-40de-a800-4d8e921ed13c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fd4e04f5-ab6b-4e55-8b5d-3e40c5df590e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4b8c624e-02c3-4ff6-a165-1ce2e6a9d505
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 28fe33fd-e32a-4418-9968-73581c4f0e10
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b5c63092-ac89-41ae-9012-d1e738708b4a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 424c0fd8-9891-45a8-8900-cd9da84e6d1e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2b6b1685-8b07-4325-991c-74da61a8bc35
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 98a591f0-ad59-41ee-a424-9c90c7d33dac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7480787e-036a-4ee4-803d-9f4e623b456b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a4c60546-ead7-4814-aac2-b530cc313823
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 28e7dd12-f1a4-47a9-affa-ede635a2c224
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8687 {grpc_status:14, grpc_message:"Socket closed"}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_45
Server: localhost:8687
Algorithm: FEDAVG
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_45
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_45/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_45/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_45/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_45/test_labels.txt

📊 Raw data loaded:
   Train: X=(1585, 24), y=(1585,)
   Test:  X=(397, 24), y=(397,)

⚠️  Limiting training data: 1585 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  388 samples, 5 features
✅ Client client_45 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

============================================================
🔄 Round 5 - Client client_45
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0747 (↓), lr=0.001000
   • Epoch   2/100: train=0.0776, val=0.0745, patience=1/15, lr=0.001000
   • Epoch   3/100: train=0.0768, val=0.0743, patience=2/15, lr=0.001000
   ✓ Epoch   4/100: train=0.0758, val=0.0741 (↓), lr=0.001000
   ✓ Epoch   5/100: train=0.0744, val=0.0732 (↓), lr=0.001000
   • Epoch  11/100: train=0.0662, val=0.0667, patience=1/15, lr=0.001000
   📉 Epoch 16: LR reduced 0.001000 → 0.000500
   • Epoch  21/100: train=0.0588, val=0.0650, patience=3/15, lr=0.000500
   📉 Epoch 24: LR reduced 0.000500 → 0.000250
   • Epoch  31/100: train=0.0554, val=0.0654, patience=13/15, lr=0.000250
   📉 Epoch 32: LR reduced 0.000250 → 0.000125

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0650)

============================================================
📊 Round 5 Summary - Client client_45
   Epochs: 33/100 (early stopped)
   LR: 0.001000 → 0.000125 (3 reductions)
   Train: Loss=0.0591, RMSE=0.2431, R²=0.2752
   Val:   Loss=0.0650, RMSE=0.2549, R²=0.1615
============================================================


============================================================
🔄 Round 6 - Client client_45
   Epochs: 100, Batch: 32, LR: 0.000125
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0765, val=0.0748 (↓), lr=0.000125
   ✓ Epoch   2/100: train=0.0760, val=0.0742 (↓), lr=0.000125
   • Epoch   3/100: train=0.0758, val=0.0737, patience=1/15, lr=0.000125
   ✓ Epoch   4/100: train=0.0755, val=0.0734 (↓), lr=0.000125
   • Epoch   5/100: train=0.0753, val=0.0732, patience=1/15, lr=0.000125
   📉 Epoch 7: LR reduced 0.000125 → 0.000063
   ✓ Epoch  11/100: train=0.0744, val=0.0724 (↓), lr=0.000063
   📉 Epoch 15: LR reduced 0.000063 → 0.000031
   • Epoch  21/100: train=0.0737, val=0.0718, patience=1/15, lr=0.000031
   📉 Epoch 23: LR reduced 0.000031 → 0.000016
   📉 Epoch 31: LR reduced 0.000016 → 0.000008
   • Epoch  31/100: train=0.0734, val=0.0716, patience=11/15, lr=0.000008

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0719)

============================================================
📊 Round 6 Summary - Client client_45
   Epochs: 35/100 (early stopped)
   LR: 0.000125 → 0.000008 (4 reductions)
   Train: Loss=0.0737, RMSE=0.2714, R²=0.0918
   Val:   Loss=0.0719, RMSE=0.2681, R²=0.0847
============================================================


============================================================
🔄 Round 7 - Client client_45
   Epochs: 100, Batch: 32, LR: 0.000008
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0736, val=0.0802 (↓), lr=0.000008
   • Epoch   2/100: train=0.0736, val=0.0802, patience=1/15, lr=0.000008
   • Epoch   3/100: train=0.0735, val=0.0801, patience=2/15, lr=0.000008
   📉 Epoch 4: LR reduced 0.000008 → 0.000004
   • Epoch   4/100: train=0.0735, val=0.0801, patience=3/15, lr=0.000004
   • Epoch   5/100: train=0.0734, val=0.0801, patience=4/15, lr=0.000004
   • Epoch  11/100: train=0.0732, val=0.0800, patience=10/15, lr=0.000004
   📉 Epoch 12: LR reduced 0.000004 → 0.000002

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 7 Summary - Client client_45
   Epochs: 16/100 (early stopped)
   LR: 0.000008 → 0.000002 (2 reductions)
   Train: Loss=0.0734, RMSE=0.2709, R²=0.0788
   Val:   Loss=0.0802, RMSE=0.2832, R²=0.0660
============================================================


📊 Round 7 Test Metrics:
   Loss: 0.0764, RMSE: 0.2763, MAE: 0.2414, R²: 0.0672

📊 Round 7 Test Metrics:
   Loss: 0.0765, RMSE: 0.2766, MAE: 0.2416, R²: 0.0650

📊 Round 7 Test Metrics:
   Loss: 0.0759, RMSE: 0.2755, MAE: 0.2403, R²: 0.0725

📊 Round 7 Test Metrics:
   Loss: 0.0761, RMSE: 0.2759, MAE: 0.2407, R²: 0.0701

============================================================
🔄 Round 12 - Client client_45
   Epochs: 100, Batch: 32, LR: 0.000002
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0732, val=0.0783 (↓), lr=0.000002
   • Epoch   2/100: train=0.0731, val=0.0783, patience=1/15, lr=0.000002
   • Epoch   3/100: train=0.0731, val=0.0783, patience=2/15, lr=0.000002
   📉 Epoch 4: LR reduced 0.000002 → 0.000001
   • Epoch   4/100: train=0.0731, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0731, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0730, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 12 Summary - Client client_45
   Epochs: 16/100 (early stopped)
   LR: 0.000002 → 0.000001 (1 reductions)
   Train: Loss=0.0733, RMSE=0.2708, R²=0.0758
   Val:   Loss=0.0783, RMSE=0.2799, R²=0.0965
============================================================


📊 Round 12 Test Metrics:
   Loss: 0.0758, RMSE: 0.2753, MAE: 0.2400, R²: 0.0741

📊 Round 12 Test Metrics:
   Loss: 0.0755, RMSE: 0.2748, MAE: 0.2395, R²: 0.0774

============================================================
🔄 Round 16 - Client client_45
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0719, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0719, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0719, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0719, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0718, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0717, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 16 Summary - Client client_45
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0719, RMSE=0.2681, R²=0.0905
   Val:   Loss=0.0794, RMSE=0.2819, R²=0.0954
============================================================


============================================================
🔄 Round 17 - Client client_45
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0744, val=0.0689 (↓), lr=0.000001
   • Epoch   2/100: train=0.0743, val=0.0689, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0743, val=0.0689, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0743, val=0.0689, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0743, val=0.0689, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0741, val=0.0688, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0689)

============================================================
📊 Round 17 Summary - Client client_45
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0743, RMSE=0.2725, R²=0.0923
   Val:   Loss=0.0689, RMSE=0.2625, R²=0.0923
============================================================


📊 Round 17 Test Metrics:
   Loss: 0.0752, RMSE: 0.2743, MAE: 0.2389, R²: 0.0810

============================================================
🔄 Round 19 - Client client_45
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0734, val=0.0726 (↓), lr=0.000001
   • Epoch   2/100: train=0.0734, val=0.0726, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0734, val=0.0726, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0733, val=0.0726, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0733, val=0.0726, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0732, val=0.0724, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0726)

============================================================
📊 Round 19 Summary - Client client_45
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0733, RMSE=0.2708, R²=0.0859
   Val:   Loss=0.0726, RMSE=0.2695, R²=0.1060
============================================================


📊 Round 19 Test Metrics:
   Loss: 0.0748, RMSE: 0.2735, MAE: 0.2380, R²: 0.0864

📊 Round 19 Test Metrics:
   Loss: 0.0747, RMSE: 0.2734, MAE: 0.2379, R²: 0.0871

============================================================
🔄 Round 23 - Client client_45
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0750, val=0.0637 (↓), lr=0.000001
   • Epoch   2/100: train=0.0749, val=0.0637, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0749, val=0.0637, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0749, val=0.0637, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0749, val=0.0637, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0747, val=0.0636, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0637)

============================================================
📊 Round 23 Summary - Client client_45
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0748, RMSE=0.2736, R²=0.1012
   Val:   Loss=0.0637, RMSE=0.2525, R²=0.1056
============================================================


📊 Round 23 Test Metrics:
   Loss: 0.0747, RMSE: 0.2733, MAE: 0.2379, R²: 0.0874

============================================================
🔄 Round 24 - Client client_45
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0714, val=0.0777 (↓), lr=0.000001
   • Epoch   2/100: train=0.0713, val=0.0777, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0713, val=0.0777, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0713, val=0.0776, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0713, val=0.0776, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0711, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 24 Summary - Client client_45
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0713, RMSE=0.2671, R²=0.0977
   Val:   Loss=0.0777, RMSE=0.2787, R²=0.1180
============================================================


📊 Round 24 Test Metrics:
   Loss: 0.0747, RMSE: 0.2733, MAE: 0.2379, R²: 0.0874

📊 Round 24 Test Metrics:
   Loss: 0.0747, RMSE: 0.2733, MAE: 0.2379, R²: 0.0874

============================================================
🔄 Round 26 - Client client_45
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0734, val=0.0691 (↓), lr=0.000001
   • Epoch   2/100: train=0.0734, val=0.0691, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0734, val=0.0691, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0733, val=0.0691, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0733, val=0.0691, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0732, val=0.0690, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0691)

============================================================
📊 Round 26 Summary - Client client_45
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0734, RMSE=0.2710, R²=0.0955
   Val:   Loss=0.0691, RMSE=0.2629, R²=0.1012
============================================================


============================================================
🔄 Round 27 - Client client_45
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0720, val=0.0754 (↓), lr=0.000001
   • Epoch   2/100: train=0.0719, val=0.0753, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0719, val=0.0753, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0719, val=0.0753, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0719, val=0.0753, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0717, val=0.0751, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0754)

============================================================
📊 Round 27 Summary - Client client_45
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0719, RMSE=0.2681, R²=0.1035
   Val:   Loss=0.0754, RMSE=0.2745, R²=0.1006
============================================================


📊 Round 27 Test Metrics:
   Loss: 0.0747, RMSE: 0.2733, MAE: 0.2379, R²: 0.0875

============================================================
🔄 Round 33 - Client client_45
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0734, val=0.0691 (↓), lr=0.000001
   • Epoch   2/100: train=0.0734, val=0.0691, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0733, val=0.0691, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0733, val=0.0691, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0733, val=0.0690, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0731, val=0.0689, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0691)

============================================================
📊 Round 33 Summary - Client client_45
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0734, RMSE=0.2710, R²=0.1002
   Val:   Loss=0.0691, RMSE=0.2629, R²=0.1085
============================================================


============================================================
🔄 Round 35 - Client client_45
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0722, val=0.0741 (↓), lr=0.000001
   • Epoch   2/100: train=0.0721, val=0.0741, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0721, val=0.0740, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0721, val=0.0740, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0721, val=0.0740, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0719, val=0.0738, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0741)

============================================================
📊 Round 35 Summary - Client client_45
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0722, RMSE=0.2687, R²=0.0973
   Val:   Loss=0.0741, RMSE=0.2722, R²=0.1220
============================================================


📊 Round 35 Test Metrics:
   Loss: 0.0747, RMSE: 0.2733, MAE: 0.2378, R²: 0.0876

============================================================
🔄 Round 37 - Client client_45
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0739, val=0.0677 (↓), lr=0.000001
   • Epoch   2/100: train=0.0738, val=0.0677, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0738, val=0.0677, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0738, val=0.0676, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0738, val=0.0676, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0736, val=0.0675, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0677)

============================================================
📊 Round 37 Summary - Client client_45
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0738, RMSE=0.2716, R²=0.1107
   Val:   Loss=0.0677, RMSE=0.2602, R²=0.0623
============================================================


📊 Round 37 Test Metrics:
   Loss: 0.0747, RMSE: 0.2733, MAE: 0.2378, R²: 0.0877

============================================================
🔄 Round 40 - Client client_45
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0702, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0701, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0701, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0701, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0701, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0700, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 40 Summary - Client client_45
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0704, RMSE=0.2653, R²=0.0995
   Val:   Loss=0.0813, RMSE=0.2851, R²=0.1037
============================================================


============================================================
🔄 Round 41 - Client client_45
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0713, val=0.0780 (↓), lr=0.000001
   • Epoch   2/100: train=0.0713, val=0.0779, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0712, val=0.0779, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0712, val=0.0779, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0712, val=0.0779, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0710, val=0.0778, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 41 Summary - Client client_45
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0712, RMSE=0.2669, R²=0.1119
   Val:   Loss=0.0780, RMSE=0.2792, R²=0.0695
============================================================


============================================================
🔄 Round 43 - Client client_45
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0718, val=0.0764 (↓), lr=0.000001
   • Epoch   2/100: train=0.0718, val=0.0764, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0718, val=0.0764, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0718, val=0.0763, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0717, val=0.0763, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0716, val=0.0762, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0764)

============================================================
📊 Round 43 Summary - Client client_45
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0716, RMSE=0.2676, R²=0.1030
   Val:   Loss=0.0764, RMSE=0.2764, R²=0.0923
============================================================


📊 Round 43 Test Metrics:
   Loss: 0.0747, RMSE: 0.2732, MAE: 0.2378, R²: 0.0879

📊 Round 43 Test Metrics:
   Loss: 0.0747, RMSE: 0.2732, MAE: 0.2378, R²: 0.0879

📊 Round 43 Test Metrics:
   Loss: 0.0747, RMSE: 0.2732, MAE: 0.2378, R²: 0.0879

============================================================
🔄 Round 46 - Client client_45
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0725, val=0.0735 (↓), lr=0.000001
   • Epoch   2/100: train=0.0725, val=0.0735, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0725, val=0.0735, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0724, val=0.0735, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0724, val=0.0735, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0722, val=0.0734, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0735)

============================================================
📊 Round 46 Summary - Client client_45
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0723, RMSE=0.2689, R²=0.1075
   Val:   Loss=0.0735, RMSE=0.2711, R²=0.0863
============================================================


📊 Round 46 Test Metrics:
   Loss: 0.0747, RMSE: 0.2732, MAE: 0.2378, R²: 0.0879

============================================================
🔄 Round 47 - Client client_45
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0722, val=0.0734 (↓), lr=0.000001
   • Epoch   2/100: train=0.0722, val=0.0733, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0722, val=0.0733, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0722, val=0.0733, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0721, val=0.0733, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0720, val=0.0732, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0734)

============================================================
📊 Round 47 Summary - Client client_45
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0723, RMSE=0.2690, R²=0.0998
   Val:   Loss=0.0734, RMSE=0.2709, R²=0.1173
============================================================


📊 Round 47 Test Metrics:
   Loss: 0.0747, RMSE: 0.2732, MAE: 0.2378, R²: 0.0879

📊 Round 47 Test Metrics:
   Loss: 0.0746, RMSE: 0.2732, MAE: 0.2378, R²: 0.0880

============================================================
🔄 Round 51 - Client client_45
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0731, val=0.0698 (↓), lr=0.000001
   • Epoch   2/100: train=0.0731, val=0.0698, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0730, val=0.0698, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0730, val=0.0698, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0730, val=0.0698, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0728, val=0.0697, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0698)

============================================================
📊 Round 51 Summary - Client client_45
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0732, RMSE=0.2706, R²=0.1069
   Val:   Loss=0.0698, RMSE=0.2642, R²=0.0709
============================================================


📊 Round 51 Test Metrics:
   Loss: 0.0746, RMSE: 0.2732, MAE: 0.2378, R²: 0.0880

📊 Round 51 Test Metrics:
   Loss: 0.0746, RMSE: 0.2732, MAE: 0.2378, R²: 0.0880

============================================================
🔄 Round 55 - Client client_45
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0739, val=0.0668 (↓), lr=0.000001
   • Epoch   2/100: train=0.0739, val=0.0668, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0738, val=0.0668, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0738, val=0.0668, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0738, val=0.0668, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0736, val=0.0667, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0668)

============================================================
📊 Round 55 Summary - Client client_45
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0740, RMSE=0.2719, R²=0.1094
   Val:   Loss=0.0668, RMSE=0.2585, R²=0.0757
============================================================


📊 Round 55 Test Metrics:
   Loss: 0.0746, RMSE: 0.2732, MAE: 0.2378, R²: 0.0881

============================================================
🔄 Round 58 - Client client_45
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0729, val=0.0710 (↓), lr=0.000001
   • Epoch   2/100: train=0.0729, val=0.0709, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0729, val=0.0709, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0729, val=0.0709, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0729, val=0.0709, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0727, val=0.0708, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0710)

============================================================
📊 Round 58 Summary - Client client_45
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0729, RMSE=0.2700, R²=0.1089
   Val:   Loss=0.0710, RMSE=0.2664, R²=0.0703
============================================================


📊 Round 58 Test Metrics:
   Loss: 0.0746, RMSE: 0.2732, MAE: 0.2378, R²: 0.0882

============================================================
🔄 Round 62 - Client client_45
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0723, val=0.0748 (↓), lr=0.000001
   • Epoch   2/100: train=0.0723, val=0.0748, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0722, val=0.0747, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0722, val=0.0747, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0722, val=0.0747, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0721, val=0.0746, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0748)

============================================================
📊 Round 62 Summary - Client client_45
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0720, RMSE=0.2682, R²=0.0999
   Val:   Loss=0.0748, RMSE=0.2734, R²=0.0997
============================================================


============================================================
🔄 Round 64 - Client client_45
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0729, val=0.0708 (↓), lr=0.000001
   • Epoch   2/100: train=0.0729, val=0.0707, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0728, val=0.0707, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0728, val=0.0707, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0728, val=0.0707, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0727, val=0.0705, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0708)

============================================================
📊 Round 64 Summary - Client client_45
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0730, RMSE=0.2701, R²=0.1054
   Val:   Loss=0.0708, RMSE=0.2660, R²=0.0956
============================================================


📊 Round 64 Test Metrics:
   Loss: 0.0746, RMSE: 0.2732, MAE: 0.2377, R²: 0.0884

📊 Round 64 Test Metrics:
   Loss: 0.0746, RMSE: 0.2732, MAE: 0.2377, R²: 0.0884

📊 Round 64 Test Metrics:
   Loss: 0.0746, RMSE: 0.2731, MAE: 0.2377, R²: 0.0886

============================================================
🔄 Round 71 - Client client_45
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0718, val=0.0756 (↓), lr=0.000001
   • Epoch   2/100: train=0.0718, val=0.0756, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0718, val=0.0756, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0717, val=0.0756, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0717, val=0.0756, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0715, val=0.0755, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0756)

============================================================
📊 Round 71 Summary - Client client_45
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0717, RMSE=0.2678, R²=0.1101
   Val:   Loss=0.0756, RMSE=0.2750, R²=0.0793
============================================================


============================================================
🔄 Round 72 - Client client_45
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0732, val=0.0692 (↓), lr=0.000001
   • Epoch   2/100: train=0.0732, val=0.0692, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0732, val=0.0692, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0732, val=0.0691, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0731, val=0.0691, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0730, val=0.0691, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0692)

============================================================
📊 Round 72 Summary - Client client_45
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0733, RMSE=0.2708, R²=0.1082
   Val:   Loss=0.0692, RMSE=0.2630, R²=0.0838
============================================================


📊 Round 72 Test Metrics:
   Loss: 0.0746, RMSE: 0.2731, MAE: 0.2377, R²: 0.0887

📊 Round 72 Test Metrics:
   Loss: 0.0746, RMSE: 0.2731, MAE: 0.2377, R²: 0.0887

============================================================
🔄 Round 74 - Client client_45
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0711, val=0.0780 (↓), lr=0.000001
   • Epoch   2/100: train=0.0711, val=0.0779, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0710, val=0.0779, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0710, val=0.0779, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0710, val=0.0779, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0709, val=0.0777, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 74 Summary - Client client_45
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0711, RMSE=0.2667, R²=0.1064
   Val:   Loss=0.0780, RMSE=0.2792, R²=0.0926
============================================================


📊 Round 74 Test Metrics:
   Loss: 0.0746, RMSE: 0.2731, MAE: 0.2377, R²: 0.0887

============================================================
🔄 Round 77 - Client client_45
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0704, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0703, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0703, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0703, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0703, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0701, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 77 Summary - Client client_45
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0704, RMSE=0.2652, R²=0.1130
   Val:   Loss=0.0810, RMSE=0.2846, R²=0.0715
============================================================


📊 Round 77 Test Metrics:
   Loss: 0.0746, RMSE: 0.2731, MAE: 0.2376, R²: 0.0889

📊 Round 77 Test Metrics:
   Loss: 0.0746, RMSE: 0.2731, MAE: 0.2376, R²: 0.0890

============================================================
🔄 Round 80 - Client client_45
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0742, val=0.0648 (↓), lr=0.000001
   • Epoch   2/100: train=0.0742, val=0.0648, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0742, val=0.0648, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0742, val=0.0648, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0742, val=0.0647, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0740, val=0.0646, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0648)

============================================================
📊 Round 80 Summary - Client client_45
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0744, RMSE=0.2727, R²=0.0990
   Val:   Loss=0.0648, RMSE=0.2546, R²=0.1209
============================================================


============================================================
🔄 Round 81 - Client client_45
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0724, val=0.0729 (↓), lr=0.000001
   • Epoch   2/100: train=0.0723, val=0.0729, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0723, val=0.0729, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0723, val=0.0729, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0723, val=0.0729, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0721, val=0.0727, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0729)

============================================================
📊 Round 81 Summary - Client client_45
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0724, RMSE=0.2690, R²=0.1037
   Val:   Loss=0.0729, RMSE=0.2701, R²=0.1041
============================================================


============================================================
🔄 Round 83 - Client client_45
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0718, val=0.0751 (↓), lr=0.000001
   • Epoch   2/100: train=0.0718, val=0.0751, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0717, val=0.0751, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0717, val=0.0750, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0717, val=0.0750, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0715, val=0.0749, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0751)

============================================================
📊 Round 83 Summary - Client client_45
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0718, RMSE=0.2680, R²=0.1044
   Val:   Loss=0.0751, RMSE=0.2740, R²=0.0997
============================================================


📊 Round 83 Test Metrics:
   Loss: 0.0746, RMSE: 0.2731, MAE: 0.2376, R²: 0.0890

============================================================
🔄 Round 85 - Client client_45
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0717, val=0.0753 (↓), lr=0.000001
   • Epoch   2/100: train=0.0717, val=0.0752, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0717, val=0.0752, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0716, val=0.0752, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0716, val=0.0752, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0715, val=0.0751, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0753)

============================================================
📊 Round 85 Summary - Client client_45
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0718, RMSE=0.2679, R²=0.1047
   Val:   Loss=0.0753, RMSE=0.2743, R²=0.0890
============================================================


📊 Round 85 Test Metrics:
   Loss: 0.0746, RMSE: 0.2731, MAE: 0.2376, R²: 0.0890

============================================================
🔄 Round 86 - Client client_45
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0739, val=0.0674 (↓), lr=0.000001
   • Epoch   2/100: train=0.0738, val=0.0674, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0738, val=0.0673, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0738, val=0.0673, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0738, val=0.0673, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0736, val=0.0671, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0674)

============================================================
📊 Round 86 Summary - Client client_45
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0737, RMSE=0.2715, R²=0.0983
   Val:   Loss=0.0674, RMSE=0.2596, R²=0.1292
============================================================


============================================================
🔄 Round 87 - Client client_45
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0745, val=0.0633 (↓), lr=0.000001
   • Epoch   2/100: train=0.0745, val=0.0633, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0745, val=0.0632, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0745, val=0.0632, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0745, val=0.0632, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0743, val=0.0630, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0633)

============================================================
📊 Round 87 Summary - Client client_45
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0748, RMSE=0.2734, R²=0.0913
   Val:   Loss=0.0633, RMSE=0.2516, R²=0.1515
============================================================


📊 Round 87 Test Metrics:
   Loss: 0.0746, RMSE: 0.2731, MAE: 0.2376, R²: 0.0891

============================================================
🔄 Round 88 - Client client_45
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0733, val=0.0691 (↓), lr=0.000001
   • Epoch   2/100: train=0.0732, val=0.0691, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0732, val=0.0691, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0732, val=0.0691, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0732, val=0.0691, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0730, val=0.0689, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0691)

============================================================
📊 Round 88 Summary - Client client_45
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0733, RMSE=0.2707, R²=0.1079
   Val:   Loss=0.0691, RMSE=0.2630, R²=0.0885
============================================================


📊 Round 88 Test Metrics:
   Loss: 0.0746, RMSE: 0.2731, MAE: 0.2376, R²: 0.0891

📊 Round 88 Test Metrics:
   Loss: 0.0746, RMSE: 0.2730, MAE: 0.2376, R²: 0.0891

============================================================
🔄 Round 90 - Client client_45
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0728, val=0.0713 (↓), lr=0.000001
   • Epoch   2/100: train=0.0727, val=0.0712, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0727, val=0.0712, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0727, val=0.0712, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0727, val=0.0712, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0725, val=0.0710, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0713)

============================================================
📊 Round 90 Summary - Client client_45
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0728, RMSE=0.2697, R²=0.1082
   Val:   Loss=0.0713, RMSE=0.2669, R²=0.0885
============================================================


📊 Round 90 Test Metrics:
   Loss: 0.0746, RMSE: 0.2730, MAE: 0.2376, R²: 0.0892

📊 Round 90 Test Metrics:
   Loss: 0.0745, RMSE: 0.2730, MAE: 0.2376, R²: 0.0893

📊 Round 90 Test Metrics:
   Loss: 0.0745, RMSE: 0.2730, MAE: 0.2376, R²: 0.0893

============================================================
🔄 Round 95 - Client client_45
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0735, val=0.0691 (↓), lr=0.000001
   • Epoch   2/100: train=0.0735, val=0.0691, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0735, val=0.0691, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0735, val=0.0691, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0735, val=0.0690, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0733, val=0.0689, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0691)

============================================================
📊 Round 95 Summary - Client client_45
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0733, RMSE=0.2707, R²=0.1007
   Val:   Loss=0.0691, RMSE=0.2629, R²=0.1050
============================================================


📊 Round 95 Test Metrics:
   Loss: 0.0745, RMSE: 0.2730, MAE: 0.2376, R²: 0.0893

============================================================
🔄 Round 96 - Client client_45
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0712, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0711, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0711, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0711, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0711, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0709, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 96 Summary - Client client_45
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0709, RMSE=0.2663, R²=0.1037
   Val:   Loss=0.0786, RMSE=0.2804, R²=0.1001
============================================================


============================================================
🔄 Round 97 - Client client_45
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0740, val=0.0669 (↓), lr=0.000001
   • Epoch   2/100: train=0.0740, val=0.0669, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0740, val=0.0669, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0740, val=0.0668, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0739, val=0.0668, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0738, val=0.0667, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0669)

============================================================
📊 Round 97 Summary - Client client_45
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0738, RMSE=0.2717, R²=0.0988
   Val:   Loss=0.0669, RMSE=0.2586, R²=0.1238
============================================================


📊 Round 97 Test Metrics:
   Loss: 0.0745, RMSE: 0.2730, MAE: 0.2376, R²: 0.0895

============================================================
🔄 Round 100 - Client client_45
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0721, val=0.0739 (↓), lr=0.000001
   • Epoch   2/100: train=0.0720, val=0.0739, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0720, val=0.0739, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0720, val=0.0739, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0719, val=0.0739, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0718, val=0.0738, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0739)

============================================================
📊 Round 100 Summary - Client client_45
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0721, RMSE=0.2684, R²=0.1067
   Val:   Loss=0.0739, RMSE=0.2719, R²=0.0874
============================================================


📊 Round 100 Test Metrics:
   Loss: 0.0745, RMSE: 0.2730, MAE: 0.2376, R²: 0.0895

============================================================
🔄 Round 102 - Client client_45
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0730, val=0.0715 (↓), lr=0.000001
   • Epoch   2/100: train=0.0729, val=0.0715, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0729, val=0.0714, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0729, val=0.0714, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0729, val=0.0714, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0727, val=0.0713, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0715)

============================================================
📊 Round 102 Summary - Client client_45
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0727, RMSE=0.2696, R²=0.1048
   Val:   Loss=0.0715, RMSE=0.2673, R²=0.1048
============================================================


============================================================
🔄 Round 103 - Client client_45
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0712, val=0.0779 (↓), lr=0.000001
   • Epoch   2/100: train=0.0712, val=0.0779, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0711, val=0.0779, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0711, val=0.0779, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0711, val=0.0778, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0709, val=0.0778, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0779)

============================================================
📊 Round 103 Summary - Client client_45
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0711, RMSE=0.2666, R²=0.1097
   Val:   Loss=0.0779, RMSE=0.2791, R²=0.0628
============================================================


============================================================
🔄 Round 105 - Client client_45
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0715, val=0.0750 (↓), lr=0.000001
   • Epoch   2/100: train=0.0714, val=0.0750, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0714, val=0.0750, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0714, val=0.0750, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0714, val=0.0750, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0712, val=0.0749, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0750)

============================================================
📊 Round 105 Summary - Client client_45
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0718, RMSE=0.2679, R²=0.1050
   Val:   Loss=0.0750, RMSE=0.2739, R²=0.0907
============================================================


============================================================
🔄 Round 107 - Client client_45
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0719, val=0.0754 (↓), lr=0.000001
   • Epoch   2/100: train=0.0719, val=0.0754, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0719, val=0.0754, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0718, val=0.0754, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0718, val=0.0754, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0716, val=0.0753, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0754)

============================================================
📊 Round 107 Summary - Client client_45
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0717, RMSE=0.2677, R²=0.1130
   Val:   Loss=0.0754, RMSE=0.2747, R²=0.0654
============================================================


============================================================
🔄 Round 109 - Client client_45
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0707, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0707, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0706, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0706, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0706, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0704, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 109 Summary - Client client_45
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0707, RMSE=0.2659, R²=0.1029
   Val:   Loss=0.0793, RMSE=0.2815, R²=0.1075
============================================================


============================================================
🔄 Round 110 - Client client_45
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0711, val=0.0776 (↓), lr=0.000001
   • Epoch   2/100: train=0.0711, val=0.0776, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0710, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0710, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0710, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0708, val=0.0774, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 110 Summary - Client client_45
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0711, RMSE=0.2667, R²=0.1100
   Val:   Loss=0.0776, RMSE=0.2786, R²=0.0860
============================================================


============================================================
🔄 Round 111 - Client client_45
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0738, val=0.0676 (↓), lr=0.000001
   • Epoch   2/100: train=0.0738, val=0.0675, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0738, val=0.0675, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0738, val=0.0675, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0737, val=0.0675, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0736, val=0.0674, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0676)

============================================================
📊 Round 111 Summary - Client client_45
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0736, RMSE=0.2713, R²=0.1062
   Val:   Loss=0.0676, RMSE=0.2599, R²=0.0989
============================================================


📊 Round 111 Test Metrics:
   Loss: 0.0745, RMSE: 0.2729, MAE: 0.2375, R²: 0.0898

============================================================
🔄 Round 114 - Client client_45
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0714, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0714, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0713, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0713, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0713, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0711, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 114 Summary - Client client_45
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0709, RMSE=0.2663, R²=0.1083
   Val:   Loss=0.0784, RMSE=0.2801, R²=0.0932
============================================================


📊 Round 114 Test Metrics:
   Loss: 0.0745, RMSE: 0.2729, MAE: 0.2375, R²: 0.0899

============================================================
🔄 Round 115 - Client client_45
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0713, val=0.0769 (↓), lr=0.000001
   • Epoch   2/100: train=0.0713, val=0.0769, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0712, val=0.0769, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0712, val=0.0768, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0712, val=0.0768, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0710, val=0.0767, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0769)

============================================================
📊 Round 115 Summary - Client client_45
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0713, RMSE=0.2670, R²=0.1067
   Val:   Loss=0.0769, RMSE=0.2773, R²=0.0986
============================================================


📊 Round 115 Test Metrics:
   Loss: 0.0745, RMSE: 0.2729, MAE: 0.2375, R²: 0.0899

============================================================
🔄 Round 116 - Client client_45
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0715, val=0.0759 (↓), lr=0.000001
   • Epoch   2/100: train=0.0714, val=0.0759, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0714, val=0.0759, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0714, val=0.0758, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0714, val=0.0758, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0712, val=0.0756, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0759)

============================================================
📊 Round 116 Summary - Client client_45
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0715, RMSE=0.2674, R²=0.1001
   Val:   Loss=0.0759, RMSE=0.2755, R²=0.1221
============================================================


📊 Round 116 Test Metrics:
   Loss: 0.0745, RMSE: 0.2729, MAE: 0.2375, R²: 0.0901

============================================================
🔄 Round 120 - Client client_45
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0716, val=0.0761 (↓), lr=0.000001
   • Epoch   2/100: train=0.0716, val=0.0760, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0715, val=0.0760, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0715, val=0.0760, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0715, val=0.0760, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0713, val=0.0759, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0761)

============================================================
📊 Round 120 Summary - Client client_45
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0715, RMSE=0.2673, R²=0.1071
   Val:   Loss=0.0761, RMSE=0.2758, R²=0.0868
============================================================


📊 Round 120 Test Metrics:
   Loss: 0.0745, RMSE: 0.2729, MAE: 0.2374, R²: 0.0902

============================================================
🔄 Round 124 - Client client_45
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0689, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0689, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0688, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0688, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0688, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0686, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 124 Summary - Client client_45
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0690, RMSE=0.2626, R²=0.1090
   Val:   Loss=0.0861, RMSE=0.2935, R²=0.0899
============================================================


📊 Round 124 Test Metrics:
   Loss: 0.0745, RMSE: 0.2729, MAE: 0.2374, R²: 0.0902

============================================================
🔄 Round 128 - Client client_45
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0721, val=0.0736 (↓), lr=0.000001
   • Epoch   2/100: train=0.0720, val=0.0735, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0720, val=0.0735, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0720, val=0.0735, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0720, val=0.0735, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0718, val=0.0733, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0736)

============================================================
📊 Round 128 Summary - Client client_45
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0721, RMSE=0.2685, R²=0.0968
   Val:   Loss=0.0736, RMSE=0.2712, R²=0.1212
============================================================


📊 Round 128 Test Metrics:
   Loss: 0.0745, RMSE: 0.2729, MAE: 0.2374, R²: 0.0903

============================================================
🔄 Round 129 - Client client_45
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0734, val=0.0683 (↓), lr=0.000001
   • Epoch   2/100: train=0.0734, val=0.0683, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0734, val=0.0683, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0734, val=0.0683, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0733, val=0.0683, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0732, val=0.0682, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0683)

============================================================
📊 Round 129 Summary - Client client_45
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0734, RMSE=0.2709, R²=0.1069
   Val:   Loss=0.0683, RMSE=0.2614, R²=0.0945
============================================================


============================================================
🔄 Round 132 - Client client_45
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0746, val=0.0638 (↓), lr=0.000001
   • Epoch   2/100: train=0.0746, val=0.0638, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0745, val=0.0638, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0745, val=0.0637, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0745, val=0.0637, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0743, val=0.0636, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0638)

============================================================
📊 Round 132 Summary - Client client_45
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0745, RMSE=0.2730, R²=0.1023
   Val:   Loss=0.0638, RMSE=0.2526, R²=0.1126
============================================================


📊 Round 132 Test Metrics:
   Loss: 0.0745, RMSE: 0.2729, MAE: 0.2374, R²: 0.0903

============================================================
🔄 Round 134 - Client client_45
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0738, val=0.0677 (↓), lr=0.000001
   • Epoch   2/100: train=0.0738, val=0.0677, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0738, val=0.0677, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0737, val=0.0676, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0737, val=0.0676, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0736, val=0.0675, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0677)

============================================================
📊 Round 134 Summary - Client client_45
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0735, RMSE=0.2712, R²=0.1021
   Val:   Loss=0.0677, RMSE=0.2602, R²=0.1198
============================================================


============================================================
🔄 Round 135 - Client client_45
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0737, val=0.0680 (↓), lr=0.000001
   • Epoch   2/100: train=0.0737, val=0.0680, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0736, val=0.0679, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0736, val=0.0679, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0736, val=0.0679, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0734, val=0.0678, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0680)

============================================================
📊 Round 135 Summary - Client client_45
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0735, RMSE=0.2710, R²=0.1042
   Val:   Loss=0.0680, RMSE=0.2607, R²=0.1055
============================================================


📊 Round 135 Test Metrics:
   Loss: 0.0745, RMSE: 0.2729, MAE: 0.2374, R²: 0.0903

📊 Round 135 Test Metrics:
   Loss: 0.0745, RMSE: 0.2729, MAE: 0.2374, R²: 0.0903

============================================================
🔄 Round 141 - Client client_45
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0716, val=0.0754 (↓), lr=0.000001
   • Epoch   2/100: train=0.0716, val=0.0754, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0716, val=0.0754, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0716, val=0.0754, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0715, val=0.0754, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0714, val=0.0752, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0754)

============================================================
📊 Round 141 Summary - Client client_45
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0716, RMSE=0.2676, R²=0.1073
   Val:   Loss=0.0754, RMSE=0.2747, R²=0.0986
============================================================


📊 Round 141 Test Metrics:
   Loss: 0.0744, RMSE: 0.2729, MAE: 0.2374, R²: 0.0904

============================================================
🔄 Round 142 - Client client_45
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0714, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0713, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0713, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0713, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0712, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0711, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 142 Summary - Client client_45
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0711, RMSE=0.2666, R²=0.1003
   Val:   Loss=0.0775, RMSE=0.2785, R²=0.0929
============================================================


📊 Round 142 Test Metrics:
   Loss: 0.0744, RMSE: 0.2729, MAE: 0.2374, R²: 0.0904

============================================================
🔄 Round 144 - Client client_45
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0739, val=0.0664 (↓), lr=0.000001
   • Epoch   2/100: train=0.0739, val=0.0664, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0739, val=0.0663, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0739, val=0.0663, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0738, val=0.0663, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0737, val=0.0662, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0664)

============================================================
📊 Round 144 Summary - Client client_45
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0738, RMSE=0.2717, R²=0.1037
   Val:   Loss=0.0664, RMSE=0.2576, R²=0.1006
============================================================


============================================================
🔄 Round 145 - Client client_45
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0743, val=0.0648 (↓), lr=0.000001
   • Epoch   2/100: train=0.0742, val=0.0648, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0742, val=0.0648, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0742, val=0.0648, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0742, val=0.0648, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0740, val=0.0646, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0648)

============================================================
📊 Round 145 Summary - Client client_45
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0742, RMSE=0.2724, R²=0.1050
   Val:   Loss=0.0648, RMSE=0.2547, R²=0.1055
============================================================


📊 Round 145 Test Metrics:
   Loss: 0.0744, RMSE: 0.2728, MAE: 0.2374, R²: 0.0905

📊 Round 145 Test Metrics:
   Loss: 0.0744, RMSE: 0.2728, MAE: 0.2374, R²: 0.0905

============================================================
🔄 Round 147 - Client client_45
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0736, val=0.0673 (↓), lr=0.000001
   • Epoch   2/100: train=0.0735, val=0.0673, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0735, val=0.0673, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0735, val=0.0672, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0735, val=0.0672, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0733, val=0.0671, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0673)

============================================================
📊 Round 147 Summary - Client client_45
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0736, RMSE=0.2713, R²=0.1076
   Val:   Loss=0.0673, RMSE=0.2594, R²=0.0976
============================================================


📊 Round 147 Test Metrics:
   Loss: 0.0744, RMSE: 0.2728, MAE: 0.2374, R²: 0.0906

📊 Round 147 Test Metrics:
   Loss: 0.0744, RMSE: 0.2728, MAE: 0.2374, R²: 0.0906

============================================================
🔄 Round 151 - Client client_45
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0717, val=0.0754 (↓), lr=0.000001
   • Epoch   2/100: train=0.0717, val=0.0754, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0717, val=0.0754, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0717, val=0.0754, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0716, val=0.0753, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0715, val=0.0752, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0754)

============================================================
📊 Round 151 Summary - Client client_45
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0716, RMSE=0.2675, R²=0.1063
   Val:   Loss=0.0754, RMSE=0.2746, R²=0.1018
============================================================


📊 Round 151 Test Metrics:
   Loss: 0.0744, RMSE: 0.2728, MAE: 0.2374, R²: 0.0907

============================================================
🔄 Round 154 - Client client_45
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0697, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0697, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0696, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0696, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0696, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0694, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 154 Summary - Client client_45
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0698, RMSE=0.2642, R²=0.1117
   Val:   Loss=0.0825, RMSE=0.2873, R²=0.0788
============================================================


============================================================
🔄 Round 155 - Client client_45
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0719, val=0.0738 (↓), lr=0.000001
   • Epoch   2/100: train=0.0719, val=0.0738, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0719, val=0.0738, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0718, val=0.0738, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0718, val=0.0737, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0717, val=0.0736, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0738)

============================================================
📊 Round 155 Summary - Client client_45
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0720, RMSE=0.2682, R²=0.1044
   Val:   Loss=0.0738, RMSE=0.2717, R²=0.1047
============================================================


============================================================
🔄 Round 157 - Client client_45
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0724, val=0.0720 (↓), lr=0.000001
   • Epoch   2/100: train=0.0723, val=0.0720, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0723, val=0.0719, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0723, val=0.0719, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0723, val=0.0719, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0721, val=0.0718, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0720)

============================================================
📊 Round 157 Summary - Client client_45
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0724, RMSE=0.2691, R²=0.1044
   Val:   Loss=0.0720, RMSE=0.2683, R²=0.1125
============================================================


============================================================
🔄 Round 159 - Client client_45
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0732, val=0.0700 (↓), lr=0.000001
   • Epoch   2/100: train=0.0732, val=0.0699, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0731, val=0.0699, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0731, val=0.0699, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0731, val=0.0699, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0729, val=0.0698, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0700)

============================================================
📊 Round 159 Summary - Client client_45
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0729, RMSE=0.2700, R²=0.1021
   Val:   Loss=0.0700, RMSE=0.2645, R²=0.1142
============================================================


📊 Round 159 Test Metrics:
   Loss: 0.0744, RMSE: 0.2728, MAE: 0.2374, R²: 0.0908

📊 Round 159 Test Metrics:
   Loss: 0.0744, RMSE: 0.2728, MAE: 0.2374, R²: 0.0908

============================================================
🔄 Round 163 - Client client_45
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0721, val=0.0736 (↓), lr=0.000001
   • Epoch   2/100: train=0.0720, val=0.0736, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0720, val=0.0736, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0720, val=0.0735, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0720, val=0.0735, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0718, val=0.0734, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0736)

============================================================
📊 Round 163 Summary - Client client_45
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0720, RMSE=0.2683, R²=0.1090
   Val:   Loss=0.0736, RMSE=0.2713, R²=0.0922
============================================================


📊 Round 163 Test Metrics:
   Loss: 0.0744, RMSE: 0.2728, MAE: 0.2374, R²: 0.0909

============================================================
🔄 Round 165 - Client client_45
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0715, val=0.0752 (↓), lr=0.000001
   • Epoch   2/100: train=0.0714, val=0.0752, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0714, val=0.0751, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0714, val=0.0751, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0714, val=0.0751, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0712, val=0.0750, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0752)

============================================================
📊 Round 165 Summary - Client client_45
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0716, RMSE=0.2676, R²=0.1089
   Val:   Loss=0.0752, RMSE=0.2742, R²=0.0957
============================================================


📊 Round 165 Test Metrics:
   Loss: 0.0744, RMSE: 0.2728, MAE: 0.2374, R²: 0.0909

📊 Round 165 Test Metrics:
   Loss: 0.0744, RMSE: 0.2728, MAE: 0.2374, R²: 0.0909

============================================================
🔄 Round 169 - Client client_45
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0705, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0705, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0704, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0704, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0704, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0702, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 169 Summary - Client client_45
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0705, RMSE=0.2655, R²=0.1088
   Val:   Loss=0.0796, RMSE=0.2821, R²=0.0535
============================================================


📊 Round 169 Test Metrics:
   Loss: 0.0744, RMSE: 0.2728, MAE: 0.2374, R²: 0.0909

============================================================
🔄 Round 172 - Client client_45
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0725, val=0.0732 (↓), lr=0.000001
   • Epoch   2/100: train=0.0725, val=0.0732, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0724, val=0.0732, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0724, val=0.0731, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0724, val=0.0731, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0722, val=0.0730, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0732)

============================================================
📊 Round 172 Summary - Client client_45
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0721, RMSE=0.2685, R²=0.1119
   Val:   Loss=0.0732, RMSE=0.2705, R²=0.0801
============================================================


📊 Round 172 Test Metrics:
   Loss: 0.0744, RMSE: 0.2728, MAE: 0.2373, R²: 0.0910

============================================================
🔄 Round 173 - Client client_45
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0730, val=0.0689 (↓), lr=0.000001
   • Epoch   2/100: train=0.0730, val=0.0689, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0730, val=0.0689, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0729, val=0.0689, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0729, val=0.0689, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0728, val=0.0687, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0689)

============================================================
📊 Round 173 Summary - Client client_45
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0731, RMSE=0.2704, R²=0.1042
   Val:   Loss=0.0689, RMSE=0.2626, R²=0.1128
============================================================


============================================================
🔄 Round 174 - Client client_45
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0737, val=0.0666 (↓), lr=0.000001
   • Epoch   2/100: train=0.0736, val=0.0666, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0736, val=0.0665, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0736, val=0.0665, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0736, val=0.0665, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0734, val=0.0664, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0666)

============================================================
📊 Round 174 Summary - Client client_45
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0737, RMSE=0.2715, R²=0.0987
   Val:   Loss=0.0666, RMSE=0.2581, R²=0.1230
============================================================


============================================================
🔄 Round 175 - Client client_45
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0737, val=0.0671 (↓), lr=0.000001
   • Epoch   2/100: train=0.0736, val=0.0670, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0736, val=0.0670, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0736, val=0.0670, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0736, val=0.0670, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0734, val=0.0668, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0671)

============================================================
📊 Round 175 Summary - Client client_45
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0736, RMSE=0.2713, R²=0.0985
   Val:   Loss=0.0671, RMSE=0.2590, R²=0.1383
============================================================


📊 Round 175 Test Metrics:
   Loss: 0.0744, RMSE: 0.2728, MAE: 0.2373, R²: 0.0911

============================================================
🔄 Round 177 - Client client_45
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0726, val=0.0710 (↓), lr=0.000001
   • Epoch   2/100: train=0.0726, val=0.0709, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0725, val=0.0709, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0725, val=0.0709, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0725, val=0.0709, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0723, val=0.0707, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0710)

============================================================
📊 Round 177 Summary - Client client_45
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0726, RMSE=0.2695, R²=0.1102
   Val:   Loss=0.0710, RMSE=0.2664, R²=0.0893
============================================================


📊 Round 177 Test Metrics:
   Loss: 0.0744, RMSE: 0.2727, MAE: 0.2373, R²: 0.0912

📊 Round 177 Test Metrics:
   Loss: 0.0744, RMSE: 0.2727, MAE: 0.2373, R²: 0.0912

📊 Round 177 Test Metrics:
   Loss: 0.0744, RMSE: 0.2728, MAE: 0.2373, R²: 0.0911

📊 Round 177 Test Metrics:
   Loss: 0.0744, RMSE: 0.2727, MAE: 0.2373, R²: 0.0911

📊 Round 177 Test Metrics:
   Loss: 0.0744, RMSE: 0.2727, MAE: 0.2373, R²: 0.0912

============================================================
🔄 Round 183 - Client client_45
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0722, val=0.0728 (↓), lr=0.000001
   • Epoch   2/100: train=0.0722, val=0.0728, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0721, val=0.0727, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0721, val=0.0727, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0721, val=0.0727, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0719, val=0.0726, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0728)

============================================================
📊 Round 183 Summary - Client client_45
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0722, RMSE=0.2686, R²=0.1041
   Val:   Loss=0.0728, RMSE=0.2698, R²=0.1146
============================================================


============================================================
🔄 Round 185 - Client client_45
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0715, val=0.0759 (↓), lr=0.000001
   • Epoch   2/100: train=0.0715, val=0.0759, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0714, val=0.0759, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0714, val=0.0758, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0714, val=0.0758, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0712, val=0.0757, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0759)

============================================================
📊 Round 185 Summary - Client client_45
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0714, RMSE=0.2672, R²=0.1081
   Val:   Loss=0.0759, RMSE=0.2755, R²=0.1010
============================================================


============================================================
🔄 Round 188 - Client client_45
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0733, val=0.0682 (↓), lr=0.000001
   • Epoch   2/100: train=0.0732, val=0.0682, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0732, val=0.0682, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0732, val=0.0682, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0732, val=0.0681, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0730, val=0.0680, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0682)

============================================================
📊 Round 188 Summary - Client client_45
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0733, RMSE=0.2707, R²=0.1095
   Val:   Loss=0.0682, RMSE=0.2612, R²=0.0942
============================================================


📊 Round 188 Test Metrics:
   Loss: 0.0744, RMSE: 0.2727, MAE: 0.2373, R²: 0.0912

============================================================
🔄 Round 190 - Client client_45
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0729, val=0.0702 (↓), lr=0.000001
   • Epoch   2/100: train=0.0728, val=0.0702, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0728, val=0.0701, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0728, val=0.0701, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0727, val=0.0701, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0726, val=0.0701, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0702)

============================================================
📊 Round 190 Summary - Client client_45
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0728, RMSE=0.2698, R²=0.1159
   Val:   Loss=0.0702, RMSE=0.2649, R²=0.0516
============================================================


============================================================
🔄 Round 191 - Client client_45
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0715, val=0.0748 (↓), lr=0.000001
   • Epoch   2/100: train=0.0714, val=0.0748, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0714, val=0.0748, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0714, val=0.0747, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0714, val=0.0747, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0713, val=0.0746, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0748)

============================================================
📊 Round 191 Summary - Client client_45
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0716, RMSE=0.2676, R²=0.1042
   Val:   Loss=0.0748, RMSE=0.2735, R²=0.0994
============================================================


📊 Round 191 Test Metrics:
   Loss: 0.0744, RMSE: 0.2727, MAE: 0.2373, R²: 0.0913

📊 Round 191 Test Metrics:
   Loss: 0.0744, RMSE: 0.2727, MAE: 0.2373, R²: 0.0913

📊 Round 191 Test Metrics:
   Loss: 0.0744, RMSE: 0.2727, MAE: 0.2373, R²: 0.0913

📊 Round 191 Test Metrics:
   Loss: 0.0744, RMSE: 0.2727, MAE: 0.2373, R²: 0.0913

============================================================
🔄 Round 197 - Client client_45
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0712, val=0.0764 (↓), lr=0.000001
   • Epoch   2/100: train=0.0712, val=0.0763, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0712, val=0.0763, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0712, val=0.0763, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0711, val=0.0763, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0710, val=0.0762, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0764)

============================================================
📊 Round 197 Summary - Client client_45
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0712, RMSE=0.2669, R²=0.1036
   Val:   Loss=0.0764, RMSE=0.2763, R²=0.1142
============================================================


📊 Round 197 Test Metrics:
   Loss: 0.0744, RMSE: 0.2727, MAE: 0.2373, R²: 0.0914

📊 Round 197 Test Metrics:
   Loss: 0.0744, RMSE: 0.2727, MAE: 0.2373, R²: 0.0914

============================================================
🔄 Round 200 - Client client_45
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0724, val=0.0722 (↓), lr=0.000001
   • Epoch   2/100: train=0.0724, val=0.0722, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0723, val=0.0721, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0723, val=0.0721, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0723, val=0.0721, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0722, val=0.0719, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0722)

============================================================
📊 Round 200 Summary - Client client_45
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0723, RMSE=0.2688, R²=0.1110
   Val:   Loss=0.0722, RMSE=0.2687, R²=0.0884
============================================================


📊 Round 200 Test Metrics:
   Loss: 0.0744, RMSE: 0.2727, MAE: 0.2373, R²: 0.0914

📊 Round 200 Test Metrics:
   Loss: 0.0744, RMSE: 0.2727, MAE: 0.2373, R²: 0.0915

📊 Round 200 Test Metrics:
   Loss: 0.0744, RMSE: 0.2727, MAE: 0.2373, R²: 0.0914

📊 Round 200 Test Metrics:
   Loss: 0.0744, RMSE: 0.2727, MAE: 0.2373, R²: 0.0914

============================================================
🔄 Round 206 - Client client_45
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0727, val=0.0713 (↓), lr=0.000001
   • Epoch   2/100: train=0.0726, val=0.0713, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0726, val=0.0713, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0726, val=0.0713, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0725, val=0.0713, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0723, val=0.0713, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0713)

============================================================
📊 Round 206 Summary - Client client_45
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0725, RMSE=0.2692, R²=0.1100
   Val:   Loss=0.0713, RMSE=0.2669, R²=0.0762
============================================================


============================================================
🔄 Round 207 - Client client_45
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0733, val=0.0687 (↓), lr=0.000001
   • Epoch   2/100: train=0.0733, val=0.0687, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0732, val=0.0687, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0732, val=0.0687, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0732, val=0.0687, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0730, val=0.0685, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0687)

============================================================
📊 Round 207 Summary - Client client_45
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0731, RMSE=0.2704, R²=0.1026
   Val:   Loss=0.0687, RMSE=0.2622, R²=0.1258
============================================================


============================================================
🔄 Round 210 - Client client_45
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0712, val=0.0756 (↓), lr=0.000001
   • Epoch   2/100: train=0.0712, val=0.0756, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0712, val=0.0756, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0711, val=0.0756, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0711, val=0.0755, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0710, val=0.0754, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0756)

============================================================
📊 Round 210 Summary - Client client_45
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0714, RMSE=0.2672, R²=0.1018
   Val:   Loss=0.0756, RMSE=0.2750, R²=0.1218
============================================================


============================================================
🔄 Round 213 - Client client_45
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0721, val=0.0729 (↓), lr=0.000001
   • Epoch   2/100: train=0.0720, val=0.0729, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0720, val=0.0729, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0720, val=0.0728, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0720, val=0.0728, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0718, val=0.0727, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0729)

============================================================
📊 Round 213 Summary - Client client_45
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0721, RMSE=0.2684, R²=0.0948
   Val:   Loss=0.0729, RMSE=0.2700, R²=0.1527
============================================================


📊 Round 213 Test Metrics:
   Loss: 0.0743, RMSE: 0.2727, MAE: 0.2373, R²: 0.0917

📊 Round 213 Test Metrics:
   Loss: 0.0743, RMSE: 0.2727, MAE: 0.2373, R²: 0.0917

============================================================
🔄 Round 216 - Client client_45
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0703, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0703, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0703, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0702, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0702, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0700, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 216 Summary - Client client_45
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0702, RMSE=0.2650, R²=0.1185
   Val:   Loss=0.0803, RMSE=0.2833, R²=0.0648
============================================================


📊 Round 216 Test Metrics:
   Loss: 0.0743, RMSE: 0.2727, MAE: 0.2373, R²: 0.0917

============================================================
🔄 Round 217 - Client client_45
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0702, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0702, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0701, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0701, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0701, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0700, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 217 Summary - Client client_45
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0704, RMSE=0.2652, R²=0.1097
   Val:   Loss=0.0797, RMSE=0.2823, R²=0.0983
============================================================


📊 Round 217 Test Metrics:
   Loss: 0.0743, RMSE: 0.2727, MAE: 0.2373, R²: 0.0917

📊 Round 217 Test Metrics:
   Loss: 0.0743, RMSE: 0.2727, MAE: 0.2373, R²: 0.0918

============================================================
🔄 Round 221 - Client client_45
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0715, val=0.0752 (↓), lr=0.000001
   • Epoch   2/100: train=0.0715, val=0.0752, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0715, val=0.0752, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0714, val=0.0752, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0714, val=0.0751, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0713, val=0.0751, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0752)

============================================================
📊 Round 221 Summary - Client client_45
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0715, RMSE=0.2673, R²=0.1171
   Val:   Loss=0.0752, RMSE=0.2742, R²=0.0658
============================================================


============================================================
🔄 Round 222 - Client client_45
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0732, val=0.0686 (↓), lr=0.000001
   • Epoch   2/100: train=0.0731, val=0.0686, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0731, val=0.0686, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0731, val=0.0686, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0730, val=0.0686, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0728, val=0.0686, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0686)

============================================================
📊 Round 222 Summary - Client client_45
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0731, RMSE=0.2704, R²=0.1143
   Val:   Loss=0.0686, RMSE=0.2618, R²=0.0321
============================================================


============================================================
🔄 Round 223 - Client client_45
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0719, val=0.0736 (↓), lr=0.000001
   • Epoch   2/100: train=0.0719, val=0.0736, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0719, val=0.0736, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0719, val=0.0736, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0718, val=0.0736, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0717, val=0.0734, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0736)

============================================================
📊 Round 223 Summary - Client client_45
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0718, RMSE=0.2680, R²=0.1058
   Val:   Loss=0.0736, RMSE=0.2714, R²=0.1118
============================================================


📊 Round 223 Test Metrics:
   Loss: 0.0743, RMSE: 0.2726, MAE: 0.2372, R²: 0.0919

❌ Client client_45 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8687 {grpc_status:14, grpc_message:"Socket closed"}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8687 {grpc_status:14, grpc_message:"Socket closed"}"
>
