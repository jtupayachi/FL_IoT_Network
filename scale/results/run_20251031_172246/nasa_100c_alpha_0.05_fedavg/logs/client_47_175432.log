[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2fa827ff-0af7-4747-825c-08c531621157
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4af9b36b-e1e7-4539-b6b1-1d443e8f1d67
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4b3d121f-38a4-4f2a-8820-e236ae47cfa6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4c7786b8-4cd1-4d9e-9b8b-4efe841875b8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b28468f3-a6e9-4a56-903f-5d12e10c764b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ebb97f5d-1d57-4c17-a7c5-1f897a6daa1f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 54853687-ecd7-4d51-8d34-04a8032e0b3b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e3798f6e-add0-481d-9be3-8d2358cc3842
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 13d33b9b-f379-4722-b791-f6172b62dcc0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e819a434-6b4f-448a-92d7-98df50bfa1b1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3dcf1ae5-deec-4437-b9d3-884021c77868
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0fae0918-4520-4837-b7bd-4c82b6919567
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b05d5137-e429-414d-b0ce-b1d5fcf63a6e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4d4d1d7d-55a2-40c9-903b-9f8df917a11c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7068262c-ab57-4d87-97d7-103c8a8df940
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 07ba95ad-2815-449a-ab5d-ec03c92a87a8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cd0c8e48-6e04-4e63-b321-7c715d52aef2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aac4091a-dceb-4860-bd05-735c19f93770
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2129fddd-bfb7-4b24-803c-45a4fc4dab58
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 89cbc4dd-f83d-4c3f-9614-0dee1879704f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7392405a-a841-4b94-ad32-3cd29685849e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 58ee1b71-7e74-47da-9e1d-5ed33f897b34
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b0ba33be-fe5f-49de-9953-f619a8661c28
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4dbd09aa-d281-4895-82d2-304a64716082
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a26e2da4-cfce-4d2f-9871-ed9a2d7dd71c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8f122c24-0ace-4735-aaba-3e8fb565735c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5d50ece0-4c56-4f49-bfa2-aae5472a7f74
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5be6c8ae-7da5-46a0-a5de-5421ceff15f3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9927bad3-7a1e-47fd-a3b6-c3166fdff8b6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 15acb441-0113-473f-a2a8-11fee0674cac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1fe7fa48-9b0a-4ea8-847b-3c783d1e5144
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5889fadc-6256-4cf4-aa5e-3e73e10b4269
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4d8a4937-be9c-4427-8a0a-a6b43c2196e2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a7cd0a2b-8abe-4dbe-83e6-fe4f97c9fc3b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8df403c4-2318-4f73-9c94-f6ac882ffe2d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a682e00c-4838-494d-b545-97da59158fb9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d962873b-a7b5-4d6a-8ef0-40b8d701ac75
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d0065a0f-d669-43c9-abe1-b11e09465fd0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6153d261-ddeb-4461-87bb-9a4ab5377672
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 67110b64-58fc-4b5c-9481-dc97a69883f4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 539dc26a-92a5-43eb-b33c-9d158d622a5f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 909a82c9-5042-4bfb-ab40-f37908d7e39b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ec60d690-f534-4230-9f74-f9b8b31f2047
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b049f66e-e89e-46f0-a86c-2d67005eb51b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 80fd0161-3b78-4a9e-a5c4-d8b5aaac09e0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 41c59078-7d38-43e0-8b4a-f0e015cc3ccc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 41add819-3c63-4366-8360-f55ec5ccd70e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3a5f8f17-0d7f-416f-9d3c-e64bfb7bcefc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b6ea8b1f-7caa-4b04-ac57-8367f74cd016
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5d90ae5f-72c4-46ed-9503-28f32770804a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c9a5955e-cf6f-4244-9962-6911f20a1ceb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5a6c4895-72e7-45cd-a391-6b463db959bc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message da79540a-0b63-4d3f-b1e2-9d817e095a64
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d11a6a8e-8917-4804-9e13-d9f2527291f2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a0cc3dba-62da-4026-bd15-5ff6e97f274d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 35a04432-adb9-4219-b29d-45bbf34e27e0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 54d7e6f1-5317-41f5-b523-b43db478c951
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0340a799-c700-459b-8968-2b8b36dfe6b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3a23c760-6bf3-4d79-b775-2cbdb4045efb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 65d27894-7cfe-4d48-8457-36fb0a5de1e6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 467d1255-9078-4c1c-bc5a-5d6c3813ede3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f517169d-a124-4f9f-af97-7e4492ff1215
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 60c97ea6-418a-4db2-b99f-6ca6909504dd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dc7dca87-da2a-461d-99b4-5b8869835870
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 86448017-0f12-465b-ac96-0a984ca9c3c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 11693c77-0c3c-456a-aa2d-db9e61aefd48
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3a9866d6-3c49-4024-b0b4-ba4f09c4829d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ee4f83d4-8952-47a0-99e3-8a42753b1137
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bb8b23f5-d4cc-4995-a0a4-2eb017e6eaee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4177ca00-abcf-4944-8214-da0153a212bc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 570d0c7d-9a2f-445b-aa9d-ca747f8422a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9d59c93a-be65-4027-bb9d-a45f92adfdc1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7c17f60e-78f2-4674-b79b-3fb83b49676c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a73bede2-e3d8-4ab1-937d-dccca80c7cd0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 789eab76-3ee7-4cac-93ca-56d16968000f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4f4dbcf0-9a0d-4bc3-b4c9-49e93abb5a70
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 82e4765a-adbb-47f0-901e-3f2bcbc80ec2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 49b7513a-a468-409f-9ab8-83704049f8af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3c485253-6a55-4f18-b727-0369ee8ed598
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 94661900-545a-4962-a82b-deffdd0f686b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a923da1f-c11f-4b6e-8840-4824fb23c267
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 25568a62-7220-4f32-946c-8c739c68a9e0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bb693e53-93d0-48ff-976b-56683b7f0438
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 857a3ece-9f1d-49ac-95d9-710c9029cca6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5ef15bd9-dffe-4d48-94c4-f75742d65636
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c2d68202-1570-4619-b6b5-c1e6a178c0d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a0e367c4-2962-47b0-8073-7462d5427007
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 08ddbb1d-06f9-40a8-86da-0f7ec1e3d0d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 96a9c962-2bde-4d6b-bded-e8bf5a6f30eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2717e5f1-11fd-42f8-886f-8ef5cd2d46bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bfac03b3-1cb0-4420-a721-e7a232413eee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a442ff8b-a512-4d6e-9970-f7638410ab51
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7676f833-e1fe-420e-b474-2c3da6644d6f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ee2f82a7-78e7-41ca-a5cb-d7bf4d63aacb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bad67ccf-6afd-4ae5-bcbb-03fa1f17d2f7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 536ea938-9adf-4d66-87cf-080af39f6ab2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dd5903d2-a2f9-48a2-8fd2-d4907c725e42
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 90a33dd4-dcf8-4eb1-a7f9-6adef3ee31e1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 388aae80-fae0-4a40-aa93-71d88993a31f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ced1f75b-0c52-4975-834c-449adbc36199
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d82916e8-e1ce-4329-93cc-df5bfbada958
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 52d7bb6c-579f-4e76-bf16-fe66d87c9c39
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c4e98d01-6163-4fc8-8181-e60e97f0721a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fd684c4e-aa84-4673-9bce-60e908adb371
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e159663f-bd29-4e87-b966-d18232fcfc5c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6b27ad7a-8e3e-4535-a7a4-8b49883d4a5a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f5c10b30-0c3a-4381-9be1-ff100e7bdc31
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 213e10e7-87d3-4bd9-8e29-804f33fe64fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0128571c-fe78-446e-94a6-f6ccc668066f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dbcb11f7-fc90-422d-83f0-f717d9bc464c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 307fe988-a26a-4fa5-a08f-37754ddc32c5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1732fd1e-3355-4215-8e98-fad3d387aeff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 43436dfa-db11-4cce-bc8a-b0010be46c24
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2d99c9a4-27e4-4c6e-a2cd-cd92376e9ffe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eadf4138-3aec-4e55-850e-2fe912a32d5c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2b9e85c8-c408-46d4-856c-b7320b657fb1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 64cf0403-f2f2-4b31-94c1-0f8d34626ecd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f654054b-4f71-4d03-8154-6f2da1334d31
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 010c46a1-a21c-4fdf-8d25-8b4f68835d0c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4c65c8f8-fbe9-4b3c-8d31-47af19fc20e0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5f86c519-a53d-4581-84e3-6031f044aab5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bcaf3344-9adc-4dc2-8bf9-beb7a05f095b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4a75e21d-c5a1-40e6-b85e-bcc8ec003e6e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8e983351-5447-4d3c-b712-78612e305389
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 46f86593-06e0-46c8-a826-2588e84f7480
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 86e5352e-796f-4038-874b-c9a733dc8a5f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 60f7d581-7343-4f12-8294-e1162390313b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fc93aa47-e461-4b87-9d9d-42d98e4c7971
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8027c11b-8e15-4c8c-806d-e4991ee0257b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9f6c6b06-e2b0-4b1a-99bf-b716d820b685
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 37939e64-4922-41bd-a760-36b0efe0e578
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e44ceaa9-94ab-4afc-b0c7-d9b9a79fa097
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3f7a6f10-8ee3-4cf7-b4c7-e33a01e793ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4e504f63-a160-4514-9d4b-5335235f1017
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5e529afa-d92a-4949-857b-31d1e383d607
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8056f9e9-f276-4798-bd4e-56367a6f79f7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b12f5682-2f2e-48a0-a998-727cb439a8bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c1d14b10-afe3-4857-83a4-5c8747aef947
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3de4e276-a292-4ff1-9664-c6a49845204a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5dfcbe1d-35c0-4930-aa0a-ae7e8d7497dd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7544a972-ce02-49ef-9309-0891f49533b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3058b067-0599-430d-9cde-a3d630d19d0c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cf22b541-3274-45c6-850b-8fdb44d15b15
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fc8be8a4-a343-4bcc-b422-a7e38dd25314
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6bfcf39f-cfc5-45fa-92c3-8b92b9cc556c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0841fe17-a083-42fd-9586-310d3c49e667
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ac299832-d01a-447b-8593-7e677d417b37
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a00bb125-3cec-49b1-bccc-99a6ad7465b7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0fcc91a1-471b-4033-a4b7-669f8d511ded
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0453237c-c24b-431a-a3d3-c67a8e5242f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8c09d712-8b29-4f04-a044-f2f097f133c3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 53ff0f81-9363-4078-bde3-79d8efc0dc24
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 03653a38-09c9-44e8-b8e0-ed10db793407
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7399d4b0-97f6-4adb-a9e9-5ba8a95c5e9a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0b6f9038-9ae8-4a77-ba35-37371ca520d1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c15fe2a8-b3a3-44f0-a726-0b806f4a6a5c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e2007f27-42ee-4d36-be0d-2ea350d7d4fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8d8b31a9-bebd-4058-ba70-ef2d3c71c391
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7c63b8b0-5c1c-4571-ab6a-c26bde6e4ad5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 02754389-ab33-4023-81f6-4f9f77236bdf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6d9d727b-97be-4522-8ee4-74bf89cfd0cb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 46ce7d7b-59ce-4634-bccf-65563e2f8a71
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a2409883-55d2-49b4-b8d4-1919abb8ec67
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 78977771-4e60-4d08-9788-f9164c77d904
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2b611ead-8cee-48c5-adea-10d93a937218
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ed98a43e-1e45-4c5b-8512-8ce7b0ee10dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 898572ae-2b71-4c0a-92b8-db4efe5ade48
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5c1bf33e-5b0e-4bee-bf25-f1baeabd9544
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 82b20993-bacd-43c2-b168-3e8bea2531a0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f8f0534d-69b5-4264-b89d-f435a8d4c54f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a1be8b83-ab9f-4858-b3b4-22e7b7aaf4e1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 91583a01-3141-4fc1-9585-e938d23563bb
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8687 {grpc_message:"Socket closed", grpc_status:14}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_47
Server: localhost:8687
Algorithm: FEDAVG
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_47
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_47/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_47/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_47/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_47/test_labels.txt

📊 Raw data loaded:
   Train: X=(1674, 24), y=(1674,)
   Test:  X=(419, 24), y=(419,)

⚠️  Limiting training data: 1674 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  410 samples, 5 features
✅ Client client_47 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

📊 Round 0 Test Metrics:
   Loss: 0.0816, RMSE: 0.2857, MAE: 0.2454, R²: 0.0123

📊 Round 0 Test Metrics:
   Loss: 0.0803, RMSE: 0.2833, MAE: 0.2432, R²: 0.0285

📊 Round 0 Test Metrics:
   Loss: 0.0801, RMSE: 0.2831, MAE: 0.2430, R²: 0.0301

📊 Round 0 Test Metrics:
   Loss: 0.0801, RMSE: 0.2830, MAE: 0.2429, R²: 0.0310

📊 Round 0 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2432, R²: 0.0291

============================================================
🔄 Round 14 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0772, val=0.0849 (↓), lr=0.001000
   ✓ Epoch   2/100: train=0.0768, val=0.0828 (↓), lr=0.001000
   ✓ Epoch   3/100: train=0.0763, val=0.0783 (↓), lr=0.001000
   ✓ Epoch   4/100: train=0.0742, val=0.0776 (↓), lr=0.001000
   ✓ Epoch   5/100: train=0.0727, val=0.0768 (↓), lr=0.001000
   • Epoch  11/100: train=0.0674, val=0.0748, patience=1/15, lr=0.001000
   • Epoch  21/100: train=0.0607, val=0.0735, patience=7/15, lr=0.001000
   📉 Epoch 24: LR reduced 0.001000 → 0.000500

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0734)

============================================================
📊 Round 14 Summary - Client client_47
   Epochs: 29/100 (early stopped)
   LR: 0.001000 → 0.000500 (1 reductions)
   Train: Loss=0.0643, RMSE=0.2536, R²=0.1995
   Val:   Loss=0.0734, RMSE=0.2708, R²=0.0778
============================================================


============================================================
🔄 Round 16 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.000500
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0765, val=0.0798 (↓), lr=0.000500
   • Epoch   2/100: train=0.0751, val=0.0800, patience=1/15, lr=0.000500
   📉 Epoch 3: LR reduced 0.000500 → 0.000250
   • Epoch   3/100: train=0.0743, val=0.0797, patience=2/15, lr=0.000250
   ✓ Epoch   4/100: train=0.0732, val=0.0788 (↓), lr=0.000250
   • Epoch   5/100: train=0.0728, val=0.0790, patience=1/15, lr=0.000250
   📉 Epoch 11: LR reduced 0.000250 → 0.000125
   ✓ Epoch  11/100: train=0.0705, val=0.0776 (↓), lr=0.000125
   📉 Epoch 19: LR reduced 0.000125 → 0.000063
   • Epoch  21/100: train=0.0685, val=0.0771, patience=1/15, lr=0.000063
   📉 Epoch 27: LR reduced 0.000063 → 0.000031
   • Epoch  31/100: train=0.0678, val=0.0771, patience=11/15, lr=0.000031
   📉 Epoch 35: LR reduced 0.000031 → 0.000016

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0771)

============================================================
📊 Round 16 Summary - Client client_47
   Epochs: 35/100 (early stopped)
   LR: 0.000500 → 0.000016 (5 reductions)
   Train: Loss=0.0685, RMSE=0.2617, R²=0.1411
   Val:   Loss=0.0771, RMSE=0.2777, R²=0.0613
============================================================


============================================================
🔄 Round 18 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.000016
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0762, val=0.0820 (↓), lr=0.000016
   • Epoch   2/100: train=0.0760, val=0.0816, patience=1/15, lr=0.000016
   ✓ Epoch   3/100: train=0.0758, val=0.0812 (↓), lr=0.000016
   • Epoch   4/100: train=0.0756, val=0.0810, patience=1/15, lr=0.000016
   • Epoch   5/100: train=0.0754, val=0.0808, patience=2/15, lr=0.000016
   📉 Epoch 8: LR reduced 0.000016 → 0.000008
   • Epoch  11/100: train=0.0748, val=0.0802, patience=5/15, lr=0.000008
   📉 Epoch 16: LR reduced 0.000008 → 0.000004
   • Epoch  21/100: train=0.0745, val=0.0800, patience=4/15, lr=0.000004
   📉 Epoch 24: LR reduced 0.000004 → 0.000002
   • Epoch  31/100: train=0.0744, val=0.0799, patience=14/15, lr=0.000002
   📉 Epoch 32: LR reduced 0.000002 → 0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 18 Summary - Client client_47
   Epochs: 32/100 (early stopped)
   LR: 0.000016 → 0.000001 (4 reductions)
   Train: Loss=0.0748, RMSE=0.2735, R²=0.0604
   Val:   Loss=0.0801, RMSE=0.2830, R²=0.0290
============================================================


📊 Round 18 Test Metrics:
   Loss: 0.0794, RMSE: 0.2817, MAE: 0.2418, R²: 0.0396

============================================================
🔄 Round 19 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0771, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0770, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0770, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0770, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0770, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0768, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 19 Summary - Client client_47
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0769, RMSE=0.2773, R²=0.0183
   Val:   Loss=0.0798, RMSE=0.2825, R²=0.0931
============================================================


============================================================
🔄 Round 20 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0668 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0668, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0668, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0667, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0667, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0666, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0668)

============================================================
📊 Round 20 Summary - Client client_47
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=0.0369
   Val:   Loss=0.0668, RMSE=0.2585, R²=0.0160
============================================================


📊 Round 20 Test Metrics:
   Loss: 0.0791, RMSE: 0.2813, MAE: 0.2413, R²: 0.0423

📊 Round 20 Test Metrics:
   Loss: 0.0790, RMSE: 0.2811, MAE: 0.2412, R²: 0.0437

📊 Round 20 Test Metrics:
   Loss: 0.0790, RMSE: 0.2811, MAE: 0.2411, R²: 0.0438

============================================================
🔄 Round 25 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0674 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0674, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0674, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0674, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0673, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0672, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0674)

============================================================
📊 Round 25 Summary - Client client_47
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=0.0407
   Val:   Loss=0.0674, RMSE=0.2597, R²=0.0277
============================================================


============================================================
🔄 Round 26 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0781, val=0.0741 (↓), lr=0.000001
   • Epoch   2/100: train=0.0781, val=0.0740, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0781, val=0.0740, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0780, val=0.0740, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0780, val=0.0740, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0779, val=0.0739, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0741)

============================================================
📊 Round 26 Summary - Client client_47
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0780, RMSE=0.2793, R²=0.0370
   Val:   Loss=0.0741, RMSE=0.2722, R²=0.0448
============================================================


============================================================
🔄 Round 29 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0778, val=0.0752 (↓), lr=0.000001
   • Epoch   2/100: train=0.0778, val=0.0752, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0778, val=0.0752, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0777, val=0.0752, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0777, val=0.0752, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0776, val=0.0751, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0752)

============================================================
📊 Round 29 Summary - Client client_47
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0777, RMSE=0.2788, R²=0.0354
   Val:   Loss=0.0752, RMSE=0.2743, R²=0.0503
============================================================


📊 Round 29 Test Metrics:
   Loss: 0.0790, RMSE: 0.2811, MAE: 0.2411, R²: 0.0439

============================================================
🔄 Round 31 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0764, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0764, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0764, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0763, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0763, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0762, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 31 Summary - Client client_47
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0764, RMSE=0.2764, R²=0.0474
   Val:   Loss=0.0805, RMSE=0.2837, R²=0.0006
============================================================


============================================================
🔄 Round 32 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0762, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0762, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0762, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0762, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0761, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0760, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 32 Summary - Client client_47
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0762, RMSE=0.2761, R²=0.0431
   Val:   Loss=0.0811, RMSE=0.2849, R²=0.0161
============================================================


============================================================
🔄 Round 34 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0731, val=0.0928 (↓), lr=0.000001
   • Epoch   2/100: train=0.0731, val=0.0927, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0731, val=0.0927, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0731, val=0.0927, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0730, val=0.0927, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0729, val=0.0926, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0928)

============================================================
📊 Round 34 Summary - Client client_47
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0733, RMSE=0.2708, R²=0.0430
   Val:   Loss=0.0928, RMSE=0.3046, R²=0.0240
============================================================


📊 Round 34 Test Metrics:
   Loss: 0.0790, RMSE: 0.2811, MAE: 0.2411, R²: 0.0440

📊 Round 34 Test Metrics:
   Loss: 0.0790, RMSE: 0.2810, MAE: 0.2411, R²: 0.0440

📊 Round 34 Test Metrics:
   Loss: 0.0790, RMSE: 0.2810, MAE: 0.2411, R²: 0.0440

📊 Round 34 Test Metrics:
   Loss: 0.0790, RMSE: 0.2810, MAE: 0.2411, R²: 0.0441

============================================================
🔄 Round 42 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0776, val=0.0761 (↓), lr=0.000001
   • Epoch   2/100: train=0.0776, val=0.0761, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0775, val=0.0761, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0775, val=0.0761, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0775, val=0.0761, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0773, val=0.0760, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0761)

============================================================
📊 Round 42 Summary - Client client_47
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0775, RMSE=0.2783, R²=0.0384
   Val:   Loss=0.0761, RMSE=0.2759, R²=0.0403
============================================================


📊 Round 42 Test Metrics:
   Loss: 0.0790, RMSE: 0.2810, MAE: 0.2411, R²: 0.0441

📊 Round 42 Test Metrics:
   Loss: 0.0790, RMSE: 0.2810, MAE: 0.2411, R²: 0.0442

📊 Round 42 Test Metrics:
   Loss: 0.0790, RMSE: 0.2810, MAE: 0.2411, R²: 0.0443

============================================================
🔄 Round 49 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0782, val=0.0731 (↓), lr=0.000001
   • Epoch   2/100: train=0.0782, val=0.0731, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0782, val=0.0730, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0782, val=0.0730, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0782, val=0.0730, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0780, val=0.0729, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0731)

============================================================
📊 Round 49 Summary - Client client_47
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0782, RMSE=0.2797, R²=0.0512
   Val:   Loss=0.0731, RMSE=0.2703, R²=-0.0402
============================================================


📊 Round 49 Test Metrics:
   Loss: 0.0790, RMSE: 0.2810, MAE: 0.2411, R²: 0.0443

📊 Round 49 Test Metrics:
   Loss: 0.0790, RMSE: 0.2810, MAE: 0.2411, R²: 0.0443

============================================================
🔄 Round 54 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0772, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0772, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0772, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0772, val=0.0774, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0772, val=0.0774, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0770, val=0.0773, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 54 Summary - Client client_47
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0771, RMSE=0.2777, R²=0.0386
   Val:   Loss=0.0775, RMSE=0.2784, R²=0.0386
============================================================


============================================================
🔄 Round 55 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0751, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0751, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0751, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0751, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0750, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0749, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 55 Summary - Client client_47
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0750, RMSE=0.2739, R²=0.0550
   Val:   Loss=0.0858, RMSE=0.2930, R²=-0.0241
============================================================


📊 Round 55 Test Metrics:
   Loss: 0.0789, RMSE: 0.2810, MAE: 0.2411, R²: 0.0445

📊 Round 55 Test Metrics:
   Loss: 0.0789, RMSE: 0.2810, MAE: 0.2410, R²: 0.0446

============================================================
🔄 Round 62 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0781, val=0.0748 (↓), lr=0.000001
   • Epoch   2/100: train=0.0781, val=0.0747, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0781, val=0.0747, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0781, val=0.0747, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0780, val=0.0746, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0779, val=0.0744, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0748)

============================================================
📊 Round 62 Summary - Client client_47
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0778, RMSE=0.2789, R²=0.0408
   Val:   Loss=0.0748, RMSE=0.2734, R²=0.0207
============================================================


📊 Round 62 Test Metrics:
   Loss: 0.0789, RMSE: 0.2810, MAE: 0.2410, R²: 0.0446

============================================================
🔄 Round 65 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0766, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0766, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0766, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0766, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0766, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0764, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 65 Summary - Client client_47
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0769, RMSE=0.2773, R²=0.0398
   Val:   Loss=0.0784, RMSE=0.2799, R²=0.0286
============================================================


📊 Round 65 Test Metrics:
   Loss: 0.0789, RMSE: 0.2810, MAE: 0.2410, R²: 0.0446

============================================================
🔄 Round 66 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0775, val=0.0768 (↓), lr=0.000001
   • Epoch   2/100: train=0.0775, val=0.0767, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0774, val=0.0767, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0774, val=0.0767, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0774, val=0.0767, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0773, val=0.0765, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0768)

============================================================
📊 Round 66 Summary - Client client_47
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0773, RMSE=0.2780, R²=0.0395
   Val:   Loss=0.0768, RMSE=0.2771, R²=0.0282
============================================================


📊 Round 66 Test Metrics:
   Loss: 0.0789, RMSE: 0.2810, MAE: 0.2410, R²: 0.0446

📊 Round 66 Test Metrics:
   Loss: 0.0789, RMSE: 0.2810, MAE: 0.2410, R²: 0.0446

============================================================
🔄 Round 69 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0764, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0764, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0764, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0763, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0763, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0761, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 69 Summary - Client client_47
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0764, RMSE=0.2764, R²=0.0307
   Val:   Loss=0.0802, RMSE=0.2832, R²=0.0647
============================================================


============================================================
🔄 Round 70 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0782, val=0.0727 (↓), lr=0.000001
   • Epoch   2/100: train=0.0782, val=0.0727, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0782, val=0.0727, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0782, val=0.0726, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0781, val=0.0726, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0780, val=0.0725, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0727)

============================================================
📊 Round 70 Summary - Client client_47
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0783, RMSE=0.2798, R²=0.0381
   Val:   Loss=0.0727, RMSE=0.2697, R²=0.0438
============================================================


============================================================
🔄 Round 71 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0752, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0752, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0752, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0751, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0751, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0750, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 71 Summary - Client client_47
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0751, RMSE=0.2741, R²=0.0460
   Val:   Loss=0.0853, RMSE=0.2920, R²=0.0158
============================================================


📊 Round 71 Test Metrics:
   Loss: 0.0789, RMSE: 0.2809, MAE: 0.2410, R²: 0.0447

============================================================
🔄 Round 73 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0703 (↓), lr=0.000001
   • Epoch   2/100: train=0.0785, val=0.0702, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0785, val=0.0702, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0785, val=0.0702, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0785, val=0.0702, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0700, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0703)

============================================================
📊 Round 73 Summary - Client client_47
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2808, R²=0.0400
   Val:   Loss=0.0703, RMSE=0.2651, R²=0.0357
============================================================


📊 Round 73 Test Metrics:
   Loss: 0.0789, RMSE: 0.2809, MAE: 0.2410, R²: 0.0448

============================================================
🔄 Round 74 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0764, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0763, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0763, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0763, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0762, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0761, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 74 Summary - Client client_47
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0764, RMSE=0.2764, R²=0.0409
   Val:   Loss=0.0800, RMSE=0.2829, R²=0.0326
============================================================


============================================================
🔄 Round 75 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0770, val=0.0776 (↓), lr=0.000001
   • Epoch   2/100: train=0.0769, val=0.0776, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0769, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0769, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0768, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0767, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 75 Summary - Client client_47
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0770, RMSE=0.2776, R²=0.0328
   Val:   Loss=0.0776, RMSE=0.2785, R²=0.0621
============================================================


📊 Round 75 Test Metrics:
   Loss: 0.0789, RMSE: 0.2809, MAE: 0.2410, R²: 0.0448

📊 Round 75 Test Metrics:
   Loss: 0.0789, RMSE: 0.2809, MAE: 0.2410, R²: 0.0448

📊 Round 75 Test Metrics:
   Loss: 0.0789, RMSE: 0.2809, MAE: 0.2410, R²: 0.0448

============================================================
🔄 Round 83 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0767, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0767, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0767, val=0.0782, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0766, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0766, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0765, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 83 Summary - Client client_47
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0769, RMSE=0.2772, R²=0.0412
   Val:   Loss=0.0782, RMSE=0.2796, R²=0.0338
============================================================


📊 Round 83 Test Metrics:
   Loss: 0.0789, RMSE: 0.2809, MAE: 0.2410, R²: 0.0449

============================================================
🔄 Round 84 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0709 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0709, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0708, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0708, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0708, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0706, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0709)

============================================================
📊 Round 84 Summary - Client client_47
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2805, R²=0.0380
   Val:   Loss=0.0709, RMSE=0.2663, R²=0.0366
============================================================


📊 Round 84 Test Metrics:
   Loss: 0.0789, RMSE: 0.2809, MAE: 0.2410, R²: 0.0449

============================================================
🔄 Round 90 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0772, val=0.0764 (↓), lr=0.000001
   • Epoch   2/100: train=0.0772, val=0.0763, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0772, val=0.0763, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0772, val=0.0763, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0771, val=0.0763, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0771, val=0.0762, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0764)

============================================================
📊 Round 90 Summary - Client client_47
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0773, RMSE=0.2780, R²=0.0351
   Val:   Loss=0.0764, RMSE=0.2764, R²=-0.0059
============================================================


📊 Round 90 Test Metrics:
   Loss: 0.0789, RMSE: 0.2809, MAE: 0.2410, R²: 0.0449

📊 Round 90 Test Metrics:
   Loss: 0.0789, RMSE: 0.2809, MAE: 0.2410, R²: 0.0449

============================================================
🔄 Round 94 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0770, val=0.0777 (↓), lr=0.000001
   • Epoch   2/100: train=0.0770, val=0.0777, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0769, val=0.0777, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0769, val=0.0777, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0769, val=0.0777, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0767, val=0.0777, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 94 Summary - Client client_47
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0770, RMSE=0.2774, R²=0.0369
   Val:   Loss=0.0777, RMSE=0.2788, R²=0.0418
============================================================


📊 Round 94 Test Metrics:
   Loss: 0.0789, RMSE: 0.2809, MAE: 0.2409, R²: 0.0450

📊 Round 94 Test Metrics:
   Loss: 0.0789, RMSE: 0.2809, MAE: 0.2409, R²: 0.0450

📊 Round 94 Test Metrics:
   Loss: 0.0789, RMSE: 0.2809, MAE: 0.2409, R²: 0.0450

============================================================
🔄 Round 100 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0699 (↓), lr=0.000001
   • Epoch   2/100: train=0.0785, val=0.0699, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0785, val=0.0700, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0700, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0700, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0782, val=0.0700, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0699)

============================================================
📊 Round 100 Summary - Client client_47
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2808, R²=0.0276
   Val:   Loss=0.0699, RMSE=0.2645, R²=0.0689
============================================================


============================================================
🔄 Round 101 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0767, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0767, val=0.0778, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0767, val=0.0778, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0766, val=0.0778, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0766, val=0.0778, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0764, val=0.0777, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 101 Summary - Client client_47
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0769, RMSE=0.2773, R²=0.0361
   Val:   Loss=0.0778, RMSE=0.2789, R²=0.0516
============================================================


📊 Round 101 Test Metrics:
   Loss: 0.0789, RMSE: 0.2809, MAE: 0.2409, R²: 0.0450

============================================================
🔄 Round 102 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0783, val=0.0719 (↓), lr=0.000001
   • Epoch   2/100: train=0.0783, val=0.0719, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0782, val=0.0719, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0782, val=0.0719, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0782, val=0.0719, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0780, val=0.0719, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0719)

============================================================
📊 Round 102 Summary - Client client_47
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2799, R²=0.0347
   Val:   Loss=0.0719, RMSE=0.2682, R²=0.0488
============================================================


📊 Round 102 Test Metrics:
   Loss: 0.0789, RMSE: 0.2809, MAE: 0.2409, R²: 0.0451

============================================================
🔄 Round 106 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0776, val=0.0753 (↓), lr=0.000001
   • Epoch   2/100: train=0.0776, val=0.0753, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0776, val=0.0753, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0776, val=0.0752, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0776, val=0.0752, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0775, val=0.0750, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0753)

============================================================
📊 Round 106 Summary - Client client_47
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0775, RMSE=0.2784, R²=0.0412
   Val:   Loss=0.0753, RMSE=0.2745, R²=0.0266
============================================================


📊 Round 106 Test Metrics:
   Loss: 0.0789, RMSE: 0.2809, MAE: 0.2409, R²: 0.0451

============================================================
🔄 Round 107 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0680 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0680, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0680, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0680, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0680, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0679, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0680)

============================================================
📊 Round 107 Summary - Client client_47
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2817, R²=0.0312
   Val:   Loss=0.0680, RMSE=0.2608, R²=0.0739
============================================================


============================================================
🔄 Round 108 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0774, val=0.0765 (↓), lr=0.000001
   • Epoch   2/100: train=0.0774, val=0.0765, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0773, val=0.0764, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0773, val=0.0764, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0773, val=0.0764, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0772, val=0.0762, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0765)

============================================================
📊 Round 108 Summary - Client client_47
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0772, RMSE=0.2779, R²=0.0478
   Val:   Loss=0.0765, RMSE=0.2766, R²=0.0024
============================================================


📊 Round 108 Test Metrics:
   Loss: 0.0789, RMSE: 0.2809, MAE: 0.2409, R²: 0.0451

📊 Round 108 Test Metrics:
   Loss: 0.0789, RMSE: 0.2809, MAE: 0.2409, R²: 0.0451

📊 Round 108 Test Metrics:
   Loss: 0.0789, RMSE: 0.2809, MAE: 0.2409, R²: 0.0452

📊 Round 108 Test Metrics:
   Loss: 0.0789, RMSE: 0.2809, MAE: 0.2409, R²: 0.0452

============================================================
🔄 Round 113 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0771, val=0.0767 (↓), lr=0.000001
   • Epoch   2/100: train=0.0771, val=0.0767, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0771, val=0.0767, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0770, val=0.0767, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0770, val=0.0767, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0768, val=0.0766, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0767)

============================================================
📊 Round 113 Summary - Client client_47
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0771, RMSE=0.2778, R²=0.0426
   Val:   Loss=0.0767, RMSE=0.2770, R²=0.0281
============================================================


📊 Round 113 Test Metrics:
   Loss: 0.0789, RMSE: 0.2809, MAE: 0.2409, R²: 0.0452

============================================================
🔄 Round 115 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0781, val=0.0719 (↓), lr=0.000001
   • Epoch   2/100: train=0.0781, val=0.0719, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0780, val=0.0719, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0780, val=0.0719, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0780, val=0.0718, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0778, val=0.0717, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0719)

============================================================
📊 Round 115 Summary - Client client_47
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0783, RMSE=0.2799, R²=0.0367
   Val:   Loss=0.0719, RMSE=0.2682, R²=0.0575
============================================================


📊 Round 115 Test Metrics:
   Loss: 0.0789, RMSE: 0.2809, MAE: 0.2409, R²: 0.0452

============================================================
🔄 Round 117 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0780, val=0.0733 (↓), lr=0.000001
   • Epoch   2/100: train=0.0779, val=0.0733, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0779, val=0.0733, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0779, val=0.0732, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0778, val=0.0732, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0777, val=0.0732, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0733)

============================================================
📊 Round 117 Summary - Client client_47
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0780, RMSE=0.2793, R²=0.0356
   Val:   Loss=0.0733, RMSE=0.2707, R²=0.0606
============================================================


============================================================
🔄 Round 118 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0781, val=0.0732 (↓), lr=0.000001
   • Epoch   2/100: train=0.0781, val=0.0732, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0781, val=0.0732, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0780, val=0.0732, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0780, val=0.0732, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0778, val=0.0731, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0732)

============================================================
📊 Round 118 Summary - Client client_47
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0780, RMSE=0.2793, R²=0.0446
   Val:   Loss=0.0732, RMSE=0.2706, R²=0.0195
============================================================


📊 Round 118 Test Metrics:
   Loss: 0.0789, RMSE: 0.2809, MAE: 0.2409, R²: 0.0452

📊 Round 118 Test Metrics:
   Loss: 0.0789, RMSE: 0.2809, MAE: 0.2409, R²: 0.0452

============================================================
🔄 Round 120 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0769, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0768, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0768, val=0.0782, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0768, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0767, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0765, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 120 Summary - Client client_47
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0768, RMSE=0.2770, R²=0.0368
   Val:   Loss=0.0782, RMSE=0.2796, R²=0.0385
============================================================


============================================================
🔄 Round 121 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0768, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0768, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0768, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0767, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0767, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0766, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 121 Summary - Client client_47
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0765, RMSE=0.2765, R²=0.0427
   Val:   Loss=0.0793, RMSE=0.2816, R²=0.0280
============================================================


📊 Round 121 Test Metrics:
   Loss: 0.0789, RMSE: 0.2809, MAE: 0.2409, R²: 0.0453

📊 Round 121 Test Metrics:
   Loss: 0.0789, RMSE: 0.2809, MAE: 0.2409, R²: 0.0453

============================================================
🔄 Round 123 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0762, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0762, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0762, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0761, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0761, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0759, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 123 Summary - Client client_47
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0762, RMSE=0.2760, R²=0.0362
   Val:   Loss=0.0804, RMSE=0.2836, R²=0.0521
============================================================


============================================================
🔄 Round 126 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0770, val=0.0777 (↓), lr=0.000001
   • Epoch   2/100: train=0.0769, val=0.0777, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0769, val=0.0777, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0769, val=0.0777, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0769, val=0.0777, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0767, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 126 Summary - Client client_47
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0769, RMSE=0.2772, R²=0.0536
   Val:   Loss=0.0777, RMSE=0.2788, R²=-0.0330
============================================================


📊 Round 126 Test Metrics:
   Loss: 0.0789, RMSE: 0.2809, MAE: 0.2409, R²: 0.0453

📊 Round 126 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2409, R²: 0.0454

============================================================
🔄 Round 128 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0776, val=0.0750 (↓), lr=0.000001
   • Epoch   2/100: train=0.0776, val=0.0750, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0775, val=0.0750, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0775, val=0.0749, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0775, val=0.0749, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0773, val=0.0749, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0750)

============================================================
📊 Round 128 Summary - Client client_47
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0775, RMSE=0.2785, R²=0.0392
   Val:   Loss=0.0750, RMSE=0.2738, R²=0.0442
============================================================


📊 Round 128 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2409, R²: 0.0454

============================================================
🔄 Round 129 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0772, val=0.0765 (↓), lr=0.000001
   • Epoch   2/100: train=0.0772, val=0.0765, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0772, val=0.0765, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0772, val=0.0765, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0771, val=0.0764, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0770, val=0.0763, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0765)

============================================================
📊 Round 129 Summary - Client client_47
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0772, RMSE=0.2778, R²=0.0473
   Val:   Loss=0.0765, RMSE=0.2766, R²=0.0127
============================================================


📊 Round 129 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2409, R²: 0.0454

============================================================
🔄 Round 130 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0760, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0760, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0759, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0759, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0759, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0757, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 130 Summary - Client client_47
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0761, RMSE=0.2758, R²=0.0425
   Val:   Loss=0.0809, RMSE=0.2844, R²=0.0323
============================================================


📊 Round 130 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2409, R²: 0.0455

============================================================
🔄 Round 133 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0766, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0766, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0766, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0766, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0765, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0764, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 133 Summary - Client client_47
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0766, RMSE=0.2768, R²=0.0430
   Val:   Loss=0.0788, RMSE=0.2807, R²=0.0305
============================================================


============================================================
🔄 Round 134 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0772, val=0.0757 (↓), lr=0.000001
   • Epoch   2/100: train=0.0772, val=0.0757, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0771, val=0.0757, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0771, val=0.0756, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0771, val=0.0756, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0769, val=0.0756, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0757)

============================================================
📊 Round 134 Summary - Client client_47
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0774, RMSE=0.2782, R²=0.0422
   Val:   Loss=0.0757, RMSE=0.2751, R²=0.0340
============================================================


============================================================
🔄 Round 135 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0659 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0660, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0660, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0660, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0660, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0660, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0659)

============================================================
📊 Round 135 Summary - Client client_47
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=0.0383
   Val:   Loss=0.0659, RMSE=0.2568, R²=0.0367
============================================================


📊 Round 135 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2408, R²: 0.0456

📊 Round 135 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2408, R²: 0.0457

📊 Round 135 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2408, R²: 0.0456

============================================================
🔄 Round 140 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0757, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0756, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0756, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0756, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0755, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0754, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 140 Summary - Client client_47
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0758, RMSE=0.2753, R²=0.0390
   Val:   Loss=0.0820, RMSE=0.2863, R²=0.0426
============================================================


============================================================
🔄 Round 142 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0763, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0762, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0762, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0762, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0762, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0761, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 142 Summary - Client client_47
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0763, RMSE=0.2763, R²=0.0484
   Val:   Loss=0.0797, RMSE=0.2824, R²=0.0053
============================================================


============================================================
🔄 Round 146 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0752, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0751, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0751, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0751, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0751, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0750, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 146 Summary - Client client_47
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0751, RMSE=0.2741, R²=0.0396
   Val:   Loss=0.0846, RMSE=0.2908, R²=0.0457
============================================================


📊 Round 146 Test Metrics:
   Loss: 0.0789, RMSE: 0.2808, MAE: 0.2408, R²: 0.0457

============================================================
🔄 Round 147 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0759, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0758, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0758, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0758, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0758, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0757, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 147 Summary - Client client_47
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0759, RMSE=0.2755, R²=0.0444
   Val:   Loss=0.0815, RMSE=0.2855, R²=0.0246
============================================================


============================================================
🔄 Round 149 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0781, val=0.0713 (↓), lr=0.000001
   • Epoch   2/100: train=0.0781, val=0.0713, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0781, val=0.0712, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0780, val=0.0712, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0780, val=0.0712, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0779, val=0.0711, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0713)

============================================================
📊 Round 149 Summary - Client client_47
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2801, R²=0.0480
   Val:   Loss=0.0713, RMSE=0.2670, R²=0.0104
============================================================


📊 Round 149 Test Metrics:
   Loss: 0.0788, RMSE: 0.2808, MAE: 0.2408, R²: 0.0457

📊 Round 149 Test Metrics:
   Loss: 0.0788, RMSE: 0.2808, MAE: 0.2408, R²: 0.0458

============================================================
🔄 Round 153 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0766, val=0.0779 (↓), lr=0.000001
   • Epoch   2/100: train=0.0766, val=0.0779, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0765, val=0.0779, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0765, val=0.0778, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0765, val=0.0778, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0764, val=0.0777, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0779)

============================================================
📊 Round 153 Summary - Client client_47
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0768, RMSE=0.2771, R²=0.0530
   Val:   Loss=0.0779, RMSE=0.2791, R²=-0.0080
============================================================


📊 Round 153 Test Metrics:
   Loss: 0.0788, RMSE: 0.2808, MAE: 0.2408, R²: 0.0458

============================================================
🔄 Round 157 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0724, val=0.0950 (↓), lr=0.000001
   • Epoch   2/100: train=0.0724, val=0.0950, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0724, val=0.0950, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0723, val=0.0950, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0723, val=0.0950, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0721, val=0.0949, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0950)

============================================================
📊 Round 157 Summary - Client client_47
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0725, RMSE=0.2693, R²=0.0488
   Val:   Loss=0.0950, RMSE=0.3082, R²=0.0105
============================================================


📊 Round 157 Test Metrics:
   Loss: 0.0788, RMSE: 0.2808, MAE: 0.2408, R²: 0.0458

============================================================
🔄 Round 159 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0775, val=0.0753 (↓), lr=0.000001
   • Epoch   2/100: train=0.0775, val=0.0753, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0775, val=0.0753, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0775, val=0.0753, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0774, val=0.0752, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0773, val=0.0751, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0753)

============================================================
📊 Round 159 Summary - Client client_47
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0774, RMSE=0.2782, R²=0.0443
   Val:   Loss=0.0753, RMSE=0.2745, R²=0.0280
============================================================


============================================================
🔄 Round 162 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0769, val=0.0774 (↓), lr=0.000001
   • Epoch   2/100: train=0.0769, val=0.0774, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0769, val=0.0774, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0769, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0768, val=0.0773, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0767, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0774)

============================================================
📊 Round 162 Summary - Client client_47
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0769, RMSE=0.2773, R²=0.0370
   Val:   Loss=0.0774, RMSE=0.2782, R²=0.0470
============================================================


📊 Round 162 Test Metrics:
   Loss: 0.0788, RMSE: 0.2808, MAE: 0.2408, R²: 0.0459

📊 Round 162 Test Metrics:
   Loss: 0.0788, RMSE: 0.2808, MAE: 0.2408, R²: 0.0459

📊 Round 162 Test Metrics:
   Loss: 0.0788, RMSE: 0.2808, MAE: 0.2408, R²: 0.0460

============================================================
🔄 Round 168 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0772, val=0.0754 (↓), lr=0.000001
   • Epoch   2/100: train=0.0772, val=0.0754, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0772, val=0.0754, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0772, val=0.0753, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0772, val=0.0753, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0771, val=0.0752, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0754)

============================================================
📊 Round 168 Summary - Client client_47
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0774, RMSE=0.2782, R²=0.0363
   Val:   Loss=0.0754, RMSE=0.2747, R²=0.0548
============================================================


============================================================
🔄 Round 169 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0758, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0757, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0757, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0757, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0756, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0754, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 169 Summary - Client client_47
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0758, RMSE=0.2754, R²=0.0255
   Val:   Loss=0.0816, RMSE=0.2857, R²=0.0678
============================================================


📊 Round 169 Test Metrics:
   Loss: 0.0788, RMSE: 0.2807, MAE: 0.2408, R²: 0.0460

============================================================
🔄 Round 171 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0731, val=0.0921 (↓), lr=0.000001
   • Epoch   2/100: train=0.0731, val=0.0921, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0731, val=0.0921, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0731, val=0.0921, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0730, val=0.0921, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0729, val=0.0920, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0921)

============================================================
📊 Round 171 Summary - Client client_47
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0732, RMSE=0.2706, R²=0.0381
   Val:   Loss=0.0921, RMSE=0.3035, R²=0.0511
============================================================


📊 Round 171 Test Metrics:
   Loss: 0.0788, RMSE: 0.2807, MAE: 0.2408, R²: 0.0461

============================================================
🔄 Round 172 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0761, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0760, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0760, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0760, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0760, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0758, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 172 Summary - Client client_47
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0763, RMSE=0.2762, R²=0.0479
   Val:   Loss=0.0798, RMSE=0.2824, R²=0.0114
============================================================


============================================================
🔄 Round 173 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0770, val=0.0770 (↓), lr=0.000001
   • Epoch   2/100: train=0.0770, val=0.0770, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0770, val=0.0769, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0769, val=0.0769, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0769, val=0.0769, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0768, val=0.0767, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0770)

============================================================
📊 Round 173 Summary - Client client_47
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0770, RMSE=0.2774, R²=0.0436
   Val:   Loss=0.0770, RMSE=0.2775, R²=0.0308
============================================================


📊 Round 173 Test Metrics:
   Loss: 0.0788, RMSE: 0.2807, MAE: 0.2408, R²: 0.0461

============================================================
🔄 Round 175 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0776, val=0.0751 (↓), lr=0.000001
   • Epoch   2/100: train=0.0776, val=0.0751, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0776, val=0.0751, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0775, val=0.0751, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0775, val=0.0751, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0773, val=0.0751, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0751)

============================================================
📊 Round 175 Summary - Client client_47
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0774, RMSE=0.2783, R²=0.0361
   Val:   Loss=0.0751, RMSE=0.2740, R²=0.0516
============================================================


📊 Round 175 Test Metrics:
   Loss: 0.0788, RMSE: 0.2807, MAE: 0.2408, R²: 0.0461

============================================================
🔄 Round 176 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0783, val=0.0734 (↓), lr=0.000001
   • Epoch   2/100: train=0.0783, val=0.0734, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0783, val=0.0734, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0783, val=0.0734, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0783, val=0.0733, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0781, val=0.0732, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0734)

============================================================
📊 Round 176 Summary - Client client_47
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0778, RMSE=0.2790, R²=0.0427
   Val:   Loss=0.0734, RMSE=0.2710, R²=0.0375
============================================================


📊 Round 176 Test Metrics:
   Loss: 0.0788, RMSE: 0.2807, MAE: 0.2408, R²: 0.0461

============================================================
🔄 Round 177 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0719 (↓), lr=0.000001
   • Epoch   2/100: train=0.0783, val=0.0719, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0783, val=0.0719, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0783, val=0.0718, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0783, val=0.0718, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0781, val=0.0718, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0719)

============================================================
📊 Round 177 Summary - Client client_47
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0782, RMSE=0.2797, R²=0.0415
   Val:   Loss=0.0719, RMSE=0.2681, R²=0.0353
============================================================


📊 Round 177 Test Metrics:
   Loss: 0.0788, RMSE: 0.2807, MAE: 0.2408, R²: 0.0461

============================================================
🔄 Round 179 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0775, val=0.0746 (↓), lr=0.000001
   • Epoch   2/100: train=0.0775, val=0.0745, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0775, val=0.0745, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0775, val=0.0745, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0775, val=0.0744, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0774, val=0.0743, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0746)

============================================================
📊 Round 179 Summary - Client client_47
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0776, RMSE=0.2785, R²=0.0456
   Val:   Loss=0.0746, RMSE=0.2731, R²=0.0226
============================================================


============================================================
🔄 Round 182 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0779, val=0.0718 (↓), lr=0.000001
   • Epoch   2/100: train=0.0779, val=0.0718, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0778, val=0.0718, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0778, val=0.0718, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0778, val=0.0718, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0776, val=0.0717, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0718)

============================================================
📊 Round 182 Summary - Client client_47
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0783, RMSE=0.2797, R²=0.0406
   Val:   Loss=0.0718, RMSE=0.2680, R²=0.0443
============================================================


============================================================
🔄 Round 183 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0662 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0661, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0661, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0661, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0661, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0659, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0662)

============================================================
📊 Round 183 Summary - Client client_47
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2822, R²=0.0397
   Val:   Loss=0.0662, RMSE=0.2573, R²=0.0452
============================================================


📊 Round 183 Test Metrics:
   Loss: 0.0788, RMSE: 0.2807, MAE: 0.2407, R²: 0.0462

============================================================
🔄 Round 185 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0753, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0753, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0753, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0753, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0752, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0751, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 185 Summary - Client client_47
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0753, RMSE=0.2743, R²=0.0353
   Val:   Loss=0.0838, RMSE=0.2895, R²=0.0639
============================================================


============================================================
🔄 Round 186 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0772, val=0.0758 (↓), lr=0.000001
   • Epoch   2/100: train=0.0772, val=0.0758, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0772, val=0.0758, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0771, val=0.0757, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0771, val=0.0757, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0770, val=0.0755, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0758)

============================================================
📊 Round 186 Summary - Client client_47
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0773, RMSE=0.2779, R²=0.0468
   Val:   Loss=0.0758, RMSE=0.2753, R²=0.0089
============================================================


============================================================
🔄 Round 187 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0766, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0766, val=0.0780, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0765, val=0.0780, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0765, val=0.0780, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0765, val=0.0780, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0764, val=0.0778, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 187 Summary - Client client_47
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0767, RMSE=0.2769, R²=0.0478
   Val:   Loss=0.0781, RMSE=0.2794, R²=0.0075
============================================================


============================================================
🔄 Round 189 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0746, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0746, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0746, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0745, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0745, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0744, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 189 Summary - Client client_47
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0747, RMSE=0.2733, R²=0.0390
   Val:   Loss=0.0862, RMSE=0.2935, R²=0.0506
============================================================


============================================================
🔄 Round 190 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0772, val=0.0753 (↓), lr=0.000001
   • Epoch   2/100: train=0.0772, val=0.0752, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0772, val=0.0752, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0771, val=0.0752, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0771, val=0.0752, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0769, val=0.0752, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0753)

============================================================
📊 Round 190 Summary - Client client_47
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0774, RMSE=0.2782, R²=0.0440
   Val:   Loss=0.0753, RMSE=0.2743, R²=0.0258
============================================================


============================================================
🔄 Round 191 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0764, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0764, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0763, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0763, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0763, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0761, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 191 Summary - Client client_47
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0766, RMSE=0.2767, R²=0.0420
   Val:   Loss=0.0786, RMSE=0.2803, R²=0.0406
============================================================


📊 Round 191 Test Metrics:
   Loss: 0.0788, RMSE: 0.2807, MAE: 0.2407, R²: 0.0465

📊 Round 191 Test Metrics:
   Loss: 0.0788, RMSE: 0.2807, MAE: 0.2407, R²: 0.0464

📊 Round 191 Test Metrics:
   Loss: 0.0788, RMSE: 0.2807, MAE: 0.2407, R²: 0.0465

📊 Round 191 Test Metrics:
   Loss: 0.0788, RMSE: 0.2807, MAE: 0.2407, R²: 0.0465

============================================================
🔄 Round 201 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0750, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0750, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0749, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0749, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0749, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0748, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 201 Summary - Client client_47
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0748, RMSE=0.2735, R²=0.0517
   Val:   Loss=0.0855, RMSE=0.2924, R²=-0.0079
============================================================


📊 Round 201 Test Metrics:
   Loss: 0.0788, RMSE: 0.2807, MAE: 0.2407, R²: 0.0466

============================================================
🔄 Round 205 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0762, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0762, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0762, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0762, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0761, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0760, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 205 Summary - Client client_47
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0761, RMSE=0.2759, R²=0.0384
   Val:   Loss=0.0803, RMSE=0.2833, R²=0.0466
============================================================


============================================================
🔄 Round 206 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0765, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0765, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0764, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0764, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0764, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0762, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 206 Summary - Client client_47
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0765, RMSE=0.2766, R²=0.0448
   Val:   Loss=0.0787, RMSE=0.2805, R²=0.0310
============================================================


============================================================
🔄 Round 208 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0748, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0747, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0747, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0747, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0747, val=0.0864, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0745, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 208 Summary - Client client_47
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0746, RMSE=0.2731, R²=0.0358
   Val:   Loss=0.0864, RMSE=0.2940, R²=0.0628
============================================================


============================================================
🔄 Round 209 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0705 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0705, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0705, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0705, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0704, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0703, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0705)

============================================================
📊 Round 209 Summary - Client client_47
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2802, R²=0.0451
   Val:   Loss=0.0705, RMSE=0.2656, R²=0.0235
============================================================


📊 Round 209 Test Metrics:
   Loss: 0.0788, RMSE: 0.2807, MAE: 0.2407, R²: 0.0466

============================================================
🔄 Round 210 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0761, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0761, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0761, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0760, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0760, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0759, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 210 Summary - Client client_47
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0763, RMSE=0.2762, R²=0.0439
   Val:   Loss=0.0795, RMSE=0.2820, R²=0.0349
============================================================


📊 Round 210 Test Metrics:
   Loss: 0.0788, RMSE: 0.2807, MAE: 0.2407, R²: 0.0466

============================================================
🔄 Round 212 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0770, val=0.0776 (↓), lr=0.000001
   • Epoch   2/100: train=0.0770, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0769, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0769, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0769, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0768, val=0.0773, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 212 Summary - Client client_47
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0768, RMSE=0.2771, R²=0.0406
   Val:   Loss=0.0776, RMSE=0.2785, R²=0.0452
============================================================


📊 Round 212 Test Metrics:
   Loss: 0.0788, RMSE: 0.2807, MAE: 0.2407, R²: 0.0466

============================================================
🔄 Round 213 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0775, val=0.0750 (↓), lr=0.000001
   • Epoch   2/100: train=0.0774, val=0.0750, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0774, val=0.0750, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0774, val=0.0750, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0773, val=0.0750, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0772, val=0.0749, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0750)

============================================================
📊 Round 213 Summary - Client client_47
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0774, RMSE=0.2782, R²=0.0351
   Val:   Loss=0.0750, RMSE=0.2738, R²=0.0676
============================================================


============================================================
🔄 Round 215 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0770, val=0.0764 (↓), lr=0.000001
   • Epoch   2/100: train=0.0769, val=0.0764, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0769, val=0.0764, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0769, val=0.0764, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0769, val=0.0763, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0768, val=0.0762, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0764)

============================================================
📊 Round 215 Summary - Client client_47
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0771, RMSE=0.2776, R²=0.0457
   Val:   Loss=0.0764, RMSE=0.2765, R²=0.0209
============================================================


============================================================
🔄 Round 218 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0762, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0761, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0761, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0761, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0761, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0759, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 218 Summary - Client client_47
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0761, RMSE=0.2758, R²=0.0391
   Val:   Loss=0.0803, RMSE=0.2833, R²=0.0537
============================================================


📊 Round 218 Test Metrics:
   Loss: 0.0788, RMSE: 0.2806, MAE: 0.2407, R²: 0.0467

============================================================
🔄 Round 219 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0782, val=0.0721 (↓), lr=0.000001
   • Epoch   2/100: train=0.0782, val=0.0721, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0782, val=0.0721, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0781, val=0.0721, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0781, val=0.0721, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0779, val=0.0721, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0721)

============================================================
📊 Round 219 Summary - Client client_47
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0781, RMSE=0.2795, R²=0.0451
   Val:   Loss=0.0721, RMSE=0.2685, R²=0.0155
============================================================


📊 Round 219 Test Metrics:
   Loss: 0.0788, RMSE: 0.2806, MAE: 0.2407, R²: 0.0467

============================================================
🔄 Round 221 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0706 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0706, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0783, val=0.0706, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0783, val=0.0706, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0783, val=0.0706, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0781, val=0.0706, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0706)

============================================================
📊 Round 221 Summary - Client client_47
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2802, R²=0.0320
   Val:   Loss=0.0706, RMSE=0.2657, R²=0.0757
============================================================


📊 Round 221 Test Metrics:
   Loss: 0.0788, RMSE: 0.2807, MAE: 0.2407, R²: 0.0467

============================================================
🔄 Round 224 - Client client_47
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0756, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0756, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0756, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0755, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0755, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0754, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 224 Summary - Client client_47
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0758, RMSE=0.2753, R²=0.0460
   Val:   Loss=0.0814, RMSE=0.2853, R²=0.0287
============================================================


📊 Round 224 Test Metrics:
   Loss: 0.0788, RMSE: 0.2807, MAE: 0.2407, R²: 0.0467

❌ Client client_47 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8687 {grpc_message:"Socket closed", grpc_status:14}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8687 {grpc_message:"Socket closed", grpc_status:14}"
>
