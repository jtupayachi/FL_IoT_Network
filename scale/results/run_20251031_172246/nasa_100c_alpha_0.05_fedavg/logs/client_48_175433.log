[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d566d4e8-81fa-4ce4-a125-9ffc4500d724
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 43acac34-4897-4182-9f50-5fb9de0ae841
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 12278c4f-8bea-4ca4-a6f2-563213857ab4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7384486c-3fd8-406f-898f-bdec52343e94
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4f4fb0cf-dc1f-426b-ad10-7c74ae6b955c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 416849fd-c51e-41fa-a778-cd967a55aa46
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e92c1075-8a39-4389-a74b-6495adb098a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f0e7ff87-7897-46d5-b18c-be52b60a7ca7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b906d217-4bcf-426f-ad93-28b15efc66e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 12e3e235-ed42-4b94-a536-79987297f4fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0a4d39e2-86b0-433b-9aa7-335e2ce543e6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 486e93fc-061d-40f9-9fbe-fc3b6356919a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d8ed2985-fd41-4e14-847a-bfdfe7781521
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ea56dc3b-c3db-4491-bbb4-71622087a1e1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ed33739f-c3da-4d5a-8bd0-4eb704e2f3b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7096800a-8289-4860-adbf-0ed312249a11
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e2dc9ca3-a6c3-4c5b-8065-8ab8c913c794
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b672db70-02cf-42af-93b8-2fdcb4e3bbf1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b38dc732-e89d-4a38-8a7c-5bb211a7ed96
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message daca217a-6541-49bd-9cb7-87d95ae4abb2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4895171a-166b-4b64-a603-18dd86ae2519
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 21dda1f7-5c3d-459d-927d-341f36486647
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 45dd211d-8c20-4a17-99fb-8db56fac5fe5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ae07f4f0-12b9-4beb-8054-e7a51d21b72b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f07d53cb-11c0-44b8-9424-7398ef1399e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0af37b6b-bac9-4625-86d6-3f45200f1639
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message af26a330-9409-4153-a11c-6de744d1ee4e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 15f8772a-ac54-4a81-920d-c018d8d29c42
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4eaec419-26f6-4529-a97f-0c35e5185aa1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bc2f451a-18df-46ec-8556-d7da37071082
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aee241df-a5c9-46d2-8263-95e2f8a1b131
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6e7cae4e-8fdd-4d1f-8ba2-6e54872b9fa9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e10767a2-ae18-43ea-9ecf-e7e8f8d6982a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1e6a48cd-780d-497e-ba00-2859e2d943f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 73cb74cc-44e3-4b11-bba5-a0cd0f48db67
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 81dc9734-eaea-4da4-a1f5-aaed223eb774
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a753d759-1c02-4985-a6f5-da14fd0e9974
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 995187ea-943f-4d28-aa66-717ffad4b662
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5d031d1d-6708-4d76-8211-ecbdf2fe170c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6c73fd1f-76ea-40d5-bb80-1bd1c66c4dd7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 43b25afe-44fd-408e-b752-07f7ae48d493
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0b7465af-d63c-4070-af69-dbe254e066fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b7355939-b613-4a63-ac79-83570c5448fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 936ad5f4-b829-4405-b9ac-7b6127f46ff1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4742ee52-4297-4396-ab33-11d00e53b2ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 68b1e3d1-b435-4357-a8c4-8f754489f591
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 21e93396-f412-4918-b709-bbec2f848f6e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 36ed71e8-0d69-4aff-9f63-ffb16abaecc1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c932ac87-31ae-417b-a347-ac12bbfd4d1c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5efb264b-f6f3-4cec-8458-ce127a3d7bad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 57556ae7-1481-4a49-b2df-917338281549
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 818a4b96-60a6-4182-8140-b53483a49fcd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e039978d-5993-4f45-950b-28125d2802b5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ab663831-80be-4e09-877c-62141787a240
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3ed70c21-001c-485b-be23-be62d0a9a09a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b07d0b2e-4984-45ad-84cf-ff7e7753899e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6dda9640-b226-41df-80bc-7d3f45c8a1b9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eca2c0d3-318e-473e-8313-8a1cddcba97f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 126e7124-5770-4264-8a86-e038fe36de37
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 408d586b-ef54-4f0a-9a63-fe681f7840c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 15c1fde0-6cb6-4d84-b09e-b558f63ced9e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3174ee2f-310c-434a-b81b-ac13c7e4a572
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 110eab45-276f-4e5c-b6ee-4e7ea6084fb1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cd06b8f5-3e87-4fd4-91b3-d4b979d67085
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 574bb36f-f3df-408a-91bf-73b02962bbf9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 59fa614d-5f6e-481b-a05a-6fef52549249
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c02e62aa-61f4-4856-aae8-dd31a171c8c3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 641e595e-6642-4188-bcff-652217d09deb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 91bd0560-c9e7-48ac-b5b9-ddadab25956a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c3ce3a27-dd60-4475-bfaf-75952a3e546e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 15b9ea62-09db-47dc-96de-bdd905b27c03
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 780236b7-d42a-4c75-92bb-26b98b89f818
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0decad1a-358e-4ac5-b716-2a8e11e23409
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 18880367-9ffe-456c-a748-0fe476a6877d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fd24a96d-7f04-4437-aa4d-9d34f6184710
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 87ffa540-2296-4757-b56c-94f3f14333c3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 21a88896-acbb-4a42-959b-4ba21a96d808
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 417e7215-0a90-4ccf-8efd-b4ec9fce349c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 73eaa891-036f-4a0e-b544-613afbee3b67
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 40fa6598-f552-4bf0-ab58-88d29095ef3c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ed62eed2-93f0-4aa7-b5c9-e85f0504e1d5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b96236f2-5a23-4e7e-9fbb-8607ba6e65b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f3188d21-7bfe-43ac-8bd1-a247198fe5ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1d6a29bc-28b7-414b-9c70-2dcfc9e5de43
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b30edd49-7579-40ff-941b-8cd9fccf0901
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b1c095a8-9e89-47d9-b7cd-4b6b71731e72
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d18f15d7-0c2c-4c1e-8d97-0a098be65e61
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f51c65b7-a246-4514-827f-7afc15324361
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a3df0cdd-1010-4509-adc3-d8a7f61d8fed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 495c9e85-d7de-4dae-b0ab-cefe95eee668
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b3d0447c-f0c0-4057-8d72-cd1030e53447
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 07c5d44b-eb93-4589-b752-e4a88a13a537
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 46102cc8-e4b2-4c38-88da-45c6392d4252
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 39d63793-875b-45b5-aef3-c5c7e610210f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3e9092a7-cf95-49e0-8977-a2cc72e0ad3a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d801b526-48b7-4f99-88a4-409459eae837
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 788f7fdd-dcb1-4452-b328-f162c1021383
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9245ad7e-c313-44da-8cf6-cba25cc33b57
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message acb72802-3c0b-454b-a344-a212a3bd2907
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2428d2b8-98d9-483e-8a14-eadfefd4124c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b0bb1073-a7c2-4152-af67-49a79385a577
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9a5ee084-5594-4ede-ab38-9727b7be866e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0978450f-549e-44eb-b5ce-2ba6f2601158
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message faad5822-d382-47e8-b4f9-aaedca63ed1d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 58a5b8ea-3aed-46d5-80da-e191f2dd67a7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b2689e1b-a1f3-47d1-9670-85e23f44bee5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dd578074-014b-4639-9254-ae832ff7d6a9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b10dad26-edf4-4bc3-86f1-2f7316fe7b69
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e206248d-e96a-4f31-b487-bbd9f76a8520
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cc712b08-7036-4c0d-8210-b4e7ad970751
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d37a0d7c-1745-4e7a-bd59-92efbe47eb1d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 75e625d9-d515-40d4-9514-b1f7266c50a8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message acbc8fc6-86b1-416e-9505-18cbb666f5d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2c4bf2d0-4b31-4154-a9d6-867b38e97d50
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 046a5ec7-a84a-44b9-9401-a3f39e90e21e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message adb3c2b1-04d4-409a-8179-d6f33c82fb41
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b3aadd43-1f89-4eb0-9f35-44051bf425aa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c9f176b1-8269-4005-a5b0-3838183e87ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 13123a86-d2ab-4f3b-bd27-4c71368f1a9f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 22c23cd3-8793-48c2-a8bd-2e609d191160
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0f13f307-48d3-4ca6-8a12-c3112e8b73d9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 150db65d-27b4-44e3-9e15-bbcf56caf16e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 33a7d591-05c2-470c-9ae2-285f59c28c12
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dbd374aa-0977-4393-8157-9c5343ed9966
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 24e57018-1f86-4c2e-81ab-df1d14bf2306
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bf20af81-ac37-4261-8a9a-df89b36b2b24
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4c9cede3-196f-4f5d-b91e-b7711c96a981
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0f078938-16d7-44fc-8451-7c92edb15225
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e11b6199-fee6-4a0b-abc1-3d47bea9382e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 90df3a6c-ae6c-4dcd-a9b4-c1d7a5773369
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a194e662-d55d-40d5-9aee-3db8abcf09fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c6ff4248-04d3-44d6-89a5-9cd7a240d469
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c0979641-b2d3-4cff-b650-fc92ab9b490c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0d8b867c-3173-4557-bf98-2a8b81d95627
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f2671134-cc14-499a-a3cd-9e79d38e822b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d225dc5e-b19d-4a3f-a108-89867b0103d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e8d8fa46-c3d7-4415-8bcb-7980da035a7f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 30d1b2e0-3bfe-4ea3-91c7-2c20f9ff45d9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f9cbc771-beb2-408b-ad15-16fc75a9a72d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c45efda0-1432-415f-8e02-14bef44b2cc6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2a6c7fcf-910b-4e8e-8f46-bedb2035a446
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aebe6aac-e0ee-47d6-ba0c-c11790a268e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ee28cee0-c27c-4859-80fd-5dbb4169fe55
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1c82cf77-e0ad-48a8-9686-88c1325d8720
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0242faa5-1f64-42dc-95ec-7da6e60e63de
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 007c7ed3-4e80-46d4-b668-1b128b7bcca0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 44256008-4588-4115-9b35-a77874518bdc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5adfc4ba-d9f0-4a5b-bb91-160d743795df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2e79cf52-00b1-47cb-807f-7790f7904ec8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 91a4be92-b763-48d7-ab9a-21db068f14f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9a0a55a7-13c6-4b00-a8bf-359b47061978
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 91193e86-e309-4f39-b02d-939eb40d329e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 75c869e6-5d2d-495d-9aa3-f660a93b7f29
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ec3a666f-d61b-4856-a3a9-495669d22e17
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 67b057b8-6500-4340-abf8-9947b9f1912e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message de39b90a-9d64-407b-8a4d-1ecef4e4e6a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1a4ade91-7173-41c4-8937-bda779ab0697
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4137a1f9-4b52-4366-9836-25bd9b4fe0e1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c9e937c7-a69b-42d1-b069-82f6b3299627
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a09f9877-4878-4a04-9a71-f2deec7c346b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4deca35f-8ed9-4532-aec7-0b619b267238
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8daa1755-3d39-4e84-a8ea-ff6d47c4c0a3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 30ba1f72-50bf-452e-87dc-ec30512b82d9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6ebd8740-c96d-442f-8884-d8f469b927dd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1e856b19-ba08-4447-82c3-3e2fbaaec7e8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 56d9fcac-41fb-4259-8066-9736c2683e58
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5fc7d80e-02fe-4652-96df-6acd68bd93a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3a0cc057-d537-43b4-b02f-5fb6dd9e1272
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ab0078f1-3ad0-4991-8a28-4ccd1a36890e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e0e48e96-2763-4263-883a-1d648a86cb70
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 843ac3d1-fd90-4658-a0be-987a1a5b677a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 43b6d6c5-304f-41b1-8ecc-23022cb66369
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9a0dddb7-f98c-4d35-8abf-63abcad8b81a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7dfda674-ee5c-434b-a692-ff2958099bc7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9dee64c8-fdf7-4d29-91e0-52f782c05e41
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 649f1a37-e8a1-4264-b674-9b6770288eb8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3dd9acda-f9bd-499b-95f9-80c157f3bc88
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 47ef50de-8f10-409d-a663-5acdbb1647b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 15ae1ae3-70a3-47c9-a51d-88c7797a9c5c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message efdde468-2450-47d5-8b01-4578442c9629
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8687 {grpc_status:14, grpc_message:"Socket closed"}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_48
Server: localhost:8687
Algorithm: FEDAVG
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_48
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_48/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_48/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_48/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_48/test_labels.txt

📊 Raw data loaded:
   Train: X=(1068, 24), y=(1068,)
   Test:  X=(267, 24), y=(267,)

⚠️  Limiting training data: 1068 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  258 samples, 5 features
✅ Client client_48 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

📊 Round 0 Test Metrics:
   Loss: 0.0844, RMSE: 0.2906, MAE: 0.2533, R²: -0.0154

📊 Round 0 Test Metrics:
   Loss: 0.0842, RMSE: 0.2901, MAE: 0.2530, R²: -0.0123

============================================================
🔄 Round 8 - Client client_48
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.0809 (↓), lr=0.001000
   • Epoch   2/100: train=0.0847, val=0.0816, patience=1/15, lr=0.001000
   • Epoch   3/100: train=0.0844, val=0.0821, patience=2/15, lr=0.001000
   • Epoch   4/100: train=0.0842, val=0.0828, patience=3/15, lr=0.001000
   • Epoch   5/100: train=0.0839, val=0.0820, patience=4/15, lr=0.001000
   📉 Epoch 7: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0808, val=0.0810, patience=3/15, lr=0.000500
   📉 Epoch 15: LR reduced 0.000500 → 0.000250
   • Epoch  21/100: train=0.0777, val=0.0825, patience=13/15, lr=0.000250
   📉 Epoch 23: LR reduced 0.000250 → 0.000125

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 8 Summary - Client client_48
   Epochs: 23/100 (early stopped)
   LR: 0.001000 → 0.000125 (3 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=0.0597
   Val:   Loss=0.0802, RMSE=0.2832, R²=0.0248
============================================================


📊 Round 8 Test Metrics:
   Loss: 0.0842, RMSE: 0.2902, MAE: 0.2528, R²: -0.0125

📊 Round 8 Test Metrics:
   Loss: 0.0841, RMSE: 0.2900, MAE: 0.2525, R²: -0.0117

============================================================
🔄 Round 12 - Client client_48
   Epochs: 100, Batch: 32, LR: 0.000125
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0824 (↓), lr=0.000125
   • Epoch   2/100: train=0.0850, val=0.0828, patience=1/15, lr=0.000125
   • Epoch   3/100: train=0.0845, val=0.0830, patience=2/15, lr=0.000125
   • Epoch   4/100: train=0.0842, val=0.0830, patience=3/15, lr=0.000125
   • Epoch   5/100: train=0.0840, val=0.0831, patience=4/15, lr=0.000125
   📉 Epoch 8: LR reduced 0.000125 → 0.000063
   • Epoch  11/100: train=0.0832, val=0.0833, patience=10/15, lr=0.000063
   📉 Epoch 16: LR reduced 0.000063 → 0.000031

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 12 Summary - Client client_48
   Epochs: 16/100 (early stopped)
   LR: 0.000125 → 0.000031 (2 reductions)
   Train: Loss=0.0852, RMSE=0.2918, R²=0.0154
   Val:   Loss=0.0824, RMSE=0.2870, R²=-0.0045
============================================================


📊 Round 12 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2523, R²: -0.0097

============================================================
🔄 Round 15 - Client client_48
   Epochs: 100, Batch: 32, LR: 0.000031
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0791 (↓), lr=0.000031
   • Epoch   2/100: train=0.0864, val=0.0791, patience=1/15, lr=0.000031
   • Epoch   3/100: train=0.0863, val=0.0789, patience=2/15, lr=0.000031
   • Epoch   4/100: train=0.0861, val=0.0788, patience=3/15, lr=0.000031
   ✓ Epoch   5/100: train=0.0860, val=0.0786 (↓), lr=0.000031
   • Epoch  11/100: train=0.0854, val=0.0782, patience=6/15, lr=0.000031
   • Epoch  21/100: train=0.0849, val=0.0777, patience=8/15, lr=0.000031
   • Epoch  31/100: train=0.0845, val=0.0773, patience=8/15, lr=0.000031

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 15 Summary - Client client_48
   Epochs: 38/100 (early stopped)
   LR: 0.000031 → 0.000031 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2906, R²=0.0270
   Val:   Loss=0.0776, RMSE=0.2785, R²=0.0367
============================================================


============================================================
🔄 Round 16 - Client client_48
   Epochs: 100, Batch: 32, LR: 0.000031
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0856 (↓), lr=0.000031
   • Epoch   2/100: train=0.0844, val=0.0856, patience=1/15, lr=0.000031
   • Epoch   3/100: train=0.0843, val=0.0855, patience=2/15, lr=0.000031
   • Epoch   4/100: train=0.0841, val=0.0855, patience=3/15, lr=0.000031
   • Epoch   5/100: train=0.0839, val=0.0854, patience=4/15, lr=0.000031
   📉 Epoch 6: LR reduced 0.000031 → 0.000016
   • Epoch  11/100: train=0.0835, val=0.0853, patience=10/15, lr=0.000016
   📉 Epoch 14: LR reduced 0.000016 → 0.000008

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 16 Summary - Client client_48
   Epochs: 16/100 (early stopped)
   LR: 0.000031 → 0.000008 (2 reductions)
   Train: Loss=0.0843, RMSE=0.2904, R²=0.0115
   Val:   Loss=0.0856, RMSE=0.2926, R²=0.0071
============================================================


📊 Round 16 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2518, R²: -0.0059

============================================================
🔄 Round 18 - Client client_48
   Epochs: 100, Batch: 32, LR: 0.000008
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0783 (↓), lr=0.000008
   • Epoch   2/100: train=0.0859, val=0.0783, patience=1/15, lr=0.000008
   • Epoch   3/100: train=0.0859, val=0.0783, patience=2/15, lr=0.000008
   • Epoch   4/100: train=0.0858, val=0.0783, patience=3/15, lr=0.000008
   • Epoch   5/100: train=0.0858, val=0.0782, patience=4/15, lr=0.000008
   📉 Epoch 6: LR reduced 0.000008 → 0.000004
   • Epoch  11/100: train=0.0856, val=0.0782, patience=10/15, lr=0.000004
   📉 Epoch 14: LR reduced 0.000004 → 0.000002

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 18 Summary - Client client_48
   Epochs: 16/100 (early stopped)
   LR: 0.000008 → 0.000002 (2 reductions)
   Train: Loss=0.0861, RMSE=0.2934, R²=0.0091
   Val:   Loss=0.0783, RMSE=0.2799, R²=0.0282
============================================================


📊 Round 18 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2518, R²: -0.0052

============================================================
🔄 Round 19 - Client client_48
   Epochs: 100, Batch: 32, LR: 0.000002
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0891 (↓), lr=0.000002
   • Epoch   2/100: train=0.0835, val=0.0891, patience=1/15, lr=0.000002
   • Epoch   3/100: train=0.0835, val=0.0891, patience=2/15, lr=0.000002
   • Epoch   4/100: train=0.0835, val=0.0891, patience=3/15, lr=0.000002
   • Epoch   5/100: train=0.0835, val=0.0891, patience=4/15, lr=0.000002
   📉 Epoch 6: LR reduced 0.000002 → 0.000001
   • Epoch  11/100: train=0.0835, val=0.0891, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0891)

============================================================
📊 Round 19 Summary - Client client_48
   Epochs: 16/100 (early stopped)
   LR: 0.000002 → 0.000001 (1 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=0.0201
   Val:   Loss=0.0891, RMSE=0.2986, R²=-0.0164
============================================================


============================================================
🔄 Round 21 - Client client_48
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 21 Summary - Client client_48
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2915, R²=0.0155
   Val:   Loss=0.0827, RMSE=0.2876, R²=0.0011
============================================================


📊 Round 21 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2517, R²: -0.0050

============================================================
🔄 Round 26 - Client client_48
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0868 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0868, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0868, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0868, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0868, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0869, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0868)

============================================================
📊 Round 26 Summary - Client client_48
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2896, R²=0.0091
   Val:   Loss=0.0868, RMSE=0.2947, R²=0.0126
============================================================


============================================================
🔄 Round 27 - Client client_48
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 27 Summary - Client client_48
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2926, R²=0.0051
   Val:   Loss=0.0797, RMSE=0.2824, R²=0.0433
============================================================


📊 Round 27 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2517, R²: -0.0051

============================================================
🔄 Round 30 - Client client_48
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 30 Summary - Client client_48
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2931, R²=0.0080
   Val:   Loss=0.0787, RMSE=0.2804, R²=0.0386
============================================================


📊 Round 30 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2517, R²: -0.0050

============================================================
🔄 Round 31 - Client client_48
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 31 Summary - Client client_48
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2917, R²=0.0151
   Val:   Loss=0.0818, RMSE=0.2861, R²=0.0089
============================================================


📊 Round 31 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2517, R²: -0.0050

============================================================
🔄 Round 34 - Client client_48
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0779 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0779, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0779, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0779, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0779, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0779, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0779)

============================================================
📊 Round 34 Summary - Client client_48
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2934, R²=0.0135
   Val:   Loss=0.0779, RMSE=0.2792, R²=0.0111
============================================================


📊 Round 34 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2516, R²: -0.0049

📊 Round 34 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2516, R²: -0.0049

============================================================
🔄 Round 41 - Client client_48
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 41 Summary - Client client_48
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=0.0165
   Val:   Loss=0.0837, RMSE=0.2893, R²=-0.0141
============================================================


📊 Round 41 Test Metrics:
   Loss: 0.0835, RMSE: 0.2890, MAE: 0.2516, R²: -0.0048

============================================================
🔄 Round 42 - Client client_48
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 42 Summary - Client client_48
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=0.0161
   Val:   Loss=0.0836, RMSE=0.2892, R²=-0.0020
============================================================


📊 Round 42 Test Metrics:
   Loss: 0.0835, RMSE: 0.2890, MAE: 0.2516, R²: -0.0048

============================================================
🔄 Round 46 - Client client_48
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0868 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0868, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0868, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0868, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0868, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0867, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0868)

============================================================
📊 Round 46 Summary - Client client_48
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2896, R²=0.0172
   Val:   Loss=0.0868, RMSE=0.2946, R²=0.0016
============================================================


📊 Round 46 Test Metrics:
   Loss: 0.0835, RMSE: 0.2890, MAE: 0.2516, R²: -0.0048

============================================================
🔄 Round 47 - Client client_48
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0968 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0968, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0968, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0968, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0968, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0968, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0968)

============================================================
📊 Round 47 Summary - Client client_48
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2852, R²=0.0170
   Val:   Loss=0.0968, RMSE=0.3111, R²=-0.0002
============================================================


📊 Round 47 Test Metrics:
   Loss: 0.0835, RMSE: 0.2890, MAE: 0.2516, R²: -0.0048

============================================================
🔄 Round 49 - Client client_48
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0889 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0889, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0889, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0889, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0889, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0889, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0889)

============================================================
📊 Round 49 Summary - Client client_48
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2887, R²=0.0153
   Val:   Loss=0.0889, RMSE=0.2982, R²=0.0071
============================================================


============================================================
🔄 Round 50 - Client client_48
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0869 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0869, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0869, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0869, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0869, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0870, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 50 Summary - Client client_48
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=0.0147
   Val:   Loss=0.0869, RMSE=0.2948, R²=0.0047
============================================================


============================================================
🔄 Round 52 - Client client_48
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 52 Summary - Client client_48
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2901, R²=0.0216
   Val:   Loss=0.0855, RMSE=0.2924, R²=-0.0168
============================================================


📊 Round 52 Test Metrics:
   Loss: 0.0835, RMSE: 0.2890, MAE: 0.2516, R²: -0.0048

============================================================
🔄 Round 53 - Client client_48
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0770 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0770, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0770, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0770, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0770, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0770, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0770)

============================================================
📊 Round 53 Summary - Client client_48
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2938, R²=0.0086
   Val:   Loss=0.0770, RMSE=0.2775, R²=0.0360
============================================================


============================================================
🔄 Round 54 - Client client_48
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 54 Summary - Client client_48
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2925, R²=0.0134
   Val:   Loss=0.0800, RMSE=0.2829, R²=0.0142
============================================================


============================================================
🔄 Round 55 - Client client_48
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0872 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0872, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0872, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0872, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0872, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0872, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0872)

============================================================
📊 Round 55 Summary - Client client_48
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2894, R²=0.0139
   Val:   Loss=0.0872, RMSE=0.2952, R²=0.0151
============================================================


📊 Round 55 Test Metrics:
   Loss: 0.0835, RMSE: 0.2890, MAE: 0.2516, R²: -0.0048

============================================================
🔄 Round 56 - Client client_48
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 56 Summary - Client client_48
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2927, R²=0.0134
   Val:   Loss=0.0794, RMSE=0.2817, R²=0.0112
============================================================


============================================================
🔄 Round 57 - Client client_48
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 57 Summary - Client client_48
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2915, R²=0.0181
   Val:   Loss=0.0822, RMSE=0.2868, R²=-0.0134
============================================================


============================================================
🔄 Round 58 - Client client_48
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0923 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0923, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0923, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0923, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0923, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0923, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0923)

============================================================
📊 Round 58 Summary - Client client_48
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=0.0096
   Val:   Loss=0.0923, RMSE=0.3037, R²=0.0143
============================================================


📊 Round 58 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2516, R²: -0.0049

============================================================
🔄 Round 60 - Client client_48
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0893 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0893, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0893, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0893, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0893, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0892, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0893)

============================================================
📊 Round 60 Summary - Client client_48
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=0.0192
   Val:   Loss=0.0893, RMSE=0.2988, R²=-0.0059
============================================================


📊 Round 60 Test Metrics:
   Loss: 0.0835, RMSE: 0.2890, MAE: 0.2516, R²: -0.0048

============================================================
🔄 Round 61 - Client client_48
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0756 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0756, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0756, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0756, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0756, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0756, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0756)

============================================================
📊 Round 61 Summary - Client client_48
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2943, R²=0.0206
   Val:   Loss=0.0756, RMSE=0.2749, R²=-0.0175
============================================================


📊 Round 61 Test Metrics:
   Loss: 0.0835, RMSE: 0.2890, MAE: 0.2516, R²: -0.0048

============================================================
🔄 Round 62 - Client client_48
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0938 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0938, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0938, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0938, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0938, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0937, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0938)

============================================================
📊 Round 62 Summary - Client client_48
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=0.0109
   Val:   Loss=0.0938, RMSE=0.3062, R²=0.0193
============================================================


📊 Round 62 Test Metrics:
   Loss: 0.0835, RMSE: 0.2890, MAE: 0.2516, R²: -0.0048

============================================================
🔄 Round 63 - Client client_48
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0773, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0774, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 63 Summary - Client client_48
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2936, R²=0.0155
   Val:   Loss=0.0773, RMSE=0.2780, R²=-0.0090
============================================================


📊 Round 63 Test Metrics:
   Loss: 0.0835, RMSE: 0.2890, MAE: 0.2516, R²: -0.0048

============================================================
🔄 Round 64 - Client client_48
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0920 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0920, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0920, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0920, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0920, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0920, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0920)

============================================================
📊 Round 64 Summary - Client client_48
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2873, R²=0.0193
   Val:   Loss=0.0920, RMSE=0.3033, R²=-0.0132
============================================================


============================================================
🔄 Round 66 - Client client_48
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0896 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0896, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0896, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0896, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0896, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0895, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0896)

============================================================
📊 Round 66 Summary - Client client_48
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=0.0158
   Val:   Loss=0.0896, RMSE=0.2993, R²=0.0056
============================================================


============================================================
🔄 Round 68 - Client client_48
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0926 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0926, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0926, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0926, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0926, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0926, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0926)

============================================================
📊 Round 68 Summary - Client client_48
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=0.0123
   Val:   Loss=0.0926, RMSE=0.3043, R²=0.0214
============================================================


============================================================
🔄 Round 70 - Client client_48
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0880 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0880, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0880, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0880, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0880, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0880, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0880)

============================================================
📊 Round 70 Summary - Client client_48
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=0.0168
   Val:   Loss=0.0880, RMSE=0.2966, R²=0.0036
============================================================


📊 Round 70 Test Metrics:
   Loss: 0.0835, RMSE: 0.2890, MAE: 0.2516, R²: -0.0046

📊 Round 70 Test Metrics:
   Loss: 0.0835, RMSE: 0.2890, MAE: 0.2516, R²: -0.0046

============================================================
🔄 Round 75 - Client client_48
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0741 (↓), lr=0.000001
   • Epoch   2/100: train=0.0867, val=0.0741, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0867, val=0.0741, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0741, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0741, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0866, val=0.0741, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0741)

============================================================
📊 Round 75 Summary - Client client_48
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0870, RMSE=0.2949, R²=0.0122
   Val:   Loss=0.0741, RMSE=0.2722, R²=0.0202
============================================================


============================================================
🔄 Round 76 - Client client_48
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0994 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0994, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0994, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0994, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0994, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0995, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0994)

============================================================
📊 Round 76 Summary - Client client_48
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2840, R²=0.0180
   Val:   Loss=0.0994, RMSE=0.3153, R²=-0.0033
============================================================


============================================================
🔄 Round 77 - Client client_48
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0869 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0869, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0869, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0869, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0869, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0869, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 77 Summary - Client client_48
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=0.0205
   Val:   Loss=0.0869, RMSE=0.2947, R²=-0.0105
============================================================


📊 Round 77 Test Metrics:
   Loss: 0.0835, RMSE: 0.2890, MAE: 0.2516, R²: -0.0045

============================================================
🔄 Round 81 - Client client_48
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 81 Summary - Client client_48
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2926, R²=0.0180
   Val:   Loss=0.0797, RMSE=0.2823, R²=-0.0146
============================================================


📊 Round 81 Test Metrics:
   Loss: 0.0835, RMSE: 0.2890, MAE: 0.2516, R²: -0.0045

📊 Round 81 Test Metrics:
   Loss: 0.0835, RMSE: 0.2890, MAE: 0.2516, R²: -0.0044

============================================================
🔄 Round 87 - Client client_48
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 87 Summary - Client client_48
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2928, R²=0.0145
   Val:   Loss=0.0790, RMSE=0.2811, R²=0.0006
============================================================


📊 Round 87 Test Metrics:
   Loss: 0.0835, RMSE: 0.2890, MAE: 0.2516, R²: -0.0044

============================================================
🔄 Round 91 - Client client_48
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 91 Summary - Client client_48
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2911, R²=0.0158
   Val:   Loss=0.0831, RMSE=0.2882, R²=-0.0558
============================================================


📊 Round 91 Test Metrics:
   Loss: 0.0835, RMSE: 0.2890, MAE: 0.2516, R²: -0.0043

📊 Round 91 Test Metrics:
   Loss: 0.0835, RMSE: 0.2890, MAE: 0.2516, R²: -0.0043

📊 Round 91 Test Metrics:
   Loss: 0.0835, RMSE: 0.2890, MAE: 0.2516, R²: -0.0043

============================================================
🔄 Round 99 - Client client_48
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 99 Summary - Client client_48
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2922, R²=0.0133
   Val:   Loss=0.0805, RMSE=0.2837, R²=0.0099
============================================================


📊 Round 99 Test Metrics:
   Loss: 0.0835, RMSE: 0.2890, MAE: 0.2516, R²: -0.0043

============================================================
🔄 Round 101 - Client client_48
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0874, val=0.0724 (↓), lr=0.000001
   • Epoch   2/100: train=0.0874, val=0.0724, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0874, val=0.0724, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0874, val=0.0723, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0874, val=0.0723, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0874, val=0.0723, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0724)

============================================================
📊 Round 101 Summary - Client client_48
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0874, RMSE=0.2957, R²=0.0100
   Val:   Loss=0.0724, RMSE=0.2690, R²=0.0355
============================================================


📊 Round 101 Test Metrics:
   Loss: 0.0835, RMSE: 0.2890, MAE: 0.2516, R²: -0.0042

============================================================
🔄 Round 106 - Client client_48
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0896 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0896, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0896, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0896, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0896, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0896, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0896)

============================================================
📊 Round 106 Summary - Client client_48
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=0.0232
   Val:   Loss=0.0896, RMSE=0.2993, R²=-0.0192
============================================================


============================================================
🔄 Round 107 - Client client_48
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0927 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0927, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0927, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0928, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0928, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0928, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0927)

============================================================
📊 Round 107 Summary - Client client_48
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=0.0154
   Val:   Loss=0.0927, RMSE=0.3045, R²=-0.0116
============================================================


📊 Round 107 Test Metrics:
   Loss: 0.0835, RMSE: 0.2890, MAE: 0.2516, R²: -0.0042

============================================================
🔄 Round 110 - Client client_48
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 110 Summary - Client client_48
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=0.0032
   Val:   Loss=0.0836, RMSE=0.2892, R²=0.0524
============================================================


============================================================
🔄 Round 111 - Client client_48
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0871, val=0.0746 (↓), lr=0.000001
   • Epoch   2/100: train=0.0871, val=0.0746, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0871, val=0.0746, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0871, val=0.0746, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0871, val=0.0746, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0870, val=0.0746, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0746)

============================================================
📊 Round 111 Summary - Client client_48
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0869, RMSE=0.2947, R²=0.0117
   Val:   Loss=0.0746, RMSE=0.2731, R²=0.0235
============================================================


📊 Round 111 Test Metrics:
   Loss: 0.0835, RMSE: 0.2890, MAE: 0.2516, R²: -0.0041

============================================================
🔄 Round 114 - Client client_48
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0864, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0864, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 114 Summary - Client client_48
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=0.0159
   Val:   Loss=0.0864, RMSE=0.2940, R²=-0.0070
============================================================


📊 Round 114 Test Metrics:
   Loss: 0.0835, RMSE: 0.2889, MAE: 0.2516, R²: -0.0041

============================================================
🔄 Round 115 - Client client_48
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0872 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0872, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0872, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0872, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0872, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0872, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0872)

============================================================
📊 Round 115 Summary - Client client_48
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=0.0189
   Val:   Loss=0.0872, RMSE=0.2953, R²=-0.0028
============================================================


============================================================
🔄 Round 119 - Client client_48
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0916 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0916, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0916, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0916, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0916, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0916, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0916)

============================================================
📊 Round 119 Summary - Client client_48
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=0.0050
   Val:   Loss=0.0916, RMSE=0.3026, R²=0.0276
============================================================


============================================================
🔄 Round 120 - Client client_48
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0864, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0864, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 120 Summary - Client client_48
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=0.0116
   Val:   Loss=0.0864, RMSE=0.2940, R²=0.0217
============================================================


📊 Round 120 Test Metrics:
   Loss: 0.0835, RMSE: 0.2889, MAE: 0.2515, R²: -0.0040

============================================================
🔄 Round 123 - Client client_48
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 123 Summary - Client client_48
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=0.0162
   Val:   Loss=0.0824, RMSE=0.2871, R²=0.0069
============================================================


============================================================
🔄 Round 124 - Client client_48
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 124 Summary - Client client_48
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2930, R²=0.0077
   Val:   Loss=0.0786, RMSE=0.2803, R²=0.0410
============================================================


📊 Round 124 Test Metrics:
   Loss: 0.0835, RMSE: 0.2889, MAE: 0.2515, R²: -0.0040

============================================================
🔄 Round 125 - Client client_48
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0883 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0883, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0883, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0883, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0883, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0883, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0883)

============================================================
📊 Round 125 Summary - Client client_48
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=0.0149
   Val:   Loss=0.0883, RMSE=0.2972, R²=0.0085
============================================================


📊 Round 125 Test Metrics:
   Loss: 0.0835, RMSE: 0.2889, MAE: 0.2515, R²: -0.0040

📊 Round 125 Test Metrics:
   Loss: 0.0835, RMSE: 0.2889, MAE: 0.2515, R²: -0.0040

============================================================
🔄 Round 127 - Client client_48
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 127 Summary - Client client_48
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2911, R²=0.0081
   Val:   Loss=0.0830, RMSE=0.2881, R²=0.0262
============================================================


📊 Round 127 Test Metrics:
   Loss: 0.0835, RMSE: 0.2889, MAE: 0.2515, R²: -0.0041

============================================================
🔄 Round 129 - Client client_48
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0927 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0927, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0927, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0927, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0927, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0927, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0927)

============================================================
📊 Round 129 Summary - Client client_48
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=0.0100
   Val:   Loss=0.0927, RMSE=0.3044, R²=0.0239
============================================================


📊 Round 129 Test Metrics:
   Loss: 0.0835, RMSE: 0.2889, MAE: 0.2515, R²: -0.0041

============================================================
🔄 Round 130 - Client client_48
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0922 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0922, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0922, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0922, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0922, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0921, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0922)

============================================================
📊 Round 130 Summary - Client client_48
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2871, R²=0.0179
   Val:   Loss=0.0922, RMSE=0.3036, R²=0.0014
============================================================


📊 Round 130 Test Metrics:
   Loss: 0.0835, RMSE: 0.2889, MAE: 0.2515, R²: -0.0041

============================================================
🔄 Round 133 - Client client_48
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0899 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0898, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0898, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0898, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0898, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0898, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0899)

============================================================
📊 Round 133 Summary - Client client_48
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2882, R²=0.0055
   Val:   Loss=0.0899, RMSE=0.2998, R²=0.0470
============================================================


============================================================
🔄 Round 134 - Client client_48
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0905 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0905, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0905, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0905, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0905, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0906, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0905)

============================================================
📊 Round 134 Summary - Client client_48
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=0.0033
   Val:   Loss=0.0905, RMSE=0.3008, R²=0.0379
============================================================


📊 Round 134 Test Metrics:
   Loss: 0.0835, RMSE: 0.2890, MAE: 0.2516, R²: -0.0041

============================================================
🔄 Round 136 - Client client_48
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0871 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0871, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0871, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0871, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0871, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0871, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0871)

============================================================
📊 Round 136 Summary - Client client_48
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=0.0107
   Val:   Loss=0.0871, RMSE=0.2952, R²=0.0282
============================================================


📊 Round 136 Test Metrics:
   Loss: 0.0835, RMSE: 0.2889, MAE: 0.2515, R²: -0.0041

📊 Round 136 Test Metrics:
   Loss: 0.0835, RMSE: 0.2889, MAE: 0.2515, R²: -0.0041

📊 Round 136 Test Metrics:
   Loss: 0.0835, RMSE: 0.2889, MAE: 0.2515, R²: -0.0041

============================================================
🔄 Round 141 - Client client_48
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 141 Summary - Client client_48
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=0.0017
   Val:   Loss=0.0859, RMSE=0.2932, R²=0.0569
============================================================


============================================================
🔄 Round 142 - Client client_48
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 142 Summary - Client client_48
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2920, R²=0.0148
   Val:   Loss=0.0809, RMSE=0.2844, R²=0.0059
============================================================


============================================================
🔄 Round 143 - Client client_48
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0898 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0898, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0898, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0898, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0898, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0898, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0898)

============================================================
📊 Round 143 Summary - Client client_48
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=0.0104
   Val:   Loss=0.0898, RMSE=0.2997, R²=0.0301
============================================================


============================================================
🔄 Round 144 - Client client_48
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 144 Summary - Client client_48
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=0.0122
   Val:   Loss=0.0822, RMSE=0.2868, R²=0.0243
============================================================


📊 Round 144 Test Metrics:
   Loss: 0.0835, RMSE: 0.2889, MAE: 0.2515, R²: -0.0040

============================================================
🔄 Round 145 - Client client_48
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0867 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0867, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0867, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0867, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0867, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 145 Summary - Client client_48
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=0.0150
   Val:   Loss=0.0867, RMSE=0.2945, R²=0.0095
============================================================


📊 Round 145 Test Metrics:
   Loss: 0.0835, RMSE: 0.2889, MAE: 0.2515, R²: -0.0040

============================================================
🔄 Round 147 - Client client_48
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 147 Summary - Client client_48
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2926, R²=0.0154
   Val:   Loss=0.0796, RMSE=0.2821, R²=0.0109
============================================================


============================================================
🔄 Round 150 - Client client_48
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0870 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0870, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0870, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0870, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0870, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0870, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 150 Summary - Client client_48
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2894, R²=0.0152
   Val:   Loss=0.0870, RMSE=0.2950, R²=0.0017
============================================================


============================================================
🔄 Round 154 - Client client_48
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0889 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0889, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0889, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0889, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0889, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0889, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0889)

============================================================
📊 Round 154 Summary - Client client_48
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2885, R²=0.0118
   Val:   Loss=0.0889, RMSE=0.2982, R²=0.0137
============================================================


📊 Round 154 Test Metrics:
   Loss: 0.0835, RMSE: 0.2889, MAE: 0.2515, R²: -0.0039

============================================================
🔄 Round 156 - Client client_48
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0870, val=0.0740 (↓), lr=0.000001
   • Epoch   2/100: train=0.0870, val=0.0740, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0870, val=0.0740, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0870, val=0.0740, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0869, val=0.0740, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0869, val=0.0740, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0740)

============================================================
📊 Round 156 Summary - Client client_48
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0870, RMSE=0.2949, R²=0.0117
   Val:   Loss=0.0740, RMSE=0.2721, R²=0.0226
============================================================


============================================================
🔄 Round 157 - Client client_48
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 157 Summary - Client client_48
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2913, R²=0.0106
   Val:   Loss=0.0825, RMSE=0.2872, R²=0.0236
============================================================


📊 Round 157 Test Metrics:
   Loss: 0.0835, RMSE: 0.2889, MAE: 0.2515, R²: -0.0039

📊 Round 157 Test Metrics:
   Loss: 0.0835, RMSE: 0.2889, MAE: 0.2515, R²: -0.0039

============================================================
🔄 Round 160 - Client client_48
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0923 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0923, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0923, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0923, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0923, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0922, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0923)

============================================================
📊 Round 160 Summary - Client client_48
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=0.0086
   Val:   Loss=0.0923, RMSE=0.3038, R²=0.0349
============================================================


📊 Round 160 Test Metrics:
   Loss: 0.0835, RMSE: 0.2889, MAE: 0.2515, R²: -0.0039

📊 Round 160 Test Metrics:
   Loss: 0.0835, RMSE: 0.2889, MAE: 0.2515, R²: -0.0038

📊 Round 160 Test Metrics:
   Loss: 0.0835, RMSE: 0.2889, MAE: 0.2515, R²: -0.0039

============================================================
🔄 Round 165 - Client client_48
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0900 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0900, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0900, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0900, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0900, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0900, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0900)

============================================================
📊 Round 165 Summary - Client client_48
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=0.0088
   Val:   Loss=0.0900, RMSE=0.3000, R²=0.0362
============================================================


📊 Round 165 Test Metrics:
   Loss: 0.0835, RMSE: 0.2889, MAE: 0.2515, R²: -0.0039

📊 Round 165 Test Metrics:
   Loss: 0.0835, RMSE: 0.2889, MAE: 0.2515, R²: -0.0039

============================================================
🔄 Round 167 - Client client_48
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 167 Summary - Client client_48
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=0.0160
   Val:   Loss=0.0822, RMSE=0.2867, R²=0.0018
============================================================


============================================================
🔄 Round 168 - Client client_48
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0939 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0939, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0939, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0939, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0939, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0939, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0939)

============================================================
📊 Round 168 Summary - Client client_48
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=0.0115
   Val:   Loss=0.0939, RMSE=0.3064, R²=0.0197
============================================================


📊 Round 168 Test Metrics:
   Loss: 0.0835, RMSE: 0.2889, MAE: 0.2515, R²: -0.0039

============================================================
🔄 Round 169 - Client client_48
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 169 Summary - Client client_48
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2920, R²=0.0177
   Val:   Loss=0.0808, RMSE=0.2842, R²=0.0008
============================================================


📊 Round 169 Test Metrics:
   Loss: 0.0835, RMSE: 0.2889, MAE: 0.2515, R²: -0.0039

📊 Round 169 Test Metrics:
   Loss: 0.0835, RMSE: 0.2889, MAE: 0.2515, R²: -0.0039

📊 Round 169 Test Metrics:
   Loss: 0.0835, RMSE: 0.2889, MAE: 0.2515, R²: -0.0038

============================================================
🔄 Round 178 - Client client_48
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 178 Summary - Client client_48
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=0.0107
   Val:   Loss=0.0821, RMSE=0.2865, R²=0.0260
============================================================


📊 Round 178 Test Metrics:
   Loss: 0.0835, RMSE: 0.2889, MAE: 0.2515, R²: -0.0038

============================================================
🔄 Round 180 - Client client_48
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 180 Summary - Client client_48
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=0.0215
   Val:   Loss=0.0832, RMSE=0.2885, R²=-0.0363
============================================================


📊 Round 180 Test Metrics:
   Loss: 0.0835, RMSE: 0.2889, MAE: 0.2515, R²: -0.0039

📊 Round 180 Test Metrics:
   Loss: 0.0835, RMSE: 0.2889, MAE: 0.2515, R²: -0.0039

============================================================
🔄 Round 182 - Client client_48
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 182 Summary - Client client_48
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=0.0222
   Val:   Loss=0.0847, RMSE=0.2910, R²=-0.0154
============================================================


📊 Round 182 Test Metrics:
   Loss: 0.0835, RMSE: 0.2889, MAE: 0.2515, R²: -0.0038

📊 Round 182 Test Metrics:
   Loss: 0.0835, RMSE: 0.2889, MAE: 0.2515, R²: -0.0038

📊 Round 182 Test Metrics:
   Loss: 0.0835, RMSE: 0.2889, MAE: 0.2515, R²: -0.0038

============================================================
🔄 Round 186 - Client client_48
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 186 Summary - Client client_48
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=0.0048
   Val:   Loss=0.0838, RMSE=0.2895, R²=0.0534
============================================================


📊 Round 186 Test Metrics:
   Loss: 0.0835, RMSE: 0.2889, MAE: 0.2515, R²: -0.0039

📊 Round 186 Test Metrics:
   Loss: 0.0835, RMSE: 0.2889, MAE: 0.2515, R²: -0.0039

📊 Round 186 Test Metrics:
   Loss: 0.0835, RMSE: 0.2889, MAE: 0.2515, R²: -0.0039

============================================================
🔄 Round 190 - Client client_48
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 190 Summary - Client client_48
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2916, R²=0.0148
   Val:   Loss=0.0818, RMSE=0.2860, R²=0.0147
============================================================


============================================================
🔄 Round 191 - Client client_48
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0755 (↓), lr=0.000001
   • Epoch   2/100: train=0.0867, val=0.0755, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0867, val=0.0755, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0867, val=0.0755, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0756, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0866, val=0.0756, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0755)

============================================================
📊 Round 191 Summary - Client client_48
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2942, R²=0.0042
   Val:   Loss=0.0755, RMSE=0.2748, R²=0.0493
============================================================


============================================================
🔄 Round 194 - Client client_48
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.0760 (↓), lr=0.000001
   • Epoch   2/100: train=0.0868, val=0.0760, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0868, val=0.0760, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0868, val=0.0760, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0868, val=0.0760, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0867, val=0.0760, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0760)

============================================================
📊 Round 194 Summary - Client client_48
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2940, R²=0.0069
   Val:   Loss=0.0760, RMSE=0.2756, R²=0.0495
============================================================


📊 Round 194 Test Metrics:
   Loss: 0.0835, RMSE: 0.2889, MAE: 0.2515, R²: -0.0039

📊 Round 194 Test Metrics:
   Loss: 0.0835, RMSE: 0.2889, MAE: 0.2515, R²: -0.0038

============================================================
🔄 Round 197 - Client client_48
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0863 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 197 Summary - Client client_48
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2896, R²=0.0164
   Val:   Loss=0.0863, RMSE=0.2937, R²=0.0066
============================================================


📊 Round 197 Test Metrics:
   Loss: 0.0835, RMSE: 0.2889, MAE: 0.2515, R²: -0.0038

============================================================
🔄 Round 199 - Client client_48
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0777 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0777, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0777, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0776, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0776, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 199 Summary - Client client_48
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2933, R²=0.0118
   Val:   Loss=0.0777, RMSE=0.2787, R²=0.0286
============================================================


📊 Round 199 Test Metrics:
   Loss: 0.0835, RMSE: 0.2889, MAE: 0.2515, R²: -0.0038

============================================================
🔄 Round 201 - Client client_48
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0891 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0891, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0891, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0891, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0891, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0892, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0891)

============================================================
📊 Round 201 Summary - Client client_48
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=0.0125
   Val:   Loss=0.0891, RMSE=0.2985, R²=0.0185
============================================================


📊 Round 201 Test Metrics:
   Loss: 0.0835, RMSE: 0.2889, MAE: 0.2515, R²: -0.0038

============================================================
🔄 Round 202 - Client client_48
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0896 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0896, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0896, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0896, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0896, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0895, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0896)

============================================================
📊 Round 202 Summary - Client client_48
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2882, R²=0.0163
   Val:   Loss=0.0896, RMSE=0.2993, R²=0.0081
============================================================


============================================================
🔄 Round 203 - Client client_48
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 203 Summary - Client client_48
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=0.0192
   Val:   Loss=0.0822, RMSE=0.2867, R²=-0.0040
============================================================


📊 Round 203 Test Metrics:
   Loss: 0.0835, RMSE: 0.2889, MAE: 0.2515, R²: -0.0038

📊 Round 203 Test Metrics:
   Loss: 0.0835, RMSE: 0.2889, MAE: 0.2515, R²: -0.0038

📊 Round 203 Test Metrics:
   Loss: 0.0835, RMSE: 0.2889, MAE: 0.2515, R²: -0.0038

============================================================
🔄 Round 207 - Client client_48
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0768 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0768, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0768, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0767, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0767, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0767, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0768)

============================================================
📊 Round 207 Summary - Client client_48
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2937, R²=0.0154
   Val:   Loss=0.0768, RMSE=0.2771, R²=0.0133
============================================================


============================================================
🔄 Round 208 - Client client_48
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0782, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 208 Summary - Client client_48
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2931, R²=0.0198
   Val:   Loss=0.0782, RMSE=0.2796, R²=-0.0068
============================================================


📊 Round 208 Test Metrics:
   Loss: 0.0835, RMSE: 0.2889, MAE: 0.2515, R²: -0.0037

============================================================
🔄 Round 210 - Client client_48
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0870 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0870, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0870, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0870, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0870, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0870, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 210 Summary - Client client_48
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=0.0200
   Val:   Loss=0.0870, RMSE=0.2949, R²=-0.0136
============================================================


============================================================
🔄 Round 211 - Client client_48
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 211 Summary - Client client_48
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2927, R²=0.0187
   Val:   Loss=0.0791, RMSE=0.2812, R²=-0.0020
============================================================


============================================================
🔄 Round 212 - Client client_48
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 212 Summary - Client client_48
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2901, R²=0.0131
   Val:   Loss=0.0853, RMSE=0.2920, R²=0.0144
============================================================


============================================================
🔄 Round 214 - Client client_48
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 214 Summary - Client client_48
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2934, R²=0.0018
   Val:   Loss=0.0775, RMSE=0.2784, R²=0.0629
============================================================


📊 Round 214 Test Metrics:
   Loss: 0.0835, RMSE: 0.2889, MAE: 0.2515, R²: -0.0037

============================================================
🔄 Round 215 - Client client_48
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0899 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0899, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0899, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0899, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0899, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0900, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0899)

============================================================
📊 Round 215 Summary - Client client_48
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=0.0086
   Val:   Loss=0.0899, RMSE=0.2998, R²=0.0176
============================================================


============================================================
🔄 Round 216 - Client client_48
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 216 Summary - Client client_48
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2919, R²=0.0025
   Val:   Loss=0.0809, RMSE=0.2844, R²=0.0591
============================================================


📊 Round 216 Test Metrics:
   Loss: 0.0835, RMSE: 0.2889, MAE: 0.2515, R²: -0.0037

============================================================
🔄 Round 220 - Client client_48
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0929 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0929, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0929, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0929, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0929, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0929, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0929)

============================================================
📊 Round 220 Summary - Client client_48
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=0.0137
   Val:   Loss=0.0929, RMSE=0.3048, R²=0.0192
============================================================


============================================================
🔄 Round 221 - Client client_48
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 221 Summary - Client client_48
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2925, R²=0.0164
   Val:   Loss=0.0795, RMSE=0.2819, R²=0.0016
============================================================


============================================================
🔄 Round 222 - Client client_48
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 222 Summary - Client client_48
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2904, R²=0.0072
   Val:   Loss=0.0844, RMSE=0.2905, R²=0.0323
============================================================


📊 Round 222 Test Metrics:
   Loss: 0.0834, RMSE: 0.2889, MAE: 0.2515, R²: -0.0036

❌ Client client_48 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8687 {grpc_status:14, grpc_message:"Socket closed"}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8687 {grpc_status:14, grpc_message:"Socket closed"}"
>
