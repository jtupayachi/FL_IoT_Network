[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d87e0533-ed7b-42c2-ad43-f62d2881c1d1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5160ce52-7a38-44e8-9687-a8328708ba01
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 469e7ceb-68ec-4654-8121-05b1547acfb2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9e4677ed-538a-4239-8c4d-9ae752a52576
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7e4e6fa5-74c6-46d5-9ca1-2c375cffe866
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bb202211-5755-471c-9ea6-988eb2ecfbb8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2c193473-f714-4c76-9f41-8d99a5b8cae4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7b49931c-2a2c-43cd-998c-5976e08797f4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5a228edc-ea74-4564-99f1-08a54661f2bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 96874774-a250-4179-8e01-4207ef9e91f8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0235be61-c73f-44aa-91d8-df3998377370
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dafd00a4-4b95-4f5e-b25a-c252bb249cc5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 77a7e93b-597f-4957-b4f9-e07d80e8563d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 82659c70-a843-442e-8323-81a181bf179c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d1565ec0-833c-418e-a9d0-00f7c80f80c7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a36d1c66-04f5-4869-b044-6e7f8182ac53
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5ab78048-682c-4b9c-b79e-ae746e1779c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 203059d9-a6ff-457a-9e3f-e6722e247efd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c2a33181-5cb0-4dae-9f89-ae7e9719fa92
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d1269a65-229b-47c0-a457-7d125a2f6918
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7ba51522-a8b4-46bb-8012-96c3095a9efc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c86a776c-21a1-479a-aa27-e6b79bcaef70
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 90b03414-d581-48d1-91c5-ec96ea6b3a5f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0b1eca76-461b-4c77-9a4e-81868ab28eaa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 34101d79-e480-4f7d-9e48-37715f271a94
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 282925b5-6182-4714-9bb3-55998ae9e6be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b981e9c4-c5d5-44b7-90e2-2f3e98cf5886
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 44223b9d-d286-4e1c-9f98-ff8384e7a537
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 872c4dd3-0aeb-4cce-a003-fa18fb7c7074
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 68f6576e-fd5e-4a6b-a28a-d310488755ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 75c4d802-9cc1-4d0c-bede-2d8837baaf78
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 31595761-2d30-419b-9ecc-f8fe227e8d12
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 621f90dc-c2f8-4293-aad8-d83ebbee3403
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f5b49874-285f-40b4-bcc1-2c7020b1b01e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 980e9b41-985c-4aa0-bd7d-de467aab6f8d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6505f567-038d-42a6-a518-81f898473d4d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2cedad88-63d7-440b-8d04-095028a63e29
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 65fc5208-d2b4-43ac-bd89-da3fcf92f955
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 720d4b16-547c-4b56-bd84-cccc001d1270
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ce062de0-52d0-4060-81d1-32acb5f6def6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 73830b66-f80f-4fba-ab31-e06ecbfb2d1c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9e1a1256-192a-47c2-b273-ec579a29b46b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 63f35636-0c4e-4197-b532-207d145e4ab5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bc149c88-1d20-4eb0-9b5f-1bb60c37b216
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dc9e953c-e592-4c45-8804-49cf93ea0167
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 001563e2-bfa6-48f2-8847-ac7c9c61e212
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c7b6e471-7bdd-4772-a811-a6c1124ece01
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message abec4031-0bc7-491e-a028-479afa937ef4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7e1403ad-8f4f-4287-b9d9-ec861a69f97f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3d6fe33c-6ef4-4919-822a-2cbfe15000c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a7712913-5dd3-414d-b7bd-d2f57b98bc55
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message edcc3607-b55f-4c9b-85d0-d66c8fa2bc0e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d40694c2-54fe-4ef0-b153-814a968cb615
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0fe71567-2e33-4861-810e-8ad5602d75b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ab4bf6db-b1ac-480c-ba8c-93fd09a6eb06
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 908e19fa-227a-48be-8668-abe04301cae1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 36ee446e-05b4-4c12-8610-b3db3adebd18
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 47f75008-b606-4a2c-9c0a-dbbc3eb3349b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f7e17780-5176-4c5c-8e57-190959b6ea9f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bf97d2c2-0f1c-4029-91b8-2c59f3ca0ce3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2d97faf2-0f7f-4e93-9041-26b33b14df4f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3095d1ba-edf9-46b1-87d2-8f23f53830fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3674efab-72f8-4323-993d-3914174a7972
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9a453394-33c2-40b3-ac93-a94c869555cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eb5ee664-bd20-4db9-88da-f0b1cba80d81
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2e282a0e-ebf2-42ff-93c9-c15c380152b1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d8845bcc-3653-4025-8467-e4d6c909d067
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6dce904a-09a0-4e6b-a658-e692ad1c61d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 57473349-0485-4393-aa13-0aafa19d4328
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0d8ec2d4-543d-4f01-88a3-1266de664073
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 593d1b21-2459-459c-bf40-0d7e4853139e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b45d6138-e5fc-4890-8603-4dbc40dee5e6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3a2c625f-a741-4489-9afa-90018c365f1a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7f69fd3d-10b7-4dcc-843f-e5108319a435
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7422b608-733d-4844-b3d3-ccd700a95b86
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dcf0e99a-d4e5-4afe-906d-49fbc7b930d9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 906e1503-6893-4408-9fc5-2124b3ef635c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a0936bec-d1cc-4aa0-8a9e-4f6c63abd939
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dd35f427-1398-4e5e-ad0a-fe2786a60602
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 66668583-ac9b-44e5-b388-065b9001a8f2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9a403c65-11d1-40c5-b577-76a4c10a4655
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 82ba12b7-2627-48be-9b0d-fe589f24d5c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5661e1a2-1f82-4f46-b76a-85787dddefe2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1874deda-be18-44e3-a15e-70ed09bfa93d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 71da71dc-d350-4004-92bf-a7650fae3e97
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message beba715b-6ed5-4617-8998-b834a160aaf9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bb47f3d0-5a4f-4e9d-a38e-34f36a29ddad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ea7af959-1354-4da7-a147-49a46e9225e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b9e59692-2081-4bb9-9c5e-147cd08e10a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 45020a72-1b04-4245-b0d3-bf3d066a9452
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fbffd021-86f3-436f-9f92-46a2ff2d28ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2c9dafb6-86d6-4378-9058-b7ead1ca3913
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ca5da1ed-2cf1-40a9-9c14-264ffaca81dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 99e8ddb5-07ca-4fcd-99bf-f0df9c0a268d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bb0b3286-6c1b-41c0-be8f-2cf81722cca4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9d97198c-e424-4048-994c-c684a87b5b4e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 87331502-a140-47d2-bacd-6bc9df2ba750
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 81bd3077-6f8c-42e5-adfc-439bff5744e0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b607cc25-688b-4c0f-9144-b114f7612749
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 45a2f5de-9106-445a-9cbc-100dbccdfbc0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b362f961-f690-4b93-bc33-e1d514f6b9c7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3d4fe9d5-0da3-4bd9-8e6e-ee2b00ca59a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7125aa42-9b3f-4bd3-a17f-c537ec7ed15f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bf051414-4fe3-4146-bde0-e5dd584dbc3c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 56951d3c-00b3-4b16-b36e-e85d17bed9ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9d0ed4fd-79af-46c7-9b7f-e8191612104d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6ac566b2-e49c-4dbc-890a-f0f07e8fdf56
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6c550f4e-5180-4a8a-beef-40e5bd0f237b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2cb7c718-7083-4251-be55-6395f114ddec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7a01ee76-8967-4fd7-8097-2509512eb1ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 825239a3-7b98-4325-a2cf-fcd166d22815
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b2cb928c-50d2-479f-bf33-f332c9f7b529
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 996b0f97-e876-4834-b0e4-1b6117cf7125
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 937085d4-810f-40a7-a5c4-06d51bb51140
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1c0c68bd-ab74-47aa-bbeb-8ce579f5af6f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 11ce3b8c-ba69-49c3-9489-b51717e24029
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3e036f71-188b-4f79-a8cd-6309e7b6bc45
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 399b15ed-66f0-42d1-88ee-eacbf9d26872
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0359999a-6e7a-4a2c-880c-9fe155e8d1e5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message efd4f8c5-418d-436e-b7cc-ab6f10f712d8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 303000c1-f92c-4b48-abe3-a3e45e724121
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1d166c90-5534-4bb4-9474-65daac5eb746
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fae955ec-1d44-4666-834d-2287d5fc7a71
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b9cf1b51-a1cd-4f54-982d-105d677428c9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0aa0bf8e-2ec6-431d-9f61-67e4b815de2c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bc0013ae-65c9-4952-b4c7-6f7845e2641f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 040f41dd-fd87-4142-b0f0-b8b44d9f56e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 79505900-4ddb-43bc-b069-f9b11ad8d06f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 68998c4c-87f1-48e7-9232-1125e874040f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 971cd442-b32e-43b1-ae1e-e1a245b26bcd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1c1ca1c4-7384-4bce-ad66-b5f3c6dcf8fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 53c2de78-767b-4607-a7ef-852ad5f9b00a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 08395611-db8c-44f3-925f-4453b15be259
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 90a359c7-15ff-45f5-a2e8-39eab5785ef7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 028e3faa-8cc8-4310-a0e7-3684000de743
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9cf196ae-ab70-439e-865b-2040262bc246
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dd146b76-2b21-48c6-89b1-fc2642caa390
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8f7586a5-1514-401b-aafb-d0a43b05f92c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 82a1fd35-f0cb-44bd-aa78-79065324dac0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9fb2cd39-1f67-41e4-bafc-b14b8bb5d8ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 01e9d271-c75d-4e97-b281-c03b5e81c55d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e6f64e7a-d276-4dbd-9913-b73f998ca41f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0956eba3-db45-4fee-a785-7a001dc5d207
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 853df30b-1a19-4e1c-9527-9431ea3cb7e5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dcbf722a-f16e-44a5-9a26-512bb9235359
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 13fa7c34-eb9f-483e-a8fc-351e35439595
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7e736896-e08c-47fa-a1ad-848255a7c0bc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2a7128e4-2945-4894-90ea-1bfb7bd8a48a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5f548f5c-943c-4a93-9276-27b1c06a11c6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 23c8a136-4f7b-49e3-aa57-82b9f698e2a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 850bf44e-2015-4a01-9929-42655d230d2c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 12bb99ed-f152-42b6-910f-eb7d8c195d22
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 42ee31ca-931d-481e-9ede-2b29a4b7105e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fbf0ad68-62d5-4801-b87a-b19839c1e17a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 80f0ad40-4e60-4c4a-a4a7-7497e86bb3e2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dc61d8cc-da0e-4e05-a34e-81d62d034495
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ec875b9e-4d88-4998-a1ec-ad131b4eb27e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 37895d7a-45e3-49ae-bef5-9d5cd2207a6d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 678b248b-17cb-4d88-91bc-640dad94f621
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f4963799-7515-4cd3-a4a1-181ef6c40c8a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 84f3ce0c-774d-4a00-b99c-db2e798dc12e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 649e053d-eab7-4c47-a453-956fa442f0ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f30410a1-72bc-4f7e-a55d-0cbb882abe18
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a506c484-0ad4-48d5-bfd0-eac0e83ac723
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c7c6a055-623b-465a-af63-fe41bb6b2ef4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ea3b469e-32b7-4d8e-9793-65971dc9f0d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 16675374-3b23-4a4e-9d0e-f6bbc793dd5f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9e29570d-cd29-42f4-b4c9-32092dbf14c9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9ada5706-ce61-411c-9795-52526d35b95e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e118ea85-78ac-4f1b-b433-b1b82beb1870
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 295fb24a-f951-4b56-9123-8d5df0f07570
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cfd19969-6ff2-490e-baee-567d8e49fdf3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 532ae42b-8808-4ffa-9d52-d5b9300e85fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7b4b9592-765b-43f0-96c4-e24d93def74c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f87c8e07-4d8a-495b-8c4a-2f5057281790
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8687 {grpc_message:"Socket closed", grpc_status:14}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_49
Server: localhost:8687
Algorithm: FEDAVG
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_49
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_49/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_49/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_49/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_49/test_labels.txt

📊 Raw data loaded:
   Train: X=(2404, 24), y=(2404,)
   Test:  X=(601, 24), y=(601,)

⚠️  Limiting training data: 2404 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  592 samples, 5 features
✅ Client client_49 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

============================================================
🔄 Round 6 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0930 (↓), lr=0.001000
   • Epoch   2/100: train=0.0843, val=0.0929, patience=1/15, lr=0.001000
   • Epoch   3/100: train=0.0839, val=0.0928, patience=2/15, lr=0.001000
   • Epoch   4/100: train=0.0836, val=0.0928, patience=3/15, lr=0.001000
   • Epoch   5/100: train=0.0832, val=0.0927, patience=4/15, lr=0.001000
   📉 Epoch 11: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0799, val=0.0978, patience=10/15, lr=0.000500

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0930)

============================================================
📊 Round 6 Summary - Client client_49
   Epochs: 16/100 (early stopped)
   LR: 0.001000 → 0.000500 (1 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=-0.0028
   Val:   Loss=0.0930, RMSE=0.3050, R²=-0.0573
============================================================


============================================================
🔄 Round 8 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000500
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0878, val=0.0868 (↓), lr=0.000500
   • Epoch   2/100: train=0.0870, val=0.0885, patience=1/15, lr=0.000500
   • Epoch   3/100: train=0.0855, val=0.0885, patience=2/15, lr=0.000500
   • Epoch   4/100: train=0.0850, val=0.0885, patience=3/15, lr=0.000500
   • Epoch   5/100: train=0.0848, val=0.0887, patience=4/15, lr=0.000500
   📉 Epoch 7: LR reduced 0.000500 → 0.000250
   • Epoch  11/100: train=0.0833, val=0.0897, patience=10/15, lr=0.000250
   📉 Epoch 15: LR reduced 0.000250 → 0.000125

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0868)

============================================================
📊 Round 8 Summary - Client client_49
   Epochs: 16/100 (early stopped)
   LR: 0.000500 → 0.000125 (2 reductions)
   Train: Loss=0.0867, RMSE=0.2945, R²=-0.0281
   Val:   Loss=0.0868, RMSE=0.2946, R²=-0.0353
============================================================


📊 Round 8 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2433, R²: -0.0183

============================================================
🔄 Round 11 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000125
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0869, val=0.0946 (↓), lr=0.000125
   ✓ Epoch   2/100: train=0.0862, val=0.0937 (↓), lr=0.000125
   ✓ Epoch   3/100: train=0.0856, val=0.0932 (↓), lr=0.000125
   • Epoch   4/100: train=0.0852, val=0.0930, patience=1/15, lr=0.000125
   • Epoch   5/100: train=0.0850, val=0.0928, patience=2/15, lr=0.000125
   📉 Epoch 7: LR reduced 0.000125 → 0.000063
   • Epoch  11/100: train=0.0843, val=0.0923, patience=4/15, lr=0.000063
   📉 Epoch 15: LR reduced 0.000063 → 0.000031
   • Epoch  21/100: train=0.0839, val=0.0920, patience=1/15, lr=0.000031
   📉 Epoch 23: LR reduced 0.000031 → 0.000016
   📉 Epoch 31: LR reduced 0.000016 → 0.000008
   • Epoch  31/100: train=0.0837, val=0.0919, patience=11/15, lr=0.000008

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0920)

============================================================
📊 Round 11 Summary - Client client_49
   Epochs: 35/100 (early stopped)
   LR: 0.000125 → 0.000008 (4 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=-0.0078
   Val:   Loss=0.0920, RMSE=0.3034, R²=-0.0025
============================================================


📊 Round 11 Test Metrics:
   Loss: 0.0805, RMSE: 0.2838, MAE: 0.2433, R²: -0.0174

📊 Round 11 Test Metrics:
   Loss: 0.0807, RMSE: 0.2841, MAE: 0.2435, R²: -0.0193

============================================================
🔄 Round 14 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000008
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0912, val=0.0786 (↓), lr=0.000008
   • Epoch   2/100: train=0.0911, val=0.0786, patience=1/15, lr=0.000008
   • Epoch   3/100: train=0.0911, val=0.0785, patience=2/15, lr=0.000008
   • Epoch   4/100: train=0.0910, val=0.0784, patience=3/15, lr=0.000008
   • Epoch   5/100: train=0.0909, val=0.0784, patience=4/15, lr=0.000008
   • Epoch  11/100: train=0.0906, val=0.0781, patience=1/15, lr=0.000008
   • Epoch  21/100: train=0.0901, val=0.0775, patience=2/15, lr=0.000008
   • Epoch  31/100: train=0.0897, val=0.0771, patience=12/15, lr=0.000008
   • Epoch  41/100: train=0.0895, val=0.0770, patience=8/15, lr=0.000008

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0771)

============================================================
📊 Round 14 Summary - Client client_49
   Epochs: 48/100 (early stopped)
   LR: 0.000008 → 0.000008 (0 reductions)
   Train: Loss=0.0894, RMSE=0.2990, R²=-0.0239
   Val:   Loss=0.0771, RMSE=0.2777, R²=-0.0346
============================================================


============================================================
🔄 Round 17 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000008
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0893, val=0.0869 (↓), lr=0.000008
   • Epoch   2/100: train=0.0892, val=0.0869, patience=1/15, lr=0.000008
   • Epoch   3/100: train=0.0892, val=0.0869, patience=2/15, lr=0.000008
   • Epoch   4/100: train=0.0891, val=0.0869, patience=3/15, lr=0.000008
   • Epoch   5/100: train=0.0890, val=0.0869, patience=4/15, lr=0.000008
   📉 Epoch 6: LR reduced 0.000008 → 0.000004
   • Epoch  11/100: train=0.0887, val=0.0869, patience=10/15, lr=0.000004
   📉 Epoch 14: LR reduced 0.000004 → 0.000002

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 17 Summary - Client client_49
   Epochs: 16/100 (early stopped)
   LR: 0.000008 → 0.000002 (2 reductions)
   Train: Loss=0.0893, RMSE=0.2988, R²=-0.0515
   Val:   Loss=0.0869, RMSE=0.2947, R²=-0.0375
============================================================


📊 Round 17 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2440, R²: -0.0246

============================================================
🔄 Round 19 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000002
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0884, val=0.0918 (↓), lr=0.000002
   • Epoch   2/100: train=0.0883, val=0.0919, patience=1/15, lr=0.000002
   • Epoch   3/100: train=0.0883, val=0.0919, patience=2/15, lr=0.000002
   • Epoch   4/100: train=0.0883, val=0.0919, patience=3/15, lr=0.000002
   • Epoch   5/100: train=0.0883, val=0.0919, patience=4/15, lr=0.000002
   📉 Epoch 6: LR reduced 0.000002 → 0.000001
   • Epoch  11/100: train=0.0881, val=0.0920, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0918)

============================================================
📊 Round 19 Summary - Client client_49
   Epochs: 16/100 (early stopped)
   LR: 0.000002 → 0.000001 (1 reductions)
   Train: Loss=0.0880, RMSE=0.2967, R²=-0.0474
   Val:   Loss=0.0918, RMSE=0.3031, R²=-0.0651
============================================================


📊 Round 19 Test Metrics:
   Loss: 0.0811, RMSE: 0.2848, MAE: 0.2440, R²: -0.0248

📊 Round 19 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2442, R²: -0.0271

============================================================
🔄 Round 23 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0880, val=0.0948 (↓), lr=0.000001
   • Epoch   2/100: train=0.0880, val=0.0948, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0880, val=0.0948, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0880, val=0.0948, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0880, val=0.0948, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0879, val=0.0948, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0948)

============================================================
📊 Round 23 Summary - Client client_49
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0876, RMSE=0.2959, R²=-0.0380
   Val:   Loss=0.0948, RMSE=0.3080, R²=-0.0972
============================================================


📊 Round 23 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2442, R²: -0.0271

============================================================
🔄 Round 24 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0886, val=0.0914 (↓), lr=0.000001
   • Epoch   2/100: train=0.0886, val=0.0914, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0886, val=0.0914, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0886, val=0.0914, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0886, val=0.0913, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0885, val=0.0913, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0914)

============================================================
📊 Round 24 Summary - Client client_49
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0885, RMSE=0.2974, R²=-0.0412
   Val:   Loss=0.0914, RMSE=0.3023, R²=-0.0966
============================================================


📊 Round 24 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2442, R²: -0.0272

📊 Round 24 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2442, R²: -0.0272

============================================================
🔄 Round 28 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0913, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0913, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0913, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0913, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0913, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0912, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 28 Summary - Client client_49
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0913, RMSE=0.3022, R²=-0.0469
   Val:   Loss=0.0798, RMSE=0.2825, R²=-0.0735
============================================================


📊 Round 28 Test Metrics:
   Loss: 0.0813, RMSE: 0.2852, MAE: 0.2442, R²: -0.0272

============================================================
🔄 Round 29 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0900, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0899, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0899, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0899, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0899, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0899, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 29 Summary - Client client_49
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0898, RMSE=0.2996, R²=-0.0523
   Val:   Loss=0.0860, RMSE=0.2933, R²=-0.0516
============================================================


============================================================
🔄 Round 30 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0903, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0903, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0903, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0903, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0903, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0902, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 30 Summary - Client client_49
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0904, RMSE=0.3006, R²=-0.0540
   Val:   Loss=0.0837, RMSE=0.2893, R²=-0.0631
============================================================


📊 Round 30 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2442, R²: -0.0272

📊 Round 30 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2442, R²: -0.0272

📊 Round 30 Test Metrics:
   Loss: 0.0813, RMSE: 0.2851, MAE: 0.2442, R²: -0.0272

============================================================
🔄 Round 36 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0880, val=0.0920 (↓), lr=0.000001
   • Epoch   2/100: train=0.0880, val=0.0920, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0880, val=0.0920, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0880, val=0.0920, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0880, val=0.0920, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0879, val=0.0919, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0920)

============================================================
📊 Round 36 Summary - Client client_49
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0883, RMSE=0.2972, R²=-0.0417
   Val:   Loss=0.0920, RMSE=0.3033, R²=-0.0840
============================================================


📊 Round 36 Test Metrics:
   Loss: 0.0813, RMSE: 0.2852, MAE: 0.2442, R²: -0.0272

📊 Round 36 Test Metrics:
   Loss: 0.0813, RMSE: 0.2852, MAE: 0.2442, R²: -0.0272

📊 Round 36 Test Metrics:
   Loss: 0.0813, RMSE: 0.2852, MAE: 0.2442, R²: -0.0272

============================================================
🔄 Round 42 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0876, val=0.0949 (↓), lr=0.000001
   • Epoch   2/100: train=0.0876, val=0.0949, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0876, val=0.0949, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0875, val=0.0949, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0875, val=0.0949, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0875, val=0.0949, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0949)

============================================================
📊 Round 42 Summary - Client client_49
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0876, RMSE=0.2959, R²=-0.0513
   Val:   Loss=0.0949, RMSE=0.3081, R²=-0.0653
============================================================


📊 Round 42 Test Metrics:
   Loss: 0.0813, RMSE: 0.2852, MAE: 0.2442, R²: -0.0272

============================================================
🔄 Round 43 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0891, val=0.0885 (↓), lr=0.000001
   • Epoch   2/100: train=0.0891, val=0.0885, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0891, val=0.0885, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0891, val=0.0885, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0891, val=0.0885, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0890, val=0.0885, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0885)

============================================================
📊 Round 43 Summary - Client client_49
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0892, RMSE=0.2986, R²=-0.0494
   Val:   Loss=0.0885, RMSE=0.2975, R²=-0.0529
============================================================


📊 Round 43 Test Metrics:
   Loss: 0.0813, RMSE: 0.2852, MAE: 0.2442, R²: -0.0272

📊 Round 43 Test Metrics:
   Loss: 0.0813, RMSE: 0.2852, MAE: 0.2442, R²: -0.0272

============================================================
🔄 Round 51 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0910, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0910, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0910, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0910, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0910, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0909, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 51 Summary - Client client_49
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0909, RMSE=0.3015, R²=-0.0536
   Val:   Loss=0.0815, RMSE=0.2855, R²=-0.0372
============================================================


📊 Round 51 Test Metrics:
   Loss: 0.0813, RMSE: 0.2852, MAE: 0.2442, R²: -0.0273

============================================================
🔄 Round 53 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0878, val=0.0944 (↓), lr=0.000001
   • Epoch   2/100: train=0.0877, val=0.0944, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0877, val=0.0944, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0877, val=0.0944, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0877, val=0.0944, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0877, val=0.0944, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0944)

============================================================
📊 Round 53 Summary - Client client_49
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0877, RMSE=0.2961, R²=-0.0518
   Val:   Loss=0.0944, RMSE=0.3073, R²=-0.0438
============================================================


============================================================
🔄 Round 55 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0901, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0901, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0901, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0900, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0900, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0900, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 55 Summary - Client client_49
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0900, RMSE=0.3000, R²=-0.0442
   Val:   Loss=0.0853, RMSE=0.2920, R²=-0.0837
============================================================


📊 Round 55 Test Metrics:
   Loss: 0.0813, RMSE: 0.2852, MAE: 0.2442, R²: -0.0273

📊 Round 55 Test Metrics:
   Loss: 0.0813, RMSE: 0.2852, MAE: 0.2442, R²: -0.0273

============================================================
🔄 Round 57 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0871, val=0.0967 (↓), lr=0.000001
   • Epoch   2/100: train=0.0871, val=0.0967, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0871, val=0.0967, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0871, val=0.0967, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0871, val=0.0967, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0870, val=0.0966, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0967)

============================================================
📊 Round 57 Summary - Client client_49
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0871, RMSE=0.2952, R²=-0.0463
   Val:   Loss=0.0967, RMSE=0.3109, R²=-0.0675
============================================================


📊 Round 57 Test Metrics:
   Loss: 0.0813, RMSE: 0.2852, MAE: 0.2442, R²: -0.0273

============================================================
🔄 Round 60 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0879, val=0.0935 (↓), lr=0.000001
   • Epoch   2/100: train=0.0879, val=0.0935, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0879, val=0.0935, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0879, val=0.0935, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0879, val=0.0935, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0879, val=0.0935, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0935)

============================================================
📊 Round 60 Summary - Client client_49
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0879, RMSE=0.2965, R²=-0.0565
   Val:   Loss=0.0935, RMSE=0.3058, R²=-0.0290
============================================================


📊 Round 60 Test Metrics:
   Loss: 0.0813, RMSE: 0.2852, MAE: 0.2442, R²: -0.0273

============================================================
🔄 Round 61 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0910, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0910, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0909, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0909, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0909, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0909, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 61 Summary - Client client_49
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0911, RMSE=0.3019, R²=-0.0556
   Val:   Loss=0.0806, RMSE=0.2839, R²=-0.0304
============================================================


📊 Round 61 Test Metrics:
   Loss: 0.0813, RMSE: 0.2852, MAE: 0.2442, R²: -0.0273

============================================================
🔄 Round 62 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0875, val=0.0943 (↓), lr=0.000001
   • Epoch   2/100: train=0.0875, val=0.0943, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0875, val=0.0943, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0875, val=0.0943, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0875, val=0.0943, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0874, val=0.0942, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0943)

============================================================
📊 Round 62 Summary - Client client_49
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0877, RMSE=0.2962, R²=-0.0516
   Val:   Loss=0.0943, RMSE=0.3071, R²=-0.0456
============================================================


📊 Round 62 Test Metrics:
   Loss: 0.0813, RMSE: 0.2852, MAE: 0.2442, R²: -0.0273

============================================================
🔄 Round 64 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0887, val=0.0900 (↓), lr=0.000001
   • Epoch   2/100: train=0.0887, val=0.0900, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0887, val=0.0900, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0887, val=0.0900, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0886, val=0.0900, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0886, val=0.0900, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0900)

============================================================
📊 Round 64 Summary - Client client_49
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0888, RMSE=0.2980, R²=-0.0461
   Val:   Loss=0.0900, RMSE=0.3000, R²=-0.0734
============================================================


============================================================
🔄 Round 66 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0909, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0909, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0909, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0909, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0909, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0909, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 66 Summary - Client client_49
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0909, RMSE=0.3015, R²=-0.0517
   Val:   Loss=0.0816, RMSE=0.2857, R²=-0.0668
============================================================


============================================================
🔄 Round 67 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0894, val=0.0877 (↓), lr=0.000001
   • Epoch   2/100: train=0.0894, val=0.0877, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0894, val=0.0877, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0894, val=0.0877, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0894, val=0.0877, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0894, val=0.0877, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0877)

============================================================
📊 Round 67 Summary - Client client_49
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0894, RMSE=0.2989, R²=-0.0471
   Val:   Loss=0.0877, RMSE=0.2962, R²=-0.0642
============================================================


📊 Round 67 Test Metrics:
   Loss: 0.0813, RMSE: 0.2852, MAE: 0.2442, R²: -0.0273

📊 Round 67 Test Metrics:
   Loss: 0.0813, RMSE: 0.2852, MAE: 0.2442, R²: -0.0273

============================================================
🔄 Round 70 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0889, val=0.0896 (↓), lr=0.000001
   • Epoch   2/100: train=0.0889, val=0.0896, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0889, val=0.0896, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0889, val=0.0896, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0889, val=0.0896, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0888, val=0.0897, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0896)

============================================================
📊 Round 70 Summary - Client client_49
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0889, RMSE=0.2981, R²=-0.0461
   Val:   Loss=0.0896, RMSE=0.2994, R²=-0.0748
============================================================


============================================================
🔄 Round 72 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0882, val=0.0926 (↓), lr=0.000001
   • Epoch   2/100: train=0.0882, val=0.0926, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0882, val=0.0926, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0882, val=0.0926, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0881, val=0.0926, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0881, val=0.0926, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0926)

============================================================
📊 Round 72 Summary - Client client_49
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0881, RMSE=0.2969, R²=-0.0453
   Val:   Loss=0.0926, RMSE=0.3043, R²=-0.0713
============================================================


============================================================
🔄 Round 73 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0909, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0908, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0908, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0908, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0908, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0908, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 73 Summary - Client client_49
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0907, RMSE=0.3012, R²=-0.0574
   Val:   Loss=0.0823, RMSE=0.2868, R²=-0.0240
============================================================


============================================================
🔄 Round 75 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0901, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0901, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0901, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0901, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0900, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0900, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 75 Summary - Client client_49
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0900, RMSE=0.3000, R²=-0.0525
   Val:   Loss=0.0852, RMSE=0.2919, R²=-0.0407
============================================================


📊 Round 75 Test Metrics:
   Loss: 0.0813, RMSE: 0.2852, MAE: 0.2442, R²: -0.0274

============================================================
🔄 Round 76 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0871, val=0.0964 (↓), lr=0.000001
   • Epoch   2/100: train=0.0871, val=0.0964, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0871, val=0.0964, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0870, val=0.0964, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0870, val=0.0964, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0870, val=0.0964, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0964)

============================================================
📊 Round 76 Summary - Client client_49
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0872, RMSE=0.2953, R²=-0.0459
   Val:   Loss=0.0964, RMSE=0.3105, R²=-0.0684
============================================================


============================================================
🔄 Round 77 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0899, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0899, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0899, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0899, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0899, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0899, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 77 Summary - Client client_49
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0899, RMSE=0.2998, R²=-0.0480
   Val:   Loss=0.0857, RMSE=0.2928, R²=-0.0630
============================================================


============================================================
🔄 Round 80 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0882, val=0.0920 (↓), lr=0.000001
   • Epoch   2/100: train=0.0882, val=0.0920, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0882, val=0.0920, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0882, val=0.0920, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0882, val=0.0920, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0881, val=0.0920, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0920)

============================================================
📊 Round 80 Summary - Client client_49
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0883, RMSE=0.2971, R²=-0.0485
   Val:   Loss=0.0920, RMSE=0.3034, R²=-0.0562
============================================================


============================================================
🔄 Round 81 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0895, val=0.0876 (↓), lr=0.000001
   • Epoch   2/100: train=0.0894, val=0.0876, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0894, val=0.0876, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0894, val=0.0875, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0894, val=0.0875, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0894, val=0.0875, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0876)

============================================================
📊 Round 81 Summary - Client client_49
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0894, RMSE=0.2990, R²=-0.0429
   Val:   Loss=0.0876, RMSE=0.2959, R²=-0.0857
============================================================


📊 Round 81 Test Metrics:
   Loss: 0.0813, RMSE: 0.2852, MAE: 0.2442, R²: -0.0273

============================================================
🔄 Round 82 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0879, val=0.0936 (↓), lr=0.000001
   • Epoch   2/100: train=0.0879, val=0.0936, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0879, val=0.0936, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0879, val=0.0936, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0878, val=0.0936, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0878, val=0.0936, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0936)

============================================================
📊 Round 82 Summary - Client client_49
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0879, RMSE=0.2965, R²=-0.0473
   Val:   Loss=0.0936, RMSE=0.3059, R²=-0.0771
============================================================


📊 Round 82 Test Metrics:
   Loss: 0.0813, RMSE: 0.2852, MAE: 0.2442, R²: -0.0274

📊 Round 82 Test Metrics:
   Loss: 0.0813, RMSE: 0.2852, MAE: 0.2442, R²: -0.0274

============================================================
🔄 Round 86 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0890, val=0.0886 (↓), lr=0.000001
   • Epoch   2/100: train=0.0890, val=0.0886, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0890, val=0.0886, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0890, val=0.0886, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0890, val=0.0886, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0890, val=0.0886, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0886)

============================================================
📊 Round 86 Summary - Client client_49
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0891, RMSE=0.2985, R²=-0.0539
   Val:   Loss=0.0886, RMSE=0.2976, R²=-0.0552
============================================================


📊 Round 86 Test Metrics:
   Loss: 0.0813, RMSE: 0.2852, MAE: 0.2442, R²: -0.0274

📊 Round 86 Test Metrics:
   Loss: 0.0813, RMSE: 0.2852, MAE: 0.2442, R²: -0.0274

📊 Round 86 Test Metrics:
   Loss: 0.0813, RMSE: 0.2852, MAE: 0.2442, R²: -0.0274

============================================================
🔄 Round 92 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0869, val=0.0976 (↓), lr=0.000001
   • Epoch   2/100: train=0.0869, val=0.0976, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0869, val=0.0975, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0869, val=0.0975, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0869, val=0.0975, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0869, val=0.0975, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0976)

============================================================
📊 Round 92 Summary - Client client_49
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0869, RMSE=0.2948, R²=-0.0461
   Val:   Loss=0.0976, RMSE=0.3123, R²=-0.0656
============================================================


📊 Round 92 Test Metrics:
   Loss: 0.0813, RMSE: 0.2852, MAE: 0.2442, R²: -0.0274

📊 Round 92 Test Metrics:
   Loss: 0.0813, RMSE: 0.2852, MAE: 0.2442, R²: -0.0274

============================================================
🔄 Round 96 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0907, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0907, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0906, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0906, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0906, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0906, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 96 Summary - Client client_49
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0906, RMSE=0.3010, R²=-0.0572
   Val:   Loss=0.0826, RMSE=0.2875, R²=-0.0348
============================================================


📊 Round 96 Test Metrics:
   Loss: 0.0813, RMSE: 0.2852, MAE: 0.2442, R²: -0.0274

============================================================
🔄 Round 97 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0900, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0900, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0900, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0900, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0900, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0899, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 97 Summary - Client client_49
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0902, RMSE=0.3004, R²=-0.0638
   Val:   Loss=0.0841, RMSE=0.2900, R²=0.0056
============================================================


============================================================
🔄 Round 98 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0895, val=0.0885 (↓), lr=0.000001
   • Epoch   2/100: train=0.0895, val=0.0885, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0894, val=0.0885, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0894, val=0.0885, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0894, val=0.0885, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0894, val=0.0885, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0885)

============================================================
📊 Round 98 Summary - Client client_49
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0891, RMSE=0.2986, R²=-0.0529
   Val:   Loss=0.0885, RMSE=0.2975, R²=-0.0383
============================================================


============================================================
🔄 Round 99 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0905, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0904, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0904, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0904, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0904, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0904, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 99 Summary - Client client_49
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0902, RMSE=0.3003, R²=-0.0481
   Val:   Loss=0.0843, RMSE=0.2903, R²=-0.0897
============================================================


📊 Round 99 Test Metrics:
   Loss: 0.0813, RMSE: 0.2852, MAE: 0.2442, R²: -0.0274

📊 Round 99 Test Metrics:
   Loss: 0.0813, RMSE: 0.2852, MAE: 0.2442, R²: -0.0274

============================================================
🔄 Round 105 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0869, val=0.0974 (↓), lr=0.000001
   • Epoch   2/100: train=0.0869, val=0.0974, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0869, val=0.0974, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0869, val=0.0974, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0869, val=0.0974, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0868, val=0.0974, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0974)

============================================================
📊 Round 105 Summary - Client client_49
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0869, RMSE=0.2948, R²=-0.0487
   Val:   Loss=0.0974, RMSE=0.3122, R²=-0.0594
============================================================


============================================================
🔄 Round 106 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0916, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0915, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0915, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0915, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0915, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0915, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 106 Summary - Client client_49
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0914, RMSE=0.3023, R²=-0.0465
   Val:   Loss=0.0796, RMSE=0.2821, R²=-0.0665
============================================================


============================================================
🔄 Round 108 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0879, val=0.0926 (↓), lr=0.000001
   • Epoch   2/100: train=0.0879, val=0.0926, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0879, val=0.0926, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0879, val=0.0926, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0879, val=0.0926, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0879, val=0.0926, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0926)

============================================================
📊 Round 108 Summary - Client client_49
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0881, RMSE=0.2969, R²=-0.0507
   Val:   Loss=0.0926, RMSE=0.3043, R²=-0.0519
============================================================


📊 Round 108 Test Metrics:
   Loss: 0.0813, RMSE: 0.2852, MAE: 0.2442, R²: -0.0274

📊 Round 108 Test Metrics:
   Loss: 0.0813, RMSE: 0.2852, MAE: 0.2442, R²: -0.0274

============================================================
🔄 Round 110 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0871, val=0.0973 (↓), lr=0.000001
   • Epoch   2/100: train=0.0871, val=0.0973, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0871, val=0.0973, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0871, val=0.0973, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0871, val=0.0973, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0870, val=0.0973, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0973)

============================================================
📊 Round 110 Summary - Client client_49
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0869, RMSE=0.2949, R²=-0.0545
   Val:   Loss=0.0973, RMSE=0.3120, R²=-0.0414
============================================================


📊 Round 110 Test Metrics:
   Loss: 0.0813, RMSE: 0.2852, MAE: 0.2442, R²: -0.0274

============================================================
🔄 Round 113 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0883, val=0.0922 (↓), lr=0.000001
   • Epoch   2/100: train=0.0883, val=0.0922, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0883, val=0.0922, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0883, val=0.0922, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0883, val=0.0922, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0882, val=0.0922, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0922)

============================================================
📊 Round 113 Summary - Client client_49
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0882, RMSE=0.2970, R²=-0.0438
   Val:   Loss=0.0922, RMSE=0.3036, R²=-0.0792
============================================================


📊 Round 113 Test Metrics:
   Loss: 0.0813, RMSE: 0.2852, MAE: 0.2442, R²: -0.0275

============================================================
🔄 Round 115 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0875, val=0.0950 (↓), lr=0.000001
   • Epoch   2/100: train=0.0875, val=0.0950, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0875, val=0.0950, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0875, val=0.0950, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0875, val=0.0950, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0875, val=0.0949, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0950)

============================================================
📊 Round 115 Summary - Client client_49
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0875, RMSE=0.2959, R²=-0.0487
   Val:   Loss=0.0950, RMSE=0.3082, R²=-0.0555
============================================================


📊 Round 115 Test Metrics:
   Loss: 0.0813, RMSE: 0.2852, MAE: 0.2442, R²: -0.0275

============================================================
🔄 Round 116 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0913, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0912, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0912, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0912, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0912, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0912, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 116 Summary - Client client_49
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0915, RMSE=0.3025, R²=-0.0563
   Val:   Loss=0.0792, RMSE=0.2813, R²=-0.0217
============================================================


📊 Round 116 Test Metrics:
   Loss: 0.0813, RMSE: 0.2852, MAE: 0.2442, R²: -0.0275

📊 Round 116 Test Metrics:
   Loss: 0.0813, RMSE: 0.2852, MAE: 0.2442, R²: -0.0275

📊 Round 116 Test Metrics:
   Loss: 0.0813, RMSE: 0.2852, MAE: 0.2442, R²: -0.0275

============================================================
🔄 Round 121 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0901, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0901, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0901, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0901, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0901, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0901, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 121 Summary - Client client_49
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0903, RMSE=0.3005, R²=-0.0473
   Val:   Loss=0.0839, RMSE=0.2897, R²=-0.0682
============================================================


============================================================
🔄 Round 124 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0893, val=0.0884 (↓), lr=0.000001
   • Epoch   2/100: train=0.0893, val=0.0884, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0893, val=0.0884, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0893, val=0.0884, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0893, val=0.0884, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0892, val=0.0884, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0884)

============================================================
📊 Round 124 Summary - Client client_49
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0892, RMSE=0.2986, R²=-0.0526
   Val:   Loss=0.0884, RMSE=0.2974, R²=-0.0394
============================================================


📊 Round 124 Test Metrics:
   Loss: 0.0813, RMSE: 0.2852, MAE: 0.2442, R²: -0.0275

============================================================
🔄 Round 127 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0909, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0909, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0909, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0908, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0908, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0908, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 127 Summary - Client client_49
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0909, RMSE=0.3016, R²=-0.0553
   Val:   Loss=0.0813, RMSE=0.2851, R²=-0.0544
============================================================


============================================================
🔄 Round 128 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0894, val=0.0875 (↓), lr=0.000001
   • Epoch   2/100: train=0.0894, val=0.0875, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0894, val=0.0874, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0894, val=0.0874, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0894, val=0.0874, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0893, val=0.0874, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0875)

============================================================
📊 Round 128 Summary - Client client_49
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0894, RMSE=0.2990, R²=-0.0491
   Val:   Loss=0.0875, RMSE=0.2957, R²=-0.0534
============================================================


📊 Round 128 Test Metrics:
   Loss: 0.0813, RMSE: 0.2852, MAE: 0.2442, R²: -0.0275

============================================================
🔄 Round 130 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0901, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0901, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0900, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0900, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0900, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0900, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 130 Summary - Client client_49
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0903, RMSE=0.3005, R²=-0.0576
   Val:   Loss=0.0838, RMSE=0.2895, R²=-0.0191
============================================================


📊 Round 130 Test Metrics:
   Loss: 0.0813, RMSE: 0.2852, MAE: 0.2442, R²: -0.0276

============================================================
🔄 Round 131 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0896, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0896, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0896, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0896, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0895, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0895, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 131 Summary - Client client_49
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0898, RMSE=0.2997, R²=-0.0523
   Val:   Loss=0.0858, RMSE=0.2930, R²=-0.0496
============================================================


📊 Round 131 Test Metrics:
   Loss: 0.0813, RMSE: 0.2852, MAE: 0.2442, R²: -0.0276

============================================================
🔄 Round 133 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0872, val=0.0964 (↓), lr=0.000001
   • Epoch   2/100: train=0.0872, val=0.0964, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0872, val=0.0964, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0872, val=0.0964, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0872, val=0.0964, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0872, val=0.0964, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0964)

============================================================
📊 Round 133 Summary - Client client_49
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0872, RMSE=0.2953, R²=-0.0379
   Val:   Loss=0.0964, RMSE=0.3105, R²=-0.0969
============================================================


📊 Round 133 Test Metrics:
   Loss: 0.0813, RMSE: 0.2852, MAE: 0.2442, R²: -0.0276

============================================================
🔄 Round 134 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0879, val=0.0936 (↓), lr=0.000001
   • Epoch   2/100: train=0.0879, val=0.0936, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0879, val=0.0936, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0879, val=0.0936, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0878, val=0.0936, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0878, val=0.0936, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0936)

============================================================
📊 Round 134 Summary - Client client_49
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0879, RMSE=0.2965, R²=-0.0552
   Val:   Loss=0.0936, RMSE=0.3059, R²=-0.0455
============================================================


============================================================
🔄 Round 137 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0883, val=0.0918 (↓), lr=0.000001
   • Epoch   2/100: train=0.0883, val=0.0918, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0883, val=0.0918, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0882, val=0.0918, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0882, val=0.0918, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0881, val=0.0919, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0918)

============================================================
📊 Round 137 Summary - Client client_49
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0883, RMSE=0.2972, R²=-0.0562
   Val:   Loss=0.0918, RMSE=0.3030, R²=-0.0517
============================================================


📊 Round 137 Test Metrics:
   Loss: 0.0813, RMSE: 0.2852, MAE: 0.2443, R²: -0.0276

============================================================
🔄 Round 138 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0899, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0899, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0899, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0898, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0898, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0898, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 138 Summary - Client client_49
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0899, RMSE=0.2999, R²=-0.0310
   Val:   Loss=0.0854, RMSE=0.2923, R²=-0.1495
============================================================


📊 Round 138 Test Metrics:
   Loss: 0.0813, RMSE: 0.2852, MAE: 0.2443, R²: -0.0276

📊 Round 138 Test Metrics:
   Loss: 0.0813, RMSE: 0.2852, MAE: 0.2443, R²: -0.0276

============================================================
🔄 Round 140 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0878, val=0.0932 (↓), lr=0.000001
   • Epoch   2/100: train=0.0878, val=0.0932, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0878, val=0.0932, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0878, val=0.0933, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0878, val=0.0933, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0877, val=0.0933, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0932)

============================================================
📊 Round 140 Summary - Client client_49
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0880, RMSE=0.2966, R²=-0.0510
   Val:   Loss=0.0932, RMSE=0.3054, R²=-0.0595
============================================================


============================================================
🔄 Round 141 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0896, val=0.0863 (↓), lr=0.000001
   • Epoch   2/100: train=0.0896, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0896, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0896, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0896, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0895, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 141 Summary - Client client_49
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0897, RMSE=0.2995, R²=-0.0507
   Val:   Loss=0.0863, RMSE=0.2937, R²=-0.0598
============================================================


📊 Round 141 Test Metrics:
   Loss: 0.0813, RMSE: 0.2852, MAE: 0.2443, R²: -0.0276

============================================================
🔄 Round 142 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0917, val=0.0771 (↓), lr=0.000001
   • Epoch   2/100: train=0.0917, val=0.0771, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0917, val=0.0771, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0916, val=0.0771, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0916, val=0.0771, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0916, val=0.0771, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0771)

============================================================
📊 Round 142 Summary - Client client_49
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0920, RMSE=0.3033, R²=-0.0523
   Val:   Loss=0.0771, RMSE=0.2777, R²=-0.0438
============================================================


============================================================
🔄 Round 143 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0874, val=0.0948 (↓), lr=0.000001
   • Epoch   2/100: train=0.0874, val=0.0948, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0874, val=0.0948, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0874, val=0.0948, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0874, val=0.0948, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0874, val=0.0948, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0948)

============================================================
📊 Round 143 Summary - Client client_49
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0876, RMSE=0.2959, R²=-0.0533
   Val:   Loss=0.0948, RMSE=0.3079, R²=-0.0401
============================================================


📊 Round 143 Test Metrics:
   Loss: 0.0813, RMSE: 0.2852, MAE: 0.2442, R²: -0.0276

📊 Round 143 Test Metrics:
   Loss: 0.0813, RMSE: 0.2852, MAE: 0.2442, R²: -0.0276

============================================================
🔄 Round 146 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0910, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0910, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0910, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0910, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0910, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0909, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 146 Summary - Client client_49
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0908, RMSE=0.3013, R²=-0.0596
   Val:   Loss=0.0819, RMSE=0.2862, R²=-0.0113
============================================================


📊 Round 146 Test Metrics:
   Loss: 0.0813, RMSE: 0.2852, MAE: 0.2443, R²: -0.0276

============================================================
🔄 Round 152 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0894, val=0.0881 (↓), lr=0.000001
   • Epoch   2/100: train=0.0894, val=0.0881, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0894, val=0.0881, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0894, val=0.0881, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0894, val=0.0881, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0894, val=0.0880, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0881)

============================================================
📊 Round 152 Summary - Client client_49
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0892, RMSE=0.2987, R²=-0.0391
   Val:   Loss=0.0881, RMSE=0.2968, R²=-0.1055
============================================================


📊 Round 152 Test Metrics:
   Loss: 0.0813, RMSE: 0.2852, MAE: 0.2443, R²: -0.0276

============================================================
🔄 Round 154 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0883, val=0.0915 (↓), lr=0.000001
   • Epoch   2/100: train=0.0883, val=0.0915, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0883, val=0.0915, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0883, val=0.0915, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0883, val=0.0915, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0882, val=0.0915, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0915)

============================================================
📊 Round 154 Summary - Client client_49
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0884, RMSE=0.2973, R²=-0.0428
   Val:   Loss=0.0915, RMSE=0.3025, R²=-0.0897
============================================================


📊 Round 154 Test Metrics:
   Loss: 0.0813, RMSE: 0.2852, MAE: 0.2443, R²: -0.0276

============================================================
🔄 Round 155 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0872, val=0.0960 (↓), lr=0.000001
   • Epoch   2/100: train=0.0872, val=0.0960, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0871, val=0.0960, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0871, val=0.0960, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0871, val=0.0960, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0871, val=0.0959, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0960)

============================================================
📊 Round 155 Summary - Client client_49
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0873, RMSE=0.2954, R²=-0.0458
   Val:   Loss=0.0960, RMSE=0.3098, R²=-0.0694
============================================================


📊 Round 155 Test Metrics:
   Loss: 0.0813, RMSE: 0.2852, MAE: 0.2443, R²: -0.0276

📊 Round 155 Test Metrics:
   Loss: 0.0813, RMSE: 0.2852, MAE: 0.2443, R²: -0.0276

📊 Round 155 Test Metrics:
   Loss: 0.0813, RMSE: 0.2852, MAE: 0.2443, R²: -0.0276

============================================================
🔄 Round 160 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0898, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0898, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0898, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0898, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0898, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0897, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 160 Summary - Client client_49
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0897, RMSE=0.2996, R²=-0.0587
   Val:   Loss=0.0861, RMSE=0.2935, R²=-0.0152
============================================================


📊 Round 160 Test Metrics:
   Loss: 0.0813, RMSE: 0.2852, MAE: 0.2443, R²: -0.0276

============================================================
🔄 Round 162 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0899, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0899, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0899, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0899, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0898, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0898, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 162 Summary - Client client_49
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0898, RMSE=0.2997, R²=-0.0521
   Val:   Loss=0.0858, RMSE=0.2930, R²=-0.0407
============================================================


📊 Round 162 Test Metrics:
   Loss: 0.0813, RMSE: 0.2852, MAE: 0.2443, R²: -0.0276

============================================================
🔄 Round 165 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0883, val=0.0923 (↓), lr=0.000001
   • Epoch   2/100: train=0.0883, val=0.0923, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0883, val=0.0923, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0883, val=0.0923, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0883, val=0.0923, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0882, val=0.0923, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0923)

============================================================
📊 Round 165 Summary - Client client_49
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0882, RMSE=0.2970, R²=-0.0501
   Val:   Loss=0.0923, RMSE=0.3038, R²=-0.0496
============================================================


📊 Round 165 Test Metrics:
   Loss: 0.0813, RMSE: 0.2852, MAE: 0.2443, R²: -0.0277

============================================================
🔄 Round 167 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0906, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0906, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0906, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0906, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0905, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0905, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 167 Summary - Client client_49
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0905, RMSE=0.3009, R²=-0.0538
   Val:   Loss=0.0829, RMSE=0.2880, R²=-0.0603
============================================================


📊 Round 167 Test Metrics:
   Loss: 0.0813, RMSE: 0.2852, MAE: 0.2443, R²: -0.0277

============================================================
🔄 Round 170 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0910, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0910, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0910, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0910, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0910, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0910, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 170 Summary - Client client_49
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0907, RMSE=0.3012, R²=-0.0408
   Val:   Loss=0.0821, RMSE=0.2865, R²=-0.0938
============================================================


📊 Round 170 Test Metrics:
   Loss: 0.0813, RMSE: 0.2852, MAE: 0.2443, R²: -0.0277

📊 Round 170 Test Metrics:
   Loss: 0.0813, RMSE: 0.2852, MAE: 0.2443, R²: -0.0277

============================================================
🔄 Round 176 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0871, val=0.0974 (↓), lr=0.000001
   • Epoch   2/100: train=0.0871, val=0.0974, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0871, val=0.0974, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0871, val=0.0974, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0871, val=0.0974, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0870, val=0.0974, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0974)

============================================================
📊 Round 176 Summary - Client client_49
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0869, RMSE=0.2948, R²=-0.0471
   Val:   Loss=0.0974, RMSE=0.3120, R²=-0.0799
============================================================


============================================================
🔄 Round 177 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0889, val=0.0894 (↓), lr=0.000001
   • Epoch   2/100: train=0.0889, val=0.0894, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0889, val=0.0893, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0889, val=0.0893, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0889, val=0.0893, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0889, val=0.0893, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0894)

============================================================
📊 Round 177 Summary - Client client_49
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0889, RMSE=0.2982, R²=-0.0474
   Val:   Loss=0.0894, RMSE=0.2989, R²=-0.0619
============================================================


============================================================
🔄 Round 182 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0918, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0918, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0918, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0918, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0918, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0917, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 182 Summary - Client client_49
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0916, RMSE=0.3026, R²=-0.0555
   Val:   Loss=0.0788, RMSE=0.2808, R²=-0.0357
============================================================


📊 Round 182 Test Metrics:
   Loss: 0.0814, RMSE: 0.2852, MAE: 0.2443, R²: -0.0277

============================================================
🔄 Round 183 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0895, val=0.0883 (↓), lr=0.000001
   • Epoch   2/100: train=0.0895, val=0.0883, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0895, val=0.0883, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0895, val=0.0883, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0895, val=0.0883, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0895, val=0.0883, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0883)

============================================================
📊 Round 183 Summary - Client client_49
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0892, RMSE=0.2986, R²=-0.0494
   Val:   Loss=0.0883, RMSE=0.2972, R²=-0.0521
============================================================


============================================================
🔄 Round 184 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0886, val=0.0905 (↓), lr=0.000001
   • Epoch   2/100: train=0.0886, val=0.0904, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0886, val=0.0904, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0886, val=0.0904, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0886, val=0.0904, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0885, val=0.0904, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0905)

============================================================
📊 Round 184 Summary - Client client_49
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0887, RMSE=0.2978, R²=-0.0503
   Val:   Loss=0.0905, RMSE=0.3007, R²=-0.0503
============================================================


============================================================
🔄 Round 187 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0908, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0907, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0907, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0907, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0907, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0907, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 187 Summary - Client client_49
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0910, RMSE=0.3016, R²=-0.0566
   Val:   Loss=0.0812, RMSE=0.2850, R²=-0.0228
============================================================


📊 Round 187 Test Metrics:
   Loss: 0.0814, RMSE: 0.2852, MAE: 0.2443, R²: -0.0278

============================================================
🔄 Round 192 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0879, val=0.0925 (↓), lr=0.000001
   • Epoch   2/100: train=0.0879, val=0.0925, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0879, val=0.0925, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0879, val=0.0925, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0879, val=0.0925, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0878, val=0.0925, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0925)

============================================================
📊 Round 192 Summary - Client client_49
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0881, RMSE=0.2969, R²=-0.0521
   Val:   Loss=0.0925, RMSE=0.3042, R²=-0.0423
============================================================


📊 Round 192 Test Metrics:
   Loss: 0.0814, RMSE: 0.2852, MAE: 0.2443, R²: -0.0278

============================================================
🔄 Round 194 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0902, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0901, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0901, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0901, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0901, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0900, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 194 Summary - Client client_49
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0898, RMSE=0.2997, R²=-0.0617
   Val:   Loss=0.0857, RMSE=0.2928, R²=-0.0158
============================================================


📊 Round 194 Test Metrics:
   Loss: 0.0814, RMSE: 0.2852, MAE: 0.2443, R²: -0.0278

============================================================
🔄 Round 195 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0870, val=0.0960 (↓), lr=0.000001
   • Epoch   2/100: train=0.0870, val=0.0960, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0870, val=0.0960, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0870, val=0.0960, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0870, val=0.0960, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0869, val=0.0960, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0960)

============================================================
📊 Round 195 Summary - Client client_49
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0873, RMSE=0.2954, R²=-0.0466
   Val:   Loss=0.0960, RMSE=0.3099, R²=-0.0654
============================================================


============================================================
🔄 Round 196 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0895, val=0.0870 (↓), lr=0.000001
   • Epoch   2/100: train=0.0895, val=0.0870, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0895, val=0.0870, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0895, val=0.0871, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0895, val=0.0871, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0894, val=0.0872, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 196 Summary - Client client_49
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0895, RMSE=0.2992, R²=-0.0488
   Val:   Loss=0.0870, RMSE=0.2950, R²=-0.0816
============================================================


📊 Round 196 Test Metrics:
   Loss: 0.0814, RMSE: 0.2852, MAE: 0.2443, R²: -0.0278

============================================================
🔄 Round 199 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0897, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0897, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0897, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0896, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0896, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0896, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 199 Summary - Client client_49
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0899, RMSE=0.2998, R²=-0.0504
   Val:   Loss=0.0855, RMSE=0.2925, R²=-0.0481
============================================================


📊 Round 199 Test Metrics:
   Loss: 0.0814, RMSE: 0.2852, MAE: 0.2443, R²: -0.0278

📊 Round 199 Test Metrics:
   Loss: 0.0814, RMSE: 0.2852, MAE: 0.2443, R²: -0.0278

============================================================
🔄 Round 201 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0901, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0900, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0900, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0900, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0900, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0900, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 201 Summary - Client client_49
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0902, RMSE=0.3004, R²=-0.0507
   Val:   Loss=0.0841, RMSE=0.2901, R²=-0.0503
============================================================


📊 Round 201 Test Metrics:
   Loss: 0.0814, RMSE: 0.2852, MAE: 0.2443, R²: -0.0278

============================================================
🔄 Round 202 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0896, val=0.0863 (↓), lr=0.000001
   • Epoch   2/100: train=0.0896, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0896, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0896, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0896, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0895, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 202 Summary - Client client_49
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0897, RMSE=0.2995, R²=-0.0471
   Val:   Loss=0.0863, RMSE=0.2937, R²=-0.0679
============================================================


📊 Round 202 Test Metrics:
   Loss: 0.0814, RMSE: 0.2852, MAE: 0.2443, R²: -0.0279

============================================================
🔄 Round 208 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0894, val=0.0881 (↓), lr=0.000001
   • Epoch   2/100: train=0.0894, val=0.0881, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0893, val=0.0881, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0893, val=0.0881, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0893, val=0.0881, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0893, val=0.0881, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0881)

============================================================
📊 Round 208 Summary - Client client_49
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0892, RMSE=0.2987, R²=-0.0539
   Val:   Loss=0.0881, RMSE=0.2969, R²=-0.0344
============================================================


📊 Round 208 Test Metrics:
   Loss: 0.0814, RMSE: 0.2852, MAE: 0.2443, R²: -0.0279

📊 Round 208 Test Metrics:
   Loss: 0.0814, RMSE: 0.2852, MAE: 0.2443, R²: -0.0279

============================================================
🔄 Round 211 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0888, val=0.0894 (↓), lr=0.000001
   • Epoch   2/100: train=0.0888, val=0.0894, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0888, val=0.0894, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0888, val=0.0894, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0888, val=0.0894, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0887, val=0.0893, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0894)

============================================================
📊 Round 211 Summary - Client client_49
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0889, RMSE=0.2982, R²=-0.0462
   Val:   Loss=0.0894, RMSE=0.2990, R²=-0.0685
============================================================


📊 Round 211 Test Metrics:
   Loss: 0.0814, RMSE: 0.2852, MAE: 0.2443, R²: -0.0278

============================================================
🔄 Round 213 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0920, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0920, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0920, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0920, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0920, val=0.0773, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0919, val=0.0773, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 213 Summary - Client client_49
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0919, RMSE=0.3032, R²=-0.0634
   Val:   Loss=0.0773, RMSE=0.2780, R²=0.0098
============================================================


📊 Round 213 Test Metrics:
   Loss: 0.0814, RMSE: 0.2852, MAE: 0.2443, R²: -0.0278

📊 Round 213 Test Metrics:
   Loss: 0.0814, RMSE: 0.2852, MAE: 0.2443, R²: -0.0279

============================================================
🔄 Round 216 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0879, val=0.0929 (↓), lr=0.000001
   • Epoch   2/100: train=0.0879, val=0.0929, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0879, val=0.0929, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0878, val=0.0929, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0878, val=0.0929, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0878, val=0.0929, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0929)

============================================================
📊 Round 216 Summary - Client client_49
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0881, RMSE=0.2967, R²=-0.0510
   Val:   Loss=0.0929, RMSE=0.3048, R²=-0.0456
============================================================


📊 Round 216 Test Metrics:
   Loss: 0.0814, RMSE: 0.2852, MAE: 0.2443, R²: -0.0279

============================================================
🔄 Round 218 - Client client_49
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0915, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0915, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0914, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0914, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0914, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0914, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 218 Summary - Client client_49
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0914, RMSE=0.3023, R²=-0.0459
   Val:   Loss=0.0795, RMSE=0.2820, R²=-0.0767
============================================================


📊 Round 218 Test Metrics:
   Loss: 0.0814, RMSE: 0.2852, MAE: 0.2443, R²: -0.0279

📊 Round 218 Test Metrics:
   Loss: 0.0814, RMSE: 0.2852, MAE: 0.2443, R²: -0.0279

❌ Client client_49 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8687 {grpc_message:"Socket closed", grpc_status:14}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8687 {grpc_message:"Socket closed", grpc_status:14}"
>
