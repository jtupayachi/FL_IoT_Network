[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 02dd5983-7b46-4261-a170-b8bb5852cb86
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b031344f-f609-4984-a95a-93a367a1a7b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0c4f7827-0e80-436b-b66b-4d7125af4d5e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c76b0477-4a8a-4469-993f-f079635222c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 41164281-c856-4a0e-b5f7-712b5165d5d5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3a8ff18f-cc58-4d06-852e-50bc6b12c83f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 33afbe0e-e12c-4629-9e74-78e854bee6a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 820753c3-ae5a-4ac4-a16d-09a635ada221
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 74514e9f-421f-4673-8bfa-24c6d8b46250
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fe800b68-ceb8-46bb-a532-835a57ff34f3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dd40ebed-a87f-4320-b42e-bd6d0ea6625c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bafe1467-c43f-4cab-a501-3fd49fd5dd69
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9e3ea98e-935e-4027-8e96-466f181a943b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 909efabf-9699-4038-bfc9-36d2e70f239f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9aaa720c-9a14-40d7-81d0-93044206f152
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 08df5de1-3f34-4e1a-a3db-9a3a9dfd5ae8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 969b7fc0-5196-47ab-9310-c8d96dbd2b40
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 37359523-e419-47ef-b377-eed261435a99
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5130976f-ba67-4a1d-959b-147fdb5d9409
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 01783357-dc6e-4789-b367-adeee0bcb80c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b43f710f-ae6c-422a-ab73-156bed6a9323
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1a14e475-9a77-4adb-b301-e7ae8e1a3103
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e4399c4a-4783-4726-b194-22c9964ff99f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f3d8c522-7723-4156-a45f-759db908d403
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0d62fe93-7b36-4b34-a81e-7fe7f16b6269
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 03e61c5d-83c0-4f8c-a1bc-47b395f1376d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bc87c507-dd99-4f1c-8327-d4508aa1ac96
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6a960bff-2fe1-4b7c-b81a-3c94f5746a19
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 40b1fadc-d593-4b65-a085-c8dac364a7fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f5e70a24-8cf6-45c3-be87-6245ccbc39d5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dda7c325-bd2c-45e2-9e3a-5568354c14a8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3a63185e-22a8-44d8-a8fb-02cdb8f88d83
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 30bd9970-4337-4338-a0a0-b259f0cdaa34
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2675d416-27c4-4ce5-94cd-939db5d20980
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e22df430-66a6-4895-946a-3a1b7e032407
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a940417a-9086-47d1-ba33-4339e9ead65d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b28333d6-c8e8-4111-b41f-e99a3e135ab7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f264d379-2b6b-48cf-b887-37f19a95f994
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f17b4f27-49cb-44b4-89f6-caddf7086feb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3ea182c3-9533-4724-99af-a34c5b1c22b6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8550bedf-62f5-4036-8fe8-ac95a9454161
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 78611304-b8b3-4b77-b29a-bf63dcaa872e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 26f0f177-11c2-44f8-bede-5da5537cb547
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 17cb1c1e-a2fb-4164-b7f6-1456e983b852
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 26c03f2b-87f0-4ef8-9b44-adc4d90011e9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message de450d51-cf04-4c4f-8031-5bb91051a60f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d1bf23c0-1fb7-4a9e-b096-0a9e06a24c12
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 68a56272-b581-4f8c-ae23-72d53ff19369
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c25543d8-427a-415e-ac9c-3b44fafb8048
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1052aead-9ff6-4888-b822-25e2a52c4e0f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message db4be781-0a14-4465-bfa0-1121e0f4bc58
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 44437537-9681-49d2-b511-bd5638fe9f42
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 22e7c674-0c8c-4098-a472-22eafba45bc4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message efd8555b-33e9-4fe8-9c65-99c6ab32355e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a2b41e5a-3274-4b30-a0ef-35344d36fb54
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 07fa2f91-7c34-4533-9c4b-952e5f5a3b57
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message df0c1eab-104c-4292-a481-450743ba9196
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f0441682-96c0-47d2-be17-16389fd2499a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 85538ce0-317d-48a1-bb84-d1f574365a80
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ab9dbd54-5091-4ad7-a6bd-9d1b9e931e08
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3293cf87-28e3-4d91-bd8a-7e475a4ccd21
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e10127c5-6b9e-49b0-be42-582c3d31ed3c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message affcc59f-2b91-4205-b9be-29abf4b7ecb5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d848c988-be0f-4c95-9066-94c44b1584a7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f3384937-9584-4991-9475-fbb7e83059c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b8cbebcd-3f4a-466e-90aa-81eccaa930eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 62558394-ea0e-4787-b07c-b1adddd81c0c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2e5e26a0-e583-499d-b5d5-3c9a12277caa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 77b67789-7cf8-4bf5-8f11-96f02788ef3b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8a3cf203-9a8a-4095-ac6b-f4e64dc4059a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8f578e45-027b-4d9d-be33-3eb36f68edb3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3a5f348c-3bfe-4924-8cfe-e952492f47bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4d13db27-92db-4f9e-ad23-2f79a3c8dc41
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4fad2861-bb4b-463a-a1ed-281610813369
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 322bccb0-e21a-43fb-96d5-782ba0bcf4bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 118ae940-0256-4215-8c19-46dc8fcb9c3b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 974fc583-cae2-44d1-9df5-df495cac36e5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 97c37d99-5fd2-40d3-9806-1e23a930a7ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 725ddea3-b846-426a-824c-d16c0c29096a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 01414a5f-1a18-495a-959b-8c2c90d1134b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3472c239-c687-44ef-ae2e-9e9a11a8509b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d9905250-4fc0-4103-8ae1-b2047b57c7f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4a68037e-56f9-4b0e-976e-bbe78727890f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f46bf593-e573-4657-9e14-e6af27e87bfa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5f118844-da6a-4aef-b256-b44d15e0f3c7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3e602ba1-a207-4ddb-8e90-ca72d9d84b2d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7f59f76a-be5b-4285-96c1-e863d25be3f8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0c4801e5-6068-48e1-96dd-a7e57648a586
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7f0d958d-0f0c-4367-b4cb-53fb15efd9d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9e7e2243-71e1-4c75-9993-5fcf965946c5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e0c2567e-0b54-4fda-8124-68ad171fd002
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cfcb14ce-a4cd-4ab7-8fb1-ec18cbce4379
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 99d28dcb-94be-404e-a7c9-4b492710ff22
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d41c649b-84f4-4d33-b112-1ee733e5277a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 00d71567-da8b-48a3-a76e-16e000aa04c9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bcb27a43-7845-4bf5-904d-1c200ab58cd0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fce31489-5c2e-48c4-8bb7-80555ade0512
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d7520391-1ebb-4620-97da-a064869f1852
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9c85355c-ecea-4a61-81df-91781f652323
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 362ecc0c-5f35-4ccd-a857-34529d252cdb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9781f8d5-2dd7-4358-b9d6-96afeac111d9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 62bca8de-8b07-4bdb-a246-4327b3f341cb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 84d46ee8-cc47-4cc5-9d3c-5badd4afaa05
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 95e327ba-338e-47e9-b1a4-ec6b1ccad97a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c7223a2f-8f5b-4016-a3fe-e9f2b4033998
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8395983b-5f8b-44e8-82ef-d8e38a9ba451
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 136843be-6769-49bd-b56b-684b5052b7b0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f2718577-a1da-41e8-aad7-31207566516b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 562cce2c-85d3-42e6-bec7-b59794add555
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4403e09e-21aa-40e4-b7d2-92b6f210fc8c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 97b008f9-cd1d-4952-878d-44f2e9e4e781
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a05aa937-2c25-484f-8cd1-5b6452260a99
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 397eb438-478d-4352-b76f-93a47fe05361
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 65e7df58-a04b-4969-af95-b196f4093832
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8b35d852-0ce6-4c2a-9121-2437a8141c88
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 241a2248-57c7-445b-8e95-77c5797bfc07
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5d6ed460-e80b-4ee0-9c8d-1f0fc71323d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 20000e63-b25a-4d84-b7d3-0a00b203c6c7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 492f63f8-f487-48a7-9239-6cfbd0857d36
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 07d998b6-8be0-4ab7-a407-02830ce52881
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1acc5b16-97af-416c-a94e-ebf8eab23f49
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 496f2974-c420-4306-b1f7-7949c0572f7a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5d724d80-c82b-4b58-88c5-84e872d15b01
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aad3e3be-8cce-47ee-9842-9d214e1593ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 60effbb6-2710-4212-af81-50fe1d971b28
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 17b89d3d-a2c8-4bc1-849d-e776bd435bea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7c12b9a9-4392-49d1-beb3-4b1346fb8e0a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 32b007d2-771a-4596-aaa3-78f705ca6e50
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 568dd36c-6233-45d6-acd2-5e110cbb833e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ff116b6b-5a82-4083-91e3-2bdfb2a98137
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c284a0f9-1a2b-4671-aaa0-a702385f569f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a63eb86f-ae19-4b43-9baa-40872ca56903
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1f71d649-4016-4c92-a4de-a9c5a13bff64
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c3247160-6a07-46e4-88c6-69d45d117ea6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bea2afef-a419-49d9-b753-86b6076e0dfc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 17753347-6fb0-4441-aa0c-a442aad7ec2e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 550d08d4-6e5e-4d8b-963d-3d22174d35ce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 13bfea81-3a65-42a2-8834-8dd3b90b995a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e6b454e6-5f3c-43e5-9a37-c75ea8394cfa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message acc8dae8-a71a-4800-9121-2c78db243dce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4a0fca37-699c-48c5-ac0b-6dbac6f9f09d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bd741ac4-f2e2-4cae-aae9-3b918d3dfb5a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5d9f3f9c-2980-46eb-abb6-37172de23ce1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8f443787-cd79-4be7-8942-80fcf66a75a3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bc620652-5494-401d-acb1-2ab00501b34c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c039437b-86a0-4c84-9da0-90c9abbe7a33
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 09063f36-6c38-4863-a12c-d8d33e08b4eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1d24b2b3-84ce-4842-ae12-608cdf335b7c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 695145c5-4d57-4b81-ad86-49f405e617f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 00006e47-5dca-47b1-9584-df1beacfeaf1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fc11a9e2-0e01-42f2-ad39-1f3f7b21a263
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 26f0bef7-c729-4e01-a3ae-f4b48bac70eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 37df93b6-d3a9-4c93-b605-13173bc6c3bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 10db1bb7-f665-481f-8029-ffe8385618d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 950b0c5c-5097-4b58-92a6-a689762987da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cbccd6e3-cdef-4e27-a330-e5f6f12542e6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 925b2b66-ae4c-4388-aea1-5a6800682be5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message efbeab00-83a6-49a4-b1e6-ed2140036bb0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3219c724-1bc5-40e5-98c2-acc5efbc5a11
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e146ae54-02f5-4c02-8e69-ab28306bc2ea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 559d7409-58fd-4ad1-b701-96b5a1d79794
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 13c7e0c4-afef-4999-a289-0cc5970693fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 940fd46c-834e-43cd-820c-45ad01234028
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3c14082e-5bcc-4862-a6fd-b6f00b421cc0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c603b147-f637-4b25-a09e-783d45d98870
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f3324cdb-cdb8-4eb9-b303-9fc0052a84d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3ec59b48-21d5-4bb1-82f2-7a8ed1af6306
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 42089df3-16af-4897-b3dd-2cf85c41809d
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8687 {grpc_status:14, grpc_message:"Socket closed"}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_50
Server: localhost:8687
Algorithm: FEDAVG
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_50
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_50/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_50/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_50/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_50/test_labels.txt

📊 Raw data loaded:
   Train: X=(2043, 24), y=(2043,)
   Test:  X=(511, 24), y=(511,)

⚠️  Limiting training data: 2043 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  502 samples, 5 features
✅ Client client_50 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

============================================================
🔄 Round 5 - Client client_50
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0933 (↓), lr=0.001000
   • Epoch   2/100: train=0.0860, val=0.0957, patience=1/15, lr=0.001000
   • Epoch   3/100: train=0.0874, val=0.0933, patience=2/15, lr=0.001000
   ✓ Epoch   4/100: train=0.0872, val=0.0914 (↓), lr=0.001000
   • Epoch   5/100: train=0.0850, val=0.0911, patience=1/15, lr=0.001000
   ✓ Epoch  11/100: train=0.0831, val=0.0907 (↓), lr=0.001000
   📉 Epoch 20: LR reduced 0.001000 → 0.000500
   • Epoch  21/100: train=0.0743, val=0.0939, patience=10/15, lr=0.000500

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0907)

============================================================
📊 Round 5 Summary - Client client_50
   Epochs: 26/100 (early stopped)
   LR: 0.001000 → 0.000500 (1 reductions)
   Train: Loss=0.0815, RMSE=0.2854, R²=0.0492
   Val:   Loss=0.0907, RMSE=0.3011, R²=0.0305
============================================================


📊 Round 5 Test Metrics:
   Loss: 0.0802, RMSE: 0.2831, MAE: 0.2452, R²: 0.0070

============================================================
🔄 Round 6 - Client client_50
   Epochs: 100, Batch: 32, LR: 0.000500
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0866 (↓), lr=0.000500
   ✓ Epoch   2/100: train=0.0853, val=0.0858 (↓), lr=0.000500
   • Epoch   3/100: train=0.0849, val=0.0857, patience=1/15, lr=0.000500
   • Epoch   4/100: train=0.0846, val=0.0857, patience=2/15, lr=0.000500
   • Epoch   5/100: train=0.0843, val=0.0857, patience=3/15, lr=0.000500
   📉 Epoch 9: LR reduced 0.000500 → 0.000250
   • Epoch  11/100: train=0.0828, val=0.0861, patience=9/15, lr=0.000250
   📉 Epoch 17: LR reduced 0.000250 → 0.000125

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 6 Summary - Client client_50
   Epochs: 17/100 (early stopped)
   LR: 0.000500 → 0.000125 (2 reductions)
   Train: Loss=0.0850, RMSE=0.2915, R²=0.0239
   Val:   Loss=0.0858, RMSE=0.2930, R²=0.0213
============================================================


============================================================
🔄 Round 7 - Client client_50
   Epochs: 100, Batch: 32, LR: 0.000125
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0855 (↓), lr=0.000125
   • Epoch   2/100: train=0.0852, val=0.0854, patience=1/15, lr=0.000125
   • Epoch   3/100: train=0.0850, val=0.0853, patience=2/15, lr=0.000125
   • Epoch   4/100: train=0.0848, val=0.0851, patience=3/15, lr=0.000125
   • Epoch   5/100: train=0.0847, val=0.0851, patience=4/15, lr=0.000125
   • Epoch  11/100: train=0.0839, val=0.0849, patience=4/15, lr=0.000125
   📉 Epoch 15: LR reduced 0.000125 → 0.000063
   • Epoch  21/100: train=0.0830, val=0.0852, patience=14/15, lr=0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 7 Summary - Client client_50
   Epochs: 22/100 (early stopped)
   LR: 0.000125 → 0.000063 (1 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=0.0435
   Val:   Loss=0.0850, RMSE=0.2915, R²=0.0001
============================================================


============================================================
🔄 Round 10 - Client client_50
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   📉 Epoch 1: LR reduced 0.000063 → 0.000031
   ✓ Epoch   1/100: train=0.0846, val=0.0865 (↓), lr=0.000031
   • Epoch   2/100: train=0.0843, val=0.0865, patience=1/15, lr=0.000031
   • Epoch   3/100: train=0.0841, val=0.0864, patience=2/15, lr=0.000031
   • Epoch   4/100: train=0.0840, val=0.0864, patience=3/15, lr=0.000031
   • Epoch   5/100: train=0.0839, val=0.0863, patience=4/15, lr=0.000031
   📉 Epoch 9: LR reduced 0.000031 → 0.000016
   • Epoch  11/100: train=0.0834, val=0.0861, patience=10/15, lr=0.000016

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0865)

============================================================
📊 Round 10 Summary - Client client_50
   Epochs: 16/100 (early stopped)
   LR: 0.000063 → 0.000016 (2 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=0.0326
   Val:   Loss=0.0865, RMSE=0.2942, R²=0.0131
============================================================


============================================================
🔄 Round 11 - Client client_50
   Epochs: 100, Batch: 32, LR: 0.000016
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0837 (↓), lr=0.000016
   • Epoch   2/100: train=0.0852, val=0.0837, patience=1/15, lr=0.000016
   • Epoch   3/100: train=0.0851, val=0.0836, patience=2/15, lr=0.000016
   • Epoch   4/100: train=0.0850, val=0.0835, patience=3/15, lr=0.000016
   • Epoch   5/100: train=0.0849, val=0.0834, patience=4/15, lr=0.000016
   • Epoch  11/100: train=0.0846, val=0.0830, patience=3/15, lr=0.000016
   • Epoch  21/100: train=0.0841, val=0.0826, patience=2/15, lr=0.000016
   • Epoch  31/100: train=0.0838, val=0.0824, patience=12/15, lr=0.000016

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 11 Summary - Client client_50
   Epochs: 34/100 (early stopped)
   LR: 0.000016 → 0.000016 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=0.0360
   Val:   Loss=0.0827, RMSE=0.2875, R²=0.0405
============================================================


============================================================
🔄 Round 13 - Client client_50
   Epochs: 100, Batch: 32, LR: 0.000016
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0889 (↓), lr=0.000016
   • Epoch   2/100: train=0.0839, val=0.0889, patience=1/15, lr=0.000016
   • Epoch   3/100: train=0.0838, val=0.0889, patience=2/15, lr=0.000016
   • Epoch   4/100: train=0.0837, val=0.0888, patience=3/15, lr=0.000016
   • Epoch   5/100: train=0.0836, val=0.0888, patience=4/15, lr=0.000016
   📉 Epoch 6: LR reduced 0.000016 → 0.000008
   • Epoch  11/100: train=0.0831, val=0.0888, patience=10/15, lr=0.000008
   📉 Epoch 14: LR reduced 0.000008 → 0.000004

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0889)

============================================================
📊 Round 13 Summary - Client client_50
   Epochs: 16/100 (early stopped)
   LR: 0.000016 → 0.000004 (2 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=0.0324
   Val:   Loss=0.0889, RMSE=0.2982, R²=-0.0014
============================================================


📊 Round 13 Test Metrics:
   Loss: 0.0797, RMSE: 0.2823, MAE: 0.2442, R²: 0.0128

============================================================
🔄 Round 15 - Client client_50
   Epochs: 100, Batch: 32, LR: 0.000004
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0787 (↓), lr=0.000004
   • Epoch   2/100: train=0.0864, val=0.0787, patience=1/15, lr=0.000004
   • Epoch   3/100: train=0.0864, val=0.0787, patience=2/15, lr=0.000004
   • Epoch   4/100: train=0.0863, val=0.0787, patience=3/15, lr=0.000004
   • Epoch   5/100: train=0.0863, val=0.0787, patience=4/15, lr=0.000004
   📉 Epoch 7: LR reduced 0.000004 → 0.000002
   • Epoch  11/100: train=0.0862, val=0.0787, patience=10/15, lr=0.000002
   📉 Epoch 15: LR reduced 0.000002 → 0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 15 Summary - Client client_50
   Epochs: 16/100 (early stopped)
   LR: 0.000004 → 0.000001 (2 reductions)
   Train: Loss=0.0864, RMSE=0.2939, R²=0.0311
   Val:   Loss=0.0787, RMSE=0.2805, R²=0.0127
============================================================


============================================================
🔄 Round 16 - Client client_50
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 16 Summary - Client client_50
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=0.0201
   Val:   Loss=0.0846, RMSE=0.2909, R²=0.0593
============================================================


============================================================
🔄 Round 17 - Client client_50
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 17 Summary - Client client_50
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2920, R²=0.0289
   Val:   Loss=0.0829, RMSE=0.2880, R²=0.0275
============================================================


============================================================
🔄 Round 19 - Client client_50
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0868 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0868, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0868, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0868, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0868, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0867, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0868)

============================================================
📊 Round 19 Summary - Client client_50
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2904, R²=0.0176
   Val:   Loss=0.0868, RMSE=0.2946, R²=0.0571
============================================================


📊 Round 19 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2444, R²: 0.0116

============================================================
🔄 Round 22 - Client client_50
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 22 Summary - Client client_50
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2919, R²=0.0354
   Val:   Loss=0.0823, RMSE=0.2869, R²=0.0105
============================================================


📊 Round 22 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2443, R²: 0.0124

📊 Round 22 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2443, R²: 0.0122

📊 Round 22 Test Metrics:
   Loss: 0.0798, RMSE: 0.2824, MAE: 0.2443, R²: 0.0121

============================================================
🔄 Round 28 - Client client_50
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 28 Summary - Client client_50
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=0.0242
   Val:   Loss=0.0850, RMSE=0.2915, R²=0.0484
============================================================


📊 Round 28 Test Metrics:
   Loss: 0.0798, RMSE: 0.2824, MAE: 0.2443, R²: 0.0121

============================================================
🔄 Round 30 - Client client_50
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0969 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0969, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0969, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0969, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0969, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0968, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0969)

============================================================
📊 Round 30 Summary - Client client_50
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=0.0301
   Val:   Loss=0.0969, RMSE=0.3113, R²=0.0314
============================================================


============================================================
🔄 Round 32 - Client client_50
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 32 Summary - Client client_50
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2906, R²=0.0299
   Val:   Loss=0.0851, RMSE=0.2917, R²=0.0098
============================================================


📊 Round 32 Test Metrics:
   Loss: 0.0798, RMSE: 0.2824, MAE: 0.2443, R²: 0.0122

============================================================
🔄 Round 33 - Client client_50
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0927 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0927, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0927, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0927, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0927, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0927, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0927)

============================================================
📊 Round 33 Summary - Client client_50
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=0.0363
   Val:   Loss=0.0927, RMSE=0.3044, R²=0.0106
============================================================


============================================================
🔄 Round 35 - Client client_50
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0872 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0872, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0872, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0872, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0872, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0872, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0872)

============================================================
📊 Round 35 Summary - Client client_50
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=0.0263
   Val:   Loss=0.0872, RMSE=0.2954, R²=0.0468
============================================================


📊 Round 35 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2443, R²: 0.0123

📊 Round 35 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2443, R²: 0.0122

📊 Round 35 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2443, R²: 0.0123

============================================================
🔄 Round 39 - Client client_50
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0780 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0780, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0780, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0780, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0780, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 39 Summary - Client client_50
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2937, R²=0.0292
   Val:   Loss=0.0780, RMSE=0.2793, R²=0.0389
============================================================


📊 Round 39 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2443, R²: 0.0123

📊 Round 39 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2443, R²: 0.0124

============================================================
🔄 Round 43 - Client client_50
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0899 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0899, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0899, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0899, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0899, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0899, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0899)

============================================================
📊 Round 43 Summary - Client client_50
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=0.0358
   Val:   Loss=0.0899, RMSE=0.2998, R²=0.0138
============================================================


📊 Round 43 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2443, R²: 0.0124

============================================================
🔄 Round 44 - Client client_50
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 44 Summary - Client client_50
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2925, R²=0.0318
   Val:   Loss=0.0806, RMSE=0.2839, R²=0.0287
============================================================


============================================================
🔄 Round 46 - Client client_50
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 46 Summary - Client client_50
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2913, R²=0.0267
   Val:   Loss=0.0835, RMSE=0.2890, R²=0.0451
============================================================


📊 Round 46 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2443, R²: 0.0124

============================================================
🔄 Round 47 - Client client_50
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 47 Summary - Client client_50
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2925, R²=0.0312
   Val:   Loss=0.0808, RMSE=0.2842, R²=0.0311
============================================================


============================================================
🔄 Round 48 - Client client_50
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0883, val=0.0694 (↓), lr=0.000001
   • Epoch   2/100: train=0.0882, val=0.0694, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0882, val=0.0694, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0882, val=0.0694, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0882, val=0.0694, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0882, val=0.0694, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0694)

============================================================
📊 Round 48 Summary - Client client_50
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0884, RMSE=0.2973, R²=0.0312
   Val:   Loss=0.0694, RMSE=0.2635, R²=0.0315
============================================================


📊 Round 48 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2443, R²: 0.0124

============================================================
🔄 Round 50 - Client client_50
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0777 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0777, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0777, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0777, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0777, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0777, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 50 Summary - Client client_50
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2938, R²=0.0274
   Val:   Loss=0.0777, RMSE=0.2788, R²=0.0363
============================================================


============================================================
🔄 Round 52 - Client client_50
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0955 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0955, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0955, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0955, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0955, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0955, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0955)

============================================================
📊 Round 52 Summary - Client client_50
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2861, R²=0.0278
   Val:   Loss=0.0955, RMSE=0.3091, R²=0.0431
============================================================


📊 Round 52 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2443, R²: 0.0124

📊 Round 52 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2443, R²: 0.0123

📊 Round 52 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2443, R²: 0.0123

============================================================
🔄 Round 58 - Client client_50
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0898 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0899, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0899, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0899, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0899, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0900, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0898)

============================================================
📊 Round 58 Summary - Client client_50
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=0.0352
   Val:   Loss=0.0898, RMSE=0.2997, R²=-0.0029
============================================================


📊 Round 58 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2443, R²: 0.0123

============================================================
🔄 Round 61 - Client client_50
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 61 Summary - Client client_50
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2923, R²=0.0301
   Val:   Loss=0.0812, RMSE=0.2849, R²=0.0330
============================================================


============================================================
🔄 Round 63 - Client client_50
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 63 Summary - Client client_50
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2928, R²=0.0299
   Val:   Loss=0.0801, RMSE=0.2830, R²=0.0363
============================================================


📊 Round 63 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2443, R²: 0.0124

============================================================
🔄 Round 64 - Client client_50
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 64 Summary - Client client_50
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=0.0311
   Val:   Loss=0.0843, RMSE=0.2904, R²=0.0323
============================================================


============================================================
🔄 Round 65 - Client client_50
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 65 Summary - Client client_50
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2918, R²=0.0331
   Val:   Loss=0.0824, RMSE=0.2870, R²=0.0238
============================================================


📊 Round 65 Test Metrics:
   Loss: 0.0797, RMSE: 0.2824, MAE: 0.2443, R²: 0.0125

📊 Round 65 Test Metrics:
   Loss: 0.0797, RMSE: 0.2823, MAE: 0.2443, R²: 0.0126

============================================================
🔄 Round 70 - Client client_50
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0886 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0886, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0886, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0886, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0886, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0886, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0886)

============================================================
📊 Round 70 Summary - Client client_50
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=0.0333
   Val:   Loss=0.0886, RMSE=0.2977, R²=0.0241
============================================================


============================================================
🔄 Round 71 - Client client_50
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0890 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0890, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0890, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0890, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0890, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0890, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0890)

============================================================
📊 Round 71 Summary - Client client_50
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=0.0328
   Val:   Loss=0.0890, RMSE=0.2984, R²=0.0236
============================================================


============================================================
🔄 Round 72 - Client client_50
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 72 Summary - Client client_50
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2915, R²=0.0316
   Val:   Loss=0.0830, RMSE=0.2881, R²=0.0103
============================================================


============================================================
🔄 Round 74 - Client client_50
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 74 Summary - Client client_50
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2918, R²=0.0277
   Val:   Loss=0.0822, RMSE=0.2867, R²=0.0435
============================================================


📊 Round 74 Test Metrics:
   Loss: 0.0797, RMSE: 0.2823, MAE: 0.2443, R²: 0.0127

============================================================
🔄 Round 75 - Client client_50
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 75 Summary - Client client_50
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2915, R²=0.0316
   Val:   Loss=0.0830, RMSE=0.2881, R²=0.0295
============================================================


📊 Round 75 Test Metrics:
   Loss: 0.0797, RMSE: 0.2823, MAE: 0.2443, R²: 0.0127

============================================================
🔄 Round 77 - Client client_50
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0873, val=0.0735 (↓), lr=0.000001
   • Epoch   2/100: train=0.0873, val=0.0735, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0873, val=0.0735, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0873, val=0.0735, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0872, val=0.0735, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0872, val=0.0735, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0735)

============================================================
📊 Round 77 Summary - Client client_50
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0873, RMSE=0.2955, R²=0.0343
   Val:   Loss=0.0735, RMSE=0.2711, R²=0.0066
============================================================


============================================================
🔄 Round 78 - Client client_50
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 78 Summary - Client client_50
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=0.0374
   Val:   Loss=0.0857, RMSE=0.2927, R²=-0.0003
============================================================


📊 Round 78 Test Metrics:
   Loss: 0.0797, RMSE: 0.2823, MAE: 0.2443, R²: 0.0128

📊 Round 78 Test Metrics:
   Loss: 0.0797, RMSE: 0.2823, MAE: 0.2443, R²: 0.0128

============================================================
🔄 Round 82 - Client client_50
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 82 Summary - Client client_50
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=0.0331
   Val:   Loss=0.0852, RMSE=0.2918, R²=0.0126
============================================================


============================================================
🔄 Round 84 - Client client_50
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0889 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0889, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0889, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0889, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0889, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0888, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0889)

============================================================
📊 Round 84 Summary - Client client_50
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=0.0352
   Val:   Loss=0.0889, RMSE=0.2982, R²=0.0171
============================================================


📊 Round 84 Test Metrics:
   Loss: 0.0797, RMSE: 0.2823, MAE: 0.2443, R²: 0.0128

============================================================
🔄 Round 85 - Client client_50
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 85 Summary - Client client_50
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2913, R²=0.0324
   Val:   Loss=0.0834, RMSE=0.2888, R²=0.0183
============================================================


============================================================
🔄 Round 86 - Client client_50
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.0757 (↓), lr=0.000001
   • Epoch   2/100: train=0.0868, val=0.0757, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0867, val=0.0757, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0867, val=0.0757, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0867, val=0.0757, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0867, val=0.0757, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0757)

============================================================
📊 Round 86 Summary - Client client_50
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2946, R²=0.0290
   Val:   Loss=0.0757, RMSE=0.2752, R²=0.0401
============================================================


📊 Round 86 Test Metrics:
   Loss: 0.0797, RMSE: 0.2823, MAE: 0.2443, R²: 0.0128

============================================================
🔄 Round 89 - Client client_50
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 89 Summary - Client client_50
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=0.0309
   Val:   Loss=0.0837, RMSE=0.2894, R²=0.0308
============================================================


============================================================
🔄 Round 90 - Client client_50
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 90 Summary - Client client_50
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2933, R²=0.0261
   Val:   Loss=0.0786, RMSE=0.2804, R²=0.0502
============================================================


📊 Round 90 Test Metrics:
   Loss: 0.0797, RMSE: 0.2823, MAE: 0.2443, R²: 0.0129

============================================================
🔄 Round 94 - Client client_50
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 94 Summary - Client client_50
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=0.0299
   Val:   Loss=0.0858, RMSE=0.2929, R²=0.0378
============================================================


============================================================
🔄 Round 95 - Client client_50
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0899 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0899, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0899, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0899, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0899, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0900, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0899)

============================================================
📊 Round 95 Summary - Client client_50
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=0.0369
   Val:   Loss=0.0899, RMSE=0.2999, R²=0.0045
============================================================


============================================================
🔄 Round 96 - Client client_50
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0877 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0877, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0877, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0877, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0876, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0876, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0877)

============================================================
📊 Round 96 Summary - Client client_50
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=0.0304
   Val:   Loss=0.0877, RMSE=0.2961, R²=0.0356
============================================================


📊 Round 96 Test Metrics:
   Loss: 0.0797, RMSE: 0.2823, MAE: 0.2442, R²: 0.0130

📊 Round 96 Test Metrics:
   Loss: 0.0797, RMSE: 0.2823, MAE: 0.2442, R²: 0.0130

📊 Round 96 Test Metrics:
   Loss: 0.0797, RMSE: 0.2823, MAE: 0.2442, R²: 0.0130

============================================================
🔄 Round 101 - Client client_50
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0870, val=0.0752 (↓), lr=0.000001
   • Epoch   2/100: train=0.0870, val=0.0752, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0870, val=0.0752, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0870, val=0.0752, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0869, val=0.0752, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0869, val=0.0752, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0752)

============================================================
📊 Round 101 Summary - Client client_50
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0869, RMSE=0.2948, R²=0.0286
   Val:   Loss=0.0752, RMSE=0.2742, R²=0.0258
============================================================


============================================================
🔄 Round 102 - Client client_50
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0869 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0869, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0869, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0869, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0869, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0868, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 102 Summary - Client client_50
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=0.0295
   Val:   Loss=0.0869, RMSE=0.2947, R²=0.0371
============================================================


============================================================
🔄 Round 103 - Client client_50
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0776 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0776, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0776, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0776, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0776, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 103 Summary - Client client_50
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2938, R²=0.0329
   Val:   Loss=0.0776, RMSE=0.2785, R²=0.0255
============================================================


📊 Round 103 Test Metrics:
   Loss: 0.0797, RMSE: 0.2823, MAE: 0.2442, R²: 0.0131

============================================================
🔄 Round 105 - Client client_50
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0955 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0955, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0955, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0955, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0955, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0954, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0955)

============================================================
📊 Round 105 Summary - Client client_50
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=0.0319
   Val:   Loss=0.0955, RMSE=0.3091, R²=0.0293
============================================================


============================================================
🔄 Round 106 - Client client_50
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 106 Summary - Client client_50
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2924, R²=0.0353
   Val:   Loss=0.0808, RMSE=0.2843, R²=0.0156
============================================================


============================================================
🔄 Round 108 - Client client_50
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0932 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0932, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0932, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0932, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0932, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0932, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0932)

============================================================
📊 Round 108 Summary - Client client_50
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=0.0302
   Val:   Loss=0.0932, RMSE=0.3054, R²=0.0353
============================================================


============================================================
🔄 Round 109 - Client client_50
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 109 Summary - Client client_50
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2916, R²=0.0358
   Val:   Loss=0.0826, RMSE=0.2873, R²=0.0144
============================================================


📊 Round 109 Test Metrics:
   Loss: 0.0797, RMSE: 0.2823, MAE: 0.2442, R²: 0.0132

📊 Round 109 Test Metrics:
   Loss: 0.0797, RMSE: 0.2823, MAE: 0.2442, R²: 0.0132

============================================================
🔄 Round 113 - Client client_50
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0926 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0926, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0926, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0926, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0926, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0926, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0926)

============================================================
📊 Round 113 Summary - Client client_50
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2873, R²=0.0344
   Val:   Loss=0.0926, RMSE=0.3043, R²=0.0203
============================================================


📊 Round 113 Test Metrics:
   Loss: 0.0797, RMSE: 0.2823, MAE: 0.2442, R²: 0.0132

============================================================
🔄 Round 115 - Client client_50
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0923 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0923, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0923, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0923, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0923, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0923, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0923)

============================================================
📊 Round 115 Summary - Client client_50
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=0.0338
   Val:   Loss=0.0923, RMSE=0.3039, R²=0.0236
============================================================


============================================================
🔄 Round 116 - Client client_50
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0907 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0907, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0907, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0907, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0907, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0907, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0907)

============================================================
📊 Round 116 Summary - Client client_50
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=0.0253
   Val:   Loss=0.0907, RMSE=0.3012, R²=0.0465
============================================================


📊 Round 116 Test Metrics:
   Loss: 0.0797, RMSE: 0.2822, MAE: 0.2442, R²: 0.0133

============================================================
🔄 Round 118 - Client client_50
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 118 Summary - Client client_50
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2934, R²=0.0352
   Val:   Loss=0.0784, RMSE=0.2800, R²=0.0161
============================================================


============================================================
🔄 Round 121 - Client client_50
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 121 Summary - Client client_50
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2931, R²=0.0361
   Val:   Loss=0.0791, RMSE=0.2812, R²=0.0019
============================================================


============================================================
🔄 Round 122 - Client client_50
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0780 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0780, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0780, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0780, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0780, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 122 Summary - Client client_50
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2935, R²=0.0261
   Val:   Loss=0.0780, RMSE=0.2794, R²=0.0556
============================================================


============================================================
🔄 Round 123 - Client client_50
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0763 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0762, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0762, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0762, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0762, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0762, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0763)

============================================================
📊 Round 123 Summary - Client client_50
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2943, R²=0.0313
   Val:   Loss=0.0763, RMSE=0.2761, R²=0.0274
============================================================


============================================================
🔄 Round 124 - Client client_50
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0936 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0936, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0936, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0935, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0935, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0935, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0936)

============================================================
📊 Round 124 Summary - Client client_50
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=0.0369
   Val:   Loss=0.0936, RMSE=0.3059, R²=0.0132
============================================================


📊 Round 124 Test Metrics:
   Loss: 0.0797, RMSE: 0.2822, MAE: 0.2442, R²: 0.0134

============================================================
🔄 Round 126 - Client client_50
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0864, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0864, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 126 Summary - Client client_50
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2899, R²=0.0269
   Val:   Loss=0.0864, RMSE=0.2940, R²=0.0502
============================================================


📊 Round 126 Test Metrics:
   Loss: 0.0797, RMSE: 0.2822, MAE: 0.2442, R²: 0.0134

============================================================
🔄 Round 127 - Client client_50
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 127 Summary - Client client_50
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2906, R²=0.0337
   Val:   Loss=0.0849, RMSE=0.2914, R²=0.0215
============================================================


📊 Round 127 Test Metrics:
   Loss: 0.0797, RMSE: 0.2822, MAE: 0.2442, R²: 0.0134

============================================================
🔄 Round 129 - Client client_50
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 129 Summary - Client client_50
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=0.0296
   Val:   Loss=0.0831, RMSE=0.2883, R²=0.0398
============================================================


============================================================
🔄 Round 130 - Client client_50
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0882, val=0.0702 (↓), lr=0.000001
   • Epoch   2/100: train=0.0882, val=0.0702, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0881, val=0.0702, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0881, val=0.0702, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0881, val=0.0702, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0881, val=0.0701, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0702)

============================================================
📊 Round 130 Summary - Client client_50
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0881, RMSE=0.2969, R²=0.0337
   Val:   Loss=0.0702, RMSE=0.2649, R²=0.0200
============================================================


📊 Round 130 Test Metrics:
   Loss: 0.0797, RMSE: 0.2823, MAE: 0.2442, R²: 0.0132

============================================================
🔄 Round 131 - Client client_50
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 131 Summary - Client client_50
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2924, R²=0.0291
   Val:   Loss=0.0806, RMSE=0.2840, R²=0.0406
============================================================


============================================================
🔄 Round 133 - Client client_50
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 133 Summary - Client client_50
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2901, R²=0.0347
   Val:   Loss=0.0861, RMSE=0.2934, R²=0.0200
============================================================


📊 Round 133 Test Metrics:
   Loss: 0.0797, RMSE: 0.2822, MAE: 0.2442, R²: 0.0133

============================================================
🔄 Round 135 - Client client_50
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0889 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0889, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0889, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0889, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0889, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0889, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0889)

============================================================
📊 Round 135 Summary - Client client_50
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2889, R²=0.0372
   Val:   Loss=0.0889, RMSE=0.2982, R²=0.0113
============================================================


📊 Round 135 Test Metrics:
   Loss: 0.0797, RMSE: 0.2823, MAE: 0.2442, R²: 0.0133

📊 Round 135 Test Metrics:
   Loss: 0.0797, RMSE: 0.2822, MAE: 0.2442, R²: 0.0133

📊 Round 135 Test Metrics:
   Loss: 0.0797, RMSE: 0.2822, MAE: 0.2442, R²: 0.0133

============================================================
🔄 Round 145 - Client client_50
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 145 Summary - Client client_50
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2916, R²=0.0353
   Val:   Loss=0.0825, RMSE=0.2873, R²=0.0172
============================================================


📊 Round 145 Test Metrics:
   Loss: 0.0797, RMSE: 0.2822, MAE: 0.2442, R²: 0.0133

📊 Round 145 Test Metrics:
   Loss: 0.0797, RMSE: 0.2822, MAE: 0.2442, R²: 0.0134

============================================================
🔄 Round 149 - Client client_50
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0770 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0770, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0770, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0770, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0770, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0770, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0770)

============================================================
📊 Round 149 Summary - Client client_50
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2939, R²=0.0305
   Val:   Loss=0.0770, RMSE=0.2776, R²=0.0371
============================================================


📊 Round 149 Test Metrics:
   Loss: 0.0797, RMSE: 0.2822, MAE: 0.2442, R²: 0.0133

📊 Round 149 Test Metrics:
   Loss: 0.0797, RMSE: 0.2822, MAE: 0.2442, R²: 0.0133

============================================================
🔄 Round 152 - Client client_50
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 152 Summary - Client client_50
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2915, R²=0.0312
   Val:   Loss=0.0827, RMSE=0.2875, R²=0.0301
============================================================


📊 Round 152 Test Metrics:
   Loss: 0.0797, RMSE: 0.2822, MAE: 0.2442, R²: 0.0134

📊 Round 152 Test Metrics:
   Loss: 0.0797, RMSE: 0.2822, MAE: 0.2442, R²: 0.0134

📊 Round 152 Test Metrics:
   Loss: 0.0797, RMSE: 0.2822, MAE: 0.2442, R²: 0.0134

============================================================
🔄 Round 163 - Client client_50
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0777, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0777, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0777, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0777, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0777, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 163 Summary - Client client_50
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2936, R²=0.0259
   Val:   Loss=0.0778, RMSE=0.2788, R²=0.0542
============================================================


📊 Round 163 Test Metrics:
   Loss: 0.0797, RMSE: 0.2822, MAE: 0.2442, R²: 0.0133

📊 Round 163 Test Metrics:
   Loss: 0.0797, RMSE: 0.2822, MAE: 0.2442, R²: 0.0133

📊 Round 163 Test Metrics:
   Loss: 0.0797, RMSE: 0.2822, MAE: 0.2442, R²: 0.0134

============================================================
🔄 Round 170 - Client client_50
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 170 Summary - Client client_50
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2925, R²=0.0254
   Val:   Loss=0.0804, RMSE=0.2835, R²=0.0470
============================================================


📊 Round 170 Test Metrics:
   Loss: 0.0797, RMSE: 0.2822, MAE: 0.2442, R²: 0.0134

============================================================
🔄 Round 171 - Client client_50
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 171 Summary - Client client_50
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=0.0352
   Val:   Loss=0.0842, RMSE=0.2902, R²=0.0177
============================================================


============================================================
🔄 Round 172 - Client client_50
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0912 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0912, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0912, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0912, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0912, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0912, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0912)

============================================================
📊 Round 172 Summary - Client client_50
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=0.0282
   Val:   Loss=0.0912, RMSE=0.3020, R²=0.0428
============================================================


============================================================
🔄 Round 173 - Client client_50
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0882 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0882, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0882, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0881, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0881, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0881, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0882)

============================================================
📊 Round 173 Summary - Client client_50
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=0.0263
   Val:   Loss=0.0882, RMSE=0.2969, R²=0.0517
============================================================


============================================================
🔄 Round 175 - Client client_50
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0859, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 175 Summary - Client client_50
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2901, R²=0.0386
   Val:   Loss=0.0859, RMSE=0.2932, R²=0.0034
============================================================


📊 Round 175 Test Metrics:
   Loss: 0.0796, RMSE: 0.2822, MAE: 0.2442, R²: 0.0135

============================================================
🔄 Round 178 - Client client_50
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0879 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0879, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0879, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0879, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0879, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0880, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0879)

============================================================
📊 Round 178 Summary - Client client_50
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=0.0254
   Val:   Loss=0.0879, RMSE=0.2964, R²=0.0363
============================================================


============================================================
🔄 Round 179 - Client client_50
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 179 Summary - Client client_50
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2916, R²=0.0368
   Val:   Loss=0.0823, RMSE=0.2869, R²=0.0122
============================================================


📊 Round 179 Test Metrics:
   Loss: 0.0796, RMSE: 0.2822, MAE: 0.2442, R²: 0.0135

📊 Round 179 Test Metrics:
   Loss: 0.0796, RMSE: 0.2822, MAE: 0.2442, R²: 0.0135

============================================================
🔄 Round 184 - Client client_50
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0946 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0946, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0946, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0946, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0946, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0945, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0946)

============================================================
📊 Round 184 Summary - Client client_50
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=0.0345
   Val:   Loss=0.0946, RMSE=0.3075, R²=0.0188
============================================================


============================================================
🔄 Round 185 - Client client_50
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 185 Summary - Client client_50
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2918, R²=0.0318
   Val:   Loss=0.0819, RMSE=0.2861, R²=0.0239
============================================================


📊 Round 185 Test Metrics:
   Loss: 0.0796, RMSE: 0.2822, MAE: 0.2442, R²: 0.0135

📊 Round 185 Test Metrics:
   Loss: 0.0797, RMSE: 0.2822, MAE: 0.2442, R²: 0.0134

============================================================
🔄 Round 188 - Client client_50
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 188 Summary - Client client_50
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2917, R²=0.0352
   Val:   Loss=0.0821, RMSE=0.2866, R²=0.0176
============================================================


📊 Round 188 Test Metrics:
   Loss: 0.0797, RMSE: 0.2822, MAE: 0.2442, R²: 0.0134

============================================================
🔄 Round 189 - Client client_50
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0865 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0865, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0864, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0864, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0865)

============================================================
📊 Round 189 Summary - Client client_50
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2899, R²=0.0251
   Val:   Loss=0.0865, RMSE=0.2940, R²=0.0529
============================================================


============================================================
🔄 Round 192 - Client client_50
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 192 Summary - Client client_50
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2915, R²=0.0351
   Val:   Loss=0.0826, RMSE=0.2873, R²=0.0188
============================================================


📊 Round 192 Test Metrics:
   Loss: 0.0797, RMSE: 0.2822, MAE: 0.2442, R²: 0.0134

============================================================
🔄 Round 197 - Client client_50
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 197 Summary - Client client_50
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2929, R²=0.0258
   Val:   Loss=0.0793, RMSE=0.2816, R²=0.0560
============================================================


📊 Round 197 Test Metrics:
   Loss: 0.0796, RMSE: 0.2822, MAE: 0.2442, R²: 0.0135

============================================================
🔄 Round 199 - Client client_50
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0864, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0864, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 199 Summary - Client client_50
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2899, R²=0.0310
   Val:   Loss=0.0864, RMSE=0.2940, R²=0.0254
============================================================


📊 Round 199 Test Metrics:
   Loss: 0.0796, RMSE: 0.2822, MAE: 0.2442, R²: 0.0135

============================================================
🔄 Round 200 - Client client_50
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 200 Summary - Client client_50
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2918, R²=0.0307
   Val:   Loss=0.0818, RMSE=0.2861, R²=0.0148
============================================================


📊 Round 200 Test Metrics:
   Loss: 0.0796, RMSE: 0.2822, MAE: 0.2442, R²: 0.0135

============================================================
🔄 Round 204 - Client client_50
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 204 Summary - Client client_50
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=0.0311
   Val:   Loss=0.0837, RMSE=0.2894, R²=0.0366
============================================================


📊 Round 204 Test Metrics:
   Loss: 0.0797, RMSE: 0.2822, MAE: 0.2442, R²: 0.0134

📊 Round 204 Test Metrics:
   Loss: 0.0797, RMSE: 0.2822, MAE: 0.2442, R²: 0.0134

📊 Round 204 Test Metrics:
   Loss: 0.0796, RMSE: 0.2822, MAE: 0.2442, R²: 0.0135

============================================================
🔄 Round 209 - Client client_50
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 209 Summary - Client client_50
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2931, R²=0.0312
   Val:   Loss=0.0788, RMSE=0.2807, R²=0.0337
============================================================


📊 Round 209 Test Metrics:
   Loss: 0.0796, RMSE: 0.2822, MAE: 0.2442, R²: 0.0136

============================================================
🔄 Round 210 - Client client_50
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 210 Summary - Client client_50
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2922, R²=0.0281
   Val:   Loss=0.0810, RMSE=0.2846, R²=0.0483
============================================================


📊 Round 210 Test Metrics:
   Loss: 0.0796, RMSE: 0.2822, MAE: 0.2442, R²: 0.0136

============================================================
🔄 Round 212 - Client client_50
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0863 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 212 Summary - Client client_50
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2899, R²=0.0389
   Val:   Loss=0.0863, RMSE=0.2937, R²=-0.0031
============================================================


============================================================
🔄 Round 215 - Client client_50
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 215 Summary - Client client_50
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=0.0260
   Val:   Loss=0.0857, RMSE=0.2928, R²=0.0157
============================================================


📊 Round 215 Test Metrics:
   Loss: 0.0796, RMSE: 0.2822, MAE: 0.2442, R²: 0.0136

============================================================
🔄 Round 217 - Client client_50
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 217 Summary - Client client_50
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2904, R²=0.0360
   Val:   Loss=0.0851, RMSE=0.2916, R²=0.0147
============================================================


============================================================
🔄 Round 220 - Client client_50
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0874 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0874, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0874, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0874, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0874, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0874, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0874)

============================================================
📊 Round 220 Summary - Client client_50
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2894, R²=0.0336
   Val:   Loss=0.0874, RMSE=0.2956, R²=0.0251
============================================================


📊 Round 220 Test Metrics:
   Loss: 0.0796, RMSE: 0.2822, MAE: 0.2442, R²: 0.0137

============================================================
🔄 Round 224 - Client client_50
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 224 Summary - Client client_50
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2901, R²=0.0374
   Val:   Loss=0.0857, RMSE=0.2928, R²=0.0103
============================================================


❌ Client client_50 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8687 {grpc_status:14, grpc_message:"Socket closed"}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8687 {grpc_status:14, grpc_message:"Socket closed"}"
>
