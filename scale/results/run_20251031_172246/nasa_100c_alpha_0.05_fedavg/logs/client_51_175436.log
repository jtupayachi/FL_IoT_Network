[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c03244fd-4874-41db-b5db-b597f7a0c9f9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c2f3370a-b669-453f-a79f-7821de8d971e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6dc99518-5052-4db7-9b46-2ba7680d0cf9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6be927b8-a10e-4c32-9d00-720501873f61
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c6ce7f62-bb43-4d1d-85ca-bf910fd7f6e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 751956e1-66dd-4710-993d-fa8c41e9f416
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 58007dfc-9d9c-4672-b7d8-8ee62a27f7c9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 84a4cad8-8425-4e52-a63c-7986cd15d4ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 92907050-8dcc-4566-9710-58f538b2869c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f4fbab67-b435-4057-b585-7b2db262a2cb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 636929fa-4d3d-4eaa-8c39-4a0b285705d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7f7f54aa-64d9-4e56-bc79-0d911e70b411
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9b2f2fb2-d131-40f6-b788-5d21252dd2f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1eadb69b-dcd7-4e06-8ad4-6395e0411e24
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 68acdacd-4255-4e81-9b9f-5da3a9e16627
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 688df052-1094-47d4-86db-e9cce5584f7b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 98ebeff6-c7fb-4e7f-916a-2f7631ce2750
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2c890ca7-e261-45a9-b05f-5d539c6e4879
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0238a406-727f-46a3-a9c5-1e85d1964d04
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 24813b02-cc0c-4d29-9f85-414e24420e04
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 621d3ed7-ff6c-4498-a02a-30bd46a440b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6039fa40-c30c-4bba-8121-5c608e881f77
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 500757a9-869d-4c8f-8216-bd986f08c8cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 12261f8e-4f15-45a4-945f-8703a0df4885
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9ded43b0-a05f-4838-b28a-a1399fc47b30
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c54bf6ab-a134-462b-9c86-6fe9f17c4d1c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 86e30180-b06a-4a00-86d5-c359b3fdda7f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c514f083-51a2-49ff-b866-1532316200e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2087a62c-adb9-40de-aad4-05a1033a2451
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 70b683bf-d419-4d12-b872-9b50242e5047
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6ed3a616-9aac-45ba-8a27-dcbc4487aa7e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f641befa-b07e-4743-b3d5-0faeffa507f8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 28a28a96-82aa-45fa-862a-27ae29374c78
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a1efc681-5012-4bfb-aa15-4108b1c54ee9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message de4ed61c-20e5-488c-bfa1-a1a36995b360
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message df331538-00ae-44d0-b8d0-9ae987f6432a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 79d4a8c8-cc80-4072-9eee-b8a57b5ea44b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 87087242-55fb-4719-9390-e0c11c4142bd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9f174ee1-0529-4080-9aea-7bea7bcd044b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bed07c0e-6e83-446d-a2d8-f6b1fc31d021
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4097228b-acea-4dba-962f-9dba51ec6150
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8a4b97f7-32f1-4288-9e29-6ef868737185
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0fac9477-caa9-419c-8a94-1e479329147a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1dcddaaa-4c67-4744-af32-676aeeeb2029
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ce714e3a-8487-464a-85fd-d95617915843
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5e778b65-865f-4e35-8e83-0cf084c9440c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1be64354-5be7-4322-8bf4-2324d476ea7d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b9eeee56-2dd8-4202-a59a-d1afeda8ac6b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fdcddea0-15f9-4c10-80cd-8514c7cdcfe3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 79073632-c2c0-427d-a04c-c6495cd77d38
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fcdd19ec-c99a-4b55-b53c-b985758f0ecc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b8edd9f6-d47c-4c5b-87b3-0d93b9e1de9b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 260a3b17-8bd7-4a62-9f23-60c3d2c77568
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9fd5f804-b374-4ac9-b939-4048563f86bc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 47388a14-88d0-4ca2-9408-6586dcb870af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e127eed5-2ebb-48d4-9e77-ad360f2bc3b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d7b44d53-0bc8-483d-b790-5c79c166af5c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ff39da41-a9e9-4253-89aa-f7bc1dd1d937
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4362e891-e151-4fe6-97e1-300a09d83408
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 14afdeea-7976-45a5-bc64-e8b98b17e90c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6579887a-c716-4948-950c-ca5b09289ff3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8cdb3555-b02f-4c13-9b0d-505d0ff9156c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3ad23191-89f9-4ee8-b9c8-af78c9045c55
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dfed11e4-17d9-440c-977d-3c2a9837e407
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ecd035f2-300e-47b3-9a84-a41aec819037
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2039624e-4737-4ba2-a188-6a950944a0cd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e11b52da-49da-4660-bc32-159f450577e9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ad562bb8-de90-41b6-b22a-aa2536ad9e8a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 17888d3c-17b2-4118-af51-b24501631e22
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 910f1c8c-d572-41e4-9464-1560ae39bdbd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 61ecaea7-c44c-4d14-8c94-8172759048b9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 35bc538d-25c1-4bca-a6ad-d410de775ee3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b67bdd6a-1959-4778-b713-d4b931e64cb1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a778edf0-5278-413b-accf-3b17e0c92df0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 025c7fd5-3882-4f0d-9a2e-fa2a9dc4bc7b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 08313517-5dac-4cc2-8677-bd03f6c26705
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f7652821-f732-4ecc-9a7d-f333c4665e88
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2b50f887-1020-4968-948e-fab79f5d9280
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f44aef6a-4ea0-47c9-906c-7404099351a0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message beb28fef-ee53-46fc-a89b-1dd02dea4e40
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 12816fe3-65cc-46a1-ab46-d43162347c89
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9c86b226-5e2b-4f08-babe-429dd08c017e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7e1dcf34-89de-452f-9726-2f8e6997d2c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a846d850-1065-4ea2-b805-a64bb630b1c4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d6a656b9-00be-41dd-89ec-186bb08b068c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 54bf6df3-8894-4f82-bf35-853d831484ea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9ad39fe3-7a01-4aef-b1cb-3596c2315dab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 58eaa3de-dbb3-4ccf-bcb9-d9336ba11c35
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9196cd51-62b2-4c9e-9990-6455b16c889b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fed15253-0a60-4a13-ab19-4591e34cdb1b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4af584e0-37e8-48f0-9cf6-9a0c0bb39add
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b012e916-2a5f-48ff-bdd1-7ef4172f88fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b859f922-6c44-467b-8105-7666b24e13f3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e5ce1be1-b3f3-4848-a8a9-605b105b6816
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 11ce938d-dc33-4f27-9275-cb4492abf765
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e6811279-d04e-41bf-aa78-23762faec249
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 84634525-b6fc-4301-9861-62b8abf2ea2d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f4b3667f-f35b-4106-b9e8-a4396f98f2e2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f9e31d62-4155-494f-a1be-57df3e230c74
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1face760-c00b-4404-a10a-5978f7996dc3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4646e22c-a0b1-405f-840f-0679debef7ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5e9c5b60-2f89-4ccc-a55c-0bee72da0b3f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2d1efcaf-67a4-4d9d-b47b-9940e93c7e1b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c6da70eb-c86a-4767-a390-7d41a84b243f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6d52cf72-9cf2-4ea1-bac5-4f4c8a430357
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d2e0d7ff-d424-4816-9a32-3abb4720ef1d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7b0411ba-49ee-4f25-9702-af8e192d75d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6202c852-1166-4d4f-a40a-f578617713a3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ff492da1-73fa-4e79-8d2a-0fb1981b2a49
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2f8aa85e-cd5e-4ed7-a480-5e3ea18fb411
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 70fe9609-f35b-4602-acce-1f2d5121ac64
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 09e675ac-9e42-43ba-aafc-15cb5bfec103
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2c960b61-a619-41c6-97b8-2a8fafc2f45a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ac99cc15-394a-43a5-94ee-8f8300abef65
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 82992ae2-f383-4245-928f-93c07b9d9539
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5cfe3878-5320-408d-afde-3abd2dfd80aa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c73d8ef5-a288-48fc-aee5-60ce8440b3cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e9cd8ecd-129b-4e42-bef6-69fa67318df5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 41d3b9b5-85c4-4958-90f5-be4c15c71be6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 00a8134d-e49f-43c4-90ec-afbba8ebf5e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0c87cef2-5bd4-4ae8-ac24-558bd529e485
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e2af097c-d070-44f5-9d14-c1dcd401ec51
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fb203704-8062-438d-8243-18e80642247f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c0dc216a-f963-4ae3-9914-341614f833e1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3da984ce-cd98-41cb-a193-5289b4f44422
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bfcf9a06-0dd2-4b3a-8e26-3e85880ea7b7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0f9cf9d1-7ef5-4c3f-86bf-31d4dede7e57
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9b5c2389-b6f7-41f5-bf9d-f2babf5c4f07
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e7d012b9-d078-4dd6-8b20-3912abe9e866
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1e99d5a8-5e87-481e-bd81-bb54afa41aa1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c8c6dc29-ce06-4ce2-afd3-76fc9cd1dda8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 79c92746-9187-432a-aea1-77353a540569
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e5145239-3c37-415d-b8eb-afea931539b7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9c1b22de-68dd-4254-ade1-e26ecfe7a63a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b3450281-6126-4e94-ba28-08c2280f467c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ad74959c-52f3-46c1-8b84-52694e79a369
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 43d0165f-5818-4575-962f-77a2475bfca9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 87f11e0f-8813-4581-8dfb-b64d93d0aa6a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 99386a95-76bc-4dac-ac72-407fe1f816de
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e231f1b3-89fb-4b0a-93a3-4dfef5c2281c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dfee87f4-a3f7-4c1e-b77c-843b30b45946
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 210bbecb-4578-4abf-b116-4811e1f18bef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 78ca9c4d-99bf-4ff4-835d-d4cee08b9a34
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6cb33875-f377-4696-a492-4a048ca1f313
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 773d40c7-6af3-44a3-84e2-483b95d6e91b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ada70138-2b1b-4599-acd4-a46fafe8162c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2409e71d-3bef-426f-8436-c0b54c400844
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1b4b332e-b2e2-43ac-8854-b422d00c7139
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message da94c288-d1a5-4214-b886-bb21f4dd6845
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 79fb9fc6-969d-4597-b649-5d494310e3ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8a6fc384-468e-4d96-9d26-1f2be5ec2935
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7dc75de8-2ee1-4909-a591-e770c5576835
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9eb11948-1ce1-447d-b1ec-8cb9b4593615
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message edc9fa90-2708-48f8-aab2-7d3e05f6de4c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ee7d0060-2900-4d4d-854a-5647b289469f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 64fe357e-99bc-489e-9fff-38ac6fdedcf9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8f02490a-920c-4fc0-b828-0f1db1718a78
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 34fafff9-350e-446d-aa35-fb1fd96379a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 00e0f588-6a75-4576-b20f-f00dec7b21ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 53978b17-a7ed-4dfa-a872-4abe3e1bd9c5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fca243c4-fc28-4a5b-be1f-51075815950b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7472b297-6f47-40fb-8e73-3010d3a8280c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8af98620-c927-4477-be70-e846e549063a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 51b122ea-5ec8-46ce-b6fb-4f86a6a124be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 549c31f6-addf-41cb-8abb-49bcf71557ca
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8687 {grpc_message:"Socket closed", grpc_status:14}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_51
Server: localhost:8687
Algorithm: FEDAVG
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_51
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_51/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_51/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_51/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_51/test_labels.txt

📊 Raw data loaded:
   Train: X=(505, 24), y=(505,)
   Test:  X=(127, 24), y=(127,)

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 496 samples, 5 features
   Test:  118 samples, 5 features
✅ Client client_51 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

📊 Round 0 Test Metrics:
   Loss: 0.0759, RMSE: 0.2756, MAE: 0.2378, R²: 0.0133

============================================================
🔄 Round 8 - Client client_51
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0802 (↓), lr=0.001000
   • Epoch   2/100: train=0.0820, val=0.0804, patience=1/15, lr=0.001000
   ✓ Epoch   3/100: train=0.0805, val=0.0793 (↓), lr=0.001000
   • Epoch   4/100: train=0.0794, val=0.0788, patience=1/15, lr=0.001000
   ✓ Epoch   5/100: train=0.0786, val=0.0784 (↓), lr=0.001000
   • Epoch  11/100: train=0.0725, val=0.0760, patience=1/15, lr=0.001000
   📉 Epoch 16: LR reduced 0.001000 → 0.000500
   • Epoch  21/100: train=0.0650, val=0.0769, patience=11/15, lr=0.000500
   📉 Epoch 24: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0757)

============================================================
📊 Round 8 Summary - Client client_51
   Epochs: 25/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0727, RMSE=0.2697, R²=0.1488
   Val:   Loss=0.0757, RMSE=0.2751, R²=0.1048
============================================================


============================================================
🔄 Round 9 - Client client_51
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0829 (↓), lr=0.000250
   • Epoch   2/100: train=0.0837, val=0.0828, patience=1/15, lr=0.000250
   • Epoch   3/100: train=0.0833, val=0.0826, patience=2/15, lr=0.000250
   • Epoch   4/100: train=0.0829, val=0.0825, patience=3/15, lr=0.000250
   ✓ Epoch   5/100: train=0.0826, val=0.0824 (↓), lr=0.000250
   📉 Epoch 7: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0816, val=0.0817, patience=2/15, lr=0.000125
   📉 Epoch 15: LR reduced 0.000125 → 0.000063
   • Epoch  21/100: train=0.0809, val=0.0810, patience=6/15, lr=0.000063
   📉 Epoch 23: LR reduced 0.000063 → 0.000031
   📉 Epoch 31: LR reduced 0.000031 → 0.000016
   • Epoch  31/100: train=0.0806, val=0.0807, patience=1/15, lr=0.000016
   📉 Epoch 39: LR reduced 0.000016 → 0.000008
   • Epoch  41/100: train=0.0805, val=0.0806, patience=11/15, lr=0.000008

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 9 Summary - Client client_51
   Epochs: 45/100 (early stopped)
   LR: 0.000250 → 0.000008 (5 reductions)
   Train: Loss=0.0793, RMSE=0.2816, R²=0.0603
   Val:   Loss=0.0807, RMSE=0.2841, R²=0.0895
============================================================


============================================================
🔄 Round 10 - Client client_51
   Epochs: 100, Batch: 32, LR: 0.000008
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0784 (↓), lr=0.000008
   📉 Epoch 2: LR reduced 0.000008 → 0.000004
   • Epoch   2/100: train=0.0836, val=0.0784, patience=1/15, lr=0.000004
   • Epoch   3/100: train=0.0836, val=0.0784, patience=2/15, lr=0.000004
   • Epoch   4/100: train=0.0836, val=0.0784, patience=3/15, lr=0.000004
   • Epoch   5/100: train=0.0836, val=0.0784, patience=4/15, lr=0.000004
   📉 Epoch 10: LR reduced 0.000004 → 0.000002
   • Epoch  11/100: train=0.0835, val=0.0785, patience=10/15, lr=0.000002

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 10 Summary - Client client_51
   Epochs: 16/100 (early stopped)
   LR: 0.000008 → 0.000002 (2 reductions)
   Train: Loss=0.0833, RMSE=0.2887, R²=0.0310
   Val:   Loss=0.0784, RMSE=0.2800, R²=0.0408
============================================================


📊 Round 10 Test Metrics:
   Loss: 0.0753, RMSE: 0.2744, MAE: 0.2369, R²: 0.0215

📊 Round 10 Test Metrics:
   Loss: 0.0753, RMSE: 0.2745, MAE: 0.2372, R²: 0.0210

📊 Round 10 Test Metrics:
   Loss: 0.0755, RMSE: 0.2748, MAE: 0.2374, R²: 0.0190

📊 Round 10 Test Metrics:
   Loss: 0.0756, RMSE: 0.2749, MAE: 0.2375, R²: 0.0181

============================================================
🔄 Round 15 - Client client_51
   Epochs: 100, Batch: 32, LR: 0.000002
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0791 (↓), lr=0.000002
   📉 Epoch 2: LR reduced 0.000002 → 0.000001
   • Epoch   2/100: train=0.0835, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 15 Summary - Client client_51
   Epochs: 16/100 (early stopped)
   LR: 0.000002 → 0.000001 (1 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=0.0394
   Val:   Loss=0.0791, RMSE=0.2813, R²=0.0080
============================================================


📊 Round 15 Test Metrics:
   Loss: 0.0755, RMSE: 0.2747, MAE: 0.2371, R²: 0.0196

📊 Round 15 Test Metrics:
   Loss: 0.0755, RMSE: 0.2747, MAE: 0.2371, R²: 0.0192

📊 Round 15 Test Metrics:
   Loss: 0.0753, RMSE: 0.2745, MAE: 0.2367, R²: 0.0213

============================================================
🔄 Round 22 - Client client_51
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0773, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0774, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 22 Summary - Client client_51
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2892, R²=0.0271
   Val:   Loss=0.0773, RMSE=0.2779, R²=0.0250
============================================================


📊 Round 22 Test Metrics:
   Loss: 0.0753, RMSE: 0.2744, MAE: 0.2366, R²: 0.0216

📊 Round 22 Test Metrics:
   Loss: 0.0753, RMSE: 0.2744, MAE: 0.2366, R²: 0.0217

📊 Round 22 Test Metrics:
   Loss: 0.0753, RMSE: 0.2744, MAE: 0.2365, R²: 0.0219

📊 Round 22 Test Metrics:
   Loss: 0.0753, RMSE: 0.2744, MAE: 0.2366, R²: 0.0218

============================================================
🔄 Round 32 - Client client_51
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0764 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0764, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0764, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0764, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0764, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0764, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0764)

============================================================
📊 Round 32 Summary - Client client_51
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=0.0231
   Val:   Loss=0.0764, RMSE=0.2765, R²=0.0793
============================================================


============================================================
🔄 Round 33 - Client client_51
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0728 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0728, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0728, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0728, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0728, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0729, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0728)

============================================================
📊 Round 33 Summary - Client client_51
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2911, R²=0.0379
   Val:   Loss=0.0728, RMSE=0.2698, R²=-0.0223
============================================================


📊 Round 33 Test Metrics:
   Loss: 0.0753, RMSE: 0.2744, MAE: 0.2366, R²: 0.0217

============================================================
🔄 Round 34 - Client client_51
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0748 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0748, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0748, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0748, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0748, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0747, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0748)

============================================================
📊 Round 34 Summary - Client client_51
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=0.0409
   Val:   Loss=0.0748, RMSE=0.2735, R²=0.0015
============================================================


============================================================
🔄 Round 35 - Client client_51
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0968 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0968, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0968, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0968, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0968, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0969, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0968)

============================================================
📊 Round 35 Summary - Client client_51
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2806, R²=0.0242
   Val:   Loss=0.0968, RMSE=0.3111, R²=0.0165
============================================================


============================================================
🔄 Round 36 - Client client_51
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0925 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0925, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0925, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0925, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0925, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0925, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0925)

============================================================
📊 Round 36 Summary - Client client_51
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=0.0298
   Val:   Loss=0.0925, RMSE=0.3042, R²=0.0472
============================================================


📊 Round 36 Test Metrics:
   Loss: 0.0753, RMSE: 0.2744, MAE: 0.2366, R²: 0.0217

📊 Round 36 Test Metrics:
   Loss: 0.0753, RMSE: 0.2744, MAE: 0.2366, R²: 0.0216

============================================================
🔄 Round 42 - Client client_51
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0738 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0738, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0738, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0738, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0738, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0739, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0738)

============================================================
📊 Round 42 Summary - Client client_51
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=0.0207
   Val:   Loss=0.0738, RMSE=0.2717, R²=0.0784
============================================================


📊 Round 42 Test Metrics:
   Loss: 0.0753, RMSE: 0.2744, MAE: 0.2366, R²: 0.0216

============================================================
🔄 Round 44 - Client client_51
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 44 Summary - Client client_51
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=0.0444
   Val:   Loss=0.0837, RMSE=0.2894, R²=-0.0140
============================================================


📊 Round 44 Test Metrics:
   Loss: 0.0753, RMSE: 0.2744, MAE: 0.2366, R²: 0.0216

============================================================
🔄 Round 46 - Client client_51
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 46 Summary - Client client_51
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=0.0268
   Val:   Loss=0.0781, RMSE=0.2795, R²=0.0634
============================================================


============================================================
🔄 Round 47 - Client client_51
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0875, val=0.0668 (↓), lr=0.000001
   • Epoch   2/100: train=0.0875, val=0.0668, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0875, val=0.0668, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0875, val=0.0668, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0874, val=0.0668, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0874, val=0.0668, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0668)

============================================================
📊 Round 47 Summary - Client client_51
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2937, R²=0.0342
   Val:   Loss=0.0668, RMSE=0.2585, R²=0.0151
============================================================


============================================================
🔄 Round 48 - Client client_51
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0769, val=0.0954 (↓), lr=0.000001
   • Epoch   2/100: train=0.0769, val=0.0954, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0769, val=0.0954, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0769, val=0.0954, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0769, val=0.0954, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0769, val=0.0954, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0954)

============================================================
📊 Round 48 Summary - Client client_51
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2813, R²=0.0286
   Val:   Loss=0.0954, RMSE=0.3088, R²=0.0402
============================================================


📊 Round 48 Test Metrics:
   Loss: 0.0753, RMSE: 0.2744, MAE: 0.2366, R²: 0.0216

============================================================
🔄 Round 54 - Client client_51
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 54 Summary - Client client_51
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=0.0306
   Val:   Loss=0.0781, RMSE=0.2795, R²=0.0410
============================================================


📊 Round 54 Test Metrics:
   Loss: 0.0753, RMSE: 0.2744, MAE: 0.2366, R²: 0.0217

📊 Round 54 Test Metrics:
   Loss: 0.0753, RMSE: 0.2744, MAE: 0.2366, R²: 0.0217

============================================================
🔄 Round 57 - Client client_51
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0733 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0733, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0733, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0733, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0733, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0733, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0733)

============================================================
📊 Round 57 Summary - Client client_51
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=0.0258
   Val:   Loss=0.0733, RMSE=0.2708, R²=0.0686
============================================================


📊 Round 57 Test Metrics:
   Loss: 0.0753, RMSE: 0.2744, MAE: 0.2366, R²: 0.0217

============================================================
🔄 Round 61 - Client client_51
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 61 Summary - Client client_51
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=0.0326
   Val:   Loss=0.0836, RMSE=0.2892, R²=0.0385
============================================================


============================================================
🔄 Round 63 - Client client_51
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0696 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0696, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0696, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0697, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0697, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0698, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0696)

============================================================
📊 Round 63 Summary - Client client_51
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2925, R²=0.0268
   Val:   Loss=0.0696, RMSE=0.2638, R²=0.0394
============================================================


============================================================
🔄 Round 64 - Client client_51
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 64 Summary - Client client_51
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=0.0284
   Val:   Loss=0.0789, RMSE=0.2808, R²=0.0500
============================================================


📊 Round 64 Test Metrics:
   Loss: 0.0753, RMSE: 0.2744, MAE: 0.2366, R²: 0.0216

============================================================
🔄 Round 65 - Client client_51
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 65 Summary - Client client_51
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=0.0346
   Val:   Loss=0.0818, RMSE=0.2860, R²=0.0302
============================================================


📊 Round 65 Test Metrics:
   Loss: 0.0753, RMSE: 0.2744, MAE: 0.2366, R²: 0.0215

📊 Round 65 Test Metrics:
   Loss: 0.0753, RMSE: 0.2744, MAE: 0.2366, R²: 0.0215

📊 Round 65 Test Metrics:
   Loss: 0.0753, RMSE: 0.2744, MAE: 0.2366, R²: 0.0214

============================================================
🔄 Round 74 - Client client_51
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0697 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0697, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0697, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0697, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0697, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0697, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0697)

============================================================
📊 Round 74 Summary - Client client_51
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2924, R²=0.0182
   Val:   Loss=0.0697, RMSE=0.2641, R²=0.0870
============================================================


📊 Round 74 Test Metrics:
   Loss: 0.0753, RMSE: 0.2745, MAE: 0.2366, R²: 0.0213

📊 Round 74 Test Metrics:
   Loss: 0.0753, RMSE: 0.2745, MAE: 0.2366, R²: 0.0212

📊 Round 74 Test Metrics:
   Loss: 0.0753, RMSE: 0.2745, MAE: 0.2366, R²: 0.0212

📊 Round 74 Test Metrics:
   Loss: 0.0753, RMSE: 0.2745, MAE: 0.2366, R²: 0.0212

============================================================
🔄 Round 87 - Client client_51
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0877 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0877, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0877, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0877, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0877, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0877, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0877)

============================================================
📊 Round 87 Summary - Client client_51
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2847, R²=0.0338
   Val:   Loss=0.0877, RMSE=0.2961, R²=0.0346
============================================================


📊 Round 87 Test Metrics:
   Loss: 0.0753, RMSE: 0.2745, MAE: 0.2366, R²: 0.0212

📊 Round 87 Test Metrics:
   Loss: 0.0753, RMSE: 0.2745, MAE: 0.2366, R²: 0.0212

============================================================
🔄 Round 91 - Client client_51
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0737 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0737, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0737, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0737, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0737, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0738, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0737)

============================================================
📊 Round 91 Summary - Client client_51
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=0.0342
   Val:   Loss=0.0737, RMSE=0.2715, R²=0.0125
============================================================


📊 Round 91 Test Metrics:
   Loss: 0.0753, RMSE: 0.2745, MAE: 0.2366, R²: 0.0211

============================================================
🔄 Round 93 - Client client_51
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 93 Summary - Client client_51
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=0.0336
   Val:   Loss=0.0821, RMSE=0.2866, R²=0.0319
============================================================


============================================================
🔄 Round 97 - Client client_51
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 97 Summary - Client client_51
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2887, R²=0.0363
   Val:   Loss=0.0785, RMSE=0.2802, R²=0.0090
============================================================


📊 Round 97 Test Metrics:
   Loss: 0.0753, RMSE: 0.2745, MAE: 0.2367, R²: 0.0210

📊 Round 97 Test Metrics:
   Loss: 0.0754, RMSE: 0.2745, MAE: 0.2367, R²: 0.0210

📊 Round 97 Test Metrics:
   Loss: 0.0754, RMSE: 0.2745, MAE: 0.2367, R²: 0.0210

📊 Round 97 Test Metrics:
   Loss: 0.0754, RMSE: 0.2745, MAE: 0.2367, R²: 0.0210

============================================================
🔄 Round 103 - Client client_51
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 103 Summary - Client client_51
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2880, R²=0.0319
   Val:   Loss=0.0801, RMSE=0.2830, R²=0.0429
============================================================


============================================================
🔄 Round 104 - Client client_51
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0756 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0756, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0756, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0756, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0756, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0756, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0756)

============================================================
📊 Round 104 Summary - Client client_51
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2899, R²=0.0372
   Val:   Loss=0.0756, RMSE=0.2750, R²=0.0190
============================================================


📊 Round 104 Test Metrics:
   Loss: 0.0754, RMSE: 0.2745, MAE: 0.2367, R²: 0.0210

============================================================
🔄 Round 106 - Client client_51
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0759 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0759, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0759, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0759, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0759, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0760, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0759)

============================================================
📊 Round 106 Summary - Client client_51
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=0.0291
   Val:   Loss=0.0759, RMSE=0.2755, R²=0.0068
============================================================


📊 Round 106 Test Metrics:
   Loss: 0.0754, RMSE: 0.2745, MAE: 0.2367, R²: 0.0209

============================================================
🔄 Round 107 - Client client_51
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0949 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0949, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0949, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0949, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0949, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0949, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0949)

============================================================
📊 Round 107 Summary - Client client_51
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2815, R²=0.0292
   Val:   Loss=0.0949, RMSE=0.3081, R²=0.0501
============================================================


📊 Round 107 Test Metrics:
   Loss: 0.0754, RMSE: 0.2745, MAE: 0.2367, R²: 0.0209

============================================================
🔄 Round 110 - Client client_51
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 110 Summary - Client client_51
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2875, R²=0.0382
   Val:   Loss=0.0811, RMSE=0.2848, R²=0.0109
============================================================


📊 Round 110 Test Metrics:
   Loss: 0.0754, RMSE: 0.2745, MAE: 0.2367, R²: 0.0210

📊 Round 110 Test Metrics:
   Loss: 0.0754, RMSE: 0.2745, MAE: 0.2367, R²: 0.0209

============================================================
🔄 Round 114 - Client client_51
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 114 Summary - Client client_51
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=0.0307
   Val:   Loss=0.0820, RMSE=0.2864, R²=0.0287
============================================================


📊 Round 114 Test Metrics:
   Loss: 0.0754, RMSE: 0.2745, MAE: 0.2367, R²: 0.0209

📊 Round 114 Test Metrics:
   Loss: 0.0754, RMSE: 0.2745, MAE: 0.2367, R²: 0.0208

============================================================
🔄 Round 118 - Client client_51
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 118 Summary - Client client_51
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2868, R²=0.0230
   Val:   Loss=0.0828, RMSE=0.2878, R²=0.0715
============================================================


📊 Round 118 Test Metrics:
   Loss: 0.0754, RMSE: 0.2745, MAE: 0.2367, R²: 0.0208

============================================================
🔄 Round 119 - Client client_51
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0738 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0738, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0738, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0738, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0738, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0738, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0738)

============================================================
📊 Round 119 Summary - Client client_51
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=0.0329
   Val:   Loss=0.0738, RMSE=0.2716, R²=0.0311
============================================================


📊 Round 119 Test Metrics:
   Loss: 0.0754, RMSE: 0.2745, MAE: 0.2367, R²: 0.0208

============================================================
🔄 Round 122 - Client client_51
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0883 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0883, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0883, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0883, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0882, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0882, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0883)

============================================================
📊 Round 122 Summary - Client client_51
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=0.0394
   Val:   Loss=0.0883, RMSE=0.2971, R²=0.0126
============================================================


============================================================
🔄 Round 123 - Client client_51
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0923 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0923, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0923, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0923, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0922, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0922, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0923)

============================================================
📊 Round 123 Summary - Client client_51
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2826, R²=0.0383
   Val:   Loss=0.0923, RMSE=0.3037, R²=0.0187
============================================================


📊 Round 123 Test Metrics:
   Loss: 0.0754, RMSE: 0.2745, MAE: 0.2367, R²: 0.0208

============================================================
🔄 Round 125 - Client client_51
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0899 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0899, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0899, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0900, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0900, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0900, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0899)

============================================================
📊 Round 125 Summary - Client client_51
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=0.0375
   Val:   Loss=0.0899, RMSE=0.2999, R²=0.0134
============================================================


📊 Round 125 Test Metrics:
   Loss: 0.0754, RMSE: 0.2745, MAE: 0.2367, R²: 0.0207

============================================================
🔄 Round 126 - Client client_51
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0882 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0882, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0882, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0883, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0883, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0884, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0882)

============================================================
📊 Round 126 Summary - Client client_51
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=0.0216
   Val:   Loss=0.0882, RMSE=0.2970, R²=-0.0107
============================================================


📊 Round 126 Test Metrics:
   Loss: 0.0754, RMSE: 0.2745, MAE: 0.2367, R²: 0.0207

============================================================
🔄 Round 129 - Client client_51
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0902 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0902, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0902, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0902, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0901, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0901, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0902)

============================================================
📊 Round 129 Summary - Client client_51
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=0.0346
   Val:   Loss=0.0902, RMSE=0.3003, R²=0.0304
============================================================


📊 Round 129 Test Metrics:
   Loss: 0.0754, RMSE: 0.2745, MAE: 0.2367, R²: 0.0209

📊 Round 129 Test Metrics:
   Loss: 0.0754, RMSE: 0.2745, MAE: 0.2367, R²: 0.0209

============================================================
🔄 Round 133 - Client client_51
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0740 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0740, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0740, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0740, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0740, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0740, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0740)

============================================================
📊 Round 133 Summary - Client client_51
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2906, R²=0.0297
   Val:   Loss=0.0740, RMSE=0.2720, R²=0.0250
============================================================


============================================================
🔄 Round 134 - Client client_51
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 134 Summary - Client client_51
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2875, R²=0.0348
   Val:   Loss=0.0812, RMSE=0.2850, R²=0.0266
============================================================


============================================================
🔄 Round 136 - Client client_51
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 136 Summary - Client client_51
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2880, R²=0.0215
   Val:   Loss=0.0799, RMSE=0.2827, R²=0.0775
============================================================


============================================================
🔄 Round 137 - Client client_51
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 137 Summary - Client client_51
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=0.0260
   Val:   Loss=0.0805, RMSE=0.2837, R²=0.0485
============================================================


============================================================
🔄 Round 138 - Client client_51
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 138 Summary - Client client_51
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2861, R²=0.0356
   Val:   Loss=0.0845, RMSE=0.2907, R²=0.0206
============================================================


📊 Round 138 Test Metrics:
   Loss: 0.0754, RMSE: 0.2745, MAE: 0.2367, R²: 0.0210

============================================================
🔄 Round 142 - Client client_51
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 142 Summary - Client client_51
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=0.0240
   Val:   Loss=0.0791, RMSE=0.2812, R²=0.0743
============================================================


📊 Round 142 Test Metrics:
   Loss: 0.0754, RMSE: 0.2745, MAE: 0.2367, R²: 0.0209

📊 Round 142 Test Metrics:
   Loss: 0.0754, RMSE: 0.2745, MAE: 0.2367, R²: 0.0209

============================================================
🔄 Round 148 - Client client_51
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 148 Summary - Client client_51
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2887, R²=0.0334
   Val:   Loss=0.0784, RMSE=0.2801, R²=0.0328
============================================================


============================================================
🔄 Round 150 - Client client_51
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0934 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0934, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0934, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0934, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0934, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0934, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0934)

============================================================
📊 Round 150 Summary - Client client_51
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2822, R²=0.0358
   Val:   Loss=0.0934, RMSE=0.3055, R²=0.0279
============================================================


📊 Round 150 Test Metrics:
   Loss: 0.0754, RMSE: 0.2745, MAE: 0.2367, R²: 0.0209

============================================================
🔄 Round 151 - Client client_51
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0694 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0694, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0694, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0694, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0694, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0694, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0694)

============================================================
📊 Round 151 Summary - Client client_51
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2926, R²=0.0314
   Val:   Loss=0.0694, RMSE=0.2634, R²=0.0464
============================================================


📊 Round 151 Test Metrics:
   Loss: 0.0754, RMSE: 0.2745, MAE: 0.2367, R²: 0.0209

============================================================
🔄 Round 154 - Client client_51
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 154 Summary - Client client_51
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2884, R²=0.0266
   Val:   Loss=0.0792, RMSE=0.2814, R²=0.0555
============================================================


📊 Round 154 Test Metrics:
   Loss: 0.0754, RMSE: 0.2745, MAE: 0.2367, R²: 0.0208

📊 Round 154 Test Metrics:
   Loss: 0.0754, RMSE: 0.2745, MAE: 0.2367, R²: 0.0208

============================================================
🔄 Round 159 - Client client_51
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0750 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0750, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0750, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0750, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0750, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0750, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0750)

============================================================
📊 Round 159 Summary - Client client_51
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=0.0352
   Val:   Loss=0.0750, RMSE=0.2739, R²=0.0202
============================================================


📊 Round 159 Test Metrics:
   Loss: 0.0754, RMSE: 0.2745, MAE: 0.2367, R²: 0.0209

============================================================
🔄 Round 161 - Client client_51
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0721 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0721, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0721, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0721, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0721, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0721, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0721)

============================================================
📊 Round 161 Summary - Client client_51
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=0.0351
   Val:   Loss=0.0721, RMSE=0.2686, R²=0.0286
============================================================


📊 Round 161 Test Metrics:
   Loss: 0.0754, RMSE: 0.2745, MAE: 0.2367, R²: 0.0209

============================================================
🔄 Round 162 - Client client_51
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 162 Summary - Client client_51
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=0.0391
   Val:   Loss=0.0838, RMSE=0.2894, R²=0.0134
============================================================


📊 Round 162 Test Metrics:
   Loss: 0.0754, RMSE: 0.2745, MAE: 0.2367, R²: 0.0209

============================================================
🔄 Round 165 - Client client_51
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0876 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0876, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0876, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0876, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0876, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0876, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0876)

============================================================
📊 Round 165 Summary - Client client_51
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2847, R²=0.0321
   Val:   Loss=0.0876, RMSE=0.2959, R²=0.0373
============================================================


============================================================
🔄 Round 166 - Client client_51
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0880 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0880, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0880, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0880, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0880, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0881, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0880)

============================================================
📊 Round 166 Summary - Client client_51
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2845, R²=0.0283
   Val:   Loss=0.0880, RMSE=0.2967, R²=0.0343
============================================================


============================================================
🔄 Round 167 - Client client_51
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0732 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0732, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0732, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0732, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0732, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0732, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0732)

============================================================
📊 Round 167 Summary - Client client_51
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=0.0308
   Val:   Loss=0.0732, RMSE=0.2706, R²=0.0266
============================================================


============================================================
🔄 Round 168 - Client client_51
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0726 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0726, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0727, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0727, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0727, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0727, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0726)

============================================================
📊 Round 168 Summary - Client client_51
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=0.0394
   Val:   Loss=0.0726, RMSE=0.2695, R²=0.0075
============================================================


📊 Round 168 Test Metrics:
   Loss: 0.0754, RMSE: 0.2745, MAE: 0.2366, R²: 0.0210

============================================================
🔄 Round 169 - Client client_51
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 169 Summary - Client client_51
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2854, R²=0.0352
   Val:   Loss=0.0861, RMSE=0.2934, R²=0.0291
============================================================


============================================================
🔄 Round 170 - Client client_51
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0895 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0895, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0895, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0895, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0895, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0895, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0895)

============================================================
📊 Round 170 Summary - Client client_51
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=0.0257
   Val:   Loss=0.0895, RMSE=0.2992, R²=0.0173
============================================================


============================================================
🔄 Round 171 - Client client_51
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0773, val=0.0940 (↓), lr=0.000001
   • Epoch   2/100: train=0.0773, val=0.0940, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0772, val=0.0940, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0772, val=0.0940, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0772, val=0.0940, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0772, val=0.0940, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0940)

============================================================
📊 Round 171 Summary - Client client_51
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2819, R²=0.0384
   Val:   Loss=0.0940, RMSE=0.3066, R²=0.0033
============================================================


📊 Round 171 Test Metrics:
   Loss: 0.0754, RMSE: 0.2745, MAE: 0.2367, R²: 0.0209

============================================================
🔄 Round 172 - Client client_51
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0899 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0899, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0899, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0899, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0899, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0899, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0899)

============================================================
📊 Round 172 Summary - Client client_51
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=0.0260
   Val:   Loss=0.0899, RMSE=0.2998, R²=0.0467
============================================================


📊 Round 172 Test Metrics:
   Loss: 0.0754, RMSE: 0.2745, MAE: 0.2367, R²: 0.0209

============================================================
🔄 Round 175 - Client client_51
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 175 Summary - Client client_51
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=0.0400
   Val:   Loss=0.0807, RMSE=0.2842, R²=0.0061
============================================================


📊 Round 175 Test Metrics:
   Loss: 0.0754, RMSE: 0.2745, MAE: 0.2367, R²: 0.0209

📊 Round 175 Test Metrics:
   Loss: 0.0754, RMSE: 0.2745, MAE: 0.2367, R²: 0.0209

📊 Round 175 Test Metrics:
   Loss: 0.0754, RMSE: 0.2745, MAE: 0.2366, R²: 0.0209

📊 Round 175 Test Metrics:
   Loss: 0.0754, RMSE: 0.2745, MAE: 0.2366, R²: 0.0210

============================================================
🔄 Round 181 - Client client_51
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0868 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0868, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0868, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0868, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0868, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0868, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0868)

============================================================
📊 Round 181 Summary - Client client_51
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=0.0256
   Val:   Loss=0.0868, RMSE=0.2947, R²=0.0597
============================================================


📊 Round 181 Test Metrics:
   Loss: 0.0754, RMSE: 0.2745, MAE: 0.2366, R²: 0.0210

============================================================
🔄 Round 184 - Client client_51
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0712 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0712, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0712, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0712, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0712, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0711, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0712)

============================================================
📊 Round 184 Summary - Client client_51
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2918, R²=0.0195
   Val:   Loss=0.0712, RMSE=0.2668, R²=0.0967
============================================================


============================================================
🔄 Round 185 - Client client_51
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0736 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0736, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0736, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0736, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0736, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0736, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0736)

============================================================
📊 Round 185 Summary - Client client_51
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2908, R²=0.0452
   Val:   Loss=0.0736, RMSE=0.2713, R²=-0.0227
============================================================


📊 Round 185 Test Metrics:
   Loss: 0.0754, RMSE: 0.2745, MAE: 0.2366, R²: 0.0210

============================================================
🔄 Round 186 - Client client_51
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 186 Summary - Client client_51
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=0.0406
   Val:   Loss=0.0852, RMSE=0.2918, R²=0.0062
============================================================


============================================================
🔄 Round 188 - Client client_51
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0868 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0868, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0868, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0868, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0868, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0869, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0868)

============================================================
📊 Round 188 Summary - Client client_51
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=0.0343
   Val:   Loss=0.0868, RMSE=0.2947, R²=0.0191
============================================================


📊 Round 188 Test Metrics:
   Loss: 0.0753, RMSE: 0.2745, MAE: 0.2366, R²: 0.0211

============================================================
🔄 Round 189 - Client client_51
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0660 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0660, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0660, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0660, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0660, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0661, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0660)

============================================================
📊 Round 189 Summary - Client client_51
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2941, R²=0.0289
   Val:   Loss=0.0660, RMSE=0.2569, R²=0.0185
============================================================


============================================================
🔄 Round 191 - Client client_51
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0876 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0877, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0877, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0877, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0877, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0878, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0876)

============================================================
📊 Round 191 Summary - Client client_51
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2847, R²=0.0327
   Val:   Loss=0.0876, RMSE=0.2960, R²=0.0187
============================================================


============================================================
🔄 Round 192 - Client client_51
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 192 Summary - Client client_51
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=0.0335
   Val:   Loss=0.0810, RMSE=0.2846, R²=0.0349
============================================================


============================================================
🔄 Round 193 - Client client_51
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0689 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0689, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0689, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0689, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0689, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0689, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0689)

============================================================
📊 Round 193 Summary - Client client_51
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2928, R²=0.0389
   Val:   Loss=0.0689, RMSE=0.2624, R²=0.0061
============================================================


📊 Round 193 Test Metrics:
   Loss: 0.0753, RMSE: 0.2745, MAE: 0.2366, R²: 0.0212

============================================================
🔄 Round 196 - Client client_51
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 196 Summary - Client client_51
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=0.0308
   Val:   Loss=0.0827, RMSE=0.2876, R²=0.0366
============================================================


📊 Round 196 Test Metrics:
   Loss: 0.0753, RMSE: 0.2745, MAE: 0.2366, R²: 0.0211

📊 Round 196 Test Metrics:
   Loss: 0.0753, RMSE: 0.2745, MAE: 0.2366, R²: 0.0211

============================================================
🔄 Round 202 - Client client_51
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0735 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0735, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0735, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0735, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0735, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0735, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0735)

============================================================
📊 Round 202 Summary - Client client_51
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2908, R²=0.0390
   Val:   Loss=0.0735, RMSE=0.2712, R²=-0.0001
============================================================


📊 Round 202 Test Metrics:
   Loss: 0.0753, RMSE: 0.2745, MAE: 0.2366, R²: 0.0211

============================================================
🔄 Round 204 - Client client_51
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 204 Summary - Client client_51
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2882, R²=0.0415
   Val:   Loss=0.0796, RMSE=0.2822, R²=-0.0584
============================================================


📊 Round 204 Test Metrics:
   Loss: 0.0753, RMSE: 0.2745, MAE: 0.2366, R²: 0.0212

📊 Round 204 Test Metrics:
   Loss: 0.0753, RMSE: 0.2745, MAE: 0.2366, R²: 0.0212

📊 Round 204 Test Metrics:
   Loss: 0.0753, RMSE: 0.2745, MAE: 0.2366, R²: 0.0212

📊 Round 204 Test Metrics:
   Loss: 0.0753, RMSE: 0.2745, MAE: 0.2366, R²: 0.0211

📊 Round 204 Test Metrics:
   Loss: 0.0753, RMSE: 0.2745, MAE: 0.2366, R²: 0.0211

============================================================
🔄 Round 214 - Client client_51
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0883 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0883, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0883, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0883, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0883, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0882, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0883)

============================================================
📊 Round 214 Summary - Client client_51
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2845, R²=0.0365
   Val:   Loss=0.0883, RMSE=0.2971, R²=0.0227
============================================================


📊 Round 214 Test Metrics:
   Loss: 0.0753, RMSE: 0.2745, MAE: 0.2366, R²: 0.0211

============================================================
🔄 Round 215 - Client client_51
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0923 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0923, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0923, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0923, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0923, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0923, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0923)

============================================================
📊 Round 215 Summary - Client client_51
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=0.0414
   Val:   Loss=0.0923, RMSE=0.3039, R²=0.0056
============================================================


📊 Round 215 Test Metrics:
   Loss: 0.0753, RMSE: 0.2745, MAE: 0.2366, R²: 0.0212

📊 Round 215 Test Metrics:
   Loss: 0.0753, RMSE: 0.2745, MAE: 0.2366, R²: 0.0212

============================================================
🔄 Round 218 - Client client_51
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0780 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0780, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0780, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0780, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0780, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 218 Summary - Client client_51
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=0.0378
   Val:   Loss=0.0780, RMSE=0.2793, R²=0.0148
============================================================


📊 Round 218 Test Metrics:
   Loss: 0.0753, RMSE: 0.2745, MAE: 0.2366, R²: 0.0212

============================================================
🔄 Round 219 - Client client_51
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0778, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0778, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0778, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0778, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0778, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 219 Summary - Client client_51
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=0.0384
   Val:   Loss=0.0778, RMSE=0.2789, R²=0.0124
============================================================


============================================================
🔄 Round 220 - Client client_51
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0893 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0893, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0893, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0893, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0893, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0893, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0893)

============================================================
📊 Round 220 Summary - Client client_51
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2840, R²=0.0420
   Val:   Loss=0.0893, RMSE=0.2988, R²=-0.0012
============================================================


📊 Round 220 Test Metrics:
   Loss: 0.0753, RMSE: 0.2745, MAE: 0.2366, R²: 0.0211

📊 Round 220 Test Metrics:
   Loss: 0.0753, RMSE: 0.2745, MAE: 0.2366, R²: 0.0211

📊 Round 220 Test Metrics:
   Loss: 0.0753, RMSE: 0.2745, MAE: 0.2366, R²: 0.0210

============================================================
🔄 Round 225 - Client client_51
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0729 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0729, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0729, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0729, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0729, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0729, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0729)

============================================================
📊 Round 225 Summary - Client client_51
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2911, R²=0.0375
   Val:   Loss=0.0729, RMSE=0.2700, R²=0.0115
============================================================


❌ Client client_51 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8687 {grpc_message:"Socket closed", grpc_status:14}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8687 {grpc_message:"Socket closed", grpc_status:14}"
>
