[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cf08a68b-dfd4-4cc4-861b-d4b71a89159c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3bc582bf-779a-4ca8-9837-4675a48f6878
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ab2431c5-92e1-4dce-ac38-ae89c7d74900
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 921bd9b4-eb86-4e32-a099-33c57caa1565
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f379b482-e146-4d85-9d67-51ecfaa13c87
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e6d3892a-0eef-455a-b5b5-e6d4420a9c8b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4da3bc47-e740-436c-8894-0b8a27eab74f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 94aba4e8-9437-41c4-a0b7-dbac3944e2e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 429a066b-bcdf-492c-a72c-f8145d9d0522
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cd74c365-901b-4c76-a0f6-9c300caf23c3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f360a833-c299-46d8-950a-37af7bed073a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 66aa9d58-9ee0-4f39-8974-c2d06941c990
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e20e2528-840b-4bc7-884c-6fb5e5704f8b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d77bcc52-d7da-4ad9-b5cf-80c0576dbf11
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 070aa437-048b-43e5-8620-d65dfd641fcf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fe25c036-15a4-4c91-a5c5-fc19b45f4843
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message be995603-e5bc-47db-966d-8aa02c462904
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1aa70727-b94a-4f2a-84ab-c534f8c3d4ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1db8a95b-d0dc-4320-b7d0-89e38a0929ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3f6b92dd-689f-4c56-942c-42176a632989
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0959598d-b852-4ac5-ae31-a2f3806ea40e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b53803f9-29c3-4aa4-8545-e14ae6ff3e32
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 82d9f19c-0ad8-4152-a24e-c2b15f0638f2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 01e5f790-bb91-47b3-b6e6-1b45c6fc93d8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cdfa9117-5f9c-460e-80b7-850ad37ae709
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 73efc466-3915-4311-8f5a-a971cbce7448
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5855b9d9-f58d-46f8-9de3-d9d4b09d93b0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 29e16722-5cd4-4f3f-9017-d143ec9dc599
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 33b8dd48-646b-4d84-8d93-880b8d56e2eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c3d28282-2c25-4bae-ae56-049187e67432
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8bdcd263-f473-4dc6-a979-a6a08f07b134
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1292cce3-7a0c-492e-82be-48b0e70c82df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ed923046-ce10-4c53-a75b-c5ed37b05df6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a802c8de-7c11-4374-8252-26e95bc1f44c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1dee3386-bc8b-4763-8340-4eb975485564
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0f4957f1-1270-4f09-9331-5d407063a060
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8c02b186-29e8-4f91-88da-3ee1004c7f3d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 90f2f55b-7b86-48c2-b62d-f17b9dfbdc99
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e500da20-b59a-416c-8323-be3d93502c1d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5395d4f9-0024-43b9-bb49-3128eddcd6c5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 486a300d-ad15-4100-bc6c-a9966103e4cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d346b124-2596-4ad5-8186-57b89a384683
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 36089004-634c-4688-8bb6-60ac5a2b4105
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4db8b1e0-44bb-4213-9854-ead82a536d93
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cd373b2a-168d-45b9-b77b-0e555bd3f5b9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 557eae81-2b4e-4137-a22f-30d5d58982c9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 36a72717-0fab-4516-a773-7ce262ac3e2b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 453d4479-0d43-4110-8206-20e45d629a17
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9ff00a69-6cd9-4295-a338-d5a7aca4a5af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 31f26efc-13d3-4656-a16c-13e480be619d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c2ca83b9-491d-4d10-b1f6-fb8dee938b05
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 219c07a7-e128-404c-8534-7768f766efb1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f130c456-5860-42bd-80b7-a77b024f0e03
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c45d1a8f-f0f6-4eda-8fcf-d73c76d6f8c5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1ba71dc5-d525-4415-8a4d-26adbc7d58b0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 24b58d6f-6d74-4844-bf79-3aee2423977e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 187a2eae-71ca-4f72-8cc9-6c91086cf491
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 33e35f65-9557-460f-8f31-2b1f2e53836e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dd9c83bf-136c-4ab5-a596-3fbf212b954d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8e43fd35-2440-475a-b143-225a5c8bc6df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 74275ca0-151c-4b92-8d4a-ed03c0f7a01f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bc1c8448-2731-47df-afea-f63df0adaf88
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1dd5d5d4-630b-413c-8b80-b55808bdc366
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 43fa51ab-6b52-46cb-8426-5109073395fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ddb37e1c-897c-452c-be17-c30901c0d149
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2198927b-d66c-4d7a-b767-0064a0e1e35d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 97ec3332-efd4-4e16-9ff4-9ebce3bb4312
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 028fa6dc-55eb-47ee-8744-dbea75748572
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ffd2bd2d-de71-4daf-8de5-41ea3d079170
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bb3004bb-0b71-4102-8e2e-cba814666127
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 356b4d6e-387c-4b9c-aac1-e7fd39393313
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 094f58f8-f3a0-4621-81a2-141207be6b1b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b44e0686-c3ab-409c-8913-e4ea7bfc3db5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 020c6950-5c44-42e2-a1f9-869807f7b2de
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 31887c27-1634-446c-a95f-312b3d2ebeb8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 56c9403b-a115-418d-b956-b581eb933b73
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3cd27b55-b934-4665-a409-2b4eee26094e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b79a49be-1f22-4cd5-b9ae-69a04f7cf63f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7e293bae-8c51-486e-9371-411d596778cd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1e56597d-ef45-4f97-a8c6-4562749ea8a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7eb8f215-1ef7-4b16-8de3-f5509d92630e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c370c5f9-aebc-4f5a-bba2-1980c047b0d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 94e6d409-b5c1-4cc6-a398-fe5d265f2d57
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5991127e-5f7a-4ce7-896d-c9c0b79a70d5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3ad96971-5b55-46d0-98fc-aa6883afea7b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 038d65f6-de1b-4a84-a1d3-a01c340114da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 676dd0b2-1d10-454a-ad0d-5fbfdc7c12e8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1826471e-a3ae-43fb-9d62-92501da883db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message caf5c28c-d6e4-42ba-b930-89c57e411894
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9de80161-69f4-4aa1-bedb-d73ffbfc9581
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6009de1c-6175-4819-812d-a8e5afa105d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5cb08196-da9c-42a2-bcb5-5eccd521aa95
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message abe7d5bc-90cb-4eab-a21c-4627625a46cd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2a218720-3e3a-4588-a8be-c6f5ade359d8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a801acc8-913b-4ed5-9558-69c88088464d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1db50d27-5d09-479f-8f4e-b3d1f2f21701
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 68a0d51a-28d3-4e2b-9253-a8a263229797
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a00c60f0-6bb5-4cd8-80b7-dcae2efb6397
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f54e323d-b55b-4d0e-a338-acf373cc069c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 66870a62-ceb3-4ce2-a4ed-09ce4a59b87e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c4df47f2-76dc-4010-a506-5eee267eacf1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ea5bb25f-7e80-42d4-a869-4708dbabc9ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 51fafeb9-eacc-46c4-854c-00c8e612f8f4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 852a80cd-f0be-40d2-85a7-fcca37add6b7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cd721677-0686-4cd8-ae06-c317b2499444
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 38e1d8f3-4bd5-4c1f-b0f2-16e02fc96533
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5ce7a4af-4740-4a5e-a13e-84f342d3b45f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fe5dab5b-0db2-4a94-8997-390e56e9872e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 96cf230b-0e31-46ff-af2a-6ad253aeb295
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c3db095c-96d3-437d-9fb7-3ec30d9c49a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 03460acc-06cf-4a96-9bfa-0bb60c3fd8a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e4a7868b-1e67-491e-9ec9-101e3e691f35
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b092ec33-6226-4f69-93d4-432003b414b5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 56dc98ee-c216-4069-808f-205ef6d6fab3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8524db55-f78c-492d-bebf-446ee34d6154
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bad49064-9a0f-489f-a8ae-b9685551e77c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e67854e6-5119-46d9-83de-7da6fbe91fec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8090e1de-4f58-4d6e-9145-ebd0526a0618
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 84b8ade0-ef56-4689-bd35-ab7903927c04
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 25479b7d-2d93-452f-9199-d7a214932972
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 107c6c31-9cac-42ad-a024-13cbd7d067f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9d41f596-43d3-4966-85b5-f23b6edbe070
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7c6ad731-bf62-474b-a63f-09e4e0c316bc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c5e23c50-9446-4e1c-9602-4ec062f77537
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a5b3aaf9-2737-42a7-8409-b68070f9f2a0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 37806af1-496a-455c-a974-5cf13eb7f90d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8322255d-145a-4be7-83fc-3ff7a3f2a094
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 83e90089-eab5-4de8-b64f-9ce9d3883ed2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fc51204a-b666-4383-9e67-c527c4ed6831
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1f297ee6-b855-4e06-b0d2-641b99558078
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ab0b3635-ba7c-4c21-ab18-8a7001f9d5f2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b8cc5ee8-3822-4f7a-bd64-f4e7fae12b1c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bb11b0e8-b97f-497f-8056-a0996fe86ee6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cec21b0c-2279-4a31-8e88-367a22f4af84
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b0e7060b-b2e3-4052-a8ff-978dc1b979b9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cf55961d-be29-40df-b672-d73a170f1648
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3533eee1-e655-4b9b-8dca-1bb7616020f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 15e5eb58-450b-45da-aef3-43b933ef7e04
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fbf6741b-de06-4ea9-b6bc-957fd012d3d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bb5de27a-ed19-473c-b5bf-33652673d782
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0bf7334e-0d41-454d-b99a-b6ffa1898337
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 188f6bac-6678-4ca3-a922-8af33b4ebbe6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 91e90297-2869-4252-ab6c-853596462c82
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 812df360-6475-4bc4-9762-4ade6511c38b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d72276a6-533d-4895-92a1-67397f26b018
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 96e6b44a-c29d-4e47-adb2-958347300525
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a3a61730-c043-4241-b5d9-94ff65f6abe3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c27d050e-26f8-49f8-9a8f-2acaa529272d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e280bf02-3e21-4f8c-8a82-9c38b8304632
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9ee05adb-2c5b-4f3c-bc87-331dca817b18
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1372d21f-5012-43c3-8484-a140ad74a8eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cfc0557b-ebec-4853-b286-9fecf4322650
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 700abf3a-e7af-47c8-baa4-08b6ab389ab3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2ac9a877-1419-4900-bcba-213bd8105710
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 74b0e599-e300-46ca-b68d-a07e84d8580c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dcaf6842-0121-4eff-a661-bebfb1c7abb8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cdafafee-ad83-4080-9f56-8db5ec2abecb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 31b7e5d1-5126-4ee1-883f-c3a576a8ccf7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 693ee363-fcfc-49c5-9c88-1279daba2c5c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f55e5436-a84c-402e-abdc-1d004b9132c5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 48c06ab1-01a0-4faf-a9bf-c0bd6f16c867
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d06bb60e-d785-432c-9af8-f02c711fdd78
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c8748750-2dbd-4476-a290-83afaeed912f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 821faa77-782b-43de-ae7c-e69c1aac775f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 84dea8f8-49cf-40de-85bb-d2d19189ba97
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3f6ed25c-3317-4b7c-98ee-698bd5612f17
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7b40e2a9-9da4-4614-a45d-4f8703c241c3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0358eb85-903f-4f79-9ecf-02fde039e19a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8e093609-0b5e-4f4a-b038-4a060b46c189
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 669a8fe6-4a0b-4464-8cbc-b7a897e97807
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b07344ab-5d10-4567-93e3-8729203f3223
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6e58df21-81d0-42a3-b6ef-c5a538377807
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dd290e2c-9ff2-44b5-b517-d32b09824ba1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5a0522cd-e37f-439d-adb8-1633e3b67f73
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c7002fff-f755-466e-8c44-23d8aeaaf173
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 58741207-5702-4033-9497-eaa1638ab17e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 679db2f8-a26a-423d-a6e2-4e431cacddb3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2dab51ef-6ea3-4489-a4bd-a32f8b4b5730
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 35f5fc79-3b0f-486f-86ec-d6552baacc0c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 49011a7a-59a8-45c9-8886-9a62776327dd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6256317e-4085-40b5-bc0c-4510de9a4915
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 18a5404f-f539-437e-abb7-302e972f5581
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2a3eb89a-ac54-4f32-a4be-dc95d92df978
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c3573bab-5f99-4e9d-a1af-f9a53432c1fb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0e779db6-ceb4-40c3-8885-40828b8324e5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f865114c-7b4f-49c8-992c-8aff9b9e5aa2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 54e63bb9-5863-4296-914e-260eb41674b6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 43cc3fb4-d088-4b2f-a49e-175099b25e3d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4f827684-97df-4575-ab8e-dfe3f90febbe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2615c2fe-93ba-45d1-8827-1f32c08094dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 83a5743c-1211-4fb1-a94c-1b31f4529f5e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 43b1cacf-248b-4b6b-a5dd-bcecd1b6215c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 381c320b-44fb-4b4c-8446-1ff5bf12046f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6c8a7a75-b4f5-4fc5-8f36-c16f0759bd5d
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8687 {grpc_message:"Socket closed", grpc_status:14}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_52
Server: localhost:8687
Algorithm: FEDAVG
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_52
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_52/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_52/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_52/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_52/test_labels.txt

📊 Raw data loaded:
   Train: X=(1116, 24), y=(1116,)
   Test:  X=(280, 24), y=(280,)

⚠️  Limiting training data: 1116 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  271 samples, 5 features
✅ Client client_52 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

============================================================
🔄 Round 7 - Client client_52
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0891 (↓), lr=0.001000
   ✓ Epoch   2/100: train=0.0797, val=0.0883 (↓), lr=0.001000
   • Epoch   3/100: train=0.0792, val=0.0883, patience=1/15, lr=0.001000
   ✓ Epoch   4/100: train=0.0786, val=0.0869 (↓), lr=0.001000
   • Epoch   5/100: train=0.0779, val=0.0875, patience=1/15, lr=0.001000
   • Epoch  11/100: train=0.0746, val=0.0875, patience=5/15, lr=0.001000
   📉 Epoch 12: LR reduced 0.001000 → 0.000500
   📉 Epoch 20: LR reduced 0.000500 → 0.000250
   • Epoch  21/100: train=0.0684, val=0.0899, patience=15/15, lr=0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 7 Summary - Client client_52
   Epochs: 21/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0761, RMSE=0.2759, R²=0.0755
   Val:   Loss=0.0860, RMSE=0.2932, R²=0.0548
============================================================


📊 Round 7 Test Metrics:
   Loss: 0.0751, RMSE: 0.2740, MAE: 0.2381, R²: 0.0379

📊 Round 7 Test Metrics:
   Loss: 0.0751, RMSE: 0.2740, MAE: 0.2378, R²: 0.0379

📊 Round 7 Test Metrics:
   Loss: 0.0749, RMSE: 0.2736, MAE: 0.2375, R²: 0.0404

============================================================
🔄 Round 11 - Client client_52
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0878 (↓), lr=0.000250
   ✓ Epoch   2/100: train=0.0795, val=0.0868 (↓), lr=0.000250
   • Epoch   3/100: train=0.0790, val=0.0868, patience=1/15, lr=0.000250
   • Epoch   4/100: train=0.0787, val=0.0867, patience=2/15, lr=0.000250
   • Epoch   5/100: train=0.0784, val=0.0866, patience=3/15, lr=0.000250
   📉 Epoch 7: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0773, val=0.0861, patience=3/15, lr=0.000125
   📉 Epoch 15: LR reduced 0.000125 → 0.000063
   • Epoch  21/100: train=0.0766, val=0.0859, patience=13/15, lr=0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 11 Summary - Client client_52
   Epochs: 23/100 (early stopped)
   LR: 0.000250 → 0.000063 (2 reductions)
   Train: Loss=0.0772, RMSE=0.2778, R²=0.0624
   Val:   Loss=0.0863, RMSE=0.2937, R²=0.0385
============================================================


📊 Round 11 Test Metrics:
   Loss: 0.0749, RMSE: 0.2737, MAE: 0.2376, R²: 0.0400

============================================================
🔄 Round 12 - Client client_52
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0841 (↓), lr=0.000063
   • Epoch   2/100: train=0.0803, val=0.0838, patience=1/15, lr=0.000063
   ✓ Epoch   3/100: train=0.0801, val=0.0836 (↓), lr=0.000063
   • Epoch   4/100: train=0.0800, val=0.0834, patience=1/15, lr=0.000063
   • Epoch   5/100: train=0.0799, val=0.0833, patience=2/15, lr=0.000063
   • Epoch  11/100: train=0.0792, val=0.0832, patience=8/15, lr=0.000063
   📉 Epoch 13: LR reduced 0.000063 → 0.000031

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 12 Summary - Client client_52
   Epochs: 18/100 (early stopped)
   LR: 0.000063 → 0.000031 (1 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=0.0441
   Val:   Loss=0.0836, RMSE=0.2891, R²=0.0228
============================================================


📊 Round 12 Test Metrics:
   Loss: 0.0749, RMSE: 0.2736, MAE: 0.2376, R²: 0.0404

📊 Round 12 Test Metrics:
   Loss: 0.0746, RMSE: 0.2732, MAE: 0.2371, R²: 0.0436

============================================================
🔄 Round 17 - Client client_52
   Epochs: 100, Batch: 32, LR: 0.000031
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0795 (↓), lr=0.000031
   • Epoch   2/100: train=0.0806, val=0.0794, patience=1/15, lr=0.000031
   • Epoch   3/100: train=0.0805, val=0.0793, patience=2/15, lr=0.000031
   • Epoch   4/100: train=0.0803, val=0.0793, patience=3/15, lr=0.000031
   • Epoch   5/100: train=0.0802, val=0.0793, patience=4/15, lr=0.000031
   • Epoch  11/100: train=0.0799, val=0.0791, patience=10/15, lr=0.000031
   • Epoch  21/100: train=0.0794, val=0.0789, patience=6/15, lr=0.000031

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 17 Summary - Client client_52
   Epochs: 30/100 (early stopped)
   LR: 0.000031 → 0.000031 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=0.0569
   Val:   Loss=0.0790, RMSE=0.2811, R²=0.0230
============================================================


============================================================
🔄 Round 19 - Client client_52
   Epochs: 100, Batch: 32, LR: 0.000031
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0792 (↓), lr=0.000031
   • Epoch   2/100: train=0.0811, val=0.0790, patience=1/15, lr=0.000031
   • Epoch   3/100: train=0.0809, val=0.0788, patience=2/15, lr=0.000031
   • Epoch   4/100: train=0.0807, val=0.0787, patience=3/15, lr=0.000031
   • Epoch   5/100: train=0.0806, val=0.0787, patience=4/15, lr=0.000031
   • Epoch  11/100: train=0.0801, val=0.0787, patience=10/15, lr=0.000031
   📉 Epoch 15: LR reduced 0.000031 → 0.000016

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 19 Summary - Client client_52
   Epochs: 16/100 (early stopped)
   LR: 0.000031 → 0.000016 (1 reductions)
   Train: Loss=0.0810, RMSE=0.2847, R²=0.0418
   Val:   Loss=0.0792, RMSE=0.2814, R²=0.0322
============================================================


📊 Round 19 Test Metrics:
   Loss: 0.0745, RMSE: 0.2730, MAE: 0.2369, R²: 0.0448

============================================================
🔄 Round 21 - Client client_52
   Epochs: 100, Batch: 32, LR: 0.000016
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0755 (↓), lr=0.000016
   • Epoch   2/100: train=0.0820, val=0.0754, patience=1/15, lr=0.000016
   • Epoch   3/100: train=0.0819, val=0.0753, patience=2/15, lr=0.000016
   • Epoch   4/100: train=0.0818, val=0.0753, patience=3/15, lr=0.000016
   • Epoch   5/100: train=0.0818, val=0.0752, patience=4/15, lr=0.000016
   • Epoch  11/100: train=0.0815, val=0.0752, patience=10/15, lr=0.000016

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0755)

============================================================
📊 Round 21 Summary - Client client_52
   Epochs: 16/100 (early stopped)
   LR: 0.000016 → 0.000016 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=0.0458
   Val:   Loss=0.0755, RMSE=0.2747, R²=0.0248
============================================================


============================================================
🔄 Round 22 - Client client_52
   Epochs: 100, Batch: 32, LR: 0.000016
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0854 (↓), lr=0.000016
   • Epoch   2/100: train=0.0793, val=0.0855, patience=1/15, lr=0.000016
   • Epoch   3/100: train=0.0792, val=0.0855, patience=2/15, lr=0.000016
   • Epoch   4/100: train=0.0791, val=0.0856, patience=3/15, lr=0.000016
   • Epoch   5/100: train=0.0790, val=0.0856, patience=4/15, lr=0.000016
   📉 Epoch 6: LR reduced 0.000016 → 0.000008
   • Epoch  11/100: train=0.0788, val=0.0857, patience=10/15, lr=0.000008
   📉 Epoch 14: LR reduced 0.000008 → 0.000004

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 22 Summary - Client client_52
   Epochs: 16/100 (early stopped)
   LR: 0.000016 → 0.000004 (2 reductions)
   Train: Loss=0.0793, RMSE=0.2817, R²=0.0390
   Val:   Loss=0.0854, RMSE=0.2922, R²=0.0433
============================================================


📊 Round 22 Test Metrics:
   Loss: 0.0744, RMSE: 0.2727, MAE: 0.2367, R²: 0.0469

============================================================
🔄 Round 23 - Client client_52
   Epochs: 100, Batch: 32, LR: 0.000004
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0763 (↓), lr=0.000004
   • Epoch   2/100: train=0.0818, val=0.0763, patience=1/15, lr=0.000004
   • Epoch   3/100: train=0.0817, val=0.0763, patience=2/15, lr=0.000004
   • Epoch   4/100: train=0.0817, val=0.0763, patience=3/15, lr=0.000004
   • Epoch   5/100: train=0.0817, val=0.0763, patience=4/15, lr=0.000004
   📉 Epoch 6: LR reduced 0.000004 → 0.000002
   • Epoch  11/100: train=0.0815, val=0.0763, patience=10/15, lr=0.000002
   📉 Epoch 14: LR reduced 0.000002 → 0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0763)

============================================================
📊 Round 23 Summary - Client client_52
   Epochs: 16/100 (early stopped)
   LR: 0.000004 → 0.000001 (2 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=0.0324
   Val:   Loss=0.0763, RMSE=0.2763, R²=0.0736
============================================================


============================================================
🔄 Round 24 - Client client_52
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 24 Summary - Client client_52
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=0.0392
   Val:   Loss=0.0812, RMSE=0.2850, R²=0.0377
============================================================


============================================================
🔄 Round 29 - Client client_52
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 29 Summary - Client client_52
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=0.0369
   Val:   Loss=0.0843, RMSE=0.2903, R²=0.0533
============================================================


============================================================
🔄 Round 30 - Client client_52
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 30 Summary - Client client_52
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2845, R²=0.0388
   Val:   Loss=0.0794, RMSE=0.2818, R²=0.0475
============================================================


📊 Round 30 Test Metrics:
   Loss: 0.0743, RMSE: 0.2727, MAE: 0.2367, R²: 0.0470

============================================================
🔄 Round 31 - Client client_52
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 31 Summary - Client client_52
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=0.0436
   Val:   Loss=0.0802, RMSE=0.2833, R²=0.0261
============================================================


============================================================
🔄 Round 33 - Client client_52
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0768 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0768, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0768, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0768, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0768, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0768, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0768)

============================================================
📊 Round 33 Summary - Client client_52
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=0.0458
   Val:   Loss=0.0768, RMSE=0.2771, R²=0.0190
============================================================


📊 Round 33 Test Metrics:
   Loss: 0.0743, RMSE: 0.2726, MAE: 0.2367, R²: 0.0471

============================================================
🔄 Round 34 - Client client_52
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 34 Summary - Client client_52
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2845, R²=0.0356
   Val:   Loss=0.0793, RMSE=0.2817, R²=0.0570
============================================================


📊 Round 34 Test Metrics:
   Loss: 0.0743, RMSE: 0.2726, MAE: 0.2367, R²: 0.0471

============================================================
🔄 Round 38 - Client client_52
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0783, val=0.0900 (↓), lr=0.000001
   • Epoch   2/100: train=0.0783, val=0.0900, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0783, val=0.0900, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0783, val=0.0900, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0783, val=0.0900, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0782, val=0.0899, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0900)

============================================================
📊 Round 38 Summary - Client client_52
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0783, RMSE=0.2798, R²=0.0419
   Val:   Loss=0.0900, RMSE=0.3000, R²=0.0371
============================================================


📊 Round 38 Test Metrics:
   Loss: 0.0743, RMSE: 0.2726, MAE: 0.2367, R²: 0.0472

============================================================
🔄 Round 39 - Client client_52
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0770 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0770, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0770, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0770, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0770, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0769, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0770)

============================================================
📊 Round 39 Summary - Client client_52
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=0.0342
   Val:   Loss=0.0770, RMSE=0.2775, R²=0.0692
============================================================


📊 Round 39 Test Metrics:
   Loss: 0.0743, RMSE: 0.2726, MAE: 0.2367, R²: 0.0472

============================================================
🔄 Round 40 - Client client_52
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 40 Summary - Client client_52
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=0.0408
   Val:   Loss=0.0790, RMSE=0.2811, R²=0.0124
============================================================


============================================================
🔄 Round 41 - Client client_52
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 41 Summary - Client client_52
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2824, R²=0.0424
   Val:   Loss=0.0840, RMSE=0.2898, R²=0.0331
============================================================


📊 Round 41 Test Metrics:
   Loss: 0.0743, RMSE: 0.2726, MAE: 0.2367, R²: 0.0473

============================================================
🔄 Round 42 - Client client_52
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0774 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0774, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0774, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0774, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0774, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0774, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0774)

============================================================
📊 Round 42 Summary - Client client_52
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=0.0437
   Val:   Loss=0.0774, RMSE=0.2782, R²=0.0306
============================================================


============================================================
🔄 Round 44 - Client client_52
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0767 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0767, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0767, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0767, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0767, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0767, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0767)

============================================================
📊 Round 44 Summary - Client client_52
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=0.0452
   Val:   Loss=0.0767, RMSE=0.2769, R²=0.0177
============================================================


📊 Round 44 Test Metrics:
   Loss: 0.0743, RMSE: 0.2726, MAE: 0.2366, R²: 0.0473

============================================================
🔄 Round 45 - Client client_52
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0879 (↓), lr=0.000001
   • Epoch   2/100: train=0.0787, val=0.0879, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0879, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0879, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0879, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0878, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0879)

============================================================
📊 Round 45 Summary - Client client_52
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2807, R²=0.0361
   Val:   Loss=0.0879, RMSE=0.2964, R²=0.0588
============================================================


📊 Round 45 Test Metrics:
   Loss: 0.0743, RMSE: 0.2726, MAE: 0.2366, R²: 0.0474

📊 Round 45 Test Metrics:
   Loss: 0.0743, RMSE: 0.2726, MAE: 0.2366, R²: 0.0474

============================================================
🔄 Round 49 - Client client_52
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 49 Summary - Client client_52
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=0.0400
   Val:   Loss=0.0814, RMSE=0.2853, R²=0.0460
============================================================


============================================================
🔄 Round 50 - Client client_52
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0769 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0769, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0769, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0769, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0769, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0768, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0769)

============================================================
📊 Round 50 Summary - Client client_52
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=0.0424
   Val:   Loss=0.0769, RMSE=0.2773, R²=0.0353
============================================================


📊 Round 50 Test Metrics:
   Loss: 0.0743, RMSE: 0.2726, MAE: 0.2366, R²: 0.0474

============================================================
🔄 Round 51 - Client client_52
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0731 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0731, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0731, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0731, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0730, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0730, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0731)

============================================================
📊 Round 51 Summary - Client client_52
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=0.0386
   Val:   Loss=0.0731, RMSE=0.2703, R²=0.0527
============================================================


📊 Round 51 Test Metrics:
   Loss: 0.0743, RMSE: 0.2726, MAE: 0.2366, R²: 0.0474

📊 Round 51 Test Metrics:
   Loss: 0.0743, RMSE: 0.2726, MAE: 0.2366, R²: 0.0475

📊 Round 51 Test Metrics:
   Loss: 0.0743, RMSE: 0.2726, MAE: 0.2366, R²: 0.0475

📊 Round 51 Test Metrics:
   Loss: 0.0743, RMSE: 0.2726, MAE: 0.2366, R²: 0.0475

============================================================
🔄 Round 58 - Client client_52
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 58 Summary - Client client_52
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=0.0521
   Val:   Loss=0.0790, RMSE=0.2810, R²=-0.0069
============================================================


📊 Round 58 Test Metrics:
   Loss: 0.0743, RMSE: 0.2726, MAE: 0.2366, R²: 0.0475

============================================================
🔄 Round 60 - Client client_52
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0864, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0864, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 60 Summary - Client client_52
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2814, R²=0.0370
   Val:   Loss=0.0864, RMSE=0.2939, R²=0.0565
============================================================


📊 Round 60 Test Metrics:
   Loss: 0.0743, RMSE: 0.2726, MAE: 0.2366, R²: 0.0475

============================================================
🔄 Round 62 - Client client_52
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 62 Summary - Client client_52
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=0.0404
   Val:   Loss=0.0781, RMSE=0.2795, R²=0.0419
============================================================


📊 Round 62 Test Metrics:
   Loss: 0.0743, RMSE: 0.2726, MAE: 0.2366, R²: 0.0476

📊 Round 62 Test Metrics:
   Loss: 0.0743, RMSE: 0.2726, MAE: 0.2366, R²: 0.0476

============================================================
🔄 Round 67 - Client client_52
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0779 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0779, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0779, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0779, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0779, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0779, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0779)

============================================================
📊 Round 67 Summary - Client client_52
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=0.0361
   Val:   Loss=0.0779, RMSE=0.2791, R²=0.0531
============================================================


📊 Round 67 Test Metrics:
   Loss: 0.0743, RMSE: 0.2726, MAE: 0.2366, R²: 0.0478

📊 Round 67 Test Metrics:
   Loss: 0.0743, RMSE: 0.2725, MAE: 0.2366, R²: 0.0478

============================================================
🔄 Round 71 - Client client_52
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0755 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0754, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0754, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0754, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0754, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0754, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0755)

============================================================
📊 Round 71 Summary - Client client_52
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2861, R²=0.0461
   Val:   Loss=0.0755, RMSE=0.2747, R²=0.0204
============================================================


📊 Round 71 Test Metrics:
   Loss: 0.0743, RMSE: 0.2725, MAE: 0.2366, R²: 0.0479

============================================================
🔄 Round 73 - Client client_52
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0740 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0740, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0740, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0740, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0740, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0739, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0740)

============================================================
📊 Round 73 Summary - Client client_52
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2868, R²=0.0400
   Val:   Loss=0.0740, RMSE=0.2720, R²=0.0444
============================================================


============================================================
🔄 Round 74 - Client client_52
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 74 Summary - Client client_52
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2833, R²=0.0372
   Val:   Loss=0.0820, RMSE=0.2863, R²=0.0429
============================================================


============================================================
🔄 Round 76 - Client client_52
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0874 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0874, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0875, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0875, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0875, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0876, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0874)

============================================================
📊 Round 76 Summary - Client client_52
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2808, R²=0.0341
   Val:   Loss=0.0874, RMSE=0.2956, R²=0.0362
============================================================


📊 Round 76 Test Metrics:
   Loss: 0.0743, RMSE: 0.2725, MAE: 0.2366, R²: 0.0480

📊 Round 76 Test Metrics:
   Loss: 0.0743, RMSE: 0.2725, MAE: 0.2366, R²: 0.0480

📊 Round 76 Test Metrics:
   Loss: 0.0743, RMSE: 0.2725, MAE: 0.2366, R²: 0.0480

============================================================
🔄 Round 79 - Client client_52
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 79 Summary - Client client_52
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=0.0367
   Val:   Loss=0.0794, RMSE=0.2818, R²=0.0591
============================================================


📊 Round 79 Test Metrics:
   Loss: 0.0743, RMSE: 0.2725, MAE: 0.2366, R²: 0.0480

============================================================
🔄 Round 80 - Client client_52
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 80 Summary - Client client_52
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=0.0454
   Val:   Loss=0.0806, RMSE=0.2839, R²=0.0252
============================================================


📊 Round 80 Test Metrics:
   Loss: 0.0743, RMSE: 0.2725, MAE: 0.2366, R²: 0.0481

============================================================
🔄 Round 81 - Client client_52
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 81 Summary - Client client_52
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2840, R²=0.0419
   Val:   Loss=0.0803, RMSE=0.2833, R²=0.0154
============================================================


============================================================
🔄 Round 82 - Client client_52
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 82 Summary - Client client_52
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=0.0435
   Val:   Loss=0.0830, RMSE=0.2882, R²=0.0026
============================================================


============================================================
🔄 Round 83 - Client client_52
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 83 Summary - Client client_52
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2821, R²=0.0395
   Val:   Loss=0.0845, RMSE=0.2908, R²=0.0469
============================================================


============================================================
🔄 Round 84 - Client client_52
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 84 Summary - Client client_52
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=0.0353
   Val:   Loss=0.0785, RMSE=0.2802, R²=0.0663
============================================================


📊 Round 84 Test Metrics:
   Loss: 0.0743, RMSE: 0.2725, MAE: 0.2366, R²: 0.0481

📊 Round 84 Test Metrics:
   Loss: 0.0743, RMSE: 0.2725, MAE: 0.2366, R²: 0.0481

📊 Round 84 Test Metrics:
   Loss: 0.0743, RMSE: 0.2725, MAE: 0.2366, R²: 0.0482

============================================================
🔄 Round 89 - Client client_52
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 89 Summary - Client client_52
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2820, R²=0.0433
   Val:   Loss=0.0849, RMSE=0.2913, R²=0.0095
============================================================


============================================================
🔄 Round 91 - Client client_52
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 91 Summary - Client client_52
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=0.0424
   Val:   Loss=0.0800, RMSE=0.2828, R²=0.0386
============================================================


============================================================
🔄 Round 92 - Client client_52
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0773, val=0.0941 (↓), lr=0.000001
   • Epoch   2/100: train=0.0773, val=0.0941, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0773, val=0.0941, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0772, val=0.0941, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0772, val=0.0941, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0771, val=0.0942, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0941)

============================================================
📊 Round 92 Summary - Client client_52
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0772, RMSE=0.2779, R²=0.0364
   Val:   Loss=0.0941, RMSE=0.3067, R²=0.0388
============================================================


📊 Round 92 Test Metrics:
   Loss: 0.0742, RMSE: 0.2725, MAE: 0.2366, R²: 0.0483

📊 Round 92 Test Metrics:
   Loss: 0.0742, RMSE: 0.2725, MAE: 0.2365, R²: 0.0483

============================================================
🔄 Round 94 - Client client_52
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 94 Summary - Client client_52
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=0.0432
   Val:   Loss=0.0836, RMSE=0.2891, R²=0.0323
============================================================


📊 Round 94 Test Metrics:
   Loss: 0.0742, RMSE: 0.2725, MAE: 0.2365, R²: 0.0483

============================================================
🔄 Round 95 - Client client_52
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 95 Summary - Client client_52
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=0.0395
   Val:   Loss=0.0796, RMSE=0.2821, R²=0.0489
============================================================


📊 Round 95 Test Metrics:
   Loss: 0.0742, RMSE: 0.2725, MAE: 0.2365, R²: 0.0484

📊 Round 95 Test Metrics:
   Loss: 0.0742, RMSE: 0.2725, MAE: 0.2365, R²: 0.0484

============================================================
🔄 Round 98 - Client client_52
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 98 Summary - Client client_52
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=0.0466
   Val:   Loss=0.0829, RMSE=0.2879, R²=0.0184
============================================================


📊 Round 98 Test Metrics:
   Loss: 0.0742, RMSE: 0.2725, MAE: 0.2365, R²: 0.0485

============================================================
🔄 Round 100 - Client client_52
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0765 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0765, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0765, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0765, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0765, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0765, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0765)

============================================================
📊 Round 100 Summary - Client client_52
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=0.0406
   Val:   Loss=0.0765, RMSE=0.2766, R²=0.0176
============================================================


============================================================
🔄 Round 101 - Client client_52
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 101 Summary - Client client_52
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2831, R²=0.0519
   Val:   Loss=0.0822, RMSE=0.2868, R²=-0.0001
============================================================


============================================================
🔄 Round 102 - Client client_52
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0782, val=0.0902 (↓), lr=0.000001
   • Epoch   2/100: train=0.0782, val=0.0902, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0782, val=0.0902, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0782, val=0.0902, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0782, val=0.0902, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0782, val=0.0901, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0902)

============================================================
📊 Round 102 Summary - Client client_52
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0781, RMSE=0.2795, R²=0.0478
   Val:   Loss=0.0902, RMSE=0.3004, R²=0.0190
============================================================


============================================================
🔄 Round 103 - Client client_52
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0729 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0729, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0729, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0729, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0729, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0730, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0729)

============================================================
📊 Round 103 Summary - Client client_52
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=0.0380
   Val:   Loss=0.0729, RMSE=0.2699, R²=0.0396
============================================================


📊 Round 103 Test Metrics:
   Loss: 0.0742, RMSE: 0.2724, MAE: 0.2365, R²: 0.0486

📊 Round 103 Test Metrics:
   Loss: 0.0742, RMSE: 0.2724, MAE: 0.2365, R²: 0.0486

📊 Round 103 Test Metrics:
   Loss: 0.0742, RMSE: 0.2724, MAE: 0.2365, R²: 0.0486

📊 Round 103 Test Metrics:
   Loss: 0.0742, RMSE: 0.2724, MAE: 0.2365, R²: 0.0486

📊 Round 103 Test Metrics:
   Loss: 0.0742, RMSE: 0.2724, MAE: 0.2365, R²: 0.0487

📊 Round 103 Test Metrics:
   Loss: 0.0742, RMSE: 0.2724, MAE: 0.2365, R²: 0.0487

============================================================
🔄 Round 109 - Client client_52
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0755 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0755, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0755, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0755, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0755, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0755, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0755)

============================================================
📊 Round 109 Summary - Client client_52
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=0.0394
   Val:   Loss=0.0755, RMSE=0.2749, R²=0.0480
============================================================


============================================================
🔄 Round 110 - Client client_52
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 110 Summary - Client client_52
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=0.0375
   Val:   Loss=0.0818, RMSE=0.2861, R²=0.0588
============================================================


📊 Round 110 Test Metrics:
   Loss: 0.0742, RMSE: 0.2724, MAE: 0.2365, R²: 0.0487

============================================================
🔄 Round 111 - Client client_52
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 111 Summary - Client client_52
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2833, R²=0.0299
   Val:   Loss=0.0818, RMSE=0.2859, R²=0.0863
============================================================


📊 Round 111 Test Metrics:
   Loss: 0.0742, RMSE: 0.2724, MAE: 0.2365, R²: 0.0488

============================================================
🔄 Round 115 - Client client_52
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 115 Summary - Client client_52
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2818, R²=0.0486
   Val:   Loss=0.0851, RMSE=0.2917, R²=0.0081
============================================================


============================================================
🔄 Round 116 - Client client_52
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 116 Summary - Client client_52
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=0.0427
   Val:   Loss=0.0804, RMSE=0.2836, R²=0.0391
============================================================


📊 Round 116 Test Metrics:
   Loss: 0.0742, RMSE: 0.2724, MAE: 0.2365, R²: 0.0490

📊 Round 116 Test Metrics:
   Loss: 0.0742, RMSE: 0.2724, MAE: 0.2365, R²: 0.0491

📊 Round 116 Test Metrics:
   Loss: 0.0742, RMSE: 0.2724, MAE: 0.2365, R²: 0.0490

============================================================
🔄 Round 124 - Client client_52
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 124 Summary - Client client_52
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=0.0393
   Val:   Loss=0.0796, RMSE=0.2822, R²=0.0486
============================================================


📊 Round 124 Test Metrics:
   Loss: 0.0742, RMSE: 0.2724, MAE: 0.2365, R²: 0.0490

============================================================
🔄 Round 126 - Client client_52
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0773, val=0.0933 (↓), lr=0.000001
   • Epoch   2/100: train=0.0773, val=0.0933, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0773, val=0.0933, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0773, val=0.0932, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0773, val=0.0932, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0773, val=0.0932, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0933)

============================================================
📊 Round 126 Summary - Client client_52
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0774, RMSE=0.2781, R²=0.0445
   Val:   Loss=0.0933, RMSE=0.3054, R²=0.0333
============================================================


============================================================
🔄 Round 128 - Client client_52
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 128 Summary - Client client_52
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2833, R²=0.0498
   Val:   Loss=0.0817, RMSE=0.2858, R²=0.0100
============================================================


============================================================
🔄 Round 129 - Client client_52
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 129 Summary - Client client_52
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=0.0448
   Val:   Loss=0.0791, RMSE=0.2813, R²=0.0301
============================================================


📊 Round 129 Test Metrics:
   Loss: 0.0742, RMSE: 0.2724, MAE: 0.2365, R²: 0.0491

============================================================
🔄 Round 133 - Client client_52
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 133 Summary - Client client_52
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2817, R²=0.0451
   Val:   Loss=0.0852, RMSE=0.2919, R²=0.0144
============================================================


📊 Round 133 Test Metrics:
   Loss: 0.0742, RMSE: 0.2723, MAE: 0.2365, R²: 0.0492

============================================================
🔄 Round 134 - Client client_52
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0773, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0773, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 134 Summary - Client client_52
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2852, R²=0.0419
   Val:   Loss=0.0773, RMSE=0.2780, R²=0.0340
============================================================


📊 Round 134 Test Metrics:
   Loss: 0.0742, RMSE: 0.2723, MAE: 0.2365, R²: 0.0492

📊 Round 134 Test Metrics:
   Loss: 0.0742, RMSE: 0.2723, MAE: 0.2364, R²: 0.0492

============================================================
🔄 Round 138 - Client client_52
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0758 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0758, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0758, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0758, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0758, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0758, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0758)

============================================================
📊 Round 138 Summary - Client client_52
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=0.0335
   Val:   Loss=0.0758, RMSE=0.2753, R²=0.0771
============================================================


📊 Round 138 Test Metrics:
   Loss: 0.0742, RMSE: 0.2723, MAE: 0.2364, R²: 0.0492

📊 Round 138 Test Metrics:
   Loss: 0.0742, RMSE: 0.2723, MAE: 0.2364, R²: 0.0492

============================================================
🔄 Round 141 - Client client_52
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0759 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0759, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0759, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0759, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0759, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0760, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0759)

============================================================
📊 Round 141 Summary - Client client_52
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=0.0387
   Val:   Loss=0.0759, RMSE=0.2756, R²=0.0529
============================================================


============================================================
🔄 Round 142 - Client client_52
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0879 (↓), lr=0.000001
   • Epoch   2/100: train=0.0785, val=0.0879, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0785, val=0.0879, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0879, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0879, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0879, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0879)

============================================================
📊 Round 142 Summary - Client client_52
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2805, R²=0.0474
   Val:   Loss=0.0879, RMSE=0.2965, R²=0.0191
============================================================


============================================================
🔄 Round 143 - Client client_52
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0731 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0731, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0731, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0731, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0731, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0731, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0731)

============================================================
📊 Round 143 Summary - Client client_52
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=0.0356
   Val:   Loss=0.0731, RMSE=0.2704, R²=0.0707
============================================================


📊 Round 143 Test Metrics:
   Loss: 0.0742, RMSE: 0.2723, MAE: 0.2364, R²: 0.0493

============================================================
🔄 Round 145 - Client client_52
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0776 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0776, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0776, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0776, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0776, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 145 Summary - Client client_52
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2850, R²=0.0440
   Val:   Loss=0.0776, RMSE=0.2786, R²=0.0243
============================================================


============================================================
🔄 Round 146 - Client client_52
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 146 Summary - Client client_52
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=0.0407
   Val:   Loss=0.0817, RMSE=0.2859, R²=0.0442
============================================================


📊 Round 146 Test Metrics:
   Loss: 0.0742, RMSE: 0.2723, MAE: 0.2364, R²: 0.0494

============================================================
🔄 Round 148 - Client client_52
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0776 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0776, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0776, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0776, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0776, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 148 Summary - Client client_52
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=0.0351
   Val:   Loss=0.0776, RMSE=0.2786, R²=0.0667
============================================================


📊 Round 148 Test Metrics:
   Loss: 0.0742, RMSE: 0.2723, MAE: 0.2364, R²: 0.0494

============================================================
🔄 Round 149 - Client client_52
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 149 Summary - Client client_52
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=0.0297
   Val:   Loss=0.0787, RMSE=0.2805, R²=0.0314
============================================================


📊 Round 149 Test Metrics:
   Loss: 0.0742, RMSE: 0.2723, MAE: 0.2364, R²: 0.0494

📊 Round 149 Test Metrics:
   Loss: 0.0742, RMSE: 0.2723, MAE: 0.2364, R²: 0.0495

📊 Round 149 Test Metrics:
   Loss: 0.0742, RMSE: 0.2723, MAE: 0.2364, R²: 0.0495

============================================================
🔄 Round 152 - Client client_52
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 152 Summary - Client client_52
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2816, R²=0.0369
   Val:   Loss=0.0854, RMSE=0.2922, R²=0.0438
============================================================


============================================================
🔄 Round 153 - Client client_52
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 153 Summary - Client client_52
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=0.0329
   Val:   Loss=0.0802, RMSE=0.2832, R²=0.0722
============================================================


============================================================
🔄 Round 154 - Client client_52
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 154 Summary - Client client_52
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2845, R²=0.0413
   Val:   Loss=0.0789, RMSE=0.2810, R²=0.0459
============================================================


📊 Round 154 Test Metrics:
   Loss: 0.0741, RMSE: 0.2723, MAE: 0.2364, R²: 0.0496

============================================================
🔄 Round 156 - Client client_52
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 156 Summary - Client client_52
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=0.0548
   Val:   Loss=0.0819, RMSE=0.2862, R²=-0.0193
============================================================


============================================================
🔄 Round 157 - Client client_52
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 157 Summary - Client client_52
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2845, R²=0.0368
   Val:   Loss=0.0788, RMSE=0.2807, R²=0.0589
============================================================


📊 Round 157 Test Metrics:
   Loss: 0.0741, RMSE: 0.2723, MAE: 0.2364, R²: 0.0496

📊 Round 157 Test Metrics:
   Loss: 0.0741, RMSE: 0.2723, MAE: 0.2364, R²: 0.0496

============================================================
🔄 Round 159 - Client client_52
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0772 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0772, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0772, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0772, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0772, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0771, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 159 Summary - Client client_52
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2852, R²=0.0421
   Val:   Loss=0.0772, RMSE=0.2779, R²=0.0333
============================================================


============================================================
🔄 Round 160 - Client client_52
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0756 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0756, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0756, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0756, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0756, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0756, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0756)

============================================================
📊 Round 160 Summary - Client client_52
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=0.0311
   Val:   Loss=0.0756, RMSE=0.2750, R²=0.0874
============================================================


📊 Round 160 Test Metrics:
   Loss: 0.0741, RMSE: 0.2723, MAE: 0.2364, R²: 0.0496

============================================================
🔄 Round 163 - Client client_52
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0896 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0896, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0896, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0896, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0896, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0895, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0896)

============================================================
📊 Round 163 Summary - Client client_52
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0782, RMSE=0.2797, R²=0.0447
   Val:   Loss=0.0896, RMSE=0.2994, R²=0.0285
============================================================


📊 Round 163 Test Metrics:
   Loss: 0.0741, RMSE: 0.2723, MAE: 0.2364, R²: 0.0496

============================================================
🔄 Round 165 - Client client_52
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0723 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0723, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0723, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0723, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0723, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0723, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0723)

============================================================
📊 Round 165 Summary - Client client_52
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2873, R²=0.0446
   Val:   Loss=0.0723, RMSE=0.2690, R²=0.0289
============================================================


📊 Round 165 Test Metrics:
   Loss: 0.0741, RMSE: 0.2723, MAE: 0.2364, R²: 0.0497

============================================================
🔄 Round 166 - Client client_52
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 166 Summary - Client client_52
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=0.0471
   Val:   Loss=0.0819, RMSE=0.2861, R²=0.0127
============================================================


📊 Round 166 Test Metrics:
   Loss: 0.0741, RMSE: 0.2723, MAE: 0.2364, R²: 0.0497

============================================================
🔄 Round 167 - Client client_52
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 167 Summary - Client client_52
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=0.0497
   Val:   Loss=0.0793, RMSE=0.2817, R²=0.0097
============================================================


📊 Round 167 Test Metrics:
   Loss: 0.0741, RMSE: 0.2723, MAE: 0.2364, R²: 0.0497

============================================================
🔄 Round 168 - Client client_52
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 168 Summary - Client client_52
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=0.0503
   Val:   Loss=0.0797, RMSE=0.2822, R²=0.0066
============================================================


============================================================
🔄 Round 169 - Client client_52
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 169 Summary - Client client_52
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=0.0435
   Val:   Loss=0.0823, RMSE=0.2868, R²=0.0376
============================================================


📊 Round 169 Test Metrics:
   Loss: 0.0741, RMSE: 0.2723, MAE: 0.2364, R²: 0.0497

============================================================
🔄 Round 170 - Client client_52
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 170 Summary - Client client_52
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2820, R²=0.0410
   Val:   Loss=0.0845, RMSE=0.2907, R²=0.0473
============================================================


============================================================
🔄 Round 171 - Client client_52
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 171 Summary - Client client_52
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2831, R²=0.0498
   Val:   Loss=0.0819, RMSE=0.2862, R²=0.0056
============================================================


============================================================
🔄 Round 173 - Client client_52
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 173 Summary - Client client_52
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2824, R²=0.0365
   Val:   Loss=0.0835, RMSE=0.2889, R²=0.0574
============================================================


============================================================
🔄 Round 178 - Client client_52
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 178 Summary - Client client_52
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2819, R²=0.0468
   Val:   Loss=0.0846, RMSE=0.2909, R²=0.0257
============================================================


📊 Round 178 Test Metrics:
   Loss: 0.0741, RMSE: 0.2722, MAE: 0.2364, R²: 0.0499

============================================================
🔄 Round 179 - Client client_52
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 179 Summary - Client client_52
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=0.0465
   Val:   Loss=0.0825, RMSE=0.2872, R²=0.0210
============================================================


📊 Round 179 Test Metrics:
   Loss: 0.0741, RMSE: 0.2722, MAE: 0.2364, R²: 0.0499

============================================================
🔄 Round 182 - Client client_52
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 182 Summary - Client client_52
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2845, R²=0.0326
   Val:   Loss=0.0787, RMSE=0.2805, R²=0.0649
============================================================


📊 Round 182 Test Metrics:
   Loss: 0.0741, RMSE: 0.2722, MAE: 0.2364, R²: 0.0499

============================================================
🔄 Round 185 - Client client_52
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0725 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0725, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0725, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0725, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0725, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0724, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0725)

============================================================
📊 Round 185 Summary - Client client_52
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=0.0473
   Val:   Loss=0.0725, RMSE=0.2692, R²=0.0143
============================================================


📊 Round 185 Test Metrics:
   Loss: 0.0741, RMSE: 0.2722, MAE: 0.2363, R²: 0.0500

============================================================
🔄 Round 190 - Client client_52
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 190 Summary - Client client_52
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=0.0400
   Val:   Loss=0.0817, RMSE=0.2859, R²=0.0517
============================================================


📊 Round 190 Test Metrics:
   Loss: 0.0741, RMSE: 0.2722, MAE: 0.2363, R²: 0.0501

============================================================
🔄 Round 192 - Client client_52
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0711 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0711, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0711, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0711, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0711, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0711, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0711)

============================================================
📊 Round 192 Summary - Client client_52
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=0.0435
   Val:   Loss=0.0711, RMSE=0.2666, R²=0.0356
============================================================


============================================================
🔄 Round 194 - Client client_52
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 194 Summary - Client client_52
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2815, R²=0.0398
   Val:   Loss=0.0857, RMSE=0.2927, R²=0.0511
============================================================


📊 Round 194 Test Metrics:
   Loss: 0.0741, RMSE: 0.2722, MAE: 0.2363, R²: 0.0501

📊 Round 194 Test Metrics:
   Loss: 0.0741, RMSE: 0.2722, MAE: 0.2363, R²: 0.0501

📊 Round 194 Test Metrics:
   Loss: 0.0741, RMSE: 0.2722, MAE: 0.2363, R²: 0.0501

============================================================
🔄 Round 198 - Client client_52
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 198 Summary - Client client_52
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=0.0440
   Val:   Loss=0.0785, RMSE=0.2801, R²=0.0359
============================================================


📊 Round 198 Test Metrics:
   Loss: 0.0741, RMSE: 0.2722, MAE: 0.2363, R²: 0.0502

============================================================
🔄 Round 199 - Client client_52
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0774 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0774, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0774, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0774, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0774, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0774, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0774)

============================================================
📊 Round 199 Summary - Client client_52
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=0.0429
   Val:   Loss=0.0774, RMSE=0.2783, R²=0.0348
============================================================


============================================================
🔄 Round 200 - Client client_52
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 200 Summary - Client client_52
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=0.0423
   Val:   Loss=0.0805, RMSE=0.2837, R²=0.0403
============================================================


📊 Round 200 Test Metrics:
   Loss: 0.0741, RMSE: 0.2722, MAE: 0.2363, R²: 0.0502

============================================================
🔄 Round 202 - Client client_52
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0676 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0676, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0676, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0676, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0676, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0676, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0676)

============================================================
📊 Round 202 Summary - Client client_52
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=0.0408
   Val:   Loss=0.0676, RMSE=0.2600, R²=0.0504
============================================================


============================================================
🔄 Round 205 - Client client_52
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 205 Summary - Client client_52
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=0.0428
   Val:   Loss=0.0792, RMSE=0.2815, R²=0.0342
============================================================


📊 Round 205 Test Metrics:
   Loss: 0.0741, RMSE: 0.2722, MAE: 0.2363, R²: 0.0502

📊 Round 205 Test Metrics:
   Loss: 0.0741, RMSE: 0.2722, MAE: 0.2363, R²: 0.0503

============================================================
🔄 Round 208 - Client client_52
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 208 Summary - Client client_52
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2824, R²=0.0439
   Val:   Loss=0.0834, RMSE=0.2889, R²=0.0312
============================================================


📊 Round 208 Test Metrics:
   Loss: 0.0741, RMSE: 0.2722, MAE: 0.2363, R²: 0.0503

============================================================
🔄 Round 211 - Client client_52
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 211 Summary - Client client_52
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2840, R²=0.0333
   Val:   Loss=0.0800, RMSE=0.2828, R²=0.0702
============================================================


📊 Round 211 Test Metrics:
   Loss: 0.0741, RMSE: 0.2722, MAE: 0.2363, R²: 0.0505

============================================================
🔄 Round 214 - Client client_52
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 214 Summary - Client client_52
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=0.0507
   Val:   Loss=0.0837, RMSE=0.2893, R²=0.0082
============================================================


📊 Round 214 Test Metrics:
   Loss: 0.0741, RMSE: 0.2722, MAE: 0.2363, R²: 0.0505

============================================================
🔄 Round 218 - Client client_52
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 218 Summary - Client client_52
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2816, R²=0.0461
   Val:   Loss=0.0852, RMSE=0.2919, R²=0.0282
============================================================


============================================================
🔄 Round 219 - Client client_52
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 219 Summary - Client client_52
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=0.0502
   Val:   Loss=0.0829, RMSE=0.2879, R²=0.0116
============================================================


📊 Round 219 Test Metrics:
   Loss: 0.0741, RMSE: 0.2721, MAE: 0.2363, R²: 0.0506

============================================================
🔄 Round 223 - Client client_52
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0863 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 223 Summary - Client client_52
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2811, R²=0.0466
   Val:   Loss=0.0863, RMSE=0.2938, R²=0.0247
============================================================


============================================================
🔄 Round 224 - Client client_52
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 224 Summary - Client client_52
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=0.0461
   Val:   Loss=0.0801, RMSE=0.2831, R²=0.0240
============================================================


❌ Client client_52 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8687 {grpc_message:"Socket closed", grpc_status:14}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8687 {grpc_message:"Socket closed", grpc_status:14}"
>
