[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 71dbb8da-64ca-4003-b4a8-18f57abed6a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c2c3bed2-30c2-448a-befc-5597c845b451
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cfebb88a-7b77-4897-8058-e983ab9a1b26
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6d967fe9-62ab-4822-bbb7-b668fa82acd0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4ca42f70-76e2-4cff-9823-f9cd2a4762aa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 210e197a-8638-47f0-b10c-3d80b7095e72
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 489a91f9-839a-4c9f-bd69-cfec3032e4f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c89f7e9f-d342-4782-9807-e5a1a6437385
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d3a868fb-777b-44b9-a23b-6517e701e79c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b32df3b4-4a70-40a6-a48b-aa9f700681be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 215c2d2b-261f-44e0-83e0-4cd2964f713c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bb33b4cc-d586-466a-9b73-7acfd331f6a3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 54b5a025-8443-4ad2-b475-40e4b48cdf62
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a1fb1200-6e8a-48ac-ac92-3167497c0ce0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 91c24ab0-3266-44f1-9fbc-9fffb942eea4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bc958fa6-7978-4381-9a73-646a87716e90
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1892efbc-fead-4ba7-8f0f-1c4b20c99194
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 97a31709-9a20-418f-be91-49508fe05747
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9427f6d1-e54d-4da5-b0ab-e69a99da727c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 58869e79-8b46-4fbd-9907-12dbe40cb7bc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 881bc490-4281-40d9-bfab-827222f2ce46
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 13dabf3d-ea62-4787-98c9-907f90584b7b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 24acf537-c518-495e-a775-7d6f1e3290bc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fc8d0c1e-35cd-43a7-80af-e70fe5097b66
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c3d2b881-5a34-4ff8-b552-718e3db45c3a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bc99b838-1bda-4be9-83df-e1f3fcf29f9d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e01cdee8-4629-4212-b3c8-33b559135e27
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f9dab1f2-872a-4143-8635-dbc3d20178ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8d3647e0-e734-4cc4-9ef0-f1f5223f6935
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0202061f-50e5-46b8-8c25-a1ff6b28d88d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b57b1f4f-ad27-45e3-97b3-9735f0eb8888
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 722e5cb8-3b6b-49d6-b4a6-c9e660fa26cb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fdc6ee0c-9e25-400a-ad61-865a872412fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4462b3c4-8845-4bf3-a3df-a42c9ad4eddc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a582c913-f42c-4f2d-9141-9d392e510105
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bf772352-8381-4046-b01f-5284fa573d6b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8c642477-c7d9-4dce-856a-a2723556ae57
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7fdedda0-a1d4-4d51-9a31-b482db814adf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b09936b3-42cd-4a1f-b887-274673d0429b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d8f1ce1d-9185-4931-8965-7d531712e3fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 04cfd1a1-523f-4fb3-afd5-e0e55c922d7e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8d5698d8-b93d-430c-9b88-4559ed3dc506
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1afa789d-7f70-4715-9bf6-b69660e95d5e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 10f0de61-d8da-4792-8273-b9a9e615e749
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message db1cdb96-f684-4763-9b30-cb5cd2d02251
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8d20f127-4053-44a8-b5ba-c1f6c95301b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cb16e16c-3167-49c3-914e-ceb7386aa950
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d6f5d389-df98-4b4b-9d4f-1609e622c16f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8ad39073-243d-4529-b3c4-9c02f5261f88
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dfdebf6a-ed8a-4e12-9193-014dc9fc082d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 40f0d419-2985-4003-9d1c-9bc138268afe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 76b0ed16-d865-4ab6-a578-d0284659d7d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a66762a3-b2b5-4382-8fee-c77e71cb1e64
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 52db8456-b1d8-435b-9ba0-bbc23827a17f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 398ee237-7f80-4999-9a4a-f0bbb7bbd36f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3d0a63c1-bc5b-4db1-8eb5-ab33dacb114f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d53ced2b-c22c-40da-b239-4abca0d2fd70
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 52813206-7a92-409c-9dd5-319b0a51a45b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b7fd05d8-11b8-45e0-a0d9-e9fcb22580a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 21e7fc8f-b851-4916-91b8-533598845697
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 07b67282-7bfd-415e-b175-202f84e5c810
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3ba4d301-b367-44e1-9244-cd207136be46
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 49682aca-5f41-416b-9dc8-9d741fa9c98a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 431eb15a-3975-4746-8294-c6d16c041837
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b2945625-5799-4bb7-b113-d792d3902a16
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d09ec513-f372-46cb-8e85-7c0ae70279e5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d632b7df-cad3-4790-ba25-4035f1d7ba6f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c10652e4-d9c4-4baf-acb6-0957fef883da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8c4942b4-b960-4906-9e34-487536ab0912
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8aa52f37-c258-4894-890d-ce304cd3a1ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a43005d7-8d55-485e-9a88-858f56290900
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fc8a0a69-98f8-44c4-a9b5-0a9aeb438bbe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 94397348-aba0-45e6-935b-0d4d0bb8a338
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 418c4b30-66ba-4dbc-9404-61808f0aeafc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8a36d250-15a7-441b-9b9d-f348049f07ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c01faec5-0be1-4d0e-a2e7-af9454d6dbed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d8b9861a-ae58-4191-8697-a06fff6d364a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 96eef992-4f8f-4d04-b5a2-27dc2d81dde4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a656e130-5733-4968-806d-80ad1779cd37
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6cc9a049-81b2-4b2e-93f9-2ac3b1d46f96
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e8d8dd71-6391-4ade-ac82-318aa46ad27e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 185edf69-c74e-4f02-a811-b8b647ec337b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 11ed1c07-ee6b-4d54-b469-b3e4fec78fb9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message db927c89-abe7-4077-a710-2d3ca05deeed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 71651e81-fc0a-4b97-be4f-5d16e1e10055
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5cd95bca-eb8c-45a3-acc8-9cf239e53e3b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f90654c8-b7ee-446c-b76c-afeab94567c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6bed6189-2a9d-4195-87a7-53ec52c73853
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 592128b5-d1b5-4ed5-aa0a-d90ca866ec03
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 453b7908-44b8-4cb6-b006-83575273fe3a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9bc168c6-0acf-43d2-9b9c-871b7ed28a6d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c58f9df0-bf35-41e4-a484-ac75fbfb3d5d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 041e35f2-1046-40e8-a916-c086441218f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 168cb8e5-554e-4f44-83cf-6812052202b5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bc3e985a-5a27-4993-a1ba-493d64ee046e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a36a347a-f01f-44f6-b92b-70082a2ffd25
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 558371c1-bf50-45c4-8c26-12d97ba8ce0e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message df959dba-fe24-47a3-a8e7-20dcb3c05be8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2c815e50-d734-4816-ab21-845cd0e07ccd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9b1fee4f-90ec-44c4-9b62-f1122d9b7796
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5fadea02-540f-41fa-aa34-61c17cbc89e5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5205379f-7632-4c8a-89de-0c18e4c24a09
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fd5df8fb-35a0-4273-a4e7-4abed44613c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a46fb34e-8b96-4868-8021-77003d1fa519
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f523fb81-81bb-4f90-ab26-bf86a017dd7d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6a7471e4-359b-45c7-838e-f9282c4a1086
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c6753c0c-ccc7-47c4-af5c-8e27ed3b166c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b380c289-ffd8-4f0c-845f-32d77e34aedb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f8f1fcfe-3bec-4a4f-ac2c-ba74e1194049
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b1e8fc64-da9f-4067-8508-ada34152fb3e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 41840e98-1d35-48ce-b4f6-9857a78e029e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b521fee0-ece8-4c66-8367-51e41b49908b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ac958851-09e6-4d80-9223-fbc4cb07cb53
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3de5768f-30f6-4213-95a1-f1195e46de37
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ce327433-c87c-4ad5-bc16-2ba60cb8fb71
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3461dad9-f289-41b7-99c5-dbbf345cf478
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c567e740-75fd-458b-9e34-ff78761bc019
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 81205b7e-468e-48c9-bf5d-17afdda35b89
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a901a0ce-595f-468a-8045-603ee14dabfc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 201dae4d-7de6-42bd-afed-0c67e63a479a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 14807844-80b9-48ee-b158-3e809d0f00bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e924ba37-3ae0-4f44-a0ab-f68b64ee6797
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9597563a-b623-4860-bb76-a67b66913194
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message caac6736-a9b2-4040-b538-99742f668dd6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d9ec1712-6f1b-436a-bc9e-ba829112ca35
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 65013235-6cc2-4fe8-acd9-a4abaa77f46b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 77a9f0f2-df8b-47f3-ae5b-5a844d280269
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e8613fe8-24f4-48a6-915d-fc2f72d871fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 011298cc-0ee8-44df-862d-97795c02e6ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 31e7b273-cf21-46ae-a33c-24abc77e16e2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cfc7a8f8-d6ea-4954-9769-2a95a52220be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 68fa2b3c-53c9-47c1-9ae3-36a082694bf6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c9aa76fa-5eea-46e0-9681-ec392355820c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 12874fc5-73d9-457e-97e3-1682dc15c60c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6e4e5084-65db-434e-bca7-32c5cd7c6ae6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7fcabd62-c7fb-4499-8193-6763b024c918
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5671edc7-5ed0-4253-9e21-b8435aacb122
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8244e788-4fbb-4eb1-931d-aec19fa215c4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8fb657ed-4b0e-4b85-9d9a-6041a7d1ec5d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 146f7142-d032-4018-b041-444f731adf69
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 12a27bfc-6645-49ff-99ee-6604278dda82
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cc34f9da-ee8a-4e0e-b97f-59af763e78e1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9ee6f67e-f9e7-4cef-8937-2e1134762392
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0da836a2-c01c-4e8a-add4-5d1a60711574
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 11f31f20-b054-43c4-a4de-d5e8ca9269c7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bb0bf42c-6084-4893-8f9f-340f898268a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d614a984-c7f4-4d88-b65f-8907e777a40f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 374c33a1-9356-4ff9-a850-97d99a252e37
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b397dfb2-f040-40b8-80e1-98668c952aab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1e19c873-d967-494f-9145-79d25a019d4e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fedb7ed5-4092-4d1c-a52e-1f4456072bb1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1b0d9ba7-d785-445c-ac8e-a81cd9b1c5d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7e0a20fd-6182-46bf-a8d0-f75859ad59ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b6e41752-4dae-415c-9019-a64e8faac22b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e794f2a0-1d55-452b-8b86-b54d4b81883d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 70c9c1d9-afa3-4c02-8fe4-5ece5fb1691d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4935ea49-35b3-472f-becf-aead56c0b81b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e8af17f5-7b82-42e9-a55a-613e0ef78c62
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6d017d49-bba7-4945-87d3-7cdc879418e2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2fad0b3d-dca1-4d4a-94b3-f25c44a3b334
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dfa3d77d-c2bc-4019-9c26-f5098bcc1c1d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2aa5bab4-4df9-464a-bf6c-f6ef81620e52
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a6d021b5-98a7-45ca-992d-3c25f4a80003
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 25b28694-5b9c-4c3e-861f-e11906f35162
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 25784064-1c22-486f-a4a7-392522aab92c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c2917aaa-52d9-40ad-8375-81cedfdba632
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ff281f53-bba5-434a-836c-802a2a01b3e6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5e43ddba-723a-4b66-bc55-e383fb95ac74
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 66c96175-eabc-4203-a372-8c16c7c0ad9f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 38aa2e3c-8042-494b-aa19-7c7e5d557b6f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 540e51e6-ff19-4252-af1f-a08386ca75fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c67ecf29-96d1-4fa4-95f1-f0e37a804464
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8687 {grpc_status:14, grpc_message:"Socket closed"}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_53
Server: localhost:8687
Algorithm: FEDAVG
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_53
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_53/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_53/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_53/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_53/test_labels.txt

📊 Raw data loaded:
   Train: X=(1126, 24), y=(1126,)
   Test:  X=(282, 24), y=(282,)

⚠️  Limiting training data: 1126 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  273 samples, 5 features
✅ Client client_53 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

============================================================
🔄 Round 6 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0823 (↓), lr=0.001000
   • Epoch   2/100: train=0.0848, val=0.0827, patience=1/15, lr=0.001000
   • Epoch   3/100: train=0.0848, val=0.0831, patience=2/15, lr=0.001000
   • Epoch   4/100: train=0.0846, val=0.0827, patience=3/15, lr=0.001000
   • Epoch   5/100: train=0.0842, val=0.0823, patience=4/15, lr=0.001000
   • Epoch  11/100: train=0.0822, val=0.0815, patience=2/15, lr=0.001000
   📉 Epoch 19: LR reduced 0.001000 → 0.000500
   • Epoch  21/100: train=0.0753, val=0.0846, patience=12/15, lr=0.000500

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 6 Summary - Client client_53
   Epochs: 24/100 (early stopped)
   LR: 0.001000 → 0.000500 (1 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=0.0244
   Val:   Loss=0.0817, RMSE=0.2859, R²=-0.0204
============================================================


📊 Round 6 Test Metrics:
   Loss: 0.0869, RMSE: 0.2947, MAE: 0.2572, R²: -0.0401

📊 Round 6 Test Metrics:
   Loss: 0.0867, RMSE: 0.2945, MAE: 0.2572, R²: -0.0384

============================================================
🔄 Round 10 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000500
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0984 (↓), lr=0.000500
   • Epoch   2/100: train=0.0810, val=0.0980, patience=1/15, lr=0.000500
   📉 Epoch 3: LR reduced 0.000500 → 0.000250
   ✓ Epoch   3/100: train=0.0804, val=0.0979 (↓), lr=0.000250
   • Epoch   4/100: train=0.0800, val=0.0979, patience=1/15, lr=0.000250
   • Epoch   5/100: train=0.0798, val=0.0979, patience=2/15, lr=0.000250
   📉 Epoch 11: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0793, val=0.0978, patience=8/15, lr=0.000125

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0979)

============================================================
📊 Round 10 Summary - Client client_53
   Epochs: 18/100 (early stopped)
   LR: 0.000500 → 0.000125 (2 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=-0.0023
   Val:   Loss=0.0979, RMSE=0.3128, R²=-0.0005
============================================================


============================================================
🔄 Round 12 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000125
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   📉 Epoch 1: LR reduced 0.000125 → 0.000063
   ✓ Epoch   1/100: train=0.0845, val=0.0893 (↓), lr=0.000063
   • Epoch   2/100: train=0.0838, val=0.0891, patience=1/15, lr=0.000063
   • Epoch   3/100: train=0.0834, val=0.0889, patience=2/15, lr=0.000063
   • Epoch   4/100: train=0.0832, val=0.0889, patience=3/15, lr=0.000063
   • Epoch   5/100: train=0.0831, val=0.0889, patience=4/15, lr=0.000063
   📉 Epoch 9: LR reduced 0.000063 → 0.000031
   • Epoch  11/100: train=0.0827, val=0.0890, patience=10/15, lr=0.000031

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0893)

============================================================
📊 Round 12 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000125 → 0.000031 (2 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=-0.0210
   Val:   Loss=0.0893, RMSE=0.2988, R²=-0.0114
============================================================


============================================================
🔄 Round 13 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000031
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   📉 Epoch 1: LR reduced 0.000031 → 0.000016
   ✓ Epoch   1/100: train=0.0843, val=0.0904 (↓), lr=0.000016
   • Epoch   2/100: train=0.0841, val=0.0903, patience=1/15, lr=0.000016
   • Epoch   3/100: train=0.0840, val=0.0901, patience=2/15, lr=0.000016
   • Epoch   4/100: train=0.0839, val=0.0900, patience=3/15, lr=0.000016
   ✓ Epoch   5/100: train=0.0838, val=0.0899 (↓), lr=0.000016
   📉 Epoch 9: LR reduced 0.000016 → 0.000008
   • Epoch  11/100: train=0.0834, val=0.0894, patience=6/15, lr=0.000008
   📉 Epoch 17: LR reduced 0.000008 → 0.000004
   • Epoch  21/100: train=0.0832, val=0.0892, patience=9/15, lr=0.000004
   📉 Epoch 25: LR reduced 0.000004 → 0.000002

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0894)

============================================================
📊 Round 13 Summary - Client client_53
   Epochs: 27/100 (early stopped)
   LR: 0.000031 → 0.000002 (4 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=-0.0075
   Val:   Loss=0.0894, RMSE=0.2990, R²=-0.0373
============================================================


============================================================
🔄 Round 15 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000002
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0871, val=0.0808 (↓), lr=0.000002
   • Epoch   2/100: train=0.0871, val=0.0807, patience=1/15, lr=0.000002
   • Epoch   3/100: train=0.0871, val=0.0807, patience=2/15, lr=0.000002
   • Epoch   4/100: train=0.0870, val=0.0807, patience=3/15, lr=0.000002
   • Epoch   5/100: train=0.0870, val=0.0807, patience=4/15, lr=0.000002
   • Epoch  11/100: train=0.0869, val=0.0807, patience=10/15, lr=0.000002

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 15 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000002 → 0.000002 (0 reductions)
   Train: Loss=0.0873, RMSE=0.2954, R²=-0.0360
   Val:   Loss=0.0808, RMSE=0.2842, R²=-0.0141
============================================================


============================================================
🔄 Round 16 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000002
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0836 (↓), lr=0.000002
   • Epoch   2/100: train=0.0867, val=0.0835, patience=1/15, lr=0.000002
   • Epoch   3/100: train=0.0867, val=0.0835, patience=2/15, lr=0.000002
   • Epoch   4/100: train=0.0866, val=0.0835, patience=3/15, lr=0.000002
   📉 Epoch 5: LR reduced 0.000002 → 0.000001
   • Epoch   5/100: train=0.0866, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0866, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 16 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000002 → 0.000001 (1 reductions)
   Train: Loss=0.0867, RMSE=0.2945, R²=-0.0321
   Val:   Loss=0.0836, RMSE=0.2891, R²=-0.0333
============================================================


📊 Round 16 Test Metrics:
   Loss: 0.0881, RMSE: 0.2969, MAE: 0.2590, R²: -0.0554

============================================================
🔄 Round 18 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0880, val=0.0780 (↓), lr=0.000001
   • Epoch   2/100: train=0.0880, val=0.0780, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0880, val=0.0780, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0879, val=0.0780, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0879, val=0.0780, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0879, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 18 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0882, RMSE=0.2970, R²=-0.0262
   Val:   Loss=0.0780, RMSE=0.2794, R²=-0.0651
============================================================


📊 Round 18 Test Metrics:
   Loss: 0.0882, RMSE: 0.2970, MAE: 0.2590, R²: -0.0560

📊 Round 18 Test Metrics:
   Loss: 0.0881, RMSE: 0.2969, MAE: 0.2590, R²: -0.0553

============================================================
🔄 Round 21 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0916 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0916, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0916, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0916, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0916, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0915, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0916)

============================================================
📊 Round 21 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2917, R²=-0.0348
   Val:   Loss=0.0916, RMSE=0.3026, R²=-0.0400
============================================================


============================================================
🔄 Round 22 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0897 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0897, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0897, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0897, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0897, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0896, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0897)

============================================================
📊 Round 22 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2926, R²=-0.0351
   Val:   Loss=0.0897, RMSE=0.2995, R²=-0.0418
============================================================


============================================================
🔄 Round 23 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0900 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0900, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0900, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0900, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0900, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0900, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0900)

============================================================
📊 Round 23 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2925, R²=-0.0389
   Val:   Loss=0.0900, RMSE=0.2999, R²=-0.0500
============================================================


📊 Round 23 Test Metrics:
   Loss: 0.0886, RMSE: 0.2977, MAE: 0.2595, R²: -0.0613

📊 Round 23 Test Metrics:
   Loss: 0.0886, RMSE: 0.2977, MAE: 0.2595, R²: -0.0612

============================================================
🔄 Round 26 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0894, val=0.0739 (↓), lr=0.000001
   • Epoch   2/100: train=0.0894, val=0.0739, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0894, val=0.0739, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0894, val=0.0739, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0894, val=0.0739, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0893, val=0.0739, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0739)

============================================================
📊 Round 26 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0896, RMSE=0.2993, R²=-0.0398
   Val:   Loss=0.0739, RMSE=0.2718, R²=-0.0458
============================================================


============================================================
🔄 Round 27 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0968 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0968, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0968, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0968, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0968, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0968, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0968)

============================================================
📊 Round 27 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2896, R²=-0.0327
   Val:   Loss=0.0968, RMSE=0.3111, R²=-0.0656
============================================================


📊 Round 27 Test Metrics:
   Loss: 0.0886, RMSE: 0.2977, MAE: 0.2595, R²: -0.0610

============================================================
🔄 Round 29 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0870 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0869, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0869, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0869, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0869, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0869, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 29 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2938, R²=-0.0310
   Val:   Loss=0.0870, RMSE=0.2949, R²=-0.0642
============================================================


📊 Round 29 Test Metrics:
   Loss: 0.0886, RMSE: 0.2977, MAE: 0.2595, R²: -0.0610

📊 Round 29 Test Metrics:
   Loss: 0.0886, RMSE: 0.2977, MAE: 0.2595, R²: -0.0611

============================================================
🔄 Round 31 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0902 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0902, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0902, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0902, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0902, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0901, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0902)

============================================================
📊 Round 31 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2925, R²=-0.0285
   Val:   Loss=0.0902, RMSE=0.3004, R²=-0.0689
============================================================


📊 Round 31 Test Metrics:
   Loss: 0.0886, RMSE: 0.2977, MAE: 0.2595, R²: -0.0611

============================================================
🔄 Round 32 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0969 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0969, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0969, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0969, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0969, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0969, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0969)

============================================================
📊 Round 32 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2896, R²=-0.0378
   Val:   Loss=0.0969, RMSE=0.3113, R²=-0.0362
============================================================


📊 Round 32 Test Metrics:
   Loss: 0.0886, RMSE: 0.2977, MAE: 0.2595, R²: -0.0611

============================================================
🔄 Round 33 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0896 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0896, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0896, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0896, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0896, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0896, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0896)

============================================================
📊 Round 33 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2927, R²=-0.0413
   Val:   Loss=0.0896, RMSE=0.2993, R²=-0.0509
============================================================


============================================================
🔄 Round 34 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0876, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0876, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0876, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0876, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0875, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0875, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 34 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0878, RMSE=0.2962, R²=-0.0343
   Val:   Loss=0.0813, RMSE=0.2851, R²=-0.0475
============================================================


============================================================
🔄 Round 37 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0867 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0867, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0867, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0867, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0867, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 37 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2940, R²=-0.0402
   Val:   Loss=0.0867, RMSE=0.2944, R²=-0.0567
============================================================


============================================================
🔄 Round 38 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0941 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0941, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0941, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0941, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0941, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0941, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0941)

============================================================
📊 Round 38 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2908, R²=-0.0397
   Val:   Loss=0.0941, RMSE=0.3068, R²=-0.0318
============================================================


📊 Round 38 Test Metrics:
   Loss: 0.0886, RMSE: 0.2977, MAE: 0.2595, R²: -0.0612

============================================================
🔄 Round 41 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0883, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0883, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0883, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0883, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0882, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0882, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 41 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0886, RMSE=0.2976, R²=-0.0423
   Val:   Loss=0.0781, RMSE=0.2794, R²=-0.0504
============================================================


📊 Round 41 Test Metrics:
   Loss: 0.0886, RMSE: 0.2977, MAE: 0.2595, R²: -0.0613

============================================================
🔄 Round 42 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0870, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0870, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0870, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0870, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0870, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0870, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 42 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2947, R²=-0.0379
   Val:   Loss=0.0850, RMSE=0.2915, R²=-0.0357
============================================================


============================================================
🔄 Round 44 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0870, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0870, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0870, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0870, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0869, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0869, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 44 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0869, RMSE=0.2948, R²=-0.0293
   Val:   Loss=0.0847, RMSE=0.2910, R²=-0.0730
============================================================


📊 Round 44 Test Metrics:
   Loss: 0.0886, RMSE: 0.2977, MAE: 0.2595, R²: -0.0613

============================================================
🔄 Round 45 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0903 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0903, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0903, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0903, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0903, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0903, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0903)

============================================================
📊 Round 45 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2924, R²=-0.0470
   Val:   Loss=0.0903, RMSE=0.3005, R²=0.0005
============================================================


📊 Round 45 Test Metrics:
   Loss: 0.0886, RMSE: 0.2977, MAE: 0.2595, R²: -0.0613

============================================================
🔄 Round 48 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0905 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0905, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0905, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0905, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0905, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0905, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0905)

============================================================
📊 Round 48 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2923, R²=-0.0379
   Val:   Loss=0.0905, RMSE=0.3009, R²=-0.0344
============================================================


📊 Round 48 Test Metrics:
   Loss: 0.0886, RMSE: 0.2977, MAE: 0.2595, R²: -0.0612

============================================================
🔄 Round 49 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0871 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0871, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0871, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0871, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0871, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0870, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0871)

============================================================
📊 Round 49 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2938, R²=-0.0356
   Val:   Loss=0.0871, RMSE=0.2951, R²=-0.0418
============================================================


📊 Round 49 Test Metrics:
   Loss: 0.0886, RMSE: 0.2977, MAE: 0.2595, R²: -0.0613

============================================================
🔄 Round 50 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0879 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0879, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0879, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0879, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0879, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0879, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0879)

============================================================
📊 Round 50 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2934, R²=-0.0330
   Val:   Loss=0.0879, RMSE=0.2965, R²=-0.0640
============================================================


📊 Round 50 Test Metrics:
   Loss: 0.0886, RMSE: 0.2977, MAE: 0.2595, R²: -0.0613

============================================================
🔄 Round 54 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0876, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0876, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0876, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0876, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0875, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0875, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 54 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0878, RMSE=0.2964, R²=-0.0407
   Val:   Loss=0.0810, RMSE=0.2847, R²=-0.0222
============================================================


📊 Round 54 Test Metrics:
   Loss: 0.0886, RMSE: 0.2977, MAE: 0.2595, R²: -0.0613

📊 Round 54 Test Metrics:
   Loss: 0.0886, RMSE: 0.2977, MAE: 0.2595, R²: -0.0612

============================================================
🔄 Round 58 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0920 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0920, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0920, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0920, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0920, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0919, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0920)

============================================================
📊 Round 58 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2917, R²=-0.0324
   Val:   Loss=0.0920, RMSE=0.3034, R²=-0.0536
============================================================


📊 Round 58 Test Metrics:
   Loss: 0.0886, RMSE: 0.2977, MAE: 0.2595, R²: -0.0612

============================================================
🔄 Round 62 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0874, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0874, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0874, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0874, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0874, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0873, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 62 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0874, RMSE=0.2956, R²=-0.0296
   Val:   Loss=0.0829, RMSE=0.2879, R²=-0.0772
============================================================


============================================================
🔄 Round 63 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0883, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0883, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0883, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0883, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0883, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0882, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 63 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0884, RMSE=0.2973, R²=-0.0384
   Val:   Loss=0.0788, RMSE=0.2808, R²=-0.0427
============================================================


📊 Round 63 Test Metrics:
   Loss: 0.0886, RMSE: 0.2977, MAE: 0.2595, R²: -0.0613

📊 Round 63 Test Metrics:
   Loss: 0.0886, RMSE: 0.2977, MAE: 0.2595, R²: -0.0614

============================================================
🔄 Round 65 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0880, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0880, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0880, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0880, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0879, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0879, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 65 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0880, RMSE=0.2967, R²=-0.0333
   Val:   Loss=0.0803, RMSE=0.2834, R²=-0.0718
============================================================


📊 Round 65 Test Metrics:
   Loss: 0.0886, RMSE: 0.2977, MAE: 0.2595, R²: -0.0614

============================================================
🔄 Round 68 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 68 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2943, R²=-0.0252
   Val:   Loss=0.0860, RMSE=0.2932, R²=-0.1188
============================================================


============================================================
🔄 Round 70 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0893 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0893, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0893, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0893, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0893, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0892, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0893)

============================================================
📊 Round 70 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2929, R²=-0.0406
   Val:   Loss=0.0893, RMSE=0.2988, R²=-0.0250
============================================================


📊 Round 70 Test Metrics:
   Loss: 0.0887, RMSE: 0.2977, MAE: 0.2595, R²: -0.0616

============================================================
🔄 Round 72 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0966 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0966, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0966, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0966, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0966, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0965, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0966)

============================================================
📊 Round 72 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=-0.0430
   Val:   Loss=0.0966, RMSE=0.3108, R²=-0.0179
============================================================


============================================================
🔄 Round 73 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0869, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0869, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0869, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0869, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0869, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0868, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 73 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2946, R²=-0.0442
   Val:   Loss=0.0853, RMSE=0.2920, R²=-0.0211
============================================================


============================================================
🔄 Round 75 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0887, val=0.0777 (↓), lr=0.000001
   • Epoch   2/100: train=0.0887, val=0.0777, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0887, val=0.0776, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0887, val=0.0776, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0886, val=0.0776, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0886, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 75 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0887, RMSE=0.2978, R²=-0.0408
   Val:   Loss=0.0777, RMSE=0.2787, R²=-0.0229
============================================================


============================================================
🔄 Round 76 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0902, val=0.0712 (↓), lr=0.000001
   • Epoch   2/100: train=0.0901, val=0.0711, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0901, val=0.0711, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0901, val=0.0711, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0901, val=0.0711, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0901, val=0.0711, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0712)

============================================================
📊 Round 76 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0903, RMSE=0.3005, R²=-0.0358
   Val:   Loss=0.0712, RMSE=0.2667, R²=-0.0486
============================================================


📊 Round 76 Test Metrics:
   Loss: 0.0887, RMSE: 0.2978, MAE: 0.2595, R²: -0.0618

📊 Round 76 Test Metrics:
   Loss: 0.0887, RMSE: 0.2978, MAE: 0.2595, R²: -0.0617

============================================================
🔄 Round 85 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0877 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0877, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0877, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0877, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0877, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0876, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0877)

============================================================
📊 Round 85 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2936, R²=-0.0311
   Val:   Loss=0.0877, RMSE=0.2961, R²=-0.0628
============================================================


============================================================
🔄 Round 86 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0873, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0873, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0873, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0873, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0873, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0872, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 86 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0874, RMSE=0.2957, R²=-0.0346
   Val:   Loss=0.0828, RMSE=0.2877, R²=-0.0475
============================================================


============================================================
🔄 Round 87 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0884, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0883, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0883, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0883, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0883, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0882, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 87 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0882, RMSE=0.2971, R²=-0.0360
   Val:   Loss=0.0794, RMSE=0.2819, R²=-0.0421
============================================================


📊 Round 87 Test Metrics:
   Loss: 0.0887, RMSE: 0.2978, MAE: 0.2595, R²: -0.0617

============================================================
🔄 Round 89 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0924 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0924, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0924, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0924, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0924, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0924, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0924)

============================================================
📊 Round 89 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2916, R²=-0.0325
   Val:   Loss=0.0924, RMSE=0.3040, R²=-0.0567
============================================================


============================================================
🔄 Round 92 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0878 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0878, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0878, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0878, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0878, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0878, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0878)

============================================================
📊 Round 92 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2935, R²=-0.0435
   Val:   Loss=0.0878, RMSE=0.2964, R²=-0.0195
============================================================


📊 Round 92 Test Metrics:
   Loss: 0.0887, RMSE: 0.2978, MAE: 0.2595, R²: -0.0619

📊 Round 92 Test Metrics:
   Loss: 0.0887, RMSE: 0.2978, MAE: 0.2595, R²: -0.0618

============================================================
🔄 Round 97 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0885 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0885, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0884, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0884, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0884, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0884, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0885)

============================================================
📊 Round 97 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2933, R²=-0.0420
   Val:   Loss=0.0885, RMSE=0.2974, R²=-0.0183
============================================================


📊 Round 97 Test Metrics:
   Loss: 0.0887, RMSE: 0.2978, MAE: 0.2596, R²: -0.0620

📊 Round 97 Test Metrics:
   Loss: 0.0887, RMSE: 0.2978, MAE: 0.2596, R²: -0.0620

============================================================
🔄 Round 102 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0887, val=0.0774 (↓), lr=0.000001
   • Epoch   2/100: train=0.0887, val=0.0774, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0887, val=0.0774, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0887, val=0.0774, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0887, val=0.0774, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0887, val=0.0773, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0774)

============================================================
📊 Round 102 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0888, RMSE=0.2979, R²=-0.0370
   Val:   Loss=0.0774, RMSE=0.2782, R²=-0.0384
============================================================


📊 Round 102 Test Metrics:
   Loss: 0.0887, RMSE: 0.2978, MAE: 0.2596, R²: -0.0620

📊 Round 102 Test Metrics:
   Loss: 0.0887, RMSE: 0.2978, MAE: 0.2596, R²: -0.0621

============================================================
🔄 Round 104 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0874, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0873, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0873, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0873, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0873, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0873, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 104 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0872, RMSE=0.2954, R²=-0.0352
   Val:   Loss=0.0835, RMSE=0.2889, R²=-0.0466
============================================================


📊 Round 104 Test Metrics:
   Loss: 0.0887, RMSE: 0.2978, MAE: 0.2596, R²: -0.0621

============================================================
🔄 Round 107 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0866, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 107 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2946, R²=-0.0339
   Val:   Loss=0.0853, RMSE=0.2920, R²=-0.0565
============================================================


📊 Round 107 Test Metrics:
   Loss: 0.0887, RMSE: 0.2978, MAE: 0.2596, R²: -0.0622

============================================================
🔄 Round 109 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0868, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0868, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0868, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0868, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0867, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 109 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2943, R²=-0.0405
   Val:   Loss=0.0861, RMSE=0.2934, R²=-0.0254
============================================================


============================================================
🔄 Round 110 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0882, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0882, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0882, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0882, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0882, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0881, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 110 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0882, RMSE=0.2970, R²=-0.0456
   Val:   Loss=0.0796, RMSE=0.2821, R²=-0.0075
============================================================


📊 Round 110 Test Metrics:
   Loss: 0.0887, RMSE: 0.2978, MAE: 0.2596, R²: -0.0621

📊 Round 110 Test Metrics:
   Loss: 0.0887, RMSE: 0.2978, MAE: 0.2596, R²: -0.0621

============================================================
🔄 Round 113 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0887, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0887, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0887, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0886, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0886, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0885, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 113 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0888, RMSE=0.2979, R²=-0.0428
   Val:   Loss=0.0775, RMSE=0.2783, R²=-0.0269
============================================================


============================================================
🔄 Round 114 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0874, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0874, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0874, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0874, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0874, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0873, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 114 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0878, RMSE=0.2963, R²=-0.0413
   Val:   Loss=0.0813, RMSE=0.2852, R²=-0.0189
============================================================


📊 Round 114 Test Metrics:
   Loss: 0.0887, RMSE: 0.2978, MAE: 0.2596, R²: -0.0622

📊 Round 114 Test Metrics:
   Loss: 0.0887, RMSE: 0.2978, MAE: 0.2596, R²: -0.0623

📊 Round 114 Test Metrics:
   Loss: 0.0887, RMSE: 0.2978, MAE: 0.2596, R²: -0.0623

============================================================
🔄 Round 118 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0868, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0868, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0868, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0867, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0867, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 118 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0871, RMSE=0.2951, R²=-0.0456
   Val:   Loss=0.0841, RMSE=0.2900, R²=-0.0035
============================================================


============================================================
🔄 Round 119 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0877, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0877, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0877, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0877, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0877, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0876, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 119 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0877, RMSE=0.2962, R²=-0.0377
   Val:   Loss=0.0817, RMSE=0.2858, R²=-0.0438
============================================================


📊 Round 119 Test Metrics:
   Loss: 0.0887, RMSE: 0.2979, MAE: 0.2596, R²: -0.0624

============================================================
🔄 Round 123 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0903 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0903, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0903, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0902, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0902, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0902, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0903)

============================================================
📊 Round 123 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2925, R²=-0.0350
   Val:   Loss=0.0903, RMSE=0.3005, R²=-0.0488
============================================================


📊 Round 123 Test Metrics:
   Loss: 0.0887, RMSE: 0.2979, MAE: 0.2596, R²: -0.0624

📊 Round 123 Test Metrics:
   Loss: 0.0887, RMSE: 0.2979, MAE: 0.2596, R²: -0.0624

📊 Round 123 Test Metrics:
   Loss: 0.0887, RMSE: 0.2979, MAE: 0.2596, R²: -0.0624

============================================================
🔄 Round 127 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0870, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0870, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0870, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0870, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0869, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0869, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 127 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0872, RMSE=0.2952, R²=-0.0269
   Val:   Loss=0.0839, RMSE=0.2897, R²=-0.0864
============================================================


============================================================
🔄 Round 128 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0876, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0876, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0876, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0876, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0876, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0875, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 128 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0875, RMSE=0.2959, R²=-0.0324
   Val:   Loss=0.0824, RMSE=0.2871, R²=-0.0585
============================================================


📊 Round 128 Test Metrics:
   Loss: 0.0887, RMSE: 0.2979, MAE: 0.2596, R²: -0.0623

📊 Round 128 Test Metrics:
   Loss: 0.0887, RMSE: 0.2978, MAE: 0.2596, R²: -0.0623

============================================================
🔄 Round 131 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0872, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0872, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0872, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0872, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0872, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0871, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 131 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0874, RMSE=0.2957, R²=-0.0371
   Val:   Loss=0.0829, RMSE=0.2879, R²=-0.0528
============================================================


📊 Round 131 Test Metrics:
   Loss: 0.0887, RMSE: 0.2978, MAE: 0.2596, R²: -0.0622

📊 Round 131 Test Metrics:
   Loss: 0.0887, RMSE: 0.2978, MAE: 0.2596, R²: -0.0623

============================================================
🔄 Round 133 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0914 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0914, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0914, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0914, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0914, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0913, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0914)

============================================================
📊 Round 133 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2921, R²=-0.0258
   Val:   Loss=0.0914, RMSE=0.3023, R²=-0.0832
============================================================


📊 Round 133 Test Metrics:
   Loss: 0.0887, RMSE: 0.2978, MAE: 0.2596, R²: -0.0623

============================================================
🔄 Round 134 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0895, val=0.0737 (↓), lr=0.000001
   • Epoch   2/100: train=0.0895, val=0.0737, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0895, val=0.0737, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0895, val=0.0737, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0895, val=0.0737, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0894, val=0.0737, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0737)

============================================================
📊 Round 134 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0897, RMSE=0.2995, R²=-0.0429
   Val:   Loss=0.0737, RMSE=0.2715, R²=-0.0141
============================================================


📊 Round 134 Test Metrics:
   Loss: 0.0887, RMSE: 0.2978, MAE: 0.2596, R²: -0.0622

📊 Round 134 Test Metrics:
   Loss: 0.0887, RMSE: 0.2978, MAE: 0.2596, R²: -0.0622

============================================================
🔄 Round 138 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0975 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0975, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0975, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0975, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0975, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0974, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0975)

============================================================
📊 Round 138 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2894, R²=-0.0358
   Val:   Loss=0.0975, RMSE=0.3122, R²=-0.0426
============================================================


📊 Round 138 Test Metrics:
   Loss: 0.0887, RMSE: 0.2978, MAE: 0.2596, R²: -0.0623

============================================================
🔄 Round 141 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 141 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2943, R²=-0.0443
   Val:   Loss=0.0861, RMSE=0.2934, R²=-0.0110
============================================================


📊 Round 141 Test Metrics:
   Loss: 0.0887, RMSE: 0.2978, MAE: 0.2596, R²: -0.0623

============================================================
🔄 Round 142 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0873, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0873, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0872, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0872, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0872, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0871, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 142 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0869, RMSE=0.2948, R²=-0.0475
   Val:   Loss=0.0849, RMSE=0.2914, R²=-0.0222
============================================================


============================================================
🔄 Round 144 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0948 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0948, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0948, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0948, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0948, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0948, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0948)

============================================================
📊 Round 144 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2906, R²=-0.0387
   Val:   Loss=0.0948, RMSE=0.3080, R²=-0.0337
============================================================


============================================================
🔄 Round 148 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0895 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0895, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0895, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0895, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0895, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0894, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0895)

============================================================
📊 Round 148 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2929, R²=-0.0411
   Val:   Loss=0.0895, RMSE=0.2991, R²=-0.0230
============================================================


📊 Round 148 Test Metrics:
   Loss: 0.0887, RMSE: 0.2978, MAE: 0.2596, R²: -0.0623

============================================================
🔄 Round 150 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0961 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0961, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0961, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0961, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0961, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0961, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0961)

============================================================
📊 Round 150 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=-0.0399
   Val:   Loss=0.0961, RMSE=0.3100, R²=-0.0396
============================================================


📊 Round 150 Test Metrics:
   Loss: 0.0887, RMSE: 0.2979, MAE: 0.2596, R²: -0.0624

📊 Round 150 Test Metrics:
   Loss: 0.0887, RMSE: 0.2979, MAE: 0.2596, R²: -0.0624

============================================================
🔄 Round 154 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0923 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0923, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0924, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0924, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0924, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0924, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0923)

============================================================
📊 Round 154 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2917, R²=-0.0353
   Val:   Loss=0.0923, RMSE=0.3039, R²=-0.0777
============================================================


📊 Round 154 Test Metrics:
   Loss: 0.0887, RMSE: 0.2979, MAE: 0.2596, R²: -0.0625

📊 Round 154 Test Metrics:
   Loss: 0.0887, RMSE: 0.2979, MAE: 0.2596, R²: -0.0624

============================================================
🔄 Round 158 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0878, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0877, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0877, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0877, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0877, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0877, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 158 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0875, RMSE=0.2959, R²=-0.0290
   Val:   Loss=0.0824, RMSE=0.2871, R²=-0.0750
============================================================


📊 Round 158 Test Metrics:
   Loss: 0.0887, RMSE: 0.2979, MAE: 0.2596, R²: -0.0624

📊 Round 158 Test Metrics:
   Loss: 0.0887, RMSE: 0.2979, MAE: 0.2596, R²: -0.0624

📊 Round 158 Test Metrics:
   Loss: 0.0887, RMSE: 0.2979, MAE: 0.2596, R²: -0.0624

============================================================
🔄 Round 166 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0924 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0924, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0924, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0924, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0924, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0923, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0924)

============================================================
📊 Round 166 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2916, R²=-0.0278
   Val:   Loss=0.0924, RMSE=0.3040, R²=-0.0747
============================================================


📊 Round 166 Test Metrics:
   Loss: 0.0887, RMSE: 0.2979, MAE: 0.2596, R²: -0.0624

📊 Round 166 Test Metrics:
   Loss: 0.0887, RMSE: 0.2979, MAE: 0.2596, R²: -0.0624

📊 Round 166 Test Metrics:
   Loss: 0.0887, RMSE: 0.2979, MAE: 0.2596, R²: -0.0624

============================================================
🔄 Round 172 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0875, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0875, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0875, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0875, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0875, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0874, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 172 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0875, RMSE=0.2957, R²=-0.0492
   Val:   Loss=0.0828, RMSE=0.2877, R²=0.0095
============================================================


📊 Round 172 Test Metrics:
   Loss: 0.0887, RMSE: 0.2979, MAE: 0.2596, R²: -0.0625

📊 Round 172 Test Metrics:
   Loss: 0.0887, RMSE: 0.2979, MAE: 0.2596, R²: -0.0625

📊 Round 172 Test Metrics:
   Loss: 0.0887, RMSE: 0.2979, MAE: 0.2596, R²: -0.0626

============================================================
🔄 Round 176 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0870, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0870, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0870, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0869, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0869, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0869, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 176 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0870, RMSE=0.2950, R²=-0.0311
   Val:   Loss=0.0844, RMSE=0.2906, R²=-0.0671
============================================================


============================================================
🔄 Round 179 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 179 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0867, RMSE=0.2945, R²=-0.0329
   Val:   Loss=0.0858, RMSE=0.2930, R²=-0.0567
============================================================


============================================================
🔄 Round 180 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0905 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0905, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0905, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0905, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0905, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0904, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0905)

============================================================
📊 Round 180 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2925, R²=-0.0368
   Val:   Loss=0.0905, RMSE=0.3008, R²=-0.0393
============================================================


============================================================
🔄 Round 181 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0883, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0883, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0883, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0883, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0883, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0882, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 181 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0883, RMSE=0.2972, R²=-0.0361
   Val:   Loss=0.0793, RMSE=0.2817, R²=-0.0432
============================================================


============================================================
🔄 Round 182 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 182 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2946, R²=-0.0445
   Val:   Loss=0.0855, RMSE=0.2924, R²=-0.0123
============================================================


📊 Round 182 Test Metrics:
   Loss: 0.0887, RMSE: 0.2979, MAE: 0.2596, R²: -0.0625

============================================================
🔄 Round 184 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0877 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0877, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0877, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0877, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0877, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0876, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0877)

============================================================
📊 Round 184 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2937, R²=-0.0404
   Val:   Loss=0.0877, RMSE=0.2961, R²=-0.0259
============================================================


============================================================
🔄 Round 187 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0885 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0885, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0885, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0885, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0885, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0884, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0885)

============================================================
📊 Round 187 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2933, R²=-0.0372
   Val:   Loss=0.0885, RMSE=0.2975, R²=-0.0493
============================================================


============================================================
🔄 Round 189 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0941 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0941, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0941, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0941, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0941, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0940, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0941)

============================================================
📊 Round 189 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=-0.0349
   Val:   Loss=0.0941, RMSE=0.3068, R²=-0.0471
============================================================


============================================================
🔄 Round 191 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0885, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0885, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0884, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0884, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0884, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0884, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 191 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0885, RMSE=0.2975, R²=-0.0460
   Val:   Loss=0.0785, RMSE=0.2803, R²=-0.0005
============================================================


📊 Round 191 Test Metrics:
   Loss: 0.0887, RMSE: 0.2979, MAE: 0.2596, R²: -0.0624

============================================================
🔄 Round 192 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0895, val=0.0748 (↓), lr=0.000001
   • Epoch   2/100: train=0.0895, val=0.0748, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0895, val=0.0748, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0894, val=0.0748, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0894, val=0.0748, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0894, val=0.0747, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0748)

============================================================
📊 Round 192 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0895, RMSE=0.2991, R²=-0.0302
   Val:   Loss=0.0748, RMSE=0.2736, R²=-0.0758
============================================================


============================================================
🔄 Round 193 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0880, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0879, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0879, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0879, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0879, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0879, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 193 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0877, RMSE=0.2962, R²=-0.0324
   Val:   Loss=0.0818, RMSE=0.2860, R²=-0.0692
============================================================


============================================================
🔄 Round 196 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0882, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0882, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0882, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0882, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0882, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0881, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 196 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0881, RMSE=0.2968, R²=-0.0280
   Val:   Loss=0.0803, RMSE=0.2835, R²=-0.0837
============================================================


📊 Round 196 Test Metrics:
   Loss: 0.0887, RMSE: 0.2979, MAE: 0.2596, R²: -0.0624

📊 Round 196 Test Metrics:
   Loss: 0.0887, RMSE: 0.2979, MAE: 0.2596, R²: -0.0624

============================================================
🔄 Round 198 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0931 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0931, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0931, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0931, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0931, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0930, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0931)

============================================================
📊 Round 198 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=-0.0394
   Val:   Loss=0.0931, RMSE=0.3051, R²=-0.0351
============================================================


📊 Round 198 Test Metrics:
   Loss: 0.0887, RMSE: 0.2979, MAE: 0.2596, R²: -0.0625

============================================================
🔄 Round 201 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0992 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0992, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0992, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0992, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0991, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0991, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0992)

============================================================
📊 Round 201 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=-0.0349
   Val:   Loss=0.0992, RMSE=0.3149, R²=-0.0476
============================================================


📊 Round 201 Test Metrics:
   Loss: 0.0887, RMSE: 0.2979, MAE: 0.2596, R²: -0.0625

============================================================
🔄 Round 202 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0877, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0877, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0877, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0876, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0876, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0876, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 202 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0876, RMSE=0.2959, R²=-0.0348
   Val:   Loss=0.0823, RMSE=0.2870, R²=-0.0497
============================================================


📊 Round 202 Test Metrics:
   Loss: 0.0887, RMSE: 0.2979, MAE: 0.2597, R²: -0.0624

============================================================
🔄 Round 204 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0884 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0884, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0884, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0884, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0884, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0884, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0884)

============================================================
📊 Round 204 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2934, R²=-0.0266
   Val:   Loss=0.0884, RMSE=0.2973, R²=-0.1139
============================================================


============================================================
🔄 Round 207 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0887, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0886, val=0.0774, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0886, val=0.0774, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0886, val=0.0774, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0886, val=0.0774, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0886, val=0.0774, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 207 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0888, RMSE=0.2980, R²=-0.0368
   Val:   Loss=0.0775, RMSE=0.2783, R²=-0.0439
============================================================


📊 Round 207 Test Metrics:
   Loss: 0.0887, RMSE: 0.2979, MAE: 0.2597, R²: -0.0625

============================================================
🔄 Round 209 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0870 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0870, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0870, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0870, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0869, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0869, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 209 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2940, R²=-0.0319
   Val:   Loss=0.0870, RMSE=0.2949, R²=-0.0604
============================================================


📊 Round 209 Test Metrics:
   Loss: 0.0887, RMSE: 0.2979, MAE: 0.2597, R²: -0.0626

============================================================
🔄 Round 214 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0903 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0903, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0903, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0903, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0903, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0902, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0903)

============================================================
📊 Round 214 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2926, R²=-0.0331
   Val:   Loss=0.0903, RMSE=0.3005, R²=-0.0553
============================================================


============================================================
🔄 Round 217 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0875, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0875, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0874, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0874, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0874, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0873, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 217 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0875, RMSE=0.2958, R²=-0.0439
   Val:   Loss=0.0828, RMSE=0.2878, R²=-0.0514
============================================================


📊 Round 217 Test Metrics:
   Loss: 0.0887, RMSE: 0.2979, MAE: 0.2597, R²: -0.0626

============================================================
🔄 Round 220 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0874, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0874, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0874, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0873, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0873, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0873, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 220 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0874, RMSE=0.2957, R²=-0.0367
   Val:   Loss=0.0830, RMSE=0.2881, R²=-0.0432
============================================================


============================================================
🔄 Round 221 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0869, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0869, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0869, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0868, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0868, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0868, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 221 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0870, RMSE=0.2950, R²=-0.0404
   Val:   Loss=0.0846, RMSE=0.2908, R²=-0.0335
============================================================


📊 Round 221 Test Metrics:
   Loss: 0.0887, RMSE: 0.2979, MAE: 0.2597, R²: -0.0627

============================================================
🔄 Round 224 - Client client_53
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0932 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0932, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0931, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0931, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0931, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0931, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0932)

============================================================
📊 Round 224 Summary - Client client_53
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=-0.0358
   Val:   Loss=0.0932, RMSE=0.3052, R²=-0.0460
============================================================


📊 Round 224 Test Metrics:
   Loss: 0.0887, RMSE: 0.2979, MAE: 0.2597, R²: -0.0627

❌ Client client_53 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8687 {grpc_status:14, grpc_message:"Socket closed"}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8687 {grpc_status:14, grpc_message:"Socket closed"}"
>
