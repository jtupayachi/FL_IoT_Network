[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 49c80b54-a622-45a2-97d0-62bc7f4470d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 029b5208-acb4-436c-a3d4-ac1cbacc6be1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6e1f163f-5ead-4c78-b01f-760d3c664c48
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5dbe6da6-4029-4889-b25c-b65f73451140
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 82a08d15-9b96-42c1-93f4-d4dfbacf5bce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 95f8ed13-2632-4a35-abd1-fcb50c7fb423
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5bd26d38-4303-47c3-899f-9c0e499b87a3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 47624a90-0001-4a4c-828a-963c3472c8d8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9c39af01-99af-4dc2-9032-3f15f476b7d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 70d39bc9-8687-4a7a-bb34-5c7524423e16
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9797c3a0-9e57-4f7a-82aa-6d203266e2f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bbb53cab-beea-434f-80e4-f399a296b024
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 468a2f79-cde4-49bd-9264-c3d9e82e7e96
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c2f830ad-a23b-458f-816e-33f8ce56750b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6d74c384-dd7a-4c93-b3ae-1ee0c9d20202
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 555171a5-e55d-495a-a744-3698950e6f9d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 82728f12-163c-419e-a8db-7b120f471222
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 09cb4ad3-b6fb-419a-a1c7-59f41a99a9fb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 115d13b5-09cc-49db-80a9-fecc15a59825
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4ee21b62-e32c-49cf-a0b8-75d2e3b88101
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5461854b-a047-4998-9cfc-38ec32a51b02
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 33114018-864d-4ba1-bd88-cb651ecd8893
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f09c2920-1f34-4bc2-87b0-6becb5645aab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ac4d7eff-32bb-4a51-87fc-5e963be40ff2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0e0ca659-97a6-48c4-9e06-c7f482f0f237
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 182fff56-cce8-456f-bea4-82aae5ef3d89
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fecca80b-4cfd-4039-84e9-9005ce56fd54
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 43f60ff6-360c-40c5-b8e0-5e054c8190a0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e88f6b45-efb9-4334-9ba6-5b4e621deb00
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cfbea429-8c68-4a25-a3b5-1d0f2d810ba4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2498f539-eb62-43d8-8f51-57ceb8837496
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 60e05c58-d26e-4018-9a37-a6ddd3239483
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6c3cd13c-f351-4894-81e4-58dfb549a945
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a2cb8f57-0169-4d7a-8a55-7ef155f7d2cb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d6eeade4-f058-4ecd-b8aa-5d7fd8c13799
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8dc00ece-005a-4ef6-a2b7-d3ba1b864d28
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4f2523a0-6b7c-4b8b-a6d5-b0d95be2d9bc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8f51a813-6072-44da-92b1-ab8701828521
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c73158ac-ad4e-421e-a77b-cca46f4e0e55
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 16b5f138-7e0d-4513-98de-3439c028ea0b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b92d0742-5e2b-49dd-a68d-cfa10423b634
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 189856ee-8f2e-43c7-9497-a38828e75b42
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0e0c5edd-9880-450b-a242-c18953796d32
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f13b9df2-b085-4e15-82cc-467a3dfb4c92
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9d5396eb-ddc6-436e-9116-5990f42a4eb1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 08301aaf-905b-4d4f-be37-bd887bb19307
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c66622d3-01ca-46e9-8279-b9df98bf573f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bb24981a-f80f-430d-a160-4f33490f5cec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 085d1de4-e068-4e60-9fdc-e4512ff411ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d7a9dd43-92c0-4a99-beb4-247d2c7203ea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aa77fcda-1cae-48f7-9647-8b109c5aee7f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9ab9b553-418d-4419-b49b-68703caa79a3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 465cd428-51ff-41ae-9bbf-9fb2b34f31d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message df25af5f-af30-44ca-85fb-49e171df209f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c8b8fce3-026f-4673-a8a7-fc2e12d041fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 25d599ad-6c88-4174-97e8-ad2e2790cf7f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2d5a7e41-8d9b-46b8-a01d-09c364f25ed8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3fdaaf0a-26ac-48b8-bd2e-2c23432a2e4a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ff19115a-6c58-42b1-adf0-f6c8f8cdd173
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7dc079cb-a8c5-4d5f-9709-0d20f9de262f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 40eead21-a6f7-4696-b75c-c1a70fd4ddc2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 99a9e780-df85-4b5e-9be1-f06373aba74d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0ecf7d59-09df-4da1-8945-333260f3eec5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e3dc3a47-b289-4815-a44e-f1a28cae9050
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 055d0464-8210-4578-b734-ca257b7fc8d1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2d77b1b2-9f88-4497-a509-a7bcf3bd70bc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 73d6a01b-14ea-4e61-8cf4-e2cf6a6c3901
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ee4c216d-f49c-44e1-b786-7fafc1dc2666
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2a8b4f50-ed42-4eca-9b41-c7549be26fc5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5dfd9db8-be2a-43a9-9855-1e2f280d9541
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e7bea202-10c6-4c10-9984-3c4b94bb118c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ffbeef7d-3a23-45a2-8834-15ec4ea78a51
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 023180de-86b9-4215-8e43-7f194ff3b6c6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a820c1f4-669f-40a3-90f0-21c741bfdd0d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c87041a8-c1c9-4dea-a340-5ccd43c090d1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5e48bd1d-3a0f-469f-93db-4cd1f7224f41
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cc49f772-58c3-4f04-8704-a61c159fdb47
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5d4ff92b-3bbe-4886-bdd2-916b5cf3bf12
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1de7e416-fca1-4318-ade1-1e028686ea69
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2c6e56d6-6638-4fc6-a7fd-16f391423a0f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 90db3074-dcad-4654-8afe-d0c2f47e37ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2a71b976-7e37-4b18-b283-69222b1d735e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f64d835f-ef69-4ad6-be00-4f260547fbed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7c884eb2-1922-4eb3-ab8d-d4c8438aeb12
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aea1ebfe-4efa-42d0-86c3-3661934b2d4b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b2b64ff6-bda3-4c36-8b25-b431bd767cfc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ceeb78be-c303-4662-baba-cca16b0df6b7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 346ebb16-e911-4a72-b916-15a44b70d10e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0e7fa667-f79b-47b3-b8cc-cc275c637672
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 54bab04b-f0bf-4e3a-9f9c-0d1beb0e433d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 61775557-a73b-4e57-b4a2-d455072971f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 81c8add1-b6fc-4b51-acaa-c55f00354c11
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e89dcb2c-d18d-4cdf-99ff-f131e5f35607
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4cef97d2-4ad9-421d-8251-d63b3d6e7b09
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d14bcb67-73f3-4f0b-8961-39b8afe93d73
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f58156cb-68fe-4997-9779-7b1775ae9dae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fed16a4f-cac4-4bf0-b5d1-c85f94395719
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f27df3ae-c42e-4bcd-b70b-e92a056f9367
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c4b21149-31dd-4f1b-b6ee-7b30f50288e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 64ce20f4-4f92-4e3d-9525-6c42e499f358
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9e23ba81-bdb4-4445-9be7-0d8260cf6bfb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d1c64f96-7a9a-4027-91d1-74aa2d11d6d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message baae9d72-adf3-4620-a224-45e43936b0b8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b31ac134-919b-4c79-b2f5-3898a5992364
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message af274273-6ef4-422d-bd68-68d721600b8a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f6b708c2-df2d-400e-84f4-56f5456467b6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d8c2e88c-678b-4448-a8bc-5571ab3a776a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8073f5f8-284a-48ed-977e-9073da6343ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b1be21ba-81ca-4641-958d-fe2f174afcfd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c32d0c61-2ea9-4fb1-b0e1-76e559d614b0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0d9cd0d5-dc7d-4c04-a3b1-ad3bd3a4743c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bc679225-732e-4e19-a117-89a02730b34e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6630513c-0f53-4381-a5e8-649738728363
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 463d5bb9-9e12-43fd-ac87-095282e27679
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a08495f7-a0a1-482a-89d7-bca5b3cf8bf5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 000f8b85-b50c-4b0e-ab3b-fd075d5f0fbb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2202f764-425b-434b-b9f2-e65d4c8d13c6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9a24b513-ddb6-4310-a373-795f38ea1095
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cf81da57-22bb-4158-baa5-92e54ebe64db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8fab4e7c-068a-4208-a86f-ad0abeccf724
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c22e5714-87d0-4652-b788-09c2d343248d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cacd3ef3-2e09-4a1d-bc43-950b8836a1a8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4dbdd248-ea45-44ba-b2af-e31854776842
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d2121009-c1dd-4867-ace6-fa07bd8edf16
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c45bc6e5-2779-483e-956f-cd421a1a647e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 68806481-8dfc-429b-9394-45bb405c80e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6a2e72bd-bff1-42b8-a472-3cdda53d5a24
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c51db6b3-f1f2-40c0-b8d5-72f136154966
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 954a7c2c-b394-427a-9ce9-447fd6a60cf4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dda10b11-aa0c-4c8d-9e76-d561ff022e61
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 43759633-c34e-4c59-a3b1-edc9590fb11e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ba415ef4-5737-403a-8584-07c6f25ecb8b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c7b289ff-89ae-40ca-a6c9-a1c20271cee8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fe6a0e05-6dff-4fd1-afc6-7200e685c3b9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2610449e-34f0-41fd-8839-4b8fbacf5ee1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e809973c-e937-4e3c-87b2-1532670a3e5a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 285b67d2-8a86-4625-9d63-3727ebcf320a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3f0e2228-abd4-4143-b97f-37e01605dd3b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c4e47950-eb52-4c7a-b96a-87e230225ab2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 540de96a-f5c5-42f2-a6aa-c2397b7a9fcb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eb2e2a95-5aac-4e7a-983c-2622724c911e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aecc0a9a-d99f-4548-8e23-6932341d3a47
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a50cdca4-f3ae-45c3-8f18-cf85d6191125
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 62615297-1d72-41a7-8e21-94b0e6dea8c5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5ca10885-74bc-45fb-8d7f-5c0573ea885e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3dc8d6b2-2bc1-407e-bc05-c62c95896d3a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3f47ea9d-88c7-4746-ab1b-1494b9e18902
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aa94dc06-ff76-4bff-bba5-8c880f84d4ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ca5b91e2-168d-4e07-8d18-bfab79378dea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6e46f224-63d6-4f98-97d1-9c458d380868
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 928fa6c4-be8e-45f6-8b00-d23a1c294b95
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2a988ab7-6dbc-40f2-a38e-42eb573d0016
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 13275caf-8827-4334-8293-b55c3dc11555
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 25f11e39-abae-4af5-a766-b351c45974bc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d7cf9b27-6ccd-4492-ac79-cb62b3026de6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 602f24df-39a8-44a2-b5f4-43683ac0fe46
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 484a2a33-df32-42b4-a713-f2f91c411666
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5deb3381-842c-4a8d-99d3-abd7debf94ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8d6bbde7-2b35-4277-ae36-865f48c949df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d39c76ec-f1a7-4c2a-8a8a-e170a2f27835
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a2087ce9-113c-45bf-8714-a24e345d1ed6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f531463e-f137-4465-9768-5bc28127852b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8cbd4b02-84c2-4327-bd8d-8ab065924654
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9a0e7819-32fe-4a90-a589-aea63ac8de49
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6f516e0f-de33-4415-be7e-7d99d76ba885
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7320b9d8-19e4-4456-b6d2-5edc2d6d12ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1c1b1dea-5130-4ded-948a-a38415e8a744
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c1716e8f-b693-4e07-ac38-046ad9cd26a8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2a3a5e4c-93aa-4717-9aa7-2afe836be6fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 42ac278c-1ad7-4e1e-91eb-26a138df1871
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3f56976e-438d-47f8-a91f-fbc06d76d10f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dadfeeda-ab19-40ce-ae34-f8d5c83572c3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 87cb8995-3700-4eb3-87a9-bb1aa8b2b8a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 98deaa83-6b24-4c34-9a50-f823627160a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4c74f05a-3d02-45de-9116-211eeb35bbeb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 105dd8c9-0f1c-47ce-b612-0689d5c88b22
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 65a0b06b-ecaa-46fb-af7c-1b8e709bc01a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fb2a71c4-69b4-45c4-a938-5ae647fefbe4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a9b91ab9-b3b3-4005-ad66-b077e4410f6e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 14a4aa39-27b2-429e-84ab-8a678b250817
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fe651f99-8068-4e39-abe8-9d9a6e9098c3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3e7babac-4f8b-4731-b712-e8d47873c076
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f089bb1f-ec22-4761-804a-5a40e3cf1bd6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0f5b86c5-6999-47e9-a950-5e2714a294ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 211d7f54-6447-481d-a049-0ada1cea713d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message febde907-cc39-4938-af19-2100182d57ad
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8687 {grpc_status:14, grpc_message:"Socket closed"}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_54
Server: localhost:8687
Algorithm: FEDAVG
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_54
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_54/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_54/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_54/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_54/test_labels.txt

📊 Raw data loaded:
   Train: X=(3010, 24), y=(3010,)
   Test:  X=(753, 24), y=(753,)

⚠️  Limiting training data: 3010 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  744 samples, 5 features
✅ Client client_54 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

============================================================
🔄 Round 6 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0822 (↓), lr=0.001000
   • Epoch   2/100: train=0.0835, val=0.0848, patience=1/15, lr=0.001000
   ✓ Epoch   3/100: train=0.0841, val=0.0809 (↓), lr=0.001000
   ✓ Epoch   4/100: train=0.0826, val=0.0799 (↓), lr=0.001000
   • Epoch   5/100: train=0.0808, val=0.0795, patience=1/15, lr=0.001000
   • Epoch  11/100: train=0.0771, val=0.0789, patience=4/15, lr=0.001000
   📉 Epoch 17: LR reduced 0.001000 → 0.000500
   • Epoch  21/100: train=0.0701, val=0.0804, patience=14/15, lr=0.000500

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 6 Summary - Client client_54
   Epochs: 22/100 (early stopped)
   LR: 0.001000 → 0.000500 (1 reductions)
   Train: Loss=0.0782, RMSE=0.2797, R²=0.0642
   Val:   Loss=0.0794, RMSE=0.2817, R²=0.0245
============================================================


📊 Round 6 Test Metrics:
   Loss: 0.0883, RMSE: 0.2971, MAE: 0.2579, R²: 0.0103

============================================================
🔄 Round 7 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.000500
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0777 (↓), lr=0.000500
   • Epoch   2/100: train=0.0818, val=0.0786, patience=1/15, lr=0.000500
   • Epoch   3/100: train=0.0810, val=0.0795, patience=2/15, lr=0.000500
   • Epoch   4/100: train=0.0803, val=0.0802, patience=3/15, lr=0.000500
   • Epoch   5/100: train=0.0799, val=0.0806, patience=4/15, lr=0.000500
   📉 Epoch 7: LR reduced 0.000500 → 0.000250
   • Epoch  11/100: train=0.0775, val=0.0813, patience=10/15, lr=0.000250
   📉 Epoch 15: LR reduced 0.000250 → 0.000125

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 7 Summary - Client client_54
   Epochs: 16/100 (early stopped)
   LR: 0.000500 → 0.000125 (2 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=0.0348
   Val:   Loss=0.0777, RMSE=0.2787, R²=0.0133
============================================================


============================================================
🔄 Round 8 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.000125
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0796 (↓), lr=0.000125
   • Epoch   2/100: train=0.0806, val=0.0793, patience=1/15, lr=0.000125
   • Epoch   3/100: train=0.0805, val=0.0792, patience=2/15, lr=0.000125
   ✓ Epoch   4/100: train=0.0804, val=0.0791 (↓), lr=0.000125
   • Epoch   5/100: train=0.0803, val=0.0791, patience=1/15, lr=0.000125
   📉 Epoch 7: LR reduced 0.000125 → 0.000063
   • Epoch  11/100: train=0.0797, val=0.0788, patience=7/15, lr=0.000063
   📉 Epoch 15: LR reduced 0.000063 → 0.000031
   • Epoch  21/100: train=0.0792, val=0.0785, patience=4/15, lr=0.000031
   📉 Epoch 23: LR reduced 0.000031 → 0.000016
   📉 Epoch 31: LR reduced 0.000016 → 0.000008
   • Epoch  31/100: train=0.0790, val=0.0784, patience=14/15, lr=0.000008

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 8 Summary - Client client_54
   Epochs: 32/100 (early stopped)
   LR: 0.000125 → 0.000008 (4 reductions)
   Train: Loss=0.0794, RMSE=0.2817, R²=0.0481
   Val:   Loss=0.0786, RMSE=0.2804, R²=0.0414
============================================================


============================================================
🔄 Round 10 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.000008
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0777, val=0.0920 (↓), lr=0.000008
   • Epoch   2/100: train=0.0777, val=0.0920, patience=1/15, lr=0.000008
   • Epoch   3/100: train=0.0776, val=0.0919, patience=2/15, lr=0.000008
   • Epoch   4/100: train=0.0776, val=0.0919, patience=3/15, lr=0.000008
   • Epoch   5/100: train=0.0776, val=0.0918, patience=4/15, lr=0.000008
   📉 Epoch 7: LR reduced 0.000008 → 0.000004
   • Epoch  11/100: train=0.0774, val=0.0917, patience=10/15, lr=0.000004
   📉 Epoch 15: LR reduced 0.000004 → 0.000002

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0920)

============================================================
📊 Round 10 Summary - Client client_54
   Epochs: 16/100 (early stopped)
   LR: 0.000008 → 0.000002 (2 reductions)
   Train: Loss=0.0780, RMSE=0.2793, R²=0.0314
   Val:   Loss=0.0920, RMSE=0.3033, R²=0.0172
============================================================


📊 Round 10 Test Metrics:
   Loss: 0.0881, RMSE: 0.2967, MAE: 0.2576, R²: 0.0128

============================================================
🔄 Round 12 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.000002
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0831 (↓), lr=0.000002
   • Epoch   2/100: train=0.0802, val=0.0831, patience=1/15, lr=0.000002
   • Epoch   3/100: train=0.0802, val=0.0831, patience=2/15, lr=0.000002
   • Epoch   4/100: train=0.0802, val=0.0831, patience=3/15, lr=0.000002
   • Epoch   5/100: train=0.0802, val=0.0831, patience=4/15, lr=0.000002
   📉 Epoch 7: LR reduced 0.000002 → 0.000001
   • Epoch  11/100: train=0.0801, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 12 Summary - Client client_54
   Epochs: 16/100 (early stopped)
   LR: 0.000002 → 0.000001 (1 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=0.0313
   Val:   Loss=0.0831, RMSE=0.2883, R²=0.0098
============================================================


📊 Round 12 Test Metrics:
   Loss: 0.0881, RMSE: 0.2967, MAE: 0.2576, R²: 0.0129

============================================================
🔄 Round 13 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 13 Summary - Client client_54
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=0.0271
   Val:   Loss=0.0836, RMSE=0.2891, R²=0.0241
============================================================


📊 Round 13 Test Metrics:
   Loss: 0.0880, RMSE: 0.2967, MAE: 0.2576, R²: 0.0130

============================================================
🔄 Round 16 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 16 Summary - Client client_54
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=0.0305
   Val:   Loss=0.0800, RMSE=0.2829, R²=0.0118
============================================================


============================================================
🔄 Round 17 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 17 Summary - Client client_54
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=0.0196
   Val:   Loss=0.0788, RMSE=0.2808, R²=0.0631
============================================================


============================================================
🔄 Round 18 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 18 Summary - Client client_54
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=0.0313
   Val:   Loss=0.0806, RMSE=0.2839, R²=-0.0027
============================================================


============================================================
🔄 Round 19 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 19 Summary - Client client_54
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2847, R²=0.0301
   Val:   Loss=0.0796, RMSE=0.2821, R²=0.0135
============================================================


📊 Round 19 Test Metrics:
   Loss: 0.0880, RMSE: 0.2966, MAE: 0.2575, R²: 0.0135

📊 Round 19 Test Metrics:
   Loss: 0.0880, RMSE: 0.2966, MAE: 0.2575, R²: 0.0139

============================================================
🔄 Round 23 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 23 Summary - Client client_54
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2838, R²=0.0274
   Val:   Loss=0.0814, RMSE=0.2854, R²=0.0204
============================================================


📊 Round 23 Test Metrics:
   Loss: 0.0880, RMSE: 0.2966, MAE: 0.2574, R²: 0.0140

============================================================
🔄 Round 24 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0759 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0759, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0759, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0759, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0759, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0758, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0759)

============================================================
📊 Round 24 Summary - Client client_54
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=0.0337
   Val:   Loss=0.0759, RMSE=0.2754, R²=0.0099
============================================================


📊 Round 24 Test Metrics:
   Loss: 0.0880, RMSE: 0.2966, MAE: 0.2574, R²: 0.0139

============================================================
🔄 Round 25 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 25 Summary - Client client_54
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2819, R²=0.0248
   Val:   Loss=0.0858, RMSE=0.2929, R²=0.0412
============================================================


📊 Round 25 Test Metrics:
   Loss: 0.0880, RMSE: 0.2966, MAE: 0.2574, R²: 0.0139

============================================================
🔄 Round 28 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 28 Summary - Client client_54
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=0.0272
   Val:   Loss=0.0845, RMSE=0.2906, R²=0.0344
============================================================


============================================================
🔄 Round 30 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0770 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0770, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0770, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0770, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0770, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0770, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0770)

============================================================
📊 Round 30 Summary - Client client_54
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2857, R²=0.0293
   Val:   Loss=0.0770, RMSE=0.2776, R²=0.0279
============================================================


📊 Round 30 Test Metrics:
   Loss: 0.0880, RMSE: 0.2966, MAE: 0.2574, R²: 0.0139

============================================================
🔄 Round 31 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0774 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0774, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0774, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0774, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0774, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0774, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0774)

============================================================
📊 Round 31 Summary - Client client_54
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=0.0330
   Val:   Loss=0.0774, RMSE=0.2783, R²=0.0105
============================================================


📊 Round 31 Test Metrics:
   Loss: 0.0880, RMSE: 0.2966, MAE: 0.2574, R²: 0.0139

📊 Round 31 Test Metrics:
   Loss: 0.0880, RMSE: 0.2966, MAE: 0.2574, R²: 0.0139

============================================================
🔄 Round 34 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0718 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0718, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0718, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0717, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0717, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0717, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0718)

============================================================
📊 Round 34 Summary - Client client_54
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2880, R²=0.0309
   Val:   Loss=0.0718, RMSE=0.2679, R²=0.0069
============================================================


📊 Round 34 Test Metrics:
   Loss: 0.0880, RMSE: 0.2966, MAE: 0.2574, R²: 0.0139

📊 Round 34 Test Metrics:
   Loss: 0.0880, RMSE: 0.2966, MAE: 0.2574, R²: 0.0139

📊 Round 34 Test Metrics:
   Loss: 0.0880, RMSE: 0.2966, MAE: 0.2574, R²: 0.0139

============================================================
🔄 Round 38 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0745 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0745, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0745, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0744, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0744, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0744, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0745)

============================================================
📊 Round 38 Summary - Client client_54
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=0.0303
   Val:   Loss=0.0745, RMSE=0.2729, R²=0.0027
============================================================


📊 Round 38 Test Metrics:
   Loss: 0.0880, RMSE: 0.2966, MAE: 0.2574, R²: 0.0139

📊 Round 38 Test Metrics:
   Loss: 0.0880, RMSE: 0.2966, MAE: 0.2574, R²: 0.0139

📊 Round 38 Test Metrics:
   Loss: 0.0880, RMSE: 0.2966, MAE: 0.2574, R²: 0.0139

============================================================
🔄 Round 41 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 41 Summary - Client client_54
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2818, R²=0.0281
   Val:   Loss=0.0860, RMSE=0.2933, R²=0.0292
============================================================


📊 Round 41 Test Metrics:
   Loss: 0.0880, RMSE: 0.2966, MAE: 0.2574, R²: 0.0140

📊 Round 41 Test Metrics:
   Loss: 0.0880, RMSE: 0.2966, MAE: 0.2574, R²: 0.0140

📊 Round 41 Test Metrics:
   Loss: 0.0880, RMSE: 0.2966, MAE: 0.2574, R²: 0.0139

📊 Round 41 Test Metrics:
   Loss: 0.0880, RMSE: 0.2966, MAE: 0.2574, R²: 0.0140

📊 Round 41 Test Metrics:
   Loss: 0.0880, RMSE: 0.2966, MAE: 0.2574, R²: 0.0140

============================================================
🔄 Round 50 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 50 Summary - Client client_54
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2843, R²=0.0228
   Val:   Loss=0.0802, RMSE=0.2832, R²=0.0426
============================================================


📊 Round 50 Test Metrics:
   Loss: 0.0880, RMSE: 0.2966, MAE: 0.2574, R²: 0.0140

============================================================
🔄 Round 51 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 51 Summary - Client client_54
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=0.0286
   Val:   Loss=0.0803, RMSE=0.2834, R²=0.0294
============================================================


📊 Round 51 Test Metrics:
   Loss: 0.0880, RMSE: 0.2966, MAE: 0.2574, R²: 0.0140

============================================================
🔄 Round 53 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 53 Summary - Client client_54
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=0.0288
   Val:   Loss=0.0804, RMSE=0.2835, R²=0.0287
============================================================


📊 Round 53 Test Metrics:
   Loss: 0.0880, RMSE: 0.2966, MAE: 0.2574, R²: 0.0140

============================================================
🔄 Round 54 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 54 Summary - Client client_54
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=0.0329
   Val:   Loss=0.0813, RMSE=0.2851, R²=0.0051
============================================================


============================================================
🔄 Round 55 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0769 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0769, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0769, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0769, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0769, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0769, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0769)

============================================================
📊 Round 55 Summary - Client client_54
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=0.0316
   Val:   Loss=0.0769, RMSE=0.2774, R²=0.0177
============================================================


📊 Round 55 Test Metrics:
   Loss: 0.0880, RMSE: 0.2966, MAE: 0.2574, R²: 0.0140

============================================================
🔄 Round 60 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 60 Summary - Client client_54
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=0.0307
   Val:   Loss=0.0786, RMSE=0.2804, R²=0.0222
============================================================


============================================================
🔄 Round 62 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 62 Summary - Client client_54
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=0.0319
   Val:   Loss=0.0793, RMSE=0.2815, R²=0.0154
============================================================


📊 Round 62 Test Metrics:
   Loss: 0.0880, RMSE: 0.2966, MAE: 0.2574, R²: 0.0140

============================================================
🔄 Round 63 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 63 Summary - Client client_54
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=0.0223
   Val:   Loss=0.0789, RMSE=0.2809, R²=0.0555
============================================================


📊 Round 63 Test Metrics:
   Loss: 0.0880, RMSE: 0.2966, MAE: 0.2574, R²: 0.0140

============================================================
🔄 Round 64 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 64 Summary - Client client_54
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=0.0241
   Val:   Loss=0.0805, RMSE=0.2837, R²=0.0494
============================================================


📊 Round 64 Test Metrics:
   Loss: 0.0880, RMSE: 0.2966, MAE: 0.2574, R²: 0.0140

============================================================
🔄 Round 66 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0743 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0743, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0743, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0743, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0742, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0742, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0743)

============================================================
📊 Round 66 Summary - Client client_54
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=0.0308
   Val:   Loss=0.0743, RMSE=0.2725, R²=0.0213
============================================================


📊 Round 66 Test Metrics:
   Loss: 0.0879, RMSE: 0.2966, MAE: 0.2574, R²: 0.0140

============================================================
🔄 Round 69 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0728 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0728, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0728, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0728, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0727, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0727, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0728)

============================================================
📊 Round 69 Summary - Client client_54
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=0.0258
   Val:   Loss=0.0728, RMSE=0.2698, R²=0.0443
============================================================


============================================================
🔄 Round 70 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0761 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0761, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0761, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0761, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0761, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0761, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0761)

============================================================
📊 Round 70 Summary - Client client_54
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2861, R²=0.0372
   Val:   Loss=0.0761, RMSE=0.2758, R²=-0.0061
============================================================


============================================================
🔄 Round 71 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0772 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0771, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0771, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0771, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0771, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0771, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 71 Summary - Client client_54
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=0.0305
   Val:   Loss=0.0772, RMSE=0.2778, R²=0.0160
============================================================


============================================================
🔄 Round 73 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0773, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 73 Summary - Client client_54
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=0.0251
   Val:   Loss=0.0773, RMSE=0.2781, R²=0.0468
============================================================


============================================================
🔄 Round 74 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0771 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0770, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0770, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0770, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0770, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0770, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0771)

============================================================
📊 Round 74 Summary - Client client_54
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=0.0332
   Val:   Loss=0.0771, RMSE=0.2776, R²=0.0124
============================================================


📊 Round 74 Test Metrics:
   Loss: 0.0879, RMSE: 0.2966, MAE: 0.2574, R²: 0.0141

============================================================
🔄 Round 77 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0778, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0778, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0778, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0778, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0778, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 77 Summary - Client client_54
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=0.0308
   Val:   Loss=0.0778, RMSE=0.2790, R²=-0.0077
============================================================


============================================================
🔄 Round 78 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 78 Summary - Client client_54
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=0.0300
   Val:   Loss=0.0833, RMSE=0.2885, R²=0.0211
============================================================


============================================================
🔄 Round 79 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0756 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0756, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0756, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0756, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0756, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0756, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0756)

============================================================
📊 Round 79 Summary - Client client_54
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=0.0314
   Val:   Loss=0.0756, RMSE=0.2749, R²=0.0152
============================================================


📊 Round 79 Test Metrics:
   Loss: 0.0879, RMSE: 0.2965, MAE: 0.2574, R²: 0.0141

📊 Round 79 Test Metrics:
   Loss: 0.0879, RMSE: 0.2965, MAE: 0.2574, R²: 0.0141

============================================================
🔄 Round 83 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 83 Summary - Client client_54
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2820, R²=0.0326
   Val:   Loss=0.0855, RMSE=0.2924, R²=0.0174
============================================================


📊 Round 83 Test Metrics:
   Loss: 0.0879, RMSE: 0.2965, MAE: 0.2574, R²: 0.0141

📊 Round 83 Test Metrics:
   Loss: 0.0879, RMSE: 0.2965, MAE: 0.2574, R²: 0.0141

📊 Round 83 Test Metrics:
   Loss: 0.0879, RMSE: 0.2965, MAE: 0.2574, R²: 0.0141

============================================================
🔄 Round 88 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 88 Summary - Client client_54
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2826, R²=0.0265
   Val:   Loss=0.0841, RMSE=0.2899, R²=0.0404
============================================================


============================================================
🔄 Round 89 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0779 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0778, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0778, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0778, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0778, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0778, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0779)

============================================================
📊 Round 89 Summary - Client client_54
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=0.0265
   Val:   Loss=0.0779, RMSE=0.2790, R²=0.0267
============================================================


📊 Round 89 Test Metrics:
   Loss: 0.0879, RMSE: 0.2965, MAE: 0.2574, R²: 0.0141

============================================================
🔄 Round 90 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 90 Summary - Client client_54
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=0.0288
   Val:   Loss=0.0802, RMSE=0.2833, R²=0.0319
============================================================


============================================================
🔄 Round 92 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0766 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0766, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0766, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0766, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0766, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0766, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0766)

============================================================
📊 Round 92 Summary - Client client_54
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=0.0264
   Val:   Loss=0.0766, RMSE=0.2768, R²=0.0425
============================================================


📊 Round 92 Test Metrics:
   Loss: 0.0879, RMSE: 0.2965, MAE: 0.2574, R²: 0.0141

============================================================
🔄 Round 95 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 95 Summary - Client client_54
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=0.0316
   Val:   Loss=0.0787, RMSE=0.2806, R²=0.0156
============================================================


============================================================
🔄 Round 96 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 96 Summary - Client client_54
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=0.0300
   Val:   Loss=0.0800, RMSE=0.2828, R²=0.0170
============================================================


📊 Round 96 Test Metrics:
   Loss: 0.0879, RMSE: 0.2965, MAE: 0.2574, R²: 0.0142

============================================================
🔄 Round 97 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 97 Summary - Client client_54
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2838, R²=0.0264
   Val:   Loss=0.0813, RMSE=0.2852, R²=0.0409
============================================================


============================================================
🔄 Round 98 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0770 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0770, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0770, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0770, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0770, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0770, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0770)

============================================================
📊 Round 98 Summary - Client client_54
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=0.0343
   Val:   Loss=0.0770, RMSE=0.2775, R²=0.0049
============================================================


📊 Round 98 Test Metrics:
   Loss: 0.0879, RMSE: 0.2965, MAE: 0.2574, R²: 0.0142

============================================================
🔄 Round 100 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 100 Summary - Client client_54
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2818, R²=0.0281
   Val:   Loss=0.0857, RMSE=0.2928, R²=0.0259
============================================================


📊 Round 100 Test Metrics:
   Loss: 0.0879, RMSE: 0.2965, MAE: 0.2574, R²: 0.0142

============================================================
🔄 Round 102 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0893 (↓), lr=0.000001
   • Epoch   2/100: train=0.0785, val=0.0893, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0785, val=0.0893, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0785, val=0.0892, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0785, val=0.0892, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0892, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0893)

============================================================
📊 Round 102 Summary - Client client_54
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2803, R²=0.0309
   Val:   Loss=0.0893, RMSE=0.2988, R²=0.0233
============================================================


📊 Round 102 Test Metrics:
   Loss: 0.0879, RMSE: 0.2965, MAE: 0.2574, R²: 0.0142

📊 Round 102 Test Metrics:
   Loss: 0.0879, RMSE: 0.2965, MAE: 0.2574, R²: 0.0142

============================================================
🔄 Round 106 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0643 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0643, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0643, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0643, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0643, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0644, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0643)

============================================================
📊 Round 106 Summary - Client client_54
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=0.0357
   Val:   Loss=0.0643, RMSE=0.2536, R²=-0.0123
============================================================


📊 Round 106 Test Metrics:
   Loss: 0.0879, RMSE: 0.2965, MAE: 0.2574, R²: 0.0142

📊 Round 106 Test Metrics:
   Loss: 0.0879, RMSE: 0.2965, MAE: 0.2574, R²: 0.0142

============================================================
🔄 Round 111 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 111 Summary - Client client_54
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2816, R²=0.0200
   Val:   Loss=0.0862, RMSE=0.2937, R²=0.0637
============================================================


============================================================
🔄 Round 112 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 112 Summary - Client client_54
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2845, R²=0.0337
   Val:   Loss=0.0797, RMSE=0.2824, R²=0.0122
============================================================


📊 Round 112 Test Metrics:
   Loss: 0.0879, RMSE: 0.2965, MAE: 0.2574, R²: 0.0142

📊 Round 112 Test Metrics:
   Loss: 0.0879, RMSE: 0.2965, MAE: 0.2574, R²: 0.0143

📊 Round 112 Test Metrics:
   Loss: 0.0879, RMSE: 0.2965, MAE: 0.2574, R²: 0.0143

============================================================
🔄 Round 118 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0693 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0693, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0693, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0693, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0693, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0694, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0693)

============================================================
📊 Round 118 Summary - Client client_54
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=0.0239
   Val:   Loss=0.0693, RMSE=0.2632, R²=0.0433
============================================================


📊 Round 118 Test Metrics:
   Loss: 0.0879, RMSE: 0.2965, MAE: 0.2574, R²: 0.0143

============================================================
🔄 Round 119 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0778, val=0.0914 (↓), lr=0.000001
   • Epoch   2/100: train=0.0778, val=0.0914, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0778, val=0.0914, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0777, val=0.0914, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0777, val=0.0914, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0777, val=0.0913, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0914)

============================================================
📊 Round 119 Summary - Client client_54
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0780, RMSE=0.2793, R²=0.0318
   Val:   Loss=0.0914, RMSE=0.3024, R²=0.0225
============================================================


📊 Round 119 Test Metrics:
   Loss: 0.0879, RMSE: 0.2965, MAE: 0.2574, R²: 0.0143

📊 Round 119 Test Metrics:
   Loss: 0.0879, RMSE: 0.2965, MAE: 0.2574, R²: 0.0143

📊 Round 119 Test Metrics:
   Loss: 0.0879, RMSE: 0.2965, MAE: 0.2574, R²: 0.0143

============================================================
🔄 Round 124 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0719 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0719, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0719, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0719, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0719, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0719, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0719)

============================================================
📊 Round 124 Summary - Client client_54
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=0.0264
   Val:   Loss=0.0719, RMSE=0.2681, R²=0.0409
============================================================


📊 Round 124 Test Metrics:
   Loss: 0.0879, RMSE: 0.2965, MAE: 0.2574, R²: 0.0143

============================================================
🔄 Round 125 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0864, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0864, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 125 Summary - Client client_54
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2815, R²=0.0323
   Val:   Loss=0.0864, RMSE=0.2939, R²=0.0177
============================================================


📊 Round 125 Test Metrics:
   Loss: 0.0879, RMSE: 0.2965, MAE: 0.2574, R²: 0.0143

============================================================
🔄 Round 127 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 127 Summary - Client client_54
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2831, R²=0.0273
   Val:   Loss=0.0827, RMSE=0.2876, R²=0.0387
============================================================


============================================================
🔄 Round 128 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 128 Summary - Client client_54
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=0.0306
   Val:   Loss=0.0831, RMSE=0.2882, R²=0.0266
============================================================


📊 Round 128 Test Metrics:
   Loss: 0.0879, RMSE: 0.2965, MAE: 0.2574, R²: 0.0143

============================================================
🔄 Round 129 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0763 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0763, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0763, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0763, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0763, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0763, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0763)

============================================================
📊 Round 129 Summary - Client client_54
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2859, R²=0.0280
   Val:   Loss=0.0763, RMSE=0.2762, R²=0.0291
============================================================


📊 Round 129 Test Metrics:
   Loss: 0.0879, RMSE: 0.2965, MAE: 0.2574, R²: 0.0143

📊 Round 129 Test Metrics:
   Loss: 0.0879, RMSE: 0.2965, MAE: 0.2574, R²: 0.0143

📊 Round 129 Test Metrics:
   Loss: 0.0879, RMSE: 0.2965, MAE: 0.2574, R²: 0.0143

============================================================
🔄 Round 134 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0782, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 134 Summary - Client client_54
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=0.0303
   Val:   Loss=0.0783, RMSE=0.2798, R²=0.0085
============================================================


📊 Round 134 Test Metrics:
   Loss: 0.0879, RMSE: 0.2965, MAE: 0.2574, R²: 0.0143

📊 Round 134 Test Metrics:
   Loss: 0.0879, RMSE: 0.2965, MAE: 0.2574, R²: 0.0143

📊 Round 134 Test Metrics:
   Loss: 0.0879, RMSE: 0.2965, MAE: 0.2574, R²: 0.0143

============================================================
🔄 Round 138 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 138 Summary - Client client_54
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2816, R²=0.0340
   Val:   Loss=0.0862, RMSE=0.2936, R²=0.0032
============================================================


📊 Round 138 Test Metrics:
   Loss: 0.0879, RMSE: 0.2965, MAE: 0.2574, R²: 0.0143

============================================================
🔄 Round 139 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 139 Summary - Client client_54
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=0.0338
   Val:   Loss=0.0810, RMSE=0.2846, R²=0.0130
============================================================


============================================================
🔄 Round 141 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0740 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0740, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0740, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0740, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0740, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0740, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0740)

============================================================
📊 Round 141 Summary - Client client_54
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=0.0261
   Val:   Loss=0.0740, RMSE=0.2721, R²=0.0396
============================================================


📊 Round 141 Test Metrics:
   Loss: 0.0879, RMSE: 0.2965, MAE: 0.2574, R²: 0.0143

============================================================
🔄 Round 145 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 145 Summary - Client client_54
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2840, R²=0.0345
   Val:   Loss=0.0808, RMSE=0.2842, R²=-0.0003
============================================================


============================================================
🔄 Round 146 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 146 Summary - Client client_54
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=0.0261
   Val:   Loss=0.0842, RMSE=0.2901, R²=0.0426
============================================================


📊 Round 146 Test Metrics:
   Loss: 0.0879, RMSE: 0.2965, MAE: 0.2574, R²: 0.0144

============================================================
🔄 Round 147 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 147 Summary - Client client_54
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=0.0261
   Val:   Loss=0.0798, RMSE=0.2825, R²=0.0416
============================================================


📊 Round 147 Test Metrics:
   Loss: 0.0879, RMSE: 0.2965, MAE: 0.2574, R²: 0.0144

============================================================
🔄 Round 151 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0771 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0771, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0771, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0770, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0770, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0770, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0771)

============================================================
📊 Round 151 Summary - Client client_54
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=0.0299
   Val:   Loss=0.0771, RMSE=0.2776, R²=0.0224
============================================================


📊 Round 151 Test Metrics:
   Loss: 0.0879, RMSE: 0.2965, MAE: 0.2574, R²: 0.0144

📊 Round 151 Test Metrics:
   Loss: 0.0879, RMSE: 0.2965, MAE: 0.2574, R²: 0.0144

📊 Round 151 Test Metrics:
   Loss: 0.0879, RMSE: 0.2965, MAE: 0.2574, R²: 0.0144

============================================================
🔄 Round 158 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 158 Summary - Client client_54
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=0.0281
   Val:   Loss=0.0797, RMSE=0.2824, R²=0.0363
============================================================


============================================================
🔄 Round 161 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 161 Summary - Client client_54
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2820, R²=0.0297
   Val:   Loss=0.0853, RMSE=0.2921, R²=0.0281
============================================================


📊 Round 161 Test Metrics:
   Loss: 0.0879, RMSE: 0.2965, MAE: 0.2574, R²: 0.0144

============================================================
🔄 Round 165 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 165 Summary - Client client_54
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2831, R²=0.0316
   Val:   Loss=0.0828, RMSE=0.2877, R²=0.0221
============================================================


📊 Round 165 Test Metrics:
   Loss: 0.0879, RMSE: 0.2965, MAE: 0.2574, R²: 0.0144

📊 Round 165 Test Metrics:
   Loss: 0.0879, RMSE: 0.2965, MAE: 0.2574, R²: 0.0144

📊 Round 165 Test Metrics:
   Loss: 0.0879, RMSE: 0.2965, MAE: 0.2574, R²: 0.0144

📊 Round 165 Test Metrics:
   Loss: 0.0879, RMSE: 0.2965, MAE: 0.2574, R²: 0.0144

============================================================
🔄 Round 176 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 176 Summary - Client client_54
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=0.0335
   Val:   Loss=0.0820, RMSE=0.2864, R²=0.0123
============================================================


📊 Round 176 Test Metrics:
   Loss: 0.0879, RMSE: 0.2965, MAE: 0.2574, R²: 0.0144

============================================================
🔄 Round 178 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 178 Summary - Client client_54
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2829, R²=0.0222
   Val:   Loss=0.0832, RMSE=0.2884, R²=0.0573
============================================================


📊 Round 178 Test Metrics:
   Loss: 0.0879, RMSE: 0.2965, MAE: 0.2574, R²: 0.0144

============================================================
🔄 Round 180 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 180 Summary - Client client_54
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2843, R²=0.0280
   Val:   Loss=0.0799, RMSE=0.2827, R²=0.0369
============================================================


📊 Round 180 Test Metrics:
   Loss: 0.0879, RMSE: 0.2965, MAE: 0.2574, R²: 0.0144

============================================================
🔄 Round 182 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0782, val=0.0902 (↓), lr=0.000001
   • Epoch   2/100: train=0.0782, val=0.0902, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0782, val=0.0902, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0782, val=0.0902, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0782, val=0.0902, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0781, val=0.0902, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0902)

============================================================
📊 Round 182 Summary - Client client_54
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0783, RMSE=0.2798, R²=0.0362
   Val:   Loss=0.0902, RMSE=0.3004, R²=0.0040
============================================================


📊 Round 182 Test Metrics:
   Loss: 0.0879, RMSE: 0.2965, MAE: 0.2574, R²: 0.0144

📊 Round 182 Test Metrics:
   Loss: 0.0879, RMSE: 0.2965, MAE: 0.2574, R²: 0.0144

============================================================
🔄 Round 185 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 185 Summary - Client client_54
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=0.0341
   Val:   Loss=0.0810, RMSE=0.2846, R²=0.0110
============================================================


📊 Round 185 Test Metrics:
   Loss: 0.0879, RMSE: 0.2965, MAE: 0.2574, R²: 0.0144

============================================================
🔄 Round 186 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 186 Summary - Client client_54
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2829, R²=0.0271
   Val:   Loss=0.0832, RMSE=0.2885, R²=0.0377
============================================================


📊 Round 186 Test Metrics:
   Loss: 0.0879, RMSE: 0.2965, MAE: 0.2574, R²: 0.0144

📊 Round 186 Test Metrics:
   Loss: 0.0879, RMSE: 0.2965, MAE: 0.2574, R²: 0.0144

📊 Round 186 Test Metrics:
   Loss: 0.0879, RMSE: 0.2965, MAE: 0.2574, R²: 0.0144

📊 Round 186 Test Metrics:
   Loss: 0.0879, RMSE: 0.2965, MAE: 0.2574, R²: 0.0144

📊 Round 186 Test Metrics:
   Loss: 0.0879, RMSE: 0.2965, MAE: 0.2574, R²: 0.0144

📊 Round 186 Test Metrics:
   Loss: 0.0879, RMSE: 0.2965, MAE: 0.2574, R²: 0.0144

============================================================
🔄 Round 192 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0731 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0730, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0730, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0730, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0730, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0730, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0731)

============================================================
📊 Round 192 Summary - Client client_54
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=0.0342
   Val:   Loss=0.0731, RMSE=0.2703, R²=-0.0006
============================================================


📊 Round 192 Test Metrics:
   Loss: 0.0879, RMSE: 0.2965, MAE: 0.2574, R²: 0.0144

============================================================
🔄 Round 193 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0871 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0871, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0871, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0871, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0871, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0871, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0871)

============================================================
📊 Round 193 Summary - Client client_54
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2812, R²=0.0276
   Val:   Loss=0.0871, RMSE=0.2951, R²=0.0364
============================================================


============================================================
🔄 Round 194 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 194 Summary - Client client_54
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2840, R²=0.0239
   Val:   Loss=0.0807, RMSE=0.2841, R²=0.0522
============================================================


📊 Round 194 Test Metrics:
   Loss: 0.0879, RMSE: 0.2965, MAE: 0.2574, R²: 0.0144

============================================================
🔄 Round 196 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 196 Summary - Client client_54
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=0.0311
   Val:   Loss=0.0819, RMSE=0.2862, R²=0.0232
============================================================


📊 Round 196 Test Metrics:
   Loss: 0.0879, RMSE: 0.2965, MAE: 0.2574, R²: 0.0144

📊 Round 196 Test Metrics:
   Loss: 0.0879, RMSE: 0.2965, MAE: 0.2574, R²: 0.0144

============================================================
🔄 Round 199 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0769 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0769, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0770, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0770, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0770, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0769)

============================================================
📊 Round 199 Summary - Client client_54
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=0.0185
   Val:   Loss=0.0769, RMSE=0.2773, R²=0.0412
============================================================


📊 Round 199 Test Metrics:
   Loss: 0.0879, RMSE: 0.2965, MAE: 0.2574, R²: 0.0144

📊 Round 199 Test Metrics:
   Loss: 0.0879, RMSE: 0.2965, MAE: 0.2573, R²: 0.0144

📊 Round 199 Test Metrics:
   Loss: 0.0879, RMSE: 0.2965, MAE: 0.2573, R²: 0.0144

============================================================
🔄 Round 207 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 207 Summary - Client client_54
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=0.0288
   Val:   Loss=0.0835, RMSE=0.2890, R²=0.0306
============================================================


📊 Round 207 Test Metrics:
   Loss: 0.0879, RMSE: 0.2965, MAE: 0.2573, R²: 0.0144

📊 Round 207 Test Metrics:
   Loss: 0.0879, RMSE: 0.2965, MAE: 0.2573, R²: 0.0144

============================================================
🔄 Round 209 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0773, val=0.0946 (↓), lr=0.000001
   • Epoch   2/100: train=0.0773, val=0.0945, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0773, val=0.0945, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0772, val=0.0945, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0772, val=0.0945, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0772, val=0.0945, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0946)

============================================================
📊 Round 209 Summary - Client client_54
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0772, RMSE=0.2779, R²=0.0323
   Val:   Loss=0.0946, RMSE=0.3075, R²=0.0208
============================================================


📊 Round 209 Test Metrics:
   Loss: 0.0879, RMSE: 0.2965, MAE: 0.2573, R²: 0.0144

============================================================
🔄 Round 212 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 212 Summary - Client client_54
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2838, R²=0.0317
   Val:   Loss=0.0812, RMSE=0.2849, R²=0.0218
============================================================


============================================================
🔄 Round 213 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 213 Summary - Client client_54
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2847, R²=0.0260
   Val:   Loss=0.0791, RMSE=0.2813, R²=0.0391
============================================================


📊 Round 213 Test Metrics:
   Loss: 0.0879, RMSE: 0.2965, MAE: 0.2573, R²: 0.0145

============================================================
🔄 Round 216 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 216 Summary - Client client_54
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2847, R²=0.0292
   Val:   Loss=0.0790, RMSE=0.2812, R²=0.0320
============================================================


📊 Round 216 Test Metrics:
   Loss: 0.0879, RMSE: 0.2965, MAE: 0.2573, R²: 0.0145

============================================================
🔄 Round 218 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0777 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0777, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0777, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0777, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0777, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0777, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 218 Summary - Client client_54
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=0.0295
   Val:   Loss=0.0777, RMSE=0.2788, R²=0.0303
============================================================


============================================================
🔄 Round 219 - Client client_54
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 219 Summary - Client client_54
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2820, R²=0.0243
   Val:   Loss=0.0852, RMSE=0.2919, R²=0.0491
============================================================


📊 Round 219 Test Metrics:
   Loss: 0.0879, RMSE: 0.2965, MAE: 0.2573, R²: 0.0145

❌ Client client_54 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8687 {grpc_status:14, grpc_message:"Socket closed"}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8687 {grpc_status:14, grpc_message:"Socket closed"}"
>
