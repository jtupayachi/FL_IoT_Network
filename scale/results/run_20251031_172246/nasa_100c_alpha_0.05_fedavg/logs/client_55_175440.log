[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7aae19a6-d327-4387-af62-cb1c153e878e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7e8531be-65f4-430b-95a6-dc08e637061b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8cdd3ee0-31de-4bcb-a18b-8bf1240a8a18
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eafcabd2-4294-458d-abd6-e10a94804849
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dc5eb487-4674-4999-9fd1-898b3e6cf3e5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b4b7c8d1-b144-4b28-8d71-4a72c4015b9d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 34621079-c294-4a1e-bd36-2105643a5b99
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 379da643-fda4-46bd-ad3c-fcca95def7f2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 36eea98e-33b0-48e0-85d9-e6d1c2d1c687
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 55ec4f9b-2b7f-4761-a9e1-ee5ce82b6b7f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a4545969-af75-4056-83ae-147efb62844e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f0f38f8f-b7a0-4946-a3a7-41ea371a5ab2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5dc015f0-70e5-4bec-a732-0be8e5590cc9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 34fd9de6-f5e6-4d87-8457-742797312579
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 04de3d71-72f6-46e6-a481-bf1e4e66a83b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 63f9c1fa-1245-4b7d-a369-fde0db4657df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9785682c-39b5-459c-ba7a-973ade983371
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 75ee807c-66f0-4799-ae07-c33f602378ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bf443baa-cd6d-4e59-b094-8f2052a541e1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6871db5b-23cf-4568-89f9-33514fb87f1e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 029a005e-d860-4f07-97c2-6f1aa215f505
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c59979e9-4819-4b5f-a038-5c63e43c82f2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 479feea7-2602-486e-9da7-1392c275c6fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aa9143ef-8426-43df-acff-0d793d12b004
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 023fe434-7bdb-4ced-b812-ebf8f1817ea7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b1c34bae-0a81-4d17-8429-aad2f206afa0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3f5c4a63-f35f-41f4-b851-1411da6fa81a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9c7d7bab-8705-480d-a2f1-ae6a5ca50257
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 37696756-6c2b-4fea-801f-a376cf73fa02
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7d082911-90a8-4161-9eb3-adf33150137a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 403adb45-7c67-4b35-9233-594ea192297e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1d34f5fa-27ad-46cd-9570-d0c1e5048601
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a22a2503-580d-429c-9b8c-7f0a759f42da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cf5bae37-2e95-468a-a613-7c7cd83db9e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fa537d75-af24-4f80-aef5-c2dae375752f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b9193f24-3baf-4def-8783-c41aad942b26
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a5444b3f-2338-4368-9621-d9e0772493c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cb845338-ffe5-4379-86c5-f85b32adcc8c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5bddf391-5e54-4905-ac68-922261d73e74
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5594cf2a-98f7-489b-9be7-0a03dabea7bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 09a21d14-6515-45da-8b21-3b95f6d7ff24
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 94c239c4-8720-42ea-afcc-2b8c73bda2ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5709ccab-24a1-4d93-83fa-12542ce10c50
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cd970eeb-e8a0-4ec8-a048-18c8c6f32db2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7d3d4ebd-f8d7-4ad6-af38-e0012c809850
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e2a3246a-4b16-415d-a8c3-dad16574e3e8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0b6dffc7-f441-4b5d-83bc-6bbc74465f9b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bc44281c-a1e6-44b1-93b2-5fc0cf98f911
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5ba066ca-aff7-436f-8bf4-f0a60a649acf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message edd6e6ef-c000-4114-897b-6e43316b6eb5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6e9b717b-02ab-4886-85e4-ca4bc2ebbaa5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cdd02316-f772-4f74-a6fc-b5e8a6809a3d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3465d961-7a9d-467e-b78a-5f0a22b16857
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 51cfba41-96bd-4069-9310-34f51daf6579
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 910a4ec4-358a-4cab-8f65-2667fddc4640
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e293922f-df3e-49bb-890b-b4031bd0dc3c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dbf56919-ce6e-424d-be2c-d3c82e0b7058
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 76e250e7-299e-4e1f-889c-860e6adce682
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 819c0a55-79c8-4770-a31f-c6872e568299
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9ad10a51-188f-4d19-b8bf-199968303f33
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 63a3dba1-6030-43f4-87a6-ab161ddd6d89
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b3263a53-f434-4cef-b77e-a1335ee6aa2c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bba5ff14-bd06-46a4-ade9-92e7e008cbe1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 772af617-9dce-415c-a163-e66156e929c5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ee07df65-f9f1-420b-94cb-78e2af0fa6a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 137070e0-ded8-44b9-9e6c-3de23691b330
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3d6955df-3150-49d7-bef8-deff4eaa4817
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 578253e4-7fda-4f39-997e-7023f3a45938
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 539b2806-994f-460b-bb98-2541d471520b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5ac6c4d8-28fc-4012-9775-c321a1b3dd3f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9b75b419-3ecc-41e5-b75d-cc9ca7eb1046
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 27b160af-2d33-4d7e-bbd7-1a18d6951a5a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f18e7cf4-30d0-4efe-bea3-fdf3ce4e1982
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 45106a46-1d5e-419a-99d8-c6023ffc43cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 89c58070-f17b-4cba-9d2c-381ee503e2ea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message adc87fdd-25ce-418e-aac2-3ba542306f27
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3257ec1e-db9a-427f-aadf-998645db7b43
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 91f9db4f-f40d-4b1c-a309-b75ac489eb2d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 948a9527-91d9-4795-a030-89d74943972b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 117a485d-af9c-4e19-a7db-e9e15f2e3dd2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b23d5c39-f58c-4d2a-87c0-52b4b1afef2d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2b81a345-9206-49a3-b2a3-9a257c820f8d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 377b5087-3859-499b-921b-ecdb206de853
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e67a30b1-4108-4944-9c0a-e323e3bbeb8f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ce82cca0-471a-44a8-8195-882c9a07ce41
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4613b806-e455-4bfc-b694-e5ee7012a9a7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a57c42ca-0693-4ed7-89f2-ec5de13c7d8b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4b5776bc-1b0c-4336-9fce-edd36586bcf7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3ba9a849-0c41-4cb7-81d5-b7564ac915cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dc484ac6-7901-42f7-80a5-a2bd1c626d94
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a857ecec-3bb2-482a-92b4-79e46745a923
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 022727d6-7825-4e3a-9620-2839e860f282
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e7d888cc-0916-400f-86cc-e027a770b5f7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a478bc4f-75be-42cb-977f-8222e0ba9cbd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cafc1841-9493-4244-b364-5d2a039b2664
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 591f0893-88f3-456e-8e64-ca2ecb5ee8eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 903e7bbe-4116-4690-adc4-67ec593e2d73
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fb7b5231-6b20-458e-8eaf-166484db5265
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7b72df80-8437-44b2-aea9-f27e6d226e54
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9d7afed1-3918-46ba-9139-bd8d24dcbda1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message acc7504c-2c8f-40af-a053-354515241187
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a7d08eb4-9af8-4cbf-8c1b-26e65f157d94
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5cc28cc7-52ce-44ff-87a5-e9cbe8dd38cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d3232695-e4c0-43f0-a98f-e8c50d7dd113
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2e478dd7-7768-4265-ade2-44bcde42ec92
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2c82edf3-1d33-4b5a-9932-5b0e5503eede
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bda24f09-e969-4ee8-841e-6e71fed1f6da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e07c2bc4-5fc3-4daf-bd17-72f19c380c07
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f6a674a9-579e-4ea4-b4f6-6d9dd8ac63ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0c9df477-c8c0-4015-b791-b8db7273b0f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7c5e2ac3-487b-40d6-baf4-9e1e557f92ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 71682309-746c-4c5a-b7d8-bb849879e241
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1c147a03-04e2-491d-8fb1-77d706e4cf91
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cd9b22e0-bd99-41fb-9918-dc29591538a0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f70b9d83-3b9a-44db-9d30-fdc4363855fb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 944376ba-5be7-4bfd-8e08-2c66c2603aaa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6afcee5d-0d89-49ec-9393-cbe97534a515
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cdff1e6b-56f3-407c-b546-594a389824dd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8338c1fd-9ab8-4acf-87b1-a22aec72252d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b2237cc3-1592-4536-9170-46b2b002ee6e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4b22018a-6f96-4661-80da-882217c3c527
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b9acbf5c-c4c5-4302-a948-989d9a30b7d5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0f6650fa-a64e-4f92-a49c-520e76e7e41c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9874604c-573c-49df-a7f1-83f08a894d9f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 41738f3e-5431-4f4f-b81e-8a735c753e11
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 34413c48-3bd1-4d17-97b0-9a868cce928a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eecdc6a2-17e3-43ec-8077-97dcca5ffb22
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1799e42e-c9b5-43ed-8ba4-5411a0cf46e8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 33025884-951e-4d66-b812-8d7e13587234
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 05571cf9-f7ab-4a8d-9228-6e609277111a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 15e3c95a-3eb3-4c3d-a3b8-51d0dd65d55a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 68807347-1c58-4b05-99e9-bab40915eda5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a6b1d686-f208-470b-b174-51acba15e098
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e0c8206a-7552-408e-b3da-0a2f19080388
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fcc0637f-a253-46de-9fe1-1259dc62ff2f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cbf09ae9-64f7-43e6-b3f0-b21eacf44575
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 65261c55-60e8-4232-8b86-0900b69c4a1c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f276178c-5d03-4533-b79d-c35e814dc341
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 513a301a-fbe9-4734-8451-1a48d52c90ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 686842ce-9a82-42fc-b4c3-17dfd127572b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3d6070dc-2915-44fa-a406-cec6b53a3940
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b290e98a-5223-4bd7-9c44-0917c9330632
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4cfba39a-53de-4eb3-b9cd-5b48d6fce6a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d9feac0c-40fd-4582-b5c2-88c347e4bb06
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 90f85a88-5fb7-4060-b6d5-48891632ed97
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 63a0701d-5eee-4364-b04f-6da66b595fb9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c8896074-7d28-4b0f-8834-5d92379225e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 75ecd346-e45d-43e3-9836-aa0b3ffe8ec8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3216e266-2296-4ffe-9943-a1059a8c31a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 97b5176e-bc7e-48df-b982-23f5955f15a0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 056da6e1-6ffe-4c56-9c77-7df0198843f8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 684005ae-73ac-4513-b2ef-a67539797083
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 03d66abd-e299-451e-a00d-f5574b74f141
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d7cd61fb-8f8b-4951-ba32-941db0390729
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4d942674-bd25-4fab-aa7f-6c0cf2e878b0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 42b28f01-c04f-4b61-8548-22eacb2e5532
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 40dbdb37-f5cf-49bd-bdd5-817c04bafe94
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a1bf9fca-2664-4e8b-9185-95207338731e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c7db2d97-f3cd-4c0e-bbdd-5e01afff27e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aacc0eb7-7fc4-4f3f-b856-beffd74de74d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 83d19198-1c01-403e-b083-52fb518c9d1e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 18224f47-a1af-452d-8cff-8c3d157688d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4c7870e4-e0af-4b91-9aee-489b0df95d38
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9966293e-92b8-47d3-a013-76ccf5b2d4ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d36d625a-27d2-4e32-b465-a632361626bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9a232a54-bd59-4d25-91bf-a3a41314745d
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "recvmsg:Connection reset by peer"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8687 {grpc_message:"recvmsg:Connection reset by peer", grpc_status:14}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_55
Server: localhost:8687
Algorithm: FEDAVG
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_55
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_55/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_55/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_55/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_55/test_labels.txt

📊 Raw data loaded:
   Train: X=(1940, 24), y=(1940,)
   Test:  X=(486, 24), y=(486,)

⚠️  Limiting training data: 1940 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  477 samples, 5 features
✅ Client client_55 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

============================================================
🔄 Round 5 - Client client_55
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0833 (↓), lr=0.001000
   ✓ Epoch   2/100: train=0.0817, val=0.0824 (↓), lr=0.001000
   • Epoch   3/100: train=0.0811, val=0.0826, patience=1/15, lr=0.001000
   • Epoch   4/100: train=0.0808, val=0.0825, patience=2/15, lr=0.001000
   • Epoch   5/100: train=0.0805, val=0.0825, patience=3/15, lr=0.001000
   • Epoch  11/100: train=0.0770, val=0.0828, patience=9/15, lr=0.001000
   ✓ Epoch  21/100: train=0.0648, val=0.0792 (↓), lr=0.001000
   • Epoch  31/100: train=0.0512, val=0.0800, patience=3/15, lr=0.001000
   📉 Epoch 34: LR reduced 0.001000 → 0.000500
   • Epoch  41/100: train=0.0410, val=0.0820, patience=13/15, lr=0.000500
   📉 Epoch 42: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 5 Summary - Client client_55
   Epochs: 43/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0518, RMSE=0.2276, R²=0.3652
   Val:   Loss=0.0773, RMSE=0.2781, R²=0.0665
============================================================


============================================================
🔄 Round 7 - Client client_55
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0857 (↓), lr=0.000250
   • Epoch   2/100: train=0.0800, val=0.0857, patience=1/15, lr=0.000250
   • Epoch   3/100: train=0.0798, val=0.0858, patience=2/15, lr=0.000250
   • Epoch   4/100: train=0.0796, val=0.0858, patience=3/15, lr=0.000250
   • Epoch   5/100: train=0.0795, val=0.0859, patience=4/15, lr=0.000250
   📉 Epoch 7: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0789, val=0.0858, patience=10/15, lr=0.000125
   📉 Epoch 15: LR reduced 0.000125 → 0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 7 Summary - Client client_55
   Epochs: 16/100 (early stopped)
   LR: 0.000250 → 0.000063 (2 reductions)
   Train: Loss=0.0800, RMSE=0.2829, R²=0.0108
   Val:   Loss=0.0857, RMSE=0.2927, R²=-0.0060
============================================================


============================================================
🔄 Round 8 - Client client_55
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0843 (↓), lr=0.000063
   • Epoch   2/100: train=0.0810, val=0.0843, patience=1/15, lr=0.000063
   • Epoch   3/100: train=0.0808, val=0.0842, patience=2/15, lr=0.000063
   • Epoch   4/100: train=0.0808, val=0.0842, patience=3/15, lr=0.000063
   • Epoch   5/100: train=0.0807, val=0.0841, patience=4/15, lr=0.000063
   📉 Epoch 7: LR reduced 0.000063 → 0.000031
   • Epoch  11/100: train=0.0803, val=0.0840, patience=10/15, lr=0.000031
   📉 Epoch 15: LR reduced 0.000031 → 0.000016

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 8 Summary - Client client_55
   Epochs: 16/100 (early stopped)
   LR: 0.000063 → 0.000016 (2 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=0.0098
   Val:   Loss=0.0843, RMSE=0.2904, R²=-0.0161
============================================================


📊 Round 8 Test Metrics:
   Loss: 0.0856, RMSE: 0.2926, MAE: 0.2555, R²: -0.0010

============================================================
🔄 Round 14 - Client client_55
   Epochs: 100, Batch: 32, LR: 0.000016
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0771 (↓), lr=0.000016
   • Epoch   2/100: train=0.0828, val=0.0771, patience=1/15, lr=0.000016
   • Epoch   3/100: train=0.0827, val=0.0771, patience=2/15, lr=0.000016
   • Epoch   4/100: train=0.0826, val=0.0771, patience=3/15, lr=0.000016
   • Epoch   5/100: train=0.0826, val=0.0771, patience=4/15, lr=0.000016
   • Epoch  11/100: train=0.0822, val=0.0770, patience=10/15, lr=0.000016

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0771)

============================================================
📊 Round 14 Summary - Client client_55
   Epochs: 16/100 (early stopped)
   LR: 0.000016 → 0.000016 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2875, R²=0.0042
   Val:   Loss=0.0771, RMSE=0.2778, R²=-0.0031
============================================================


📊 Round 14 Test Metrics:
   Loss: 0.0853, RMSE: 0.2921, MAE: 0.2551, R²: 0.0024

============================================================
🔄 Round 18 - Client client_55
   Epochs: 100, Batch: 32, LR: 0.000016
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0768 (↓), lr=0.000016
   • Epoch   2/100: train=0.0823, val=0.0768, patience=1/15, lr=0.000016
   • Epoch   3/100: train=0.0822, val=0.0769, patience=2/15, lr=0.000016
   • Epoch   4/100: train=0.0821, val=0.0769, patience=3/15, lr=0.000016
   • Epoch   5/100: train=0.0820, val=0.0769, patience=4/15, lr=0.000016
   📉 Epoch 7: LR reduced 0.000016 → 0.000008
   • Epoch  11/100: train=0.0814, val=0.0768, patience=10/15, lr=0.000008
   📉 Epoch 15: LR reduced 0.000008 → 0.000004

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0768)

============================================================
📊 Round 18 Summary - Client client_55
   Epochs: 16/100 (early stopped)
   LR: 0.000016 → 0.000004 (2 reductions)
   Train: Loss=0.0823, RMSE=0.2868, R²=0.0045
   Val:   Loss=0.0768, RMSE=0.2771, R²=-0.0005
============================================================


📊 Round 18 Test Metrics:
   Loss: 0.0851, RMSE: 0.2917, MAE: 0.2548, R²: 0.0048

📊 Round 18 Test Metrics:
   Loss: 0.0851, RMSE: 0.2918, MAE: 0.2549, R²: 0.0044

============================================================
🔄 Round 20 - Client client_55
   Epochs: 100, Batch: 32, LR: 0.000004
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0860 (↓), lr=0.000004
   • Epoch   2/100: train=0.0801, val=0.0859, patience=1/15, lr=0.000004
   • Epoch   3/100: train=0.0801, val=0.0859, patience=2/15, lr=0.000004
   • Epoch   4/100: train=0.0800, val=0.0859, patience=3/15, lr=0.000004
   • Epoch   5/100: train=0.0800, val=0.0859, patience=4/15, lr=0.000004
   📉 Epoch 7: LR reduced 0.000004 → 0.000002
   • Epoch  11/100: train=0.0799, val=0.0858, patience=10/15, lr=0.000002
   📉 Epoch 15: LR reduced 0.000002 → 0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 20 Summary - Client client_55
   Epochs: 16/100 (early stopped)
   LR: 0.000004 → 0.000001 (2 reductions)
   Train: Loss=0.0800, RMSE=0.2829, R²=0.0082
   Val:   Loss=0.0860, RMSE=0.2932, R²=-0.0056
============================================================


📊 Round 20 Test Metrics:
   Loss: 0.0850, RMSE: 0.2915, MAE: 0.2546, R²: 0.0066

============================================================
🔄 Round 21 - Client client_55
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0895 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0895, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0895, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0895, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0895, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0895, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0895)

============================================================
📊 Round 21 Summary - Client client_55
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2811, R²=0.0075
   Val:   Loss=0.0895, RMSE=0.2992, R²=0.0047
============================================================


============================================================
🔄 Round 22 - Client client_55
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 22 Summary - Client client_55
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=0.0112
   Val:   Loss=0.0847, RMSE=0.2911, R²=0.0022
============================================================


📊 Round 22 Test Metrics:
   Loss: 0.0849, RMSE: 0.2914, MAE: 0.2545, R²: 0.0074

============================================================
🔄 Round 23 - Client client_55
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 23 Summary - Client client_55
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=0.0124
   Val:   Loss=0.0805, RMSE=0.2838, R²=-0.0087
============================================================


📊 Round 23 Test Metrics:
   Loss: 0.0849, RMSE: 0.2913, MAE: 0.2544, R²: 0.0075

📊 Round 23 Test Metrics:
   Loss: 0.0849, RMSE: 0.2913, MAE: 0.2544, R²: 0.0075

📊 Round 23 Test Metrics:
   Loss: 0.0849, RMSE: 0.2913, MAE: 0.2544, R²: 0.0075

📊 Round 23 Test Metrics:
   Loss: 0.0849, RMSE: 0.2913, MAE: 0.2544, R²: 0.0075

============================================================
🔄 Round 31 - Client client_55
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0867 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0867, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0867, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0866, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0866, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 31 Summary - Client client_55
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2821, R²=0.0126
   Val:   Loss=0.0867, RMSE=0.2944, R²=0.0008
============================================================


============================================================
🔄 Round 32 - Client client_55
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 32 Summary - Client client_55
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=0.0070
   Val:   Loss=0.0858, RMSE=0.2929, R²=0.0113
============================================================


============================================================
🔄 Round 34 - Client client_55
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 34 Summary - Client client_55
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2845, R²=0.0124
   Val:   Loss=0.0812, RMSE=0.2850, R²=0.0010
============================================================


📊 Round 34 Test Metrics:
   Loss: 0.0849, RMSE: 0.2913, MAE: 0.2544, R²: 0.0077

============================================================
🔄 Round 36 - Client client_55
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 36 Summary - Client client_55
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2840, R²=0.0126
   Val:   Loss=0.0825, RMSE=0.2871, R²=-0.0063
============================================================


============================================================
🔄 Round 37 - Client client_55
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 37 Summary - Client client_55
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=0.0113
   Val:   Loss=0.0835, RMSE=0.2890, R²=0.0046
============================================================


📊 Round 37 Test Metrics:
   Loss: 0.0849, RMSE: 0.2913, MAE: 0.2544, R²: 0.0077

============================================================
🔄 Round 39 - Client client_55
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 39 Summary - Client client_55
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2847, R²=0.0015
   Val:   Loss=0.0809, RMSE=0.2844, R²=0.0411
============================================================


📊 Round 39 Test Metrics:
   Loss: 0.0849, RMSE: 0.2913, MAE: 0.2544, R²: 0.0077

============================================================
🔄 Round 41 - Client client_55
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0777 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0777, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0777, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0777, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0777, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 41 Summary - Client client_55
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=0.0024
   Val:   Loss=0.0777, RMSE=0.2788, R²=0.0404
============================================================


============================================================
🔄 Round 42 - Client client_55
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0768 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0768, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0768, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0767, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0767, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0767, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0768)

============================================================
📊 Round 42 Summary - Client client_55
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=0.0129
   Val:   Loss=0.0768, RMSE=0.2771, R²=-0.0025
============================================================


📊 Round 42 Test Metrics:
   Loss: 0.0848, RMSE: 0.2913, MAE: 0.2544, R²: 0.0079

📊 Round 42 Test Metrics:
   Loss: 0.0848, RMSE: 0.2913, MAE: 0.2544, R²: 0.0079

📊 Round 42 Test Metrics:
   Loss: 0.0848, RMSE: 0.2913, MAE: 0.2544, R²: 0.0079

============================================================
🔄 Round 47 - Client client_55
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0778, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0778, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0778, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0778, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0778, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 47 Summary - Client client_55
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=0.0084
   Val:   Loss=0.0778, RMSE=0.2789, R²=0.0081
============================================================


============================================================
🔄 Round 50 - Client client_55
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 50 Summary - Client client_55
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=0.0148
   Val:   Loss=0.0788, RMSE=0.2808, R²=-0.0127
============================================================


📊 Round 50 Test Metrics:
   Loss: 0.0848, RMSE: 0.2913, MAE: 0.2544, R²: 0.0080

📊 Round 50 Test Metrics:
   Loss: 0.0848, RMSE: 0.2913, MAE: 0.2544, R²: 0.0080

📊 Round 50 Test Metrics:
   Loss: 0.0848, RMSE: 0.2913, MAE: 0.2544, R²: 0.0080

📊 Round 50 Test Metrics:
   Loss: 0.0848, RMSE: 0.2913, MAE: 0.2544, R²: 0.0080

============================================================
🔄 Round 58 - Client client_55
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0782, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 58 Summary - Client client_55
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=0.0081
   Val:   Loss=0.0782, RMSE=0.2797, R²=0.0198
============================================================


📊 Round 58 Test Metrics:
   Loss: 0.0848, RMSE: 0.2913, MAE: 0.2544, R²: 0.0080

============================================================
🔄 Round 62 - Client client_55
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0772, val=0.0961 (↓), lr=0.000001
   • Epoch   2/100: train=0.0772, val=0.0961, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0772, val=0.0961, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0772, val=0.0960, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0772, val=0.0960, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0771, val=0.0960, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0961)

============================================================
📊 Round 62 Summary - Client client_55
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0772, RMSE=0.2779, R²=0.0161
   Val:   Loss=0.0961, RMSE=0.3100, R²=-0.0083
============================================================


📊 Round 62 Test Metrics:
   Loss: 0.0848, RMSE: 0.2912, MAE: 0.2543, R²: 0.0082

============================================================
🔄 Round 63 - Client client_55
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0777 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0777, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0777, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0777, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0777, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0777, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 63 Summary - Client client_55
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=0.0152
   Val:   Loss=0.0777, RMSE=0.2788, R²=-0.0093
============================================================


📊 Round 63 Test Metrics:
   Loss: 0.0848, RMSE: 0.2912, MAE: 0.2543, R²: 0.0082

============================================================
🔄 Round 64 - Client client_55
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 64 Summary - Client client_55
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=0.0096
   Val:   Loss=0.0845, RMSE=0.2907, R²=-0.0012
============================================================


📊 Round 64 Test Metrics:
   Loss: 0.0848, RMSE: 0.2912, MAE: 0.2543, R²: 0.0082

============================================================
🔄 Round 66 - Client client_55
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 66 Summary - Client client_55
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=0.0115
   Val:   Loss=0.0836, RMSE=0.2891, R²=0.0051
============================================================


📊 Round 66 Test Metrics:
   Loss: 0.0848, RMSE: 0.2912, MAE: 0.2543, R²: 0.0083

============================================================
🔄 Round 68 - Client client_55
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 68 Summary - Client client_55
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2843, R²=0.0051
   Val:   Loss=0.0814, RMSE=0.2853, R²=0.0134
============================================================


============================================================
🔄 Round 69 - Client client_55
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 69 Summary - Client client_55
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=0.0076
   Val:   Loss=0.0782, RMSE=0.2796, R²=0.0210
============================================================


📊 Round 69 Test Metrics:
   Loss: 0.0848, RMSE: 0.2912, MAE: 0.2543, R²: 0.0086

============================================================
🔄 Round 80 - Client client_55
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0752 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0752, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0752, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0752, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0752, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0751, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0752)

============================================================
📊 Round 80 Summary - Client client_55
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=0.0153
   Val:   Loss=0.0752, RMSE=0.2742, R²=-0.0142
============================================================


============================================================
🔄 Round 82 - Client client_55
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 82 Summary - Client client_55
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=0.0090
   Val:   Loss=0.0787, RMSE=0.2805, R²=0.0172
============================================================


📊 Round 82 Test Metrics:
   Loss: 0.0848, RMSE: 0.2912, MAE: 0.2543, R²: 0.0087

============================================================
🔄 Round 84 - Client client_55
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0908 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0908, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0908, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0908, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0785, val=0.0908, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0785, val=0.0908, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0908)

============================================================
📊 Round 84 Summary - Client client_55
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2802, R²=0.0118
   Val:   Loss=0.0908, RMSE=0.3013, R²=0.0015
============================================================


📊 Round 84 Test Metrics:
   Loss: 0.0848, RMSE: 0.2912, MAE: 0.2542, R²: 0.0088

============================================================
🔄 Round 90 - Client client_55
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 90 Summary - Client client_55
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=0.0123
   Val:   Loss=0.0849, RMSE=0.2913, R²=0.0034
============================================================


============================================================
🔄 Round 91 - Client client_55
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 91 Summary - Client client_55
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2831, R²=0.0135
   Val:   Loss=0.0841, RMSE=0.2901, R²=0.0010
============================================================


============================================================
🔄 Round 92 - Client client_55
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 92 Summary - Client client_55
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=0.0174
   Val:   Loss=0.0848, RMSE=0.2912, R²=-0.0148
============================================================


📊 Round 92 Test Metrics:
   Loss: 0.0848, RMSE: 0.2911, MAE: 0.2542, R²: 0.0089

📊 Round 92 Test Metrics:
   Loss: 0.0848, RMSE: 0.2911, MAE: 0.2542, R²: 0.0089

============================================================
🔄 Round 97 - Client client_55
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0653 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0653, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0653, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0653, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0653, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0653, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0653)

============================================================
📊 Round 97 Summary - Client client_55
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2913, R²=-0.0022
   Val:   Loss=0.0653, RMSE=0.2555, R²=0.0580
============================================================


============================================================
🔄 Round 98 - Client client_55
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 98 Summary - Client client_55
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2833, R²=0.0021
   Val:   Loss=0.0836, RMSE=0.2891, R²=0.0421
============================================================


============================================================
🔄 Round 99 - Client client_55
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 99 Summary - Client client_55
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2854, R²=0.0128
   Val:   Loss=0.0789, RMSE=0.2809, R²=-0.0065
============================================================


📊 Round 99 Test Metrics:
   Loss: 0.0847, RMSE: 0.2911, MAE: 0.2542, R²: 0.0091

============================================================
🔄 Round 103 - Client client_55
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0678 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0678, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0678, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0678, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0678, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0677, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0678)

============================================================
📊 Round 103 Summary - Client client_55
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=0.0127
   Val:   Loss=0.0678, RMSE=0.2604, R²=0.0012
============================================================


📊 Round 103 Test Metrics:
   Loss: 0.0847, RMSE: 0.2911, MAE: 0.2542, R²: 0.0092

📊 Round 103 Test Metrics:
   Loss: 0.0847, RMSE: 0.2911, MAE: 0.2542, R²: 0.0092

📊 Round 103 Test Metrics:
   Loss: 0.0847, RMSE: 0.2911, MAE: 0.2542, R²: 0.0092

📊 Round 103 Test Metrics:
   Loss: 0.0847, RMSE: 0.2911, MAE: 0.2542, R²: 0.0093

============================================================
🔄 Round 108 - Client client_55
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 108 Summary - Client client_55
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=0.0050
   Val:   Loss=0.0797, RMSE=0.2824, R²=0.0047
============================================================


📊 Round 108 Test Metrics:
   Loss: 0.0847, RMSE: 0.2911, MAE: 0.2542, R²: 0.0093

============================================================
🔄 Round 109 - Client client_55
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0886 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0886, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0886, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0886, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0886, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0885, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0886)

============================================================
📊 Round 109 Summary - Client client_55
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2811, R²=0.0174
   Val:   Loss=0.0886, RMSE=0.2976, R²=-0.0132
============================================================


📊 Round 109 Test Metrics:
   Loss: 0.0847, RMSE: 0.2911, MAE: 0.2542, R²: 0.0093

============================================================
🔄 Round 110 - Client client_55
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0885 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0884, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0884, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0884, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0884, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0884, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0885)

============================================================
📊 Round 110 Summary - Client client_55
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2811, R²=0.0070
   Val:   Loss=0.0885, RMSE=0.2974, R²=0.0157
============================================================


📊 Round 110 Test Metrics:
   Loss: 0.0847, RMSE: 0.2911, MAE: 0.2542, R²: 0.0093

============================================================
🔄 Round 112 - Client client_55
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 112 Summary - Client client_55
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=0.0194
   Val:   Loss=0.0814, RMSE=0.2854, R²=-0.0349
============================================================


📊 Round 112 Test Metrics:
   Loss: 0.0847, RMSE: 0.2911, MAE: 0.2542, R²: 0.0093

📊 Round 112 Test Metrics:
   Loss: 0.0847, RMSE: 0.2911, MAE: 0.2542, R²: 0.0093

============================================================
🔄 Round 116 - Client client_55
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 116 Summary - Client client_55
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=0.0059
   Val:   Loss=0.0813, RMSE=0.2851, R²=0.0206
============================================================


📊 Round 116 Test Metrics:
   Loss: 0.0847, RMSE: 0.2911, MAE: 0.2541, R²: 0.0094

📊 Round 116 Test Metrics:
   Loss: 0.0847, RMSE: 0.2910, MAE: 0.2541, R²: 0.0095

============================================================
🔄 Round 118 - Client client_55
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 118 Summary - Client client_55
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2852, R²=0.0107
   Val:   Loss=0.0791, RMSE=0.2812, R²=0.0136
============================================================


📊 Round 118 Test Metrics:
   Loss: 0.0847, RMSE: 0.2910, MAE: 0.2541, R²: 0.0095

📊 Round 118 Test Metrics:
   Loss: 0.0847, RMSE: 0.2910, MAE: 0.2541, R²: 0.0095

============================================================
🔄 Round 120 - Client client_55
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0872 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0871, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0871, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0871, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0871, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0871, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0872)

============================================================
📊 Round 120 Summary - Client client_55
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2817, R²=0.0116
   Val:   Loss=0.0872, RMSE=0.2952, R²=0.0080
============================================================


📊 Round 120 Test Metrics:
   Loss: 0.0847, RMSE: 0.2910, MAE: 0.2541, R²: 0.0096

============================================================
🔄 Round 124 - Client client_55
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0704 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0703, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0703, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0703, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0703, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0703, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0704)

============================================================
📊 Round 124 Summary - Client client_55
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=0.0096
   Val:   Loss=0.0704, RMSE=0.2652, R²=0.0186
============================================================


📊 Round 124 Test Metrics:
   Loss: 0.0847, RMSE: 0.2910, MAE: 0.2541, R²: 0.0096

📊 Round 124 Test Metrics:
   Loss: 0.0847, RMSE: 0.2910, MAE: 0.2541, R²: 0.0096

============================================================
🔄 Round 127 - Client client_55
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0772 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0772, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0772, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0771, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0771, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0771, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 127 Summary - Client client_55
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2861, R²=0.0080
   Val:   Loss=0.0772, RMSE=0.2778, R²=0.0212
============================================================


============================================================
🔄 Round 130 - Client client_55
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0776, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0777, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 130 Summary - Client client_55
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=0.0129
   Val:   Loss=0.0775, RMSE=0.2784, R²=-0.0625
============================================================


============================================================
🔄 Round 131 - Client client_55
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0676 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0676, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0676, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0676, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0676, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0675, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0676)

============================================================
📊 Round 131 Summary - Client client_55
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=0.0141
   Val:   Loss=0.0676, RMSE=0.2600, R²=-0.0038
============================================================


📊 Round 131 Test Metrics:
   Loss: 0.0847, RMSE: 0.2910, MAE: 0.2541, R²: 0.0096

============================================================
🔄 Round 132 - Client client_55
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 132 Summary - Client client_55
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=0.0122
   Val:   Loss=0.0796, RMSE=0.2821, R²=0.0068
============================================================


📊 Round 132 Test Metrics:
   Loss: 0.0847, RMSE: 0.2910, MAE: 0.2541, R²: 0.0097

📊 Round 132 Test Metrics:
   Loss: 0.0847, RMSE: 0.2910, MAE: 0.2541, R²: 0.0097

============================================================
🔄 Round 136 - Client client_55
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0763 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0763, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0763, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0763, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0763, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0762, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0763)

============================================================
📊 Round 136 Summary - Client client_55
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=0.0054
   Val:   Loss=0.0763, RMSE=0.2762, R²=0.0377
============================================================


📊 Round 136 Test Metrics:
   Loss: 0.0847, RMSE: 0.2910, MAE: 0.2541, R²: 0.0097

============================================================
🔄 Round 139 - Client client_55
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 139 Summary - Client client_55
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=0.0216
   Val:   Loss=0.0804, RMSE=0.2835, R²=-0.0323
============================================================


============================================================
🔄 Round 140 - Client client_55
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 140 Summary - Client client_55
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2845, R²=0.0156
   Val:   Loss=0.0807, RMSE=0.2840, R²=-0.0052
============================================================


📊 Round 140 Test Metrics:
   Loss: 0.0847, RMSE: 0.2910, MAE: 0.2541, R²: 0.0098

============================================================
🔄 Round 146 - Client client_55
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0771 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0771, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0771, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0771, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0771, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0770, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0771)

============================================================
📊 Round 146 Summary - Client client_55
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=0.0132
   Val:   Loss=0.0771, RMSE=0.2776, R²=-0.0046
============================================================


============================================================
🔄 Round 148 - Client client_55
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 148 Summary - Client client_55
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=0.0082
   Val:   Loss=0.0827, RMSE=0.2876, R²=0.0250
============================================================


============================================================
🔄 Round 149 - Client client_55
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0687 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0687, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0687, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0687, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0687, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0686, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0687)

============================================================
📊 Round 149 Summary - Client client_55
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=0.0065
   Val:   Loss=0.0687, RMSE=0.2621, R²=0.0312
============================================================


📊 Round 149 Test Metrics:
   Loss: 0.0847, RMSE: 0.2910, MAE: 0.2540, R²: 0.0100

📊 Round 149 Test Metrics:
   Loss: 0.0847, RMSE: 0.2910, MAE: 0.2540, R²: 0.0100

============================================================
🔄 Round 155 - Client client_55
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 155 Summary - Client client_55
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2821, R²=0.0143
   Val:   Loss=0.0860, RMSE=0.2933, R²=0.0029
============================================================


============================================================
🔄 Round 157 - Client client_55
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 157 Summary - Client client_55
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=0.0079
   Val:   Loss=0.0813, RMSE=0.2851, R²=0.0245
============================================================


============================================================
🔄 Round 158 - Client client_55
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 158 Summary - Client client_55
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=0.0139
   Val:   Loss=0.0828, RMSE=0.2877, R²=0.0040
============================================================


============================================================
🔄 Round 160 - Client client_55
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0706 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0706, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0705, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0705, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0705, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0705, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0706)

============================================================
📊 Round 160 Summary - Client client_55
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=0.0093
   Val:   Loss=0.0706, RMSE=0.2656, R²=0.0228
============================================================


📊 Round 160 Test Metrics:
   Loss: 0.0847, RMSE: 0.2910, MAE: 0.2540, R²: 0.0101

📊 Round 160 Test Metrics:
   Loss: 0.0847, RMSE: 0.2910, MAE: 0.2540, R²: 0.0101

============================================================
🔄 Round 163 - Client client_55
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 163 Summary - Client client_55
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=0.0107
   Val:   Loss=0.0840, RMSE=0.2898, R²=0.0160
============================================================


============================================================
🔄 Round 164 - Client client_55
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 164 Summary - Client client_55
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2831, R²=0.0042
   Val:   Loss=0.0837, RMSE=0.2892, R²=0.0379
============================================================


📊 Round 164 Test Metrics:
   Loss: 0.0847, RMSE: 0.2910, MAE: 0.2540, R²: 0.0101

============================================================
🔄 Round 165 - Client client_55
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 165 Summary - Client client_55
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=0.0109
   Val:   Loss=0.0781, RMSE=0.2795, R²=0.0167
============================================================


📊 Round 165 Test Metrics:
   Loss: 0.0847, RMSE: 0.2909, MAE: 0.2540, R²: 0.0102

📊 Round 165 Test Metrics:
   Loss: 0.0847, RMSE: 0.2909, MAE: 0.2540, R²: 0.0102

============================================================
🔄 Round 168 - Client client_55
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 168 Summary - Client client_55
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=0.0117
   Val:   Loss=0.0827, RMSE=0.2875, R²=0.0109
============================================================


📊 Round 168 Test Metrics:
   Loss: 0.0846, RMSE: 0.2909, MAE: 0.2540, R²: 0.0102

📊 Round 168 Test Metrics:
   Loss: 0.0846, RMSE: 0.2909, MAE: 0.2540, R²: 0.0102

============================================================
🔄 Round 173 - Client client_55
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0763 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0763, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0763, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0763, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0763, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0762, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0763)

============================================================
📊 Round 173 Summary - Client client_55
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=0.0048
   Val:   Loss=0.0763, RMSE=0.2762, R²=0.0427
============================================================


📊 Round 173 Test Metrics:
   Loss: 0.0846, RMSE: 0.2909, MAE: 0.2540, R²: 0.0103

📊 Round 173 Test Metrics:
   Loss: 0.0846, RMSE: 0.2909, MAE: 0.2540, R²: 0.0103

============================================================
🔄 Round 175 - Client client_55
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 175 Summary - Client client_55
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=0.0126
   Val:   Loss=0.0794, RMSE=0.2818, R²=0.0080
============================================================


📊 Round 175 Test Metrics:
   Loss: 0.0846, RMSE: 0.2909, MAE: 0.2540, R²: 0.0104

📊 Round 175 Test Metrics:
   Loss: 0.0846, RMSE: 0.2909, MAE: 0.2540, R²: 0.0104

============================================================
🔄 Round 179 - Client client_55
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0725 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0725, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0725, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0725, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0725, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0724, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0725)

============================================================
📊 Round 179 Summary - Client client_55
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=0.0126
   Val:   Loss=0.0725, RMSE=0.2692, R²=0.0110
============================================================


============================================================
🔄 Round 180 - Client client_55
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 180 Summary - Client client_55
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=0.0075
   Val:   Loss=0.0802, RMSE=0.2833, R²=0.0161
============================================================


============================================================
🔄 Round 183 - Client client_55
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0705 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0705, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0705, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0705, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0705, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0705, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0705)

============================================================
📊 Round 183 Summary - Client client_55
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=0.0128
   Val:   Loss=0.0705, RMSE=0.2655, R²=0.0061
============================================================


============================================================
🔄 Round 184 - Client client_55
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 184 Summary - Client client_55
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2831, R²=0.0089
   Val:   Loss=0.0834, RMSE=0.2888, R²=0.0146
============================================================


📊 Round 184 Test Metrics:
   Loss: 0.0846, RMSE: 0.2909, MAE: 0.2540, R²: 0.0104

============================================================
🔄 Round 185 - Client client_55
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 185 Summary - Client client_55
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2847, R²=0.0021
   Val:   Loss=0.0798, RMSE=0.2826, R²=0.0489
============================================================


📊 Round 185 Test Metrics:
   Loss: 0.0846, RMSE: 0.2909, MAE: 0.2540, R²: 0.0105

📊 Round 185 Test Metrics:
   Loss: 0.0846, RMSE: 0.2909, MAE: 0.2540, R²: 0.0104

============================================================
🔄 Round 190 - Client client_55
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 190 Summary - Client client_55
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=0.0159
   Val:   Loss=0.0809, RMSE=0.2843, R²=-0.0016
============================================================


============================================================
🔄 Round 191 - Client client_55
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0755 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0755, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0755, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0755, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0755, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0755, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0755)

============================================================
📊 Round 191 Summary - Client client_55
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2866, R²=0.0088
   Val:   Loss=0.0755, RMSE=0.2747, R²=-0.0050
============================================================


📊 Round 191 Test Metrics:
   Loss: 0.0846, RMSE: 0.2909, MAE: 0.2540, R²: 0.0105

📊 Round 191 Test Metrics:
   Loss: 0.0846, RMSE: 0.2909, MAE: 0.2540, R²: 0.0105

📊 Round 191 Test Metrics:
   Loss: 0.0846, RMSE: 0.2909, MAE: 0.2540, R²: 0.0105

============================================================
🔄 Round 196 - Client client_55
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0765 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0765, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0765, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0765, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0765, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0765, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0765)

============================================================
📊 Round 196 Summary - Client client_55
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2861, R²=0.0095
   Val:   Loss=0.0765, RMSE=0.2767, R²=0.0255
============================================================


============================================================
🔄 Round 198 - Client client_55
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0904 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0904, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0904, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0904, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0904, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0785, val=0.0903, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0904)

============================================================
📊 Round 198 Summary - Client client_55
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2800, R²=0.0141
   Val:   Loss=0.0904, RMSE=0.3006, R²=0.0046
============================================================


============================================================
🔄 Round 199 - Client client_55
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0708 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0708, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0707, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0707, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0707, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0707, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0708)

============================================================
📊 Round 199 Summary - Client client_55
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=0.0197
   Val:   Loss=0.0708, RMSE=0.2660, R²=-0.0227
============================================================


📊 Round 199 Test Metrics:
   Loss: 0.0846, RMSE: 0.2909, MAE: 0.2539, R²: 0.0106

📊 Round 199 Test Metrics:
   Loss: 0.0846, RMSE: 0.2909, MAE: 0.2539, R²: 0.0106

📊 Round 199 Test Metrics:
   Loss: 0.0846, RMSE: 0.2909, MAE: 0.2539, R²: 0.0106

============================================================
🔄 Round 204 - Client client_55
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 204 Summary - Client client_55
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2847, R²=0.0061
   Val:   Loss=0.0797, RMSE=0.2824, R²=0.0371
============================================================


📊 Round 204 Test Metrics:
   Loss: 0.0846, RMSE: 0.2909, MAE: 0.2540, R²: 0.0106

📊 Round 204 Test Metrics:
   Loss: 0.0846, RMSE: 0.2909, MAE: 0.2539, R²: 0.0106

============================================================
🔄 Round 206 - Client client_55
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 206 Summary - Client client_55
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=0.0178
   Val:   Loss=0.0843, RMSE=0.2904, R²=-0.0255
============================================================


📊 Round 206 Test Metrics:
   Loss: 0.0846, RMSE: 0.2909, MAE: 0.2539, R²: 0.0107

📊 Round 206 Test Metrics:
   Loss: 0.0846, RMSE: 0.2909, MAE: 0.2539, R²: 0.0107

============================================================
🔄 Round 209 - Client client_55
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0752 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0752, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0752, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0752, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0752, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0752, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0752)

============================================================
📊 Round 209 Summary - Client client_55
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=0.0171
   Val:   Loss=0.0752, RMSE=0.2742, R²=-0.0283
============================================================


📊 Round 209 Test Metrics:
   Loss: 0.0846, RMSE: 0.2909, MAE: 0.2539, R²: 0.0108

============================================================
🔄 Round 212 - Client client_55
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 212 Summary - Client client_55
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=0.0152
   Val:   Loss=0.0831, RMSE=0.2882, R²=-0.0031
============================================================


📊 Round 212 Test Metrics:
   Loss: 0.0846, RMSE: 0.2908, MAE: 0.2539, R²: 0.0108

📊 Round 212 Test Metrics:
   Loss: 0.0846, RMSE: 0.2908, MAE: 0.2539, R²: 0.0109

📊 Round 212 Test Metrics:
   Loss: 0.0846, RMSE: 0.2908, MAE: 0.2539, R²: 0.0109

============================================================
🔄 Round 216 - Client client_55
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 216 Summary - Client client_55
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=0.0170
   Val:   Loss=0.0806, RMSE=0.2840, R²=-0.0044
============================================================


📊 Round 216 Test Metrics:
   Loss: 0.0846, RMSE: 0.2908, MAE: 0.2539, R²: 0.0108

============================================================
🔄 Round 218 - Client client_55
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0746 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0746, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0746, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0746, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0746, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0745, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0746)

============================================================
📊 Round 218 Summary - Client client_55
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=0.0144
   Val:   Loss=0.0746, RMSE=0.2732, R²=0.0063
============================================================


📊 Round 218 Test Metrics:
   Loss: 0.0846, RMSE: 0.2908, MAE: 0.2539, R²: 0.0110

============================================================
🔄 Round 223 - Client client_55
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0759 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0759, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0759, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0759, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0759, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0759, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0759)

============================================================
📊 Round 223 Summary - Client client_55
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=0.0143
   Val:   Loss=0.0759, RMSE=0.2755, R²=0.0010
============================================================


============================================================
🔄 Round 225 - Client client_55
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 225 Summary - Client client_55
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=0.0069
   Val:   Loss=0.0840, RMSE=0.2898, R²=0.0350
============================================================


❌ Client client_55 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "recvmsg:Connection reset by peer"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8687 {grpc_message:"recvmsg:Connection reset by peer", grpc_status:14}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "recvmsg:Connection reset by peer"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8687 {grpc_message:"recvmsg:Connection reset by peer", grpc_status:14}"
>
