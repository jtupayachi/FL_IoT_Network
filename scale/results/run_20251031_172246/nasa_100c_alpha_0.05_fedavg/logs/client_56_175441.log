[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eaae28cb-02fe-42de-a952-eb9ebaeb033f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d0a2a56b-1117-48a2-989f-c33204a48344
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0a69e797-a3db-4819-b55b-1fe62ebb4941
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ce061c81-5537-442c-9183-bde096606ab4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message da96e527-ae2f-43c4-9c73-031255481e28
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aa5b6b0d-ceab-44ab-bb84-71c7c5a3f5ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2273f67e-becb-4afd-8195-369732e396f2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c58400a4-b99e-454b-9eb2-80843f3a418b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6f061611-28f0-49c2-bee1-f79bda23f116
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0deefa18-6886-4714-85f8-0d3c70c0acb5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f03b5c5c-dfc1-4bbf-b9f3-3050b6fba484
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 874e173b-ba6a-44fb-a2b6-698605aa0fdf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3e146336-eda3-4554-92ca-bba4b655c539
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 04d75087-cdd6-4c96-8462-f5b309b9b159
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0e0e2b79-6804-4672-93cd-f6856d601894
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b22db17f-adc1-4532-a4c0-33c4acbe7c93
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8049beee-6ff9-4b85-8b0b-b3491a9d36bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1749e877-db5a-4d48-963c-804f9454c73e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f8a911d4-32db-476f-811a-48a2dd69efb8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0b6a0928-caf1-4a52-a3aa-dc291aff21c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a9e0fd36-efeb-4743-b3b2-8f9e8a75d2d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bd8a7a2f-3406-48d3-ae35-eb6e5002367a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0041bcad-086b-402b-9c96-2cd3e48f2c0f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3c3e026d-5a62-4a8b-b83e-a26deb5401a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f3e8173a-d444-421a-93c5-6b5a5828e1ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d8084596-417a-4244-b502-657f95d28d57
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c4933aae-44ec-4f08-942d-0c8a1aa86659
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9a3195b9-5cbe-41c1-9018-5cbe76f6f831
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cb55f1c9-7533-40b3-a544-139847672524
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9ed3e663-ab96-46a4-8f2b-8a89d1aa5dfa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b8169dd3-891f-466d-ad63-e35f80548c33
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 98143091-6ea2-4049-8415-db000d1ca559
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 213c8bfb-e793-4014-9aca-c99b5dd9fe56
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0cece199-660d-491b-ae5d-2667e9bc4f9c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f70ea93e-bd9e-4cd6-920a-9fd8042a3b0e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 904dd27c-1938-45e6-b4be-179e3a62b4d8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b1234c48-3f5e-4cf9-a455-5686b08f8798
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e2a7c137-86d6-4cbc-aac1-4ed9e3fc3560
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1956f9c8-c299-4824-bfbd-d675a7abb3c7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 262f2baf-2e43-4a14-bd21-b6fd8008c75e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dfe4e20b-6eec-4ee5-86a9-7d8b7fb19d65
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f74dc5ac-d38f-4071-a359-9ac6faada744
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fe5f3233-e139-4e83-a1b3-e17a40682696
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4f8f6790-ecb5-41d5-960f-9a2db80422b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4fcefc7d-dee1-44bf-bce4-6c778a1ea0f9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 68db7cf4-3f77-4b7d-a90d-41ab8a05cc77
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e317a625-d9c2-4569-b1d7-84c7d9cf4203
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8405283a-6f5e-4267-a845-d45de4f3c313
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 38ad7922-52e6-417d-9d7a-8d14df817223
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bce6a14c-04c4-46eb-a005-f21efbadd84c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a2c923bf-9fde-4e53-93b9-bfaef2b8594f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7feb07f4-914a-4e77-bf27-831acfcf86e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f546483c-339e-4cf2-8050-72f29e0c2169
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 90527817-9a1d-408c-8dad-397ef1442f10
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2aea163a-dfca-40a3-8a3e-7d0b2a4cad0c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0f4a03eb-7c48-456b-ac91-42abd8adfca5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 76f8ce8d-31ac-4d5a-bf1a-e8a88d72c742
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 94a67159-dc5c-4565-9dc6-c4572a2ec93d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ec5cf89e-71d3-4b30-8083-4eff11943774
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5164c50f-ba6c-491d-a7be-ea53b615e40d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a3f31db4-5c13-40be-b35c-699362613450
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 35bdf839-9ad5-408d-9593-84cbeabd54ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 327e5b0c-a89d-4fb1-a3a5-3a249c9acfc3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fb428b10-cc76-4acd-82b8-f441c489aaba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 40436bb8-2b64-4159-aea7-94c4bcf0cad9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0867e290-7133-4a1d-933a-b5b45a65d2a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message df504358-51e2-4cd1-8d5e-13680b526cb3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 982c5e9f-b858-40e5-895e-7f8fa539601e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 912d2ffb-629c-4723-a5e4-f2a5dd867bee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9a0d85d0-9946-4c74-b4ca-8a37d4b275bc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3f26a85a-8d8e-4d8b-a9ca-61d648504346
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e323ed18-bff9-46fb-99fd-10d28921d1fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d4fcb5d9-2d66-41f6-9339-9089a5243d3b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 558bef56-039c-47af-9c50-8fe1bc8e6c1e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f78a3cbc-697a-4bb4-86ab-07c428564fe3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 569d16e2-9ffe-43a6-a9f5-bc3089330317
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c493a664-5589-48aa-b560-f03cc28e0b3c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2d6f25d4-fcd1-4141-a3a3-11a133e60611
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 829513bf-0802-46fe-a9be-4fb7151bcf3a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3b2af15b-b5b7-4117-9d63-ffdeb81abda3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f16bc33d-2d1f-480e-8c14-565a85003d77
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f0ca6b9c-0749-4063-9069-bba6a542b95c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ff05084b-2aa2-4900-93c9-9ff0b78cdfcf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f76b7209-95fb-4b8c-9793-72d71870de01
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e7702aca-00c4-436c-9bef-aad2a24ef765
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7b9a2035-ff8f-40d8-a3c3-adaa22cc4757
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d61e2401-747b-4586-a3e5-97e1ee00ba69
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 025dd380-a6d0-4280-b95a-73968ce44477
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 35172866-5b17-4b0a-8e73-dc6ee21f1944
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 514563c8-03fd-4c1d-b08f-a5d0e49a68bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f9377694-abe3-448b-b9ff-98a27a665c6c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message abd57317-4830-4adc-a567-ebe3651170a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cb236079-613f-47e1-8f02-de8c439972b5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0505e4b3-88d1-4f04-bd64-8fa14d4eb9c4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 580bae6c-8642-41d0-a111-d0e270c625a3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e000973d-d751-40fb-b1c6-ac54fb3d8657
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a92dfee2-cf86-46ae-b2e8-6f5db9901200
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e14cba66-f534-4e03-a632-7f2ddbf48085
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 66c31278-880f-467d-879b-e43e87b23771
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 79a070fa-cd40-4b38-b6cc-b28e3541603e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4d7d4ed5-be71-4c09-a8e2-86343a1e6e05
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 89535470-4e42-4d65-95db-d8f0e036ef99
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d78bc5e8-4b5f-4dc8-9d24-bd81e754c33b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c9340871-da7d-4750-827d-ec525099278b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c1dc4561-c8c9-4ae5-a095-f060406edd20
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2b5a0afb-bf96-436d-9495-14f25e2d37fb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fc54937b-70dc-4b60-94f0-bf6ed783ac39
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fff09126-79f0-499e-b6fa-f453ef45dd8a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 980329d7-bd9c-49b8-928c-576d1e3086c6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ac6abdd3-03f1-43df-a200-9d23e7736b2f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d01460e8-43a3-4a1b-abe1-1a49ede59f87
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8f130d0c-2446-4924-b2e6-08761143114f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 844dbd16-ed13-4d37-9de9-80a9089a4b48
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 63e5d9e7-f34c-43e0-b37a-ed8f6e4bff70
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6139ab9e-027d-4016-b0b7-92a4fe42af67
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ad417575-2f73-444e-a462-e53e7b0bee14
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 69a19952-3cbe-466f-b6fb-3053e7c23086
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eab3dd82-1ae1-4b02-bbba-169d8e35ed32
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1e70c7d2-1aa6-449e-b5a5-af454a8652e6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2df11d48-07bc-4a9a-b778-af4efddb5c4e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 900bbacb-bdb0-46a7-83c5-789f02637659
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e40aeffd-dfdb-4865-ad55-5aaad5ef5dcb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dc2dc242-d1be-4c75-93ca-dda316c89cd5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c4b3d7bb-1ca6-4fb5-8da2-cceb224e4f4f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c4ed6569-0106-4138-9a34-07c6c630e1e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 24850d69-5204-4687-86b0-54aab35cbec1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 93d4d2ba-24ab-485d-88d9-5e3375f11b8b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c7960ab0-a9bf-494f-a31d-8ad4012d1cd3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message debc03b8-ce0a-4514-8e4f-015357f7a2cd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2088b58d-d88b-4839-9470-e9998857cb5d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8b7d717b-c4d4-4064-bac6-e27a108d417f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 108c0795-a79d-4162-a076-be58d8923a7b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e653ef72-f388-41e8-8fd0-ecba39ec18ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d70e9b2e-3884-4241-b049-74385872cfe4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b843a3c5-f6ce-4914-8d38-47249125db80
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9fe8aa07-d109-4643-9aff-e936d95cb9da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 46258dee-070a-4f46-a36b-da9a60fe7be3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c60378ea-6df2-4a5e-abea-6b2d6ee4569d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 964030a0-815f-426c-b545-6497e33b29af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3bec7fb8-9f29-442a-b5b3-dbb3a143fe87
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7910f953-c7c4-46d0-b30e-847ffd25d3eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 25286faa-a8ff-4d67-a70a-3c6f72b7be46
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b52c1c76-6c0a-4510-9a6b-63b2461bc6a9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bfd8a6c3-6ceb-47b3-a022-5d0dc3f96e50
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1492dd5f-6a4d-41e9-8c00-23a693a3a301
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message afe35ab5-40c8-4770-9092-c9f50f6c649f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b4ee0299-16ff-4acd-aa24-f7ef0d53b31d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5198c980-fdda-4ba9-b551-47c8a266ff86
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a54e43cf-b762-4118-83ea-10b273e1f88c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 558b24f2-ca95-4bf9-81f2-475fcca54636
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5198fdfd-8810-4912-b0e6-1ac39f0b8241
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message df884ef5-821d-4329-b33b-4e8b7a873da2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0f19090d-139c-4161-afc9-45546dad5bdc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 53e5631a-fd3a-46c5-a523-8fb3821038f9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e78c9871-8dea-4913-acea-e2930e15c32f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 789e657c-cb29-485e-b535-0bab1e1e591f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fcb5b132-a9ec-4236-8d53-d7fd5cc56ca7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 92b0afad-2f7d-48f9-a848-f6a6bae9b31a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cd68750d-7108-4d87-a94e-aa3e7bb35604
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message df009075-a5c4-4da2-bb64-ca42083f5057
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f339e2f6-e09d-46d3-9ab1-9d2ea41cfb7c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cb4f717b-2289-4d01-a262-d6300de059ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7f113d5e-1c03-42ba-b265-b1f40c4474a7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8ea912c6-9287-400d-953b-757360ac53a0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 80380c1c-d03d-4a44-9e22-33dbd682dfde
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message befc1b85-2e7b-4802-9f89-250a1a501ddd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2816a660-8969-4951-b084-be635b78a9ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 21e43c5e-0686-4405-b4e3-c1bffb1faac2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 874acabf-241f-4341-befa-f9c9296f1bb3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e770e9b7-e0fa-497a-a0d1-fad296ca05ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 05a1d9aa-8867-42f9-b831-3ca19f6e8fd1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 72cc8b1d-b514-40fa-89fc-3b7513c243d5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 88b55c2e-8123-4cc7-80e3-878029294c82
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cd1bf6d6-c2cf-459d-8e25-129cd938f02a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 453b01d1-1b24-46d7-a8be-e2ac63ca73da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5578287f-abba-49dc-8967-198cadd9ba60
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eedc7c47-61a1-438a-86a4-eb364574e6e5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0c0fa71b-62e1-4b11-a83d-6904808a2a4a
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8687 {grpc_status:14, grpc_message:"Socket closed"}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_56
Server: localhost:8687
Algorithm: FEDAVG
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_56
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_56/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_56/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_56/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_56/test_labels.txt

📊 Raw data loaded:
   Train: X=(1226, 24), y=(1226,)
   Test:  X=(307, 24), y=(307,)

⚠️  Limiting training data: 1226 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  298 samples, 5 features
✅ Client client_56 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

============================================================
🔄 Round 5 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0843 (↓), lr=0.001000
   • Epoch   2/100: train=0.0787, val=0.0858, patience=1/15, lr=0.001000
   • Epoch   3/100: train=0.0780, val=0.0858, patience=2/15, lr=0.001000
   • Epoch   4/100: train=0.0772, val=0.0845, patience=3/15, lr=0.001000
   • Epoch   5/100: train=0.0760, val=0.0839, patience=4/15, lr=0.001000
   ✓ Epoch  11/100: train=0.0713, val=0.0808 (↓), lr=0.001000
   • Epoch  21/100: train=0.0655, val=0.0796, patience=3/15, lr=0.001000
   📉 Epoch 26: LR reduced 0.001000 → 0.000500
   • Epoch  31/100: train=0.0566, val=0.0826, patience=13/15, lr=0.000500

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 5 Summary - Client client_56
   Epochs: 33/100 (early stopped)
   LR: 0.001000 → 0.000500 (1 reductions)
   Train: Loss=0.0663, RMSE=0.2576, R²=0.1622
   Val:   Loss=0.0795, RMSE=0.2819, R²=0.0653
============================================================


📊 Round 5 Test Metrics:
   Loss: 0.0811, RMSE: 0.2847, MAE: 0.2481, R²: 0.0501

============================================================
🔄 Round 6 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000500
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0692 (↓), lr=0.000500
   • Epoch   2/100: train=0.0798, val=0.0689, patience=1/15, lr=0.000500
   • Epoch   3/100: train=0.0794, val=0.0687, patience=2/15, lr=0.000500
   ✓ Epoch   4/100: train=0.0790, val=0.0685 (↓), lr=0.000500
   • Epoch   5/100: train=0.0786, val=0.0684, patience=1/15, lr=0.000500
   ✓ Epoch  11/100: train=0.0766, val=0.0668 (↓), lr=0.000500
   • Epoch  21/100: train=0.0736, val=0.0641, patience=2/15, lr=0.000500
   • Epoch  31/100: train=0.0710, val=0.0624, patience=6/15, lr=0.000500
   • Epoch  41/100: train=0.0685, val=0.0620, patience=7/15, lr=0.000500
   📉 Epoch 47: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0621)

============================================================
📊 Round 6 Summary - Client client_56
   Epochs: 49/100 (early stopped)
   LR: 0.000500 → 0.000250 (1 reductions)
   Train: Loss=0.0693, RMSE=0.2632, R²=0.1596
   Val:   Loss=0.0621, RMSE=0.2493, R²=0.1218
============================================================


============================================================
🔄 Round 7 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0756, val=0.0828 (↓), lr=0.000250
   • Epoch   2/100: train=0.0752, val=0.0825, patience=1/15, lr=0.000250
   • Epoch   3/100: train=0.0749, val=0.0824, patience=2/15, lr=0.000250
   ✓ Epoch   4/100: train=0.0747, val=0.0822 (↓), lr=0.000250
   • Epoch   5/100: train=0.0745, val=0.0821, patience=1/15, lr=0.000250
   📉 Epoch 6: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0736, val=0.0816, patience=1/15, lr=0.000125
   📉 Epoch 14: LR reduced 0.000125 → 0.000063
   • Epoch  21/100: train=0.0729, val=0.0811, patience=1/15, lr=0.000063
   📉 Epoch 22: LR reduced 0.000063 → 0.000031
   📉 Epoch 30: LR reduced 0.000031 → 0.000016
   • Epoch  31/100: train=0.0725, val=0.0808, patience=11/15, lr=0.000016

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 7 Summary - Client client_56
   Epochs: 35/100 (early stopped)
   LR: 0.000250 → 0.000016 (4 reductions)
   Train: Loss=0.0729, RMSE=0.2701, R²=0.0789
   Val:   Loss=0.0812, RMSE=0.2849, R²=0.0358
============================================================


📊 Round 7 Test Metrics:
   Loss: 0.0791, RMSE: 0.2813, MAE: 0.2447, R²: 0.0728

============================================================
🔄 Round 8 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000016
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0750, val=0.0836 (↓), lr=0.000016
   • Epoch   2/100: train=0.0749, val=0.0836, patience=1/15, lr=0.000016
   📉 Epoch 3: LR reduced 0.000016 → 0.000008
   • Epoch   3/100: train=0.0749, val=0.0835, patience=2/15, lr=0.000008
   • Epoch   4/100: train=0.0749, val=0.0835, patience=3/15, lr=0.000008
   • Epoch   5/100: train=0.0749, val=0.0835, patience=4/15, lr=0.000008
   📉 Epoch 11: LR reduced 0.000008 → 0.000004
   • Epoch  11/100: train=0.0748, val=0.0833, patience=10/15, lr=0.000004

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 8 Summary - Client client_56
   Epochs: 16/100 (early stopped)
   LR: 0.000016 → 0.000004 (2 reductions)
   Train: Loss=0.0748, RMSE=0.2734, R²=0.0433
   Val:   Loss=0.0836, RMSE=0.2892, R²=0.0585
============================================================


📊 Round 8 Test Metrics:
   Loss: 0.0787, RMSE: 0.2805, MAE: 0.2438, R²: 0.0785

📊 Round 8 Test Metrics:
   Loss: 0.0790, RMSE: 0.2810, MAE: 0.2443, R²: 0.0747

============================================================
🔄 Round 15 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000004
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0763, val=0.0769 (↓), lr=0.000004
   • Epoch   2/100: train=0.0763, val=0.0769, patience=1/15, lr=0.000004
   📉 Epoch 3: LR reduced 0.000004 → 0.000002
   • Epoch   3/100: train=0.0763, val=0.0769, patience=2/15, lr=0.000002
   • Epoch   4/100: train=0.0763, val=0.0769, patience=3/15, lr=0.000002
   • Epoch   5/100: train=0.0763, val=0.0769, patience=4/15, lr=0.000002
   📉 Epoch 11: LR reduced 0.000002 → 0.000001
   • Epoch  11/100: train=0.0762, val=0.0769, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0769)

============================================================
📊 Round 15 Summary - Client client_56
   Epochs: 16/100 (early stopped)
   LR: 0.000004 → 0.000001 (2 reductions)
   Train: Loss=0.0763, RMSE=0.2762, R²=0.0486
   Val:   Loss=0.0769, RMSE=0.2773, R²=0.0454
============================================================


📊 Round 15 Test Metrics:
   Loss: 0.0786, RMSE: 0.2803, MAE: 0.2437, R²: 0.0794

📊 Round 15 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2438, R²: 0.0787

============================================================
🔄 Round 19 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0764, val=0.0758 (↓), lr=0.000001
   • Epoch   2/100: train=0.0764, val=0.0758, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0764, val=0.0758, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0764, val=0.0758, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0764, val=0.0758, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0763, val=0.0758, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0758)

============================================================
📊 Round 19 Summary - Client client_56
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0765, RMSE=0.2766, R²=0.0541
   Val:   Loss=0.0758, RMSE=0.2753, R²=0.0302
============================================================


============================================================
🔄 Round 20 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0761, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0761, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0761, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0761, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0761, val=0.0773, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0761, val=0.0773, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 20 Summary - Client client_56
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0761, RMSE=0.2759, R²=0.0485
   Val:   Loss=0.0773, RMSE=0.2780, R²=0.0532
============================================================


📊 Round 20 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2435, R²: 0.0800

============================================================
🔄 Round 24 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0761, val=0.0764 (↓), lr=0.000001
   • Epoch   2/100: train=0.0761, val=0.0764, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0761, val=0.0764, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0761, val=0.0765, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0761, val=0.0765, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0760, val=0.0765, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0764)

============================================================
📊 Round 24 Summary - Client client_56
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0761, RMSE=0.2759, R²=0.0491
   Val:   Loss=0.0764, RMSE=0.2764, R²=0.0381
============================================================


📊 Round 24 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2435, R²: 0.0800

============================================================
🔄 Round 31 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0634 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0634, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0634, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0634, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0634, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0634, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0634)

============================================================
📊 Round 31 Summary - Client client_56
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2817, R²=0.0528
   Val:   Loss=0.0634, RMSE=0.2519, R²=0.0462
============================================================


📊 Round 31 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2435, R²: 0.0800

============================================================
🔄 Round 34 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0756, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0756, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0755, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0755, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0755, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0755, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 34 Summary - Client client_56
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0757, RMSE=0.2750, R²=0.0548
   Val:   Loss=0.0783, RMSE=0.2799, R²=0.0396
============================================================


📊 Round 34 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2435, R²: 0.0800

============================================================
🔄 Round 36 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0769, val=0.0727 (↓), lr=0.000001
   • Epoch   2/100: train=0.0769, val=0.0727, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0769, val=0.0727, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0769, val=0.0727, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0769, val=0.0727, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0768, val=0.0727, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0727)

============================================================
📊 Round 36 Summary - Client client_56
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0771, RMSE=0.2776, R²=0.0507
   Val:   Loss=0.0727, RMSE=0.2696, R²=0.0470
============================================================


📊 Round 36 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2435, R²: 0.0800

📊 Round 36 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2435, R²: 0.0800

============================================================
🔄 Round 41 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0742, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0742, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0742, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0741, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0741, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0741, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 41 Summary - Client client_56
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0741, RMSE=0.2722, R²=0.0515
   Val:   Loss=0.0845, RMSE=0.2907, R²=0.0404
============================================================


📊 Round 41 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2435, R²: 0.0800

============================================================
🔄 Round 43 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0756, val=0.0779 (↓), lr=0.000001
   • Epoch   2/100: train=0.0756, val=0.0779, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0756, val=0.0779, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0756, val=0.0779, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0756, val=0.0779, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0756, val=0.0779, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0779)

============================================================
📊 Round 43 Summary - Client client_56
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0758, RMSE=0.2752, R²=0.0579
   Val:   Loss=0.0779, RMSE=0.2791, R²=0.0254
============================================================


📊 Round 43 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2435, R²: 0.0800

============================================================
🔄 Round 46 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0650 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0650, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0650, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0650, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0650, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0649, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0650)

============================================================
📊 Round 46 Summary - Client client_56
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2810, R²=0.0533
   Val:   Loss=0.0650, RMSE=0.2549, R²=0.0436
============================================================


============================================================
🔄 Round 48 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0765, val=0.0745 (↓), lr=0.000001
   • Epoch   2/100: train=0.0765, val=0.0745, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0765, val=0.0744, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0765, val=0.0744, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0765, val=0.0744, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0765, val=0.0744, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0745)

============================================================
📊 Round 48 Summary - Client client_56
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0766, RMSE=0.2768, R²=0.0466
   Val:   Loss=0.0745, RMSE=0.2729, R²=0.0659
============================================================


📊 Round 48 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2435, R²: 0.0801

============================================================
🔄 Round 49 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0676 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0676, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0676, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0676, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0783, val=0.0677, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0677, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0676)

============================================================
📊 Round 49 Summary - Client client_56
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0783, RMSE=0.2799, R²=0.0482
   Val:   Loss=0.0676, RMSE=0.2600, R²=0.0472
============================================================


📊 Round 49 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2435, R²: 0.0801

📊 Round 49 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2435, R²: 0.0801

📊 Round 49 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2435, R²: 0.0801

📊 Round 49 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2435, R²: 0.0801

📊 Round 49 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2435, R²: 0.0801

📊 Round 49 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2435, R²: 0.0801

============================================================
🔄 Round 59 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0776, val=0.0719 (↓), lr=0.000001
   • Epoch   2/100: train=0.0776, val=0.0719, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0776, val=0.0719, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0776, val=0.0719, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0776, val=0.0719, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0776, val=0.0718, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0719)

============================================================
📊 Round 59 Summary - Client client_56
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0773, RMSE=0.2780, R²=0.0554
   Val:   Loss=0.0719, RMSE=0.2681, R²=0.0224
============================================================


📊 Round 59 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2435, R²: 0.0801

📊 Round 59 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2435, R²: 0.0801

============================================================
🔄 Round 62 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0743, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0743, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0743, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0743, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0743, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0742, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 62 Summary - Client client_56
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0744, RMSE=0.2728, R²=0.0504
   Val:   Loss=0.0832, RMSE=0.2884, R²=0.0303
============================================================


📊 Round 62 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2435, R²: 0.0801

📊 Round 62 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2435, R²: 0.0801

============================================================
🔄 Round 64 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0756, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0755, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0755, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0755, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0755, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0755, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 64 Summary - Client client_56
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0756, RMSE=0.2749, R²=0.0599
   Val:   Loss=0.0786, RMSE=0.2803, R²=0.0194
============================================================


============================================================
🔄 Round 65 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0767, val=0.0742 (↓), lr=0.000001
   • Epoch   2/100: train=0.0767, val=0.0742, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0767, val=0.0742, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0767, val=0.0742, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0767, val=0.0742, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0766, val=0.0742, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0742)

============================================================
📊 Round 65 Summary - Client client_56
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0767, RMSE=0.2769, R²=0.0529
   Val:   Loss=0.0742, RMSE=0.2724, R²=0.0475
============================================================


============================================================
🔄 Round 66 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0777, val=0.0717 (↓), lr=0.000001
   • Epoch   2/100: train=0.0777, val=0.0717, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0777, val=0.0717, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0777, val=0.0717, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0776, val=0.0717, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0776, val=0.0716, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0717)

============================================================
📊 Round 66 Summary - Client client_56
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0773, RMSE=0.2780, R²=0.0428
   Val:   Loss=0.0717, RMSE=0.2677, R²=0.0867
============================================================


📊 Round 66 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2435, R²: 0.0801

============================================================
🔄 Round 67 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0766, val=0.0741 (↓), lr=0.000001
   • Epoch   2/100: train=0.0766, val=0.0741, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0766, val=0.0741, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0766, val=0.0741, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0766, val=0.0741, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0766, val=0.0742, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0741)

============================================================
📊 Round 67 Summary - Client client_56
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0767, RMSE=0.2769, R²=0.0503
   Val:   Loss=0.0741, RMSE=0.2723, R²=0.0552
============================================================


📊 Round 67 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2435, R²: 0.0801

============================================================
🔄 Round 69 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0773, val=0.0722 (↓), lr=0.000001
   • Epoch   2/100: train=0.0773, val=0.0722, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0773, val=0.0722, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0772, val=0.0722, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0772, val=0.0722, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0772, val=0.0722, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0722)

============================================================
📊 Round 69 Summary - Client client_56
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0772, RMSE=0.2778, R²=0.0465
   Val:   Loss=0.0722, RMSE=0.2687, R²=0.0748
============================================================


============================================================
🔄 Round 74 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0764, val=0.0747 (↓), lr=0.000001
   • Epoch   2/100: train=0.0764, val=0.0747, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0764, val=0.0746, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0764, val=0.0746, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0764, val=0.0746, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0764, val=0.0746, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0747)

============================================================
📊 Round 74 Summary - Client client_56
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0766, RMSE=0.2767, R²=0.0454
   Val:   Loss=0.0747, RMSE=0.2732, R²=0.0727
============================================================


📊 Round 74 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2435, R²: 0.0801

============================================================
🔄 Round 75 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0756, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0756, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0756, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0756, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0756, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0756, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 75 Summary - Client client_56
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0755, RMSE=0.2748, R²=0.0542
   Val:   Loss=0.0787, RMSE=0.2806, R²=0.0434
============================================================


📊 Round 75 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2435, R²: 0.0801

📊 Round 75 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2435, R²: 0.0801

📊 Round 75 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2435, R²: 0.0801

============================================================
🔄 Round 81 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0758, val=0.0774 (↓), lr=0.000001
   • Epoch   2/100: train=0.0758, val=0.0774, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0758, val=0.0774, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0758, val=0.0774, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0758, val=0.0774, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0757, val=0.0774, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0774)

============================================================
📊 Round 81 Summary - Client client_56
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0758, RMSE=0.2754, R²=0.0579
   Val:   Loss=0.0774, RMSE=0.2783, R²=0.0270
============================================================


📊 Round 81 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2435, R²: 0.0801

============================================================
🔄 Round 82 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0747, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0747, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0747, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0747, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0747, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0747, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 82 Summary - Client client_56
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0748, RMSE=0.2735, R²=0.0445
   Val:   Loss=0.0816, RMSE=0.2856, R²=0.0773
============================================================


📊 Round 82 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2435, R²: 0.0801

============================================================
🔄 Round 88 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0769, val=0.0737 (↓), lr=0.000001
   • Epoch   2/100: train=0.0769, val=0.0737, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0769, val=0.0737, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0769, val=0.0737, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0769, val=0.0737, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0769, val=0.0737, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0737)

============================================================
📊 Round 88 Summary - Client client_56
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0768, RMSE=0.2771, R²=0.0424
   Val:   Loss=0.0737, RMSE=0.2715, R²=0.0884
============================================================


📊 Round 88 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2435, R²: 0.0801

📊 Round 88 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2435, R²: 0.0801

============================================================
🔄 Round 90 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0775, val=0.0707 (↓), lr=0.000001
   • Epoch   2/100: train=0.0775, val=0.0707, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0775, val=0.0707, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0775, val=0.0708, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0775, val=0.0708, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0774, val=0.0708, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0707)

============================================================
📊 Round 90 Summary - Client client_56
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0775, RMSE=0.2784, R²=0.0557
   Val:   Loss=0.0707, RMSE=0.2660, R²=0.0273
============================================================


📊 Round 90 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2435, R²: 0.0801

📊 Round 90 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2435, R²: 0.0801

============================================================
🔄 Round 92 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0760, val=0.0764 (↓), lr=0.000001
   • Epoch   2/100: train=0.0760, val=0.0764, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0760, val=0.0764, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0760, val=0.0764, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0760, val=0.0764, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0760, val=0.0764, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0764)

============================================================
📊 Round 92 Summary - Client client_56
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0761, RMSE=0.2759, R²=0.0488
   Val:   Loss=0.0764, RMSE=0.2764, R²=0.0642
============================================================


📊 Round 92 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2435, R²: 0.0801

============================================================
🔄 Round 95 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0769, val=0.0730 (↓), lr=0.000001
   • Epoch   2/100: train=0.0769, val=0.0730, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0769, val=0.0730, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0769, val=0.0730, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0769, val=0.0730, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0768, val=0.0730, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0730)

============================================================
📊 Round 95 Summary - Client client_56
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0770, RMSE=0.2774, R²=0.0497
   Val:   Loss=0.0730, RMSE=0.2701, R²=0.0482
============================================================


============================================================
🔄 Round 96 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0762, val=0.0759 (↓), lr=0.000001
   • Epoch   2/100: train=0.0762, val=0.0759, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0762, val=0.0759, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0762, val=0.0759, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0762, val=0.0759, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0761, val=0.0759, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0759)

============================================================
📊 Round 96 Summary - Client client_56
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0762, RMSE=0.2761, R²=0.0515
   Val:   Loss=0.0759, RMSE=0.2755, R²=0.0454
============================================================


📊 Round 96 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2435, R²: 0.0801

============================================================
🔄 Round 98 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0769, val=0.0739 (↓), lr=0.000001
   • Epoch   2/100: train=0.0768, val=0.0739, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0768, val=0.0739, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0768, val=0.0739, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0768, val=0.0739, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0768, val=0.0738, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0739)

============================================================
📊 Round 98 Summary - Client client_56
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0767, RMSE=0.2770, R²=0.0514
   Val:   Loss=0.0739, RMSE=0.2718, R²=0.0548
============================================================


============================================================
🔄 Round 99 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0773, val=0.0710 (↓), lr=0.000001
   • Epoch   2/100: train=0.0773, val=0.0710, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0773, val=0.0710, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0773, val=0.0710, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0773, val=0.0710, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0772, val=0.0710, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0710)

============================================================
📊 Round 99 Summary - Client client_56
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0774, RMSE=0.2783, R²=0.0464
   Val:   Loss=0.0710, RMSE=0.2665, R²=0.0694
============================================================


============================================================
🔄 Round 101 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0747, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0747, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0747, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0747, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0747, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0746, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 101 Summary - Client client_56
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0749, RMSE=0.2736, R²=0.0505
   Val:   Loss=0.0813, RMSE=0.2852, R²=0.0579
============================================================


============================================================
🔄 Round 102 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0752, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0752, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0752, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0752, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0752, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0752, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 102 Summary - Client client_56
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0752, RMSE=0.2743, R²=0.0479
   Val:   Loss=0.0798, RMSE=0.2825, R²=0.0683
============================================================


📊 Round 102 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2435, R²: 0.0801

============================================================
🔄 Round 105 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0749, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0749, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0748, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0748, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0748, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0748, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 105 Summary - Client client_56
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0751, RMSE=0.2740, R²=0.0527
   Val:   Loss=0.0804, RMSE=0.2835, R²=0.0428
============================================================


📊 Round 105 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2435, R²: 0.0801

============================================================
🔄 Round 107 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0766, val=0.0751 (↓), lr=0.000001
   • Epoch   2/100: train=0.0766, val=0.0751, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0766, val=0.0751, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0766, val=0.0751, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0766, val=0.0751, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0765, val=0.0751, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0751)

============================================================
📊 Round 107 Summary - Client client_56
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0764, RMSE=0.2764, R²=0.0543
   Val:   Loss=0.0751, RMSE=0.2740, R²=0.0433
============================================================


📊 Round 107 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2435, R²: 0.0801

============================================================
🔄 Round 108 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0776, val=0.0709 (↓), lr=0.000001
   • Epoch   2/100: train=0.0776, val=0.0709, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0775, val=0.0709, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0775, val=0.0709, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0775, val=0.0709, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0775, val=0.0708, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0709)

============================================================
📊 Round 108 Summary - Client client_56
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0775, RMSE=0.2783, R²=0.0583
   Val:   Loss=0.0709, RMSE=0.2662, R²=0.0249
============================================================


============================================================
🔄 Round 109 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0762, val=0.0751 (↓), lr=0.000001
   • Epoch   2/100: train=0.0762, val=0.0751, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0762, val=0.0751, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0762, val=0.0751, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0762, val=0.0751, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0761, val=0.0751, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0751)

============================================================
📊 Round 109 Summary - Client client_56
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0764, RMSE=0.2764, R²=0.0531
   Val:   Loss=0.0751, RMSE=0.2740, R²=0.0391
============================================================


============================================================
🔄 Round 111 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0776, val=0.0695 (↓), lr=0.000001
   • Epoch   2/100: train=0.0776, val=0.0695, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0776, val=0.0695, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0776, val=0.0695, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0776, val=0.0695, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0776, val=0.0694, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0695)

============================================================
📊 Round 111 Summary - Client client_56
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0778, RMSE=0.2790, R²=0.0502
   Val:   Loss=0.0695, RMSE=0.2636, R²=0.0594
============================================================


============================================================
🔄 Round 112 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0763, val=0.0760 (↓), lr=0.000001
   • Epoch   2/100: train=0.0763, val=0.0760, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0763, val=0.0760, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0763, val=0.0760, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0762, val=0.0760, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0762, val=0.0760, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0760)

============================================================
📊 Round 112 Summary - Client client_56
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0762, RMSE=0.2760, R²=0.0578
   Val:   Loss=0.0760, RMSE=0.2756, R²=0.0220
============================================================


📊 Round 112 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2435, R²: 0.0801

📊 Round 112 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2435, R²: 0.0801

============================================================
🔄 Round 117 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0771, val=0.0721 (↓), lr=0.000001
   • Epoch   2/100: train=0.0771, val=0.0721, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0771, val=0.0721, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0771, val=0.0721, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0771, val=0.0721, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0770, val=0.0721, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0721)

============================================================
📊 Round 117 Summary - Client client_56
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0771, RMSE=0.2778, R²=0.0505
   Val:   Loss=0.0721, RMSE=0.2685, R²=0.0600
============================================================


============================================================
🔄 Round 118 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0772, val=0.0714 (↓), lr=0.000001
   • Epoch   2/100: train=0.0772, val=0.0714, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0772, val=0.0714, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0772, val=0.0714, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0772, val=0.0714, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0771, val=0.0715, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0714)

============================================================
📊 Round 118 Summary - Client client_56
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0773, RMSE=0.2781, R²=0.0542
   Val:   Loss=0.0714, RMSE=0.2673, R²=0.0392
============================================================


============================================================
🔄 Round 119 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0755, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0754, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0754, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0754, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0754, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0754, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 119 Summary - Client client_56
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0755, RMSE=0.2749, R²=0.0578
   Val:   Loss=0.0785, RMSE=0.2802, R²=0.0270
============================================================


📊 Round 119 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2435, R²: 0.0801

============================================================
🔄 Round 121 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0778, val=0.0709 (↓), lr=0.000001
   • Epoch   2/100: train=0.0778, val=0.0709, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0778, val=0.0709, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0778, val=0.0709, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0778, val=0.0709, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0777, val=0.0708, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0709)

============================================================
📊 Round 121 Summary - Client client_56
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0775, RMSE=0.2783, R²=0.0495
   Val:   Loss=0.0709, RMSE=0.2662, R²=0.0636
============================================================


📊 Round 121 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2435, R²: 0.0800

📊 Round 121 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2435, R²: 0.0801

============================================================
🔄 Round 126 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0766, val=0.0742 (↓), lr=0.000001
   • Epoch   2/100: train=0.0765, val=0.0742, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0765, val=0.0742, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0765, val=0.0742, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0765, val=0.0742, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0765, val=0.0742, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0742)

============================================================
📊 Round 126 Summary - Client client_56
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0766, RMSE=0.2768, R²=0.0527
   Val:   Loss=0.0742, RMSE=0.2724, R²=0.0463
============================================================


============================================================
🔄 Round 127 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0680 (↓), lr=0.000001
   • Epoch   2/100: train=0.0785, val=0.0680, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0680, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0680, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0680, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0680, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0680)

============================================================
📊 Round 127 Summary - Client client_56
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0782, RMSE=0.2796, R²=0.0516
   Val:   Loss=0.0680, RMSE=0.2608, R²=0.0550
============================================================


📊 Round 127 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2435, R²: 0.0800

============================================================
🔄 Round 132 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0751, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0751, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0751, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0751, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0751, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0750, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 132 Summary - Client client_56
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0751, RMSE=0.2740, R²=0.0619
   Val:   Loss=0.0804, RMSE=0.2836, R²=-0.0092
============================================================


============================================================
🔄 Round 133 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0764, val=0.0744 (↓), lr=0.000001
   • Epoch   2/100: train=0.0763, val=0.0745, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0763, val=0.0745, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0763, val=0.0745, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0763, val=0.0745, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0762, val=0.0745, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0744)

============================================================
📊 Round 133 Summary - Client client_56
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0766, RMSE=0.2767, R²=0.0472
   Val:   Loss=0.0744, RMSE=0.2729, R²=0.0599
============================================================


============================================================
🔄 Round 134 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0779, val=0.0699 (↓), lr=0.000001
   • Epoch   2/100: train=0.0779, val=0.0699, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0779, val=0.0699, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0779, val=0.0699, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0779, val=0.0699, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0778, val=0.0699, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0699)

============================================================
📊 Round 134 Summary - Client client_56
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0777, RMSE=0.2787, R²=0.0539
   Val:   Loss=0.0699, RMSE=0.2644, R²=0.0405
============================================================


============================================================
🔄 Round 135 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0761, val=0.0754 (↓), lr=0.000001
   • Epoch   2/100: train=0.0761, val=0.0754, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0761, val=0.0754, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0760, val=0.0754, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0760, val=0.0754, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0760, val=0.0753, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0754)

============================================================
📊 Round 135 Summary - Client client_56
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0763, RMSE=0.2763, R²=0.0561
   Val:   Loss=0.0754, RMSE=0.2745, R²=0.0374
============================================================


📊 Round 135 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2435, R²: 0.0801

============================================================
🔄 Round 136 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0759, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0759, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0759, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0759, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0759, val=0.0773, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0758, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 136 Summary - Client client_56
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0759, RMSE=0.2754, R²=0.0487
   Val:   Loss=0.0773, RMSE=0.2780, R²=0.0668
============================================================


📊 Round 136 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2435, R²: 0.0801

============================================================
🔄 Round 137 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0746, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0746, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0746, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0746, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0746, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0746, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 137 Summary - Client client_56
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0748, RMSE=0.2735, R²=0.0557
   Val:   Loss=0.0814, RMSE=0.2854, R²=0.0396
============================================================


📊 Round 137 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2435, R²: 0.0800

============================================================
🔄 Round 139 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0762, val=0.0755 (↓), lr=0.000001
   • Epoch   2/100: train=0.0761, val=0.0755, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0761, val=0.0755, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0761, val=0.0755, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0761, val=0.0755, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0761, val=0.0755, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0755)

============================================================
📊 Round 139 Summary - Client client_56
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0763, RMSE=0.2762, R²=0.0552
   Val:   Loss=0.0755, RMSE=0.2748, R²=0.0377
============================================================


📊 Round 139 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2435, R²: 0.0800

============================================================
🔄 Round 142 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0752, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0752, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0752, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0752, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0752, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0751, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 142 Summary - Client client_56
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0752, RMSE=0.2743, R²=0.0547
   Val:   Loss=0.0798, RMSE=0.2824, R²=0.0421
============================================================


📊 Round 142 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2435, R²: 0.0800

📊 Round 142 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2435, R²: 0.0800

============================================================
🔄 Round 144 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0744, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0744, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0744, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0743, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0743, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0743, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 144 Summary - Client client_56
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0745, RMSE=0.2729, R²=0.0517
   Val:   Loss=0.0827, RMSE=0.2877, R²=0.0529
============================================================


📊 Round 144 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2435, R²: 0.0800

============================================================
🔄 Round 145 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0758, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0758, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0758, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0758, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0758, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0757, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 145 Summary - Client client_56
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0756, RMSE=0.2749, R²=0.0481
   Val:   Loss=0.0783, RMSE=0.2798, R²=0.0662
============================================================


============================================================
🔄 Round 147 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0758, val=0.0760 (↓), lr=0.000001
   • Epoch   2/100: train=0.0758, val=0.0760, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0758, val=0.0760, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0758, val=0.0760, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0758, val=0.0760, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0757, val=0.0760, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0760)

============================================================
📊 Round 147 Summary - Client client_56
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0762, RMSE=0.2760, R²=0.0504
   Val:   Loss=0.0760, RMSE=0.2758, R²=0.0602
============================================================


📊 Round 147 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2435, R²: 0.0800

============================================================
🔄 Round 149 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0764, val=0.0760 (↓), lr=0.000001
   • Epoch   2/100: train=0.0764, val=0.0760, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0764, val=0.0760, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0764, val=0.0760, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0763, val=0.0760, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0763, val=0.0760, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0760)

============================================================
📊 Round 149 Summary - Client client_56
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0762, RMSE=0.2760, R²=0.0548
   Val:   Loss=0.0760, RMSE=0.2756, R²=0.0404
============================================================


📊 Round 149 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2435, R²: 0.0800

============================================================
🔄 Round 152 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0768, val=0.0742 (↓), lr=0.000001
   • Epoch   2/100: train=0.0768, val=0.0742, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0768, val=0.0742, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0768, val=0.0742, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0768, val=0.0742, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0767, val=0.0742, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0742)

============================================================
📊 Round 152 Summary - Client client_56
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0766, RMSE=0.2768, R²=0.0528
   Val:   Loss=0.0742, RMSE=0.2724, R²=0.0487
============================================================


📊 Round 152 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2435, R²: 0.0800

============================================================
🔄 Round 153 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0761, val=0.0763 (↓), lr=0.000001
   • Epoch   2/100: train=0.0761, val=0.0763, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0761, val=0.0763, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0761, val=0.0763, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0761, val=0.0763, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0760, val=0.0762, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0763)

============================================================
📊 Round 153 Summary - Client client_56
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0761, RMSE=0.2758, R²=0.0546
   Val:   Loss=0.0763, RMSE=0.2762, R²=0.0446
============================================================


📊 Round 153 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2435, R²: 0.0800

📊 Round 153 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2435, R²: 0.0800

============================================================
🔄 Round 157 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0758, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0758, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0758, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0757, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0757, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0757, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 157 Summary - Client client_56
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0758, RMSE=0.2753, R²=0.0544
   Val:   Loss=0.0775, RMSE=0.2784, R²=0.0253
============================================================


============================================================
🔄 Round 159 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0783, val=0.0670 (↓), lr=0.000001
   • Epoch   2/100: train=0.0783, val=0.0670, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0783, val=0.0670, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0783, val=0.0670, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0783, val=0.0669, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0782, val=0.0669, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0670)

============================================================
📊 Round 159 Summary - Client client_56
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2800, R²=0.0600
   Val:   Loss=0.0670, RMSE=0.2588, R²=0.0165
============================================================


============================================================
🔄 Round 160 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0745, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0744, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0744, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0744, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0744, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0744, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 160 Summary - Client client_56
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0744, RMSE=0.2728, R²=0.0515
   Val:   Loss=0.0830, RMSE=0.2880, R²=0.0561
============================================================


📊 Round 160 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2435, R²: 0.0800

============================================================
🔄 Round 162 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0768, val=0.0729 (↓), lr=0.000001
   • Epoch   2/100: train=0.0768, val=0.0729, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0768, val=0.0729, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0768, val=0.0729, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0767, val=0.0729, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0767, val=0.0729, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0729)

============================================================
📊 Round 162 Summary - Client client_56
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0769, RMSE=0.2774, R²=0.0576
   Val:   Loss=0.0729, RMSE=0.2700, R²=0.0293
============================================================


📊 Round 162 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2435, R²: 0.0800

============================================================
🔄 Round 168 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0756, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0756, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0756, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0756, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0756, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0755, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 168 Summary - Client client_56
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0756, RMSE=0.2749, R²=0.0544
   Val:   Loss=0.0783, RMSE=0.2797, R²=0.0329
============================================================


============================================================
🔄 Round 169 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0765, val=0.0744 (↓), lr=0.000001
   • Epoch   2/100: train=0.0764, val=0.0743, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0764, val=0.0743, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0764, val=0.0743, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0764, val=0.0743, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0764, val=0.0743, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0744)

============================================================
📊 Round 169 Summary - Client client_56
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0766, RMSE=0.2767, R²=0.0484
   Val:   Loss=0.0744, RMSE=0.2727, R²=0.0684
============================================================


============================================================
🔄 Round 170 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0655 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0655, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0655, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0655, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0655, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0654, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0655)

============================================================
📊 Round 170 Summary - Client client_56
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2807, R²=0.0519
   Val:   Loss=0.0655, RMSE=0.2559, R²=0.0556
============================================================


📊 Round 170 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2435, R²: 0.0799

📊 Round 170 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2435, R²: 0.0799

============================================================
🔄 Round 174 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0745, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0745, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0745, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0745, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0745, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0744, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 174 Summary - Client client_56
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0747, RMSE=0.2732, R²=0.0569
   Val:   Loss=0.0820, RMSE=0.2863, R²=0.0366
============================================================


============================================================
🔄 Round 175 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0766, val=0.0744 (↓), lr=0.000001
   • Epoch   2/100: train=0.0766, val=0.0744, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0766, val=0.0744, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0766, val=0.0744, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0766, val=0.0744, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0765, val=0.0744, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0744)

============================================================
📊 Round 175 Summary - Client client_56
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0765, RMSE=0.2766, R²=0.0572
   Val:   Loss=0.0744, RMSE=0.2729, R²=0.0264
============================================================


📊 Round 175 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2435, R²: 0.0799

============================================================
🔄 Round 177 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0740, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0740, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0740, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0740, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0740, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0740, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 177 Summary - Client client_56
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0740, RMSE=0.2721, R²=0.0486
   Val:   Loss=0.0844, RMSE=0.2905, R²=0.0668
============================================================


📊 Round 177 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2435, R²: 0.0799

============================================================
🔄 Round 179 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0765, val=0.0758 (↓), lr=0.000001
   • Epoch   2/100: train=0.0765, val=0.0758, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0765, val=0.0758, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0765, val=0.0758, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0765, val=0.0758, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0764, val=0.0759, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0758)

============================================================
📊 Round 179 Summary - Client client_56
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0762, RMSE=0.2760, R²=0.0590
   Val:   Loss=0.0758, RMSE=0.2754, R²=0.0204
============================================================


============================================================
🔄 Round 180 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0753, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0753, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0753, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0753, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0753, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0752, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 180 Summary - Client client_56
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0751, RMSE=0.2740, R²=0.0521
   Val:   Loss=0.0802, RMSE=0.2831, R²=0.0497
============================================================


📊 Round 180 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2435, R²: 0.0799

============================================================
🔄 Round 184 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0755, val=0.0780 (↓), lr=0.000001
   • Epoch   2/100: train=0.0755, val=0.0780, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0755, val=0.0779, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0755, val=0.0779, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0754, val=0.0779, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0754, val=0.0779, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 184 Summary - Client client_56
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0756, RMSE=0.2750, R²=0.0540
   Val:   Loss=0.0780, RMSE=0.2792, R²=0.0462
============================================================


📊 Round 184 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2435, R²: 0.0799

📊 Round 184 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2435, R²: 0.0799

============================================================
🔄 Round 186 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0754, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0754, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0754, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0754, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0754, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0754, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 186 Summary - Client client_56
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0755, RMSE=0.2747, R²=0.0446
   Val:   Loss=0.0787, RMSE=0.2805, R²=0.0759
============================================================


============================================================
🔄 Round 188 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0762, val=0.0765 (↓), lr=0.000001
   • Epoch   2/100: train=0.0762, val=0.0765, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0762, val=0.0765, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0762, val=0.0765, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0762, val=0.0765, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0761, val=0.0764, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0765)

============================================================
📊 Round 188 Summary - Client client_56
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0760, RMSE=0.2757, R²=0.0541
   Val:   Loss=0.0765, RMSE=0.2765, R²=0.0429
============================================================


============================================================
🔄 Round 189 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0768, val=0.0735 (↓), lr=0.000001
   • Epoch   2/100: train=0.0768, val=0.0735, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0768, val=0.0735, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0768, val=0.0735, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0768, val=0.0735, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0767, val=0.0735, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0735)

============================================================
📊 Round 189 Summary - Client client_56
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0768, RMSE=0.2770, R²=0.0478
   Val:   Loss=0.0735, RMSE=0.2712, R²=0.0717
============================================================


📊 Round 189 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2435, R²: 0.0799

============================================================
🔄 Round 190 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0780, val=0.0681 (↓), lr=0.000001
   • Epoch   2/100: train=0.0780, val=0.0681, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0780, val=0.0681, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0780, val=0.0681, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0780, val=0.0681, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0779, val=0.0682, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0681)

============================================================
📊 Round 190 Summary - Client client_56
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0781, RMSE=0.2795, R²=0.0437
   Val:   Loss=0.0681, RMSE=0.2610, R²=0.0823
============================================================


============================================================
🔄 Round 191 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0767, val=0.0738 (↓), lr=0.000001
   • Epoch   2/100: train=0.0767, val=0.0738, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0767, val=0.0738, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0766, val=0.0738, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0766, val=0.0738, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0766, val=0.0738, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0738)

============================================================
📊 Round 191 Summary - Client client_56
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0767, RMSE=0.2769, R²=0.0570
   Val:   Loss=0.0738, RMSE=0.2717, R²=0.0348
============================================================


📊 Round 191 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2435, R²: 0.0799

📊 Round 191 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2435, R²: 0.0799

============================================================
🔄 Round 193 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0751, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0751, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0750, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0750, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0750, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0750, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 193 Summary - Client client_56
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0751, RMSE=0.2740, R²=0.0438
   Val:   Loss=0.0802, RMSE=0.2832, R²=0.0848
============================================================


============================================================
🔄 Round 194 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0776, val=0.0709 (↓), lr=0.000001
   • Epoch   2/100: train=0.0776, val=0.0709, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0776, val=0.0709, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0776, val=0.0709, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0776, val=0.0709, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0775, val=0.0709, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0709)

============================================================
📊 Round 194 Summary - Client client_56
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0774, RMSE=0.2782, R²=0.0525
   Val:   Loss=0.0709, RMSE=0.2662, R²=0.0496
============================================================


============================================================
🔄 Round 195 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0746, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0746, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0746, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0746, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0746, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0746, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 195 Summary - Client client_56
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0750, RMSE=0.2739, R²=0.0570
   Val:   Loss=0.0806, RMSE=0.2839, R²=0.0297
============================================================


============================================================
🔄 Round 197 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0764, val=0.0754 (↓), lr=0.000001
   • Epoch   2/100: train=0.0764, val=0.0754, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0764, val=0.0754, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0764, val=0.0754, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0764, val=0.0754, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0763, val=0.0753, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0754)

============================================================
📊 Round 197 Summary - Client client_56
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0763, RMSE=0.2762, R²=0.0545
   Val:   Loss=0.0754, RMSE=0.2745, R²=0.0320
============================================================


============================================================
🔄 Round 199 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0755, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0755, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0755, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0755, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0755, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0754, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 199 Summary - Client client_56
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0752, RMSE=0.2743, R²=0.0493
   Val:   Loss=0.0796, RMSE=0.2821, R²=0.0659
============================================================


============================================================
🔄 Round 201 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0758, val=0.0772 (↓), lr=0.000001
   • Epoch   2/100: train=0.0757, val=0.0772, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0757, val=0.0772, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0757, val=0.0772, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0757, val=0.0772, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0757, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 201 Summary - Client client_56
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0758, RMSE=0.2754, R²=0.0580
   Val:   Loss=0.0772, RMSE=0.2779, R²=0.0322
============================================================


============================================================
🔄 Round 203 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0736, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0736, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0736, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0736, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0736, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0735, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 203 Summary - Client client_56
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0737, RMSE=0.2715, R²=0.0572
   Val:   Loss=0.0857, RMSE=0.2928, R²=0.0334
============================================================


📊 Round 203 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2435, R²: 0.0799

============================================================
🔄 Round 208 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0769, val=0.0718 (↓), lr=0.000001
   • Epoch   2/100: train=0.0769, val=0.0718, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0769, val=0.0718, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0769, val=0.0718, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0769, val=0.0718, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0768, val=0.0718, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0718)

============================================================
📊 Round 208 Summary - Client client_56
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0772, RMSE=0.2778, R²=0.0558
   Val:   Loss=0.0718, RMSE=0.2680, R²=0.0306
============================================================


============================================================
🔄 Round 210 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0755, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0755, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0754, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0754, val=0.0774, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0754, val=0.0774, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0754, val=0.0774, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 210 Summary - Client client_56
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0758, RMSE=0.2752, R²=0.0530
   Val:   Loss=0.0775, RMSE=0.2783, R²=0.0519
============================================================


📊 Round 210 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2435, R²: 0.0799

============================================================
🔄 Round 212 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0763, val=0.0753 (↓), lr=0.000001
   • Epoch   2/100: train=0.0763, val=0.0753, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0763, val=0.0753, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0763, val=0.0753, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0763, val=0.0753, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0762, val=0.0752, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0753)

============================================================
📊 Round 212 Summary - Client client_56
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0763, RMSE=0.2762, R²=0.0541
   Val:   Loss=0.0753, RMSE=0.2744, R²=0.0482
============================================================


============================================================
🔄 Round 213 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0761, val=0.0758 (↓), lr=0.000001
   • Epoch   2/100: train=0.0761, val=0.0758, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0761, val=0.0758, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0761, val=0.0758, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0761, val=0.0758, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0760, val=0.0757, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0758)

============================================================
📊 Round 213 Summary - Client client_56
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0762, RMSE=0.2760, R²=0.0555
   Val:   Loss=0.0758, RMSE=0.2753, R²=0.0417
============================================================


============================================================
🔄 Round 214 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0742, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0742, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0742, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0742, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0742, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0741, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 214 Summary - Client client_56
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0742, RMSE=0.2724, R²=0.0529
   Val:   Loss=0.0836, RMSE=0.2892, R²=0.0535
============================================================


📊 Round 214 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2435, R²: 0.0799

📊 Round 214 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2435, R²: 0.0799

============================================================
🔄 Round 216 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0735, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0735, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0735, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0735, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0735, val=0.0864, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0735, val=0.0864, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 216 Summary - Client client_56
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0735, RMSE=0.2711, R²=0.0598
   Val:   Loss=0.0864, RMSE=0.2940, R²=0.0274
============================================================


============================================================
🔄 Round 217 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0757, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0757, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0757, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0757, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0757, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0756, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 217 Summary - Client client_56
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0753, RMSE=0.2745, R²=0.0535
   Val:   Loss=0.0791, RMSE=0.2812, R²=0.0394
============================================================


============================================================
🔄 Round 218 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0770, val=0.0734 (↓), lr=0.000001
   • Epoch   2/100: train=0.0770, val=0.0734, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0770, val=0.0734, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0770, val=0.0734, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0770, val=0.0734, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0769, val=0.0734, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0734)

============================================================
📊 Round 218 Summary - Client client_56
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0768, RMSE=0.2770, R²=0.0539
   Val:   Loss=0.0734, RMSE=0.2710, R²=0.0426
============================================================


============================================================
🔄 Round 219 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0770, val=0.0732 (↓), lr=0.000001
   • Epoch   2/100: train=0.0769, val=0.0732, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0769, val=0.0732, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0769, val=0.0732, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0769, val=0.0732, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0768, val=0.0732, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0732)

============================================================
📊 Round 219 Summary - Client client_56
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0768, RMSE=0.2772, R²=0.0504
   Val:   Loss=0.0732, RMSE=0.2705, R²=0.0585
============================================================


============================================================
🔄 Round 221 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0757, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0757, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0756, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0756, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0756, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0756, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 221 Summary - Client client_56
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0754, RMSE=0.2746, R²=0.0559
   Val:   Loss=0.0788, RMSE=0.2807, R²=0.0420
============================================================


📊 Round 221 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2435, R²: 0.0799

============================================================
🔄 Round 222 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0772, val=0.0712 (↓), lr=0.000001
   • Epoch   2/100: train=0.0772, val=0.0712, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0772, val=0.0712, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0772, val=0.0712, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0772, val=0.0712, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0771, val=0.0712, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0712)

============================================================
📊 Round 222 Summary - Client client_56
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0773, RMSE=0.2780, R²=0.0513
   Val:   Loss=0.0712, RMSE=0.2668, R²=0.0608
============================================================


============================================================
🔄 Round 223 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0765, val=0.0746 (↓), lr=0.000001
   • Epoch   2/100: train=0.0765, val=0.0746, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0765, val=0.0746, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0765, val=0.0746, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0765, val=0.0746, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0764, val=0.0746, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0746)

============================================================
📊 Round 223 Summary - Client client_56
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0765, RMSE=0.2765, R²=0.0434
   Val:   Loss=0.0746, RMSE=0.2732, R²=0.0745
============================================================


============================================================
🔄 Round 224 - Client client_56
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0753, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0753, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0753, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0753, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0753, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0753, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 224 Summary - Client client_56
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0754, RMSE=0.2746, R²=0.0466
   Val:   Loss=0.0787, RMSE=0.2805, R²=0.0764
============================================================


📊 Round 224 Test Metrics:
   Loss: 0.0785, RMSE: 0.2803, MAE: 0.2435, R²: 0.0799

❌ Client client_56 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8687 {grpc_status:14, grpc_message:"Socket closed"}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8687 {grpc_status:14, grpc_message:"Socket closed"}"
>
