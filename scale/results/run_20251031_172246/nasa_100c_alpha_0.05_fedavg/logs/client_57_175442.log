[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 06e8ce7f-e6cb-40f8-9089-c4f5a8dfe078
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8732d943-b1dd-41b0-a4cd-404b2de5e5c7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e01078f6-0fe0-44fc-a627-8d3f52653032
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 972a34c2-3e4e-477e-bfbd-c02e0a4911f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8b67368c-ed33-494d-8b3e-46749a94c212
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 24ac0814-7af5-4945-bce5-b16115e15f06
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8de99756-7c76-478b-8511-c375e338662b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5a2afa17-4a22-4eb6-b167-eb2cbb9bf6a8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 80d0c73f-861a-4b07-8692-d6113cdffb68
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3e73ff77-7de9-4880-8864-15c299317b00
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1942fd30-be2e-4a2b-bf90-c989d9d87eba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4f207e72-55fb-4251-a6c0-e830ff770309
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9c5e71b9-149f-45e9-aa8f-b440a68f008a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 748d360f-b053-44e4-96b1-a964f82f9300
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 317ddee9-e8dd-4d26-a10b-0c6f8562496d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 922e26ac-3662-4328-8aa6-0e7b10480fb9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 49e30362-ce90-4cb8-8e9d-841aa128c7bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9abcfa72-d14c-405b-906d-f05b46f1b060
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d96d2d1d-954a-40c8-b59f-c55dac1250d8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c602e078-efa0-4418-a8fb-ab4657e3a30a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e073beb6-65bf-4fc4-8590-9412752df70b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 74ac5426-83e7-49e4-999f-83425f149735
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6feee658-9623-45a9-b59e-00ff6bfa96e0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dfa2a6d2-b8f4-4ebf-9eda-6cde0e069746
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 039c4d92-c5e4-4afa-a81e-0ac08f949c31
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bf8e0a28-f2f0-4664-94d5-d9e26ac20442
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 44290396-cf07-4fc6-8fb0-393eb1a172f7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aaee9d4b-fef4-4540-ae22-1d922a5ff787
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 244abe3a-4fed-48d4-9cef-27ef90df1a08
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1f2d450c-9e67-46e8-aef7-ce7d44e22356
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d7637817-466b-4b13-985f-156706306956
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 51070343-082e-4d8f-bd22-23ec85476b54
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dc9d30f2-75b5-4373-8315-502225b12c7d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4525286d-ff24-4b02-b6c9-38fe60d8d5f3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a72c7622-80f3-4f22-9a1d-8437e0493650
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f3a42185-2ce3-4a44-8dc7-a9a87cb11d1e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0d87bed2-2db4-4f86-9525-93bed80e0a25
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0a65ce3b-0393-4483-9957-08aefb8ec3f6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 39294fd1-5a43-4b30-84c3-d3eef00248be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aa8a3a0f-320f-4d3d-921d-3f07366578e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5e62a9c0-b68a-4227-97db-0f7aeafc7e43
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5bd1a0b5-5011-4981-b251-075cf1016164
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d1a0554b-0239-4686-bca4-3517e6ed60ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7537d8f1-57c3-422f-8641-5d7270510626
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 570f3079-9415-4ba5-a8e6-060298b87ef5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 556c954b-8ea8-4a99-a53a-16fee20390fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bd745589-285f-41bc-b967-391fbbb193cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0e082ce3-4b4f-4a7b-a319-d79916a6028f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d65b7afb-47d2-48cc-8d10-590ccdddb787
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 51465e9a-f7cf-4010-bb31-e19f47eb4180
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 944a584e-6b10-4080-b4b0-b29d426d1537
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 90330c8e-dbc1-4916-bbbb-7e97eabd48bd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c25d5b44-c70d-43de-bc19-05353f0cf7f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ceaa632f-8867-4dcc-a908-8ed309afb568
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a9020f5c-3aa6-49e0-9dce-174d1b9f345f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 39b8eefb-8045-4ddd-b14d-d57757e95d88
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ead59f91-8a41-4004-b5dd-4125745eea85
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5c8fdfb3-d63d-4985-8175-4096b5e682dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 53e44e3a-84ed-48ca-a8f3-51ff18245cb3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 54609807-935c-4f3d-a6e1-40a20d03b0bd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fe7e78d2-61ea-4a7e-bbab-ad0318dccdbb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fbe17525-5492-4790-abb9-9698786fa717
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7cf26378-77da-41d6-8250-4fa537024661
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f11ba1a3-e41b-46f8-99e0-8226af45317f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9d77afb1-fdc6-4c91-967b-6eecd71e516c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 07ca7b93-6e8b-4d4f-9be5-5a2f0e8ec3ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 799f309b-501b-42dc-91a3-2d8757c2f3bd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 768943d3-11fd-4956-b0b0-04124a65730c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1c334a0d-5e99-4313-893b-9841e3fdee50
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9f7ad352-937a-4c94-bc59-dddc1ea040bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4c27fc29-97f1-4979-9ecf-ee4662c3a4cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b7511cfc-9ac2-4028-bda6-0f91b7119ebc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f75614fc-fe06-44ee-a123-754dad4fd27d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 54014201-9169-4463-aa90-7d723a95dd70
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 36d308ec-d6d5-4b96-becc-ee1c08527635
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 26e34ac6-a41a-4105-83df-59f71898f4aa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0a8d3e40-963a-4948-88a6-1df5e3f4c208
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 12e225a7-adce-47fb-a443-edbfb765b01c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2ec20d8d-8d24-42df-89af-4acea7bebe7b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e126c50b-062d-4a21-a32f-6aced60eed51
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 311ace0e-a303-4771-8659-1133c67ebafc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1e2c97d7-86e3-4f64-bc7e-a5fa922810d8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e7ed9d15-2791-4ee6-95eb-5e59e0113fe5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e81c9cfd-5266-4be3-abd5-d8a595e6eb44
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e8312794-4dbf-48ff-9964-ac17bfb4fc7d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d1db6712-dab4-445e-a720-3549cfb9ed71
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8c712422-460b-4883-aef2-5620b769c087
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 37c9aa8b-aeb7-48ee-85ba-474b692025cb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 02a84eba-2c7f-42d9-8458-03359b288142
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 56a6cf48-50bd-4987-980b-c625dde51cee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 235cdb41-2966-4b58-80d5-abcb68a3f670
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 77353678-0d3e-488b-96a0-c7f71626c6f7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5b28b027-e962-4da8-8a1a-b4609609ec55
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9f413035-f1c9-4afc-8e22-d682cf3bdd30
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message af8a90e9-6636-4582-b8e6-8388e28656f7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 267dfdd1-08b1-4b3d-81a6-a17204f10943
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f5210cd5-99ab-4c92-ae0f-5353d1268ec6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e674fef4-0f83-48b1-a3d2-9c2eaec2d098
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 23d66f56-d204-4af2-93bd-82571d8dca7b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d3730992-61d3-4118-a561-23bd3a723760
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cfc88c06-0493-43c5-8a97-376f3f207b7d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0d86434f-0c4b-4435-8bef-cee6e2bd9d00
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 905b828c-0b02-4654-abc8-bed30b853a80
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9ce53bf7-ac34-4d6b-8150-f26fed857aa6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 887d3494-189f-46e3-90d3-2c410a4acc1a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3fb4f817-d4c3-4a72-b09c-4b783b33f80a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5a83d539-6c8a-401f-bfce-2502041d5935
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cfff58a6-443c-4c0d-b6fd-57159b9affe9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0e8dba03-906e-4b29-a092-4481db7c7c46
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 686492e3-c07e-4aba-aa24-fd629e062754
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ee39ec3e-4505-42bd-bf34-a5b6e378d7df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e733cd4d-1168-4ff6-bba6-583f5fcc9d07
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e62cc8ff-43f6-46d9-bf21-998e8b413084
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1bd1c916-37a1-487e-9613-d66d14ad0e68
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1baa0d82-e770-4bca-82fe-a9273e4bf29e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message acc23ab3-37b6-4414-9e58-954cb6fe5f56
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6a2f5021-49b5-4f63-9168-ef744b19f91f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bad197ed-7990-4dc0-ade1-25d14d7dd531
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c9384848-3433-406f-abb5-06683e8005b6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1f7f3383-d128-4ec2-9906-0b0cc860f823
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fa18775d-9c87-489f-b77f-aae43b1a5c5a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 17b74dcf-e80e-4742-8f52-df2658595bf0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2c434f2d-921f-483e-901e-f38bb23421a8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8168ef9b-3820-4c9c-a92f-832ccc65b568
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0a4a927a-bd87-48ae-ae04-12b21c86169a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1c5c9ffe-4b80-4509-8dbb-ac84a4ba478a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ab00a589-0640-4e1a-9a82-a1a8525c3dd4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0cd01424-c7a7-4a3f-99d1-f85032d87adc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 17ac7c19-902c-4cdc-9d2b-89322af32876
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dedce40e-c197-44b0-b2fa-f700bca9cf54
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 03b5e954-73c0-494a-9e67-aef3686d93c4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 480eb225-e589-4e6b-8d50-3c369818235d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4bf2a353-9af1-458a-b2f2-aa72e818772f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f2eaf52e-1daa-41b3-b0d6-304e54b839f7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a978db15-0c79-4606-aa53-976d160933d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9c4058c6-93d4-4964-9563-e23d01fe00ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fe5211c2-76c9-4e2f-8f2a-75d7c52d161a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 24f810bf-56d8-4e9a-90fc-b03413beaf0f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6ff9b9fc-96a4-4ab8-a438-763e5e8769c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 11e625ea-f76c-4dc3-b38c-68f51afffcfb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a338988b-1425-47ae-96f0-57b620abb2ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b3f9ef96-aa98-4291-8676-e2491ba08d92
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f86d0a53-b741-4133-91f0-16f87ae57317
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fa8840a2-a2ca-4485-a1a2-95bd16f4dc2b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 09df45d0-34c6-4e66-a73d-651923b0975e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ed87d580-066a-4fb9-b072-a1896771aa49
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 35c64a5b-15d1-4fb9-b673-50d5d47db215
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 422bf205-1d1c-4cb4-bfd6-19cb533f57df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8aab25f4-d638-4606-9b58-d53e39ccf7ea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f4fc5a90-a34b-4bf4-a1fe-f6486f001442
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 084586bb-b0ec-4bc9-a121-dbb0f1148257
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f3f803a6-d6e3-432a-949d-54078f031922
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 92fe6687-dd93-4b73-8b4a-e9e18471eff8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 41898b63-193b-4d02-b405-4abedcb4306b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 38e6fdcd-5b74-4682-afe9-9ad3a70296a3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d92458e8-eca2-410c-8f21-72d6cbd7ddb6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 82d7d141-ea2b-423f-8c82-942af55e6191
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a0105b74-fdb5-4035-9431-660458d558b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 57877e9a-fda8-44ba-9f4f-f3dd8a855149
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 08c011d7-0e64-4ec8-a48c-19ca5cac165a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dcf28e96-248b-4b85-8926-b8cc2fbdcbbd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d1207599-6cc3-4d8f-8097-8dcd34acdb10
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bbe0eed8-0345-460a-aa36-6f458dd5cb06
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 54255c7e-904e-424c-9f0e-b7d0ea40cf44
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3dc58271-18f6-433d-9ae7-f3f765c7d1f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6a443bfb-1f63-4151-bd8f-404efcf5bc53
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 215eab63-dffe-4a82-bb8e-720c124205c5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 09ea251c-ec0a-4f41-85f5-563c60970ee1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1686ab39-71cf-46a8-8ddc-d4f496343719
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 384e3a6a-05c9-4640-bbcf-26ea8321a40e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 76d41c02-63d1-4ea6-95ec-a2baaa3fd678
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e20dfc28-fe88-4820-9ef9-3bd57d49f162
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message baac5877-21ad-437d-9809-3120ae745639
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8dcf08e6-7272-4150-b324-6fd9e7a1ac39
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b6608626-af66-4e0f-9c81-4934820b6d65
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c8b7f7c2-58bb-47c0-b787-94048eedd2f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 65601c88-2ba1-413e-8f4e-cbf4e26038cb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b2e4179b-a9ad-4b43-b189-5cbd6c0643b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eaab79c2-3e1f-45ad-b3fe-fe8d9aeb77a0
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8687 {grpc_status:14, grpc_message:"Socket closed"}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_57
Server: localhost:8687
Algorithm: FEDAVG
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_57
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_57/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_57/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_57/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_57/test_labels.txt

📊 Raw data loaded:
   Train: X=(1626, 24), y=(1626,)
   Test:  X=(407, 24), y=(407,)

⚠️  Limiting training data: 1626 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  398 samples, 5 features
✅ Client client_57 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

============================================================
🔄 Round 5 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0872 (↓), lr=0.001000
   ✓ Epoch   2/100: train=0.0837, val=0.0855 (↓), lr=0.001000
   ✓ Epoch   3/100: train=0.0836, val=0.0848 (↓), lr=0.001000
   ✓ Epoch   4/100: train=0.0835, val=0.0842 (↓), lr=0.001000
   • Epoch   5/100: train=0.0831, val=0.0843, patience=1/15, lr=0.001000
   📉 Epoch 10: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0790, val=0.0858, patience=7/15, lr=0.000500
   📉 Epoch 18: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 5 Summary - Client client_57
   Epochs: 19/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=0.0176
   Val:   Loss=0.0842, RMSE=0.2902, R²=-0.0066
============================================================


📊 Round 5 Test Metrics:
   Loss: 0.0828, RMSE: 0.2877, MAE: 0.2499, R²: -0.0098

📊 Round 5 Test Metrics:
   Loss: 0.0828, RMSE: 0.2877, MAE: 0.2500, R²: -0.0099

============================================================
🔄 Round 7 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0873, val=0.0773 (↓), lr=0.000250
   • Epoch   2/100: train=0.0866, val=0.0770, patience=1/15, lr=0.000250
   • Epoch   3/100: train=0.0863, val=0.0769, patience=2/15, lr=0.000250
   ✓ Epoch   4/100: train=0.0860, val=0.0768 (↓), lr=0.000250
   • Epoch   5/100: train=0.0858, val=0.0767, patience=1/15, lr=0.000250
   • Epoch  11/100: train=0.0851, val=0.0762, patience=1/15, lr=0.000250
   • Epoch  21/100: train=0.0840, val=0.0757, patience=2/15, lr=0.000250
   • Epoch  31/100: train=0.0830, val=0.0753, patience=12/15, lr=0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0758)

============================================================
📊 Round 7 Summary - Client client_57
   Epochs: 34/100 (early stopped)
   LR: 0.000250 → 0.000250 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2894, R²=0.0196
   Val:   Loss=0.0758, RMSE=0.2752, R²=-0.0019
============================================================


============================================================
🔄 Round 8 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0800 (↓), lr=0.000250
   • Epoch   2/100: train=0.0856, val=0.0805, patience=1/15, lr=0.000250
   📉 Epoch 3: LR reduced 0.000250 → 0.000125
   • Epoch   3/100: train=0.0851, val=0.0807, patience=2/15, lr=0.000125
   • Epoch   4/100: train=0.0846, val=0.0810, patience=3/15, lr=0.000125
   • Epoch   5/100: train=0.0845, val=0.0811, patience=4/15, lr=0.000125
   📉 Epoch 11: LR reduced 0.000125 → 0.000063
   • Epoch  11/100: train=0.0839, val=0.0817, patience=10/15, lr=0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 8 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000250 → 0.000063 (2 reductions)
   Train: Loss=0.0858, RMSE=0.2929, R²=-0.0153
   Val:   Loss=0.0800, RMSE=0.2829, R²=-0.0001
============================================================


📊 Round 8 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2503, R²: -0.0134

============================================================
🔄 Round 9 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0857 (↓), lr=0.000063
   • Epoch   2/100: train=0.0847, val=0.0856, patience=1/15, lr=0.000063
   📉 Epoch 3: LR reduced 0.000063 → 0.000031
   • Epoch   3/100: train=0.0846, val=0.0855, patience=2/15, lr=0.000031
   • Epoch   4/100: train=0.0844, val=0.0854, patience=3/15, lr=0.000031
   • Epoch   5/100: train=0.0843, val=0.0853, patience=4/15, lr=0.000031
   📉 Epoch 11: LR reduced 0.000031 → 0.000016
   • Epoch  11/100: train=0.0840, val=0.0851, patience=2/15, lr=0.000016
   📉 Epoch 19: LR reduced 0.000016 → 0.000008
   • Epoch  21/100: train=0.0837, val=0.0851, patience=12/15, lr=0.000008

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 9 Summary - Client client_57
   Epochs: 24/100 (early stopped)
   LR: 0.000063 → 0.000008 (3 reductions)
   Train: Loss=0.0841, RMSE=0.2901, R²=-0.0103
   Val:   Loss=0.0852, RMSE=0.2919, R²=-0.0034
============================================================


📊 Round 9 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2504, R²: -0.0149

============================================================
🔄 Round 10 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000008
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0888 (↓), lr=0.000008
   • Epoch   2/100: train=0.0847, val=0.0889, patience=1/15, lr=0.000008
   📉 Epoch 3: LR reduced 0.000008 → 0.000004
   • Epoch   3/100: train=0.0846, val=0.0889, patience=2/15, lr=0.000004
   • Epoch   4/100: train=0.0846, val=0.0889, patience=3/15, lr=0.000004
   • Epoch   5/100: train=0.0846, val=0.0890, patience=4/15, lr=0.000004
   📉 Epoch 11: LR reduced 0.000004 → 0.000002
   • Epoch  11/100: train=0.0844, val=0.0890, patience=10/15, lr=0.000002

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0888)

============================================================
📊 Round 10 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000008 → 0.000002 (2 reductions)
   Train: Loss=0.0845, RMSE=0.2906, R²=-0.0231
   Val:   Loss=0.0888, RMSE=0.2980, R²=-0.0195
============================================================


============================================================
🔄 Round 11 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000002
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0882 (↓), lr=0.000002
   • Epoch   2/100: train=0.0846, val=0.0882, patience=1/15, lr=0.000002
   📉 Epoch 3: LR reduced 0.000002 → 0.000001
   • Epoch   3/100: train=0.0846, val=0.0882, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0882, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0882, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0883, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0882)

============================================================
📊 Round 11 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000002 → 0.000001 (1 reductions)
   Train: Loss=0.0847, RMSE=0.2911, R²=-0.0212
   Val:   Loss=0.0882, RMSE=0.2970, R²=-0.0468
============================================================


📊 Round 11 Test Metrics:
   Loss: 0.0832, RMSE: 0.2884, MAE: 0.2504, R²: -0.0145

============================================================
🔄 Round 12 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0883 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0883, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0883, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0882, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0882, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0882, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0883)

============================================================
📊 Round 12 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=-0.0149
   Val:   Loss=0.0883, RMSE=0.2971, R²=-0.0435
============================================================


============================================================
🔄 Round 14 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 14 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2936, R²=-0.0311
   Val:   Loss=0.0832, RMSE=0.2884, R²=-0.0025
============================================================


📊 Round 14 Test Metrics:
   Loss: 0.0834, RMSE: 0.2888, MAE: 0.2507, R²: -0.0174

============================================================
🔄 Round 16 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0954 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0954, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0954, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0954, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0954, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0953, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0954)

============================================================
📊 Round 16 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=-0.0227
   Val:   Loss=0.0954, RMSE=0.3088, R²=-0.0477
============================================================


📊 Round 16 Test Metrics:
   Loss: 0.0835, RMSE: 0.2890, MAE: 0.2507, R²: -0.0188

============================================================
🔄 Round 22 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0879 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0879, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0879, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0879, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0879, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0878, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0879)

============================================================
📊 Round 22 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2929, R²=-0.0311
   Val:   Loss=0.0879, RMSE=0.2964, R²=-0.0307
============================================================


📊 Round 22 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2508, R²: -0.0204

============================================================
🔄 Round 24 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0888 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0888, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0888, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0888, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0888, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0887, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0888)

============================================================
📊 Round 24 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2925, R²=-0.0302
   Val:   Loss=0.0888, RMSE=0.2980, R²=-0.0402
============================================================


============================================================
🔄 Round 25 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0915 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0915, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0915, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0915, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0915, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0915, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0915)

============================================================
📊 Round 25 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=-0.0317
   Val:   Loss=0.0915, RMSE=0.3024, R²=-0.0440
============================================================


📊 Round 25 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2508, R²: -0.0204

📊 Round 25 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2508, R²: -0.0204

📊 Round 25 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2508, R²: -0.0204

============================================================
🔄 Round 28 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0882 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0881, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0881, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0881, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0881, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0881, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0882)

============================================================
📊 Round 28 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2928, R²=-0.0408
   Val:   Loss=0.0882, RMSE=0.2969, R²=0.0036
============================================================


📊 Round 28 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2508, R²: -0.0204

============================================================
🔄 Round 33 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0876, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0876, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0876, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0876, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0876, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0876, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 33 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0877, RMSE=0.2962, R²=-0.0348
   Val:   Loss=0.0802, RMSE=0.2831, R²=-0.0149
============================================================


📊 Round 33 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2508, R²: -0.0204

============================================================
🔄 Round 37 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0870 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0870, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0870, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0870, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0870, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0870, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 37 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2933, R²=-0.0264
   Val:   Loss=0.0870, RMSE=0.2950, R²=-0.0810
============================================================


============================================================
🔄 Round 38 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 38 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2942, R²=-0.0390
   Val:   Loss=0.0848, RMSE=0.2912, R²=-0.0050
============================================================


============================================================
🔄 Round 39 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0927 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0927, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0927, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0927, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0927, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0927, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0927)

============================================================
📊 Round 39 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2908, R²=-0.0251
   Val:   Loss=0.0927, RMSE=0.3044, R²=-0.0572
============================================================


📊 Round 39 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2507, R²: -0.0204

============================================================
🔄 Round 44 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0945 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0945, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0945, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0945, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0945, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0946, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0945)

============================================================
📊 Round 44 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2901, R²=-0.0327
   Val:   Loss=0.0945, RMSE=0.3074, R²=-0.0436
============================================================


📊 Round 44 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2507, R²: -0.0204

============================================================
🔄 Round 45 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0872, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0871, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0871, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0871, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0871, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0870, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 45 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0872, RMSE=0.2952, R²=-0.0357
   Val:   Loss=0.0824, RMSE=0.2871, R²=-0.0189
============================================================


============================================================
🔄 Round 48 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0886 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0886, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0886, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0886, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0885, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0885, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0886)

============================================================
📊 Round 48 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2926, R²=-0.0292
   Val:   Loss=0.0886, RMSE=0.2976, R²=-0.0393
============================================================


============================================================
🔄 Round 50 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0874, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0874, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0874, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0874, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0874, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0873, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 50 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0875, RMSE=0.2958, R²=-0.0348
   Val:   Loss=0.0810, RMSE=0.2847, R²=-0.0163
============================================================


📊 Round 50 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2507, R²: -0.0204

📊 Round 50 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2507, R²: -0.0204

============================================================
🔄 Round 56 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0916 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0916, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0916, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0916, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0916, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0916, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0916)

============================================================
📊 Round 56 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2913, R²=-0.0261
   Val:   Loss=0.0916, RMSE=0.3027, R²=-0.0513
============================================================


📊 Round 56 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2508, R²: -0.0204

============================================================
🔄 Round 58 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0875 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0875, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0875, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0875, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0875, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0875, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0875)

============================================================
📊 Round 58 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2930, R²=-0.0324
   Val:   Loss=0.0875, RMSE=0.2959, R²=-0.0284
============================================================


📊 Round 58 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2508, R²: -0.0204

============================================================
🔄 Round 59 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0878, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0878, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0878, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0878, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0878, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0877, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 59 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0876, RMSE=0.2960, R²=-0.0385
   Val:   Loss=0.0806, RMSE=0.2839, R²=-0.0016
============================================================


📊 Round 59 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2508, R²: -0.0204

============================================================
🔄 Round 60 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0885, val=0.0767 (↓), lr=0.000001
   • Epoch   2/100: train=0.0885, val=0.0767, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0884, val=0.0767, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0884, val=0.0767, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0884, val=0.0768, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0883, val=0.0768, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0767)

============================================================
📊 Round 60 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0886, RMSE=0.2976, R²=-0.0343
   Val:   Loss=0.0767, RMSE=0.2770, R²=-0.0245
============================================================


============================================================
🔄 Round 61 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0893 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0893, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0893, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0893, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0893, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0893, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0893)

============================================================
📊 Round 61 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2923, R²=-0.0349
   Val:   Loss=0.0893, RMSE=0.2989, R²=-0.0265
============================================================


📊 Round 61 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2507, R²: -0.0204

============================================================
🔄 Round 66 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0946 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0946, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0946, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0946, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0946, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0945, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0946)

============================================================
📊 Round 66 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=-0.0320
   Val:   Loss=0.0946, RMSE=0.3075, R²=-0.0276
============================================================


📊 Round 66 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2507, R²: -0.0204

============================================================
🔄 Round 69 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0902 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0902, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0903, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0903, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0903, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0903, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0902)

============================================================
📊 Round 69 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2919, R²=-0.0400
   Val:   Loss=0.0902, RMSE=0.3004, R²=-0.0062
============================================================


============================================================
🔄 Round 70 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0913 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0913, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0913, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0913, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0913, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0913, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0913)

============================================================
📊 Round 70 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2915, R²=-0.0368
   Val:   Loss=0.0913, RMSE=0.3022, R²=-0.0110
============================================================


============================================================
🔄 Round 71 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0908 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0908, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0908, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0908, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0908, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0908, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0908)

============================================================
📊 Round 71 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2917, R²=-0.0357
   Val:   Loss=0.0908, RMSE=0.3013, R²=-0.0169
============================================================


============================================================
🔄 Round 72 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0920 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0920, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0920, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0920, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0920, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0921, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0920)

============================================================
📊 Round 72 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2911, R²=-0.0386
   Val:   Loss=0.0920, RMSE=0.3033, R²=-0.0076
============================================================


📊 Round 72 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2507, R²: -0.0204

📊 Round 72 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2507, R²: -0.0204

📊 Round 72 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2507, R²: -0.0204

============================================================
🔄 Round 75 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0867 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0867, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0867, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0867, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0868, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 75 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2934, R²=-0.0355
   Val:   Loss=0.0867, RMSE=0.2945, R²=-0.0163
============================================================


============================================================
🔄 Round 77 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0879 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0879, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0879, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0879, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0879, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0880, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0879)

============================================================
📊 Round 77 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2929, R²=-0.0293
   Val:   Loss=0.0879, RMSE=0.2965, R²=-0.0508
============================================================


📊 Round 77 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2507, R²: -0.0204

📊 Round 77 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2507, R²: -0.0204

📊 Round 77 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2507, R²: -0.0204

============================================================
🔄 Round 83 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0863 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 83 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2936, R²=-0.0291
   Val:   Loss=0.0863, RMSE=0.2938, R²=-0.0397
============================================================


📊 Round 83 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2507, R²: -0.0204

============================================================
🔄 Round 84 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 84 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2937, R²=-0.0355
   Val:   Loss=0.0860, RMSE=0.2933, R²=-0.0142
============================================================


📊 Round 84 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2507, R²: -0.0204

============================================================
🔄 Round 85 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 85 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2938, R²=-0.0272
   Val:   Loss=0.0858, RMSE=0.2930, R²=-0.0486
============================================================


📊 Round 85 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2507, R²: -0.0204

============================================================
🔄 Round 86 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0980 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0980, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0980, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0980, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0980, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0980, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0980)

============================================================
📊 Round 86 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=-0.0343
   Val:   Loss=0.0980, RMSE=0.3130, R²=-0.0411
============================================================


📊 Round 86 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2507, R²: -0.0204

============================================================
🔄 Round 88 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0875, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0875, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0875, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0875, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0875, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0874, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 88 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0876, RMSE=0.2959, R²=-0.0275
   Val:   Loss=0.0808, RMSE=0.2842, R²=-0.0483
============================================================


📊 Round 88 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2507, R²: -0.0204

============================================================
🔄 Round 89 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0867 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0867, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0867, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0867, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0866, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 89 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2934, R²=-0.0265
   Val:   Loss=0.0867, RMSE=0.2944, R²=-0.0507
============================================================


============================================================
🔄 Round 91 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0873, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0873, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0873, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0872, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0872, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0872, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 91 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0873, RMSE=0.2955, R²=-0.0391
   Val:   Loss=0.0818, RMSE=0.2860, R²=-0.0078
============================================================


📊 Round 91 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2507, R²: -0.0204

============================================================
🔄 Round 94 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0875 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0875, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0875, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0875, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0875, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0874, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0875)

============================================================
📊 Round 94 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2931, R²=-0.0291
   Val:   Loss=0.0875, RMSE=0.2958, R²=-0.0468
============================================================


📊 Round 94 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2507, R²: -0.0204

📊 Round 94 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2507, R²: -0.0204

============================================================
🔄 Round 96 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0892 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0892, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0892, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0892, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0892, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0892, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0892)

============================================================
📊 Round 96 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2924, R²=-0.0218
   Val:   Loss=0.0892, RMSE=0.2986, R²=-0.0735
============================================================


📊 Round 96 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2507, R²: -0.0204

============================================================
🔄 Round 99 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0916 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0916, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0916, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0916, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0916, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0916, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0916)

============================================================
📊 Round 99 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2913, R²=-0.0349
   Val:   Loss=0.0916, RMSE=0.3026, R²=-0.0184
============================================================


📊 Round 99 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2507, R²: -0.0204

📊 Round 99 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2507, R²: -0.0204

============================================================
🔄 Round 104 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0886 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0886, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0885, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0885, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0885, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0885, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0886)

============================================================
📊 Round 104 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2926, R²=-0.0265
   Val:   Loss=0.0886, RMSE=0.2976, R²=-0.0501
============================================================


============================================================
🔄 Round 105 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0989 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0989, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0989, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0989, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0989, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0989, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0989)

============================================================
📊 Round 105 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2882, R²=-0.0277
   Val:   Loss=0.0989, RMSE=0.3146, R²=-0.0453
============================================================


📊 Round 105 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2507, R²: -0.0204

============================================================
🔄 Round 107 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 107 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2937, R²=-0.0321
   Val:   Loss=0.0860, RMSE=0.2933, R²=-0.0296
============================================================


📊 Round 107 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2507, R²: -0.0204

📊 Round 107 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2507, R²: -0.0204

============================================================
🔄 Round 113 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 113 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2939, R²=-0.0375
   Val:   Loss=0.0857, RMSE=0.2927, R²=-0.0069
============================================================


============================================================
🔄 Round 114 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0871, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0871, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0871, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0871, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0871, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0870, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 114 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0872, RMSE=0.2953, R²=-0.0331
   Val:   Loss=0.0823, RMSE=0.2869, R²=-0.0242
============================================================


============================================================
🔄 Round 115 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0871, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0870, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0870, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0870, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0870, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0870, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 115 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0871, RMSE=0.2951, R²=-0.0280
   Val:   Loss=0.0827, RMSE=0.2875, R²=-0.0451
============================================================


📊 Round 115 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2507, R²: -0.0204

============================================================
🔄 Round 118 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0932 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0932, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0932, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0932, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0932, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0932, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0932)

============================================================
📊 Round 118 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=-0.0364
   Val:   Loss=0.0932, RMSE=0.3053, R²=-0.0137
============================================================


============================================================
🔄 Round 119 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 119 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2943, R²=-0.0264
   Val:   Loss=0.0847, RMSE=0.2911, R²=-0.0521
============================================================


📊 Round 119 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2507, R²: -0.0204

📊 Round 119 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2507, R²: -0.0204

============================================================
🔄 Round 121 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0930 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0930, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0929, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0929, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0929, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0929, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0930)

============================================================
📊 Round 121 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2908, R²=-0.0268
   Val:   Loss=0.0930, RMSE=0.3049, R²=-0.0538
============================================================


============================================================
🔄 Round 122 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0988 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0987, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0987, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0987, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0987, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0987, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0988)

============================================================
📊 Round 122 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=-0.0184
   Val:   Loss=0.0988, RMSE=0.3143, R²=-0.0816
============================================================


📊 Round 122 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2507, R²: -0.0204

============================================================
🔄 Round 123 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0939 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0939, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0939, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0939, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0939, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0939, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0939)

============================================================
📊 Round 123 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=-0.0238
   Val:   Loss=0.0939, RMSE=0.3065, R²=-0.0640
============================================================


============================================================
🔄 Round 124 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0876, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0876, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0876, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0876, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0875, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0875, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 124 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0875, RMSE=0.2958, R²=-0.0460
   Val:   Loss=0.0811, RMSE=0.2848, R²=0.0281
============================================================


============================================================
🔄 Round 125 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0930 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0930, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0930, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0930, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0930, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0930, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0930)

============================================================
📊 Round 125 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=-0.0254
   Val:   Loss=0.0930, RMSE=0.3049, R²=-0.0554
============================================================


📊 Round 125 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2507, R²: -0.0204

============================================================
🔄 Round 131 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0875, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0875, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0875, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0875, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0875, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0874, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 131 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0874, RMSE=0.2957, R²=-0.0352
   Val:   Loss=0.0814, RMSE=0.2853, R²=-0.0153
============================================================


============================================================
🔄 Round 132 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 132 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2946, R²=-0.0419
   Val:   Loss=0.0839, RMSE=0.2896, R²=0.0009
============================================================


📊 Round 132 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2507, R²: -0.0204

============================================================
🔄 Round 133 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0866, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 133 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0869, RMSE=0.2948, R²=-0.0209
   Val:   Loss=0.0835, RMSE=0.2890, R²=-0.0779
============================================================


============================================================
🔄 Round 134 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0874 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0874, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0873, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0873, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0873, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0872, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0874)

============================================================
📊 Round 134 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2931, R²=-0.0163
   Val:   Loss=0.0874, RMSE=0.2956, R²=-0.0978
============================================================


============================================================
🔄 Round 135 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0870, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0870, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0870, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0869, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0869, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0869, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 135 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0870, RMSE=0.2950, R²=-0.0262
   Val:   Loss=0.0830, RMSE=0.2880, R²=-0.0562
============================================================


============================================================
🔄 Round 138 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0928 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0927, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0927, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0927, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0927, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0927, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0928)

============================================================
📊 Round 138 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2908, R²=-0.0234
   Val:   Loss=0.0928, RMSE=0.3046, R²=-0.0657
============================================================


============================================================
🔄 Round 139 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0915 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0915, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0915, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0915, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0915, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0915, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0915)

============================================================
📊 Round 139 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2913, R²=-0.0305
   Val:   Loss=0.0915, RMSE=0.3026, R²=-0.0348
============================================================


📊 Round 139 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2507, R²: -0.0204

📊 Round 139 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2507, R²: -0.0204

============================================================
🔄 Round 142 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0894 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0894, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0894, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0894, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0894, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0894, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0894)

============================================================
📊 Round 142 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2923, R²=-0.0349
   Val:   Loss=0.0894, RMSE=0.2989, R²=-0.0255
============================================================


📊 Round 142 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2507, R²: -0.0204

============================================================
🔄 Round 146 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0868, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0868, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0868, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0868, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0867, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 146 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2947, R²=-0.0283
   Val:   Loss=0.0837, RMSE=0.2893, R²=-0.0437
============================================================


📊 Round 146 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2507, R²: -0.0204

============================================================
🔄 Round 147 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0983 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0983, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0983, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0983, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0983, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0982, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0983)

============================================================
📊 Round 147 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=-0.0258
   Val:   Loss=0.0983, RMSE=0.3136, R²=-0.0499
============================================================


📊 Round 147 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2507, R²: -0.0204

============================================================
🔄 Round 149 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0895 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0895, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0895, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0895, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0894, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0894, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0895)

============================================================
📊 Round 149 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2922, R²=-0.0302
   Val:   Loss=0.0895, RMSE=0.2991, R²=-0.0435
============================================================


📊 Round 149 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2507, R²: -0.0204

============================================================
🔄 Round 152 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 152 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2937, R²=-0.0328
   Val:   Loss=0.0861, RMSE=0.2935, R²=-0.0296
============================================================


============================================================
🔄 Round 154 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0883 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0883, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0883, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0883, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0883, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0883, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0883)

============================================================
📊 Round 154 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2927, R²=-0.0300
   Val:   Loss=0.0883, RMSE=0.2972, R²=-0.0462
============================================================


============================================================
🔄 Round 155 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0890 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0890, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0890, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0890, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0890, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0889, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0890)

============================================================
📊 Round 155 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2924, R²=-0.0240
   Val:   Loss=0.0890, RMSE=0.2984, R²=-0.0610
============================================================


============================================================
🔄 Round 156 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 156 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2938, R²=-0.0356
   Val:   Loss=0.0858, RMSE=0.2929, R²=-0.0291
============================================================


📊 Round 156 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2507, R²: -0.0205

============================================================
🔄 Round 157 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0883 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0883, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0883, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0883, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0882, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0882, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0883)

============================================================
📊 Round 157 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2928, R²=-0.0303
   Val:   Loss=0.0883, RMSE=0.2971, R²=-0.0414
============================================================


📊 Round 157 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2507, R²: -0.0205

============================================================
🔄 Round 161 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0909 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0909, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0909, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0909, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0909, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0910, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0909)

============================================================
📊 Round 161 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2916, R²=-0.0352
   Val:   Loss=0.0909, RMSE=0.3015, R²=-0.0343
============================================================


============================================================
🔄 Round 162 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0876, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0876, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0876, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0876, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0876, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0875, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 162 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0876, RMSE=0.2960, R²=-0.0306
   Val:   Loss=0.0806, RMSE=0.2838, R²=-0.0361
============================================================


📊 Round 162 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2507, R²: -0.0205

============================================================
🔄 Round 164 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0868, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0868, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0868, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0868, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0867, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 164 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2947, R²=-0.0297
   Val:   Loss=0.0838, RMSE=0.2894, R²=-0.0504
============================================================


📊 Round 164 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2507, R²: -0.0205

============================================================
🔄 Round 166 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0882, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0882, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0882, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0882, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0882, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0881, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 166 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0879, RMSE=0.2965, R²=-0.0265
   Val:   Loss=0.0793, RMSE=0.2817, R²=-0.0529
============================================================


📊 Round 166 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2507, R²: -0.0205

📊 Round 166 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2507, R²: -0.0205

============================================================
🔄 Round 169 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0921 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0921, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0921, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0921, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0921, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0921, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0921)

============================================================
📊 Round 169 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2911, R²=-0.0313
   Val:   Loss=0.0921, RMSE=0.3035, R²=-0.0330
============================================================


============================================================
🔄 Round 170 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0877, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0877, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0877, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0877, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0877, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0876, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 170 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0878, RMSE=0.2963, R²=-0.0437
   Val:   Loss=0.0799, RMSE=0.2827, R²=0.0144
============================================================


============================================================
🔄 Round 171 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0870, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0870, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0870, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0870, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0870, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0870, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 171 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0870, RMSE=0.2950, R²=-0.0285
   Val:   Loss=0.0829, RMSE=0.2880, R²=-0.0422
============================================================


📊 Round 171 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2507, R²: -0.0205

============================================================
🔄 Round 175 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0882, val=0.0772 (↓), lr=0.000001
   • Epoch   2/100: train=0.0882, val=0.0772, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0882, val=0.0772, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0882, val=0.0772, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0882, val=0.0771, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0881, val=0.0771, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 175 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0885, RMSE=0.2974, R²=-0.0340
   Val:   Loss=0.0772, RMSE=0.2778, R²=-0.0183
============================================================


📊 Round 175 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2507, R²: -0.0205

============================================================
🔄 Round 177 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0927 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0927, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0927, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0927, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0927, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0927, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0927)

============================================================
📊 Round 177 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=-0.0416
   Val:   Loss=0.0927, RMSE=0.3044, R²=-0.0056
============================================================


============================================================
🔄 Round 178 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0879, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0879, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0879, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0879, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0879, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0878, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 178 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0881, RMSE=0.2968, R²=-0.0483
   Val:   Loss=0.0787, RMSE=0.2806, R²=0.0278
============================================================


📊 Round 178 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2507, R²: -0.0205

============================================================
🔄 Round 181 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0881, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0881, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0881, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0881, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0881, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0880, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 181 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0877, RMSE=0.2961, R²=-0.0300
   Val:   Loss=0.0804, RMSE=0.2835, R²=-0.0358
============================================================


📊 Round 181 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2507, R²: -0.0205

============================================================
🔄 Round 182 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0867 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0867, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0867, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0867, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0866, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 182 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2934, R²=-0.0340
   Val:   Loss=0.0867, RMSE=0.2944, R²=-0.0194
============================================================


============================================================
🔄 Round 183 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0869, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0869, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0869, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0869, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0869, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0868, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 183 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2946, R²=-0.0298
   Val:   Loss=0.0838, RMSE=0.2895, R²=-0.0366
============================================================


📊 Round 183 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2507, R²: -0.0205

============================================================
🔄 Round 184 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0880 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0880, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0880, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0880, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0880, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0879, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0880)

============================================================
📊 Round 184 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2929, R²=-0.0248
   Val:   Loss=0.0880, RMSE=0.2966, R²=-0.0568
============================================================


📊 Round 184 Test Metrics:
   Loss: 0.0837, RMSE: 0.2892, MAE: 0.2507, R²: -0.0206

📊 Round 184 Test Metrics:
   Loss: 0.0837, RMSE: 0.2892, MAE: 0.2507, R²: -0.0206

============================================================
🔄 Round 189 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0874, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0874, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0874, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0874, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0874, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0873, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 189 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0872, RMSE=0.2953, R²=-0.0333
   Val:   Loss=0.0821, RMSE=0.2866, R²=-0.0255
============================================================


📊 Round 189 Test Metrics:
   Loss: 0.0837, RMSE: 0.2892, MAE: 0.2507, R²: -0.0206

📊 Round 189 Test Metrics:
   Loss: 0.0837, RMSE: 0.2892, MAE: 0.2507, R²: -0.0206

============================================================
🔄 Round 193 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0882 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0882, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0882, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0882, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0881, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0881, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0882)

============================================================
📊 Round 193 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2928, R²=-0.0280
   Val:   Loss=0.0882, RMSE=0.2969, R²=-0.0431
============================================================


============================================================
🔄 Round 195 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0883, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0883, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0882, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0882, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0882, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0882, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 195 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0884, RMSE=0.2973, R²=-0.0293
   Val:   Loss=0.0775, RMSE=0.2784, R²=-0.0572
============================================================


📊 Round 195 Test Metrics:
   Loss: 0.0837, RMSE: 0.2892, MAE: 0.2507, R²: -0.0206

============================================================
🔄 Round 198 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0873 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0873, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0873, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0873, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0873, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0873, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0873)

============================================================
📊 Round 198 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2931, R²=-0.0319
   Val:   Loss=0.0873, RMSE=0.2955, R²=-0.0303
============================================================


📊 Round 198 Test Metrics:
   Loss: 0.0837, RMSE: 0.2892, MAE: 0.2507, R²: -0.0206

============================================================
🔄 Round 201 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0876, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0876, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0876, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0876, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0876, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0875, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 201 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0873, RMSE=0.2955, R²=-0.0341
   Val:   Loss=0.0817, RMSE=0.2859, R²=-0.0388
============================================================


============================================================
🔄 Round 203 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0929 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0929, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0929, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0929, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0929, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0929, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0929)

============================================================
📊 Round 203 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=-0.0374
   Val:   Loss=0.0929, RMSE=0.3048, R²=-0.0268
============================================================


📊 Round 203 Test Metrics:
   Loss: 0.0837, RMSE: 0.2892, MAE: 0.2507, R²: -0.0207

============================================================
🔄 Round 207 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0878, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0878, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0878, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0878, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0878, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0878, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 207 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0876, RMSE=0.2960, R²=-0.0275
   Val:   Loss=0.0806, RMSE=0.2838, R²=-0.0473
============================================================


📊 Round 207 Test Metrics:
   Loss: 0.0837, RMSE: 0.2892, MAE: 0.2507, R²: -0.0207

============================================================
🔄 Round 210 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0883, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0883, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0883, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0883, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0882, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0882, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 210 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0880, RMSE=0.2967, R²=-0.0327
   Val:   Loss=0.0788, RMSE=0.2808, R²=-0.0356
============================================================


📊 Round 210 Test Metrics:
   Loss: 0.0837, RMSE: 0.2892, MAE: 0.2507, R²: -0.0206

📊 Round 210 Test Metrics:
   Loss: 0.0837, RMSE: 0.2892, MAE: 0.2507, R²: -0.0207

📊 Round 210 Test Metrics:
   Loss: 0.0837, RMSE: 0.2892, MAE: 0.2507, R²: -0.0207

📊 Round 210 Test Metrics:
   Loss: 0.0837, RMSE: 0.2892, MAE: 0.2507, R²: -0.0207

============================================================
🔄 Round 217 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0890 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0890, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0890, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0890, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0890, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0890, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0890)

============================================================
📊 Round 217 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2924, R²=-0.0329
   Val:   Loss=0.0890, RMSE=0.2984, R²=-0.0257
============================================================


📊 Round 217 Test Metrics:
   Loss: 0.0837, RMSE: 0.2892, MAE: 0.2507, R²: -0.0207

📊 Round 217 Test Metrics:
   Loss: 0.0837, RMSE: 0.2892, MAE: 0.2507, R²: -0.0207

============================================================
🔄 Round 219 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0936 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0936, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0936, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0936, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0936, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0935, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0936)

============================================================
📊 Round 219 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2904, R²=-0.0256
   Val:   Loss=0.0936, RMSE=0.3060, R²=-0.0567
============================================================


📊 Round 219 Test Metrics:
   Loss: 0.0837, RMSE: 0.2892, MAE: 0.2507, R²: -0.0207

============================================================
🔄 Round 222 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0885, val=0.0766 (↓), lr=0.000001
   • Epoch   2/100: train=0.0885, val=0.0766, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0885, val=0.0766, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0885, val=0.0765, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0885, val=0.0765, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0884, val=0.0765, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0766)

============================================================
📊 Round 222 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0886, RMSE=0.2977, R²=-0.0290
   Val:   Loss=0.0766, RMSE=0.2767, R²=-0.0415
============================================================


📊 Round 222 Test Metrics:
   Loss: 0.0837, RMSE: 0.2892, MAE: 0.2507, R²: -0.0207

============================================================
🔄 Round 224 - Client client_57
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0959 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0959, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0959, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0959, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0959, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0958, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0959)

============================================================
📊 Round 224 Summary - Client client_57
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=-0.0296
   Val:   Loss=0.0959, RMSE=0.3096, R²=-0.0368
============================================================


❌ Client client_57 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8687 {grpc_status:14, grpc_message:"Socket closed"}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8687 {grpc_status:14, grpc_message:"Socket closed"}"
>
