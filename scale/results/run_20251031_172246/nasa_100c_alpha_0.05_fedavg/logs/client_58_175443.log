[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0a49d958-70a1-4366-805a-9c10913a3dda
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bf985134-d7ea-4952-8f2c-f4d419f480e8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b087989b-9324-450c-812e-1f4e31222b70
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5fdc80bb-f00c-4b32-9b12-b8ece8ba4b0a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b983f212-a699-4574-9fe9-868aa3993582
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cf17a771-f57a-48c3-ab35-a18688ff0abf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b387b9aa-8b5e-4ac7-90e2-f3af8c83885f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ff144ad2-b59b-4e31-af45-8d7d29b6985b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a2a12a1a-4195-478f-aebe-8fd44e0d3807
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a7030da0-82b7-48e2-a188-43bf2b77538a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8c78eed0-693d-49df-ae66-179ca025b4eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b97173fb-32ca-4457-bbb3-38d42f5be40e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dac20ccc-fbfb-4733-a8c3-6019b3b44f91
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 82a4c795-c173-49cb-ada7-a5d99fd7cf09
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4c7bff4b-06e0-47a9-9ede-6c2d4bbcc990
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1fb242ac-2699-41c2-b345-8db94d778a56
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8ba2e386-f08f-4de6-9c2f-6ebefc6f9b84
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c0475ecc-b683-4a50-bf8b-a4c139d58b00
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 86b5ffc4-675e-4e5f-ac0a-be1c08fe629f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fb02aaf0-453e-4ca9-b2e6-22f5664f2c98
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b68f74b2-c62f-4142-99f0-52ec0a739c2a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4fa8e4d1-ca14-47bb-b6c0-359200740443
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a78b32ab-b682-4ceb-8779-68bcea26572e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cb2abacf-b69a-47ce-bff4-24e765b12ca8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message de1dac6c-92d7-4559-b858-c9ab1a0e7760
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 48911fe9-51f9-4a7d-b8a9-67c52a46e549
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message acdf309c-4699-492b-8a7c-988d1931b393
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0e009cdb-6897-4848-bc2f-06c896ad5cd8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5630b0b9-b79a-4004-8d18-d69afe5dfa27
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 370bbcea-5644-4069-b99e-1ea429ac808c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2f34adcc-9404-46e7-92b8-1ee40b566763
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2a553a18-5e4c-4144-bc5e-e222e67a848b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 614148ae-a653-48a0-b395-dc6dcb196bf3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b34b62c0-7766-46d3-8982-51680dc3b08a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c4fe638a-38be-463e-903f-2f2016142dec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 79721912-3bd8-4362-924c-9750fa9ef402
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7a07de94-d216-4457-8316-4ad20dc9bd83
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f95ee56d-1feb-4f0d-98a1-d652f74f8622
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 99f783ea-1e4b-4a4e-9001-5f0ae3b1f911
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6b0f07e1-a23f-4b64-b132-dabde3ea0148
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d1ec8a40-79a0-45d3-a0a9-b0393fe97bd3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 33ee8a7d-db7a-4949-89b0-46f6704260f7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 73c55881-959f-4b45-b3a6-e790c995593a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9eb7a897-03cd-4ec0-b7bb-7c4c8da78419
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e45796f3-4fe8-461c-be96-70dc7fb3158b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6bd49335-4ad5-49d6-9e9c-9bfefa3be50e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a7a57c45-bcdf-462f-9bdb-9a8435e541d8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 62b19cea-ac88-42c9-b937-642d825ec39c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3399ae1d-33d6-48ca-8606-1f81c76321fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b57d08a0-7b51-491f-a241-c055e4a13ec3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eb9f1bf4-9496-4ae6-916e-ea729ef983c6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8100928f-c9ee-4859-a403-44ffa1662ce0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 68d25f1f-7308-49ec-8606-8277c787c5ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f0232ae6-7104-4e07-ab19-94a2954801fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b77839f8-9407-42ed-97f2-06118be90d59
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8e40a90d-5b6d-4e99-9ac7-6278b49ea83d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 83064728-bcf2-454d-9dc7-ef29193e2505
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 469b9734-0cf4-4fd4-bbc9-335858266aa7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b4c9c21e-5694-4f0d-9a5b-0f4dcee2b0d8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5a13e40d-120d-41ac-840b-26e707178ccc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 588d2b89-ecc4-4526-96c9-6b4daa991d05
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 84e20a34-a3f4-428c-9ad0-f3ecd34a5692
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5cd4605b-f6bf-4c9f-89ff-6308a97d2a2d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 62f3f80a-37b7-4661-bd21-09650c8f2c49
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 23959b2b-a786-4340-8fd3-76df9d378fbd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6351d6e6-125a-4687-9e5f-e177b6d98ad8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f281602a-0164-41cc-b946-92b5c1f25a6c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 277b0444-5f53-4772-9b9d-65ceef5adee0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 26db9338-46db-4a80-9624-d35616ae2b2b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a370fb8c-009f-4ac1-b745-b4f710a17954
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d329f4a2-4c8a-47e1-b44d-94bfc151c705
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a7741583-dd9a-4e09-bd76-8df21fb32adc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e470f648-4caf-485d-8313-696bd02db71a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 876fbbfd-5bb3-4647-883c-8edd25c0cb6b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 66f5c1f0-5ed5-44d4-ab00-777dd8f1e0a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b148d850-0468-4a9b-9a03-6d8c2d1fe7a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d9697a26-c945-4dfc-880b-4591423410e1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2b48d35d-bd68-44a9-8e5b-5a354d3a2649
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1aed5270-a740-4a56-a594-a3d60a8e4f4d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cf93b112-1a87-4960-813c-a2061bb57848
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0352e21c-fd4d-4284-9d50-f54935eead55
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5e7a6548-79ca-46b7-98ad-30956c7a339d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b3afb3c1-02da-4eac-adb4-415175acb7c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message deea135c-570e-4efa-9351-15cdc2e094ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 778f2cfe-3b6a-4956-833e-24aad59e775d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 09b84e40-834e-413e-b894-116e706fa146
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c405b674-df8c-418b-b95c-f2dfb7b2413a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 96b253b2-cb71-4278-a66b-68c7b6f01444
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9e505150-8df6-492e-97a2-2d9c03469f06
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c89ee8f5-abc5-413c-9c8d-a703f36129a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9032bea3-ed66-41b6-b379-2d43c3f0e958
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d9790af6-afb0-436f-9241-3185013578fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message af4c37d2-52ec-42e8-a942-b30177423bd8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bd5472d6-3e37-4aac-a059-2a13a8f9d5fb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fac94f8b-bf14-402b-9a7f-0527dd7cb220
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 98c810fd-6207-4ba8-ae7c-c184e040de15
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3194dd12-4b93-47dc-bd05-bf5cad99b453
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cfe4cbcf-6de2-494b-a033-623554462b48
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 55268138-3ff3-4d3c-a36a-5a19ad92dfbc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 82801c74-4e70-49b3-95e0-85a246ec0c72
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 19deae77-c697-46ef-813c-3ba2d700b404
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ae8cb24a-26c2-4d4c-a619-cfc18f3c2433
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f09052ae-2edb-46aa-b7f5-415268a586f2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 35c7db84-a80d-4163-b9b3-3610136a0b83
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ceb2f9aa-dcbf-4ec9-bd58-8d646b08b17f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fc980373-46f7-487b-b0ed-aa689d991335
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7a440bd6-7115-4857-a848-c922e1da5073
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2c6c7513-10ab-46b3-88e0-77c7e52cb94b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 77b2ac98-889c-4af5-b753-afad2a4d6621
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 48da91df-0ff4-4f38-8c97-3ed3ed28a6f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 504fb631-6d33-498c-a3f8-2853a5ad5d70
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3247b7a0-f9f4-4b76-872d-b5724763de4c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 97a3ba5b-b810-4be7-a915-cdbc3bc0685b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 711eeaa4-68ea-43f6-8e99-0d9ead1bc3fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0505bad0-c0b2-422c-ad70-91ad747a67aa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bad47c28-273f-488b-9c2e-3f1fcd24a060
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1f5ab08e-1519-4f9b-a130-bebff28d1085
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ea8c10a3-0e6f-4e70-99c2-d6f282493dc8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 386702e1-2514-4edb-982c-0b0fd636b86f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 751e3470-bb00-4a14-87a8-37a7dd942487
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ebf048e4-ffa7-45a4-b5da-1622b6bf4624
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1f4934e5-d158-4ccc-bcfb-fb6eee4e9ac2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 40e87596-902d-4ba1-be79-52e4c9f77a5a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eb07e43f-7ce9-42df-84a6-6215ab6d0a41
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6e616a47-7a2c-4673-8e70-f0c9f45caa47
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 62248729-362c-40b6-b19e-d98b32a7a422
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3599f2b9-3313-4536-ae34-067c17b1b450
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5b761d38-d379-454a-891e-24f99bf47548
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ecfc5271-7335-4c3b-b3a1-f40a0a5b1a47
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eb04862d-7f01-4191-b071-4dd7ed5370a3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c35a6a56-9a0d-4ba0-ab0e-6283fe45806e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ac7454a7-b83f-4173-ac10-a7d69797c86e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b356660f-4315-40af-bb51-5ed1789d8808
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 98b6adcd-4112-44de-aded-81702e2ecb75
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 53386835-2d88-40d7-96ca-48c21e53991a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 163294cd-87b1-40a7-8343-85043c488b3b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5a898c32-3733-4e4d-aedb-2da40142c433
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5e4a4e27-68ec-497f-af77-514837901c1a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b0b91204-c46e-48da-8ad5-378b2e076104
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 829b61dd-36fe-435b-a449-f43a5741b630
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 726cca27-bf1c-492f-a877-0c677ae710fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fa2f0907-010e-409d-86e7-2b241e9eedf3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2ceac0f0-4dbc-4ada-80f3-0e2f0ea5ded3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ca9835cf-f386-462d-ae04-486d96bc47c4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a89f8424-6a92-463e-9e49-8bff7c8e80cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 96aac4fc-fafd-45fb-904e-77867b24cc79
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b60ba5f8-7755-4c4c-9be5-b6bf05ba26a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a4ac2249-fa53-4ee5-abd4-027b779ae1ce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bb878e6e-609f-4f23-b0f3-e9df7025d3a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7ce64528-f991-441c-8812-a3aaf6eb2abf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5b87ed75-d6b4-4a7d-aa75-4b1f741f2b93
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3a8d2ab2-5672-471f-8826-c9f62350d19a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message baa34691-f24b-4249-9e0e-d816f8afa1b0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a75bbdfa-5b7d-4fd0-b39c-432e325eb1a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e918516a-f302-4f03-9000-79c34b3ce38f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2d26e9d7-8497-402e-9e0c-0fefabcb5eb6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1a068428-98b3-4a69-b662-22f670078165
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dade260e-ed7b-4bc7-8256-7130cf5c724a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6094e4e9-dc6b-462c-b320-443a763646ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 83a25c46-806c-4f58-89cc-b8d39b455779
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aec3ad9e-c16f-4caa-88c7-35145f8e970e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 48258958-9465-4930-a279-1081734e9acf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a6e4ae4e-5a46-42eb-93d4-a87107d88a16
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4dba2a21-e729-4cf7-8904-0732ea324a27
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2c3f257c-1ac4-4cf7-a112-888f80bc373a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4acd68ac-6349-4984-9c25-26e70f709343
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 39db0f5c-0e50-40e3-b205-5312485f78d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6bcd00d8-fc65-4055-bf13-043e7ddbaf40
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1d4c9758-1146-479d-ba04-7af70a9da7c4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 86ec2fcc-ae82-46fd-986a-c387434c854b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 92151730-7f15-4d23-8f4f-bf43dbeace36
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5a7b0424-914f-4b2d-87e7-4d1de32d7251
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0272c95f-854d-4715-8433-f4a76a6eaddc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 68292064-d54b-49e5-adb2-40e05be9a1af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a2286aa3-c26a-4b6e-8f04-256ae9fde4b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message efacf5bd-91b4-41b6-a12c-a2f8d2bed317
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8d856042-f673-42e3-8491-e43cf8d5e13c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e879c206-dacf-452b-a662-eed414f42119
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9e557b6f-1b36-4575-ba90-4dba6b1a76bd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 48a15f0f-a557-4c5b-a30c-462c72a161db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 583a488f-8ac1-4fd4-ba13-27b307ab2ee5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 92ad69a1-b33b-4518-92a9-d41fb9307922
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d682681d-406a-4782-ba5c-72feed0797f9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 05b4d471-0ed3-42bf-b61a-ee3c404b87ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2b10f924-8bef-458a-a00c-c728e5d4a65f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5fb5a79c-d53f-47f1-9400-79bc2c702fe1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5e03b097-0bf4-4243-ab20-e19ec827c5b5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c97a4ce7-a1b4-45e6-b45e-ef0cbd52dc8f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4a37afc7-70f8-422a-a069-f7452882e3be
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8687 {grpc_message:"Socket closed", grpc_status:14}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_58
Server: localhost:8687
Algorithm: FEDAVG
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_58
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_58/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_58/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_58/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_58/test_labels.txt

📊 Raw data loaded:
   Train: X=(864, 24), y=(864,)
   Test:  X=(217, 24), y=(217,)

⚠️  Limiting training data: 864 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  208 samples, 5 features
✅ Client client_58 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

============================================================
🔄 Round 5 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0839 (↓), lr=0.001000
   • Epoch   2/100: train=0.0837, val=0.0866, patience=1/15, lr=0.001000
   • Epoch   3/100: train=0.0829, val=0.0865, patience=2/15, lr=0.001000
   • Epoch   4/100: train=0.0816, val=0.0847, patience=3/15, lr=0.001000
   • Epoch   5/100: train=0.0808, val=0.0848, patience=4/15, lr=0.001000
   📉 Epoch 7: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0766, val=0.0847, patience=3/15, lr=0.000500
   📉 Epoch 15: LR reduced 0.000500 → 0.000250
   • Epoch  21/100: train=0.0726, val=0.0879, patience=13/15, lr=0.000250
   📉 Epoch 23: LR reduced 0.000250 → 0.000125

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 5 Summary - Client client_58
   Epochs: 23/100 (early stopped)
   LR: 0.001000 → 0.000125 (3 reductions)
   Train: Loss=0.0771, RMSE=0.2778, R²=0.0547
   Val:   Loss=0.0834, RMSE=0.2887, R²=0.0197
============================================================


============================================================
🔄 Round 6 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000125
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0842 (↓), lr=0.000125
   • Epoch   2/100: train=0.0810, val=0.0843, patience=1/15, lr=0.000125
   • Epoch   3/100: train=0.0809, val=0.0842, patience=2/15, lr=0.000125
   • Epoch   4/100: train=0.0807, val=0.0842, patience=3/15, lr=0.000125
   • Epoch   5/100: train=0.0805, val=0.0842, patience=4/15, lr=0.000125
   📉 Epoch 8: LR reduced 0.000125 → 0.000063
   • Epoch  11/100: train=0.0799, val=0.0841, patience=10/15, lr=0.000063
   📉 Epoch 16: LR reduced 0.000063 → 0.000031

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 6 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000125 → 0.000031 (2 reductions)
   Train: Loss=0.0811, RMSE=0.2847, R²=0.0084
   Val:   Loss=0.0842, RMSE=0.2902, R²=0.0050
============================================================


📊 Round 6 Test Metrics:
   Loss: 0.0791, RMSE: 0.2813, MAE: 0.2468, R²: 0.0478

============================================================
🔄 Round 7 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000031
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0825 (↓), lr=0.000031
   • Epoch   2/100: train=0.0812, val=0.0827, patience=1/15, lr=0.000031
   • Epoch   3/100: train=0.0811, val=0.0828, patience=2/15, lr=0.000031
   • Epoch   4/100: train=0.0810, val=0.0829, patience=3/15, lr=0.000031
   • Epoch   5/100: train=0.0809, val=0.0830, patience=4/15, lr=0.000031
   📉 Epoch 8: LR reduced 0.000031 → 0.000016
   • Epoch  11/100: train=0.0806, val=0.0833, patience=10/15, lr=0.000016
   📉 Epoch 16: LR reduced 0.000016 → 0.000008

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 7 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000031 → 0.000008 (2 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=0.0143
   Val:   Loss=0.0825, RMSE=0.2872, R²=-0.0274
============================================================


============================================================
🔄 Round 8 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000008
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0815 (↓), lr=0.000008
   • Epoch   2/100: train=0.0818, val=0.0816, patience=1/15, lr=0.000008
   • Epoch   3/100: train=0.0818, val=0.0816, patience=2/15, lr=0.000008
   • Epoch   4/100: train=0.0817, val=0.0816, patience=3/15, lr=0.000008
   • Epoch   5/100: train=0.0817, val=0.0817, patience=4/15, lr=0.000008
   📉 Epoch 8: LR reduced 0.000008 → 0.000004
   • Epoch  11/100: train=0.0816, val=0.0817, patience=10/15, lr=0.000004
   📉 Epoch 16: LR reduced 0.000004 → 0.000002

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 8 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000008 → 0.000002 (2 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=0.0088
   Val:   Loss=0.0815, RMSE=0.2855, R²=0.0035
============================================================


📊 Round 8 Test Metrics:
   Loss: 0.0790, RMSE: 0.2811, MAE: 0.2460, R²: 0.0493

============================================================
🔄 Round 9 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000002
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0906 (↓), lr=0.000002
   • Epoch   2/100: train=0.0794, val=0.0906, patience=1/15, lr=0.000002
   • Epoch   3/100: train=0.0794, val=0.0906, patience=2/15, lr=0.000002
   • Epoch   4/100: train=0.0794, val=0.0906, patience=3/15, lr=0.000002
   • Epoch   5/100: train=0.0794, val=0.0906, patience=4/15, lr=0.000002
   📉 Epoch 8: LR reduced 0.000002 → 0.000001
   • Epoch  11/100: train=0.0793, val=0.0906, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0906)

============================================================
📊 Round 9 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000002 → 0.000001 (1 reductions)
   Train: Loss=0.0793, RMSE=0.2817, R²=0.0085
   Val:   Loss=0.0906, RMSE=0.3010, R²=0.0117
============================================================


📊 Round 9 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2452, R²: 0.0537

============================================================
🔄 Round 10 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 10 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=0.0185
   Val:   Loss=0.0793, RMSE=0.2816, R²=-0.0277
============================================================


============================================================
🔄 Round 11 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 11 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2866, R²=0.0151
   Val:   Loss=0.0786, RMSE=0.2803, R²=-0.0043
============================================================


📊 Round 11 Test Metrics:
   Loss: 0.0786, RMSE: 0.2804, MAE: 0.2453, R²: 0.0538

📊 Round 11 Test Metrics:
   Loss: 0.0787, RMSE: 0.2806, MAE: 0.2454, R²: 0.0528

============================================================
🔄 Round 13 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 13 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=0.0110
   Val:   Loss=0.0797, RMSE=0.2824, R²=0.0084
============================================================


📊 Round 13 Test Metrics:
   Loss: 0.0785, RMSE: 0.2802, MAE: 0.2450, R²: 0.0552

============================================================
🔄 Round 14 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 14 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=0.0063
   Val:   Loss=0.0800, RMSE=0.2829, R²=0.0277
============================================================


📊 Round 14 Test Metrics:
   Loss: 0.0783, RMSE: 0.2798, MAE: 0.2445, R²: 0.0581

============================================================
🔄 Round 18 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 18 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2847, R²=0.0085
   Val:   Loss=0.0827, RMSE=0.2876, R²=0.0223
============================================================


📊 Round 18 Test Metrics:
   Loss: 0.0782, RMSE: 0.2797, MAE: 0.2443, R²: 0.0589

📊 Round 18 Test Metrics:
   Loss: 0.0782, RMSE: 0.2797, MAE: 0.2442, R²: 0.0588

============================================================
🔄 Round 20 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0884 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0884, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0884, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0884, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0884, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0885, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0884)

============================================================
📊 Round 20 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2822, R²=0.0101
   Val:   Loss=0.0884, RMSE=0.2973, R²=-0.0178
============================================================


📊 Round 20 Test Metrics:
   Loss: 0.0780, RMSE: 0.2793, MAE: 0.2439, R²: 0.0609

============================================================
🔄 Round 21 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 21 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=0.0002
   Val:   Loss=0.0861, RMSE=0.2934, R²=0.0466
============================================================


📊 Round 21 Test Metrics:
   Loss: 0.0781, RMSE: 0.2794, MAE: 0.2439, R²: 0.0607

============================================================
🔄 Round 24 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0697 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0697, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0697, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0697, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0697, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0698, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0697)

============================================================
📊 Round 24 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2906, R²=0.0019
   Val:   Loss=0.0697, RMSE=0.2641, R²=0.0268
============================================================


📊 Round 24 Test Metrics:
   Loss: 0.0781, RMSE: 0.2794, MAE: 0.2439, R²: 0.0606

============================================================
🔄 Round 25 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 25 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2838, R²=0.0188
   Val:   Loss=0.0855, RMSE=0.2923, R²=-0.0238
============================================================


============================================================
🔄 Round 27 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 27 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=0.0045
   Val:   Loss=0.0796, RMSE=0.2820, R²=0.0301
============================================================


============================================================
🔄 Round 28 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0674 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0674, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0674, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0674, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0674, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0674, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0674)

============================================================
📊 Round 28 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2916, R²=0.0048
   Val:   Loss=0.0674, RMSE=0.2596, R²=0.0238
============================================================


📊 Round 28 Test Metrics:
   Loss: 0.0781, RMSE: 0.2794, MAE: 0.2439, R²: 0.0606

📊 Round 28 Test Metrics:
   Loss: 0.0781, RMSE: 0.2794, MAE: 0.2439, R²: 0.0606

============================================================
🔄 Round 31 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0763 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0763, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0763, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0763, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0763, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0763, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0763)

============================================================
📊 Round 31 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=0.0168
   Val:   Loss=0.0763, RMSE=0.2762, R²=-0.0195
============================================================


============================================================
🔄 Round 32 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0732 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0732, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0732, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0732, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0732, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0732, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0732)

============================================================
📊 Round 32 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=0.0002
   Val:   Loss=0.0732, RMSE=0.2706, R²=0.0536
============================================================


📊 Round 32 Test Metrics:
   Loss: 0.0781, RMSE: 0.2794, MAE: 0.2439, R²: 0.0606

============================================================
🔄 Round 34 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0668 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0668, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0668, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0667, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0667, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0667, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0668)

============================================================
📊 Round 34 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2919, R²=0.0074
   Val:   Loss=0.0668, RMSE=0.2584, R²=0.0241
============================================================


📊 Round 34 Test Metrics:
   Loss: 0.0781, RMSE: 0.2794, MAE: 0.2439, R²: 0.0606

============================================================
🔄 Round 35 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0875 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0875, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0875, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0875, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0875, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0876, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0875)

============================================================
📊 Round 35 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2829, R²=0.0165
   Val:   Loss=0.0875, RMSE=0.2958, R²=-0.0451
============================================================


📊 Round 35 Test Metrics:
   Loss: 0.0781, RMSE: 0.2794, MAE: 0.2439, R²: 0.0605

============================================================
🔄 Round 38 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 38 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2845, R²=0.0171
   Val:   Loss=0.0839, RMSE=0.2896, R²=-0.0652
============================================================


📊 Round 38 Test Metrics:
   Loss: 0.0781, RMSE: 0.2794, MAE: 0.2439, R²: 0.0605

============================================================
🔄 Round 40 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0901 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0902, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0902, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0902, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0902, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0902, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0901)

============================================================
📊 Round 40 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2817, R²=0.0163
   Val:   Loss=0.0901, RMSE=0.3002, R²=-0.0352
============================================================


============================================================
🔄 Round 41 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 41 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=0.0089
   Val:   Loss=0.0840, RMSE=0.2898, R²=0.0137
============================================================


📊 Round 41 Test Metrics:
   Loss: 0.0781, RMSE: 0.2794, MAE: 0.2439, R²: 0.0605

📊 Round 41 Test Metrics:
   Loss: 0.0781, RMSE: 0.2794, MAE: 0.2439, R²: 0.0605

============================================================
🔄 Round 44 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 44 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=0.0113
   Val:   Loss=0.0852, RMSE=0.2919, R²=0.0037
============================================================


============================================================
🔄 Round 45 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 45 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=0.0048
   Val:   Loss=0.0800, RMSE=0.2828, R²=0.0281
============================================================


📊 Round 45 Test Metrics:
   Loss: 0.0781, RMSE: 0.2794, MAE: 0.2439, R²: 0.0605

📊 Round 45 Test Metrics:
   Loss: 0.0781, RMSE: 0.2794, MAE: 0.2439, R²: 0.0604

============================================================
🔄 Round 48 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 48 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=0.0072
   Val:   Loss=0.0795, RMSE=0.2819, R²=0.0184
============================================================


============================================================
🔄 Round 49 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0894 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0894, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0894, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0894, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0894, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0894, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0894)

============================================================
📊 Round 49 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2821, R²=0.0132
   Val:   Loss=0.0894, RMSE=0.2990, R²=-0.0080
============================================================


📊 Round 49 Test Metrics:
   Loss: 0.0781, RMSE: 0.2794, MAE: 0.2439, R²: 0.0604

============================================================
🔄 Round 51 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 51 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=0.0235
   Val:   Loss=0.0827, RMSE=0.2876, R²=-0.0473
============================================================


📊 Round 51 Test Metrics:
   Loss: 0.0781, RMSE: 0.2794, MAE: 0.2439, R²: 0.0603

📊 Round 51 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2439, R²: 0.0603

📊 Round 51 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2439, R²: 0.0602

📊 Round 51 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2439, R²: 0.0602

============================================================
🔄 Round 60 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0758 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0758, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0758, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0758, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0758, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0759, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0758)

============================================================
📊 Round 60 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2880, R²=0.0052
   Val:   Loss=0.0758, RMSE=0.2753, R²=0.0144
============================================================


📊 Round 60 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2439, R²: 0.0602

📊 Round 60 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2439, R²: 0.0602

============================================================
🔄 Round 64 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0901 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0901, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0901, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0901, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0901, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0901, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0901)

============================================================
📊 Round 64 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2818, R²=0.0064
   Val:   Loss=0.0901, RMSE=0.3002, R²=0.0175
============================================================


============================================================
🔄 Round 65 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 65 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=0.0075
   Val:   Loss=0.0813, RMSE=0.2851, R²=-0.0185
============================================================


📊 Round 65 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2439, R²: 0.0602

============================================================
🔄 Round 66 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0759 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0759, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0759, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0759, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0759, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0759, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0759)

============================================================
📊 Round 66 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2880, R²=0.0059
   Val:   Loss=0.0759, RMSE=0.2756, R²=0.0018
============================================================


============================================================
🔄 Round 67 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0778, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0778, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0778, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0778, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0778, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 67 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=0.0058
   Val:   Loss=0.0778, RMSE=0.2789, R²=0.0217
============================================================


📊 Round 67 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2439, R²: 0.0602

============================================================
🔄 Round 71 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 71 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=0.0084
   Val:   Loss=0.0826, RMSE=0.2874, R²=0.0136
============================================================


📊 Round 71 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2439, R²: 0.0601

============================================================
🔄 Round 73 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 73 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=0.0055
   Val:   Loss=0.0833, RMSE=0.2886, R²=-0.0034
============================================================


📊 Round 73 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2439, R²: 0.0601

============================================================
🔄 Round 74 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 74 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2863, R²=0.0036
   Val:   Loss=0.0800, RMSE=0.2828, R²=0.0343
============================================================


📊 Round 74 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2439, R²: 0.0601

============================================================
🔄 Round 75 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 75 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=0.0001
   Val:   Loss=0.0827, RMSE=0.2876, R²=0.0383
============================================================


📊 Round 75 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2439, R²: 0.0601

============================================================
🔄 Round 77 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0928 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0928, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0928, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0928, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0928, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0927, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0928)

============================================================
📊 Round 77 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2806, R²=0.0115
   Val:   Loss=0.0928, RMSE=0.3046, R²=0.0023
============================================================


============================================================
🔄 Round 80 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0673 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0673, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0673, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0673, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0673, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0673, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0673)

============================================================
📊 Round 80 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2918, R²=0.0090
   Val:   Loss=0.0673, RMSE=0.2594, R²=-0.0017
============================================================


📊 Round 80 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2439, R²: 0.0600

============================================================
🔄 Round 81 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 81 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=0.0085
   Val:   Loss=0.0812, RMSE=0.2850, R²=0.0025
============================================================


============================================================
🔄 Round 82 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0881 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0881, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0881, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0881, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0881, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0881, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0881)

============================================================
📊 Round 82 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=0.0127
   Val:   Loss=0.0881, RMSE=0.2969, R²=-0.0017
============================================================


============================================================
🔄 Round 83 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0878 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0878, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0877, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0877, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0877, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0877, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0878)

============================================================
📊 Round 83 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2829, R²=0.0171
   Val:   Loss=0.0878, RMSE=0.2962, R²=-0.0238
============================================================


📊 Round 83 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2439, R²: 0.0600

📊 Round 83 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2439, R²: 0.0600

============================================================
🔄 Round 86 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0766 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0766, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0766, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0766, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0766, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0766, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0766)

============================================================
📊 Round 86 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=0.0060
   Val:   Loss=0.0766, RMSE=0.2768, R²=0.0208
============================================================


📊 Round 86 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2439, R²: 0.0600

============================================================
🔄 Round 87 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 87 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=0.0127
   Val:   Loss=0.0801, RMSE=0.2831, R²=-0.0037
============================================================


============================================================
🔄 Round 88 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0713 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0713, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0713, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0713, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0713, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0713, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0713)

============================================================
📊 Round 88 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=0.0067
   Val:   Loss=0.0713, RMSE=0.2671, R²=0.0223
============================================================


📊 Round 88 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2439, R²: 0.0599

============================================================
🔄 Round 92 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0749 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0750, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0749, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0750, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0750, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0750, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0749)

============================================================
📊 Round 92 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=0.0052
   Val:   Loss=0.0749, RMSE=0.2738, R²=0.0265
============================================================


📊 Round 92 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2439, R²: 0.0599

============================================================
🔄 Round 93 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 93 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=0.0051
   Val:   Loss=0.0783, RMSE=0.2799, R²=0.0271
============================================================


============================================================
🔄 Round 94 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 94 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2849, R²=0.0072
   Val:   Loss=0.0833, RMSE=0.2886, R²=0.0155
============================================================


📊 Round 94 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2439, R²: 0.0599

📊 Round 94 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2439, R²: 0.0598

📊 Round 94 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2439, R²: 0.0598

============================================================
🔄 Round 100 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0718 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0718, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0718, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0718, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0718, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0718, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0718)

============================================================
📊 Round 100 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=0.0093
   Val:   Loss=0.0718, RMSE=0.2680, R²=0.0006
============================================================


📊 Round 100 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2439, R²: 0.0598

============================================================
🔄 Round 101 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0708 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0708, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0708, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0708, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0708, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0707, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0708)

============================================================
📊 Round 101 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=0.0044
   Val:   Loss=0.0708, RMSE=0.2661, R²=0.0312
============================================================


📊 Round 101 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2439, R²: 0.0598

============================================================
🔄 Round 102 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 102 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=0.0086
   Val:   Loss=0.0849, RMSE=0.2914, R²=0.0116
============================================================


============================================================
🔄 Round 103 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 103 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=0.0090
   Val:   Loss=0.0787, RMSE=0.2805, R²=0.0112
============================================================


📊 Round 103 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2439, R²: 0.0598

============================================================
🔄 Round 104 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 104 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2856, R²=0.0084
   Val:   Loss=0.0817, RMSE=0.2859, R²=0.0114
============================================================


📊 Round 104 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2439, R²: 0.0598

============================================================
🔄 Round 106 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 106 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2852, R²=0.0138
   Val:   Loss=0.0826, RMSE=0.2875, R²=-0.0276
============================================================


📊 Round 106 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2439, R²: 0.0597

============================================================
🔄 Round 109 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0905 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0905, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0905, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0905, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0905, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0904, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0905)

============================================================
📊 Round 109 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2817, R²=0.0169
   Val:   Loss=0.0905, RMSE=0.3008, R²=-0.0199
============================================================


============================================================
🔄 Round 110 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 110 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=0.0084
   Val:   Loss=0.0801, RMSE=0.2829, R²=0.0100
============================================================


============================================================
🔄 Round 112 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0694 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0694, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0695, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0695, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0695, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0695, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0694)

============================================================
📊 Round 112 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=-0.0058
   Val:   Loss=0.0694, RMSE=0.2635, R²=0.0760
============================================================


============================================================
🔄 Round 117 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 117 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=0.0109
   Val:   Loss=0.0775, RMSE=0.2784, R²=0.0018
============================================================


📊 Round 117 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2439, R²: 0.0597

============================================================
🔄 Round 118 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 118 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2864, R²=0.0099
   Val:   Loss=0.0797, RMSE=0.2824, R²=0.0043
============================================================


📊 Round 118 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2439, R²: 0.0596

============================================================
🔄 Round 120 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0896 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0896, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0896, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0896, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0896, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0895, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0896)

============================================================
📊 Round 120 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2821, R²=0.0157
   Val:   Loss=0.0896, RMSE=0.2994, R²=-0.0145
============================================================


📊 Round 120 Test Metrics:
   Loss: 0.0781, RMSE: 0.2795, MAE: 0.2439, R²: 0.0596

============================================================
🔄 Round 124 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0754 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0754, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0754, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0754, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0754, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0754, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0754)

============================================================
📊 Round 124 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=0.0114
   Val:   Loss=0.0754, RMSE=0.2746, R²=-0.0045
============================================================


📊 Round 124 Test Metrics:
   Loss: 0.0781, RMSE: 0.2796, MAE: 0.2439, R²: 0.0596

============================================================
🔄 Round 126 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 126 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=0.0061
   Val:   Loss=0.0816, RMSE=0.2856, R²=0.0060
============================================================


📊 Round 126 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2439, R²: 0.0596

📊 Round 126 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2439, R²: 0.0595

============================================================
🔄 Round 129 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0886 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0885, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0885, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0885, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0885, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0885, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0886)

============================================================
📊 Round 129 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2826, R²=0.0147
   Val:   Loss=0.0886, RMSE=0.2976, R²=-0.0140
============================================================


📊 Round 129 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2439, R²: 0.0595

============================================================
🔄 Round 130 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0779 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0779, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0779, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0779, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0778, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0778, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0779)

============================================================
📊 Round 130 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2873, R²=0.0158
   Val:   Loss=0.0779, RMSE=0.2790, R²=-0.0262
============================================================


📊 Round 130 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2439, R²: 0.0595

📊 Round 130 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2439, R²: 0.0594

📊 Round 130 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2439, R²: 0.0594

📊 Round 130 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2439, R²: 0.0594

============================================================
🔄 Round 137 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 137 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=-0.0027
   Val:   Loss=0.0787, RMSE=0.2805, R²=0.0390
============================================================


============================================================
🔄 Round 138 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 138 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=0.0060
   Val:   Loss=0.0830, RMSE=0.2882, R²=0.0126
============================================================


============================================================
🔄 Round 140 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 140 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=0.0076
   Val:   Loss=0.0856, RMSE=0.2925, R²=0.0082
============================================================


============================================================
🔄 Round 141 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0741 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0741, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0741, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0741, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0741, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0740, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0741)

============================================================
📊 Round 141 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=0.0132
   Val:   Loss=0.0741, RMSE=0.2722, R²=-0.0126
============================================================


============================================================
🔄 Round 142 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 142 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=0.0131
   Val:   Loss=0.0788, RMSE=0.2808, R²=-0.0117
============================================================


📊 Round 142 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2439, R²: 0.0593

============================================================
🔄 Round 144 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 144 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=0.0060
   Val:   Loss=0.0829, RMSE=0.2880, R²=0.0205
============================================================


📊 Round 144 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2439, R²: 0.0593

============================================================
🔄 Round 148 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 148 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2861, R²=0.0145
   Val:   Loss=0.0807, RMSE=0.2840, R²=-0.0192
============================================================


============================================================
🔄 Round 149 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 149 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=0.0092
   Val:   Loss=0.0825, RMSE=0.2872, R²=0.0067
============================================================


============================================================
🔄 Round 150 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 150 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2866, R²=0.0085
   Val:   Loss=0.0795, RMSE=0.2820, R²=0.0106
============================================================


============================================================
🔄 Round 151 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 151 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=0.0019
   Val:   Loss=0.0786, RMSE=0.2804, R²=0.0363
============================================================


📊 Round 151 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2439, R²: 0.0592

============================================================
🔄 Round 157 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 157 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=0.0111
   Val:   Loss=0.0788, RMSE=0.2807, R²=-0.0005
============================================================


📊 Round 157 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2439, R²: 0.0591

📊 Round 157 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2439, R²: 0.0591

============================================================
🔄 Round 169 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0780 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0780, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0780, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0780, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0780, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 169 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2873, R²=0.0114
   Val:   Loss=0.0780, RMSE=0.2793, R²=-0.0143
============================================================


📊 Round 169 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2439, R²: 0.0590

📊 Round 169 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2439, R²: 0.0590

============================================================
🔄 Round 172 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 172 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=0.0122
   Val:   Loss=0.0798, RMSE=0.2824, R²=-0.0189
============================================================


============================================================
🔄 Round 174 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0747 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0747, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0747, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0747, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0747, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0746, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0747)

============================================================
📊 Round 174 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2887, R²=0.0095
   Val:   Loss=0.0747, RMSE=0.2733, R²=-0.0037
============================================================


📊 Round 174 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2439, R²: 0.0590

📊 Round 174 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2439, R²: 0.0589

📊 Round 174 Test Metrics:
   Loss: 0.0782, RMSE: 0.2796, MAE: 0.2439, R²: 0.0589

============================================================
🔄 Round 178 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0757 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0757, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0757, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0757, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0757, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0757, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0757)

============================================================
📊 Round 178 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=0.0137
   Val:   Loss=0.0757, RMSE=0.2752, R²=-0.0169
============================================================


============================================================
🔄 Round 179 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 179 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2859, R²=0.0088
   Val:   Loss=0.0812, RMSE=0.2849, R²=0.0077
============================================================


📊 Round 179 Test Metrics:
   Loss: 0.0782, RMSE: 0.2797, MAE: 0.2439, R²: 0.0589

============================================================
🔄 Round 181 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0732 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0732, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0732, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0732, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0732, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0732, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0732)

============================================================
📊 Round 181 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2894, R²=0.0151
   Val:   Loss=0.0732, RMSE=0.2706, R²=-0.0265
============================================================


📊 Round 181 Test Metrics:
   Loss: 0.0782, RMSE: 0.2797, MAE: 0.2439, R²: 0.0588

📊 Round 181 Test Metrics:
   Loss: 0.0782, RMSE: 0.2797, MAE: 0.2439, R²: 0.0588

📊 Round 181 Test Metrics:
   Loss: 0.0782, RMSE: 0.2797, MAE: 0.2439, R²: 0.0587

📊 Round 181 Test Metrics:
   Loss: 0.0782, RMSE: 0.2797, MAE: 0.2439, R²: 0.0587

============================================================
🔄 Round 190 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 190 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2840, R²=0.0015
   Val:   Loss=0.0855, RMSE=0.2924, R²=0.0038
============================================================


📊 Round 190 Test Metrics:
   Loss: 0.0782, RMSE: 0.2797, MAE: 0.2439, R²: 0.0587

============================================================
🔄 Round 191 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0769 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0769, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0769, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0769, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0769, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0769, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0769)

============================================================
📊 Round 191 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=-0.0015
   Val:   Loss=0.0769, RMSE=0.2774, R²=0.0494
============================================================


📊 Round 191 Test Metrics:
   Loss: 0.0782, RMSE: 0.2797, MAE: 0.2439, R²: 0.0587

============================================================
🔄 Round 193 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0865 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0864, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0864, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0865)

============================================================
📊 Round 193 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2836, R²=0.0127
   Val:   Loss=0.0865, RMSE=0.2940, R²=-0.0111
============================================================


📊 Round 193 Test Metrics:
   Loss: 0.0782, RMSE: 0.2797, MAE: 0.2439, R²: 0.0587

============================================================
🔄 Round 194 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 194 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2863, R²=0.0117
   Val:   Loss=0.0805, RMSE=0.2837, R²=-0.0057
============================================================


📊 Round 194 Test Metrics:
   Loss: 0.0782, RMSE: 0.2797, MAE: 0.2439, R²: 0.0587

============================================================
🔄 Round 195 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 195 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2861, R²=0.0022
   Val:   Loss=0.0807, RMSE=0.2842, R²=0.0315
============================================================


============================================================
🔄 Round 196 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0721 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0721, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0720, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0720, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0720, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0720, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0721)

============================================================
📊 Round 196 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2899, R²=0.0088
   Val:   Loss=0.0721, RMSE=0.2684, R²=0.0038
============================================================


============================================================
🔄 Round 198 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0765 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0765, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0765, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0765, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0765, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0765, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0765)

============================================================
📊 Round 198 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2880, R²=0.0134
   Val:   Loss=0.0765, RMSE=0.2765, R²=-0.0532
============================================================


============================================================
🔄 Round 199 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0911 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0911, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0911, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0911, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0911, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0911, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0911)

============================================================
📊 Round 199 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2816, R²=0.0027
   Val:   Loss=0.0911, RMSE=0.3018, R²=0.0222
============================================================


============================================================
🔄 Round 200 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0782, val=0.0948 (↓), lr=0.000001
   • Epoch   2/100: train=0.0782, val=0.0948, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0782, val=0.0948, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0782, val=0.0948, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0782, val=0.0948, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0781, val=0.0948, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0948)

============================================================
📊 Round 200 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2799, R²=0.0108
   Val:   Loss=0.0948, RMSE=0.3080, R²=-0.0002
============================================================


📊 Round 200 Test Metrics:
   Loss: 0.0782, RMSE: 0.2797, MAE: 0.2439, R²: 0.0586

============================================================
🔄 Round 204 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 204 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=0.0080
   Val:   Loss=0.0790, RMSE=0.2810, R²=0.0103
============================================================


📊 Round 204 Test Metrics:
   Loss: 0.0782, RMSE: 0.2797, MAE: 0.2439, R²: 0.0585

📊 Round 204 Test Metrics:
   Loss: 0.0782, RMSE: 0.2797, MAE: 0.2439, R²: 0.0585

📊 Round 204 Test Metrics:
   Loss: 0.0782, RMSE: 0.2797, MAE: 0.2439, R²: 0.0585

============================================================
🔄 Round 208 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 208 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2854, R²=0.0066
   Val:   Loss=0.0824, RMSE=0.2871, R²=-0.0226
============================================================


============================================================
🔄 Round 209 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 209 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=-0.0007
   Val:   Loss=0.0852, RMSE=0.2918, R²=0.0403
============================================================


📊 Round 209 Test Metrics:
   Loss: 0.0782, RMSE: 0.2797, MAE: 0.2439, R²: 0.0585

============================================================
🔄 Round 211 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0768 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0768, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0768, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0768, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0768, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0767, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0768)

============================================================
📊 Round 211 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=0.0110
   Val:   Loss=0.0768, RMSE=0.2771, R²=-0.0060
============================================================


============================================================
🔄 Round 212 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0779 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0779, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0779, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0779, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0779, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0779, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0779)

============================================================
📊 Round 212 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=0.0010
   Val:   Loss=0.0779, RMSE=0.2791, R²=0.0381
============================================================


============================================================
🔄 Round 213 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 213 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=0.0069
   Val:   Loss=0.0807, RMSE=0.2840, R²=0.0032
============================================================


📊 Round 213 Test Metrics:
   Loss: 0.0782, RMSE: 0.2797, MAE: 0.2439, R²: 0.0584

============================================================
🔄 Round 215 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0774, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0774, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0774, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0774, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 215 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=0.0039
   Val:   Loss=0.0775, RMSE=0.2783, R²=0.0266
============================================================


📊 Round 215 Test Metrics:
   Loss: 0.0782, RMSE: 0.2797, MAE: 0.2439, R²: 0.0584

============================================================
🔄 Round 220 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 220 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=0.0087
   Val:   Loss=0.0816, RMSE=0.2856, R²=0.0060
============================================================


============================================================
🔄 Round 221 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 221 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2863, R²=0.0061
   Val:   Loss=0.0804, RMSE=0.2836, R²=0.0136
============================================================


📊 Round 221 Test Metrics:
   Loss: 0.0782, RMSE: 0.2797, MAE: 0.2439, R²: 0.0584

📊 Round 221 Test Metrics:
   Loss: 0.0782, RMSE: 0.2797, MAE: 0.2439, R²: 0.0584

============================================================
🔄 Round 223 - Client client_58
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 223 Summary - Client client_58
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2840, R²=0.0189
   Val:   Loss=0.0857, RMSE=0.2928, R²=-0.0342
============================================================


📊 Round 223 Test Metrics:
   Loss: 0.0782, RMSE: 0.2797, MAE: 0.2440, R²: 0.0584

❌ Client client_58 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8687 {grpc_message:"Socket closed", grpc_status:14}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8687 {grpc_message:"Socket closed", grpc_status:14}"
>
