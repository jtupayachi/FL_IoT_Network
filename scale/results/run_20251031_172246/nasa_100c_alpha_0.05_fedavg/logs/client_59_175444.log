[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3f446041-91ce-44bf-abce-c6b4fd31e23f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 65f6ff86-2db8-46a9-b3c9-61f856dd9aa6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ab95014b-3a71-4780-8b35-e06f6d6d945e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c6afd23d-b955-4fa4-a0eb-c5460ec7e8c7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fe45ee33-e115-43e6-8d34-02159aaa46b8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fa2e0623-1a9f-45ba-8643-82d922d0f460
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a5a7a735-e4db-44b7-a161-1422834c4be4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message be952b2f-dab6-4bfa-8dc8-a91850a98b19
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 296d4a00-43b7-473a-a551-5c31aae6bf40
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0e030726-68c7-434c-a3a0-987dca51b566
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 24275cde-2501-4360-a41d-2f79e580cd60
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b95f06a5-ad8e-4882-bcc9-e855a2707714
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 50d54eb3-6269-47f6-a1cd-a710a31c5249
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 71aa67a4-b2d6-4776-9fb9-29d8a962ad6d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5db00133-3b6a-42eb-9bb4-b10b223d6ebf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dbce20a8-6a1b-4504-8b92-f51e79d87624
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f52635a0-1408-454c-bde8-36014745ac33
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 23d3ae96-abe3-4152-a60b-e1bbe241aba0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 83bb9796-d5bc-4172-8e68-f12ed7c78b45
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 10f07235-b061-4f53-b8a8-b48195326370
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 80e1edba-b054-4bfa-a8c3-b0710c10865a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dead5861-b8f3-4be2-8267-02e7e4ba0630
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 53a7aea7-e4ee-4b04-bb4f-a51bf3547794
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5f3c1b23-a9d8-437b-8ca0-99ddaa3e5d65
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eb213c97-6405-4d2b-a159-bf688fe06a3e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7c42edb6-662f-4e63-93a2-f725181d5c7b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c744d7c4-aa94-4ccb-bb98-b22b1354ad87
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3bbfd7ee-e93b-4940-84b9-4b76e84c96f6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cd73f2ae-8b70-4d97-a56a-2c5f99564514
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 04dcfbda-a7b2-4a89-bbcd-3a90e8d496bd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d66d4a59-c7dc-4d5e-8ef9-fbcd1dd85fc3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ba6d6a87-96c8-4198-a12a-e5a08e212976
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 97eb97c0-e167-4b5c-90d0-5e22d20b80f9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9d5bace5-649b-4e2d-b510-7d4e035abc97
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bb4f115d-2571-4291-b7fc-3f925e25d552
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5610e14d-7511-44b2-89ef-04a0301d15ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7a9a05fc-636b-4dcd-b686-2895a72a2dfe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0df7c1c5-c4b2-4f6d-b1be-45d2674f7604
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a63db2a1-39b6-4452-a52d-cc958b88039f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f89be99d-b8c2-46bc-96d5-d4ff19a75c8c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7dbbc71f-46cb-4001-b5b2-d6db1fdaae36
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 151fa413-5fee-49c8-854b-03372bb4433f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 639167fe-3ccf-4a0b-8318-5a208fbda8df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e75bacb8-9b39-40dc-a25a-a948e110e499
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4e8dc39f-85ff-46da-9221-bafafb9b38cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b58ef60a-830c-40db-9bd3-511d329ca3b1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a2a3ba21-0600-4c1d-8347-a4693e571f2e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 20f388cb-2f48-446e-beed-523df67597bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7871f02d-466b-497f-b8e3-b60dc0ba940c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0a791d84-cf8a-4612-9fc8-e0b9873ec278
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4ff3a479-be75-41cf-b617-524debd65b45
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1a013446-2b0f-424c-8083-263c9f79f442
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 922df68a-7d19-455c-b080-fde5c70e5e42
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1585dc6f-a028-4afe-a14f-2527ac246647
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c8f2e1df-6fcd-4dba-8a83-e235d2bb2317
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0f063870-4997-4e43-b9f1-dc8e981002af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f8b3de99-65a5-45ad-8239-20670c67b646
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 146f2f6a-5e2b-4406-8bb2-cf1301a7b702
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b425aba8-505c-473f-86f6-170c5d3fee32
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9df2cc33-53c1-4fc3-b58f-5273f8887813
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b8d1957a-a547-4603-8be4-3e4cc21d8275
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 496f0149-f259-455d-afda-8354440ffb35
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6ef8f8d0-4ce4-4f08-9caa-6aceca9cb452
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bd7efc7a-6f2c-498b-beb4-d51998f99d4c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message afb465e5-6b1d-44df-921b-8167b0d22fa1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5355fb25-bfdb-4331-a34b-e693cd9d46d9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b3218ab4-7f30-44f0-b65f-1dc0a0c5f79f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6762ddb3-8e7c-4492-b57e-22538705d3ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4015c2d7-5211-4c97-9e88-21ddc7b6d278
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ad0a0766-a8fd-4e00-bb06-e54176777371
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c104e379-29d9-454d-a3e8-b6b1dacd8da8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b01bb4be-03c1-439e-b1c6-e4450634ea86
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1e593487-2711-42da-88b5-8cd01b87d202
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b8a24075-5046-4b01-b1ed-1d29ff7a0d98
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c7164873-6390-4fa9-b8a4-a4995e1fe4fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e08c7b02-9c71-4536-8b1c-d513f1285377
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6e177ed4-572e-42f7-9c83-8f683ca2e34f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c7366a8d-e6a8-467e-8077-6ea4802d3603
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9518082f-e462-4fb3-8e98-e9b8772d49e5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e447dbc4-a5b2-4e15-a569-0cfd17e1a819
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e4afc114-89ac-474c-b3e9-6aa6d7928436
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4dff56b7-474b-4c06-96aa-53154454c35e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f61f8472-8f3a-4035-be0a-d36ad11b15ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d9da0674-fc0a-4dba-9dfa-31edb6c93734
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b81c85cc-2bbe-4794-b04f-4dce79a67d36
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 49e5b092-31af-46c5-ae30-a0fa6fdbea8c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7ee66600-0bff-4552-b1bc-c1cceafd2f4d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bcc22a09-5c07-4730-a22a-127db9b18d20
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e648df03-7cb0-4072-97d5-364831ab88a9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6355630d-62e9-4fd4-994e-9682e5205a92
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ad48904f-436b-4446-9168-56f1f117195d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ef87b0df-029b-49be-8eb8-0a388c3094ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d54aac08-5013-4f77-ab95-e9037e3bf154
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4eb3ade8-5f97-4340-be00-2d7468aaa8b0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2d9e5a47-350e-4afd-8627-d40c26ebd09c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4ca86a6d-a601-4458-8ad3-2f72f378b44d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2c4cdc7f-f35d-4e7f-8603-afe447545f7d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 08f51933-2488-4272-9d52-768c15bc1648
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 97b9c69e-483a-406f-b599-6356b0f2c81f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 19eaae1b-3c8b-43c6-89a7-55383d6da810
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f4e10c42-387c-4fa1-8649-35ad71933a55
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3b4c4e20-2e64-4174-a55a-bae484a90175
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c492d778-fd97-4d60-9744-98c9c6cee8dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8a75d5ec-8e24-4174-94ce-0e90920143c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c0bb8dd2-fbde-487a-bece-002a965bf03a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a230654d-bf77-437a-9061-7f508eda5f92
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0e356873-b8c1-43d3-bb68-50d813f7830a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7aa947ed-e1d6-40e7-bb63-9b61f17ee1de
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 95120cde-7fa8-4206-9c33-e51ee1be1d91
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d8e79113-21a4-4ac5-9b34-a786d3193cf4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ed013163-1987-4cad-bf98-467c2de76ea5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a014a7fd-846f-4497-a73d-4b17e1ef5ba0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 44cb6377-d75e-499b-afa2-45e7986307d8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 877231d8-d7ac-42f2-9d9d-a4284f41dec2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0b9fba71-6ff7-4d47-ab21-dca59ce3bd60
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 614f83d2-87ab-429d-a4bd-13e6eaa0a4eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 45cfb744-5e05-400b-a420-23c7b6f85cc4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f4bba98b-96ea-4898-adcd-f0460640d519
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 659641e3-9ac0-4f88-bdd6-95f4ecf38418
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e811a9ab-1c61-4447-bae0-1de72418625f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 85186772-45a8-41c7-9471-deea65d3320b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0ffe24f0-da5f-4814-8771-719f1417620a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2a273bfd-d7c3-4340-b960-9088c20895d5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1c2a6ccf-cbb8-42a1-83ac-6da8bc96f33c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c9ad66ba-a7b3-41ea-b3ea-b86d14a8ffd4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b2829d75-0d12-4875-8c48-b8208bf89c81
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c1926085-7d7d-4cab-9e30-7a0f802ad479
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aefcd0ff-a633-4353-90b6-d765a98ef570
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message baec0ba8-8dd8-40a1-be41-a108206f99d9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 14bffc63-274f-4191-b950-f6597834a1ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a35d59a4-695b-4bbd-9b0b-a96f3f2f5e91
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 23ed713a-67b4-4264-bf01-c2399d919a25
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 71e3d636-ad88-4b3e-9dc8-278391f590ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a5f07104-5bef-4ded-a346-8f43d090cfb4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8614d873-e65a-47e7-a752-0c5cbf222c00
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 84e0e2a0-f6a1-4c9d-b3fd-a2094e35a729
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a724459d-0edb-42ab-b3e1-dd0dc9b3cbb0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7b24391d-015d-43c0-bb0e-c3d20b257f82
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 30e6fb16-5219-45a7-8c9e-a5e7bd05572a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 92df70a5-f5ac-45f6-88d5-ee4a722bf13d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ed042a64-b3b0-4b38-8461-34a417a40f9e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d4ad1e51-7bc4-49c8-ae5b-5b9203921f7d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 28601d17-7ef5-4b58-915c-e334130d7805
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 180f068d-6240-4581-990e-d363ab12c02b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eaad820e-8476-4e47-bdd4-fe7c7fd61d92
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f7303b8c-801e-489e-86ad-90072e99c0a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0481ce2a-5a55-43fd-9141-721c69fca345
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0d359b01-b482-48c6-b28c-fede47a30732
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 527b4650-d248-4ac3-ad79-39a11320259d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 23491b5f-e605-4b0b-ae57-de7fc9ba0355
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1f99e6ea-27c4-46f1-9e64-91288e0bc272
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 977e22e8-4143-4003-9d7e-fdb38520d50d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 527bbaaf-6e24-456f-b800-07baa06e7312
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 223e2186-ae02-416a-9341-8394810e28e6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 601012f2-bfb2-4b81-b543-53cb8fbae83f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fce390a3-d7ad-4053-87fa-918af3ef9dd9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5bad75e9-3bef-445e-861c-c8d7cd710338
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f6839bbd-1082-4fe8-acf8-ba15d702be76
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ab530885-bb91-44e0-ad5c-8f14eb38005b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d41b1533-acd1-42cd-94d3-1175011a1f54
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8687 {grpc_status:14, grpc_message:"Socket closed"}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_59
Server: localhost:8687
Algorithm: FEDAVG
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_59
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_59/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_59/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_59/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_59/test_labels.txt

📊 Raw data loaded:
   Train: X=(1113, 24), y=(1113,)
   Test:  X=(279, 24), y=(279,)

⚠️  Limiting training data: 1113 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  270 samples, 5 features
✅ Client client_59 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

============================================================
🔄 Round 6 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0906 (↓), lr=0.001000
   • Epoch   2/100: train=0.0803, val=0.0908, patience=1/15, lr=0.001000
   • Epoch   3/100: train=0.0806, val=0.0902, patience=2/15, lr=0.001000
   • Epoch   4/100: train=0.0797, val=0.0902, patience=3/15, lr=0.001000
   • Epoch   5/100: train=0.0791, val=0.0904, patience=4/15, lr=0.001000
   📉 Epoch 10: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0767, val=0.0909, patience=10/15, lr=0.000500

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0906)

============================================================
📊 Round 6 Summary - Client client_59
   Epochs: 16/100 (early stopped)
   LR: 0.001000 → 0.000500 (1 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=-0.0091
   Val:   Loss=0.0906, RMSE=0.3010, R²=-0.0331
============================================================


============================================================
🔄 Round 7 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000500
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0837 (↓), lr=0.000500
   • Epoch   2/100: train=0.0820, val=0.0834, patience=1/15, lr=0.000500
   • Epoch   3/100: train=0.0810, val=0.0838, patience=2/15, lr=0.000500
   • Epoch   4/100: train=0.0807, val=0.0841, patience=3/15, lr=0.000500
   • Epoch   5/100: train=0.0804, val=0.0843, patience=4/15, lr=0.000500
   📉 Epoch 8: LR reduced 0.000500 → 0.000250
   • Epoch  11/100: train=0.0792, val=0.0848, patience=10/15, lr=0.000250
   📉 Epoch 16: LR reduced 0.000250 → 0.000125

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 7 Summary - Client client_59
   Epochs: 16/100 (early stopped)
   LR: 0.000500 → 0.000125 (2 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=-0.0201
   Val:   Loss=0.0837, RMSE=0.2893, R²=-0.0137
============================================================


📊 Round 7 Test Metrics:
   Loss: 0.0889, RMSE: 0.2982, MAE: 0.2578, R²: -0.0655

============================================================
🔄 Round 9 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000125
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0746 (↓), lr=0.000125
   • Epoch   2/100: train=0.0843, val=0.0747, patience=1/15, lr=0.000125
   • Epoch   3/100: train=0.0837, val=0.0748, patience=2/15, lr=0.000125
   • Epoch   4/100: train=0.0835, val=0.0750, patience=3/15, lr=0.000125
   • Epoch   5/100: train=0.0833, val=0.0751, patience=4/15, lr=0.000125
   📉 Epoch 8: LR reduced 0.000125 → 0.000063
   • Epoch  11/100: train=0.0827, val=0.0755, patience=10/15, lr=0.000063
   📉 Epoch 16: LR reduced 0.000063 → 0.000031

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0746)

============================================================
📊 Round 9 Summary - Client client_59
   Epochs: 16/100 (early stopped)
   LR: 0.000125 → 0.000031 (2 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=-0.0310
   Val:   Loss=0.0746, RMSE=0.2731, R²=0.0173
============================================================


============================================================
🔄 Round 10 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000031
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0794 (↓), lr=0.000031
   • Epoch   2/100: train=0.0838, val=0.0795, patience=1/15, lr=0.000031
   • Epoch   3/100: train=0.0836, val=0.0794, patience=2/15, lr=0.000031
   • Epoch   4/100: train=0.0834, val=0.0793, patience=3/15, lr=0.000031
   • Epoch   5/100: train=0.0832, val=0.0792, patience=4/15, lr=0.000031
   📉 Epoch 8: LR reduced 0.000031 → 0.000016
   • Epoch  11/100: train=0.0826, val=0.0790, patience=10/15, lr=0.000016
   📉 Epoch 16: LR reduced 0.000016 → 0.000008

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 10 Summary - Client client_59
   Epochs: 16/100 (early stopped)
   LR: 0.000031 → 0.000008 (2 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=-0.0363
   Val:   Loss=0.0794, RMSE=0.2818, R²=-0.0246
============================================================


📊 Round 10 Test Metrics:
   Loss: 0.0894, RMSE: 0.2990, MAE: 0.2584, R²: -0.0715

============================================================
🔄 Round 12 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000008
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0774 (↓), lr=0.000008
   • Epoch   2/100: train=0.0846, val=0.0774, patience=1/15, lr=0.000008
   • Epoch   3/100: train=0.0845, val=0.0774, patience=2/15, lr=0.000008
   • Epoch   4/100: train=0.0845, val=0.0773, patience=3/15, lr=0.000008
   • Epoch   5/100: train=0.0844, val=0.0773, patience=4/15, lr=0.000008
   📉 Epoch 8: LR reduced 0.000008 → 0.000004
   • Epoch  11/100: train=0.0841, val=0.0771, patience=10/15, lr=0.000004
   📉 Epoch 16: LR reduced 0.000004 → 0.000002

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0774)

============================================================
📊 Round 12 Summary - Client client_59
   Epochs: 16/100 (early stopped)
   LR: 0.000008 → 0.000002 (2 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=-0.0231
   Val:   Loss=0.0774, RMSE=0.2783, R²=-0.0601
============================================================


============================================================
🔄 Round 14 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000002
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0894 (↓), lr=0.000002
   • Epoch   2/100: train=0.0816, val=0.0894, patience=1/15, lr=0.000002
   • Epoch   3/100: train=0.0816, val=0.0894, patience=2/15, lr=0.000002
   • Epoch   4/100: train=0.0816, val=0.0894, patience=3/15, lr=0.000002
   • Epoch   5/100: train=0.0816, val=0.0894, patience=4/15, lr=0.000002
   📉 Epoch 8: LR reduced 0.000002 → 0.000001
   • Epoch  11/100: train=0.0815, val=0.0894, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0894)

============================================================
📊 Round 14 Summary - Client client_59
   Epochs: 16/100 (early stopped)
   LR: 0.000002 → 0.000001 (1 reductions)
   Train: Loss=0.0818, RMSE=0.2861, R²=-0.0323
   Val:   Loss=0.0894, RMSE=0.2990, R²=-0.0420
============================================================


============================================================
🔄 Round 16 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 16 Summary - Client client_59
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=-0.0453
   Val:   Loss=0.0833, RMSE=0.2887, R²=-0.0341
============================================================


============================================================
🔄 Round 17 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 17 Summary - Client client_59
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=-0.0414
   Val:   Loss=0.0808, RMSE=0.2843, R²=-0.0358
============================================================


📊 Round 17 Test Metrics:
   Loss: 0.0901, RMSE: 0.3001, MAE: 0.2594, R²: -0.0794

============================================================
🔄 Round 20 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 20 Summary - Client client_59
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2922, R²=-0.0459
   Val:   Loss=0.0784, RMSE=0.2801, R²=-0.0198
============================================================


📊 Round 20 Test Metrics:
   Loss: 0.0903, RMSE: 0.3005, MAE: 0.2596, R²: -0.0823

📊 Round 20 Test Metrics:
   Loss: 0.0903, RMSE: 0.3005, MAE: 0.2596, R²: -0.0823

📊 Round 20 Test Metrics:
   Loss: 0.0903, RMSE: 0.3005, MAE: 0.2596, R²: -0.0823

============================================================
🔄 Round 27 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0886, val=0.0666 (↓), lr=0.000001
   • Epoch   2/100: train=0.0886, val=0.0667, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0886, val=0.0667, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0886, val=0.0667, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0885, val=0.0667, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0884, val=0.0667, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0666)

============================================================
📊 Round 27 Summary - Client client_59
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0887, RMSE=0.2978, R²=-0.0584
   Val:   Loss=0.0666, RMSE=0.2582, R²=0.0256
============================================================


📊 Round 27 Test Metrics:
   Loss: 0.0903, RMSE: 0.3005, MAE: 0.2596, R²: -0.0825

============================================================
🔄 Round 29 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0740 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0740, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0740, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0740, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0740, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0741, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0740)

============================================================
📊 Round 29 Summary - Client client_59
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2947, R²=-0.0515
   Val:   Loss=0.0740, RMSE=0.2721, R²=-0.0243
============================================================


📊 Round 29 Test Metrics:
   Loss: 0.0903, RMSE: 0.3005, MAE: 0.2596, R²: -0.0825

📊 Round 29 Test Metrics:
   Loss: 0.0903, RMSE: 0.3005, MAE: 0.2596, R²: -0.0825

============================================================
🔄 Round 31 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 31 Summary - Client client_59
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2903, R²=-0.0440
   Val:   Loss=0.0845, RMSE=0.2906, R²=-0.0550
============================================================


============================================================
🔄 Round 32 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 32 Summary - Client client_59
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=-0.0361
   Val:   Loss=0.0847, RMSE=0.2910, R²=-0.0773
============================================================


📊 Round 32 Test Metrics:
   Loss: 0.0903, RMSE: 0.3005, MAE: 0.2596, R²: -0.0824

============================================================
🔄 Round 35 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0888 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0888, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0888, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0888, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0888, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0888, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0888)

============================================================
📊 Round 35 Summary - Client client_59
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=-0.0560
   Val:   Loss=0.0888, RMSE=0.2980, R²=-0.0131
============================================================


📊 Round 35 Test Metrics:
   Loss: 0.0903, RMSE: 0.3005, MAE: 0.2596, R²: -0.0824

============================================================
🔄 Round 36 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0756 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0756, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0756, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0756, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0756, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0756, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0756)

============================================================
📊 Round 36 Summary - Client client_59
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2940, R²=-0.0491
   Val:   Loss=0.0756, RMSE=0.2750, R²=-0.0233
============================================================


📊 Round 36 Test Metrics:
   Loss: 0.0903, RMSE: 0.3005, MAE: 0.2596, R²: -0.0825

📊 Round 36 Test Metrics:
   Loss: 0.0903, RMSE: 0.3005, MAE: 0.2596, R²: -0.0825

📊 Round 36 Test Metrics:
   Loss: 0.0903, RMSE: 0.3005, MAE: 0.2596, R²: -0.0825

📊 Round 36 Test Metrics:
   Loss: 0.0903, RMSE: 0.3005, MAE: 0.2596, R²: -0.0825

============================================================
🔄 Round 40 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0990 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0990, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0990, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0990, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0990, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0989, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0990)

============================================================
📊 Round 40 Summary - Client client_59
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=-0.0417
   Val:   Loss=0.0990, RMSE=0.3147, R²=-0.0527
============================================================


============================================================
🔄 Round 41 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.0738 (↓), lr=0.000001
   • Epoch   2/100: train=0.0868, val=0.0738, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0868, val=0.0738, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0868, val=0.0738, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0868, val=0.0738, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0867, val=0.0738, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0738)

============================================================
📊 Round 41 Summary - Client client_59
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0869, RMSE=0.2948, R²=-0.0541
   Val:   Loss=0.0738, RMSE=0.2717, R²=-0.0006
============================================================


============================================================
🔄 Round 43 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0863 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 43 Summary - Client client_59
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=-0.0484
   Val:   Loss=0.0863, RMSE=0.2938, R²=-0.0281
============================================================


📊 Round 43 Test Metrics:
   Loss: 0.0903, RMSE: 0.3005, MAE: 0.2596, R²: -0.0824

📊 Round 43 Test Metrics:
   Loss: 0.0903, RMSE: 0.3005, MAE: 0.2596, R²: -0.0825

============================================================
🔄 Round 46 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 46 Summary - Client client_59
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2899, R²=-0.0402
   Val:   Loss=0.0854, RMSE=0.2922, R²=-0.0630
============================================================


📊 Round 46 Test Metrics:
   Loss: 0.0903, RMSE: 0.3005, MAE: 0.2596, R²: -0.0825

============================================================
🔄 Round 48 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 48 Summary - Client client_59
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=-0.0484
   Val:   Loss=0.0844, RMSE=0.2905, R²=-0.0297
============================================================


============================================================
🔄 Round 49 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0880 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0879, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0879, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0879, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0879, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0879, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0880)

============================================================
📊 Round 49 Summary - Client client_59
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=-0.0350
   Val:   Loss=0.0880, RMSE=0.2966, R²=-0.0861
============================================================


📊 Round 49 Test Metrics:
   Loss: 0.0903, RMSE: 0.3006, MAE: 0.2596, R²: -0.0826

============================================================
🔄 Round 53 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0914 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0914, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0914, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0914, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0914, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0914, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0914)

============================================================
📊 Round 53 Summary - Client client_59
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2873, R²=-0.0434
   Val:   Loss=0.0914, RMSE=0.3023, R²=-0.0477
============================================================


============================================================
🔄 Round 55 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 55 Summary - Client client_59
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2911, R²=-0.0414
   Val:   Loss=0.0825, RMSE=0.2872, R²=-0.0706
============================================================


📊 Round 55 Test Metrics:
   Loss: 0.0903, RMSE: 0.3006, MAE: 0.2596, R²: -0.0827

============================================================
🔄 Round 58 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 58 Summary - Client client_59
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2928, R²=-0.0492
   Val:   Loss=0.0785, RMSE=0.2803, R²=-0.0281
============================================================


============================================================
🔄 Round 61 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 61 Summary - Client client_59
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=-0.0330
   Val:   Loss=0.0839, RMSE=0.2896, R²=-0.1059
============================================================


📊 Round 61 Test Metrics:
   Loss: 0.0904, RMSE: 0.3006, MAE: 0.2596, R²: -0.0828

📊 Round 61 Test Metrics:
   Loss: 0.0904, RMSE: 0.3006, MAE: 0.2596, R²: -0.0828

📊 Round 61 Test Metrics:
   Loss: 0.0903, RMSE: 0.3006, MAE: 0.2596, R²: -0.0828

============================================================
🔄 Round 66 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 66 Summary - Client client_59
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2915, R²=-0.0438
   Val:   Loss=0.0817, RMSE=0.2859, R²=-0.0472
============================================================


============================================================
🔄 Round 69 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0777 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0777, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0777, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0777, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0777, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0777, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 69 Summary - Client client_59
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2932, R²=-0.0406
   Val:   Loss=0.0777, RMSE=0.2787, R²=-0.0784
============================================================


📊 Round 69 Test Metrics:
   Loss: 0.0903, RMSE: 0.3006, MAE: 0.2596, R²: -0.0827

📊 Round 69 Test Metrics:
   Loss: 0.0903, RMSE: 0.3006, MAE: 0.2596, R²: -0.0826

============================================================
🔄 Round 71 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 71 Summary - Client client_59
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2908, R²=-0.0523
   Val:   Loss=0.0833, RMSE=0.2887, R²=-0.0136
============================================================


📊 Round 71 Test Metrics:
   Loss: 0.0903, RMSE: 0.3006, MAE: 0.2596, R²: -0.0827

📊 Round 71 Test Metrics:
   Loss: 0.0903, RMSE: 0.3006, MAE: 0.2596, R²: -0.0827

📊 Round 71 Test Metrics:
   Loss: 0.0903, RMSE: 0.3006, MAE: 0.2596, R²: -0.0826

============================================================
🔄 Round 76 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0888 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0888, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0888, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0888, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0888, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0887, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0888)

============================================================
📊 Round 76 Summary - Client client_59
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=-0.0300
   Val:   Loss=0.0888, RMSE=0.2980, R²=-0.1057
============================================================


============================================================
🔄 Round 77 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 77 Summary - Client client_59
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2908, R²=-0.0444
   Val:   Loss=0.0833, RMSE=0.2886, R²=-0.0466
============================================================


📊 Round 77 Test Metrics:
   Loss: 0.0903, RMSE: 0.3006, MAE: 0.2596, R²: -0.0826

============================================================
🔄 Round 79 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0759 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0759, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0759, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0759, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0759, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0760, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0759)

============================================================
📊 Round 79 Summary - Client client_59
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2940, R²=-0.0536
   Val:   Loss=0.0759, RMSE=0.2755, R²=-0.0095
============================================================


📊 Round 79 Test Metrics:
   Loss: 0.0903, RMSE: 0.3006, MAE: 0.2596, R²: -0.0826

============================================================
🔄 Round 83 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0888 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0888, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0888, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0888, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0888, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0888, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0888)

============================================================
📊 Round 83 Summary - Client client_59
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=-0.0473
   Val:   Loss=0.0888, RMSE=0.2980, R²=-0.0383
============================================================


📊 Round 83 Test Metrics:
   Loss: 0.0903, RMSE: 0.3006, MAE: 0.2596, R²: -0.0827

============================================================
🔄 Round 85 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0914 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0914, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0914, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0914, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0914, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0914, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0914)

============================================================
📊 Round 85 Summary - Client client_59
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2873, R²=-0.0413
   Val:   Loss=0.0914, RMSE=0.3023, R²=-0.0736
============================================================


📊 Round 85 Test Metrics:
   Loss: 0.0903, RMSE: 0.3006, MAE: 0.2596, R²: -0.0827

📊 Round 85 Test Metrics:
   Loss: 0.0903, RMSE: 0.3006, MAE: 0.2596, R²: -0.0826

📊 Round 85 Test Metrics:
   Loss: 0.0903, RMSE: 0.3006, MAE: 0.2596, R²: -0.0827

📊 Round 85 Test Metrics:
   Loss: 0.0903, RMSE: 0.3006, MAE: 0.2596, R²: -0.0827

📊 Round 85 Test Metrics:
   Loss: 0.0903, RMSE: 0.3006, MAE: 0.2596, R²: -0.0828

============================================================
🔄 Round 95 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0875 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0875, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0875, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0875, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0875, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0875, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0875)

============================================================
📊 Round 95 Summary - Client client_59
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=-0.0368
   Val:   Loss=0.0875, RMSE=0.2959, R²=-0.0899
============================================================


📊 Round 95 Test Metrics:
   Loss: 0.0903, RMSE: 0.3006, MAE: 0.2596, R²: -0.0827

📊 Round 95 Test Metrics:
   Loss: 0.0903, RMSE: 0.3006, MAE: 0.2596, R²: -0.0827

============================================================
🔄 Round 97 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 97 Summary - Client client_59
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=-0.0493
   Val:   Loss=0.0853, RMSE=0.2921, R²=-0.0565
============================================================


============================================================
🔄 Round 99 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 99 Summary - Client client_59
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2929, R²=-0.0478
   Val:   Loss=0.0786, RMSE=0.2803, R²=-0.0332
============================================================


📊 Round 99 Test Metrics:
   Loss: 0.0903, RMSE: 0.3006, MAE: 0.2596, R²: -0.0827

============================================================
🔄 Round 100 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 100 Summary - Client client_59
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2911, R²=-0.0459
   Val:   Loss=0.0826, RMSE=0.2875, R²=-0.0439
============================================================


📊 Round 100 Test Metrics:
   Loss: 0.0903, RMSE: 0.3006, MAE: 0.2596, R²: -0.0827

============================================================
🔄 Round 102 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0762 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0762, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0762, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0762, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0762, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0762, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0762)

============================================================
📊 Round 102 Summary - Client client_59
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2939, R²=-0.0457
   Val:   Loss=0.0762, RMSE=0.2761, R²=-0.0415
============================================================


📊 Round 102 Test Metrics:
   Loss: 0.0903, RMSE: 0.3006, MAE: 0.2596, R²: -0.0826

📊 Round 102 Test Metrics:
   Loss: 0.0903, RMSE: 0.3006, MAE: 0.2597, R²: -0.0826

============================================================
🔄 Round 111 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 111 Summary - Client client_59
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=-0.0495
   Val:   Loss=0.0838, RMSE=0.2895, R²=-0.0275
============================================================


📊 Round 111 Test Metrics:
   Loss: 0.0903, RMSE: 0.3006, MAE: 0.2597, R²: -0.0827

📊 Round 111 Test Metrics:
   Loss: 0.0903, RMSE: 0.3006, MAE: 0.2597, R²: -0.0827

============================================================
🔄 Round 114 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0915 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0915, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0915, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0915, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0915, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0915, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0915)

============================================================
📊 Round 114 Summary - Client client_59
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2873, R²=-0.0446
   Val:   Loss=0.0915, RMSE=0.3025, R²=-0.0529
============================================================


📊 Round 114 Test Metrics:
   Loss: 0.0903, RMSE: 0.3006, MAE: 0.2597, R²: -0.0826

📊 Round 114 Test Metrics:
   Loss: 0.0903, RMSE: 0.3006, MAE: 0.2597, R²: -0.0827

============================================================
🔄 Round 124 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0886, val=0.0665 (↓), lr=0.000001
   • Epoch   2/100: train=0.0886, val=0.0665, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0885, val=0.0665, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0885, val=0.0665, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0885, val=0.0665, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0885, val=0.0665, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0665)

============================================================
📊 Round 124 Summary - Client client_59
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0888, RMSE=0.2980, R²=-0.0563
   Val:   Loss=0.0665, RMSE=0.2578, R²=0.0074
============================================================


============================================================
🔄 Round 125 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 125 Summary - Client client_59
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=-0.0453
   Val:   Loss=0.0826, RMSE=0.2874, R²=-0.0461
============================================================


📊 Round 125 Test Metrics:
   Loss: 0.0903, RMSE: 0.3006, MAE: 0.2597, R²: -0.0827

============================================================
🔄 Round 126 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 126 Summary - Client client_59
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2911, R²=-0.0456
   Val:   Loss=0.0829, RMSE=0.2879, R²=-0.0421
============================================================


📊 Round 126 Test Metrics:
   Loss: 0.0903, RMSE: 0.3006, MAE: 0.2597, R²: -0.0826

📊 Round 126 Test Metrics:
   Loss: 0.0903, RMSE: 0.3006, MAE: 0.2597, R²: -0.0828

📊 Round 126 Test Metrics:
   Loss: 0.0904, RMSE: 0.3006, MAE: 0.2597, R²: -0.0829

============================================================
🔄 Round 130 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 130 Summary - Client client_59
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2913, R²=-0.0438
   Val:   Loss=0.0823, RMSE=0.2869, R²=-0.0514
============================================================


📊 Round 130 Test Metrics:
   Loss: 0.0904, RMSE: 0.3006, MAE: 0.2597, R²: -0.0830

============================================================
🔄 Round 131 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0873, val=0.0741 (↓), lr=0.000001
   • Epoch   2/100: train=0.0873, val=0.0741, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0873, val=0.0741, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0873, val=0.0741, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0873, val=0.0741, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0872, val=0.0742, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0741)

============================================================
📊 Round 131 Summary - Client client_59
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0869, RMSE=0.2948, R²=-0.0452
   Val:   Loss=0.0741, RMSE=0.2722, R²=-0.0655
============================================================


📊 Round 131 Test Metrics:
   Loss: 0.0904, RMSE: 0.3006, MAE: 0.2597, R²: -0.0830

============================================================
🔄 Round 134 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0782, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 134 Summary - Client client_59
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2931, R²=-0.0387
   Val:   Loss=0.0782, RMSE=0.2796, R²=-0.0790
============================================================


📊 Round 134 Test Metrics:
   Loss: 0.0904, RMSE: 0.3006, MAE: 0.2597, R²: -0.0831

============================================================
🔄 Round 135 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0868 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0868, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0868, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0868, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0868, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0867, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0868)

============================================================
📊 Round 135 Summary - Client client_59
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2894, R²=-0.0499
   Val:   Loss=0.0868, RMSE=0.2946, R²=-0.0308
============================================================


📊 Round 135 Test Metrics:
   Loss: 0.0904, RMSE: 0.3006, MAE: 0.2597, R²: -0.0832

============================================================
🔄 Round 137 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0868 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0868, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0868, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0868, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0868, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0868, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0868)

============================================================
📊 Round 137 Summary - Client client_59
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2894, R²=-0.0428
   Val:   Loss=0.0868, RMSE=0.2947, R²=-0.0607
============================================================


📊 Round 137 Test Metrics:
   Loss: 0.0904, RMSE: 0.3006, MAE: 0.2597, R²: -0.0831

📊 Round 137 Test Metrics:
   Loss: 0.0904, RMSE: 0.3006, MAE: 0.2597, R²: -0.0831

📊 Round 137 Test Metrics:
   Loss: 0.0904, RMSE: 0.3006, MAE: 0.2597, R²: -0.0831

📊 Round 137 Test Metrics:
   Loss: 0.0904, RMSE: 0.3006, MAE: 0.2597, R²: -0.0831

📊 Round 137 Test Metrics:
   Loss: 0.0904, RMSE: 0.3006, MAE: 0.2597, R²: -0.0830

============================================================
🔄 Round 142 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0749 (↓), lr=0.000001
   • Epoch   2/100: train=0.0867, val=0.0749, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0867, val=0.0749, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0867, val=0.0749, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0867, val=0.0749, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0866, val=0.0749, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0749)

============================================================
📊 Round 142 Summary - Client client_59
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0867, RMSE=0.2945, R²=-0.0395
   Val:   Loss=0.0749, RMSE=0.2738, R²=-0.0710
============================================================


============================================================
🔄 Round 143 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0868 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0868, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0868, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0868, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0868, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0868, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0868)

============================================================
📊 Round 143 Summary - Client client_59
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2894, R²=-0.0349
   Val:   Loss=0.0868, RMSE=0.2947, R²=-0.0857
============================================================


📊 Round 143 Test Metrics:
   Loss: 0.0904, RMSE: 0.3006, MAE: 0.2597, R²: -0.0830

📊 Round 143 Test Metrics:
   Loss: 0.0904, RMSE: 0.3006, MAE: 0.2597, R²: -0.0830

📊 Round 143 Test Metrics:
   Loss: 0.0904, RMSE: 0.3006, MAE: 0.2597, R²: -0.0830

============================================================
🔄 Round 148 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 148 Summary - Client client_59
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=-0.0587
   Val:   Loss=0.0830, RMSE=0.2881, R²=-0.0075
============================================================


📊 Round 148 Test Metrics:
   Loss: 0.0904, RMSE: 0.3006, MAE: 0.2597, R²: -0.0830

============================================================
🔄 Round 149 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0900 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0900, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0900, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0900, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0900, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0900, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0900)

============================================================
📊 Round 149 Summary - Client client_59
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2880, R²=-0.0494
   Val:   Loss=0.0900, RMSE=0.3000, R²=-0.0287
============================================================


📊 Round 149 Test Metrics:
   Loss: 0.0904, RMSE: 0.3006, MAE: 0.2597, R²: -0.0831

============================================================
🔄 Round 152 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 152 Summary - Client client_59
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=-0.0440
   Val:   Loss=0.0842, RMSE=0.2902, R²=-0.0492
============================================================


📊 Round 152 Test Metrics:
   Loss: 0.0904, RMSE: 0.3006, MAE: 0.2597, R²: -0.0831

============================================================
🔄 Round 154 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0953 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0953, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0953, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0953, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0953, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0953, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0953)

============================================================
📊 Round 154 Summary - Client client_59
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=-0.0458
   Val:   Loss=0.0953, RMSE=0.3087, R²=-0.0425
============================================================


============================================================
🔄 Round 157 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0908 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0908, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0908, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0908, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0908, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0908, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0908)

============================================================
📊 Round 157 Summary - Client client_59
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=-0.0437
   Val:   Loss=0.0908, RMSE=0.3013, R²=-0.0571
============================================================


============================================================
🔄 Round 158 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 158 Summary - Client client_59
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2899, R²=-0.0427
   Val:   Loss=0.0856, RMSE=0.2925, R²=-0.0671
============================================================


📊 Round 158 Test Metrics:
   Loss: 0.0904, RMSE: 0.3006, MAE: 0.2597, R²: -0.0832

📊 Round 158 Test Metrics:
   Loss: 0.0904, RMSE: 0.3006, MAE: 0.2597, R²: -0.0831

============================================================
🔄 Round 163 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 163 Summary - Client client_59
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=-0.0428
   Val:   Loss=0.0859, RMSE=0.2930, R²=-0.0671
============================================================


============================================================
🔄 Round 164 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0938 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0937, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0937, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0937, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0937, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0937, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0938)

============================================================
📊 Round 164 Summary - Client client_59
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=-0.0309
   Val:   Loss=0.0938, RMSE=0.3062, R²=-0.0989
============================================================


============================================================
🔄 Round 169 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0877, val=0.0716 (↓), lr=0.000001
   • Epoch   2/100: train=0.0877, val=0.0716, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0877, val=0.0716, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0877, val=0.0716, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0876, val=0.0716, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0876, val=0.0715, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0716)

============================================================
📊 Round 169 Summary - Client client_59
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0876, RMSE=0.2959, R²=-0.0443
   Val:   Loss=0.0716, RMSE=0.2676, R²=-0.0575
============================================================


============================================================
🔄 Round 175 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 175 Summary - Client client_59
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2904, R²=-0.0404
   Val:   Loss=0.0846, RMSE=0.2909, R²=-0.0646
============================================================


============================================================
🔄 Round 176 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0918 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0918, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0918, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0918, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0918, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0918, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0918)

============================================================
📊 Round 176 Summary - Client client_59
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=-0.0389
   Val:   Loss=0.0918, RMSE=0.3031, R²=-0.0727
============================================================


============================================================
🔄 Round 177 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 177 Summary - Client client_59
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2923, R²=-0.0376
   Val:   Loss=0.0802, RMSE=0.2832, R²=-0.0811
============================================================


📊 Round 177 Test Metrics:
   Loss: 0.0904, RMSE: 0.3007, MAE: 0.2597, R²: -0.0834

============================================================
🔄 Round 183 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 183 Summary - Client client_59
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=-0.0487
   Val:   Loss=0.0851, RMSE=0.2918, R²=-0.0317
============================================================


📊 Round 183 Test Metrics:
   Loss: 0.0904, RMSE: 0.3007, MAE: 0.2597, R²: -0.0835

============================================================
🔄 Round 187 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0886 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0886, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0886, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0886, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0886, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0886, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0886)

============================================================
📊 Round 187 Summary - Client client_59
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=-0.0530
   Val:   Loss=0.0886, RMSE=0.2977, R²=-0.0181
============================================================


============================================================
🔄 Round 188 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 188 Summary - Client client_59
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=-0.0315
   Val:   Loss=0.0823, RMSE=0.2869, R²=-0.1069
============================================================


============================================================
🔄 Round 189 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 189 Summary - Client client_59
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2901, R²=-0.0488
   Val:   Loss=0.0852, RMSE=0.2919, R²=-0.0506
============================================================


📊 Round 189 Test Metrics:
   Loss: 0.0904, RMSE: 0.3007, MAE: 0.2597, R²: -0.0836

📊 Round 189 Test Metrics:
   Loss: 0.0904, RMSE: 0.3007, MAE: 0.2597, R²: -0.0837

📊 Round 189 Test Metrics:
   Loss: 0.0904, RMSE: 0.3007, MAE: 0.2597, R²: -0.0837

============================================================
🔄 Round 192 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0869 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0869, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0869, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0869, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0869, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0870, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 192 Summary - Client client_59
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2894, R²=-0.0481
   Val:   Loss=0.0869, RMSE=0.2948, R²=-0.0533
============================================================


📊 Round 192 Test Metrics:
   Loss: 0.0904, RMSE: 0.3007, MAE: 0.2597, R²: -0.0837

📊 Round 192 Test Metrics:
   Loss: 0.0904, RMSE: 0.3007, MAE: 0.2597, R²: -0.0837

============================================================
🔄 Round 197 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 197 Summary - Client client_59
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2913, R²=-0.0476
   Val:   Loss=0.0824, RMSE=0.2870, R²=-0.0359
============================================================


📊 Round 197 Test Metrics:
   Loss: 0.0904, RMSE: 0.3007, MAE: 0.2597, R²: -0.0837

============================================================
🔄 Round 198 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 198 Summary - Client client_59
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2927, R²=-0.0588
   Val:   Loss=0.0791, RMSE=0.2813, R²=-0.0045
============================================================


📊 Round 198 Test Metrics:
   Loss: 0.0904, RMSE: 0.3007, MAE: 0.2597, R²: -0.0836

============================================================
🔄 Round 199 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0913 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0913, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0913, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0913, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0913, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0913, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0913)

============================================================
📊 Round 199 Summary - Client client_59
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2875, R²=-0.0465
   Val:   Loss=0.0913, RMSE=0.3022, R²=-0.0421
============================================================


📊 Round 199 Test Metrics:
   Loss: 0.0904, RMSE: 0.3007, MAE: 0.2597, R²: -0.0837

============================================================
🔄 Round 202 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0864, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0864, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 202 Summary - Client client_59
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2896, R²=-0.0453
   Val:   Loss=0.0864, RMSE=0.2939, R²=-0.0592
============================================================


📊 Round 202 Test Metrics:
   Loss: 0.0904, RMSE: 0.3007, MAE: 0.2597, R²: -0.0837

============================================================
🔄 Round 204 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0864, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 204 Summary - Client client_59
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2896, R²=-0.0376
   Val:   Loss=0.0864, RMSE=0.2939, R²=-0.0809
============================================================


============================================================
🔄 Round 205 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 205 Summary - Client client_59
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2928, R²=-0.0403
   Val:   Loss=0.0789, RMSE=0.2809, R²=-0.0709
============================================================


============================================================
🔄 Round 206 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0908 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0908, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0908, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0908, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0908, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0909, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0908)

============================================================
📊 Round 206 Summary - Client client_59
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2877, R²=-0.0481
   Val:   Loss=0.0908, RMSE=0.3013, R²=-0.0461
============================================================


============================================================
🔄 Round 208 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 208 Summary - Client client_59
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2915, R²=-0.0490
   Val:   Loss=0.0821, RMSE=0.2866, R²=-0.0509
============================================================


📊 Round 208 Test Metrics:
   Loss: 0.0904, RMSE: 0.3007, MAE: 0.2597, R²: -0.0838

============================================================
🔄 Round 212 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0877 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0877, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0877, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0877, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0877, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0877, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0877)

============================================================
📊 Round 212 Summary - Client client_59
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=-0.0395
   Val:   Loss=0.0877, RMSE=0.2962, R²=-0.0816
============================================================


📊 Round 212 Test Metrics:
   Loss: 0.0904, RMSE: 0.3007, MAE: 0.2597, R²: -0.0837

============================================================
🔄 Round 215 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0776 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0776, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0776, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0777, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0777, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0778, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 215 Summary - Client client_59
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2934, R²=-0.0614
   Val:   Loss=0.0776, RMSE=0.2786, R²=-0.0126
============================================================


📊 Round 215 Test Metrics:
   Loss: 0.0904, RMSE: 0.3007, MAE: 0.2597, R²: -0.0838

============================================================
🔄 Round 216 - Client client_59
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 216 Summary - Client client_59
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=-0.0390
   Val:   Loss=0.0850, RMSE=0.2915, R²=-0.0721
============================================================


📊 Round 216 Test Metrics:
   Loss: 0.0904, RMSE: 0.3007, MAE: 0.2597, R²: -0.0838

❌ Client client_59 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8687 {grpc_status:14, grpc_message:"Socket closed"}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8687 {grpc_status:14, grpc_message:"Socket closed"}"
>
