[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 18dd78ea-83e8-4d1e-a105-caabcfd3aa1e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 86ccf07e-d42e-43f1-b27a-597413078396
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a0a7daec-8824-49ed-ac11-991594a0514d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f2453f27-9f48-48c4-9756-db0ce704d9c3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 20c97da4-6856-4a09-80ab-3a684bc0a509
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3dd9b65e-49e9-4588-a18e-c71d0389e4dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 873bc058-9cdf-405b-96c9-1792fb644291
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cd2b75aa-c39b-497f-8f3c-02ea74f42f7b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0ee54da0-0c84-4189-8c5b-89f9464dea70
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1b1b0726-d19f-4a0b-a75c-232bd31bcf83
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ff384abf-b8e5-4cb4-8b15-d019ae344f04
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d014359c-6d10-4823-bdde-07654ce0afdd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f4bdfbaf-720b-4478-a01b-358cf7e26671
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fa98404f-65d8-4076-b566-24f222dfabeb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 85f0995f-87f9-4faa-bced-367ff1d3b55b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 99bdf332-169e-4dc3-b231-b59a095cf40c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 301f6862-c607-40e2-95a9-5527aef4767b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e489dfce-7d4e-40a9-ac72-a65743bfd7b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5fe4c225-c5c9-4dab-a79a-baff8b4aed34
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f3a2d722-5a15-4532-b35c-edc4fe1c0f02
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 25b845cb-7812-4e2f-b9f2-5702d91dc4db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3895d4d5-3c88-4456-a319-14d56193b7b9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b2ac07a3-b834-4aa6-b935-36bd71f74aff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8896ecb5-546d-4c43-ac3d-39df1d17171d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1b2c572c-b265-4872-9df4-ede5880db8c4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d63e91bd-6a13-44e6-af81-8a35784920ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2569446d-0eb9-416b-a661-eeefd7ef328c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 75a34b35-9dad-4423-97b3-d2fb03b81a5d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 84c387fb-fdc7-4d5b-8c48-ea43f6a3f8db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 801b6234-6fb8-460b-84bf-05d035dac1a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 007ca63c-e87e-4069-be27-8549cca546ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bc493ff3-c739-4f4d-9c22-d13c132cca34
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6a229fc8-ac6a-4dcb-8ed6-632c878926e0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c2efc486-053b-4b79-9192-d4acfac3929f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d2e6a4ad-7738-4b6c-8f6e-d12cb36381ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 35afad03-0c71-4ab1-9a02-12c4e83c0767
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d64fbba7-07a0-4f80-93cb-9024676110a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fdb5877b-a424-4369-ac19-c2f720f2d7c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 72862fb4-2cc4-48df-aa9e-b0a1ee1944c6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0f73e79b-7ee0-4070-8aac-e997da3bf35d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a12c7e30-32e8-4579-9e85-d7303758432a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b2fc79d6-9e3c-4399-ba0d-acfcbd62bf91
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 78cbea32-22bb-45c8-93ff-6f04bf7f8692
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3a8f934f-2a5d-42a8-b0e9-84e47d4ebb4d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 07b57950-26ca-425f-ad76-a95ed6209070
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cda63ad9-7250-46c8-b53f-445d1f303d31
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3667cb9f-ce73-4cc8-80cb-cddb3f40b2ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 23e58bec-19c9-40c6-81dc-2d46c115870d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c8c5d561-4ae0-4715-a1d9-8ef385121b01
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 264997f7-be3d-4326-a8b0-5a2876e670c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 456d1052-0e73-4347-93f9-8ca3cb925019
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6d436bcd-49d7-4ebb-a380-e6d64d61145d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 41e0f01d-a759-4906-b767-c8c98bf7d550
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e60e271f-13a6-4866-896b-c461e3a627b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3c09ed37-9c65-4bc7-8f52-f6f1c8e5b2a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e493a073-fbfc-460e-98b7-1333185079d9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2e80863f-d171-4a0b-b274-da91ed41bc1f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8f3d343f-f9d0-473e-b1db-76448d433077
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eeff8ddc-004d-48bc-b142-fb2af7a05c3c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 68133559-2d4e-4f98-8336-c86d36865803
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message feea5310-ba79-4a45-9644-26fa75d62fff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0b9dd605-a726-47a5-bd6e-2124891cd650
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 64216967-d1bf-48ce-8f7f-e37ebf69b9d1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 04799181-e0e7-4f0d-a689-97f601da2b50
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 25373425-95a4-4d10-929d-fe42291dc026
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 323cb38a-5999-40fd-aece-412f87cf7d09
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 89ad4b6f-d85c-4316-b983-02abe1374e89
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 29dde7e2-86b9-4a1b-a899-ad7dc9d250f4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 72166d17-28f8-436b-a341-f94cd0038cfe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 79dede8e-224d-4fe0-9b45-17e2071df8eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 28d37ba1-1010-4816-af5b-fd89141bd79b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2ba570c6-bd84-4381-b4f5-c7b65140dab7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 72020f47-fd88-450c-ae5e-4b36aac09a9d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c9187410-cb6c-4b97-8280-2c315ba8caa8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 94c41e4d-c8e4-4458-83ae-4ec64a7968b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8c15a93b-787b-49b5-9f81-0e327d09f314
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9c4a3388-1d4b-4c87-9318-4691acd0b3ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b8d66eb3-4245-4b1d-97d2-3696bf469b14
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 223a8120-38c5-4f7a-b793-e8c00ac1f93a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1681469a-19b8-47ac-9825-63c5e619706b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d6b3386a-a6e3-4736-9e50-588832ff46dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4f4bb33f-bf42-42d6-b8b8-5efb0d94811c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8d25fb96-bfae-4d3a-a151-e32123447b1e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cc10d1b4-e78b-4df9-9ce0-951f83f639c7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5a3dbf65-43cb-4a40-a429-614d3e9b7cc3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bd1a90e3-1eb3-4b19-a7d0-39dabbc30add
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 90b2042c-5d2b-4a0d-8afc-2bf5623b3859
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 34762d8b-72f6-4a2a-984d-d2ee0d45f07e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a1efe520-1f34-45b2-9282-012c91253098
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 351313f9-891c-4242-b850-d620b7581361
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 79643e04-721d-4b17-9cfb-02358b97bf68
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d533385d-f4bf-43e3-88ba-ad68f0a1b7d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9d3edf73-4daf-4f9f-a9c0-111a7e0cbad2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9a3f96d8-4ea4-405c-8e3e-4a0b64299d6b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8a7b4925-a1b3-4f95-81ff-e95499f600a0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 59a71740-cd91-4ade-a7ad-3a53bb7ed44e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d2f8dc14-e431-4c9d-b17d-0dac1d50d098
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fbb5bf6f-fb3d-417b-be4c-9d9cf9b907cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 451c94e7-b933-43da-9586-c86b029ef3fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f98a6ad9-c864-4cec-9b93-56ef16ee1bff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 71f259ab-72a4-430b-a4f5-f1077fd5a22d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fd82eb26-022a-48c8-ab4c-9ca7933e8718
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 624e34dc-8872-4d44-aac8-7f851574712e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e9f11604-94ba-4a6a-bc4d-996b111bbb5f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ecce1ec8-f991-4c8b-a715-5eb14aed5e77
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1460ac17-87d3-4e4e-b30d-9be8aad6ddf9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f57f06e6-1050-424c-bd51-784871517d92
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 575cf493-8df0-4ed7-918a-c13eda981532
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b73c2102-cc56-43a4-92f8-e738f0d83d90
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 61bb10d6-9ddf-4ab9-89fc-011dcf60b9c5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 680254c4-9f47-47cc-9652-0ca9e6f82191
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a42e3f68-44d7-41f5-b3ba-76481b537272
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2f410de0-8750-4a39-aec6-ab1e420deb06
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 705fd192-ecfa-46b8-ba7a-50d093df28fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 806fbbf9-642f-40d1-a9b7-ed876ea756e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8a380172-d6d1-412e-bbdd-79768c535de9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e25490a5-2e46-4a2c-86dd-96c4e3f14b9b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 445d9d5e-32a3-4713-a165-0bb59fdb9ba6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bcd4056c-d506-4442-a37e-b9013db5c8bc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 165285e4-0596-4023-a3a7-380687953318
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 32101d67-d7f2-4bf1-859d-a123bef7a501
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8ec2ec3b-4954-4c58-acb8-a5d91dec33e5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 190a9f39-f208-4495-b229-14442d9b1b86
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ab4416fd-1174-4c4f-87b6-a4b89ca015a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a6899378-8955-48ad-923e-f64815f9a036
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8e60097b-d671-4294-ae2a-0223c08b1d9d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2a5b0eb3-8ad3-4788-aa30-c0aa267b3453
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7d7df887-240d-4d69-9bc8-1aab0dcbbc6b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a814e65d-a8ca-4a79-aec2-0c9de568d785
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3d588d71-ec45-494e-83df-646ea3705a66
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b1487c4d-841e-45b5-9c46-58fd06f2f188
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b601026f-3b5d-4c52-bb94-f596e5200bd6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message adf25144-f03c-47c4-88d3-53adfa61fa5b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b038a4ee-f699-4477-97f3-7e992750d7cd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ab5580b2-5f88-474e-9e57-0c478be29a6d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 21df430d-b317-43ef-bb86-edd53f027f01
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c333e889-4c3d-43c9-a530-453fd797484f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dd729165-e168-48dc-991b-5371a2bf81a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e987e166-5edb-4815-bf7e-283fb7e83400
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5f00255c-47b2-4bd8-80d0-627ce9290011
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c6a7f695-729c-45d9-b415-5e473acd9b7a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ac6cd739-71da-4e5e-82f0-667c13c46212
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 91773d2c-6238-424d-9221-0dc1f4507c4a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9958f489-0ade-4545-b16a-cb0182b2c69b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c8998ce2-7b86-4df7-b82e-ffb47c8cf68a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e4dc59a5-55f5-46cd-9e46-65ec64936365
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dca7e11f-8f39-459e-82a8-8e5b62ddf6ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 91f32f58-d492-414b-ae8e-0759ad95d4c7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aa79312c-6f1d-4bdc-9d93-28594b0fd259
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d4262be0-82a2-448c-918d-bf407e02fa81
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5b8020eb-2e15-4ead-9065-d3fdb8628f07
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5ab21cc4-2c53-4dc9-b486-9502e2e8b865
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 91c62355-e133-4570-85a7-8cf01f17c253
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 02d686f8-f42f-43f8-819f-6ab296620ea8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a672392a-d262-493a-87bb-173883ed78c3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7d67addc-288d-4398-9f47-0f84bbdbd6a9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b6ae426b-d432-44be-8f19-57a78c2b121d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3ce7162e-19f2-40cf-a5d4-638ec02e0ab2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 038627d2-1d93-435d-98ce-0ef3bac4e0c9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 791bcf83-021e-4cb2-b5b7-f899b11ee630
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 772f2475-5ad9-46ea-9af5-bb10c135131f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message afaffa1c-5867-45d8-ba0a-99b48f605657
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e5d6ba94-0022-4aed-abbc-28dd29636ea2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7e191659-bbb3-4ac1-bc9f-1bcd7ee3e922
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3975feed-8619-4e5f-860f-6b8f81224dd6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bdf86066-e49f-4ad7-b2e7-23415d2ab317
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4127b54d-3b66-40de-8e97-0a9c9c4e4c8f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 461fb94c-85d8-462e-93a4-c63ec3aab741
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e27cebb0-cec4-4f76-809e-7d6f858bc74e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 600efbfa-7359-4fd1-ac90-5617b6ea0491
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6093a08f-9101-426c-a137-7643c7cb9289
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1ec6f87c-e2fc-4a91-8a9e-3d038a1baf8f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8f6fd9ca-632a-48c4-9838-cdb63e39364d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 30024fa4-bf71-4c09-b336-192d563606ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6827b274-429d-4c1d-8153-e9834ccc0f40
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0da44f4a-b3e6-40aa-981e-7b7afa17c19a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f30f63f0-0de0-4b2a-afe5-64133e9c7c9a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 15af6be2-c0c8-4c63-8f18-eff694fb33c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message be0b77e8-577f-4bc5-9235-492f966a3107
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c3fe8276-f01d-472f-8d26-789e7c1b7c9d
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8687 {grpc_status:14, grpc_message:"Socket closed"}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_5
Server: localhost:8687
Algorithm: FEDAVG
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_5
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_5/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_5/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_5/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_5/test_labels.txt

📊 Raw data loaded:
   Train: X=(660, 24), y=(660,)
   Test:  X=(166, 24), y=(166,)

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 651 samples, 5 features
   Test:  157 samples, 5 features
✅ Client client_5 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

============================================================
🔄 Round 4 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0895, val=0.0872 (↓), lr=0.001000
   • Epoch   2/100: train=0.0856, val=0.0879, patience=1/15, lr=0.001000
   • Epoch   3/100: train=0.0852, val=0.0891, patience=2/15, lr=0.001000
   • Epoch   4/100: train=0.0848, val=0.0889, patience=3/15, lr=0.001000
   • Epoch   5/100: train=0.0846, val=0.0888, patience=4/15, lr=0.001000
   📉 Epoch 7: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0833, val=0.0890, patience=10/15, lr=0.000500
   📉 Epoch 15: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0872)

============================================================
📊 Round 4 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=-0.0154
   Val:   Loss=0.0872, RMSE=0.2953, R²=0.0004
============================================================


📊 Round 4 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2461, R²: -0.0236

============================================================
🔄 Round 6 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0889, val=0.0878 (↓), lr=0.000250
   • Epoch   2/100: train=0.0882, val=0.0884, patience=1/15, lr=0.000250
   • Epoch   3/100: train=0.0877, val=0.0891, patience=2/15, lr=0.000250
   • Epoch   4/100: train=0.0873, val=0.0894, patience=3/15, lr=0.000250
   • Epoch   5/100: train=0.0871, val=0.0896, patience=4/15, lr=0.000250
   📉 Epoch 7: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0861, val=0.0899, patience=10/15, lr=0.000125
   📉 Epoch 15: LR reduced 0.000125 → 0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0878)

============================================================
📊 Round 6 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000250 → 0.000063 (2 reductions)
   Train: Loss=0.0860, RMSE=0.2933, R²=-0.0184
   Val:   Loss=0.0878, RMSE=0.2963, R²=-0.0506
============================================================


📊 Round 6 Test Metrics:
   Loss: 0.0826, RMSE: 0.2874, MAE: 0.2478, R²: -0.0315

============================================================
🔄 Round 7 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0903 (↓), lr=0.000063
   • Epoch   2/100: train=0.0861, val=0.0906, patience=1/15, lr=0.000063
   • Epoch   3/100: train=0.0858, val=0.0908, patience=2/15, lr=0.000063
   • Epoch   4/100: train=0.0856, val=0.0909, patience=3/15, lr=0.000063
   • Epoch   5/100: train=0.0854, val=0.0909, patience=4/15, lr=0.000063
   📉 Epoch 7: LR reduced 0.000063 → 0.000031
   • Epoch  11/100: train=0.0850, val=0.0909, patience=10/15, lr=0.000031
   📉 Epoch 15: LR reduced 0.000031 → 0.000016

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0903)

============================================================
📊 Round 7 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000063 → 0.000016 (2 reductions)
   Train: Loss=0.0862, RMSE=0.2937, R²=-0.0342
   Val:   Loss=0.0903, RMSE=0.3006, R²=-0.0167
============================================================


============================================================
🔄 Round 8 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000016
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0897, val=0.0870 (↓), lr=0.000016
   • Epoch   2/100: train=0.0895, val=0.0872, patience=1/15, lr=0.000016
   • Epoch   3/100: train=0.0893, val=0.0874, patience=2/15, lr=0.000016
   • Epoch   4/100: train=0.0892, val=0.0876, patience=3/15, lr=0.000016
   • Epoch   5/100: train=0.0890, val=0.0877, patience=4/15, lr=0.000016
   📉 Epoch 7: LR reduced 0.000016 → 0.000008
   • Epoch  11/100: train=0.0886, val=0.0881, patience=10/15, lr=0.000008
   📉 Epoch 15: LR reduced 0.000008 → 0.000004

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 8 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000016 → 0.000004 (2 reductions)
   Train: Loss=0.0878, RMSE=0.2964, R²=-0.0448
   Val:   Loss=0.0870, RMSE=0.2950, R²=-0.0258
============================================================


📊 Round 8 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2471, R²: -0.0297

============================================================
🔄 Round 9 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000004
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0865 (↓), lr=0.000004
   • Epoch   2/100: train=0.0863, val=0.0865, patience=1/15, lr=0.000004
   • Epoch   3/100: train=0.0863, val=0.0865, patience=2/15, lr=0.000004
   • Epoch   4/100: train=0.0862, val=0.0865, patience=3/15, lr=0.000004
   • Epoch   5/100: train=0.0862, val=0.0865, patience=4/15, lr=0.000004
   • Epoch  11/100: train=0.0861, val=0.0864, patience=10/15, lr=0.000004

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0865)

============================================================
📊 Round 9 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000004 → 0.000004 (0 reductions)
   Train: Loss=0.0879, RMSE=0.2964, R²=-0.0412
   Val:   Loss=0.0865, RMSE=0.2941, R²=-0.0167
============================================================


============================================================
🔄 Round 10 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000004
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0883, val=0.0946 (↓), lr=0.000004
   • Epoch   2/100: train=0.0882, val=0.0945, patience=1/15, lr=0.000004
   • Epoch   3/100: train=0.0882, val=0.0945, patience=2/15, lr=0.000004
   • Epoch   4/100: train=0.0881, val=0.0945, patience=3/15, lr=0.000004
   • Epoch   5/100: train=0.0881, val=0.0945, patience=4/15, lr=0.000004
   📉 Epoch 6: LR reduced 0.000004 → 0.000002
   • Epoch  11/100: train=0.0880, val=0.0945, patience=10/15, lr=0.000002
   📉 Epoch 14: LR reduced 0.000002 → 0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0946)

============================================================
📊 Round 10 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000004 → 0.000001 (2 reductions)
   Train: Loss=0.0863, RMSE=0.2938, R²=-0.0426
   Val:   Loss=0.0946, RMSE=0.3075, R²=-0.0325
============================================================


📊 Round 10 Test Metrics:
   Loss: 0.0827, RMSE: 0.2877, MAE: 0.2476, R²: -0.0337

============================================================
🔄 Round 12 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0892, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0892, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0892, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0892, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0892, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0891, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 12 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0896, RMSE=0.2994, R²=-0.0362
   Val:   Loss=0.0797, RMSE=0.2823, R²=-0.0409
============================================================


============================================================
🔄 Round 13 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0890, val=0.0892 (↓), lr=0.000001
   • Epoch   2/100: train=0.0890, val=0.0892, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0890, val=0.0892, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0890, val=0.0892, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0890, val=0.0892, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0890, val=0.0892, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0892)

============================================================
📊 Round 13 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0873, RMSE=0.2955, R²=-0.0429
   Val:   Loss=0.0892, RMSE=0.2987, R²=-0.0203
============================================================


📊 Round 13 Test Metrics:
   Loss: 0.0827, RMSE: 0.2876, MAE: 0.2476, R²: -0.0334

============================================================
🔄 Round 16 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.1027 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.1027, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.1027, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.1027, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.1027, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.1027, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.1027)

============================================================
📊 Round 16 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=-0.0392
   Val:   Loss=0.1027, RMSE=0.3205, R²=-0.0449
============================================================


============================================================
🔄 Round 20 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0914 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0914, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0914, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0913, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0913, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0913, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0914)

============================================================
📊 Round 20 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0871, RMSE=0.2951, R²=-0.0378
   Val:   Loss=0.0914, RMSE=0.3023, R²=-0.0515
============================================================


📊 Round 20 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2480, R²: -0.0353

============================================================
🔄 Round 21 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0924 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0924, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0924, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0924, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0924, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0924, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0924)

============================================================
📊 Round 21 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0869, RMSE=0.2948, R²=-0.0420
   Val:   Loss=0.0924, RMSE=0.3040, R²=-0.0426
============================================================


📊 Round 21 Test Metrics:
   Loss: 0.0829, RMSE: 0.2878, MAE: 0.2479, R²: -0.0350

📊 Round 21 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2479, R²: -0.0352

============================================================
🔄 Round 25 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.1049 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.1049, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.1049, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.1049, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.1049, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.1049, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.1049)

============================================================
📊 Round 25 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=-0.0322
   Val:   Loss=0.1049, RMSE=0.3239, R²=-0.0951
============================================================


📊 Round 25 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2479, R²: -0.0352

📊 Round 25 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2479, R²: -0.0351

📊 Round 25 Test Metrics:
   Loss: 0.0829, RMSE: 0.2878, MAE: 0.2479, R²: -0.0350

📊 Round 25 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2479, R²: -0.0351

============================================================
🔄 Round 33 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.1011 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.1011, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.1011, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.1011, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.1011, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.1010, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.1011)

============================================================
📊 Round 33 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=-0.0387
   Val:   Loss=0.1011, RMSE=0.3180, R²=-0.0512
============================================================


📊 Round 33 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2479, R²: -0.0352

============================================================
🔄 Round 34 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0894, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0894, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0894, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0894, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0894, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0893, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 34 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0893, RMSE=0.2989, R²=-0.0439
   Val:   Loss=0.0828, RMSE=0.2877, R²=-0.0352
============================================================


📊 Round 34 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2479, R²: -0.0352

============================================================
🔄 Round 35 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0888, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0888, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0888, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0887, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0887, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0887, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 35 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0903, RMSE=0.3005, R²=-0.0454
   Val:   Loss=0.0789, RMSE=0.2809, R²=-0.0254
============================================================


📊 Round 35 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2479, R²: -0.0352

============================================================
🔄 Round 36 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0909 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0909, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0909, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0909, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0909, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0908, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0909)

============================================================
📊 Round 36 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0873, RMSE=0.2955, R²=-0.0352
   Val:   Loss=0.0909, RMSE=0.3015, R²=-0.0859
============================================================


============================================================
🔄 Round 37 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0900, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0900, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0900, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0899, val=0.0859, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0899, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0899, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 37 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0886, RMSE=0.2976, R²=-0.0393
   Val:   Loss=0.0859, RMSE=0.2930, R²=-0.0504
============================================================


============================================================
🔄 Round 38 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0959 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0959, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0959, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0959, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0959, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0959, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0959)

============================================================
📊 Round 38 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2934, R²=-0.0421
   Val:   Loss=0.0959, RMSE=0.3096, R²=-0.0391
============================================================


============================================================
🔄 Round 39 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0910, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0910, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0910, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0910, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0910, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0909, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 39 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0892, RMSE=0.2986, R²=-0.0466
   Val:   Loss=0.0835, RMSE=0.2890, R²=-0.0201
============================================================


============================================================
🔄 Round 40 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0912, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0912, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0911, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0911, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0911, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0911, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 40 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0894, RMSE=0.2989, R²=-0.0449
   Val:   Loss=0.0827, RMSE=0.2876, R²=-0.0406
============================================================


📊 Round 40 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2479, R²: -0.0351

============================================================
🔄 Round 41 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.1015 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.1015, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.1015, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.1015, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.1015, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.1015, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.1015)

============================================================
📊 Round 41 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=-0.0439
   Val:   Loss=0.1015, RMSE=0.3187, R²=-0.0335
============================================================


📊 Round 41 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2479, R²: -0.0352

============================================================
🔄 Round 42 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0925 (↓), lr=0.000001
   • Epoch   2/100: train=0.0867, val=0.0925, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0867, val=0.0925, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0867, val=0.0925, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0867, val=0.0925, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0867, val=0.0925, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0925)

============================================================
📊 Round 42 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0869, RMSE=0.2948, R²=-0.0391
   Val:   Loss=0.0925, RMSE=0.3041, R²=-0.0502
============================================================


📊 Round 42 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2479, R²: -0.0352

📊 Round 42 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2479, R²: -0.0352

📊 Round 42 Test Metrics:
   Loss: 0.0829, RMSE: 0.2878, MAE: 0.2479, R²: -0.0350

📊 Round 42 Test Metrics:
   Loss: 0.0829, RMSE: 0.2878, MAE: 0.2479, R²: -0.0351

============================================================
🔄 Round 49 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0891, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0891, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0890, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0890, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0890, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0890, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 49 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0896, RMSE=0.2993, R²=-0.0413
   Val:   Loss=0.0817, RMSE=0.2859, R²=-0.0476
============================================================


📊 Round 49 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2479, R²: -0.0351

📊 Round 49 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2479, R²: -0.0352

============================================================
🔄 Round 53 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0877, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0877, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0877, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0876, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0876, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0876, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 53 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0888, RMSE=0.2981, R²=-0.0425
   Val:   Loss=0.0848, RMSE=0.2912, R²=-0.0382
============================================================


============================================================
🔄 Round 54 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0886 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0886, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0886, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0886, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0886, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0886, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0886)

============================================================
📊 Round 54 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0879, RMSE=0.2965, R²=-0.0438
   Val:   Loss=0.0886, RMSE=0.2977, R²=-0.0324
============================================================


============================================================
🔄 Round 55 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0937 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0937, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0937, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0937, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0937, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0936, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0937)

============================================================
📊 Round 55 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2943, R²=-0.0362
   Val:   Loss=0.0937, RMSE=0.3061, R²=-0.0644
============================================================


📊 Round 55 Test Metrics:
   Loss: 0.0829, RMSE: 0.2878, MAE: 0.2479, R²: -0.0350

============================================================
🔄 Round 56 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0911 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0911, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0911, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0911, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0911, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0866, val=0.0911, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0911)

============================================================
📊 Round 56 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0873, RMSE=0.2954, R²=-0.0412
   Val:   Loss=0.0911, RMSE=0.3017, R²=-0.0436
============================================================


📊 Round 56 Test Metrics:
   Loss: 0.0828, RMSE: 0.2878, MAE: 0.2479, R²: -0.0349

============================================================
🔄 Round 60 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0876, val=0.0872 (↓), lr=0.000001
   • Epoch   2/100: train=0.0876, val=0.0872, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0876, val=0.0871, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0876, val=0.0871, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0876, val=0.0871, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0875, val=0.0871, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0872)

============================================================
📊 Round 60 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0883, RMSE=0.2971, R²=-0.0365
   Val:   Loss=0.0872, RMSE=0.2952, R²=-0.0627
============================================================


============================================================
🔄 Round 61 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0893 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0893, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0893, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0893, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0893, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0893, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0893)

============================================================
📊 Round 61 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0877, RMSE=0.2962, R²=-0.0400
   Val:   Loss=0.0893, RMSE=0.2988, R²=-0.0477
============================================================


📊 Round 61 Test Metrics:
   Loss: 0.0828, RMSE: 0.2878, MAE: 0.2479, R²: -0.0349

📊 Round 61 Test Metrics:
   Loss: 0.0829, RMSE: 0.2878, MAE: 0.2479, R²: -0.0350

============================================================
🔄 Round 65 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0878, val=0.0909 (↓), lr=0.000001
   • Epoch   2/100: train=0.0878, val=0.0909, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0878, val=0.0909, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0878, val=0.0909, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0878, val=0.0909, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0877, val=0.0909, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0909)

============================================================
📊 Round 65 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0873, RMSE=0.2955, R²=-0.0479
   Val:   Loss=0.0909, RMSE=0.3014, R²=-0.0256
============================================================


============================================================
🔄 Round 66 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0875, val=0.0930 (↓), lr=0.000001
   • Epoch   2/100: train=0.0875, val=0.0930, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0875, val=0.0930, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0875, val=0.0930, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0875, val=0.0930, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0874, val=0.0930, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0930)

============================================================
📊 Round 66 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2946, R²=-0.0359
   Val:   Loss=0.0930, RMSE=0.3050, R²=-0.0660
============================================================


============================================================
🔄 Round 67 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0919, val=0.0698 (↓), lr=0.000001
   • Epoch   2/100: train=0.0919, val=0.0698, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0919, val=0.0698, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0919, val=0.0698, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0919, val=0.0698, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0919, val=0.0697, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0698)

============================================================
📊 Round 67 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0926, RMSE=0.3043, R²=-0.0458
   Val:   Loss=0.0698, RMSE=0.2641, R²=-0.0201
============================================================


============================================================
🔄 Round 68 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0889, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0889, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0889, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0889, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0889, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0888, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 68 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0889, RMSE=0.2982, R²=-0.0486
   Val:   Loss=0.0845, RMSE=0.2906, R²=-0.0138
============================================================


📊 Round 68 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2479, R²: -0.0352

============================================================
🔄 Round 70 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0941 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0941, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0940, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0940, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0940, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0940, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0941)

============================================================
📊 Round 70 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2942, R²=-0.0293
   Val:   Loss=0.0941, RMSE=0.3067, R²=-0.0942
============================================================


📊 Round 70 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2479, R²: -0.0352

============================================================
🔄 Round 71 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0902, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0902, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0902, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0902, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0902, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0902, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 71 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0893, RMSE=0.2988, R²=-0.0434
   Val:   Loss=0.0830, RMSE=0.2881, R²=-0.0381
============================================================


============================================================
🔄 Round 73 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0873, val=0.0910 (↓), lr=0.000001
   • Epoch   2/100: train=0.0873, val=0.0910, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0873, val=0.0910, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0873, val=0.0910, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0873, val=0.0910, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0872, val=0.0911, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0910)

============================================================
📊 Round 73 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0873, RMSE=0.2955, R²=-0.0370
   Val:   Loss=0.0910, RMSE=0.3017, R²=-0.0754
============================================================


============================================================
🔄 Round 74 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0921, val=0.0724 (↓), lr=0.000001
   • Epoch   2/100: train=0.0921, val=0.0724, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0921, val=0.0724, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0921, val=0.0724, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0921, val=0.0724, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0920, val=0.0724, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0724)

============================================================
📊 Round 74 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0919, RMSE=0.3032, R²=-0.0448
   Val:   Loss=0.0724, RMSE=0.2691, R²=-0.0256
============================================================


📊 Round 74 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2479, R²: -0.0352

============================================================
🔄 Round 76 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0876, val=0.0901 (↓), lr=0.000001
   • Epoch   2/100: train=0.0876, val=0.0901, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0876, val=0.0901, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0876, val=0.0901, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0876, val=0.0901, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0875, val=0.0901, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0901)

============================================================
📊 Round 76 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0875, RMSE=0.2959, R²=-0.0402
   Val:   Loss=0.0901, RMSE=0.3001, R²=-0.0561
============================================================


📊 Round 76 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2480, R²: -0.0353

============================================================
🔄 Round 77 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0875, val=0.0916 (↓), lr=0.000001
   • Epoch   2/100: train=0.0874, val=0.0916, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0874, val=0.0916, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0874, val=0.0916, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0874, val=0.0916, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0874, val=0.0916, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0916)

============================================================
📊 Round 77 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0871, RMSE=0.2952, R²=-0.0462
   Val:   Loss=0.0916, RMSE=0.3027, R²=-0.0272
============================================================


📊 Round 77 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2480, R²: -0.0353

============================================================
🔄 Round 78 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0879, val=0.0865 (↓), lr=0.000001
   • Epoch   2/100: train=0.0879, val=0.0865, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0879, val=0.0865, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0879, val=0.0865, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0879, val=0.0865, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0878, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0865)

============================================================
📊 Round 78 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0884, RMSE=0.2974, R²=-0.0470
   Val:   Loss=0.0865, RMSE=0.2941, R²=-0.0380
============================================================


📊 Round 78 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2479, R²: -0.0352

============================================================
🔄 Round 84 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0899, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0899, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0899, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0899, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0899, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0898, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 84 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0899, RMSE=0.2999, R²=-0.0409
   Val:   Loss=0.0804, RMSE=0.2835, R²=-0.0474
============================================================


============================================================
🔄 Round 86 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0894, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0894, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0894, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0894, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0894, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0894, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 86 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0902, RMSE=0.3003, R²=-0.0403
   Val:   Loss=0.0795, RMSE=0.2820, R²=-0.0470
============================================================


📊 Round 86 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2480, R²: -0.0352

============================================================
🔄 Round 87 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0889, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0889, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0889, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0889, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0889, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0888, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 87 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0888, RMSE=0.2979, R²=-0.0439
   Val:   Loss=0.0851, RMSE=0.2918, R²=-0.0429
============================================================


📊 Round 87 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2480, R²: -0.0352

============================================================
🔄 Round 90 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0875, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0875, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0875, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0875, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0875, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0874, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 90 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0895, RMSE=0.2991, R²=-0.0457
   Val:   Loss=0.0823, RMSE=0.2868, R²=-0.0338
============================================================


============================================================
🔄 Round 91 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0869, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0869, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0868, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0868, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0868, val=0.0864, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0868, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 91 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0885, RMSE=0.2974, R²=-0.0382
   Val:   Loss=0.0864, RMSE=0.2939, R²=-0.0586
============================================================


📊 Round 91 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2480, R²: -0.0353

============================================================
🔄 Round 94 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0872, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0872, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0872, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0872, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0872, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0871, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 94 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0885, RMSE=0.2976, R²=-0.0428
   Val:   Loss=0.0860, RMSE=0.2933, R²=-0.0371
============================================================


============================================================
🔄 Round 97 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0942 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0942, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0942, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0942, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0942, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0942, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0942)

============================================================
📊 Round 97 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2941, R²=-0.0463
   Val:   Loss=0.0942, RMSE=0.3070, R²=-0.0268
============================================================


📊 Round 97 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2480, R²: -0.0353

============================================================
🔄 Round 98 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0888, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0888, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0888, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0888, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0888, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0888, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 98 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0888, RMSE=0.2979, R²=-0.0462
   Val:   Loss=0.0852, RMSE=0.2919, R²=-0.0236
============================================================


📊 Round 98 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2480, R²: -0.0353

============================================================
🔄 Round 101 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0873, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0873, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0873, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0873, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0873, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0872, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 101 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0889, RMSE=0.2982, R²=-0.0381
   Val:   Loss=0.0845, RMSE=0.2907, R²=-0.0570
============================================================


📊 Round 101 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2480, R²: -0.0353

============================================================
🔄 Round 105 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0941 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0941, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0941, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0941, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0941, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0941, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0941)

============================================================
📊 Round 105 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2941, R²=-0.0422
   Val:   Loss=0.0941, RMSE=0.3068, R²=-0.0414
============================================================


📊 Round 105 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2480, R²: -0.0354

📊 Round 105 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2480, R²: -0.0354

============================================================
🔄 Round 109 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0953 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0953, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0953, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0953, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0953, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0953, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0953)

============================================================
📊 Round 109 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2937, R²=-0.0314
   Val:   Loss=0.0953, RMSE=0.3087, R²=-0.1004
============================================================


============================================================
🔄 Round 112 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0870, val=0.0883 (↓), lr=0.000001
   • Epoch   2/100: train=0.0870, val=0.0883, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0870, val=0.0883, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0870, val=0.0883, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0870, val=0.0883, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0869, val=0.0883, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0883)

============================================================
📊 Round 112 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0880, RMSE=0.2966, R²=-0.0463
   Val:   Loss=0.0883, RMSE=0.2972, R²=-0.0315
============================================================


📊 Round 112 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2480, R²: -0.0354

============================================================
🔄 Round 114 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0982 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0982, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0982, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0982, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0982, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0983, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0982)

============================================================
📊 Round 114 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2924, R²=-0.0381
   Val:   Loss=0.0982, RMSE=0.3134, R²=-0.0753
============================================================


📊 Round 114 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2480, R²: -0.0354

📊 Round 114 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2480, R²: -0.0355

============================================================
🔄 Round 118 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0881, val=0.0893 (↓), lr=0.000001
   • Epoch   2/100: train=0.0881, val=0.0893, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0881, val=0.0893, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0881, val=0.0893, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0881, val=0.0893, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0880, val=0.0893, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0893)

============================================================
📊 Round 118 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0877, RMSE=0.2962, R²=-0.0421
   Val:   Loss=0.0893, RMSE=0.2989, R²=-0.0422
============================================================


============================================================
🔄 Round 120 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0886, val=0.0899 (↓), lr=0.000001
   • Epoch   2/100: train=0.0886, val=0.0899, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0886, val=0.0899, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0886, val=0.0899, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0885, val=0.0899, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0885, val=0.0899, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0899)

============================================================
📊 Round 120 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0876, RMSE=0.2960, R²=-0.0422
   Val:   Loss=0.0899, RMSE=0.2998, R²=-0.0398
============================================================


📊 Round 120 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2481, R²: -0.0356

📊 Round 120 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2481, R²: -0.0356

============================================================
🔄 Round 124 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0982 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0982, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0982, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0982, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0982, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0982, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0982)

============================================================
📊 Round 124 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2924, R²=-0.0504
   Val:   Loss=0.0982, RMSE=0.3134, R²=-0.0144
============================================================


📊 Round 124 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2481, R²: -0.0356

============================================================
🔄 Round 126 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0903, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0903, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0903, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0903, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0903, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0902, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 126 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0889, RMSE=0.2981, R²=-0.0459
   Val:   Loss=0.0848, RMSE=0.2913, R²=-0.0368
============================================================


📊 Round 126 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2480, R²: -0.0355

============================================================
🔄 Round 128 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0912, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0912, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0912, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0912, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0912, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0911, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 128 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0892, RMSE=0.2987, R²=-0.0490
   Val:   Loss=0.0835, RMSE=0.2889, R²=-0.0140
============================================================


============================================================
🔄 Round 131 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.1020 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.1020, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.1020, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.1020, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.1020, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.1020, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.1020)

============================================================
📊 Round 131 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2908, R²=-0.0333
   Val:   Loss=0.1020, RMSE=0.3194, R²=-0.0821
============================================================


📊 Round 131 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2480, R²: -0.0354

============================================================
🔄 Round 133 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0910, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0910, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0910, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0910, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0910, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0909, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 133 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0889, RMSE=0.2982, R²=-0.0470
   Val:   Loss=0.0847, RMSE=0.2910, R²=-0.0205
============================================================


📊 Round 133 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2480, R²: -0.0353

============================================================
🔄 Round 135 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0888, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0888, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0888, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0888, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0888, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0887, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 135 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0889, RMSE=0.2981, R²=-0.0440
   Val:   Loss=0.0847, RMSE=0.2911, R²=-0.0327
============================================================


============================================================
🔄 Round 136 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0910 (↓), lr=0.000001
   • Epoch   2/100: train=0.0867, val=0.0910, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0867, val=0.0910, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0910, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0910, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0866, val=0.0910, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0910)

============================================================
📊 Round 136 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0873, RMSE=0.2955, R²=-0.0499
   Val:   Loss=0.0910, RMSE=0.3017, R²=-0.0229
============================================================


============================================================
🔄 Round 137 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0895, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0895, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0895, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0895, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0895, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0895, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 137 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0904, RMSE=0.3006, R²=-0.0440
   Val:   Loss=0.0788, RMSE=0.2807, R²=-0.0501
============================================================


📊 Round 137 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2480, R²: -0.0352

📊 Round 137 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2480, R²: -0.0352

📊 Round 137 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2480, R²: -0.0353

📊 Round 137 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2480, R²: -0.0353

============================================================
🔄 Round 143 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0918 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0918, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0918, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0918, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0918, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0917, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0918)

============================================================
📊 Round 143 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0871, RMSE=0.2952, R²=-0.0444
   Val:   Loss=0.0918, RMSE=0.3029, R²=-0.0320
============================================================


📊 Round 143 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2480, R²: -0.0354

============================================================
🔄 Round 144 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0962 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0962, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0962, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0962, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0962, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0962, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0962)

============================================================
📊 Round 144 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2933, R²=-0.0360
   Val:   Loss=0.0962, RMSE=0.3102, R²=-0.0640
============================================================


📊 Round 144 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2480, R²: -0.0354

📊 Round 144 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2480, R²: -0.0354

📊 Round 144 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2480, R²: -0.0354

============================================================
🔄 Round 148 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0957 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0957, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0957, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0957, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0957, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0957, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0957)

============================================================
📊 Round 148 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2935, R²=-0.0342
   Val:   Loss=0.0957, RMSE=0.3093, R²=-0.0734
============================================================


📊 Round 148 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2480, R²: -0.0354

📊 Round 148 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2480, R²: -0.0354

============================================================
🔄 Round 151 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0935 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0934, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0934, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0934, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0934, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0934, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0935)

============================================================
📊 Round 151 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0867, RMSE=0.2945, R²=-0.0378
   Val:   Loss=0.0935, RMSE=0.3057, R²=-0.0587
============================================================


📊 Round 151 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2480, R²: -0.0354

============================================================
🔄 Round 154 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0876 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0876, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0876, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0876, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0876, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0876, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0876)

============================================================
📊 Round 154 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0882, RMSE=0.2970, R²=-0.0387
   Val:   Loss=0.0876, RMSE=0.2960, R²=-0.0551
============================================================


📊 Round 154 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2480, R²: -0.0355

📊 Round 154 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2480, R²: -0.0355

============================================================
🔄 Round 156 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0879, val=0.0867 (↓), lr=0.000001
   • Epoch   2/100: train=0.0879, val=0.0867, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0879, val=0.0867, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0879, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0878, val=0.0867, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0878, val=0.0867, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 156 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0884, RMSE=0.2973, R²=-0.0389
   Val:   Loss=0.0867, RMSE=0.2944, R²=-0.0576
============================================================


============================================================
🔄 Round 157 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0888, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0888, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0888, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0888, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0888, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0888, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 157 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0892, RMSE=0.2987, R²=-0.0386
   Val:   Loss=0.0834, RMSE=0.2888, R²=-0.0569
============================================================


📊 Round 157 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2480, R²: -0.0355

============================================================
🔄 Round 159 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0898, val=0.0881 (↓), lr=0.000001
   • Epoch   2/100: train=0.0898, val=0.0881, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0897, val=0.0881, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0897, val=0.0881, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0897, val=0.0881, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0896, val=0.0880, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0881)

============================================================
📊 Round 159 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0881, RMSE=0.2968, R²=-0.0437
   Val:   Loss=0.0881, RMSE=0.2968, R²=-0.0348
============================================================


📊 Round 159 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2480, R²: -0.0354

============================================================
🔄 Round 160 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0907, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0907, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0907, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0907, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0906, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0906, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 160 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0890, RMSE=0.2983, R²=-0.0431
   Val:   Loss=0.0844, RMSE=0.2906, R²=-0.0428
============================================================


============================================================
🔄 Round 162 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0973 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0973, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0973, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0973, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0973, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0973, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0973)

============================================================
📊 Round 162 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2929, R²=-0.0387
   Val:   Loss=0.0973, RMSE=0.3119, R²=-0.0579
============================================================


============================================================
🔄 Round 163 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0888, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0888, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0888, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0887, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0887, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0886, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 163 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0889, RMSE=0.2981, R²=-0.0416
   Val:   Loss=0.0849, RMSE=0.2914, R²=-0.0599
============================================================


📊 Round 163 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2480, R²: -0.0354

============================================================
🔄 Round 166 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0872, val=0.0933 (↓), lr=0.000001
   • Epoch   2/100: train=0.0872, val=0.0933, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0872, val=0.0933, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0872, val=0.0933, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0872, val=0.0933, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0871, val=0.0933, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0933)

============================================================
📊 Round 166 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2945, R²=-0.0438
   Val:   Loss=0.0933, RMSE=0.3055, R²=-0.0638
============================================================


============================================================
🔄 Round 168 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0872, val=0.0905 (↓), lr=0.000001
   • Epoch   2/100: train=0.0872, val=0.0905, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0872, val=0.0904, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0872, val=0.0905, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0872, val=0.0905, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0871, val=0.0905, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0905)

============================================================
📊 Round 168 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0875, RMSE=0.2958, R²=-0.0465
   Val:   Loss=0.0905, RMSE=0.3008, R²=-0.0275
============================================================


📊 Round 168 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2480, R²: -0.0353

============================================================
🔄 Round 169 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0880, val=0.0875 (↓), lr=0.000001
   • Epoch   2/100: train=0.0880, val=0.0875, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0880, val=0.0875, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0880, val=0.0875, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0880, val=0.0875, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0880, val=0.0875, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0875)

============================================================
📊 Round 169 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0882, RMSE=0.2970, R²=-0.0494
   Val:   Loss=0.0875, RMSE=0.2958, R²=-0.0125
============================================================


📊 Round 169 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2480, R²: -0.0354

============================================================
🔄 Round 173 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0900, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0900, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0900, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0900, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0900, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0900, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 173 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0902, RMSE=0.3004, R²=-0.0430
   Val:   Loss=0.0794, RMSE=0.2818, R²=-0.0436
============================================================


📊 Round 173 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2480, R²: -0.0355

============================================================
🔄 Round 178 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0875, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0875, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0875, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0875, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0875, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0875, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 178 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0888, RMSE=0.2979, R²=-0.0462
   Val:   Loss=0.0853, RMSE=0.2921, R²=-0.0248
============================================================


📊 Round 178 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2480, R²: -0.0353

============================================================
🔄 Round 184 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.1005 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.1005, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.1005, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.1005, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.1005, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.1004, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.1005)

============================================================
📊 Round 184 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2915, R²=-0.0375
   Val:   Loss=0.1005, RMSE=0.3170, R²=-0.0666
============================================================


============================================================
🔄 Round 185 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0960 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0960, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0960, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0960, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0960, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0960, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0960)

============================================================
📊 Round 185 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2934, R²=-0.0359
   Val:   Loss=0.0960, RMSE=0.3099, R²=-0.0656
============================================================


📊 Round 185 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2480, R²: -0.0353

============================================================
🔄 Round 186 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0913, val=0.0735 (↓), lr=0.000001
   • Epoch   2/100: train=0.0913, val=0.0735, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0913, val=0.0735, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0913, val=0.0735, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0913, val=0.0735, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0912, val=0.0735, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0735)

============================================================
📊 Round 186 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0917, RMSE=0.3028, R²=-0.0391
   Val:   Loss=0.0735, RMSE=0.2711, R²=-0.0598
============================================================


============================================================
🔄 Round 187 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0932 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0932, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0932, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0932, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0932, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0931, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0932)

============================================================
📊 Round 187 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2946, R²=-0.0405
   Val:   Loss=0.0932, RMSE=0.3052, R²=-0.0571
============================================================


📊 Round 187 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2480, R²: -0.0352

============================================================
🔄 Round 188 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0899, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0899, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0899, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0899, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0899, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0898, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 188 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0888, RMSE=0.2979, R²=-0.0410
   Val:   Loss=0.0853, RMSE=0.2920, R²=-0.0549
============================================================


📊 Round 188 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2480, R²: -0.0352

📊 Round 188 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2480, R²: -0.0352

============================================================
🔄 Round 190 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0912, val=0.0768 (↓), lr=0.000001
   • Epoch   2/100: train=0.0912, val=0.0768, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0911, val=0.0768, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0911, val=0.0769, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0911, val=0.0769, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0910, val=0.0769, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0768)

============================================================
📊 Round 190 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0909, RMSE=0.3015, R²=-0.0484
   Val:   Loss=0.0768, RMSE=0.2772, R²=-0.0316
============================================================


📊 Round 190 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2480, R²: -0.0352

============================================================
🔄 Round 194 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0934 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0934, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0934, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0934, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0934, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0933, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0934)

============================================================
📊 Round 194 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2945, R²=-0.0446
   Val:   Loss=0.0934, RMSE=0.3056, R²=-0.0327
============================================================


📊 Round 194 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2480, R²: -0.0352

============================================================
🔄 Round 196 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0964 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0964, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0964, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0964, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0964, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0965, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0964)

============================================================
📊 Round 196 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2933, R²=-0.0377
   Val:   Loss=0.0964, RMSE=0.3105, R²=-0.0740
============================================================


============================================================
🔄 Round 197 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0896, val=0.0776 (↓), lr=0.000001
   • Epoch   2/100: train=0.0896, val=0.0776, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0896, val=0.0776, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0896, val=0.0776, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0896, val=0.0776, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0896, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 197 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0907, RMSE=0.3011, R²=-0.0451
   Val:   Loss=0.0776, RMSE=0.2786, R²=-0.0274
============================================================


============================================================
🔄 Round 200 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0914, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0914, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0914, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0914, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0914, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0913, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 200 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0891, RMSE=0.2985, R²=-0.0420
   Val:   Loss=0.0839, RMSE=0.2897, R²=-0.0486
============================================================


============================================================
🔄 Round 201 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0900, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0900, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0900, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0900, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0900, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0899, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 201 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0897, RMSE=0.2994, R²=-0.0392
   Val:   Loss=0.0817, RMSE=0.2859, R²=-0.0606
============================================================


📊 Round 201 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2480, R²: -0.0352

📊 Round 201 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2479, R²: -0.0351

============================================================
🔄 Round 205 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0909, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0909, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0909, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0909, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0908, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0907, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 205 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0894, RMSE=0.2990, R²=-0.0502
   Val:   Loss=0.0827, RMSE=0.2876, R²=-0.1073
============================================================


📊 Round 205 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2480, R²: -0.0351

============================================================
🔄 Round 206 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0952 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0952, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0952, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0952, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0952, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0952, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0952)

============================================================
📊 Round 206 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2938, R²=-0.0349
   Val:   Loss=0.0952, RMSE=0.3086, R²=-0.0699
============================================================


📊 Round 206 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2480, R²: -0.0352

📊 Round 206 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2480, R²: -0.0353

📊 Round 206 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2480, R²: -0.0353

📊 Round 206 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2480, R²: -0.0354

📊 Round 206 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2480, R²: -0.0354

📊 Round 206 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2480, R²: -0.0353

📊 Round 206 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2480, R²: -0.0353

📊 Round 206 Test Metrics:
   Loss: 0.0829, RMSE: 0.2879, MAE: 0.2480, R²: -0.0353

============================================================
🔄 Round 223 - Client client_5
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0950 (↓), lr=0.000001
   • Epoch   2/100: train=0.0867, val=0.0950, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0867, val=0.0950, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0867, val=0.0950, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0867, val=0.0950, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0866, val=0.0950, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0950)

============================================================
📊 Round 223 Summary - Client client_5
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2938, R²=-0.0429
   Val:   Loss=0.0950, RMSE=0.3082, R²=-0.0419
============================================================


❌ Client client_5 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8687 {grpc_status:14, grpc_message:"Socket closed"}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8687 {grpc_status:14, grpc_message:"Socket closed"}"
>
