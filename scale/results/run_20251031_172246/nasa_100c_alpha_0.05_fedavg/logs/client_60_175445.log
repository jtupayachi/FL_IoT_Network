[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4df96155-4fa9-4f54-bb7b-e5504c12b1f3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7ea17580-dd77-41eb-8313-1ba3d292d105
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a51f46a6-3569-4d07-8370-e43c00c88212
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message af178f9f-7126-49d9-b184-6355aa002815
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3089079b-dd36-42ae-a60c-6301f7f90112
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 238a3ff6-c869-48dd-9597-13ef44283778
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ab79a486-1bcf-453d-82c6-100d1a6a69cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4495f912-6cfc-4fac-bcc0-f81e21424b7f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4943ca15-8278-48c9-bc9c-d930b0cdf141
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 658ca01f-2a8b-4353-9112-50ec25204064
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 82686ab9-f383-4e9b-9829-58a1646b166a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dd75bcbd-c745-4d86-aa3f-62e1b20d00e8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2929d9ea-b9bf-4d31-834a-ab799111177a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 06c6742c-5f77-468b-a00d-ae9bf977b838
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ed234d5b-df6a-4cd2-9d7d-742f1965eb93
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message be96eb29-dd87-47f4-9ce8-b81af3779854
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a4fb41cc-456a-4895-856c-86af9036222f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 36235f41-20fe-43fd-9e62-4e8563f67a3d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7b973e43-ddee-4b5b-ab9f-7603bd8caf1b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 257257f1-55af-4ca1-8bff-4339275fa39b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message faa65f52-83f0-468a-b40c-a759eb8702b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5d962aff-250d-4bab-bca9-a75cecc742d5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7bcd759e-63f0-4f43-aebc-9675815ab521
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 93cd6c9e-a72a-4d77-bf6c-65d2758e5b7b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 976962ee-c018-4560-8c98-73402f062624
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aaf8566c-27df-4d15-b02e-3a4135dd5aa6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bf6e2b46-f8e0-43a8-adf0-fbef155f485e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 84d86626-fdb2-4116-ad9e-aa65dab115aa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b49680c9-c4fb-4cf9-b928-091c34e75efb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6304301e-56e2-4617-b65e-ee99b3bb0b1b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1bbb128b-0022-4069-ad56-845d0c6e1992
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6ec60463-8d1d-47f9-b1ea-4c346a98cd23
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 15bcec96-ca52-4159-9340-ae2e4d9aadc9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 31043e33-6bcc-4af5-be58-a128629bf7d8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c609e805-a054-44e1-8001-75ba6dba602e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 332a3b74-777a-4261-b610-743bf5f87328
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0766df53-3def-4613-bf27-6f66a1b3d4b5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ee882269-b09d-4dbb-839b-316b9814169a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5f2ff468-1cd0-45ed-891d-758efc2bd15a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dd1c90c3-f5eb-4f13-93b1-f1b28b480af9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8930f9a4-dd46-4f47-ba5b-cbcf3be5b7bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e8344f46-5af1-4539-bd59-0d547e59e49d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9c9e1825-3e88-48b1-9c30-59c0e24996ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e6dc2f5b-c2c9-499a-a3d2-5aa4c8153b7f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 969ee0e7-9757-4004-aa8b-7b02c3558789
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9020d36e-5682-4c4d-8384-0625d63af693
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6b5a770b-a7ea-4357-91f1-1e18ace3ab72
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c6826075-1a7f-4e77-a052-66d3e55c3829
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1a89de54-32f5-4ead-912a-16c9fbdab13a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 05e1211f-823b-4f95-8705-2c49ac3a3a0a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 30b726aa-4de5-45d4-ae4b-4bd626111324
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 20e8354c-805d-41cf-ac26-725e511782a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e7ebbff6-8b3f-4915-9290-8cdf192ff3fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4f50d7b1-1b91-44bf-844d-b8df17fb6c77
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 92484b0e-7a51-4a2d-89d7-bc72873b9ebe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 981236d9-ef07-4c38-87c4-692d7274ade1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2f7220c1-b2d9-42ab-b451-8094142f4f1f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 86ba264f-51c5-4d3d-a4a9-0fe31d5adeca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 08e19e73-664c-4ef5-8f2b-b6677f3509f8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d15b95b6-631c-4bdf-88b0-e73546daefbb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ba29756b-349f-4e20-903d-28ea9737ce8d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f7df8514-6357-4c3e-b217-2446a4ab8efa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cb8e026a-8ebe-4c9c-94fe-50c69b853b0f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dd0c3c80-ca20-4e3e-9051-15fa1308f531
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message edbad1df-149e-4062-ab46-10d92ebaeef8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fc4c5e51-7d2e-484e-b2a4-fb5bd01aa6ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ffacc7de-77e7-4575-9c82-a015a2acd963
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c9f0d5dd-71be-4a8a-b3db-bbe784502c63
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0bb46242-ad65-4d58-a014-7981fa61ef3f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e8176875-01c8-47b8-9184-58f19ecbf1ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c558deae-ff6b-434d-b933-52585d1ad1e0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dd13225f-1b86-4c1f-91cb-62eb221f03bd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2b8ce2d8-06f8-4f3d-b032-cff0782d6dce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 69a5ba6b-2aa9-424a-abb9-6948072d9794
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8188a74b-c093-45e9-ace0-c217ef98671c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1d453caf-c6b5-4b67-8ba8-1a1ace44f4a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c1ab34ba-dc14-437d-950c-adccae3998aa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7ce17882-840b-4074-8e5d-be48302f03df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e3d3ffd6-5393-485a-82f5-1fb321351656
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d0057be5-33fc-41af-bf72-1e3cf4fe19b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4070d137-4183-4151-967f-2ce5a8bb6613
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 14e95513-8d59-4e08-ac89-305e832cc1df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 376640a0-6b20-4c29-aa19-68603678c2e9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 98fc7e3d-83e2-4f60-a9f7-acd3bc9e3f21
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5eae342a-e304-4670-b34a-5f31997ec792
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 32534090-8379-46c5-9dc6-11d0158e7378
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 96811c3e-cb7c-4d3a-a4fb-3816665b372a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b880d87c-0bb0-438e-a9ad-867dfeabfdf3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c876984c-35f6-404b-a5a0-037715d18a9d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9a63717a-5cb7-4f86-ae14-376afd5ff59b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 48e164cf-babe-49ed-96ff-cb779fba570f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0e6f4969-9686-48cf-a813-78edcbdff074
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 97de57a9-a3c7-42ff-9b31-367905dbd5e9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0769e3e6-0795-40b8-b04b-ee0b8f22fb12
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4f9b94bb-43ae-4d5a-aca4-76fcd4c2cd9a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 96c5795b-327b-430b-a626-285a767aaa6f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0f25305d-b2be-45b6-8f01-8a5bde061b5b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dd6a0e5d-fd80-4154-ba30-fbc229d24916
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2dce72ca-eed0-404a-bc2b-5c6a2df23a2a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 695dbcb1-5bcf-4339-b373-ea807a80d8a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3dc3123d-5999-46fb-9c0d-55794b5a094e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0b3203e9-47b3-4cf8-8392-dea1963533b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b0be0a1e-8f6b-42cc-862d-ab75b9d87d04
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 915fe25e-a13e-40b9-9295-0063f73bed91
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 59cd80ef-dd82-4197-8343-ebeee47dd42b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6a85617f-4d75-472b-8fae-7b4d25a59a69
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b61c2328-ea01-4155-8dd9-c27af1b4345e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6c2b5fd8-3b5b-4bda-8170-8e2e0ed58b15
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e47e8396-a420-4a82-bd2a-b858b213238a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b5036be3-578c-47d6-8279-90339022bba4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c35a3dfd-8291-411a-86a7-7ba28bb16417
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4b7021cd-35c6-4192-8e60-a43ad2b23af4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a97a6da9-fbac-4abc-8a44-43d85db00696
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 82e18d90-00bf-4d6c-a0bc-44b6cbbf87e8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c26f913c-8438-4bb1-943d-7d465acabb67
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 70a2d05d-e798-403e-b481-ae687f3673a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b813006f-a49f-4308-a87c-18e36b2bcbeb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message af74b4b7-f5f6-4126-ae65-407aac8f9fe1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2de8afd4-c692-4e22-9210-0d6dadecd2c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 70fe8e0b-e802-4a7e-960f-5f256852451e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3dc2f078-1115-440b-8222-1bf6a5e3c46d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5a4fdcff-0475-42a5-b53b-8eb0f86210e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8a35f6d8-c298-4609-a7e3-49de3ee7959f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9179d3f3-250c-40f4-ac54-90d64dc8166a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5f6d934d-2dba-4373-ad1d-a2e7b1fa9162
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 98d8cfb8-f4f4-4337-bad9-c1a162d3e6b8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4c031c27-ebc5-43cf-9161-683cb6b29b19
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d8b55664-5413-40d6-9540-7c6b4e538847
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6ad9136d-f388-4363-b712-d3c9d2bb3ee7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4e5947e9-a34e-4ef3-bd20-b2500a0f11a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a8c5211e-fe92-4ecb-8271-d87470fa7e44
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bc142bdc-1d92-4a7d-9ed7-1c4590f0a958
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f8e71ad7-cf96-4416-a2b2-9050ca3c4e05
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1c444248-e049-4fbc-a6c6-3cff5fdf2c04
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 13d3a336-7ea9-4293-8389-bb511c5a4e97
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8e7abcb6-f98c-4d69-a022-232bfcbc6fed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b28ac5ed-649b-426c-8ede-6cbc83ed2e22
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 161f18f2-22aa-41c1-a38e-d75ca16d3626
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 101761d1-ce77-49fd-ae2e-68b2c344ed96
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7b232575-e939-46e4-9f29-31a2c426ff18
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cb0181bc-0a27-4632-8507-d672a6424699
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d3ac173d-75e4-44b6-8d05-ad2eb6e65f57
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 523ed748-e891-48ff-a560-a9a7d9f0af28
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f9f0d59c-74e4-4f13-941b-6bd47cfd55dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0db6e244-76e3-49f1-98e1-cf6261e03ae9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 39217b55-104d-4727-a4c2-13a9f4b33356
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 02afec89-3c88-4616-bec9-cb90beff7167
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0a7d9782-f217-426c-ae42-0a334d0a510a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0badc121-3767-48ed-afd4-c943e14d29df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9bc0b9fd-e865-475c-b6d5-f9612fb9030d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f879c77d-e2d6-498f-8268-ed0f1e219992
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e73387ce-903e-41ef-a3a8-f6635af0851a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d17d34d0-275a-4df9-a191-b5dbe5c5b7f2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 131016ec-27ba-4f6e-ae5c-f45a764f0450
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 69fbe0e1-696f-4618-8e31-11e8607fe095
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4bd6e32f-b914-4bf5-ad2b-5b0e8c72c02f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 24f4c49d-31e3-4bdc-8ebe-119982da7725
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2e929ec3-34a6-46a9-ba46-3f2a46d57004
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e7ceebe7-49a5-40b8-ba52-c5c8db867e7a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7f17c0f4-27a1-4e64-a8c2-80d7024bf795
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 483eecf3-93e0-469b-8568-965c32903291
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2c0898a8-e328-437b-b2cd-892d0c3ae824
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 259e9311-0516-48a8-a710-6b4148f20410
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 63ff633a-d234-4073-9101-dec157a0d6b5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4d8ab0e1-46fe-47bd-b306-ebd1c0c145c9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 359b71b5-a927-4652-8515-104dbcf9b115
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b1e8dd4f-0e0a-4b30-afb0-3c8015689b9d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2cca5953-1858-48ce-8c63-a96752652517
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cb46fb99-8ab5-483c-91ef-9c29765ad6e1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aaa56115-b496-479c-9380-7091ea24579e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 44402d4b-e374-440a-9672-4e4cec595dca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1dc9747a-72b2-4e5a-af57-1b0290d2d935
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 538d5b81-e098-4110-a69c-cf86289be609
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7fe1dee7-6f91-42b5-8487-9bd623b186de
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ba8e9355-6135-4f2d-a20f-64a1d756b8cb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 43d7788d-93ee-481f-b49d-24908384d75f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e93c2d53-e241-4fb6-acb1-f8f7228e530f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 34d06970-6d31-4d85-b198-f5d52403ebc3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 58dd8ac6-a7d1-4a2d-b6b5-b2cc81d103d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3dba4d15-e96b-45c5-b3bb-1e9c325f5661
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b23191d4-cfd1-456c-8a40-e82373edd593
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c9d93791-e21f-4fc2-8d60-f3b04dc27026
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a33f0bdc-f128-45ef-917d-e55eee42e215
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "recvmsg:Connection reset by peer"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8687 {grpc_message:"recvmsg:Connection reset by peer", grpc_status:14}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_60
Server: localhost:8687
Algorithm: FEDAVG
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_60
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_60/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_60/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_60/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_60/test_labels.txt

📊 Raw data loaded:
   Train: X=(1436, 24), y=(1436,)
   Test:  X=(359, 24), y=(359,)

⚠️  Limiting training data: 1436 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  350 samples, 5 features
✅ Client client_60 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

============================================================
🔄 Round 5 - Client client_60
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0872 (↓), lr=0.001000
   ✓ Epoch   2/100: train=0.0764, val=0.0866 (↓), lr=0.001000
   ✓ Epoch   3/100: train=0.0748, val=0.0850 (↓), lr=0.001000
   ✓ Epoch   4/100: train=0.0731, val=0.0829 (↓), lr=0.001000
   ✓ Epoch   5/100: train=0.0712, val=0.0809 (↓), lr=0.001000
   • Epoch  11/100: train=0.0646, val=0.0769, patience=2/15, lr=0.001000
   • Epoch  21/100: train=0.0598, val=0.0762, patience=1/15, lr=0.001000
   📉 Epoch 26: LR reduced 0.001000 → 0.000500
   • Epoch  31/100: train=0.0533, val=0.0773, patience=11/15, lr=0.000500
   📉 Epoch 34: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0759)

============================================================
📊 Round 5 Summary - Client client_60
   Epochs: 35/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0583, RMSE=0.2414, R²=0.2736
   Val:   Loss=0.0759, RMSE=0.2755, R²=0.1666
============================================================


============================================================
🔄 Round 7 - Client client_60
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0744, val=0.0859 (↓), lr=0.000250
   • Epoch   2/100: train=0.0732, val=0.0859, patience=1/15, lr=0.000250
   • Epoch   3/100: train=0.0723, val=0.0856, patience=2/15, lr=0.000250
   ✓ Epoch   4/100: train=0.0716, val=0.0853 (↓), lr=0.000250
   • Epoch   5/100: train=0.0711, val=0.0849, patience=1/15, lr=0.000250
   📉 Epoch 7: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0689, val=0.0830, patience=2/15, lr=0.000125
   📉 Epoch 15: LR reduced 0.000125 → 0.000063
   • Epoch  21/100: train=0.0675, val=0.0813, patience=2/15, lr=0.000063
   📉 Epoch 23: LR reduced 0.000063 → 0.000031
   📉 Epoch 31: LR reduced 0.000031 → 0.000016
   • Epoch  31/100: train=0.0670, val=0.0805, patience=7/15, lr=0.000016
   📉 Epoch 39: LR reduced 0.000016 → 0.000008
   • Epoch  41/100: train=0.0668, val=0.0802, patience=8/15, lr=0.000008
   📉 Epoch 47: LR reduced 0.000008 → 0.000004

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 7 Summary - Client client_60
   Epochs: 48/100 (early stopped)
   LR: 0.000250 → 0.000004 (6 reductions)
   Train: Loss=0.0669, RMSE=0.2587, R²=0.1647
   Val:   Loss=0.0805, RMSE=0.2837, R²=0.1134
============================================================


============================================================
🔄 Round 9 - Client client_60
   Epochs: 100, Batch: 32, LR: 0.000004
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0755, val=0.0794 (↓), lr=0.000004
   • Epoch   2/100: train=0.0755, val=0.0794, patience=1/15, lr=0.000004
   • Epoch   3/100: train=0.0754, val=0.0794, patience=2/15, lr=0.000004
   • Epoch   4/100: train=0.0754, val=0.0794, patience=3/15, lr=0.000004
   • Epoch   5/100: train=0.0754, val=0.0793, patience=4/15, lr=0.000004
   📉 Epoch 7: LR reduced 0.000004 → 0.000002
   • Epoch  11/100: train=0.0752, val=0.0793, patience=10/15, lr=0.000002
   📉 Epoch 15: LR reduced 0.000002 → 0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 9 Summary - Client client_60
   Epochs: 16/100 (early stopped)
   LR: 0.000004 → 0.000001 (2 reductions)
   Train: Loss=0.0755, RMSE=0.2748, R²=0.0701
   Val:   Loss=0.0794, RMSE=0.2817, R²=0.0881
============================================================


📊 Round 9 Test Metrics:
   Loss: 0.0755, RMSE: 0.2748, MAE: 0.2358, R²: 0.0876

============================================================
🔄 Round 12 - Client client_60
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0752, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0752, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0752, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0752, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0752, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0751, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 12 Summary - Client client_60
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0754, RMSE=0.2747, R²=0.0756
   Val:   Loss=0.0784, RMSE=0.2800, R²=0.0744
============================================================


============================================================
🔄 Round 13 - Client client_60
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0765, val=0.0736 (↓), lr=0.000001
   • Epoch   2/100: train=0.0765, val=0.0736, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0765, val=0.0736, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0765, val=0.0736, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0765, val=0.0736, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0764, val=0.0736, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0736)

============================================================
📊 Round 13 Summary - Client client_60
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0765, RMSE=0.2766, R²=0.0750
   Val:   Loss=0.0736, RMSE=0.2714, R²=0.0939
============================================================


📊 Round 13 Test Metrics:
   Loss: 0.0753, RMSE: 0.2744, MAE: 0.2355, R²: 0.0900

📊 Round 13 Test Metrics:
   Loss: 0.0747, RMSE: 0.2733, MAE: 0.2344, R²: 0.0974

============================================================
🔄 Round 22 - Client client_60
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0759, val=0.0739 (↓), lr=0.000001
   • Epoch   2/100: train=0.0759, val=0.0739, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0759, val=0.0739, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0758, val=0.0739, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0758, val=0.0739, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0757, val=0.0738, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0739)

============================================================
📊 Round 22 Summary - Client client_60
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0756, RMSE=0.2749, R²=0.0855
   Val:   Loss=0.0739, RMSE=0.2718, R²=0.0797
============================================================


📊 Round 22 Test Metrics:
   Loss: 0.0747, RMSE: 0.2733, MAE: 0.2344, R²: 0.0976

============================================================
🔄 Round 24 - Client client_60
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0739, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0739, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0739, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0739, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0738, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0738, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 24 Summary - Client client_60
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0738, RMSE=0.2716, R²=0.0967
   Val:   Loss=0.0809, RMSE=0.2845, R²=0.0526
============================================================


📊 Round 24 Test Metrics:
   Loss: 0.0746, RMSE: 0.2731, MAE: 0.2342, R²: 0.0984

============================================================
🔄 Round 25 - Client client_60
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0743, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0743, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0742, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0742, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0742, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0741, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 25 Summary - Client client_60
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0744, RMSE=0.2728, R²=0.0884
   Val:   Loss=0.0783, RMSE=0.2798, R²=0.0856
============================================================


📊 Round 25 Test Metrics:
   Loss: 0.0746, RMSE: 0.2731, MAE: 0.2342, R²: 0.0984

📊 Round 25 Test Metrics:
   Loss: 0.0746, RMSE: 0.2731, MAE: 0.2342, R²: 0.0985

============================================================
🔄 Round 27 - Client client_60
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0754, val=0.0738 (↓), lr=0.000001
   • Epoch   2/100: train=0.0754, val=0.0738, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0754, val=0.0738, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0754, val=0.0738, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0754, val=0.0738, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0753, val=0.0737, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0738)

============================================================
📊 Round 27 Summary - Client client_60
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0755, RMSE=0.2748, R²=0.0944
   Val:   Loss=0.0738, RMSE=0.2716, R²=0.0490
============================================================


📊 Round 27 Test Metrics:
   Loss: 0.0746, RMSE: 0.2732, MAE: 0.2343, R²: 0.0983

============================================================
🔄 Round 28 - Client client_60
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0757, val=0.0734 (↓), lr=0.000001
   • Epoch   2/100: train=0.0757, val=0.0734, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0757, val=0.0734, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0757, val=0.0734, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0756, val=0.0733, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0756, val=0.0733, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0734)

============================================================
📊 Round 28 Summary - Client client_60
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0756, RMSE=0.2750, R²=0.0915
   Val:   Loss=0.0734, RMSE=0.2709, R²=0.0681
============================================================


📊 Round 28 Test Metrics:
   Loss: 0.0746, RMSE: 0.2732, MAE: 0.2343, R²: 0.0982

============================================================
🔄 Round 30 - Client client_60
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0762, val=0.0709 (↓), lr=0.000001
   • Epoch   2/100: train=0.0762, val=0.0709, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0762, val=0.0709, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0761, val=0.0709, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0761, val=0.0709, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0760, val=0.0708, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0709)

============================================================
📊 Round 30 Summary - Client client_60
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0763, RMSE=0.2762, R²=0.0841
   Val:   Loss=0.0709, RMSE=0.2663, R²=0.0995
============================================================


📊 Round 30 Test Metrics:
   Loss: 0.0746, RMSE: 0.2731, MAE: 0.2343, R²: 0.0983

============================================================
🔄 Round 31 - Client client_60
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0751, val=0.0750 (↓), lr=0.000001
   • Epoch   2/100: train=0.0751, val=0.0750, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0751, val=0.0750, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0751, val=0.0750, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0751, val=0.0750, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0750, val=0.0749, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0750)

============================================================
📊 Round 31 Summary - Client client_60
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0752, RMSE=0.2743, R²=0.0861
   Val:   Loss=0.0750, RMSE=0.2739, R²=0.0889
============================================================


============================================================
🔄 Round 33 - Client client_60
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0737, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0736, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0736, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0736, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0736, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0735, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 33 Summary - Client client_60
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0738, RMSE=0.2717, R²=0.0899
   Val:   Loss=0.0806, RMSE=0.2840, R²=0.0777
============================================================


📊 Round 33 Test Metrics:
   Loss: 0.0746, RMSE: 0.2731, MAE: 0.2342, R²: 0.0985

============================================================
🔄 Round 34 - Client client_60
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0761, val=0.0708 (↓), lr=0.000001
   • Epoch   2/100: train=0.0761, val=0.0708, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0760, val=0.0708, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0760, val=0.0708, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0760, val=0.0708, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0759, val=0.0708, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0708)

============================================================
📊 Round 34 Summary - Client client_60
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0763, RMSE=0.2762, R²=0.0958
   Val:   Loss=0.0708, RMSE=0.2662, R²=0.0272
============================================================


📊 Round 34 Test Metrics:
   Loss: 0.0746, RMSE: 0.2731, MAE: 0.2342, R²: 0.0985

📊 Round 34 Test Metrics:
   Loss: 0.0746, RMSE: 0.2731, MAE: 0.2342, R²: 0.0985

============================================================
🔄 Round 37 - Client client_60
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0768, val=0.0687 (↓), lr=0.000001
   • Epoch   2/100: train=0.0768, val=0.0687, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0768, val=0.0687, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0767, val=0.0687, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0767, val=0.0687, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0766, val=0.0686, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0687)

============================================================
📊 Round 37 Summary - Client client_60
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0768, RMSE=0.2771, R²=0.0900
   Val:   Loss=0.0687, RMSE=0.2622, R²=0.0765
============================================================


📊 Round 37 Test Metrics:
   Loss: 0.0746, RMSE: 0.2731, MAE: 0.2342, R²: 0.0985

📊 Round 37 Test Metrics:
   Loss: 0.0746, RMSE: 0.2731, MAE: 0.2342, R²: 0.0986

📊 Round 37 Test Metrics:
   Loss: 0.0746, RMSE: 0.2731, MAE: 0.2342, R²: 0.0986

📊 Round 37 Test Metrics:
   Loss: 0.0746, RMSE: 0.2731, MAE: 0.2342, R²: 0.0987

📊 Round 37 Test Metrics:
   Loss: 0.0746, RMSE: 0.2731, MAE: 0.2342, R²: 0.0988

📊 Round 37 Test Metrics:
   Loss: 0.0746, RMSE: 0.2731, MAE: 0.2342, R²: 0.0988

============================================================
🔄 Round 46 - Client client_60
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0762, val=0.0715 (↓), lr=0.000001
   • Epoch   2/100: train=0.0762, val=0.0715, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0761, val=0.0715, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0761, val=0.0715, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0761, val=0.0714, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0760, val=0.0714, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0715)

============================================================
📊 Round 46 Summary - Client client_60
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0761, RMSE=0.2759, R²=0.0849
   Val:   Loss=0.0715, RMSE=0.2674, R²=0.1009
============================================================


📊 Round 46 Test Metrics:
   Loss: 0.0746, RMSE: 0.2731, MAE: 0.2342, R²: 0.0988

============================================================
🔄 Round 47 - Client client_60
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0745, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0745, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0745, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0744, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0744, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0743, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 47 Summary - Client client_60
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0741, RMSE=0.2721, R²=0.0984
   Val:   Loss=0.0796, RMSE=0.2822, R²=0.0454
============================================================


============================================================
🔄 Round 48 - Client client_60
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0758, val=0.0729 (↓), lr=0.000001
   • Epoch   2/100: train=0.0758, val=0.0729, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0758, val=0.0729, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0758, val=0.0729, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0758, val=0.0728, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0757, val=0.0728, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0729)

============================================================
📊 Round 48 Summary - Client client_60
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0757, RMSE=0.2752, R²=0.0826
   Val:   Loss=0.0729, RMSE=0.2700, R²=0.1035
============================================================


============================================================
🔄 Round 49 - Client client_60
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0767, val=0.0700 (↓), lr=0.000001
   • Epoch   2/100: train=0.0767, val=0.0700, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0767, val=0.0700, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0767, val=0.0700, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0766, val=0.0700, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0766, val=0.0699, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0700)

============================================================
📊 Round 49 Summary - Client client_60
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0765, RMSE=0.2765, R²=0.0894
   Val:   Loss=0.0700, RMSE=0.2646, R²=0.0801
============================================================


============================================================
🔄 Round 50 - Client client_60
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0750, val=0.0767 (↓), lr=0.000001
   • Epoch   2/100: train=0.0750, val=0.0766, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0750, val=0.0766, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0750, val=0.0766, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0750, val=0.0766, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0749, val=0.0766, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0767)

============================================================
📊 Round 50 Summary - Client client_60
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0748, RMSE=0.2735, R²=0.0904
   Val:   Loss=0.0767, RMSE=0.2769, R²=0.0788
============================================================


============================================================
🔄 Round 51 - Client client_60
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0744, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0744, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0744, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0744, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0744, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0743, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 51 Summary - Client client_60
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0743, RMSE=0.2726, R²=0.0832
   Val:   Loss=0.0787, RMSE=0.2805, R²=0.1060
============================================================


============================================================
🔄 Round 52 - Client client_60
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0756, val=0.0726 (↓), lr=0.000001
   • Epoch   2/100: train=0.0756, val=0.0726, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0756, val=0.0726, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0756, val=0.0726, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0756, val=0.0726, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0755, val=0.0725, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0726)

============================================================
📊 Round 52 Summary - Client client_60
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0758, RMSE=0.2753, R²=0.0775
   Val:   Loss=0.0726, RMSE=0.2694, R²=0.1295
============================================================


📊 Round 52 Test Metrics:
   Loss: 0.0746, RMSE: 0.2731, MAE: 0.2342, R²: 0.0989

============================================================
🔄 Round 53 - Client client_60
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0750, val=0.0754 (↓), lr=0.000001
   • Epoch   2/100: train=0.0750, val=0.0754, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0750, val=0.0754, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0749, val=0.0754, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0749, val=0.0753, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0748, val=0.0753, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0754)

============================================================
📊 Round 53 Summary - Client client_60
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0751, RMSE=0.2741, R²=0.0898
   Val:   Loss=0.0754, RMSE=0.2746, R²=0.0798
============================================================


📊 Round 53 Test Metrics:
   Loss: 0.0746, RMSE: 0.2731, MAE: 0.2342, R²: 0.0987

📊 Round 53 Test Metrics:
   Loss: 0.0746, RMSE: 0.2731, MAE: 0.2342, R²: 0.0988

============================================================
🔄 Round 57 - Client client_60
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0768, val=0.0688 (↓), lr=0.000001
   • Epoch   2/100: train=0.0768, val=0.0688, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0768, val=0.0688, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0768, val=0.0688, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0768, val=0.0688, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0767, val=0.0687, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0688)

============================================================
📊 Round 57 Summary - Client client_60
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0767, RMSE=0.2770, R²=0.0778
   Val:   Loss=0.0688, RMSE=0.2624, R²=0.1287
============================================================


============================================================
🔄 Round 58 - Client client_60
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0743, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0743, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0743, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0743, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0743, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0742, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 58 Summary - Client client_60
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0743, RMSE=0.2726, R²=0.0907
   Val:   Loss=0.0786, RMSE=0.2803, R²=0.0783
============================================================


📊 Round 58 Test Metrics:
   Loss: 0.0746, RMSE: 0.2731, MAE: 0.2342, R²: 0.0988

============================================================
🔄 Round 59 - Client client_60
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0763, val=0.0715 (↓), lr=0.000001
   • Epoch   2/100: train=0.0763, val=0.0715, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0763, val=0.0714, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0763, val=0.0714, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0763, val=0.0714, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0762, val=0.0714, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0715)

============================================================
📊 Round 59 Summary - Client client_60
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0761, RMSE=0.2758, R²=0.0903
   Val:   Loss=0.0715, RMSE=0.2673, R²=0.0776
============================================================


📊 Round 59 Test Metrics:
   Loss: 0.0746, RMSE: 0.2731, MAE: 0.2342, R²: 0.0988

============================================================
🔄 Round 60 - Client client_60
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0783, val=0.0620 (↓), lr=0.000001
   • Epoch   2/100: train=0.0783, val=0.0619, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0783, val=0.0619, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0783, val=0.0619, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0783, val=0.0619, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0782, val=0.0618, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0620)

============================================================
📊 Round 60 Summary - Client client_60
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2801, R²=0.0854
   Val:   Loss=0.0620, RMSE=0.2489, R²=0.1021
============================================================


📊 Round 60 Test Metrics:
   Loss: 0.0746, RMSE: 0.2731, MAE: 0.2342, R²: 0.0989

📊 Round 60 Test Metrics:
   Loss: 0.0746, RMSE: 0.2731, MAE: 0.2342, R²: 0.0989

📊 Round 60 Test Metrics:
   Loss: 0.0746, RMSE: 0.2731, MAE: 0.2342, R²: 0.0990

============================================================
🔄 Round 64 - Client client_60
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0753, val=0.0747 (↓), lr=0.000001
   • Epoch   2/100: train=0.0752, val=0.0747, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0752, val=0.0747, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0752, val=0.0747, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0752, val=0.0747, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0751, val=0.0746, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0747)

============================================================
📊 Round 64 Summary - Client client_60
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0753, RMSE=0.2744, R²=0.0844
   Val:   Loss=0.0747, RMSE=0.2734, R²=0.1027
============================================================


📊 Round 64 Test Metrics:
   Loss: 0.0745, RMSE: 0.2730, MAE: 0.2341, R²: 0.0992

============================================================
🔄 Round 68 - Client client_60
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0748, val=0.0767 (↓), lr=0.000001
   • Epoch   2/100: train=0.0748, val=0.0767, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0748, val=0.0767, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0748, val=0.0767, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0748, val=0.0767, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0747, val=0.0766, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0767)

============================================================
📊 Round 68 Summary - Client client_60
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0748, RMSE=0.2734, R²=0.0803
   Val:   Loss=0.0767, RMSE=0.2770, R²=0.1164
============================================================


📊 Round 68 Test Metrics:
   Loss: 0.0745, RMSE: 0.2730, MAE: 0.2341, R²: 0.0993

============================================================
🔄 Round 70 - Client client_60
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0751, val=0.0769 (↓), lr=0.000001
   • Epoch   2/100: train=0.0751, val=0.0769, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0751, val=0.0769, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0751, val=0.0769, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0750, val=0.0769, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0749, val=0.0768, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0769)

============================================================
📊 Round 70 Summary - Client client_60
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0747, RMSE=0.2733, R²=0.0946
   Val:   Loss=0.0769, RMSE=0.2774, R²=0.0622
============================================================


📊 Round 70 Test Metrics:
   Loss: 0.0745, RMSE: 0.2730, MAE: 0.2341, R²: 0.0994

============================================================
🔄 Round 71 - Client client_60
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0742, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0742, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0741, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0741, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0741, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0740, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 71 Summary - Client client_60
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0742, RMSE=0.2724, R²=0.0905
   Val:   Loss=0.0789, RMSE=0.2810, R²=0.0701
============================================================


📊 Round 71 Test Metrics:
   Loss: 0.0745, RMSE: 0.2730, MAE: 0.2341, R²: 0.0994

============================================================
🔄 Round 72 - Client client_60
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0751, val=0.0755 (↓), lr=0.000001
   • Epoch   2/100: train=0.0751, val=0.0755, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0751, val=0.0755, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0751, val=0.0755, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0750, val=0.0755, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0749, val=0.0754, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0755)

============================================================
📊 Round 72 Summary - Client client_60
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0751, RMSE=0.2740, R²=0.0917
   Val:   Loss=0.0755, RMSE=0.2748, R²=0.0735
============================================================


============================================================
🔄 Round 74 - Client client_60
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0763, val=0.0701 (↓), lr=0.000001
   • Epoch   2/100: train=0.0762, val=0.0702, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0762, val=0.0702, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0762, val=0.0702, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0762, val=0.0702, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0760, val=0.0703, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0701)

============================================================
📊 Round 74 Summary - Client client_60
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0764, RMSE=0.2764, R²=0.0945
   Val:   Loss=0.0701, RMSE=0.2648, R²=-0.0095
============================================================


============================================================
🔄 Round 75 - Client client_60
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0770, val=0.0669 (↓), lr=0.000001
   • Epoch   2/100: train=0.0770, val=0.0669, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0770, val=0.0669, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0770, val=0.0668, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0770, val=0.0668, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0769, val=0.0668, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0669)

============================================================
📊 Round 75 Summary - Client client_60
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0772, RMSE=0.2779, R²=0.0890
   Val:   Loss=0.0669, RMSE=0.2586, R²=0.0855
============================================================


============================================================
🔄 Round 76 - Client client_60
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0769, val=0.0678 (↓), lr=0.000001
   • Epoch   2/100: train=0.0769, val=0.0678, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0769, val=0.0678, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0768, val=0.0678, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0768, val=0.0678, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0767, val=0.0678, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0678)

============================================================
📊 Round 76 Summary - Client client_60
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0770, RMSE=0.2774, R²=0.0906
   Val:   Loss=0.0678, RMSE=0.2604, R²=0.0645
============================================================


============================================================
🔄 Round 77 - Client client_60
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0752, val=0.0760 (↓), lr=0.000001
   • Epoch   2/100: train=0.0752, val=0.0760, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0751, val=0.0760, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0751, val=0.0760, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0751, val=0.0760, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0750, val=0.0760, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0760)

============================================================
📊 Round 77 Summary - Client client_60
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0749, RMSE=0.2737, R²=0.0940
   Val:   Loss=0.0760, RMSE=0.2758, R²=0.0621
============================================================


📊 Round 77 Test Metrics:
   Loss: 0.0745, RMSE: 0.2729, MAE: 0.2341, R²: 0.0997

============================================================
🔄 Round 82 - Client client_60
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0735, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0735, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0734, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0734, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0734, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0733, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 82 Summary - Client client_60
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0737, RMSE=0.2715, R²=0.0914
   Val:   Loss=0.0808, RMSE=0.2843, R²=0.0762
============================================================


============================================================
🔄 Round 86 - Client client_60
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0750, val=0.0752 (↓), lr=0.000001
   • Epoch   2/100: train=0.0750, val=0.0751, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0750, val=0.0751, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0750, val=0.0751, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0750, val=0.0751, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0749, val=0.0751, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0752)

============================================================
📊 Round 86 Summary - Client client_60
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0751, RMSE=0.2741, R²=0.0868
   Val:   Loss=0.0752, RMSE=0.2741, R²=0.0920
============================================================


📊 Round 86 Test Metrics:
   Loss: 0.0745, RMSE: 0.2729, MAE: 0.2341, R²: 0.0997

============================================================
🔄 Round 88 - Client client_60
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0767, val=0.0682 (↓), lr=0.000001
   • Epoch   2/100: train=0.0767, val=0.0682, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0766, val=0.0682, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0766, val=0.0682, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0766, val=0.0682, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0765, val=0.0681, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0682)

============================================================
📊 Round 88 Summary - Client client_60
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0769, RMSE=0.2772, R²=0.0880
   Val:   Loss=0.0682, RMSE=0.2612, R²=0.0903
============================================================


📊 Round 88 Test Metrics:
   Loss: 0.0745, RMSE: 0.2729, MAE: 0.2340, R²: 0.0999

============================================================
🔄 Round 93 - Client client_60
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0745, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0744, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0744, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0744, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0744, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0743, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 93 Summary - Client client_60
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0743, RMSE=0.2725, R²=0.0841
   Val:   Loss=0.0786, RMSE=0.2804, R²=0.1042
============================================================


📊 Round 93 Test Metrics:
   Loss: 0.0745, RMSE: 0.2729, MAE: 0.2340, R²: 0.1000

============================================================
🔄 Round 97 - Client client_60
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0732, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0732, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0731, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0731, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0731, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0730, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 97 Summary - Client client_60
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0730, RMSE=0.2702, R²=0.0942
   Val:   Loss=0.0837, RMSE=0.2893, R²=0.0639
============================================================


📊 Round 97 Test Metrics:
   Loss: 0.0745, RMSE: 0.2729, MAE: 0.2340, R²: 0.1000

============================================================
🔄 Round 98 - Client client_60
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0767, val=0.0691 (↓), lr=0.000001
   • Epoch   2/100: train=0.0767, val=0.0691, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0766, val=0.0691, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0766, val=0.0691, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0766, val=0.0690, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0765, val=0.0690, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0691)

============================================================
📊 Round 98 Summary - Client client_60
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0766, RMSE=0.2768, R²=0.0888
   Val:   Loss=0.0691, RMSE=0.2629, R²=0.0872
============================================================


📊 Round 98 Test Metrics:
   Loss: 0.0745, RMSE: 0.2729, MAE: 0.2340, R²: 0.1002

============================================================
🔄 Round 101 - Client client_60
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0750, val=0.0765 (↓), lr=0.000001
   • Epoch   2/100: train=0.0750, val=0.0765, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0750, val=0.0765, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0750, val=0.0765, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0750, val=0.0765, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0749, val=0.0764, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0765)

============================================================
📊 Round 101 Summary - Client client_60
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0748, RMSE=0.2734, R²=0.0806
   Val:   Loss=0.0765, RMSE=0.2767, R²=0.1186
============================================================


============================================================
🔄 Round 102 - Client client_60
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0740, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0740, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0740, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0740, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0740, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0739, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 102 Summary - Client client_60
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0742, RMSE=0.2724, R²=0.0818
   Val:   Loss=0.0789, RMSE=0.2808, R²=0.1122
============================================================


📊 Round 102 Test Metrics:
   Loss: 0.0745, RMSE: 0.2729, MAE: 0.2340, R²: 0.1002

============================================================
🔄 Round 103 - Client client_60
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0749, val=0.0758 (↓), lr=0.000001
   • Epoch   2/100: train=0.0749, val=0.0758, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0749, val=0.0757, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0749, val=0.0757, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0748, val=0.0757, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0748, val=0.0756, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0758)

============================================================
📊 Round 103 Summary - Client client_60
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0750, RMSE=0.2738, R²=0.0854
   Val:   Loss=0.0758, RMSE=0.2753, R²=0.1012
============================================================


📊 Round 103 Test Metrics:
   Loss: 0.0745, RMSE: 0.2729, MAE: 0.2340, R²: 0.1003

============================================================
🔄 Round 105 - Client client_60
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0757, val=0.0733 (↓), lr=0.000001
   • Epoch   2/100: train=0.0757, val=0.0733, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0757, val=0.0733, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0757, val=0.0733, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0756, val=0.0733, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0755, val=0.0733, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0733)

============================================================
📊 Round 105 Summary - Client client_60
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0756, RMSE=0.2749, R²=0.0878
   Val:   Loss=0.0733, RMSE=0.2707, R²=0.0705
============================================================


============================================================
🔄 Round 107 - Client client_60
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0742, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0742, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0742, val=0.0782, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0742, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0742, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0741, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 107 Summary - Client client_60
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0743, RMSE=0.2726, R²=0.0947
   Val:   Loss=0.0782, RMSE=0.2797, R²=0.0652
============================================================


============================================================
🔄 Round 109 - Client client_60
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0751, val=0.0745 (↓), lr=0.000001
   • Epoch   2/100: train=0.0751, val=0.0745, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0751, val=0.0745, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0751, val=0.0745, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0751, val=0.0745, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0750, val=0.0744, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0745)

============================================================
📊 Round 109 Summary - Client client_60
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0753, RMSE=0.2743, R²=0.0765
   Val:   Loss=0.0745, RMSE=0.2730, R²=0.1351
============================================================


📊 Round 109 Test Metrics:
   Loss: 0.0744, RMSE: 0.2728, MAE: 0.2340, R²: 0.1005

============================================================
🔄 Round 110 - Client client_60
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0756, val=0.0732 (↓), lr=0.000001
   • Epoch   2/100: train=0.0756, val=0.0732, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0756, val=0.0732, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0756, val=0.0731, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0756, val=0.0731, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0755, val=0.0731, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0732)

============================================================
📊 Round 110 Summary - Client client_60
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0756, RMSE=0.2749, R²=0.0923
   Val:   Loss=0.0732, RMSE=0.2705, R²=0.0690
============================================================


📊 Round 110 Test Metrics:
   Loss: 0.0744, RMSE: 0.2728, MAE: 0.2340, R²: 0.1004

📊 Round 110 Test Metrics:
   Loss: 0.0744, RMSE: 0.2728, MAE: 0.2340, R²: 0.1005

============================================================
🔄 Round 113 - Client client_60
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0758, val=0.0722 (↓), lr=0.000001
   • Epoch   2/100: train=0.0758, val=0.0722, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0758, val=0.0722, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0758, val=0.0722, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0758, val=0.0722, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0756, val=0.0722, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0722)

============================================================
📊 Round 113 Summary - Client client_60
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0758, RMSE=0.2754, R²=0.0927
   Val:   Loss=0.0722, RMSE=0.2686, R²=0.0448
============================================================


============================================================
🔄 Round 114 - Client client_60
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0752, val=0.0751 (↓), lr=0.000001
   • Epoch   2/100: train=0.0752, val=0.0751, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0752, val=0.0751, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0752, val=0.0751, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0751, val=0.0751, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0751, val=0.0750, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0751)

============================================================
📊 Round 114 Summary - Client client_60
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0751, RMSE=0.2741, R²=0.0875
   Val:   Loss=0.0751, RMSE=0.2741, R²=0.0924
============================================================


📊 Round 114 Test Metrics:
   Loss: 0.0744, RMSE: 0.2728, MAE: 0.2340, R²: 0.1006

============================================================
🔄 Round 116 - Client client_60
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0747, val=0.0762 (↓), lr=0.000001
   • Epoch   2/100: train=0.0747, val=0.0761, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0747, val=0.0761, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0747, val=0.0761, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0747, val=0.0761, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0746, val=0.0761, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0762)

============================================================
📊 Round 116 Summary - Client client_60
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0748, RMSE=0.2736, R²=0.0889
   Val:   Loss=0.0762, RMSE=0.2760, R²=0.0820
============================================================


📊 Round 116 Test Metrics:
   Loss: 0.0744, RMSE: 0.2728, MAE: 0.2339, R²: 0.1007

============================================================
🔄 Round 118 - Client client_60
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0751, val=0.0759 (↓), lr=0.000001
   • Epoch   2/100: train=0.0751, val=0.0759, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0750, val=0.0758, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0750, val=0.0758, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0750, val=0.0758, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0749, val=0.0758, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0759)

============================================================
📊 Round 118 Summary - Client client_60
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0749, RMSE=0.2737, R²=0.0951
   Val:   Loss=0.0759, RMSE=0.2754, R²=0.0613
============================================================


📊 Round 118 Test Metrics:
   Loss: 0.0744, RMSE: 0.2728, MAE: 0.2339, R²: 0.1009

============================================================
🔄 Round 121 - Client client_60
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0759, val=0.0720 (↓), lr=0.000001
   • Epoch   2/100: train=0.0759, val=0.0720, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0759, val=0.0720, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0759, val=0.0720, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0759, val=0.0720, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0758, val=0.0719, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0720)

============================================================
📊 Round 121 Summary - Client client_60
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0759, RMSE=0.2754, R²=0.0822
   Val:   Loss=0.0720, RMSE=0.2683, R²=0.1167
============================================================


============================================================
🔄 Round 122 - Client client_60
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0759, val=0.0719 (↓), lr=0.000001
   • Epoch   2/100: train=0.0758, val=0.0719, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0758, val=0.0719, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0758, val=0.0719, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0758, val=0.0719, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0757, val=0.0718, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0719)

============================================================
📊 Round 122 Summary - Client client_60
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0759, RMSE=0.2755, R²=0.0878
   Val:   Loss=0.0719, RMSE=0.2681, R²=0.0938
============================================================


📊 Round 122 Test Metrics:
   Loss: 0.0744, RMSE: 0.2727, MAE: 0.2339, R²: 0.1010

============================================================
🔄 Round 123 - Client client_60
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0767, val=0.0693 (↓), lr=0.000001
   • Epoch   2/100: train=0.0767, val=0.0693, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0767, val=0.0693, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0767, val=0.0693, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0767, val=0.0692, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0766, val=0.0692, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0693)

============================================================
📊 Round 123 Summary - Client client_60
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0765, RMSE=0.2767, R²=0.0880
   Val:   Loss=0.0693, RMSE=0.2632, R²=0.0933
============================================================


📊 Round 123 Test Metrics:
   Loss: 0.0744, RMSE: 0.2728, MAE: 0.2339, R²: 0.1009

============================================================
🔄 Round 126 - Client client_60
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0752, val=0.0751 (↓), lr=0.000001
   • Epoch   2/100: train=0.0752, val=0.0751, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0752, val=0.0751, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0752, val=0.0751, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0751, val=0.0751, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0751, val=0.0750, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0751)

============================================================
📊 Round 126 Summary - Client client_60
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0751, RMSE=0.2740, R²=0.0869
   Val:   Loss=0.0751, RMSE=0.2741, R²=0.0908
============================================================


============================================================
🔄 Round 127 - Client client_60
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0769, val=0.0684 (↓), lr=0.000001
   • Epoch   2/100: train=0.0769, val=0.0684, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0769, val=0.0684, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0769, val=0.0684, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0769, val=0.0683, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0768, val=0.0683, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0684)

============================================================
📊 Round 127 Summary - Client client_60
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0768, RMSE=0.2771, R²=0.0832
   Val:   Loss=0.0684, RMSE=0.2615, R²=0.1078
============================================================


============================================================
🔄 Round 128 - Client client_60
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0746, val=0.0764 (↓), lr=0.000001
   • Epoch   2/100: train=0.0746, val=0.0764, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0745, val=0.0764, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0745, val=0.0764, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0745, val=0.0764, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0744, val=0.0763, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0764)

============================================================
📊 Round 128 Summary - Client client_60
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0748, RMSE=0.2734, R²=0.0923
   Val:   Loss=0.0764, RMSE=0.2764, R²=0.0683
============================================================


============================================================
🔄 Round 130 - Client client_60
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0751, val=0.0760 (↓), lr=0.000001
   • Epoch   2/100: train=0.0751, val=0.0760, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0751, val=0.0760, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0751, val=0.0760, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0751, val=0.0760, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0750, val=0.0759, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0760)

============================================================
📊 Round 130 Summary - Client client_60
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0749, RMSE=0.2736, R²=0.0798
   Val:   Loss=0.0760, RMSE=0.2757, R²=0.1128
============================================================


============================================================
🔄 Round 131 - Client client_60
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0748, val=0.0763 (↓), lr=0.000001
   • Epoch   2/100: train=0.0748, val=0.0763, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0747, val=0.0763, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0747, val=0.0763, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0747, val=0.0763, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0746, val=0.0763, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0763)

============================================================
📊 Round 131 Summary - Client client_60
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0748, RMSE=0.2735, R²=0.0791
   Val:   Loss=0.0763, RMSE=0.2763, R²=0.1004
============================================================


📊 Round 131 Test Metrics:
   Loss: 0.0744, RMSE: 0.2728, MAE: 0.2339, R²: 0.1010

============================================================
🔄 Round 134 - Client client_60
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0740, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0740, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0740, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0740, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0740, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0739, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 134 Summary - Client client_60
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0741, RMSE=0.2722, R²=0.0927
   Val:   Loss=0.0790, RMSE=0.2811, R²=0.0615
============================================================


📊 Round 134 Test Metrics:
   Loss: 0.0744, RMSE: 0.2728, MAE: 0.2339, R²: 0.1009

============================================================
🔄 Round 137 - Client client_60
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0740, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0739, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0739, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0739, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0739, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0738, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 137 Summary - Client client_60
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0741, RMSE=0.2722, R²=0.0827
   Val:   Loss=0.0791, RMSE=0.2812, R²=0.1078
============================================================


📊 Round 137 Test Metrics:
   Loss: 0.0744, RMSE: 0.2728, MAE: 0.2339, R²: 0.1009

📊 Round 137 Test Metrics:
   Loss: 0.0744, RMSE: 0.2727, MAE: 0.2339, R²: 0.1010

============================================================
🔄 Round 141 - Client client_60
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0756, val=0.0733 (↓), lr=0.000001
   • Epoch   2/100: train=0.0756, val=0.0733, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0756, val=0.0733, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0756, val=0.0733, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0755, val=0.0733, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0755, val=0.0732, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0733)

============================================================
📊 Round 141 Summary - Client client_60
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0755, RMSE=0.2748, R²=0.0819
   Val:   Loss=0.0733, RMSE=0.2708, R²=0.0997
============================================================


📊 Round 141 Test Metrics:
   Loss: 0.0744, RMSE: 0.2727, MAE: 0.2339, R²: 0.1011

📊 Round 141 Test Metrics:
   Loss: 0.0744, RMSE: 0.2727, MAE: 0.2339, R²: 0.1011

============================================================
🔄 Round 145 - Client client_60
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0754, val=0.0740 (↓), lr=0.000001
   • Epoch   2/100: train=0.0754, val=0.0740, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0754, val=0.0740, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0754, val=0.0740, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0754, val=0.0740, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0753, val=0.0740, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0740)

============================================================
📊 Round 145 Summary - Client client_60
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0753, RMSE=0.2745, R²=0.0839
   Val:   Loss=0.0740, RMSE=0.2721, R²=0.0914
============================================================


📊 Round 145 Test Metrics:
   Loss: 0.0744, RMSE: 0.2727, MAE: 0.2339, R²: 0.1012

============================================================
🔄 Round 147 - Client client_60
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0751, val=0.0756 (↓), lr=0.000001
   • Epoch   2/100: train=0.0751, val=0.0756, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0751, val=0.0755, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0751, val=0.0755, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0751, val=0.0755, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0750, val=0.0755, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0756)

============================================================
📊 Round 147 Summary - Client client_60
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0750, RMSE=0.2738, R²=0.0805
   Val:   Loss=0.0756, RMSE=0.2749, R²=0.1189
============================================================


📊 Round 147 Test Metrics:
   Loss: 0.0744, RMSE: 0.2727, MAE: 0.2339, R²: 0.1012

📊 Round 147 Test Metrics:
   Loss: 0.0744, RMSE: 0.2727, MAE: 0.2339, R²: 0.1012

============================================================
🔄 Round 150 - Client client_60
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0741, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0741, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0741, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0741, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0741, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0740, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 150 Summary - Client client_60
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0741, RMSE=0.2721, R²=0.0918
   Val:   Loss=0.0791, RMSE=0.2813, R²=0.0774
============================================================


📊 Round 150 Test Metrics:
   Loss: 0.0744, RMSE: 0.2727, MAE: 0.2339, R²: 0.1012

============================================================
🔄 Round 151 - Client client_60
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0754, val=0.0742 (↓), lr=0.000001
   • Epoch   2/100: train=0.0754, val=0.0742, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0753, val=0.0742, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0753, val=0.0742, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0753, val=0.0742, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0752, val=0.0743, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0742)

============================================================
📊 Round 151 Summary - Client client_60
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0753, RMSE=0.2744, R²=0.0934
   Val:   Loss=0.0742, RMSE=0.2723, R²=0.0268
============================================================


📊 Round 151 Test Metrics:
   Loss: 0.0744, RMSE: 0.2727, MAE: 0.2339, R²: 0.1013

============================================================
🔄 Round 154 - Client client_60
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0748, val=0.0763 (↓), lr=0.000001
   • Epoch   2/100: train=0.0747, val=0.0763, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0747, val=0.0763, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0747, val=0.0763, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0747, val=0.0763, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0746, val=0.0762, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0763)

============================================================
📊 Round 154 Summary - Client client_60
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0748, RMSE=0.2734, R²=0.0874
   Val:   Loss=0.0763, RMSE=0.2763, R²=0.0952
============================================================


📊 Round 154 Test Metrics:
   Loss: 0.0744, RMSE: 0.2727, MAE: 0.2338, R²: 0.1014

============================================================
🔄 Round 155 - Client client_60
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0739, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0739, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0739, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0738, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0738, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0738, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 155 Summary - Client client_60
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0739, RMSE=0.2718, R²=0.0803
   Val:   Loss=0.0798, RMSE=0.2825, R²=0.1196
============================================================


============================================================
🔄 Round 158 - Client client_60
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0733, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0733, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0733, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0733, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0733, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0732, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 158 Summary - Client client_60
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0733, RMSE=0.2708, R²=0.0970
   Val:   Loss=0.0820, RMSE=0.2864, R²=0.0598
============================================================


📊 Round 158 Test Metrics:
   Loss: 0.0744, RMSE: 0.2727, MAE: 0.2338, R²: 0.1014

============================================================
🔄 Round 162 - Client client_60
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0753, val=0.0733 (↓), lr=0.000001
   • Epoch   2/100: train=0.0753, val=0.0733, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0753, val=0.0733, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0753, val=0.0733, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0752, val=0.0734, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0751, val=0.0735, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0733)

============================================================
📊 Round 162 Summary - Client client_60
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0755, RMSE=0.2748, R²=0.0926
   Val:   Loss=0.0733, RMSE=0.2707, R²=0.0273
============================================================


📊 Round 162 Test Metrics:
   Loss: 0.0744, RMSE: 0.2727, MAE: 0.2339, R²: 0.1013

============================================================
🔄 Round 169 - Client client_60
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0765, val=0.0698 (↓), lr=0.000001
   • Epoch   2/100: train=0.0765, val=0.0698, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0765, val=0.0698, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0765, val=0.0698, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0764, val=0.0698, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0764, val=0.0698, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0698)

============================================================
📊 Round 169 Summary - Client client_60
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0764, RMSE=0.2764, R²=0.0927
   Val:   Loss=0.0698, RMSE=0.2642, R²=0.0642
============================================================


============================================================
🔄 Round 170 - Client client_60
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0748, val=0.0772 (↓), lr=0.000001
   • Epoch   2/100: train=0.0748, val=0.0771, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0748, val=0.0771, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0748, val=0.0771, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0748, val=0.0771, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0747, val=0.0770, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 170 Summary - Client client_60
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0745, RMSE=0.2730, R²=0.0826
   Val:   Loss=0.0772, RMSE=0.2778, R²=0.1121
============================================================


============================================================
🔄 Round 171 - Client client_60
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0730, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0730, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0730, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0730, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0729, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0729, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 171 Summary - Client client_60
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0728, RMSE=0.2699, R²=0.0901
   Val:   Loss=0.0840, RMSE=0.2899, R²=0.0835
============================================================


============================================================
🔄 Round 172 - Client client_60
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0758, val=0.0734 (↓), lr=0.000001
   • Epoch   2/100: train=0.0758, val=0.0734, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0758, val=0.0734, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0758, val=0.0734, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0757, val=0.0734, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0757, val=0.0733, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0734)

============================================================
📊 Round 172 Summary - Client client_60
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0755, RMSE=0.2747, R²=0.0892
   Val:   Loss=0.0734, RMSE=0.2709, R²=0.0887
============================================================


📊 Round 172 Test Metrics:
   Loss: 0.0743, RMSE: 0.2727, MAE: 0.2338, R²: 0.1015

============================================================
🔄 Round 175 - Client client_60
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0740, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0740, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0740, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0740, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0740, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0739, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 175 Summary - Client client_60
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0741, RMSE=0.2722, R²=0.0775
   Val:   Loss=0.0789, RMSE=0.2808, R²=0.1281
============================================================


📊 Round 175 Test Metrics:
   Loss: 0.0743, RMSE: 0.2726, MAE: 0.2338, R²: 0.1017

📊 Round 175 Test Metrics:
   Loss: 0.0743, RMSE: 0.2727, MAE: 0.2338, R²: 0.1016

============================================================
🔄 Round 178 - Client client_60
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0750, val=0.0742 (↓), lr=0.000001
   • Epoch   2/100: train=0.0750, val=0.0742, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0750, val=0.0742, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0749, val=0.0742, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0749, val=0.0742, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0748, val=0.0742, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0742)

============================================================
📊 Round 178 Summary - Client client_60
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0753, RMSE=0.2744, R²=0.0913
   Val:   Loss=0.0742, RMSE=0.2724, R²=0.0765
============================================================


📊 Round 178 Test Metrics:
   Loss: 0.0743, RMSE: 0.2726, MAE: 0.2338, R²: 0.1017

============================================================
🔄 Round 180 - Client client_60
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0757, val=0.0736 (↓), lr=0.000001
   • Epoch   2/100: train=0.0757, val=0.0736, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0756, val=0.0736, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0756, val=0.0736, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0756, val=0.0736, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0756, val=0.0735, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0736)

============================================================
📊 Round 180 Summary - Client client_60
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0754, RMSE=0.2746, R²=0.0812
   Val:   Loss=0.0736, RMSE=0.2713, R²=0.1199
============================================================


📊 Round 180 Test Metrics:
   Loss: 0.0743, RMSE: 0.2726, MAE: 0.2338, R²: 0.1016

📊 Round 180 Test Metrics:
   Loss: 0.0743, RMSE: 0.2726, MAE: 0.2338, R²: 0.1017

📊 Round 180 Test Metrics:
   Loss: 0.0743, RMSE: 0.2727, MAE: 0.2338, R²: 0.1016

============================================================
🔄 Round 185 - Client client_60
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0756, val=0.0725 (↓), lr=0.000001
   • Epoch   2/100: train=0.0756, val=0.0725, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0756, val=0.0725, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0756, val=0.0725, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0756, val=0.0725, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0755, val=0.0725, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0725)

============================================================
📊 Round 185 Summary - Client client_60
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0757, RMSE=0.2751, R²=0.0960
   Val:   Loss=0.0725, RMSE=0.2693, R²=0.0485
============================================================


📊 Round 185 Test Metrics:
   Loss: 0.0743, RMSE: 0.2726, MAE: 0.2338, R²: 0.1017

📊 Round 185 Test Metrics:
   Loss: 0.0743, RMSE: 0.2727, MAE: 0.2338, R²: 0.1015

============================================================
🔄 Round 187 - Client client_60
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0746, val=0.0771 (↓), lr=0.000001
   • Epoch   2/100: train=0.0746, val=0.0771, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0746, val=0.0771, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0746, val=0.0771, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0746, val=0.0771, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0745, val=0.0770, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0771)

============================================================
📊 Round 187 Summary - Client client_60
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0746, RMSE=0.2730, R²=0.0785
   Val:   Loss=0.0771, RMSE=0.2777, R²=0.1190
============================================================


📊 Round 187 Test Metrics:
   Loss: 0.0743, RMSE: 0.2727, MAE: 0.2338, R²: 0.1015

============================================================
🔄 Round 189 - Client client_60
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0750, val=0.0747 (↓), lr=0.000001
   • Epoch   2/100: train=0.0750, val=0.0747, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0750, val=0.0747, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0750, val=0.0747, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0749, val=0.0747, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0749, val=0.0747, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0747)

============================================================
📊 Round 189 Summary - Client client_60
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0751, RMSE=0.2741, R²=0.0873
   Val:   Loss=0.0747, RMSE=0.2734, R²=0.0923
============================================================


📊 Round 189 Test Metrics:
   Loss: 0.0743, RMSE: 0.2727, MAE: 0.2338, R²: 0.1016

============================================================
🔄 Round 190 - Client client_60
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0751, val=0.0750 (↓), lr=0.000001
   • Epoch   2/100: train=0.0750, val=0.0750, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0750, val=0.0750, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0750, val=0.0750, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0750, val=0.0750, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0749, val=0.0749, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0750)

============================================================
📊 Round 190 Summary - Client client_60
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0751, RMSE=0.2740, R²=0.0904
   Val:   Loss=0.0750, RMSE=0.2739, R²=0.0853
============================================================


============================================================
🔄 Round 191 - Client client_60
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0739, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0739, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0739, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0739, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0739, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0738, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 191 Summary - Client client_60
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0740, RMSE=0.2720, R²=0.0920
   Val:   Loss=0.0793, RMSE=0.2816, R²=0.0793
============================================================


📊 Round 191 Test Metrics:
   Loss: 0.0743, RMSE: 0.2727, MAE: 0.2338, R²: 0.1016

📊 Round 191 Test Metrics:
   Loss: 0.0743, RMSE: 0.2727, MAE: 0.2338, R²: 0.1016

📊 Round 191 Test Metrics:
   Loss: 0.0743, RMSE: 0.2727, MAE: 0.2338, R²: 0.1016

📊 Round 191 Test Metrics:
   Loss: 0.0743, RMSE: 0.2726, MAE: 0.2338, R²: 0.1016

📊 Round 191 Test Metrics:
   Loss: 0.0743, RMSE: 0.2726, MAE: 0.2338, R²: 0.1017

============================================================
🔄 Round 201 - Client client_60
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0764, val=0.0706 (↓), lr=0.000001
   • Epoch   2/100: train=0.0764, val=0.0706, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0764, val=0.0706, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0764, val=0.0706, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0763, val=0.0706, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0763, val=0.0706, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0706)

============================================================
📊 Round 201 Summary - Client client_60
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0762, RMSE=0.2760, R²=0.0881
   Val:   Loss=0.0706, RMSE=0.2658, R²=0.0903
============================================================


============================================================
🔄 Round 203 - Client client_60
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0746, val=0.0780 (↓), lr=0.000001
   • Epoch   2/100: train=0.0746, val=0.0780, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0746, val=0.0780, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0745, val=0.0780, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0745, val=0.0780, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0744, val=0.0779, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 203 Summary - Client client_60
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0743, RMSE=0.2726, R²=0.0893
   Val:   Loss=0.0780, RMSE=0.2792, R²=0.0821
============================================================


============================================================
🔄 Round 205 - Client client_60
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0764, val=0.0697 (↓), lr=0.000001
   • Epoch   2/100: train=0.0764, val=0.0697, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0763, val=0.0697, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0763, val=0.0697, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0763, val=0.0696, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0762, val=0.0696, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0697)

============================================================
📊 Round 205 Summary - Client client_60
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0764, RMSE=0.2764, R²=0.0911
   Val:   Loss=0.0697, RMSE=0.2640, R²=0.0819
============================================================


============================================================
🔄 Round 206 - Client client_60
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0735, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0734, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0734, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0734, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0734, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0733, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 206 Summary - Client client_60
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0734, RMSE=0.2710, R²=0.0918
   Val:   Loss=0.0816, RMSE=0.2856, R²=0.0675
============================================================


============================================================
🔄 Round 207 - Client client_60
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0748, val=0.0769 (↓), lr=0.000001
   • Epoch   2/100: train=0.0748, val=0.0769, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0748, val=0.0769, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0748, val=0.0769, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0748, val=0.0769, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0747, val=0.0768, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0769)

============================================================
📊 Round 207 Summary - Client client_60
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0746, RMSE=0.2731, R²=0.0924
   Val:   Loss=0.0769, RMSE=0.2774, R²=0.0727
============================================================


📊 Round 207 Test Metrics:
   Loss: 0.0743, RMSE: 0.2726, MAE: 0.2338, R²: 0.1019

📊 Round 207 Test Metrics:
   Loss: 0.0743, RMSE: 0.2726, MAE: 0.2338, R²: 0.1019

📊 Round 207 Test Metrics:
   Loss: 0.0743, RMSE: 0.2726, MAE: 0.2338, R²: 0.1021

📊 Round 207 Test Metrics:
   Loss: 0.0743, RMSE: 0.2726, MAE: 0.2338, R²: 0.1020

============================================================
🔄 Round 216 - Client client_60
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0746, val=0.0764 (↓), lr=0.000001
   • Epoch   2/100: train=0.0746, val=0.0764, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0746, val=0.0764, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0746, val=0.0764, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0745, val=0.0763, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0745, val=0.0763, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0764)

============================================================
📊 Round 216 Summary - Client client_60
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0747, RMSE=0.2733, R²=0.0936
   Val:   Loss=0.0764, RMSE=0.2764, R²=0.0732
============================================================


============================================================
🔄 Round 217 - Client client_60
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0737, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0737, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0737, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0737, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0737, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0736, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 217 Summary - Client client_60
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0738, RMSE=0.2716, R²=0.0984
   Val:   Loss=0.0801, RMSE=0.2831, R²=0.0454
============================================================


============================================================
🔄 Round 218 - Client client_60
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0725, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0724, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0724, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0724, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0724, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0723, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 218 Summary - Client client_60
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0727, RMSE=0.2697, R²=0.0944
   Val:   Loss=0.0843, RMSE=0.2904, R²=0.0670
============================================================


📊 Round 218 Test Metrics:
   Loss: 0.0743, RMSE: 0.2726, MAE: 0.2337, R²: 0.1021

============================================================
🔄 Round 219 - Client client_60
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0766, val=0.0692 (↓), lr=0.000001
   • Epoch   2/100: train=0.0766, val=0.0692, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0766, val=0.0692, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0766, val=0.0692, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0766, val=0.0692, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0765, val=0.0692, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0692)

============================================================
📊 Round 219 Summary - Client client_60
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0765, RMSE=0.2766, R²=0.0808
   Val:   Loss=0.0692, RMSE=0.2631, R²=0.1236
============================================================


📊 Round 219 Test Metrics:
   Loss: 0.0743, RMSE: 0.2726, MAE: 0.2337, R²: 0.1021

============================================================
🔄 Round 220 - Client client_60
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0740, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0740, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0740, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0739, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0739, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0738, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 220 Summary - Client client_60
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0737, RMSE=0.2715, R²=0.0771
   Val:   Loss=0.0803, RMSE=0.2833, R²=0.1196
============================================================


📊 Round 220 Test Metrics:
   Loss: 0.0743, RMSE: 0.2726, MAE: 0.2337, R²: 0.1022

============================================================
🔄 Round 222 - Client client_60
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0753, val=0.0737 (↓), lr=0.000001
   • Epoch   2/100: train=0.0753, val=0.0737, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0753, val=0.0737, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0753, val=0.0737, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0753, val=0.0737, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0752, val=0.0737, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0737)

============================================================
📊 Round 222 Summary - Client client_60
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0754, RMSE=0.2745, R²=0.0790
   Val:   Loss=0.0737, RMSE=0.2715, R²=0.1260
============================================================


📊 Round 222 Test Metrics:
   Loss: 0.0743, RMSE: 0.2726, MAE: 0.2337, R²: 0.1022

📊 Round 222 Test Metrics:
   Loss: 0.0743, RMSE: 0.2725, MAE: 0.2337, R²: 0.1023

============================================================
🔄 Round 225 - Client client_60
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0765, val=0.0704 (↓), lr=0.000001
   • Epoch   2/100: train=0.0764, val=0.0703, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0764, val=0.0703, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0764, val=0.0703, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0764, val=0.0703, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0763, val=0.0703, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0704)

============================================================
📊 Round 225 Summary - Client client_60
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0762, RMSE=0.2761, R²=0.0873
   Val:   Loss=0.0704, RMSE=0.2652, R²=0.0992
============================================================


❌ Client client_60 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "recvmsg:Connection reset by peer"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8687 {grpc_message:"recvmsg:Connection reset by peer", grpc_status:14}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "recvmsg:Connection reset by peer"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8687 {grpc_message:"recvmsg:Connection reset by peer", grpc_status:14}"
>
