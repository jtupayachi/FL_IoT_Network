[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 946a584f-fec5-476a-8144-35ba4f4db632
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0b67cdb7-a9ac-4c5e-afe7-29aed662e93d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 54b2d95f-cbe5-443b-90a3-afae35890c77
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 628b1510-0bc3-4295-872d-a751d951fb25
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 346ff4d6-e852-4445-a52e-cdade42151f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b74d1de4-40d7-4127-bffb-753f5766baca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3cb3fe68-8638-41ee-a6b5-27449913dd6f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e20a177a-4068-4e76-bd80-ba4bcd244caf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7441fbb6-3787-4cb2-b27e-5ef233fc94b5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7bdd5900-19ce-40e2-84c5-0d793e6bd9a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a8f73a21-5f7c-4cf0-9511-eb084ce60dc6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b8edb8a1-99af-438b-bc85-0e3798534470
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5a58ab4b-b27c-4c27-adcd-2504aaf3b150
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f03efe4b-0fad-4854-9370-fa656b8cea15
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 52f8a117-fd28-42b4-ac72-f89747424900
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 231ab419-57eb-41b7-befd-a1847ef535f4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aa193393-8be3-417e-b9a7-2075cb77474d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a2ac6ada-f27f-44e5-9115-1da40c61ab8d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c69e9a10-58bf-4dfc-8f06-9dff343e9fa2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9c851eae-68ab-40b7-9e83-28e94c13aac3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7e13200f-574f-47a3-afcd-416b90a25340
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eca373e1-02fb-49d2-9707-ebfe3c733ede
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1e23935f-0d34-487a-be3b-3f0b8876094a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5a0e79dc-e0eb-402c-b60c-08b777760b7f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3589edab-460c-4df3-b4b3-b3626c43acaa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e83e6575-d643-45d9-9de4-6d2b554905e6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 91eeb6b0-4da9-408c-a1cf-2387f5d27f32
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7b9e7598-4034-4a8c-ba6f-3c5d630339f9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 87d79a01-ef8a-4e3a-bdb2-a6abed8e6c8c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a3ebde76-661a-458e-abdd-625235a657d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cd04f211-09c4-459f-b1f7-43d888cd8244
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 559671ab-1e73-48fb-a526-0751dfee3604
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message da6c059d-2c8e-4e68-a165-cac310cc2c5b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 900ad002-45b8-4b93-9a2e-1e5abedb16b6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9e1d60f1-31ec-45e7-b935-71f635a80054
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 90f83744-ebfc-419e-bb12-7537f4d80c86
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1e057af3-3cc3-4a6d-b3be-a36f48cce0e8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7feba38c-f5d4-402f-9bb8-ff8fbdb185cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5a9852f2-2ecb-48a0-b5fd-3bc6298371cb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3b5917aa-33f2-44b6-bb02-01723e79a347
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4f4edbfe-0f68-4111-8d9e-bd0e62451f7d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 907243a3-a9b5-4b23-8de2-6d64beff5c81
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 407f5fa1-eaf1-42ed-8495-37b339179bfd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 02fe6c3b-fd64-4cc7-acee-569432630de4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 42ff1b43-c97a-4243-a220-b39cc795658a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5977bcfb-d2a1-43c2-b4b7-9c0db6401c8f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6508de5d-df38-4b0c-9aa8-412f3a72469c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0888f019-bc38-43da-be30-3573b61283d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7e5c5b35-76ff-4191-9ccb-ed7832cd2e95
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 74f56416-fef0-44d7-b6b0-5cf092c63a33
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5706f8b0-4d79-411b-ad50-1a9b2d8c89b9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1e8a069f-7f8b-4eff-a173-ca8043e94f3a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 101f9da7-73fa-4c08-a259-1274429fe439
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message df6dc46a-c715-4091-8222-bfdbd7b9eafd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a6954868-05f6-4a08-8764-687298b76774
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2ad540be-9bbd-4cbe-878f-87a754c3e939
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dcdcc461-59bc-4dd9-acf1-c18bf45c0eae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1a188482-ce4a-4f4a-a066-f84eb52a4ed9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ad34f0fb-c9c8-45ee-84cf-28a4da52dcfb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e60063ec-3f91-4b0e-8f62-4074046ac3e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e0e9f5e0-3777-45ef-b5cf-9cf2564ac218
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7816c17c-6d57-44bb-8494-6d72274aaffb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message af1319bf-69ca-4a04-8b98-6714405c7e48
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a377e063-7991-430f-a3a1-2de73d404b45
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 97c81cdd-ec5e-401d-936c-3ebe48366916
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 09416e1d-8f40-49de-9d69-1ce210b8e477
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2255f2a8-e11e-433a-85d3-9c5c2e894121
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b780a2b5-86bb-427a-85b3-e040b3ad5ae0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b5f98aaa-9bb1-4e89-94cc-697b7eb1a063
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7a329a74-1e93-425c-9b69-c7cd3934c189
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0e612d7a-d88e-41ef-9741-62a9c5b06b8e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ea3a5b47-c387-4f8a-9959-9125c0204679
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a517dda5-583b-42f3-b517-7dd9655c7de7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2628323f-abc6-4977-ae68-717c07025261
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7687c5dc-ba38-43b3-a699-1e359002d817
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f8d09055-c9b8-4211-b3c7-10d6a1cec128
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1dfd0fce-dbc9-4b6c-ad39-0a74d96ca66f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 83ac833a-3ebb-4d4e-a39a-f8b05d7f11fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8affdd41-709f-4a19-ab76-bcbba8a57400
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2abec42f-61b3-473d-ac40-74ed3c1c2272
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3f0b25f7-138a-4c00-89c7-a22fe2e513e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a25e0f31-2785-4db0-a706-7d69abcd5ab5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1f95388b-d32a-4501-8b30-967a528a33c6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 953743bd-86c9-4220-9d3d-12cb2b0f558a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b90080b2-59ab-4c30-8a56-0ad3358d3891
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 427ac914-9f22-471c-9125-843557d3d0ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6511d57b-596d-4e1a-87fb-5010af50a2e8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 30f4b3b4-526f-4a94-95a3-b017c0b5599a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a0a41565-952a-4a7e-a325-4ce5c71e7b5f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 54183b75-dae2-4ccc-ba14-cddf24a0d59f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 678f5559-5bb4-4b5b-b9f2-5719981942d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 62bc352e-22a3-4bfb-a1c4-76f4a2cee821
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ba3bd2f1-e6d0-4e79-983e-74abb0dd12a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4c4d64d7-a2f5-483d-9c74-13af47f0cc98
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cf98227c-deb1-423a-b2b7-a0462f28cd60
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message edc0d326-430c-46ae-be4f-39ec8b9cbc0e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8d96a858-adaa-4cb9-b813-6103fa562e0c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b2a3adc4-2b9f-4f13-b36f-adc35c038ae0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 41464483-a6c8-40ec-b321-9f4dee22f414
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2a192a02-ca4e-4f27-9e94-f4764e471378
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 69143759-129d-4971-8bec-c2a500342965
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0ec51ba8-c25c-4c97-9de7-b645f17a9b3c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 58ef7dc1-2b06-4ab8-9ecb-fb33de86ecd2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 143ecfcd-ee47-47da-a121-890fe3bb7887
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9aeaa95b-10b3-4e11-8b5e-f43469176ddc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 255cbb1d-8e20-4ba2-b890-80c51587b487
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 70512574-c507-41cb-a4c8-b33a452ad8aa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 75321caf-804a-4f20-a19f-cc56a8723cf4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e66dae27-0402-4431-93ed-f7c48c9e643b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 689a534a-5b0c-49ff-94f7-bdccf64e5a11
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6c1987cf-107e-4c0b-859c-8bfa2656141d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 82f49983-0f3b-4e79-a0cf-98fe818cd947
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5cc9c568-b11a-4d74-aab0-684211fb0507
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 185b76d8-9af0-4783-89be-d034ff572c68
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2d4ecaed-4f34-4c65-b06b-0aba698c7cb2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 32e7f0f0-3a17-4f7f-8cba-5e90be1978f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 28ae51fd-bf83-46e9-a744-93d6e042d876
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f63b157c-1607-4f78-badc-2201977c6a3c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 93b0c3ee-7438-4bb9-ac72-a8e9519fa144
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e772f812-316c-4a49-a235-2a73140c6937
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7354b80b-f083-42cd-ab28-5c7ad47ed672
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2089ca34-ee19-4969-a125-e9cc1cc90324
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7588fd3c-062b-4cc8-a517-3c3ba64d6123
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ab8d6f2e-b304-4b82-9134-93931b3a997d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 442559b7-faa9-407c-9cd5-961b4cd03bbc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0f7b225c-93c4-4910-bfe3-8a466d230776
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6433fef3-d6f4-480a-a4ce-48550a2038d8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 60259960-414c-4024-9365-b3616386e12f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e6ae03bd-137b-4109-a1d9-36e3dcaf77f9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 92feb1a3-5d96-4908-ae40-17ecac167743
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2ed60a0a-d150-424f-8dec-1e1af7d0c7c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 39faaf4b-1e91-40a2-b9f6-e9d3e8b0d774
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 40a6a917-ab3e-4012-857e-7ad42de9ad6e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0a6d840e-c407-4394-8dc8-69aced326540
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7e8be8a0-db58-4855-be75-6b2d156cd0fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1905fa06-4114-4d85-ad4e-f93bb9342167
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7d973faf-b576-4902-82cf-2a6e89c7be7e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0f696e99-a86b-4b50-8483-78301d00c166
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2c8610ef-9bff-4fab-a610-b45cff677732
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 001f365b-b502-4d55-a9bb-63adcf015544
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d7c23387-62e2-45b7-803f-b776a06fae80
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 24fc05bb-39fc-4c22-a622-10fe98d026be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0a5d677c-bb4e-40c4-932e-68ff6611c4bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e3722d28-113e-4157-bf1d-2bdd1a83e286
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7a24d821-6b86-485e-a090-7139e39164cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 29415c51-3f9b-48d3-9e45-f0ce3e105d4f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 92cf71d1-f8fe-450e-bfbf-b462688fccde
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 802797a1-49fd-4d31-93ee-6ebbf791cde2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a68038ca-a703-4360-93ac-bd728ebf3cbf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 458905d1-87df-4150-be08-9efd545a138d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ca490766-1946-434f-93db-4b7a070a1cff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3f1a3789-6518-44e8-b36c-a78b731a52be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3a64a7d2-e391-45ec-aa11-540010b3d64b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ef286820-0684-460a-b1b6-4095d0b5fb53
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9e148a06-d0b8-4898-8aaa-fe9282990fbd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 769a320a-2580-417e-aa0c-f8f0e234489d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7f64e7e6-3e14-4c2e-bace-5c4d6f01af96
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0646f2fe-fca4-4d1d-a131-4dacebd64ff4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a0fe3882-33dd-48eb-a967-2995f6196981
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 85950af2-c69b-4aff-b4c6-398f8606e8e5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6ac8bcbd-2989-4dbe-99b6-d193dc268a33
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4df9c667-7dec-4a78-ac2c-914f3cf9dbf2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bfa25e94-69f2-46d2-af51-fa3575c69a7d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 12ef2019-0f0f-4d96-9179-9a8cecb329ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c107bdd7-d6ad-4201-aaca-d3081c33b642
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 31267122-f4ec-4678-8478-88bf9b723657
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 49fabeb7-4aa1-4776-948e-6c780c6cfb9a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3e262f8b-5052-4523-a9db-0cd23dc4b246
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d0e0b934-aacf-44a7-8259-25606fe5e44f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 073954c9-cac0-4701-b5c0-4c529a33e2fb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dcf08286-53e3-424d-a8c0-b33dae2c1666
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 948c9191-3885-4344-85df-61941387f7c7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 827ab151-67cc-41ff-b938-b076e19b29c5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e069d2d9-468d-43a7-8835-24d6973fe5d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 684244af-0359-434c-99a4-70a4ef23d765
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message af0c2a6b-2157-447a-98c4-480cb56e67f8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b42b5450-e989-405f-ab6c-2b9bd4d02fc3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e8cdcd83-913a-454f-9aae-1959cb071e6f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5687f653-bc36-4fd1-9995-d669ed607041
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 294013e3-4b3a-4fe0-993a-7ab4d62d4d22
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cb096f1a-ccc6-448b-a1e1-5649afb89de4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 09f7de4a-bec4-4690-974b-0bdaaa08e0a9
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8687 {grpc_message:"Socket closed", grpc_status:14}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_61
Server: localhost:8687
Algorithm: FEDAVG
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_61
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_61/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_61/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_61/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_61/test_labels.txt

📊 Raw data loaded:
   Train: X=(1000, 24), y=(1000,)
   Test:  X=(251, 24), y=(251,)

⚠️  Limiting training data: 1000 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  242 samples, 5 features
✅ Client client_61 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

============================================================
🔄 Round 6 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0878, val=0.0847 (↓), lr=0.001000
   • Epoch   2/100: train=0.0878, val=0.0898, patience=1/15, lr=0.001000
   • Epoch   3/100: train=0.0874, val=0.0905, patience=2/15, lr=0.001000
   • Epoch   4/100: train=0.0866, val=0.0886, patience=3/15, lr=0.001000
   • Epoch   5/100: train=0.0855, val=0.0875, patience=4/15, lr=0.001000
   📉 Epoch 7: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0827, val=0.0856, patience=10/15, lr=0.000500
   📉 Epoch 15: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 6 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0861, RMSE=0.2935, R²=0.0040
   Val:   Loss=0.0847, RMSE=0.2910, R²=-0.0521
============================================================


📊 Round 6 Test Metrics:
   Loss: 0.0803, RMSE: 0.2834, MAE: 0.2438, R²: -0.0107

============================================================
🔄 Round 7 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0893 (↓), lr=0.000250
   • Epoch   2/100: train=0.0857, val=0.0892, patience=1/15, lr=0.000250
   • Epoch   3/100: train=0.0855, val=0.0891, patience=2/15, lr=0.000250
   • Epoch   4/100: train=0.0853, val=0.0891, patience=3/15, lr=0.000250
   • Epoch   5/100: train=0.0850, val=0.0891, patience=4/15, lr=0.000250
   📉 Epoch 7: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0842, val=0.0888, patience=10/15, lr=0.000125
   📉 Epoch 15: LR reduced 0.000125 → 0.000063
   • Epoch  21/100: train=0.0837, val=0.0885, patience=9/15, lr=0.000063
   📉 Epoch 23: LR reduced 0.000063 → 0.000031

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0888)

============================================================
📊 Round 7 Summary - Client client_61
   Epochs: 27/100 (early stopped)
   LR: 0.000250 → 0.000031 (3 reductions)
   Train: Loss=0.0841, RMSE=0.2899, R²=0.0126
   Val:   Loss=0.0888, RMSE=0.2980, R²=-0.0185
============================================================


============================================================
🔄 Round 8 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000031
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0888, val=0.0807 (↓), lr=0.000031
   • Epoch   2/100: train=0.0886, val=0.0807, patience=1/15, lr=0.000031
   • Epoch   3/100: train=0.0884, val=0.0807, patience=2/15, lr=0.000031
   • Epoch   4/100: train=0.0883, val=0.0807, patience=3/15, lr=0.000031
   • Epoch   5/100: train=0.0882, val=0.0807, patience=4/15, lr=0.000031
   📉 Epoch 7: LR reduced 0.000031 → 0.000016
   • Epoch  11/100: train=0.0878, val=0.0808, patience=10/15, lr=0.000016
   📉 Epoch 15: LR reduced 0.000016 → 0.000008

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 8 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000031 → 0.000008 (2 reductions)
   Train: Loss=0.0885, RMSE=0.2976, R²=-0.0177
   Val:   Loss=0.0807, RMSE=0.2841, R²=-0.0077
============================================================


============================================================
🔄 Round 9 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000008
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0986 (↓), lr=0.000008
   • Epoch   2/100: train=0.0835, val=0.0986, patience=1/15, lr=0.000008
   • Epoch   3/100: train=0.0835, val=0.0986, patience=2/15, lr=0.000008
   • Epoch   4/100: train=0.0835, val=0.0986, patience=3/15, lr=0.000008
   • Epoch   5/100: train=0.0835, val=0.0986, patience=4/15, lr=0.000008
   📉 Epoch 7: LR reduced 0.000008 → 0.000004
   • Epoch  11/100: train=0.0834, val=0.0986, patience=10/15, lr=0.000004
   📉 Epoch 15: LR reduced 0.000004 → 0.000002

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0986)

============================================================
📊 Round 9 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000008 → 0.000002 (2 reductions)
   Train: Loss=0.0838, RMSE=0.2894, R²=-0.0091
   Val:   Loss=0.0986, RMSE=0.3141, R²=-0.0276
============================================================


📊 Round 9 Test Metrics:
   Loss: 0.0810, RMSE: 0.2846, MAE: 0.2446, R²: -0.0190

============================================================
🔄 Round 12 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000002
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0873, val=0.0863 (↓), lr=0.000002
   • Epoch   2/100: train=0.0873, val=0.0863, patience=1/15, lr=0.000002
   • Epoch   3/100: train=0.0873, val=0.0863, patience=2/15, lr=0.000002
   • Epoch   4/100: train=0.0873, val=0.0864, patience=3/15, lr=0.000002
   • Epoch   5/100: train=0.0873, val=0.0864, patience=4/15, lr=0.000002
   📉 Epoch 7: LR reduced 0.000002 → 0.000001
   • Epoch  11/100: train=0.0872, val=0.0864, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 12 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000002 → 0.000001 (1 reductions)
   Train: Loss=0.0869, RMSE=0.2948, R²=-0.0143
   Val:   Loss=0.0863, RMSE=0.2938, R²=-0.0318
============================================================


============================================================
🔄 Round 13 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0893, val=0.0776 (↓), lr=0.000001
   • Epoch   2/100: train=0.0893, val=0.0776, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0893, val=0.0776, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0893, val=0.0776, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0893, val=0.0776, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0893, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 13 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0892, RMSE=0.2986, R²=-0.0083
   Val:   Loss=0.0776, RMSE=0.2785, R²=-0.0446
============================================================


📊 Round 13 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2447, R²: -0.0174

============================================================
🔄 Round 14 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0871, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0871, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0871, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0871, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0871, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0871, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 14 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0873, RMSE=0.2955, R²=-0.0132
   Val:   Loss=0.0849, RMSE=0.2913, R²=-0.0257
============================================================


============================================================
🔄 Round 16 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0874, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0873, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0873, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0873, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0873, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0873, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 16 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0877, RMSE=0.2962, R²=-0.0148
   Val:   Loss=0.0834, RMSE=0.2888, R²=-0.0158
============================================================


============================================================
🔄 Round 18 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0872, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0872, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0872, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0872, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0872, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0872, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 18 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0870, RMSE=0.2950, R²=-0.0121
   Val:   Loss=0.0857, RMSE=0.2928, R²=-0.0206
============================================================


📊 Round 18 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2448, R²: -0.0177

📊 Round 18 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2448, R²: -0.0175

📊 Round 18 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2447, R²: -0.0176

============================================================
🔄 Round 24 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0879, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0879, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0879, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0879, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0879, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0878, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 24 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0880, RMSE=0.2966, R²=-0.0133
   Val:   Loss=0.0817, RMSE=0.2858, R²=-0.0200
============================================================


============================================================
🔄 Round 25 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0888, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0888, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0888, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0888, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0888, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0888, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 25 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0888, RMSE=0.2980, R²=-0.0164
   Val:   Loss=0.0785, RMSE=0.2802, R²=0.0013
============================================================


============================================================
🔄 Round 26 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0888 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0888, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0888, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0888, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0888, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0887, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0888)

============================================================
📊 Round 26 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2936, R²=-0.0112
   Val:   Loss=0.0888, RMSE=0.2979, R²=-0.0201
============================================================


📊 Round 26 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2448, R²: -0.0178

============================================================
🔄 Round 27 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0878 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0878, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0878, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0878, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0878, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0878, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0878)

============================================================
📊 Round 27 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2940, R²=-0.0165
   Val:   Loss=0.0878, RMSE=0.2964, R²=0.0011
============================================================


============================================================
🔄 Round 28 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0886 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0886, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0886, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0886, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0886, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0886, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0886)

============================================================
📊 Round 28 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2937, R²=-0.0113
   Val:   Loss=0.0886, RMSE=0.2976, R²=-0.0279
============================================================


📊 Round 28 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2447, R²: -0.0178

============================================================
🔄 Round 30 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0921 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0921, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0921, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0921, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0921, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0921, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0921)

============================================================
📊 Round 30 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2922, R²=-0.0230
   Val:   Loss=0.0921, RMSE=0.3034, R²=0.0053
============================================================


📊 Round 30 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2448, R²: -0.0178

============================================================
🔄 Round 31 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0981 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0981, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0981, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0981, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0981, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0981, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0981)

============================================================
📊 Round 31 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2896, R²=-0.0144
   Val:   Loss=0.0981, RMSE=0.3132, R²=-0.0075
============================================================


📊 Round 31 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2448, R²: -0.0178

📊 Round 31 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2448, R²: -0.0178

============================================================
🔄 Round 33 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0873 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0873, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0873, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0873, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0873, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0874, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0873)

============================================================
📊 Round 33 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2942, R²=-0.0113
   Val:   Loss=0.0873, RMSE=0.2955, R²=-0.0452
============================================================


📊 Round 33 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2448, R²: -0.0178

============================================================
🔄 Round 35 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0872, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0872, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0872, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0872, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0872, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0872, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 35 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0872, RMSE=0.2952, R²=-0.0067
   Val:   Loss=0.0850, RMSE=0.2915, R²=-0.0391
============================================================


📊 Round 35 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2448, R²: -0.0178

📊 Round 35 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2448, R²: -0.0178

============================================================
🔄 Round 41 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0882, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0882, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0882, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0882, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0882, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0882, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 41 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0884, RMSE=0.2973, R²=-0.0162
   Val:   Loss=0.0800, RMSE=0.2829, R²=-0.0058
============================================================


📊 Round 41 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2448, R²: -0.0178

============================================================
🔄 Round 44 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0898 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0898, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0898, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0898, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0898, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0898, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0898)

============================================================
📊 Round 44 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2932, R²=-0.0087
   Val:   Loss=0.0898, RMSE=0.2996, R²=-0.0388
============================================================


============================================================
🔄 Round 45 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0878, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0878, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0878, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0878, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0878, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0877, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 45 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0877, RMSE=0.2962, R²=-0.0124
   Val:   Loss=0.0826, RMSE=0.2874, R²=-0.0159
============================================================


============================================================
🔄 Round 46 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0896 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0896, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0896, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0896, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0896, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0897, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0896)

============================================================
📊 Round 46 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2933, R²=-0.0064
   Val:   Loss=0.0896, RMSE=0.2993, R²=-0.0489
============================================================


============================================================
🔄 Round 48 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0866 (↓), lr=0.000001
   • Epoch   2/100: train=0.0867, val=0.0866, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0866, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0866, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0866, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0866, val=0.0866, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0866)

============================================================
📊 Round 48 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0867, RMSE=0.2945, R²=-0.0158
   Val:   Loss=0.0866, RMSE=0.2943, R²=-0.0049
============================================================


📊 Round 48 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2448, R²: -0.0178

============================================================
🔄 Round 50 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0878, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0878, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0878, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0878, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0878, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0877, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 50 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0881, RMSE=0.2968, R²=-0.0201
   Val:   Loss=0.0811, RMSE=0.2848, R²=0.0158
============================================================


📊 Round 50 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2448, R²: -0.0178

============================================================
🔄 Round 51 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0877, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0877, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0877, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0877, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0877, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0877, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 51 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0876, RMSE=0.2960, R²=-0.0177
   Val:   Loss=0.0830, RMSE=0.2881, R²=0.0036
============================================================


📊 Round 51 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2448, R²: -0.0179

📊 Round 51 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2448, R²: -0.0179

============================================================
🔄 Round 55 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0879, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0879, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0879, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0879, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0879, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0878, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 55 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0879, RMSE=0.2964, R²=-0.0112
   Val:   Loss=0.0821, RMSE=0.2866, R²=-0.0209
============================================================


============================================================
🔄 Round 56 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0904 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0904, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0904, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0904, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0904, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0905, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0904)

============================================================
📊 Round 56 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2929, R²=-0.0097
   Val:   Loss=0.0904, RMSE=0.3007, R²=-0.0257
============================================================


📊 Round 56 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2448, R²: -0.0179

============================================================
🔄 Round 57 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0940 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0941, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0941, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0941, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0941, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0941, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0940)

============================================================
📊 Round 57 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2913, R²=-0.0093
   Val:   Loss=0.0940, RMSE=0.3067, R²=-0.0342
============================================================


📊 Round 57 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2448, R²: -0.0180

📊 Round 57 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2448, R²: -0.0179

📊 Round 57 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2448, R²: -0.0179

📊 Round 57 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2448, R²: -0.0179

============================================================
🔄 Round 63 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0870, val=0.0870 (↓), lr=0.000001
   • Epoch   2/100: train=0.0870, val=0.0870, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0870, val=0.0870, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0870, val=0.0870, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0870, val=0.0870, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0869, val=0.0870, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 63 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2944, R²=-0.0092
   Val:   Loss=0.0870, RMSE=0.2949, R²=-0.0331
============================================================


📊 Round 63 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2448, R²: -0.0179

📊 Round 63 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2448, R²: -0.0179

============================================================
🔄 Round 68 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0868, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0868, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0867, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0867, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0867, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 68 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2947, R²=-0.0110
   Val:   Loss=0.0862, RMSE=0.2936, R²=-0.0198
============================================================


📊 Round 68 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2448, R²: -0.0178

📊 Round 68 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2448, R²: -0.0178

============================================================
🔄 Round 71 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0923 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0923, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0923, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0923, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0923, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0923, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0923)

============================================================
📊 Round 71 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2921, R²=-0.0126
   Val:   Loss=0.0923, RMSE=0.3038, R²=-0.0130
============================================================


📊 Round 71 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2448, R²: -0.0178

============================================================
🔄 Round 73 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0890, val=0.0772 (↓), lr=0.000001
   • Epoch   2/100: train=0.0890, val=0.0772, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0890, val=0.0772, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0890, val=0.0772, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0890, val=0.0772, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0889, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 73 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0891, RMSE=0.2985, R²=-0.0131
   Val:   Loss=0.0772, RMSE=0.2778, R²=-0.0110
============================================================


📊 Round 73 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2448, R²: -0.0178

============================================================
🔄 Round 74 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0885 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0886, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0886, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0886, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0886, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0886, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0885)

============================================================
📊 Round 74 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2937, R²=-0.0106
   Val:   Loss=0.0885, RMSE=0.2976, R²=-0.0346
============================================================


📊 Round 74 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2448, R²: -0.0178

============================================================
🔄 Round 76 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0870, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0870, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0870, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0870, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0870, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0869, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 76 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0870, RMSE=0.2950, R²=-0.0162
   Val:   Loss=0.0854, RMSE=0.2922, R²=-0.0050
============================================================


============================================================
🔄 Round 79 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0904 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0904, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0904, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0904, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0904, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0904, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0904)

============================================================
📊 Round 79 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2929, R²=-0.0097
   Val:   Loss=0.0904, RMSE=0.3007, R²=-0.0342
============================================================


============================================================
🔄 Round 81 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0886 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0886, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0886, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0886, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0886, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0886, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0886)

============================================================
📊 Round 81 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2936, R²=-0.0112
   Val:   Loss=0.0886, RMSE=0.2977, R²=-0.0242
============================================================


📊 Round 81 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2448, R²: -0.0178

============================================================
🔄 Round 82 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0877 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0877, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0877, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0877, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0877, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0866, val=0.0877, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0877)

============================================================
📊 Round 82 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2940, R²=-0.0152
   Val:   Loss=0.0877, RMSE=0.2961, R²=-0.0030
============================================================


============================================================
🔄 Round 84 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0876, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0876, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0876, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0876, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0876, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0876, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 84 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0879, RMSE=0.2965, R²=-0.0076
   Val:   Loss=0.0820, RMSE=0.2863, R²=-0.0370
============================================================


📊 Round 84 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2448, R²: -0.0178

📊 Round 84 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2448, R²: -0.0178

📊 Round 84 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2448, R²: -0.0178

============================================================
🔄 Round 88 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0874, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0874, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0874, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0874, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0874, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0873, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 88 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0874, RMSE=0.2957, R²=-0.0195
   Val:   Loss=0.0837, RMSE=0.2894, R²=0.0028
============================================================


📊 Round 88 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2448, R²: -0.0178

============================================================
🔄 Round 92 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0864, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0864, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 92 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2946, R²=-0.0142
   Val:   Loss=0.0864, RMSE=0.2940, R²=-0.0124
============================================================


📊 Round 92 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2448, R²: -0.0177

📊 Round 92 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2448, R²: -0.0178

============================================================
🔄 Round 95 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0894, val=0.0763 (↓), lr=0.000001
   • Epoch   2/100: train=0.0894, val=0.0763, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0894, val=0.0763, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0894, val=0.0763, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0894, val=0.0763, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0894, val=0.0763, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0763)

============================================================
📊 Round 95 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0893, RMSE=0.2989, R²=-0.0138
   Val:   Loss=0.0763, RMSE=0.2761, R²=-0.0161
============================================================


📊 Round 95 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2448, R²: -0.0178

============================================================
🔄 Round 97 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0909 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0909, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0909, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0909, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0909, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0910, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0909)

============================================================
📊 Round 97 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2927, R²=-0.0133
   Val:   Loss=0.0909, RMSE=0.3015, R²=-0.0141
============================================================


📊 Round 97 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2448, R²: -0.0178

============================================================
🔄 Round 98 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0888 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0888, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0888, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0888, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0888, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0888, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0888)

============================================================
📊 Round 98 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2936, R²=-0.0156
   Val:   Loss=0.0888, RMSE=0.2980, R²=-0.0016
============================================================


📊 Round 98 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2448, R²: -0.0178

📊 Round 98 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2448, R²: -0.0177

============================================================
🔄 Round 101 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0875, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0875, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0875, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0875, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0875, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0875, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 101 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0878, RMSE=0.2963, R²=-0.0187
   Val:   Loss=0.0823, RMSE=0.2868, R²=0.0110
============================================================


============================================================
🔄 Round 102 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0929 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0929, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0929, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0929, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0929, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0929, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0929)

============================================================
📊 Round 102 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2918, R²=-0.0106
   Val:   Loss=0.0929, RMSE=0.3047, R²=-0.0293
============================================================


📊 Round 102 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2448, R²: -0.0177

📊 Round 102 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2448, R²: -0.0177

📊 Round 102 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2448, R²: -0.0177

============================================================
🔄 Round 110 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0914 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0914, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0914, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0914, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0914, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0914, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0914)

============================================================
📊 Round 110 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2924, R²=-0.0081
   Val:   Loss=0.0914, RMSE=0.3024, R²=-0.0318
============================================================


============================================================
🔄 Round 112 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0914 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0914, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0914, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0914, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0914, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0915, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0914)

============================================================
📊 Round 112 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2925, R²=-0.0137
   Val:   Loss=0.0914, RMSE=0.3023, R²=-0.0320
============================================================


📊 Round 112 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2448, R²: -0.0177

📊 Round 112 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2448, R²: -0.0177

============================================================
🔄 Round 114 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0970 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0970, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0970, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0970, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0970, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0970, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0970)

============================================================
📊 Round 114 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2901, R²=-0.0117
   Val:   Loss=0.0970, RMSE=0.3114, R²=-0.0271
============================================================


📊 Round 114 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2448, R²: -0.0177

============================================================
🔄 Round 117 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0865, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0865, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 117 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2946, R²=-0.0120
   Val:   Loss=0.0864, RMSE=0.2940, R²=-0.0206
============================================================


📊 Round 117 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2448, R²: -0.0177

============================================================
🔄 Round 120 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0869, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0869, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0869, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0869, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0869, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0869, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 120 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0869, RMSE=0.2948, R²=-0.0064
   Val:   Loss=0.0858, RMSE=0.2930, R²=-0.0419
============================================================


📊 Round 120 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2448, R²: -0.0176

📊 Round 120 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2448, R²: -0.0176

============================================================
🔄 Round 125 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0927 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0927, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0927, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0927, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0927, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0927, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0927)

============================================================
📊 Round 125 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2919, R²=-0.0115
   Val:   Loss=0.0927, RMSE=0.3044, R²=-0.0253
============================================================


📊 Round 125 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2448, R²: -0.0176

============================================================
🔄 Round 126 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0872, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0872, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0872, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0872, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0872, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0872, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 126 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0870, RMSE=0.2950, R²=-0.0087
   Val:   Loss=0.0854, RMSE=0.2922, R²=-0.0291
============================================================


============================================================
🔄 Round 129 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0939 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0939, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0939, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0939, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0939, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0939, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0939)

============================================================
📊 Round 129 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=-0.0119
   Val:   Loss=0.0939, RMSE=0.3065, R²=-0.0172
============================================================


📊 Round 129 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2448, R²: -0.0178

📊 Round 129 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2448, R²: -0.0178

📊 Round 129 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2448, R²: -0.0178

📊 Round 129 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2448, R²: -0.0179

============================================================
🔄 Round 139 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0874, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0874, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0874, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0874, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0874, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0873, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 139 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0871, RMSE=0.2951, R²=-0.0164
   Val:   Loss=0.0852, RMSE=0.2918, R²=0.0017
============================================================


📊 Round 139 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2448, R²: -0.0178

============================================================
🔄 Round 140 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0888 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0888, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0888, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0888, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0888, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0888, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0888)

============================================================
📊 Round 140 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2936, R²=-0.0107
   Val:   Loss=0.0888, RMSE=0.2980, R²=-0.0211
============================================================


📊 Round 140 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2448, R²: -0.0178

📊 Round 140 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2448, R²: -0.0178

============================================================
🔄 Round 143 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0871, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0871, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0871, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0870, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0870, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0870, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 143 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0870, RMSE=0.2949, R²=-0.0126
   Val:   Loss=0.0855, RMSE=0.2925, R²=-0.0128
============================================================


📊 Round 143 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2448, R²: -0.0178

============================================================
🔄 Round 144 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0874, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0874, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0874, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0874, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0874, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0874, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 144 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0870, RMSE=0.2950, R²=-0.0133
   Val:   Loss=0.0853, RMSE=0.2921, R²=-0.0099
============================================================


📊 Round 144 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2448, R²: -0.0178

============================================================
🔄 Round 145 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0869 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0869, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0869, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0869, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0869, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0869, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 145 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0867, RMSE=0.2944, R²=-0.0100
   Val:   Loss=0.0869, RMSE=0.2947, R²=-0.0235
============================================================


📊 Round 145 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2448, R²: -0.0178

============================================================
🔄 Round 146 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0907 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0907, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0907, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0907, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0907, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0907, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0907)

============================================================
📊 Round 146 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2927, R²=-0.0134
   Val:   Loss=0.0907, RMSE=0.3012, R²=-0.0149
============================================================


📊 Round 146 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2448, R²: -0.0177

============================================================
🔄 Round 148 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0872, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0872, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0872, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0872, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0872, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0872, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 148 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0873, RMSE=0.2955, R²=-0.0092
   Val:   Loss=0.0843, RMSE=0.2904, R²=-0.0278
============================================================


📊 Round 148 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2448, R²: -0.0177

📊 Round 148 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2448, R²: -0.0178

============================================================
🔄 Round 153 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0972 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0972, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0972, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0972, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0972, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0973, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0972)

============================================================
📊 Round 153 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2900, R²=-0.0063
   Val:   Loss=0.0972, RMSE=0.3118, R²=-0.0398
============================================================


📊 Round 153 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2448, R²: -0.0178

============================================================
🔄 Round 155 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0874, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0874, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0874, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0874, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0874, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0874, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 155 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0877, RMSE=0.2962, R²=-0.0109
   Val:   Loss=0.0826, RMSE=0.2874, R²=-0.0300
============================================================


📊 Round 155 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2448, R²: -0.0178

============================================================
🔄 Round 159 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0886 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0886, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0886, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0886, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0886, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0886, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0886)

============================================================
📊 Round 159 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2936, R²=-0.0108
   Val:   Loss=0.0886, RMSE=0.2977, R²=-0.0225
============================================================


============================================================
🔄 Round 160 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0877, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0877, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0877, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0877, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0877, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0876, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 160 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0878, RMSE=0.2962, R²=-0.0148
   Val:   Loss=0.0825, RMSE=0.2872, R²=-0.0100
============================================================


============================================================
🔄 Round 161 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0880, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0880, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0880, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0880, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0880, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0880, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 161 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0882, RMSE=0.2970, R²=-0.0150
   Val:   Loss=0.0806, RMSE=0.2839, R²=-0.0031
============================================================


📊 Round 161 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2448, R²: -0.0178

============================================================
🔄 Round 162 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0870, val=0.0869 (↓), lr=0.000001
   • Epoch   2/100: train=0.0870, val=0.0869, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0870, val=0.0869, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0870, val=0.0869, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0870, val=0.0869, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0870, val=0.0869, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 162 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2944, R²=-0.0157
   Val:   Loss=0.0869, RMSE=0.2948, R²=-0.0024
============================================================


📊 Round 162 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2448, R²: -0.0178

============================================================
🔄 Round 163 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0884, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0883, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0883, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0883, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0883, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0883, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 163 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0883, RMSE=0.2972, R²=-0.0172
   Val:   Loss=0.0801, RMSE=0.2830, R²=0.0075
============================================================


============================================================
🔄 Round 164 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0974 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0974, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0974, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0974, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0974, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0974, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0974)

============================================================
📊 Round 164 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2899, R²=-0.0086
   Val:   Loss=0.0974, RMSE=0.3121, R²=-0.0277
============================================================


============================================================
🔄 Round 165 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0874, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0874, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0874, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0874, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0874, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0874, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 165 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0878, RMSE=0.2963, R²=-0.0088
   Val:   Loss=0.0822, RMSE=0.2868, R²=-0.0289
============================================================


📊 Round 165 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2448, R²: -0.0178

📊 Round 165 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2448, R²: -0.0178

============================================================
🔄 Round 167 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0961 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0961, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0961, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0961, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0961, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0960, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0961)

============================================================
📊 Round 167 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2904, R²=-0.0053
   Val:   Loss=0.0961, RMSE=0.3100, R²=-0.0418
============================================================


============================================================
🔄 Round 168 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0890 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0890, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0890, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0890, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0890, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0890, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0890)

============================================================
📊 Round 168 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2934, R²=-0.0114
   Val:   Loss=0.0890, RMSE=0.2984, R²=-0.0273
============================================================


📊 Round 168 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2448, R²: -0.0178

============================================================
🔄 Round 171 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0894, val=0.0754 (↓), lr=0.000001
   • Epoch   2/100: train=0.0893, val=0.0754, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0893, val=0.0755, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0893, val=0.0755, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0893, val=0.0755, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0893, val=0.0755, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0754)

============================================================
📊 Round 171 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0895, RMSE=0.2992, R²=-0.0042
   Val:   Loss=0.0754, RMSE=0.2747, R²=-0.0697
============================================================


📊 Round 171 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2448, R²: -0.0178

📊 Round 171 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2448, R²: -0.0178

============================================================
🔄 Round 175 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.1009 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.1009, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.1009, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.1009, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.1009, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.1009, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.1009)

============================================================
📊 Round 175 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=-0.0149
   Val:   Loss=0.1009, RMSE=0.3176, R²=-0.0110
============================================================


📊 Round 175 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2448, R²: -0.0177

📊 Round 175 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2448, R²: -0.0178

📊 Round 175 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2448, R²: -0.0178

============================================================
🔄 Round 180 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0944 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0944, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0944, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0944, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0944, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0944, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0944)

============================================================
📊 Round 180 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2911, R²=-0.0055
   Val:   Loss=0.0944, RMSE=0.3073, R²=-0.0417
============================================================


============================================================
🔄 Round 182 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0881 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0881, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0881, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0881, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0881, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0881, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0881)

============================================================
📊 Round 182 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2939, R²=-0.0172
   Val:   Loss=0.0881, RMSE=0.2968, R²=-0.0037
============================================================


📊 Round 182 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2448, R²: -0.0178

📊 Round 182 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2448, R²: -0.0178

============================================================
🔄 Round 184 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0868, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0868, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0868, val=0.0859, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0868, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0868, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 184 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0869, RMSE=0.2948, R²=-0.0134
   Val:   Loss=0.0859, RMSE=0.2930, R²=-0.0097
============================================================


📊 Round 184 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2448, R²: -0.0178

📊 Round 184 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2448, R²: -0.0178

============================================================
🔄 Round 187 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0885, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0885, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0885, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0885, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0885, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0885, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 187 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0885, RMSE=0.2975, R²=-0.0138
   Val:   Loss=0.0794, RMSE=0.2817, R²=-0.0087
============================================================


============================================================
🔄 Round 188 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0871, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0871, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0871, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0871, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0871, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0870, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 188 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0872, RMSE=0.2953, R²=-0.0091
   Val:   Loss=0.0846, RMSE=0.2908, R²=-0.0277
============================================================


============================================================
🔄 Round 189 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0872, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0872, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0872, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0872, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0872, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0872, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 189 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0871, RMSE=0.2951, R²=-0.0111
   Val:   Loss=0.0852, RMSE=0.2919, R²=-0.0189
============================================================


============================================================
🔄 Round 190 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0907 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0907, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0907, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0907, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0907, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0907, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0907)

============================================================
📊 Round 190 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2927, R²=-0.0139
   Val:   Loss=0.0907, RMSE=0.3011, R²=-0.0169
============================================================


============================================================
🔄 Round 191 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0877, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0877, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0877, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0877, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0877, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0876, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 191 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0877, RMSE=0.2961, R²=-0.0218
   Val:   Loss=0.0828, RMSE=0.2878, R²=-0.0033
============================================================


📊 Round 191 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2447, R²: -0.0179

============================================================
🔄 Round 193 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0871, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0871, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0871, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0871, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0871, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0871, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 193 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0870, RMSE=0.2950, R²=-0.0130
   Val:   Loss=0.0853, RMSE=0.2921, R²=-0.0104
============================================================


============================================================
🔄 Round 194 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0868 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0868, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0868, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0868, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0868, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0868, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0868)

============================================================
📊 Round 194 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0867, RMSE=0.2944, R²=-0.0138
   Val:   Loss=0.0868, RMSE=0.2947, R²=-0.0145
============================================================


📊 Round 194 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2447, R²: -0.0179

📊 Round 194 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2447, R²: -0.0179

📊 Round 194 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2447, R²: -0.0179

============================================================
🔄 Round 199 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0869, val=0.0867 (↓), lr=0.000001
   • Epoch   2/100: train=0.0869, val=0.0867, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0868, val=0.0867, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0868, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0868, val=0.0868, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0868, val=0.0868, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 199 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0867, RMSE=0.2944, R²=-0.0117
   Val:   Loss=0.0867, RMSE=0.2945, R²=-0.0216
============================================================


📊 Round 199 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2447, R²: -0.0179

============================================================
🔄 Round 204 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0938 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0938, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0938, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0938, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0938, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0938, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0938)

============================================================
📊 Round 204 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=-0.0099
   Val:   Loss=0.0938, RMSE=0.3063, R²=-0.0236
============================================================


📊 Round 204 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2447, R²: -0.0180

============================================================
🔄 Round 207 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0892, val=0.0768 (↓), lr=0.000001
   • Epoch   2/100: train=0.0892, val=0.0768, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0892, val=0.0768, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0891, val=0.0768, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0891, val=0.0768, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0891, val=0.0768, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0768)

============================================================
📊 Round 207 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0892, RMSE=0.2986, R²=-0.0146
   Val:   Loss=0.0768, RMSE=0.2771, R²=-0.0134
============================================================


📊 Round 207 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2447, R²: -0.0180

============================================================
🔄 Round 211 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0899 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0899, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0899, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0899, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0899, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0899, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0899)

============================================================
📊 Round 211 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2931, R²=-0.0115
   Val:   Loss=0.0899, RMSE=0.2999, R²=-0.0164
============================================================


📊 Round 211 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2447, R²: -0.0179

📊 Round 211 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2448, R²: -0.0179

📊 Round 211 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2447, R²: -0.0180

============================================================
🔄 Round 215 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0869, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0869, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0869, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0869, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0869, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0868, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 215 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0869, RMSE=0.2948, R²=-0.0120
   Val:   Loss=0.0858, RMSE=0.2930, R²=-0.0145
============================================================


============================================================
🔄 Round 222 - Client client_61
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0909 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0909, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0909, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0909, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0909, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0909, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0909)

============================================================
📊 Round 222 Summary - Client client_61
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2926, R²=-0.0090
   Val:   Loss=0.0909, RMSE=0.3015, R²=-0.0266
============================================================


📊 Round 222 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2448, R²: -0.0179

📊 Round 222 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2448, R²: -0.0179

❌ Client client_61 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8687 {grpc_message:"Socket closed", grpc_status:14}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8687 {grpc_message:"Socket closed", grpc_status:14}"
>
