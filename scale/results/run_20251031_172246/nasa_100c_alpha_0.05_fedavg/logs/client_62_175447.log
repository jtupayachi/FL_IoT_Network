[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 414e32f0-8ed9-4c49-99e7-2f903f593254
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1450fd03-964a-4ba0-b934-547c249c969f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1f313967-d245-4bb1-873c-cbf07d8b500a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 86bb83fb-badc-43ea-8245-dd41a8ef55e9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fb24acb2-abb7-4ff4-9df2-84520b8dc92c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9414cbc7-b7cd-47a5-bf1e-74669c42494e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 36629722-5234-4436-bbfc-25400dea5eb8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e0b6a2fe-9104-4e20-8175-f5b706cc1bc7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4a5b17c9-c9db-424e-9254-2f003c90055e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b4521e65-98e4-4a95-b89e-f4431c1e2692
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3f5cccb6-0a9f-4ad3-9eb5-8662cebac9c7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d860f35e-b0c4-4e4f-a1c6-19757025fb4a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 84ceda3a-67a3-4986-9235-6a823c3a230e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d874755a-60af-4c06-9a99-f79620a0827b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b726e839-4c65-434c-b034-1456cc6517af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2f2dc3f2-a9fe-41b6-aba8-1a2e22e6268a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 26b805fa-2136-431a-a104-4b151874db06
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8f89803a-6004-4353-9a23-3fabf0f13b07
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bb925be1-2e8d-4bca-9496-8872d394bdde
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 13a91017-8e75-4e28-8ede-8591a562fca2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0ebd9b51-fdf1-4610-b9a0-7a7b2227f515
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b95aac42-2dcc-4a63-9b44-7702d41ce5cb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f5232bcb-0385-4d83-9531-43ce6483f114
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7e50a147-cf8c-4a14-9e87-da6b88a4dda8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fc958835-a76a-4dff-858a-9bd9a8bde886
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f8a942af-b80e-45b5-b0b8-c7b632fd74f8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cc74f1ef-c832-4425-82cc-c51f9db74951
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1b3b3023-202c-401b-948b-72eb7d6bb280
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8345666c-a5b4-425c-9e7c-9ff437195584
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 76eb7f63-0151-42e0-88ca-1e16193cb9a9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 65810858-47dd-4fa3-a3d9-0722ac59c3ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0fd4d73e-f3f5-4722-ae3e-f8d1125412c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d33a6239-cd20-4dd4-b9da-fff5396d57b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 46028392-dda9-4afb-9d43-376147de6f34
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9f13124f-96dd-43b3-8049-a09c41a0ffe1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 94eecbe2-3193-4aad-9b44-1626dfb85762
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c8006a1a-a54b-4acc-b897-545cd351f076
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6d29af23-5ee8-4e65-a023-aad312802907
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6884e797-162f-48fc-8856-ea5925bdec8e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ac73d524-92c5-4d7f-b9f5-b31a6d284960
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d64486ea-cf3c-4c77-b20c-c6c06f6d496b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 33f2cd8e-f6cf-4bcd-abbb-c2fc2f8a852e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3b7451e9-5aea-46f6-abeb-417e887eb06c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6262db3b-edd7-4682-8f89-06f6cb6a322a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d01e158e-7b2e-4479-8ab1-671ff806f231
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8b5b0854-4411-436f-afa9-4109cf20acf0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 32e929d5-3036-4137-a4b3-4d9197b0e502
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 30d00fcc-8a6a-47c2-acb9-a59209987e6b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 249db8b3-ab3c-4135-938e-6d881f7d5ad7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7471c7b4-4e64-4e6f-89f5-f2ce8904ac0a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9a39421d-b172-45b7-b503-77944ad07803
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e10274fc-5e49-466c-8982-db71c1f1faf2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7a0f4e10-994d-4fea-83ba-1e64e342a8cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c365ed13-16f0-4731-89af-d276863b6111
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ca753f02-ab03-4455-8194-526153f6c8df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5c792cf9-46c0-4fba-bf47-ab8a4a866956
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 94d6cd27-ad3b-4663-848e-524ae04e3217
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 254a1d97-4586-4844-ad96-1e5a8b28c256
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 831bc470-ac1c-4ead-aafe-ab9efccaaa6a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1ae8f3ab-00c2-46fe-89db-0efedf8d06ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7389f4ff-ef84-4de4-ac6c-00fb0816cef7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 92cfcfb1-b18a-4b60-be12-f17f91ccec99
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3ce69c6c-cc3b-4876-a809-405167f3b85b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d46e1d5d-fc22-47a3-b64a-507a07fd7ea7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 201c4542-65e9-4f40-8c62-67dffb06bb9f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fe4c2380-e5db-49e3-aa55-9bc148fac688
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2c31c3a2-dc0b-4409-8850-367fcd7bc1e0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ef62129d-83a4-45e0-9f1f-1efa85ca4e27
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message df7a5cea-1bfa-4894-a509-512f89fd7dae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message be956871-4d2d-41b9-9f25-d39f715bc4f2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d65affde-8fcb-48e8-ac02-24466e0e6dfb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fe1fa4b5-6934-445a-a6ae-538490276377
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fa4d995a-cb15-4cda-b24a-fd35733ffb62
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 585053ce-4c18-4326-a3b8-408729a26005
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7f483d3c-2817-4687-8de9-2b64d6a22550
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 878a3c5d-51f3-4cee-96cc-df6a4a329a4b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ea1acd0b-7c33-4b46-a9b6-8b32d7d8e58c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 48433cb2-4559-4976-8919-c0f0be60fb97
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 01caf64e-d899-47b9-83cc-e153907f75ce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4a83eeae-6dba-43bb-b835-e99ff4c4b2bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 280c225d-5c5b-4711-8f46-283dd4991d72
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0bfff941-9b3e-4f07-804d-78cbe3286115
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 08baccf3-1658-4f93-8e77-46fec7eb0c8d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bb4e3848-9670-46a6-a597-5df42e2666e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 05c273d9-3797-4ef1-bfaa-4aec13ba31c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 57e3675a-5371-4701-ba98-cadc1f7b11fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 85b11e87-9ebd-4c6c-8e60-317f1b7ca5dd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ae5b7a8c-7aa6-4da1-81b9-7b5716d839e5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bbdcf4ee-f5d4-4dd8-8bde-dc57ce4b3878
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ae469dcf-e091-4bfb-8654-9c972e1129be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 46afed36-8423-43cb-bbd8-a935564f6c01
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6cb3f802-5a2e-4d84-a515-7166fb7b5d97
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a73aaa69-cf3e-4c96-a6b4-660a44f44b4d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 034f5eda-2567-4b9c-ab73-4d431cfce286
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 23282f82-af8d-41d1-a552-8c656391fb00
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c30d6566-44c8-47a1-a6d4-b088e87ae131
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a9bef7d4-67b1-4e79-a43c-11f3202f678e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5da2a363-9076-48cc-a75d-8284d88b9edf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dce65ab8-0d65-477a-a934-1573e23dc61f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e0076d8d-2b4a-49e8-8f17-fc65f7240eca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9dbf8183-a5ac-4d60-a586-5a9c39edfa7c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fd2df159-e59d-473e-8210-c9296fe95853
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 113339c6-c7f8-4ecf-a8e1-167d50fbe624
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e9f6aba2-7530-4650-90a0-6a14b9e64d82
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 57d54637-e862-4388-a759-97914b33fcc7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 86f0ddad-ccf2-42a8-a3cc-66483eaf28b8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0dad56f1-2727-443f-96fc-98e13d02d185
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 66de9eb1-892e-49c7-bfd2-31f0bd177198
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c724f3c3-71e2-4fde-871d-093399c4ce31
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bd1c7795-7467-4afd-a9e9-7eeb0c5463d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message feeb5ce9-69bb-443a-9864-fa6dddd9bc5c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9f5233a9-90a6-4940-832f-c416bdde1c65
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b96e0180-9770-4bd1-b8a1-cf307d2d156e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a06c1529-a912-42c6-880c-4015655f11f2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 129c41ba-e4a1-4c7d-9d75-f0c8ee885eaa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 42075336-92be-4839-b9ae-b42e0252e174
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9ee69df8-e491-4f5c-a3fa-b15ac432636c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9c941329-2076-4bed-a97f-98464ed89992
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f2661f27-d976-4922-a7ae-ca305e6f0db1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 20f340ce-caa9-4e1f-8a81-9983b7557617
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f128ea19-75c4-49b1-b616-7d370444a6a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 072249a2-9c3d-4da9-8110-c644623614db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 69f9dc66-1e88-4d2e-b421-01800dca18fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 396a2f55-6254-4f8d-93d4-582c3e54c388
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b2994946-6087-43c0-85fe-a7603529bbc9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3cc07e8a-809c-4b5a-9b04-be601d9abc7c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cece245f-0d28-4ecc-bc17-0decbf42ff5e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1714d088-d75a-4330-82ac-76f3920f83fb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bcf6e447-c165-43e0-9fae-f40005d1ea55
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b9f991de-023a-48d1-8fc4-773bf80aa9d8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0d8284f4-36ef-43a2-9e0d-8c1a19853bff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4a23e5f1-544d-47b1-813f-017419089c03
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5b2bcea1-3b47-4ef0-b6c7-af56b615eb98
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 10350ea6-24ad-41fd-8fa8-d41f54be7241
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ba8a0c5a-677c-4390-86a5-0d521f5b4793
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 201c59b4-17f2-481c-829c-2b036d111932
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3557552e-5371-4375-8b10-a82bb4eec0c4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 619a326e-7cc4-4c2e-b0f7-cc1b19487ec6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a515eb19-651d-4104-8e9e-5267beffa487
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 19e6e9ef-a66a-49c3-a797-7089050b1958
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c3143bd3-d3ed-4301-853c-09ede5528f44
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9a7ee7a1-6348-4535-a89e-ce9271e4dcff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4d46b2ac-1e66-4a26-883f-389644497e6d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2eb50c57-cda7-4843-a4fe-96f7143c926a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0cef07ef-c39f-4f48-a3dd-2e51b8f91fab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b67c4cd9-108b-4836-8012-b3d867720a63
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b821a054-7c98-4913-9f16-c5189b08a7be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f594336d-848d-49aa-8934-6ce1723e3481
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5c0ab465-d0ae-45cf-a0ff-3f5dbaaf5be4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 13de2ce6-955b-446c-91f4-2f49709e9a75
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d6e82b48-10ba-4aa1-87e2-d18b8fb70e66
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 614aeadb-c844-4807-b118-4de3cb3b25b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e4fb0266-254c-4a4e-a612-cad36b8619e1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fdc0e61f-d4b6-48de-bfef-a2733bd0b1dd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3341659d-5a28-4071-a114-55ac0891b70a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 089879b5-cf43-44b7-ba4b-99c194eb4a23
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3a255c26-85d3-41d1-85fe-b112632ca6c7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message de09f601-294b-4365-852b-e71d71dfa2de
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f6d509c9-f6bd-4887-b643-4eb6661d0d1e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 32a5be43-6412-4000-885e-22e57de25804
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1354625d-355d-4a7b-9df3-f86cf2fa1fd0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6a6ad9b7-7bd7-494d-b791-c5d751ab6c4a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d8851df7-ed76-4275-9db7-7bcd51532a74
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 502d4b91-6e91-4c5f-a29d-76dd0f448204
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 11916560-47cd-42a6-9564-4e7b7d5240ba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bd231a0b-5845-404c-92e8-4c55c86a43e5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e9676b9f-9fad-4d83-a71d-5989d5f410c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 90571feb-55f7-49fe-9ed7-32cbda0a31d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5b06ac15-fdcd-43e2-94ba-3232ddc7c5cd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d5d1ebe1-c73c-43b9-9742-55d9e5549bc3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b304f46e-0c51-4e11-b5c1-c0a058a5f5e6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5ff553b1-e3c5-4237-9dd3-249521c1c10c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 090dc17b-49ad-4d10-a63e-0bbbe33e1fe2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 28656411-8da1-4b0f-8dca-8a5d3eddf152
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7d6a1b28-04a7-422b-8061-edd1606dc659
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 12e9345d-09e4-4334-a663-9d352ba55768
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 79ac4d21-ab11-4b60-b3f6-0a03734185ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9e70c2c3-c893-4694-a931-cc3a64bd2da7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fa87e19a-ff48-4e9d-ab3a-cd7963d9cdae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 32f43491-3b25-421a-8783-12acf1efa338
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 931835ae-0ae2-47b3-a760-61fa978df7cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 16c415c4-9c2b-41fc-85f9-4959e7612d45
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f450608b-0e24-4eb2-8751-2bd4ab7da9f3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 62dc341b-029a-444b-9875-56837b63129c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 181bb685-4750-4a1a-bad2-ab3e6ee809bc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c0000d03-951d-4615-bc92-4386f1649e04
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8687 {grpc_status:14, grpc_message:"Socket closed"}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_62
Server: localhost:8687
Algorithm: FEDAVG
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_62
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_62/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_62/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_62/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_62/test_labels.txt

📊 Raw data loaded:
   Train: X=(1464, 24), y=(1464,)
   Test:  X=(367, 24), y=(367,)

⚠️  Limiting training data: 1464 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  358 samples, 5 features
✅ Client client_62 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

📊 Round 0 Test Metrics:
   Loss: 0.0879, RMSE: 0.2964, MAE: 0.2586, R²: -0.0603

============================================================
🔄 Round 8 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0890, val=0.0862 (↓), lr=0.001000
   ✓ Epoch   2/100: train=0.0892, val=0.0849 (↓), lr=0.001000
   • Epoch   3/100: train=0.0863, val=0.0849, patience=1/15, lr=0.001000
   • Epoch   4/100: train=0.0851, val=0.0849, patience=2/15, lr=0.001000
   • Epoch   5/100: train=0.0852, val=0.0851, patience=3/15, lr=0.001000
   📉 Epoch 9: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0821, val=0.0861, patience=9/15, lr=0.000500
   📉 Epoch 17: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 8 Summary - Client client_62
   Epochs: 17/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0839, RMSE=0.2896, R²=-0.0008
   Val:   Loss=0.0849, RMSE=0.2914, R²=-0.0133
============================================================


============================================================
🔄 Round 10 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0875, val=0.0828 (↓), lr=0.000250
   • Epoch   2/100: train=0.0861, val=0.0823, patience=1/15, lr=0.000250
   • Epoch   3/100: train=0.0855, val=0.0829, patience=2/15, lr=0.000250
   • Epoch   4/100: train=0.0852, val=0.0830, patience=3/15, lr=0.000250
   • Epoch   5/100: train=0.0850, val=0.0831, patience=4/15, lr=0.000250
   📉 Epoch 8: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0840, val=0.0832, patience=10/15, lr=0.000125
   📉 Epoch 16: LR reduced 0.000125 → 0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 10 Summary - Client client_62
   Epochs: 16/100 (early stopped)
   LR: 0.000250 → 0.000063 (2 reductions)
   Train: Loss=0.0862, RMSE=0.2936, R²=-0.0063
   Val:   Loss=0.0828, RMSE=0.2877, R²=-0.0875
============================================================


📊 Round 10 Test Metrics:
   Loss: 0.0885, RMSE: 0.2975, MAE: 0.2598, R²: -0.0684

============================================================
🔄 Round 12 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0891, val=0.0740 (↓), lr=0.000063
   • Epoch   2/100: train=0.0885, val=0.0737, patience=1/15, lr=0.000063
   • Epoch   3/100: train=0.0880, val=0.0738, patience=2/15, lr=0.000063
   • Epoch   4/100: train=0.0877, val=0.0738, patience=3/15, lr=0.000063
   • Epoch   5/100: train=0.0875, val=0.0738, patience=4/15, lr=0.000063
   📉 Epoch 8: LR reduced 0.000063 → 0.000031
   • Epoch  11/100: train=0.0870, val=0.0740, patience=10/15, lr=0.000031
   📉 Epoch 16: LR reduced 0.000031 → 0.000016

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0740)

============================================================
📊 Round 12 Summary - Client client_62
   Epochs: 16/100 (early stopped)
   LR: 0.000063 → 0.000016 (2 reductions)
   Train: Loss=0.0889, RMSE=0.2982, R²=-0.0303
   Val:   Loss=0.0740, RMSE=0.2720, R²=-0.0001
============================================================


📊 Round 12 Test Metrics:
   Loss: 0.0887, RMSE: 0.2978, MAE: 0.2602, R²: -0.0701

📊 Round 12 Test Metrics:
   Loss: 0.0893, RMSE: 0.2989, MAE: 0.2610, R²: -0.0782

============================================================
🔄 Round 16 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000016
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0869, val=0.0890 (↓), lr=0.000016
   • Epoch   2/100: train=0.0868, val=0.0887, patience=1/15, lr=0.000016
   ✓ Epoch   3/100: train=0.0866, val=0.0884 (↓), lr=0.000016
   • Epoch   4/100: train=0.0865, val=0.0882, patience=1/15, lr=0.000016
   • Epoch   5/100: train=0.0864, val=0.0880, patience=2/15, lr=0.000016
   📉 Epoch 8: LR reduced 0.000016 → 0.000008
   • Epoch  11/100: train=0.0858, val=0.0868, patience=3/15, lr=0.000008
   📉 Epoch 16: LR reduced 0.000008 → 0.000004
   • Epoch  21/100: train=0.0854, val=0.0862, patience=9/15, lr=0.000004
   📉 Epoch 24: LR reduced 0.000004 → 0.000002
   • Epoch  31/100: train=0.0854, val=0.0861, patience=8/15, lr=0.000002
   📉 Epoch 32: LR reduced 0.000002 → 0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 16 Summary - Client client_62
   Epochs: 38/100 (early stopped)
   LR: 0.000016 → 0.000001 (4 reductions)
   Train: Loss=0.0854, RMSE=0.2922, R²=-0.0070
   Val:   Loss=0.0862, RMSE=0.2936, R²=-0.0972
============================================================


📊 Round 16 Test Metrics:
   Loss: 0.0895, RMSE: 0.2991, MAE: 0.2611, R²: -0.0799

============================================================
🔄 Round 18 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0977 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0977, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0977, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0977, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0976, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0975, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0977)

============================================================
📊 Round 18 Summary - Client client_62
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2915, R²=-0.0377
   Val:   Loss=0.0977, RMSE=0.3126, R²=-0.0672
============================================================


📊 Round 18 Test Metrics:
   Loss: 0.0895, RMSE: 0.2991, MAE: 0.2611, R²: -0.0798

📊 Round 18 Test Metrics:
   Loss: 0.0899, RMSE: 0.2998, MAE: 0.2615, R²: -0.0846

============================================================
🔄 Round 22 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0886, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0886, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0885, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0885, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0885, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0884, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 22 Summary - Client client_62
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0889, RMSE=0.2982, R²=-0.0370
   Val:   Loss=0.0841, RMSE=0.2900, R²=-0.1035
============================================================


============================================================
🔄 Round 24 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0944 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0944, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0944, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0943, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0943, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0942, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0944)

============================================================
📊 Round 24 Summary - Client client_62
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2939, R²=-0.0429
   Val:   Loss=0.0944, RMSE=0.3072, R²=-0.0804
============================================================


============================================================
🔄 Round 29 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0897, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0896, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0896, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0896, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0896, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0894, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 29 Summary - Client client_62
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0899, RMSE=0.2999, R²=-0.0638
   Val:   Loss=0.0801, RMSE=0.2830, R²=0.0118
============================================================


============================================================
🔄 Round 32 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0884, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0884, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0883, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0883, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0883, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0882, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 32 Summary - Client client_62
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0887, RMSE=0.2978, R²=-0.0591
   Val:   Loss=0.0850, RMSE=0.2916, R²=-0.0104
============================================================


📊 Round 32 Test Metrics:
   Loss: 0.0899, RMSE: 0.2999, MAE: 0.2616, R²: -0.0855

============================================================
🔄 Round 34 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0886, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0885, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0885, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0885, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0885, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0884, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 34 Summary - Client client_62
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0886, RMSE=0.2976, R²=-0.0588
   Val:   Loss=0.0855, RMSE=0.2924, R²=-0.0114
============================================================


📊 Round 34 Test Metrics:
   Loss: 0.0899, RMSE: 0.2999, MAE: 0.2616, R²: -0.0856

📊 Round 34 Test Metrics:
   Loss: 0.0900, RMSE: 0.2999, MAE: 0.2616, R²: -0.0856

============================================================
🔄 Round 38 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0876, val=0.0897 (↓), lr=0.000001
   • Epoch   2/100: train=0.0876, val=0.0897, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0876, val=0.0897, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0876, val=0.0897, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0876, val=0.0897, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0875, val=0.0896, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0897)

============================================================
📊 Round 38 Summary - Client client_62
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0875, RMSE=0.2959, R²=-0.0480
   Val:   Loss=0.0897, RMSE=0.2995, R²=-0.0594
============================================================


📊 Round 38 Test Metrics:
   Loss: 0.0900, RMSE: 0.2999, MAE: 0.2616, R²: -0.0856

📊 Round 38 Test Metrics:
   Loss: 0.0900, RMSE: 0.2999, MAE: 0.2616, R²: -0.0856

📊 Round 38 Test Metrics:
   Loss: 0.0900, RMSE: 0.2999, MAE: 0.2616, R²: -0.0856

============================================================
🔄 Round 42 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0898, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0898, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0898, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0898, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0898, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0897, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 42 Summary - Client client_62
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0898, RMSE=0.2997, R²=-0.0443
   Val:   Loss=0.0807, RMSE=0.2841, R²=-0.0833
============================================================


============================================================
🔄 Round 44 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0954 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0954, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0954, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0954, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0953, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0952, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0954)

============================================================
📊 Round 44 Summary - Client client_62
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2935, R²=-0.0304
   Val:   Loss=0.0954, RMSE=0.3089, R²=-0.1264
============================================================


📊 Round 44 Test Metrics:
   Loss: 0.0900, RMSE: 0.2999, MAE: 0.2616, R²: -0.0857

============================================================
🔄 Round 45 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0918, val=0.0729 (↓), lr=0.000001
   • Epoch   2/100: train=0.0918, val=0.0729, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0918, val=0.0729, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0918, val=0.0729, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0917, val=0.0729, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0916, val=0.0728, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0729)

============================================================
📊 Round 45 Summary - Client client_62
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0918, RMSE=0.3029, R²=-0.0607
   Val:   Loss=0.0729, RMSE=0.2701, R²=-0.0270
============================================================


📊 Round 45 Test Metrics:
   Loss: 0.0900, RMSE: 0.2999, MAE: 0.2616, R²: -0.0857

📊 Round 45 Test Metrics:
   Loss: 0.0900, RMSE: 0.2999, MAE: 0.2616, R²: -0.0857

📊 Round 45 Test Metrics:
   Loss: 0.0900, RMSE: 0.2999, MAE: 0.2616, R²: -0.0857

📊 Round 45 Test Metrics:
   Loss: 0.0900, RMSE: 0.2999, MAE: 0.2616, R²: -0.0857

============================================================
🔄 Round 50 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0907, val=0.0771 (↓), lr=0.000001
   • Epoch   2/100: train=0.0906, val=0.0771, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0906, val=0.0771, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0906, val=0.0771, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0906, val=0.0771, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0904, val=0.0771, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0771)

============================================================
📊 Round 50 Summary - Client client_62
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0907, RMSE=0.3011, R²=-0.0552
   Val:   Loss=0.0771, RMSE=0.2778, R²=-0.0263
============================================================


============================================================
🔄 Round 51 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0893, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0893, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0893, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0893, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0892, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0891, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 51 Summary - Client client_62
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0892, RMSE=0.2987, R²=-0.0557
   Val:   Loss=0.0830, RMSE=0.2881, R²=-0.0249
============================================================


📊 Round 51 Test Metrics:
   Loss: 0.0900, RMSE: 0.2999, MAE: 0.2616, R²: -0.0858

📊 Round 51 Test Metrics:
   Loss: 0.0900, RMSE: 0.2999, MAE: 0.2616, R²: -0.0858

📊 Round 51 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2616, R²: -0.0858

============================================================
🔄 Round 57 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0957 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0957, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0957, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0957, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0956, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0955, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0957)

============================================================
📊 Round 57 Summary - Client client_62
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2934, R²=-0.0397
   Val:   Loss=0.0957, RMSE=0.3094, R²=-0.0952
============================================================


============================================================
🔄 Round 59 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0898, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0898, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0898, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0898, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0898, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0896, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 59 Summary - Client client_62
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0895, RMSE=0.2991, R²=-0.0510
   Val:   Loss=0.0821, RMSE=0.2865, R²=-0.0481
============================================================


============================================================
🔄 Round 60 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0898, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0898, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0897, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0897, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0897, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0895, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 60 Summary - Client client_62
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0902, RMSE=0.3003, R²=-0.0610
   Val:   Loss=0.0792, RMSE=0.2814, R²=-0.0027
============================================================


📊 Round 60 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2616, R²: -0.0859

============================================================
🔄 Round 67 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.0932 (↓), lr=0.000001
   • Epoch   2/100: train=0.0868, val=0.0932, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0868, val=0.0932, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0868, val=0.0932, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0868, val=0.0932, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0867, val=0.0931, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0932)

============================================================
📊 Round 67 Summary - Client client_62
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0867, RMSE=0.2944, R²=-0.0525
   Val:   Loss=0.0932, RMSE=0.3053, R²=-0.0419
============================================================


📊 Round 67 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2616, R²: -0.0859

============================================================
🔄 Round 68 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.0920 (↓), lr=0.000001
   • Epoch   2/100: train=0.0868, val=0.0920, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0868, val=0.0920, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0868, val=0.0919, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0868, val=0.0919, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0867, val=0.0918, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0920)

============================================================
📊 Round 68 Summary - Client client_62
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0870, RMSE=0.2950, R²=-0.0403
   Val:   Loss=0.0920, RMSE=0.3033, R²=-0.0913
============================================================


📊 Round 68 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2616, R²: -0.0859

📊 Round 68 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2616, R²: -0.0860

📊 Round 68 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2616, R²: -0.0860

📊 Round 68 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2616, R²: -0.0860

📊 Round 68 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2616, R²: -0.0860

📊 Round 68 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2616, R²: -0.0860

============================================================
🔄 Round 79 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0928 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0928, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0928, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0928, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0927, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0927, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0928)

============================================================
📊 Round 79 Summary - Client client_62
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2947, R²=-0.0326
   Val:   Loss=0.0928, RMSE=0.3046, R²=-0.1265
============================================================


============================================================
🔄 Round 80 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0877, val=0.0891 (↓), lr=0.000001
   • Epoch   2/100: train=0.0877, val=0.0891, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0877, val=0.0891, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0877, val=0.0890, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0877, val=0.0890, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0876, val=0.0889, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0891)

============================================================
📊 Round 80 Summary - Client client_62
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0878, RMSE=0.2962, R²=-0.0418
   Val:   Loss=0.0891, RMSE=0.2985, R²=-0.0872
============================================================


📊 Round 80 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2616, R²: -0.0860

============================================================
🔄 Round 82 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0957 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0957, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0957, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0957, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0957, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0956, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0957)

============================================================
📊 Round 82 Summary - Client client_62
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2934, R²=-0.0456
   Val:   Loss=0.0957, RMSE=0.3094, R²=-0.0663
============================================================


============================================================
🔄 Round 83 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0892, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0892, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0892, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0892, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0892, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0891, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 83 Summary - Client client_62
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0891, RMSE=0.2985, R²=-0.0546
   Val:   Loss=0.0837, RMSE=0.2892, R²=-0.0301
============================================================


📊 Round 83 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2616, R²: -0.0861

============================================================
🔄 Round 86 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0872, val=0.0921 (↓), lr=0.000001
   • Epoch   2/100: train=0.0872, val=0.0921, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0871, val=0.0921, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0871, val=0.0921, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0871, val=0.0921, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0870, val=0.0920, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0921)

============================================================
📊 Round 86 Summary - Client client_62
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0870, RMSE=0.2950, R²=-0.0479
   Val:   Loss=0.0921, RMSE=0.3035, R²=-0.0705
============================================================


============================================================
🔄 Round 87 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0878, val=0.0891 (↓), lr=0.000001
   • Epoch   2/100: train=0.0878, val=0.0891, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0878, val=0.0891, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0878, val=0.0891, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0878, val=0.0890, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0877, val=0.0889, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0891)

============================================================
📊 Round 87 Summary - Client client_62
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0878, RMSE=0.2962, R²=-0.0390
   Val:   Loss=0.0891, RMSE=0.2985, R²=-0.0951
============================================================


📊 Round 87 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2616, R²: -0.0861

============================================================
🔄 Round 88 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.1031 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.1031, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.1031, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.1031, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.1031, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.1031, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.1031)

============================================================
📊 Round 88 Summary - Client client_62
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=-0.0468
   Val:   Loss=0.1031, RMSE=0.3211, R²=-0.0743
============================================================


📊 Round 88 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2616, R²: -0.0861

============================================================
🔄 Round 90 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0893, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0892, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0892, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0892, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0892, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0890, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 90 Summary - Client client_62
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0893, RMSE=0.2989, R²=-0.0569
   Val:   Loss=0.0827, RMSE=0.2876, R²=-0.0350
============================================================


============================================================
🔄 Round 94 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0899, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0899, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0899, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0898, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0898, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0897, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 94 Summary - Client client_62
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0899, RMSE=0.2998, R²=-0.0532
   Val:   Loss=0.0806, RMSE=0.2839, R²=-0.0360
============================================================


📊 Round 94 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2616, R²: -0.0862

📊 Round 94 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2616, R²: -0.0862

============================================================
🔄 Round 96 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0881, val=0.0880 (↓), lr=0.000001
   • Epoch   2/100: train=0.0881, val=0.0879, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0881, val=0.0879, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0881, val=0.0879, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0880, val=0.0879, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0880, val=0.0878, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0880)

============================================================
📊 Round 96 Summary - Client client_62
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0881, RMSE=0.2967, R²=-0.0413
   Val:   Loss=0.0880, RMSE=0.2966, R²=-0.0884
============================================================


============================================================
🔄 Round 97 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0896, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0896, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0895, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0895, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0895, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0894, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 97 Summary - Client client_62
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0894, RMSE=0.2991, R²=-0.0570
   Val:   Loss=0.0824, RMSE=0.2871, R²=-0.0210
============================================================


📊 Round 97 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2616, R²: -0.0862

============================================================
🔄 Round 98 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0900, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0900, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0900, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0900, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0900, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0899, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 98 Summary - Client client_62
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0898, RMSE=0.2997, R²=-0.0565
   Val:   Loss=0.0810, RMSE=0.2846, R²=-0.0255
============================================================


📊 Round 98 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2616, R²: -0.0862

📊 Round 98 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2616, R²: -0.0862

============================================================
🔄 Round 100 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.1006 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.1006, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.1006, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.1006, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.1006, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.1005, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.1006)

============================================================
📊 Round 100 Summary - Client client_62
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=-0.0421
   Val:   Loss=0.1006, RMSE=0.3172, R²=-0.0843
============================================================


📊 Round 100 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2616, R²: -0.0862

============================================================
🔄 Round 101 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0884, val=0.0866 (↓), lr=0.000001
   • Epoch   2/100: train=0.0884, val=0.0866, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0884, val=0.0866, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0884, val=0.0866, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0884, val=0.0866, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0883, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0866)

============================================================
📊 Round 101 Summary - Client client_62
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0884, RMSE=0.2973, R²=-0.0509
   Val:   Loss=0.0866, RMSE=0.2943, R²=-0.0565
============================================================


============================================================
🔄 Round 102 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0891, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0891, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0891, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0890, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0890, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0889, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 102 Summary - Client client_62
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0893, RMSE=0.2989, R²=-0.0448
   Val:   Loss=0.0829, RMSE=0.2879, R²=-0.0747
============================================================


============================================================
🔄 Round 103 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0873, val=0.0912 (↓), lr=0.000001
   • Epoch   2/100: train=0.0873, val=0.0911, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0873, val=0.0911, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0872, val=0.0911, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0872, val=0.0911, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0871, val=0.0911, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0912)

============================================================
📊 Round 103 Summary - Client client_62
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0873, RMSE=0.2954, R²=-0.0493
   Val:   Loss=0.0912, RMSE=0.3019, R²=-0.0533
============================================================


📊 Round 103 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2616, R²: -0.0862

============================================================
🔄 Round 104 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0893, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0893, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0893, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0893, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0893, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0892, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 104 Summary - Client client_62
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0895, RMSE=0.2992, R²=-0.0448
   Val:   Loss=0.0821, RMSE=0.2866, R²=-0.0748
============================================================


📊 Round 104 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2616, R²: -0.0862

📊 Round 104 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2616, R²: -0.0863

============================================================
🔄 Round 106 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0888, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0888, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0888, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0888, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0888, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0887, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 106 Summary - Client client_62
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0889, RMSE=0.2982, R²=-0.0454
   Val:   Loss=0.0846, RMSE=0.2909, R²=-0.0717
============================================================


============================================================
🔄 Round 107 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0969 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0969, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0969, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0969, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0969, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0968, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0969)

============================================================
📊 Round 107 Summary - Client client_62
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2930, R²=-0.0526
   Val:   Loss=0.0969, RMSE=0.3113, R²=-0.0420
============================================================


📊 Round 107 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2616, R²: -0.0863

============================================================
🔄 Round 109 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0887, val=0.0863 (↓), lr=0.000001
   • Epoch   2/100: train=0.0887, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0887, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0887, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0886, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0885, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 109 Summary - Client client_62
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0885, RMSE=0.2975, R²=-0.0464
   Val:   Loss=0.0863, RMSE=0.2938, R²=-0.0705
============================================================


📊 Round 109 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2616, R²: -0.0863

============================================================
🔄 Round 112 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0871, val=0.0919 (↓), lr=0.000001
   • Epoch   2/100: train=0.0871, val=0.0919, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0871, val=0.0919, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0871, val=0.0918, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0870, val=0.0918, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0870, val=0.0917, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0919)

============================================================
📊 Round 112 Summary - Client client_62
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0871, RMSE=0.2951, R²=-0.0446
   Val:   Loss=0.0919, RMSE=0.3031, R²=-0.0724
============================================================


📊 Round 112 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2616, R²: -0.0864

📊 Round 112 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2616, R²: -0.0864

📊 Round 112 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2616, R²: -0.0864

============================================================
🔄 Round 116 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0894, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0894, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0894, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0894, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0893, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0893, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 116 Summary - Client client_62
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0896, RMSE=0.2994, R²=-0.0358
   Val:   Loss=0.0817, RMSE=0.2859, R²=-0.1194
============================================================


📊 Round 116 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2616, R²: -0.0864

============================================================
🔄 Round 117 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0985 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0985, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0985, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0985, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0985, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0984, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0985)

============================================================
📊 Round 117 Summary - Client client_62
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2923, R²=-0.0555
   Val:   Loss=0.0985, RMSE=0.3139, R²=-0.0363
============================================================


📊 Round 117 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2616, R²: -0.0864

📊 Round 117 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2616, R²: -0.0864

============================================================
🔄 Round 119 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0878, val=0.0900 (↓), lr=0.000001
   • Epoch   2/100: train=0.0877, val=0.0900, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0877, val=0.0900, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0877, val=0.0900, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0877, val=0.0900, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0876, val=0.0899, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0900)

============================================================
📊 Round 119 Summary - Client client_62
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0876, RMSE=0.2959, R²=-0.0484
   Val:   Loss=0.0900, RMSE=0.3000, R²=-0.0594
============================================================


📊 Round 119 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2616, R²: -0.0864

============================================================
🔄 Round 120 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0875, val=0.0902 (↓), lr=0.000001
   • Epoch   2/100: train=0.0874, val=0.0902, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0874, val=0.0901, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0874, val=0.0901, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0874, val=0.0901, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0873, val=0.0900, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0902)

============================================================
📊 Round 120 Summary - Client client_62
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0875, RMSE=0.2959, R²=-0.0388
   Val:   Loss=0.0902, RMSE=0.3003, R²=-0.0979
============================================================


📊 Round 120 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2616, R²: -0.0865

============================================================
🔄 Round 123 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0928, val=0.0687 (↓), lr=0.000001
   • Epoch   2/100: train=0.0928, val=0.0687, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0928, val=0.0687, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0927, val=0.0687, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0927, val=0.0687, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0926, val=0.0687, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0687)

============================================================
📊 Round 123 Summary - Client client_62
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0929, RMSE=0.3048, R²=-0.0514
   Val:   Loss=0.0687, RMSE=0.2621, R²=-0.0495
============================================================


📊 Round 123 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2616, R²: -0.0865

📊 Round 123 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2616, R²: -0.0865

📊 Round 123 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2616, R²: -0.0865

============================================================
🔄 Round 129 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0949 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0949, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0949, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0949, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0949, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0947, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0949)

============================================================
📊 Round 129 Summary - Client client_62
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2939, R²=-0.0461
   Val:   Loss=0.0949, RMSE=0.3081, R²=-0.0667
============================================================


📊 Round 129 Test Metrics:
   Loss: 0.0900, RMSE: 0.3001, MAE: 0.2616, R²: -0.0866

============================================================
🔄 Round 130 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0907, val=0.0762 (↓), lr=0.000001
   • Epoch   2/100: train=0.0907, val=0.0762, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0907, val=0.0762, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0907, val=0.0761, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0907, val=0.0761, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0906, val=0.0760, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0762)

============================================================
📊 Round 130 Summary - Client client_62
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0910, RMSE=0.3017, R²=-0.0512
   Val:   Loss=0.0762, RMSE=0.2760, R²=-0.0673
============================================================


📊 Round 130 Test Metrics:
   Loss: 0.0900, RMSE: 0.3001, MAE: 0.2617, R²: -0.0866

📊 Round 130 Test Metrics:
   Loss: 0.0900, RMSE: 0.3001, MAE: 0.2617, R²: -0.0866

============================================================
🔄 Round 132 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0870, val=0.0920 (↓), lr=0.000001
   • Epoch   2/100: train=0.0870, val=0.0919, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0870, val=0.0919, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0870, val=0.0919, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0870, val=0.0919, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0869, val=0.0918, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0920)

============================================================
📊 Round 132 Summary - Client client_62
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0871, RMSE=0.2951, R²=-0.0387
   Val:   Loss=0.0920, RMSE=0.3033, R²=-0.0972
============================================================


============================================================
🔄 Round 134 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0876, val=0.0902 (↓), lr=0.000001
   • Epoch   2/100: train=0.0876, val=0.0902, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0876, val=0.0902, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0876, val=0.0902, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0875, val=0.0902, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0874, val=0.0901, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0902)

============================================================
📊 Round 134 Summary - Client client_62
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0875, RMSE=0.2959, R²=-0.0623
   Val:   Loss=0.0902, RMSE=0.3003, R²=-0.0071
============================================================


📊 Round 134 Test Metrics:
   Loss: 0.0900, RMSE: 0.3001, MAE: 0.2617, R²: -0.0867

============================================================
🔄 Round 136 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0870, val=0.0919 (↓), lr=0.000001
   • Epoch   2/100: train=0.0870, val=0.0919, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0869, val=0.0919, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0869, val=0.0919, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0869, val=0.0919, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0868, val=0.0919, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0919)

============================================================
📊 Round 136 Summary - Client client_62
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0871, RMSE=0.2951, R²=-0.0477
   Val:   Loss=0.0919, RMSE=0.3032, R²=-0.0645
============================================================


📊 Round 136 Test Metrics:
   Loss: 0.0900, RMSE: 0.3001, MAE: 0.2617, R²: -0.0867

============================================================
🔄 Round 138 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0900, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0900, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0900, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0900, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0900, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0899, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 138 Summary - Client client_62
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0899, RMSE=0.2999, R²=-0.0383
   Val:   Loss=0.0807, RMSE=0.2840, R²=-0.1080
============================================================


📊 Round 138 Test Metrics:
   Loss: 0.0900, RMSE: 0.3001, MAE: 0.2617, R²: -0.0867

============================================================
🔄 Round 139 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0879, val=0.0889 (↓), lr=0.000001
   • Epoch   2/100: train=0.0878, val=0.0889, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0878, val=0.0889, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0878, val=0.0888, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0878, val=0.0888, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0877, val=0.0888, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0889)

============================================================
📊 Round 139 Summary - Client client_62
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0879, RMSE=0.2964, R²=-0.0440
   Val:   Loss=0.0889, RMSE=0.2981, R²=-0.0779
============================================================


📊 Round 139 Test Metrics:
   Loss: 0.0900, RMSE: 0.3001, MAE: 0.2617, R²: -0.0867

📊 Round 139 Test Metrics:
   Loss: 0.0900, RMSE: 0.3001, MAE: 0.2617, R²: -0.0867

============================================================
🔄 Round 142 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0886, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0886, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0886, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0886, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0885, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0884, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 142 Summary - Client client_62
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0885, RMSE=0.2975, R²=-0.0550
   Val:   Loss=0.0864, RMSE=0.2939, R²=-0.0330
============================================================


============================================================
🔄 Round 144 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0878, val=0.0899 (↓), lr=0.000001
   • Epoch   2/100: train=0.0878, val=0.0899, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0877, val=0.0899, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0877, val=0.0899, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0877, val=0.0899, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0876, val=0.0898, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0899)

============================================================
📊 Round 144 Summary - Client client_62
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0876, RMSE=0.2960, R²=-0.0643
   Val:   Loss=0.0899, RMSE=0.2999, R²=0.0005
============================================================


============================================================
🔄 Round 145 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0879, val=0.0892 (↓), lr=0.000001
   • Epoch   2/100: train=0.0879, val=0.0892, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0879, val=0.0892, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0879, val=0.0892, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0879, val=0.0892, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0878, val=0.0891, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0892)

============================================================
📊 Round 145 Summary - Client client_62
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0878, RMSE=0.2963, R²=-0.0487
   Val:   Loss=0.0892, RMSE=0.2987, R²=-0.0787
============================================================


============================================================
🔄 Round 148 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0948 (↓), lr=0.000001
   • Epoch   2/100: train=0.0867, val=0.0948, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0867, val=0.0948, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0867, val=0.0948, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0867, val=0.0947, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0866, val=0.0947, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0948)

============================================================
📊 Round 148 Summary - Client client_62
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2939, R²=-0.0473
   Val:   Loss=0.0948, RMSE=0.3079, R²=-0.0626
============================================================


📊 Round 148 Test Metrics:
   Loss: 0.0900, RMSE: 0.3001, MAE: 0.2617, R²: -0.0868

============================================================
🔄 Round 151 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0890, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0890, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0890, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0890, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0890, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0889, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 151 Summary - Client client_62
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0889, RMSE=0.2982, R²=-0.0523
   Val:   Loss=0.0848, RMSE=0.2911, R²=-0.0732
============================================================


📊 Round 151 Test Metrics:
   Loss: 0.0901, RMSE: 0.3001, MAE: 0.2617, R²: -0.0868

============================================================
🔄 Round 154 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0892, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0892, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0892, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0892, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0891, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0891, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 154 Summary - Client client_62
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0892, RMSE=0.2987, R²=-0.0489
   Val:   Loss=0.0836, RMSE=0.2892, R²=-0.0635
============================================================


📊 Round 154 Test Metrics:
   Loss: 0.0901, RMSE: 0.3001, MAE: 0.2617, R²: -0.0868

📊 Round 154 Test Metrics:
   Loss: 0.0901, RMSE: 0.3001, MAE: 0.2617, R²: -0.0868

============================================================
🔄 Round 161 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0888, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0888, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0888, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0888, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0887, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0886, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 161 Summary - Client client_62
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0889, RMSE=0.2981, R²=-0.0510
   Val:   Loss=0.0850, RMSE=0.2915, R²=-0.0544
============================================================


============================================================
🔄 Round 162 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0917, val=0.0742 (↓), lr=0.000001
   • Epoch   2/100: train=0.0916, val=0.0742, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0916, val=0.0742, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0916, val=0.0741, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0916, val=0.0741, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0915, val=0.0740, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0742)

============================================================
📊 Round 162 Summary - Client client_62
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0915, RMSE=0.3026, R²=-0.0535
   Val:   Loss=0.0742, RMSE=0.2724, R²=-0.0365
============================================================


============================================================
🔄 Round 163 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0949 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0949, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0949, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0949, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0949, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0948, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0949)

============================================================
📊 Round 163 Summary - Client client_62
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2939, R²=-0.0481
   Val:   Loss=0.0949, RMSE=0.3081, R²=-0.0603
============================================================


📊 Round 163 Test Metrics:
   Loss: 0.0901, RMSE: 0.3001, MAE: 0.2617, R²: -0.0869

============================================================
🔄 Round 165 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0900, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0900, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0900, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0899, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0899, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0898, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 165 Summary - Client client_62
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0903, RMSE=0.3004, R²=-0.0702
   Val:   Loss=0.0793, RMSE=0.2817, R²=0.0067
============================================================


📊 Round 165 Test Metrics:
   Loss: 0.0901, RMSE: 0.3001, MAE: 0.2617, R²: -0.0869

============================================================
🔄 Round 169 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0880, val=0.0881 (↓), lr=0.000001
   • Epoch   2/100: train=0.0880, val=0.0881, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0879, val=0.0881, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0879, val=0.0880, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0879, val=0.0880, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0878, val=0.0880, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0881)

============================================================
📊 Round 169 Summary - Client client_62
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0881, RMSE=0.2968, R²=-0.0618
   Val:   Loss=0.0881, RMSE=0.2967, R²=-0.0081
============================================================


============================================================
🔄 Round 170 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0878, val=0.0893 (↓), lr=0.000001
   • Epoch   2/100: train=0.0878, val=0.0893, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0878, val=0.0893, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0878, val=0.0893, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0877, val=0.0893, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0876, val=0.0894, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0893)

============================================================
📊 Round 170 Summary - Client client_62
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0878, RMSE=0.2963, R²=-0.0554
   Val:   Loss=0.0893, RMSE=0.2989, R²=-0.0529
============================================================


📊 Round 170 Test Metrics:
   Loss: 0.0901, RMSE: 0.3001, MAE: 0.2617, R²: -0.0870

📊 Round 170 Test Metrics:
   Loss: 0.0901, RMSE: 0.3001, MAE: 0.2617, R²: -0.0870

📊 Round 170 Test Metrics:
   Loss: 0.0901, RMSE: 0.3001, MAE: 0.2617, R²: -0.0870

============================================================
🔄 Round 175 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0888, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0887, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0887, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0887, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0887, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0885, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 175 Summary - Client client_62
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0890, RMSE=0.2983, R²=-0.0580
   Val:   Loss=0.0846, RMSE=0.2908, R²=-0.0251
============================================================


============================================================
🔄 Round 176 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0889, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0889, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0889, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0889, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0889, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0888, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 176 Summary - Client client_62
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0893, RMSE=0.2988, R²=-0.0470
   Val:   Loss=0.0834, RMSE=0.2887, R²=-0.0754
============================================================


============================================================
🔄 Round 178 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0958 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0958, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0958, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0958, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0958, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0957, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0958)

============================================================
📊 Round 178 Summary - Client client_62
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2935, R²=-0.0392
   Val:   Loss=0.0958, RMSE=0.3095, R²=-0.0982
============================================================


============================================================
🔄 Round 179 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0887, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0887, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0887, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0887, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0887, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0886, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 179 Summary - Client client_62
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0890, RMSE=0.2983, R²=-0.0427
   Val:   Loss=0.0845, RMSE=0.2907, R²=-0.0909
============================================================


============================================================
🔄 Round 180 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0953 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0953, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0953, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0953, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0952, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0952, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0953)

============================================================
📊 Round 180 Summary - Client client_62
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2938, R²=-0.0479
   Val:   Loss=0.0953, RMSE=0.3087, R²=-0.0667
============================================================


📊 Round 180 Test Metrics:
   Loss: 0.0901, RMSE: 0.3001, MAE: 0.2617, R²: -0.0871

============================================================
🔄 Round 183 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0878, val=0.0891 (↓), lr=0.000001
   • Epoch   2/100: train=0.0878, val=0.0891, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0878, val=0.0891, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0878, val=0.0891, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0877, val=0.0891, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0876, val=0.0891, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0891)

============================================================
📊 Round 183 Summary - Client client_62
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0878, RMSE=0.2964, R²=-0.0652
   Val:   Loss=0.0891, RMSE=0.2986, R²=0.0026
============================================================


📊 Round 183 Test Metrics:
   Loss: 0.0901, RMSE: 0.3001, MAE: 0.2617, R²: -0.0871

📊 Round 183 Test Metrics:
   Loss: 0.0901, RMSE: 0.3001, MAE: 0.2617, R²: -0.0872

============================================================
🔄 Round 189 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0873, val=0.0908 (↓), lr=0.000001
   • Epoch   2/100: train=0.0873, val=0.0908, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0873, val=0.0908, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0873, val=0.0908, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0873, val=0.0908, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0872, val=0.0907, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0908)

============================================================
📊 Round 189 Summary - Client client_62
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0874, RMSE=0.2956, R²=-0.0477
   Val:   Loss=0.0908, RMSE=0.3014, R²=-0.0631
============================================================


📊 Round 189 Test Metrics:
   Loss: 0.0901, RMSE: 0.3001, MAE: 0.2617, R²: -0.0872

📊 Round 189 Test Metrics:
   Loss: 0.0901, RMSE: 0.3001, MAE: 0.2617, R²: -0.0872

📊 Round 189 Test Metrics:
   Loss: 0.0901, RMSE: 0.3001, MAE: 0.2617, R²: -0.0872

============================================================
🔄 Round 192 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0967 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0967, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0967, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0967, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0967, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0967, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0967)

============================================================
📊 Round 192 Summary - Client client_62
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2931, R²=-0.0527
   Val:   Loss=0.0967, RMSE=0.3110, R²=-0.0552
============================================================


📊 Round 192 Test Metrics:
   Loss: 0.0901, RMSE: 0.3001, MAE: 0.2617, R²: -0.0872

============================================================
🔄 Round 193 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0880, val=0.0884 (↓), lr=0.000001
   • Epoch   2/100: train=0.0880, val=0.0884, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0879, val=0.0884, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0879, val=0.0884, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0879, val=0.0884, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0879, val=0.0883, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0884)

============================================================
📊 Round 193 Summary - Client client_62
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0880, RMSE=0.2967, R²=-0.0405
   Val:   Loss=0.0884, RMSE=0.2974, R²=-0.0959
============================================================


📊 Round 193 Test Metrics:
   Loss: 0.0901, RMSE: 0.3001, MAE: 0.2617, R²: -0.0872

============================================================
🔄 Round 194 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0900, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0900, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0900, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0900, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0900, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0899, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 194 Summary - Client client_62
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0901, RMSE=0.3001, R²=-0.0497
   Val:   Loss=0.0801, RMSE=0.2830, R²=-0.0555
============================================================


📊 Round 194 Test Metrics:
   Loss: 0.0901, RMSE: 0.3001, MAE: 0.2617, R²: -0.0872

============================================================
🔄 Round 195 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0890, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0890, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0890, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0890, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0890, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0889, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 195 Summary - Client client_62
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0889, RMSE=0.2981, R²=-0.0596
   Val:   Loss=0.0850, RMSE=0.2916, R²=-0.0171
============================================================


📊 Round 195 Test Metrics:
   Loss: 0.0901, RMSE: 0.3001, MAE: 0.2617, R²: -0.0872

============================================================
🔄 Round 196 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0882, val=0.0872 (↓), lr=0.000001
   • Epoch   2/100: train=0.0882, val=0.0872, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0882, val=0.0872, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0882, val=0.0872, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0882, val=0.0872, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0881, val=0.0871, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0872)

============================================================
📊 Round 196 Summary - Client client_62
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0883, RMSE=0.2971, R²=-0.0544
   Val:   Loss=0.0872, RMSE=0.2954, R²=-0.0357
============================================================


📊 Round 196 Test Metrics:
   Loss: 0.0901, RMSE: 0.3001, MAE: 0.2617, R²: -0.0872

============================================================
🔄 Round 197 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0950 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0949, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0949, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0949, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0949, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0948, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0950)

============================================================
📊 Round 197 Summary - Client client_62
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2939, R²=-0.0602
   Val:   Loss=0.0950, RMSE=0.3082, R²=-0.0176
============================================================


📊 Round 197 Test Metrics:
   Loss: 0.0901, RMSE: 0.3001, MAE: 0.2617, R²: -0.0872

📊 Round 197 Test Metrics:
   Loss: 0.0901, RMSE: 0.3001, MAE: 0.2617, R²: -0.0873

📊 Round 197 Test Metrics:
   Loss: 0.0901, RMSE: 0.3001, MAE: 0.2617, R²: -0.0873

📊 Round 197 Test Metrics:
   Loss: 0.0901, RMSE: 0.3001, MAE: 0.2617, R²: -0.0873

📊 Round 197 Test Metrics:
   Loss: 0.0901, RMSE: 0.3002, MAE: 0.2617, R²: -0.0873

============================================================
🔄 Round 205 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0872, val=0.0921 (↓), lr=0.000001
   • Epoch   2/100: train=0.0871, val=0.0921, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0871, val=0.0922, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0871, val=0.0922, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0871, val=0.0922, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0869, val=0.0922, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0921)

============================================================
📊 Round 205 Summary - Client client_62
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0871, RMSE=0.2951, R²=-0.0408
   Val:   Loss=0.0921, RMSE=0.3035, R²=-0.1240
============================================================


============================================================
🔄 Round 206 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0894, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0894, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0894, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0893, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0893, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0892, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 206 Summary - Client client_62
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0890, RMSE=0.2983, R²=-0.0527
   Val:   Loss=0.0845, RMSE=0.2907, R²=-0.0467
============================================================


📊 Round 206 Test Metrics:
   Loss: 0.0901, RMSE: 0.3002, MAE: 0.2617, R²: -0.0873

============================================================
🔄 Round 207 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0875, val=0.0916 (↓), lr=0.000001
   • Epoch   2/100: train=0.0875, val=0.0916, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0875, val=0.0916, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0875, val=0.0916, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0874, val=0.0916, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0874, val=0.0915, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0916)

============================================================
📊 Round 207 Summary - Client client_62
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0872, RMSE=0.2953, R²=-0.0395
   Val:   Loss=0.0916, RMSE=0.3027, R²=-0.1025
============================================================


📊 Round 207 Test Metrics:
   Loss: 0.0901, RMSE: 0.3002, MAE: 0.2617, R²: -0.0873

📊 Round 207 Test Metrics:
   Loss: 0.0901, RMSE: 0.3002, MAE: 0.2617, R²: -0.0873

============================================================
🔄 Round 210 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0901, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0901, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0901, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0901, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0900, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0900, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 210 Summary - Client client_62
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0905, RMSE=0.3008, R²=-0.0454
   Val:   Loss=0.0785, RMSE=0.2802, R²=-0.0764
============================================================


============================================================
🔄 Round 212 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0878, val=0.0888 (↓), lr=0.000001
   • Epoch   2/100: train=0.0878, val=0.0888, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0877, val=0.0888, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0877, val=0.0888, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0877, val=0.0888, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0876, val=0.0887, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0888)

============================================================
📊 Round 212 Summary - Client client_62
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0879, RMSE=0.2965, R²=-0.0526
   Val:   Loss=0.0888, RMSE=0.2981, R²=-0.0439
============================================================


============================================================
🔄 Round 213 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0897, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0897, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0897, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0897, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0897, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0896, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 213 Summary - Client client_62
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0897, RMSE=0.2995, R²=-0.0437
   Val:   Loss=0.0817, RMSE=0.2858, R²=-0.0909
============================================================


============================================================
🔄 Round 215 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0881, val=0.0879 (↓), lr=0.000001
   • Epoch   2/100: train=0.0881, val=0.0879, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0880, val=0.0879, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0880, val=0.0879, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0880, val=0.0879, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0879, val=0.0879, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0879)

============================================================
📊 Round 215 Summary - Client client_62
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0881, RMSE=0.2969, R²=-0.0487
   Val:   Loss=0.0879, RMSE=0.2965, R²=-0.0722
============================================================


📊 Round 215 Test Metrics:
   Loss: 0.0901, RMSE: 0.3002, MAE: 0.2617, R²: -0.0874

============================================================
🔄 Round 217 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0884, val=0.0884 (↓), lr=0.000001
   • Epoch   2/100: train=0.0884, val=0.0883, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0884, val=0.0883, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0884, val=0.0883, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0883, val=0.0883, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0882, val=0.0883, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0884)

============================================================
📊 Round 217 Summary - Client client_62
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0880, RMSE=0.2967, R²=-0.0521
   Val:   Loss=0.0884, RMSE=0.2972, R²=-0.0474
============================================================


📊 Round 217 Test Metrics:
   Loss: 0.0901, RMSE: 0.3002, MAE: 0.2617, R²: -0.0874

============================================================
🔄 Round 219 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0893, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0893, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0893, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0892, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0892, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0891, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 219 Summary - Client client_62
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0894, RMSE=0.2990, R²=-0.0547
   Val:   Loss=0.0829, RMSE=0.2879, R²=-0.0402
============================================================


📊 Round 219 Test Metrics:
   Loss: 0.0901, RMSE: 0.3002, MAE: 0.2617, R²: -0.0874

📊 Round 219 Test Metrics:
   Loss: 0.0901, RMSE: 0.3002, MAE: 0.2617, R²: -0.0874

============================================================
🔄 Round 222 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0893, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0893, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0893, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0893, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0893, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0892, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 222 Summary - Client client_62
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0896, RMSE=0.2993, R²=-0.0476
   Val:   Loss=0.0823, RMSE=0.2869, R²=-0.0654
============================================================


============================================================
🔄 Round 224 - Client client_62
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0882, val=0.0877 (↓), lr=0.000001
   • Epoch   2/100: train=0.0882, val=0.0876, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0882, val=0.0876, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0882, val=0.0876, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0882, val=0.0876, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0881, val=0.0875, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0877)

============================================================
📊 Round 224 Summary - Client client_62
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0882, RMSE=0.2970, R²=-0.0372
   Val:   Loss=0.0877, RMSE=0.2961, R²=-0.1124
============================================================


📊 Round 224 Test Metrics:
   Loss: 0.0901, RMSE: 0.3002, MAE: 0.2617, R²: -0.0874

❌ Client client_62 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8687 {grpc_status:14, grpc_message:"Socket closed"}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8687 {grpc_status:14, grpc_message:"Socket closed"}"
>
