[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9175f127-06d3-42f6-a889-2887eec4e07c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9fdedb74-109d-4ced-8548-ca0cf74f52cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8c7b3864-63d2-4d51-935d-cf10903574c3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0aa3efc2-b3c2-4e3f-9cfd-e4876b53c3fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c01d559c-90a6-4a57-8415-134b48b75fcb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6367b1c6-feb5-4492-a923-996830e9069b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 73d63965-43c5-40d5-8e56-29291cee3560
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1829c9b3-d816-4563-acac-569f4fc40866
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 32281781-2e47-44e8-a102-13300b23157a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e9641e7f-94e6-4058-829b-16a4417ff94f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message caf8875c-dd6f-448f-a34f-0f256383ba22
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5a97efda-c795-442c-add1-60e7160dc242
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6011605a-078b-43bf-8ce2-653c37437e88
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 11506c16-5df4-4515-94ac-2d34165767a8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 998c92f2-e84b-4777-a555-bd1f6f3bdc1d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 61ab9925-661b-49ac-ba33-6ddb16d24192
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c0c807aa-e732-4b75-9ed5-c11790385acd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dca80409-992a-4e5a-83df-d05172da9abb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0948acaa-9755-43de-82d5-329ee5d70bb7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 114df8f4-2bba-4b4c-be53-ababc01f990a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 59204d29-73de-4be4-b80a-f49bc1885d05
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 974574de-83b6-4d62-95fd-2af55b554fde
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0c2739f6-ed37-4a93-a5b4-bfe510f76579
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7bc8da07-762a-4570-b8ce-510d99f06410
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e6e38e60-a3ec-4e04-b5b6-53d43b41a5cd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 87931e8f-5b2b-4b13-bbf8-c311ea1b600b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7f3ba8c3-047c-4b99-94df-27e1c9145a3d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 12d997fd-061b-45b8-9fbb-ff4589949f89
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e3aec71f-deca-4ab4-95e8-4d8b7e7ac831
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d0e49c7e-e247-4a95-8443-14fefaad3e02
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bdf7d48f-9b21-41c6-ae94-5284448bdaca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 603202ec-be26-4c3e-a5e5-f4b7c19d4553
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7fc90a9a-b7a6-4ca6-85ab-f58dd3948f15
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3ac7fcad-b8bf-4779-aeb8-f8907a507d1b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6dc14663-b102-417f-a638-ef64b694da45
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8b3d77df-eddc-447d-a0a3-1e80348550ce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7b5db840-7a4f-4c11-91d3-727c8bdf0f3d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e11681f3-bc0b-4541-8218-51d3eaba4a57
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 07962347-48ad-4852-b394-ebe0c4161b49
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fb760a0b-b7ec-4826-9679-e33f7d4ae4da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c40ec91d-2b35-45bf-a05c-22e509826764
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5b210cbd-8dc4-4c51-a755-7bc862c5cab3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 032ab57c-168c-4c75-bbbc-c18f8d6ff64e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 87dfecb1-25c2-4cc3-af3e-b5aeee20a031
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message afd6b303-b061-4b1c-a7fc-3e14200cf14e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message baa213d7-ea50-4a1e-9a08-aa5a04dc7344
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4bd483d2-7f4c-4e92-bb3d-ae0a673c1042
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8918c818-9bb3-43f5-8597-359d018f3112
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a893225f-7f20-4824-906d-faec420353a7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 67086ffa-feda-47cc-815b-78f7492e13b5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3bebb640-eb2c-4fdb-baec-b798c4e1fa59
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2d1dfb46-4b1d-45e1-a225-20b77b0f0465
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 95e124fe-3440-4a5e-a61c-7a46abd56c24
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b4201f9a-b992-482a-aba1-167b849e3938
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5774a18c-dc97-49f1-a48f-5162a647e9f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b996b5cc-f7a8-4be7-84b6-d2f76d2a7a59
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a4b6717e-7ca8-4f2b-b7a5-aa5bd0a036e6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3a3cf28d-48f9-4853-927a-931536b79af6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bd6abfe3-3be9-49cf-863b-69af091c1f9e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5e1f09f4-8134-48cc-80fd-564b5cd38441
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 28c3d1fd-21fc-4684-859a-fd72cb850288
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d6616e4c-3bd9-40a2-a71b-ccb5cddcc2a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 35a8812e-1953-47df-b09f-ef9089115003
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message af537e94-a47f-44e3-849d-c4a671e6de54
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ac3b5e41-286f-48ad-803f-06795dc3c027
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9e0f920e-7e41-4533-8189-bf13c0300ed3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7984f1c0-db78-4b92-ad42-711a33046cdf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8b8ffc76-16c8-4e56-963c-7ff567d407f3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message decd076e-9e3b-45ab-8453-e68c11fa9fd1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8536e9e1-a53c-4902-9131-3d0c1c65944a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fe768329-efb5-4165-abd8-3e38d7753f9c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 30c2bd9a-b16d-4678-b580-1a4927361dca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c542c5ee-dd73-4ddc-bff4-22e7573ba5de
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8e8504b5-0f93-46f0-83c3-1ce41e119f5b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 24d00d89-1346-4ddb-ba3d-d5701dbf5321
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 005328a9-8448-4ed7-994d-9d4cc40ea873
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 352b0422-b466-43d3-8354-b0a26b96bd2c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 70e7d4e1-37cf-488a-9a88-2d9ca5ee2dda
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7bdf12f0-4720-473b-ad78-3a711b49a8b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e608b0fe-c210-42ec-9986-ed49fecaae77
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ade2c7b1-728a-48cf-86c6-ffa5f0230ba1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6b1dab3b-b4f8-4c88-922b-eabaef967642
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b06e1527-91e3-465f-8c19-7b5a3fc594f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cf90c762-de07-4fe8-a543-4acee55e6c23
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 20dec4d3-4431-4dbf-a71d-fe45758fdcc2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4e858961-d5f2-4ce7-9b39-86cf97cfab4f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f9cda15a-8d85-4be5-92d6-8f57d6fc0fb1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4d87402b-069e-4e4e-b3c6-19941bd88292
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 61b78842-6cbd-4d4e-bde8-2ebc390fd049
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5d064938-6bee-4199-adae-5b69442e5b47
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 84b06d99-6321-4ec3-94e1-4f4f72024d95
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2f2ab269-1a70-49c9-9b06-e62dec289372
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6a168ac5-a55f-4f37-8b07-46084711bebb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 26fe3a6e-0b41-47dd-a3de-8373d76d38ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6077a0ea-44f5-4a20-9de5-6f67d87c79cd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 02dce98a-a5a6-45f8-9651-99d13717a64f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fc29cfd7-e885-4647-bdab-92ae2d88bcb5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c783c557-2477-49aa-8755-c0b51965b80f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 13764204-0b63-4642-9ced-69f3238777fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f94335e1-f700-4715-b7bb-03f18e2709aa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1ad3045a-1f78-432f-8f14-7fa87fd23ec0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 86cef889-be7b-43ac-8b26-dad7f2147e7a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e4e06a60-484c-4522-91f6-5e3d86e060ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 59f48e8f-e722-4ec9-8408-42bf2a112367
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ba22413e-9b49-4c7f-b59f-73b901cb1029
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0fa25cea-349d-44c3-9537-5d0398fb7167
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 15df00fa-c93d-48f6-9a9f-629defe0ef14
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2d370c1d-8d21-4a56-a437-092776f75c1e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 442c8881-e381-4df1-b353-fabdf5378f9c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fcede392-87d8-4120-a2c2-f78b81ae16a7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 64c6f72c-2217-452a-b04a-17dc9cea224d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ca0eed88-91c7-40af-81d2-7632df1a8386
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f2302850-c079-4a7f-aa98-bb9280762ded
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 08c8a0aa-ab3d-4950-b319-70f42cf9fc88
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2e9d7c95-b216-46f3-ac67-4767c493c6f6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0367971d-046d-41ab-9b54-556702a8c36f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2177bb18-d26b-433c-803e-d92fc391068b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ce45e870-6d8a-4e3b-bfc9-0aa4ee76f7ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f846030d-c0c7-4454-ba59-fbb2478563e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 63ef64b9-57ed-460c-9811-89d26370dcbd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 45864967-c436-4d9c-b397-8e38988ec29b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5f113a25-4ab1-4136-a64f-cded51c2fc5b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 392a6a21-abc3-4fc6-a2e1-d204d37159c9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2a839216-c9c6-4bf0-a6ba-d00304804483
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 209d9009-efca-4b6e-bb3d-5d652ac6a3ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 39b55c22-dc71-4bf2-87d1-44e32fa1af8c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3dc2f8d8-8370-48a5-a96c-a09c5c54248d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 24622c98-3c5b-4c9a-b27f-112e6040091e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f0769b91-89ad-42e5-bd5f-5e8dcaff4ef2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f3bc19f2-3c03-432c-8100-8c933a825b54
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f22a3a88-74e8-4368-8ffb-faae5f364dfe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6ffe0e16-db9d-4618-ae5c-80698f382cf8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c4263892-4f03-4adc-9985-f6c0e6291c0e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 468c7cf5-7ebb-4542-a501-6e7d91d422e0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a1455bba-f97f-4173-9a27-c3a44ae3d9d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 611b6eb5-0dba-4759-b8f1-3f90d8105ad6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 818ad96a-2919-4432-abf0-e2f5d6824804
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 16977d03-5c66-4bd6-961c-153909a272ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d3b2a7cf-dbc0-4ef6-b20b-cc0515ffd26a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d825f223-be51-41ff-aece-2e4b69b7cb67
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1e6a18cc-af1b-4599-83fb-dfc1feeda962
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 03077de2-bbbe-4380-a90b-088a79e78408
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message edc089e2-f5bc-4228-b731-64aa8bcbb7d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9a89b5a0-4a17-4dae-9cf8-96045be8fdf8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9facd2e8-dfb4-40d2-a798-f3faa3fdf261
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 367ce886-3062-4e17-afa1-044047509398
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 51a0ac93-8107-4e78-88f1-c223034abd38
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 39b89862-8f59-455d-adcf-3b66cb68b6cd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 476e601c-1a62-4b1d-ae50-ba78f4a9cd11
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 07dea2b3-7b1f-450c-a290-5c4a7f0541d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f2bb58ce-c128-4c8c-9f90-9129fa73fe80
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 90eee439-6e1e-4967-ba43-0cedd07c7800
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 53552ac6-7cdf-4ca1-a826-46968b6af82a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a4ca6c3b-a9c5-438b-afcb-fdcf50af754e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 939f947c-b8a9-4e60-8d66-efb249afb4d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 33192ff3-efcc-479b-a066-06f7baaf3250
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a018bf11-f529-49f0-8f0e-e66d77828aec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 447fb2e6-1050-4cec-b430-9d6e493e2d16
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3d2f20f8-4603-4c3f-a32e-872e24a58288
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 63380a70-2f9d-4509-9679-c152533d4d22
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c11b6370-1e6e-4722-b167-db7c2fa62f5c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 992892e0-45d8-46bc-9296-025f67c44320
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 24c5933a-a6dd-4c0a-80ef-2027c26c76f8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bffd3787-ca6d-4625-8e97-d66e78adecdf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 91ebda97-d2e0-4f10-84f0-a6b39c5053e5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 272c009a-d768-4021-be14-40e2fa6d4e36
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8f3e99d1-aa0b-4efd-a509-091068a19ce2
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8687 {grpc_status:14, grpc_message:"Socket closed"}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_63
Server: localhost:8687
Algorithm: FEDAVG
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_63
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_63/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_63/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_63/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_63/test_labels.txt

📊 Raw data loaded:
   Train: X=(1341, 24), y=(1341,)
   Test:  X=(336, 24), y=(336,)

⚠️  Limiting training data: 1341 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  327 samples, 5 features
✅ Client client_63 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

📊 Round 0 Test Metrics:
   Loss: 0.0747, RMSE: 0.2732, MAE: 0.2350, R²: 0.0123

============================================================
🔄 Round 8 - Client client_63
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0774 (↓), lr=0.001000
   • Epoch   2/100: train=0.0776, val=0.0775, patience=1/15, lr=0.001000
   • Epoch   3/100: train=0.0765, val=0.0776, patience=2/15, lr=0.001000
   • Epoch   4/100: train=0.0757, val=0.0782, patience=3/15, lr=0.001000
   ✓ Epoch   5/100: train=0.0747, val=0.0768 (↓), lr=0.001000
   📉 Epoch 11: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0706, val=0.0785, patience=6/15, lr=0.000500
   📉 Epoch 19: LR reduced 0.000500 → 0.000250
   • Epoch  21/100: train=0.0651, val=0.0762, patience=9/15, lr=0.000250
   📉 Epoch 27: LR reduced 0.000250 → 0.000125

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0747)

============================================================
📊 Round 8 Summary - Client client_63
   Epochs: 27/100 (early stopped)
   LR: 0.001000 → 0.000125 (3 reductions)
   Train: Loss=0.0676, RMSE=0.2600, R²=0.1681
   Val:   Loss=0.0747, RMSE=0.2732, R²=0.0286
============================================================


📊 Round 8 Test Metrics:
   Loss: 0.0738, RMSE: 0.2717, MAE: 0.2338, R²: 0.0236

============================================================
🔄 Round 9 - Client client_63
   Epochs: 100, Batch: 32, LR: 0.000125
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0771, val=0.0830 (↓), lr=0.000125
   • Epoch   2/100: train=0.0768, val=0.0831, patience=1/15, lr=0.000125
   • Epoch   3/100: train=0.0765, val=0.0832, patience=2/15, lr=0.000125
   • Epoch   4/100: train=0.0763, val=0.0832, patience=3/15, lr=0.000125
   • Epoch   5/100: train=0.0761, val=0.0832, patience=4/15, lr=0.000125
   📉 Epoch 8: LR reduced 0.000125 → 0.000063
   • Epoch  11/100: train=0.0751, val=0.0829, patience=10/15, lr=0.000063
   📉 Epoch 16: LR reduced 0.000063 → 0.000031

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 9 Summary - Client client_63
   Epochs: 16/100 (early stopped)
   LR: 0.000125 → 0.000031 (2 reductions)
   Train: Loss=0.0769, RMSE=0.2773, R²=0.0344
   Val:   Loss=0.0830, RMSE=0.2881, R²=-0.0075
============================================================


============================================================
🔄 Round 12 - Client client_63
   Epochs: 100, Batch: 32, LR: 0.000031
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0783, val=0.0774 (↓), lr=0.000031
   • Epoch   2/100: train=0.0780, val=0.0776, patience=1/15, lr=0.000031
   • Epoch   3/100: train=0.0778, val=0.0777, patience=2/15, lr=0.000031
   • Epoch   4/100: train=0.0777, val=0.0777, patience=3/15, lr=0.000031
   • Epoch   5/100: train=0.0776, val=0.0778, patience=4/15, lr=0.000031
   📉 Epoch 8: LR reduced 0.000031 → 0.000016
   • Epoch  11/100: train=0.0772, val=0.0780, patience=10/15, lr=0.000016
   📉 Epoch 16: LR reduced 0.000016 → 0.000008

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0774)

============================================================
📊 Round 12 Summary - Client client_63
   Epochs: 16/100 (early stopped)
   LR: 0.000031 → 0.000008 (2 reductions)
   Train: Loss=0.0785, RMSE=0.2801, R²=0.0268
   Val:   Loss=0.0774, RMSE=0.2783, R²=0.0274
============================================================


📊 Round 12 Test Metrics:
   Loss: 0.0741, RMSE: 0.2722, MAE: 0.2341, R²: 0.0195

📊 Round 12 Test Metrics:
   Loss: 0.0739, RMSE: 0.2719, MAE: 0.2338, R²: 0.0219

📊 Round 12 Test Metrics:
   Loss: 0.0739, RMSE: 0.2719, MAE: 0.2338, R²: 0.0223

============================================================
🔄 Round 16 - Client client_63
   Epochs: 100, Batch: 32, LR: 0.000008
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0761 (↓), lr=0.000008
   • Epoch   2/100: train=0.0787, val=0.0760, patience=1/15, lr=0.000008
   • Epoch   3/100: train=0.0786, val=0.0760, patience=2/15, lr=0.000008
   • Epoch   4/100: train=0.0786, val=0.0760, patience=3/15, lr=0.000008
   • Epoch   5/100: train=0.0785, val=0.0759, patience=4/15, lr=0.000008
   📉 Epoch 8: LR reduced 0.000008 → 0.000004
   • Epoch  11/100: train=0.0783, val=0.0758, patience=10/15, lr=0.000004
   📉 Epoch 16: LR reduced 0.000004 → 0.000002

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0761)

============================================================
📊 Round 16 Summary - Client client_63
   Epochs: 16/100 (early stopped)
   LR: 0.000008 → 0.000002 (2 reductions)
   Train: Loss=0.0788, RMSE=0.2807, R²=0.0239
   Val:   Loss=0.0761, RMSE=0.2758, R²=0.0421
============================================================


============================================================
🔄 Round 17 - Client client_63
   Epochs: 100, Batch: 32, LR: 0.000002
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0749 (↓), lr=0.000002
   • Epoch   2/100: train=0.0792, val=0.0749, patience=1/15, lr=0.000002
   • Epoch   3/100: train=0.0792, val=0.0749, patience=2/15, lr=0.000002
   • Epoch   4/100: train=0.0791, val=0.0748, patience=3/15, lr=0.000002
   • Epoch   5/100: train=0.0791, val=0.0748, patience=4/15, lr=0.000002
   📉 Epoch 8: LR reduced 0.000002 → 0.000001
   • Epoch  11/100: train=0.0791, val=0.0747, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0749)

============================================================
📊 Round 17 Summary - Client client_63
   Epochs: 16/100 (early stopped)
   LR: 0.000002 → 0.000001 (1 reductions)
   Train: Loss=0.0792, RMSE=0.2814, R²=0.0297
   Val:   Loss=0.0749, RMSE=0.2737, R²=0.0076
============================================================


============================================================
🔄 Round 18 - Client client_63
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0768, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0768, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0768, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0767, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0767, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0767, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 18 Summary - Client client_63
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0769, RMSE=0.2774, R²=0.0308
   Val:   Loss=0.0841, RMSE=0.2900, R²=0.0074
============================================================


📊 Round 18 Test Metrics:
   Loss: 0.0740, RMSE: 0.2720, MAE: 0.2339, R²: 0.0212

📊 Round 18 Test Metrics:
   Loss: 0.0739, RMSE: 0.2718, MAE: 0.2338, R²: 0.0223

============================================================
🔄 Round 21 - Client client_63
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0761, val=0.0865 (↓), lr=0.000001
   • Epoch   2/100: train=0.0761, val=0.0865, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0761, val=0.0865, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0760, val=0.0865, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0760, val=0.0865, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0759, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0865)

============================================================
📊 Round 21 Summary - Client client_63
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0765, RMSE=0.2766, R²=0.0242
   Val:   Loss=0.0865, RMSE=0.2940, R²=0.0245
============================================================


============================================================
🔄 Round 22 - Client client_63
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0770, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0770, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0769, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0769, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0769, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0768, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 22 Summary - Client client_63
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0771, RMSE=0.2777, R²=0.0212
   Val:   Loss=0.0840, RMSE=0.2899, R²=0.0320
============================================================


📊 Round 22 Test Metrics:
   Loss: 0.0739, RMSE: 0.2718, MAE: 0.2336, R²: 0.0229

📊 Round 22 Test Metrics:
   Loss: 0.0738, RMSE: 0.2717, MAE: 0.2336, R²: 0.0232

============================================================
🔄 Round 25 - Client client_63
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0762, val=0.0870 (↓), lr=0.000001
   • Epoch   2/100: train=0.0762, val=0.0870, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0762, val=0.0870, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0762, val=0.0869, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0762, val=0.0869, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0761, val=0.0868, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 25 Summary - Client client_63
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0764, RMSE=0.2763, R²=0.0280
   Val:   Loss=0.0870, RMSE=0.2950, R²=0.0092
============================================================


📊 Round 25 Test Metrics:
   Loss: 0.0738, RMSE: 0.2717, MAE: 0.2336, R²: 0.0232

============================================================
🔄 Round 27 - Client client_63
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0717 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0717, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0717, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0717, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0717, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0716, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0717)

============================================================
📊 Round 27 Summary - Client client_63
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=0.0306
   Val:   Loss=0.0717, RMSE=0.2678, R²=-0.0045
============================================================


📊 Round 27 Test Metrics:
   Loss: 0.0738, RMSE: 0.2717, MAE: 0.2335, R²: 0.0234

============================================================
🔄 Round 29 - Client client_63
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0751 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0751, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0751, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0751, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0751, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0751, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0751)

============================================================
📊 Round 29 Summary - Client client_63
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2817, R²=0.0241
   Val:   Loss=0.0751, RMSE=0.2740, R²=0.0176
============================================================


📊 Round 29 Test Metrics:
   Loss: 0.0738, RMSE: 0.2717, MAE: 0.2336, R²: 0.0233

📊 Round 29 Test Metrics:
   Loss: 0.0738, RMSE: 0.2717, MAE: 0.2336, R²: 0.0233

📊 Round 29 Test Metrics:
   Loss: 0.0738, RMSE: 0.2717, MAE: 0.2336, R²: 0.0233

📊 Round 29 Test Metrics:
   Loss: 0.0738, RMSE: 0.2717, MAE: 0.2336, R²: 0.0232

📊 Round 29 Test Metrics:
   Loss: 0.0738, RMSE: 0.2717, MAE: 0.2336, R²: 0.0232

📊 Round 29 Test Metrics:
   Loss: 0.0738, RMSE: 0.2717, MAE: 0.2336, R²: 0.0231

📊 Round 29 Test Metrics:
   Loss: 0.0738, RMSE: 0.2717, MAE: 0.2336, R²: 0.0231

📊 Round 29 Test Metrics:
   Loss: 0.0738, RMSE: 0.2717, MAE: 0.2336, R²: 0.0232

============================================================
🔄 Round 47 - Client client_63
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0779, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0779, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0779, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0779, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0779, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0778, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 47 Summary - Client client_63
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0779, RMSE=0.2792, R²=0.0171
   Val:   Loss=0.0807, RMSE=0.2841, R²=0.0489
============================================================


📊 Round 47 Test Metrics:
   Loss: 0.0738, RMSE: 0.2717, MAE: 0.2336, R²: 0.0232

📊 Round 47 Test Metrics:
   Loss: 0.0738, RMSE: 0.2717, MAE: 0.2336, R²: 0.0234

============================================================
🔄 Round 54 - Client client_63
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0770 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0770, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0770, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0769, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0769, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0769, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0770)

============================================================
📊 Round 54 Summary - Client client_63
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2808, R²=0.0166
   Val:   Loss=0.0770, RMSE=0.2775, R²=0.0564
============================================================


============================================================
🔄 Round 56 - Client client_63
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0762, val=0.0881 (↓), lr=0.000001
   • Epoch   2/100: train=0.0762, val=0.0880, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0762, val=0.0880, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0762, val=0.0880, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0762, val=0.0880, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0761, val=0.0880, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0881)

============================================================
📊 Round 56 Summary - Client client_63
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0761, RMSE=0.2759, R²=0.0266
   Val:   Loss=0.0881, RMSE=0.2967, R²=0.0163
============================================================


📊 Round 56 Test Metrics:
   Loss: 0.0738, RMSE: 0.2717, MAE: 0.2336, R²: 0.0234

📊 Round 56 Test Metrics:
   Loss: 0.0738, RMSE: 0.2717, MAE: 0.2335, R²: 0.0235

============================================================
🔄 Round 58 - Client client_63
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0760, val=0.0894 (↓), lr=0.000001
   • Epoch   2/100: train=0.0760, val=0.0894, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0760, val=0.0893, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0759, val=0.0893, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0759, val=0.0893, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0759, val=0.0893, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0894)

============================================================
📊 Round 58 Summary - Client client_63
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0758, RMSE=0.2753, R²=0.0227
   Val:   Loss=0.0894, RMSE=0.2989, R²=0.0314
============================================================


📊 Round 58 Test Metrics:
   Loss: 0.0738, RMSE: 0.2717, MAE: 0.2335, R²: 0.0235

📊 Round 58 Test Metrics:
   Loss: 0.0738, RMSE: 0.2717, MAE: 0.2336, R²: 0.0233

============================================================
🔄 Round 67 - Client client_63
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0772, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0772, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0771, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0771, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0771, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0769, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 67 Summary - Client client_63
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0771, RMSE=0.2776, R²=0.0194
   Val:   Loss=0.0843, RMSE=0.2903, R²=0.0197
============================================================


📊 Round 67 Test Metrics:
   Loss: 0.0738, RMSE: 0.2717, MAE: 0.2336, R²: 0.0232

📊 Round 67 Test Metrics:
   Loss: 0.0738, RMSE: 0.2717, MAE: 0.2336, R²: 0.0231

============================================================
🔄 Round 73 - Client client_63
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0783, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0783, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0783, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0781, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 73 Summary - Client client_63
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2800, R²=0.0177
   Val:   Loss=0.0790, RMSE=0.2811, R²=0.0202
============================================================


============================================================
🔄 Round 74 - Client client_63
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0714 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0714, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0714, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0714, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0714, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0713, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0714)

============================================================
📊 Round 74 Summary - Client client_63
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2833, R²=0.0242
   Val:   Loss=0.0714, RMSE=0.2673, R²=0.0187
============================================================


============================================================
🔄 Round 75 - Client client_63
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0781, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0781, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0781, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0781, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0781, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0780, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 75 Summary - Client client_63
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0779, RMSE=0.2792, R²=0.0269
   Val:   Loss=0.0808, RMSE=0.2843, R²=0.0106
============================================================


📊 Round 75 Test Metrics:
   Loss: 0.0738, RMSE: 0.2718, MAE: 0.2336, R²: 0.0230

============================================================
🔄 Round 77 - Client client_63
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0769, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0769, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0769, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0769, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0768, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0767, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 77 Summary - Client client_63
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0769, RMSE=0.2773, R²=0.0221
   Val:   Loss=0.0849, RMSE=0.2914, R²=0.0301
============================================================


📊 Round 77 Test Metrics:
   Loss: 0.0739, RMSE: 0.2718, MAE: 0.2336, R²: 0.0230

============================================================
🔄 Round 79 - Client client_63
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0772 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0772, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0771, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0771, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0771, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0785, val=0.0771, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 79 Summary - Client client_63
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2808, R²=0.0288
   Val:   Loss=0.0772, RMSE=0.2778, R²=-0.0230
============================================================


📊 Round 79 Test Metrics:
   Loss: 0.0739, RMSE: 0.2718, MAE: 0.2336, R²: 0.0230

📊 Round 79 Test Metrics:
   Loss: 0.0739, RMSE: 0.2718, MAE: 0.2336, R²: 0.0229

============================================================
🔄 Round 81 - Client client_63
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0776, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0776, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0776, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0776, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0776, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0775, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 81 Summary - Client client_63
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0775, RMSE=0.2784, R²=0.0196
   Val:   Loss=0.0825, RMSE=0.2872, R²=0.0392
============================================================


📊 Round 81 Test Metrics:
   Loss: 0.0739, RMSE: 0.2718, MAE: 0.2336, R²: 0.0229

📊 Round 81 Test Metrics:
   Loss: 0.0738, RMSE: 0.2717, MAE: 0.2336, R²: 0.0231

📊 Round 81 Test Metrics:
   Loss: 0.0738, RMSE: 0.2718, MAE: 0.2336, R²: 0.0230

📊 Round 81 Test Metrics:
   Loss: 0.0739, RMSE: 0.2718, MAE: 0.2336, R²: 0.0230

============================================================
🔄 Round 85 - Client client_63
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0772, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0771, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0771, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0771, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0771, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0770, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 85 Summary - Client client_63
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0772, RMSE=0.2778, R²=0.0230
   Val:   Loss=0.0839, RMSE=0.2896, R²=0.0296
============================================================


📊 Round 85 Test Metrics:
   Loss: 0.0739, RMSE: 0.2718, MAE: 0.2336, R²: 0.0230

============================================================
🔄 Round 88 - Client client_63
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0758 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0758, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0757, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0757, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0757, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0756, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0758)

============================================================
📊 Round 88 Summary - Client client_63
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2814, R²=0.0247
   Val:   Loss=0.0758, RMSE=0.2753, R²=0.0132
============================================================


📊 Round 88 Test Metrics:
   Loss: 0.0739, RMSE: 0.2718, MAE: 0.2336, R²: 0.0230

============================================================
🔄 Round 90 - Client client_63
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0780, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0780, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0779, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0779, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0779, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0778, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 90 Summary - Client client_63
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0778, RMSE=0.2789, R²=0.0316
   Val:   Loss=0.0815, RMSE=0.2854, R²=-0.0147
============================================================


============================================================
🔄 Round 91 - Client client_63
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0764 (↓), lr=0.000001
   • Epoch   2/100: train=0.0787, val=0.0764, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0764, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0764, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0764, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0763, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0764)

============================================================
📊 Round 91 Summary - Client client_63
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2811, R²=0.0254
   Val:   Loss=0.0764, RMSE=0.2764, R²=0.0199
============================================================


📊 Round 91 Test Metrics:
   Loss: 0.0739, RMSE: 0.2718, MAE: 0.2336, R²: 0.0229

============================================================
🔄 Round 92 - Client client_63
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0727 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0727, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0727, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0727, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0727, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0727, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0727)

============================================================
📊 Round 92 Summary - Client client_63
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=0.0204
   Val:   Loss=0.0727, RMSE=0.2696, R²=0.0340
============================================================


📊 Round 92 Test Metrics:
   Loss: 0.0739, RMSE: 0.2718, MAE: 0.2336, R²: 0.0230

📊 Round 92 Test Metrics:
   Loss: 0.0739, RMSE: 0.2718, MAE: 0.2336, R²: 0.0229

============================================================
🔄 Round 100 - Client client_63
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0783, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0783, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0782, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0782, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0782, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0781, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 100 Summary - Client client_63
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0781, RMSE=0.2794, R²=0.0242
   Val:   Loss=0.0802, RMSE=0.2833, R²=0.0148
============================================================


📊 Round 100 Test Metrics:
   Loss: 0.0739, RMSE: 0.2718, MAE: 0.2336, R²: 0.0228

📊 Round 100 Test Metrics:
   Loss: 0.0739, RMSE: 0.2718, MAE: 0.2336, R²: 0.0228

============================================================
🔄 Round 103 - Client client_63
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 103 Summary - Client client_63
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0781, RMSE=0.2795, R²=0.0199
   Val:   Loss=0.0802, RMSE=0.2832, R²=0.0337
============================================================


📊 Round 103 Test Metrics:
   Loss: 0.0739, RMSE: 0.2718, MAE: 0.2336, R²: 0.0227

📊 Round 103 Test Metrics:
   Loss: 0.0739, RMSE: 0.2718, MAE: 0.2336, R²: 0.0227

📊 Round 103 Test Metrics:
   Loss: 0.0739, RMSE: 0.2718, MAE: 0.2336, R²: 0.0227

============================================================
🔄 Round 107 - Client client_63
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0780, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0780, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0780, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0779, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0779, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0778, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 107 Summary - Client client_63
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0781, RMSE=0.2795, R²=0.0314
   Val:   Loss=0.0802, RMSE=0.2831, R²=-0.0050
============================================================


============================================================
🔄 Round 108 - Client client_63
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0765 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0765, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0764, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0764, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0764, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0763, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0765)

============================================================
📊 Round 108 Summary - Client client_63
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2811, R²=0.0247
   Val:   Loss=0.0765, RMSE=0.2765, R²=0.0164
============================================================


📊 Round 108 Test Metrics:
   Loss: 0.0739, RMSE: 0.2718, MAE: 0.2336, R²: 0.0227

============================================================
🔄 Round 113 - Client client_63
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0781, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0780, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0780, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0780, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0780, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0779, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 113 Summary - Client client_63
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0781, RMSE=0.2796, R²=0.0252
   Val:   Loss=0.0800, RMSE=0.2829, R²=0.0178
============================================================


============================================================
🔄 Round 114 - Client client_63
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0778, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0778, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0778, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0778, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0778, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0777, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 114 Summary - Client client_63
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0778, RMSE=0.2789, R²=0.0340
   Val:   Loss=0.0815, RMSE=0.2855, R²=-0.0381
============================================================


============================================================
🔄 Round 115 - Client client_63
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0740 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0740, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0740, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0740, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0740, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0739, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0740)

============================================================
📊 Round 115 Summary - Client client_63
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2822, R²=0.0256
   Val:   Loss=0.0740, RMSE=0.2721, R²=0.0170
============================================================


📊 Round 115 Test Metrics:
   Loss: 0.0739, RMSE: 0.2718, MAE: 0.2336, R²: 0.0227

📊 Round 115 Test Metrics:
   Loss: 0.0739, RMSE: 0.2718, MAE: 0.2336, R²: 0.0226

📊 Round 115 Test Metrics:
   Loss: 0.0739, RMSE: 0.2718, MAE: 0.2336, R²: 0.0225

📊 Round 115 Test Metrics:
   Loss: 0.0739, RMSE: 0.2718, MAE: 0.2336, R²: 0.0224

📊 Round 115 Test Metrics:
   Loss: 0.0739, RMSE: 0.2718, MAE: 0.2336, R²: 0.0224

============================================================
🔄 Round 123 - Client client_63
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0742 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0742, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0742, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0742, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0742, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0742, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0742)

============================================================
📊 Round 123 Summary - Client client_63
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2822, R²=0.0218
   Val:   Loss=0.0742, RMSE=0.2724, R²=0.0233
============================================================


============================================================
🔄 Round 124 - Client client_63
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0763, val=0.0873 (↓), lr=0.000001
   • Epoch   2/100: train=0.0763, val=0.0873, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0762, val=0.0873, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0762, val=0.0873, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0762, val=0.0873, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0762, val=0.0872, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0873)

============================================================
📊 Round 124 Summary - Client client_63
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0763, RMSE=0.2763, R²=0.0348
   Val:   Loss=0.0873, RMSE=0.2955, R²=-0.0202
============================================================


============================================================
🔄 Round 125 - Client client_63
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0679 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0679, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0679, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0679, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0679, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0678, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0679)

============================================================
📊 Round 125 Summary - Client client_63
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=0.0237
   Val:   Loss=0.0679, RMSE=0.2606, R²=0.0232
============================================================


📊 Round 125 Test Metrics:
   Loss: 0.0739, RMSE: 0.2718, MAE: 0.2336, R²: 0.0224

📊 Round 125 Test Metrics:
   Loss: 0.0739, RMSE: 0.2718, MAE: 0.2336, R²: 0.0227

📊 Round 125 Test Metrics:
   Loss: 0.0739, RMSE: 0.2718, MAE: 0.2336, R²: 0.0228

📊 Round 125 Test Metrics:
   Loss: 0.0739, RMSE: 0.2718, MAE: 0.2336, R²: 0.0228

📊 Round 125 Test Metrics:
   Loss: 0.0739, RMSE: 0.2718, MAE: 0.2336, R²: 0.0228

============================================================
🔄 Round 133 - Client client_63
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0733 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0733, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0733, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0733, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0733, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0732, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0733)

============================================================
📊 Round 133 Summary - Client client_63
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=0.0277
   Val:   Loss=0.0733, RMSE=0.2708, R²=0.0026
============================================================


📊 Round 133 Test Metrics:
   Loss: 0.0739, RMSE: 0.2718, MAE: 0.2336, R²: 0.0230

📊 Round 133 Test Metrics:
   Loss: 0.0739, RMSE: 0.2718, MAE: 0.2336, R²: 0.0230

============================================================
🔄 Round 139 - Client client_63
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0765, val=0.0865 (↓), lr=0.000001
   • Epoch   2/100: train=0.0765, val=0.0865, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0765, val=0.0865, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0765, val=0.0865, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0764, val=0.0865, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0763, val=0.0866, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0865)

============================================================
📊 Round 139 Summary - Client client_63
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0765, RMSE=0.2767, R²=0.0231
   Val:   Loss=0.0865, RMSE=0.2941, R²=0.0077
============================================================


📊 Round 139 Test Metrics:
   Loss: 0.0739, RMSE: 0.2718, MAE: 0.2336, R²: 0.0228

📊 Round 139 Test Metrics:
   Loss: 0.0739, RMSE: 0.2718, MAE: 0.2336, R²: 0.0228

============================================================
🔄 Round 143 - Client client_63
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0763 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0763, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0763, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0763, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0763, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0762, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0763)

============================================================
📊 Round 143 Summary - Client client_63
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2812, R²=0.0261
   Val:   Loss=0.0763, RMSE=0.2763, R²=0.0159
============================================================


============================================================
🔄 Round 144 - Client client_63
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0777, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0777, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0777, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0777, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0776, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0776, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 144 Summary - Client client_63
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0777, RMSE=0.2788, R²=0.0216
   Val:   Loss=0.0817, RMSE=0.2859, R²=0.0330
============================================================


📊 Round 144 Test Metrics:
   Loss: 0.0739, RMSE: 0.2718, MAE: 0.2336, R²: 0.0227

============================================================
🔄 Round 149 - Client client_63
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0741 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0741, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0741, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0741, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0741, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0741, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0741)

============================================================
📊 Round 149 Summary - Client client_63
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2822, R²=0.0252
   Val:   Loss=0.0741, RMSE=0.2722, R²=0.0199
============================================================


📊 Round 149 Test Metrics:
   Loss: 0.0739, RMSE: 0.2718, MAE: 0.2336, R²: 0.0227

📊 Round 149 Test Metrics:
   Loss: 0.0739, RMSE: 0.2718, MAE: 0.2336, R²: 0.0227

============================================================
🔄 Round 154 - Client client_63
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0777, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0777, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0777, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0777, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0777, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0776, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 154 Summary - Client client_63
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0777, RMSE=0.2787, R²=0.0225
   Val:   Loss=0.0819, RMSE=0.2861, R²=0.0294
============================================================


============================================================
🔄 Round 155 - Client client_63
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0772 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0772, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0772, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0772, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0771, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0771, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 155 Summary - Client client_63
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2808, R²=0.0277
   Val:   Loss=0.0772, RMSE=0.2779, R²=0.0019
============================================================


📊 Round 155 Test Metrics:
   Loss: 0.0739, RMSE: 0.2718, MAE: 0.2336, R²: 0.0226

============================================================
🔄 Round 156 - Client client_63
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0770, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0770, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0770, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0770, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0770, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0769, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 156 Summary - Client client_63
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0770, RMSE=0.2775, R²=0.0275
   Val:   Loss=0.0846, RMSE=0.2908, R²=0.0093
============================================================


📊 Round 156 Test Metrics:
   Loss: 0.0739, RMSE: 0.2718, MAE: 0.2336, R²: 0.0226

📊 Round 156 Test Metrics:
   Loss: 0.0739, RMSE: 0.2718, MAE: 0.2336, R²: 0.0226

============================================================
🔄 Round 158 - Client client_63
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0781, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0780, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0780, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0780, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0780, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0779, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 158 Summary - Client client_63
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0782, RMSE=0.2797, R²=0.0274
   Val:   Loss=0.0798, RMSE=0.2825, R²=0.0114
============================================================


============================================================
🔄 Round 159 - Client client_63
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0691 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0691, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0691, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0691, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0691, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0691, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0691)

============================================================
📊 Round 159 Summary - Client client_63
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=0.0234
   Val:   Loss=0.0691, RMSE=0.2628, R²=0.0171
============================================================


📊 Round 159 Test Metrics:
   Loss: 0.0739, RMSE: 0.2718, MAE: 0.2336, R²: 0.0227

============================================================
🔄 Round 160 - Client client_63
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0745 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0745, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0745, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0745, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0745, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0744, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0745)

============================================================
📊 Round 160 Summary - Client client_63
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2820, R²=0.0219
   Val:   Loss=0.0745, RMSE=0.2729, R²=0.0341
============================================================


📊 Round 160 Test Metrics:
   Loss: 0.0739, RMSE: 0.2718, MAE: 0.2336, R²: 0.0227

📊 Round 160 Test Metrics:
   Loss: 0.0739, RMSE: 0.2718, MAE: 0.2336, R²: 0.0226

📊 Round 160 Test Metrics:
   Loss: 0.0739, RMSE: 0.2718, MAE: 0.2336, R²: 0.0227

📊 Round 160 Test Metrics:
   Loss: 0.0739, RMSE: 0.2718, MAE: 0.2336, R²: 0.0228

📊 Round 160 Test Metrics:
   Loss: 0.0739, RMSE: 0.2718, MAE: 0.2336, R²: 0.0228

📊 Round 160 Test Metrics:
   Loss: 0.0739, RMSE: 0.2718, MAE: 0.2336, R²: 0.0228

📊 Round 160 Test Metrics:
   Loss: 0.0739, RMSE: 0.2718, MAE: 0.2336, R²: 0.0227

📊 Round 160 Test Metrics:
   Loss: 0.0739, RMSE: 0.2718, MAE: 0.2336, R²: 0.0226

============================================================
🔄 Round 176 - Client client_63
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0732 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0732, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0732, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0732, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0731, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0731, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0732)

============================================================
📊 Round 176 Summary - Client client_63
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2826, R²=0.0283
   Val:   Loss=0.0732, RMSE=0.2705, R²=0.0055
============================================================


============================================================
🔄 Round 177 - Client client_63
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0727 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0727, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0727, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0727, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0727, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0727, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0727)

============================================================
📊 Round 177 Summary - Client client_63
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=0.0259
   Val:   Loss=0.0727, RMSE=0.2697, R²=0.0144
============================================================


📊 Round 177 Test Metrics:
   Loss: 0.0739, RMSE: 0.2718, MAE: 0.2337, R²: 0.0226

============================================================
🔄 Round 179 - Client client_63
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0782, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0782, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0782, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0781, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0781, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0781, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 179 Summary - Client client_63
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0782, RMSE=0.2796, R²=0.0274
   Val:   Loss=0.0801, RMSE=0.2829, R²=0.0090
============================================================


============================================================
🔄 Round 180 - Client client_63
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0770, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0770, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0770, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0770, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0770, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0769, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 180 Summary - Client client_63
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0771, RMSE=0.2777, R²=0.0228
   Val:   Loss=0.0842, RMSE=0.2902, R²=0.0285
============================================================


📊 Round 180 Test Metrics:
   Loss: 0.0739, RMSE: 0.2718, MAE: 0.2336, R²: 0.0229

============================================================
🔄 Round 181 - Client client_63
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0767 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0767, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0767, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0767, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0767, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0767, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0767)

============================================================
📊 Round 181 Summary - Client client_63
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2810, R²=0.0258
   Val:   Loss=0.0767, RMSE=0.2770, R²=0.0180
============================================================


📊 Round 181 Test Metrics:
   Loss: 0.0739, RMSE: 0.2718, MAE: 0.2336, R²: 0.0229

============================================================
🔄 Round 183 - Client client_63
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0781, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0781, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0781, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0781, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0780, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0780, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 183 Summary - Client client_63
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0779, RMSE=0.2791, R²=0.0244
   Val:   Loss=0.0810, RMSE=0.2846, R²=0.0189
============================================================


📊 Round 183 Test Metrics:
   Loss: 0.0739, RMSE: 0.2718, MAE: 0.2336, R²: 0.0228

============================================================
🔄 Round 184 - Client client_63
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0763 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0763, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0763, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0763, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0763, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0762, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0763)

============================================================
📊 Round 184 Summary - Client client_63
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2812, R²=0.0208
   Val:   Loss=0.0763, RMSE=0.2763, R²=0.0257
============================================================


📊 Round 184 Test Metrics:
   Loss: 0.0739, RMSE: 0.2718, MAE: 0.2336, R²: 0.0229

📊 Round 184 Test Metrics:
   Loss: 0.0739, RMSE: 0.2718, MAE: 0.2336, R²: 0.0228

📊 Round 184 Test Metrics:
   Loss: 0.0739, RMSE: 0.2718, MAE: 0.2336, R²: 0.0230

📊 Round 184 Test Metrics:
   Loss: 0.0738, RMSE: 0.2717, MAE: 0.2336, R²: 0.0231

📊 Round 184 Test Metrics:
   Loss: 0.0739, RMSE: 0.2718, MAE: 0.2336, R²: 0.0230

📊 Round 184 Test Metrics:
   Loss: 0.0738, RMSE: 0.2717, MAE: 0.2336, R²: 0.0231

============================================================
🔄 Round 192 - Client client_63
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0777, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0777, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0777, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0777, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0776, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0775, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 192 Summary - Client client_63
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0777, RMSE=0.2788, R²=0.0243
   Val:   Loss=0.0816, RMSE=0.2856, R²=0.0066
============================================================


📊 Round 192 Test Metrics:
   Loss: 0.0738, RMSE: 0.2717, MAE: 0.2336, R²: 0.0231

============================================================
🔄 Round 193 - Client client_63
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0719 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0719, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0719, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0719, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0719, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0720, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0719)

============================================================
📊 Round 193 Summary - Client client_63
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2831, R²=0.0186
   Val:   Loss=0.0719, RMSE=0.2682, R²=0.0420
============================================================


============================================================
🔄 Round 197 - Client client_63
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0776, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0775, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0775, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0775, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0775, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0774, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 197 Summary - Client client_63
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0777, RMSE=0.2787, R²=0.0275
   Val:   Loss=0.0818, RMSE=0.2861, R²=-0.0015
============================================================


============================================================
🔄 Round 199 - Client client_63
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0697 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0697, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0697, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0697, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0697, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0697, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0697)

============================================================
📊 Round 199 Summary - Client client_63
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=0.0147
   Val:   Loss=0.0697, RMSE=0.2640, R²=0.0615
============================================================


📊 Round 199 Test Metrics:
   Loss: 0.0739, RMSE: 0.2718, MAE: 0.2336, R²: 0.0229

============================================================
🔄 Round 201 - Client client_63
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0779, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0779, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0779, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0779, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0778, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0778, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 201 Summary - Client client_63
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0777, RMSE=0.2788, R²=0.0300
   Val:   Loss=0.0816, RMSE=0.2857, R²=0.0009
============================================================


📊 Round 201 Test Metrics:
   Loss: 0.0738, RMSE: 0.2717, MAE: 0.2336, R²: 0.0231

============================================================
🔄 Round 204 - Client client_63
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0742 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0742, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0742, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0742, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0742, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0742, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0742)

============================================================
📊 Round 204 Summary - Client client_63
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2821, R²=0.0254
   Val:   Loss=0.0742, RMSE=0.2724, R²=0.0160
============================================================


============================================================
🔄 Round 205 - Client client_63
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0760, val=0.0880 (↓), lr=0.000001
   • Epoch   2/100: train=0.0760, val=0.0880, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0760, val=0.0880, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0760, val=0.0880, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0760, val=0.0880, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0759, val=0.0880, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0880)

============================================================
📊 Round 205 Summary - Client client_63
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0761, RMSE=0.2759, R²=0.0217
   Val:   Loss=0.0880, RMSE=0.2966, R²=0.0252
============================================================


📊 Round 205 Test Metrics:
   Loss: 0.0738, RMSE: 0.2717, MAE: 0.2336, R²: 0.0232

📊 Round 205 Test Metrics:
   Loss: 0.0738, RMSE: 0.2717, MAE: 0.2336, R²: 0.0231

============================================================
🔄 Round 207 - Client client_63
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0732 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0732, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0732, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0732, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0731, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0731, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0732)

============================================================
📊 Round 207 Summary - Client client_63
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2826, R²=0.0239
   Val:   Loss=0.0732, RMSE=0.2706, R²=0.0161
============================================================


📊 Round 207 Test Metrics:
   Loss: 0.0738, RMSE: 0.2717, MAE: 0.2336, R²: 0.0231

============================================================
🔄 Round 209 - Client client_63
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0688 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0688, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0688, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0687, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0687, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0687, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0688)

============================================================
📊 Round 209 Summary - Client client_63
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2845, R²=0.0188
   Val:   Loss=0.0688, RMSE=0.2623, R²=0.0497
============================================================


============================================================
🔄 Round 210 - Client client_63
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0744 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0744, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0744, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0744, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0743, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0743, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0744)

============================================================
📊 Round 210 Summary - Client client_63
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2820, R²=0.0246
   Val:   Loss=0.0744, RMSE=0.2727, R²=0.0195
============================================================


📊 Round 210 Test Metrics:
   Loss: 0.0739, RMSE: 0.2718, MAE: 0.2336, R²: 0.0229

============================================================
🔄 Round 213 - Client client_63
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0761 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0761, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0761, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0761, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0761, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0761, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0761)

============================================================
📊 Round 213 Summary - Client client_63
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2813, R²=0.0228
   Val:   Loss=0.0761, RMSE=0.2758, R²=0.0291
============================================================


📊 Round 213 Test Metrics:
   Loss: 0.0739, RMSE: 0.2718, MAE: 0.2336, R²: 0.0230

============================================================
🔄 Round 217 - Client client_63
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0736 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0736, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0736, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0735, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0735, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0734, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0736)

============================================================
📊 Round 217 Summary - Client client_63
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2824, R²=0.0180
   Val:   Loss=0.0736, RMSE=0.2713, R²=0.0447
============================================================


📊 Round 217 Test Metrics:
   Loss: 0.0738, RMSE: 0.2718, MAE: 0.2336, R²: 0.0230

============================================================
🔄 Round 219 - Client client_63
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0781, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0781, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0781, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0781, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0780, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0780, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 219 Summary - Client client_63
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0779, RMSE=0.2791, R²=0.0231
   Val:   Loss=0.0810, RMSE=0.2846, R²=0.0288
============================================================


📊 Round 219 Test Metrics:
   Loss: 0.0739, RMSE: 0.2718, MAE: 0.2336, R²: 0.0230

============================================================
🔄 Round 220 - Client client_63
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0782, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0782, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0782, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0782, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0782, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0781, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 220 Summary - Client client_63
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0782, RMSE=0.2796, R²=0.0297
   Val:   Loss=0.0799, RMSE=0.2826, R²=0.0007
============================================================


📊 Round 220 Test Metrics:
   Loss: 0.0739, RMSE: 0.2718, MAE: 0.2337, R²: 0.0229

============================================================
🔄 Round 222 - Client client_63
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0783, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0783, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0783, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0782, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0782, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0782, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 222 Summary - Client client_63
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2801, R²=0.0266
   Val:   Loss=0.0788, RMSE=0.2807, R²=0.0153
============================================================


📊 Round 222 Test Metrics:
   Loss: 0.0739, RMSE: 0.2718, MAE: 0.2337, R²: 0.0229

❌ Client client_63 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8687 {grpc_status:14, grpc_message:"Socket closed"}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8687 {grpc_status:14, grpc_message:"Socket closed"}"
>
