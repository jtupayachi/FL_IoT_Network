[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 58a82766-5ce0-4532-865a-e19531292473
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 15760169-9a2d-4f10-a188-c0d8477565a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1d001d91-d12d-4a51-9f36-c9481adf7d11
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 278d4707-d9b0-451e-948a-b6ac677ea724
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 982ff21f-d2cd-4193-9c19-07e9e9a5615d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8a764371-c1ba-4e79-abe1-edd5879d6915
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 556b2b78-d479-441e-b06d-8741ba24f4e5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1bb16328-535c-4ffb-8196-3f21993b898d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9ea83624-2ac9-40eb-86a3-d6a1c8e6c9ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b9fb3447-da63-4a34-b3ae-af53c8a097a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fc48898b-fbb3-4c37-8ae5-00813224be9a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3d778b0d-fb06-486e-bc16-7ebc8187f566
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 063f0f6d-0ada-4914-8aef-6a8d0d1ec464
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 62e21c78-22ec-41cd-8c41-563f04ae6352
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2a12a509-0635-45c8-be8f-9dd39d98a897
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1b95fe57-5e2a-4bdb-af5c-9be8d8f47891
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 57383dd1-9df6-4a1d-997c-62f484c7b3fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 514ae997-2c00-4982-a840-c6cbc50aaabf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c4117bcb-33c1-4c52-aab7-e55c56623f9c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 14cf8a79-3279-4883-85e2-d8f89c1a60e1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e4091b47-0f13-45ce-af1d-d79f3a2e2f54
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fbd2e63d-08c2-4c3f-a948-d2d21f346103
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ae4aed8e-3f28-48ca-ae78-928e6e6a3bef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d28f801e-adda-40f0-9abb-efb866717649
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4975efba-69d6-4bbe-b413-fbf85f2fa4c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 176c3117-b834-43e3-8b53-812c0d715304
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 055bb7db-5716-4e3f-af62-0f62024550b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1c13b665-e338-45a4-9c29-b778b8adc337
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f8a7be87-5f60-41e3-9778-283eeca94397
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message efa7b441-7d5b-48b8-9907-ccc43d391968
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 98dd290f-557f-4aec-ba76-b8c3d7e52129
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8e594815-bf88-4a83-bb67-176119a240b9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2be234cb-f7cd-4195-a733-aba1abb60f17
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 14ffd935-4675-47c2-9c0f-4c6750934ccc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b72145b2-78b5-46e8-a57e-94b1c25857df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 494c19e6-9296-4f60-93a1-ac4d19d64aa9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c6804fd2-7cf7-4eab-aa0a-e17557dc8fa4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8c018076-f82e-471f-9dd9-5a502dc3af71
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3d3a6753-b66a-48c5-b521-265fd5a9b62d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message edcda831-0322-4f43-8d93-97a97dcf7715
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 008bb478-fef1-4b6a-8a07-b73d9ca3d8ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 08a9786f-bd27-460f-9d5b-ddd0d52213d1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 47957217-7428-4c59-8230-9e9427a3cea3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 65314ee3-45ff-4b7d-8d47-364bcadc9333
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d86b962d-c971-4d05-9713-a97f90a852eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2fca0ed9-dfef-40c6-a096-124c20e87e5d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 939da507-bd50-4480-9c04-32546c507c7e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 64b0b463-b16e-4a74-96aa-b340abeac1ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e2033647-3331-451f-be51-d846bb8f0d56
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ed1ef57d-b407-4035-ba78-8e1e720fe138
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 42f570f9-9429-4223-b2e7-f10bb42e6ee3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message be451bb0-b9f8-44a4-a4c9-28d102cfc4f7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 05683784-acbf-4d84-9af4-20921ce54054
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 58eb9223-27e3-4c6b-9e9b-dd5d0134d994
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8a33d4ef-42c9-40ab-9b33-90fd330cf83a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c1a5c01d-277e-4bf2-a71a-bc2884d8dcd3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 87148147-0fe9-47d7-a61a-656e09611088
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e94ae187-08ea-47ec-844a-25ed65ba6c9b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8eca6221-a8b2-4448-9a80-2a4ea5d7fe3e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 58624cff-9a66-4ea7-a29f-64d94bf0e2d1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f975e390-8e8d-46b6-b761-1c2fee25c892
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9f45f434-da7c-4ce6-972b-580ef6955b6b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 84e420bf-b26e-4cfe-ace5-fa1ef2aa40b6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 454c12fa-15d9-42e3-8b81-0e7e5e654099
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4157475c-4928-47c3-89fe-df571c8b1760
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c149755c-d9bd-4d59-9d6b-e55f72712a4e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9da66d29-bf0f-4f8a-a5c4-30955bb9648a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 638ea0f8-70af-450e-acf7-cc718cf8ef1c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f22994b9-33d8-4b41-93bb-c581b95d48c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2f5a122b-8c07-489f-b094-146d3497b40c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9db1579b-450f-498d-bae1-42fc396ef088
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 19b081d0-3f0b-49dc-9aa2-60e157a7ca68
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 80cb8cc9-960e-4d15-a464-416853e761d1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9a13b714-cdb2-4d80-8a86-560e22f2c516
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a1c131b2-86b9-479c-a062-47284dd3f51b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6d06ab36-d879-4290-83e9-4315903f45b0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cfddf5ef-31fd-4e66-81cf-6f9ca8c15cdb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 125cb043-4cdf-4ebb-9088-9d1194ef947d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a659884d-3e9b-4345-9022-ac6c47ff5920
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message de9ccc13-0624-4d3f-9b0b-643be492b5e1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9f009727-afdd-4508-9e76-3f5d613346c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e6abe7fc-4bf5-4354-af0e-0a948a04d091
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f3bba619-8afa-4981-995a-9415941554c3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3f0a26ba-16f2-4179-bb65-df83aafa9843
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1d012c95-3fb4-46d9-b8cc-b4523c0af5ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a5afa7b9-bf7d-4abe-bd01-2bdfce5024bd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8f5d6637-c051-4743-b0fc-6004bcdaf478
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b76a98e3-e81f-4138-b0ee-d68b81f7dc97
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message affaad77-0249-4edb-9eda-3a02c67ead41
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 99827be2-b331-432d-bb29-ee4a2553a12b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5918127b-b569-4670-ae05-5c14ab789cf4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 57594d1d-e855-4a24-a9a9-fac716bfb4b0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6640b686-df23-45a0-805a-1ca7f1625124
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 513ccd4c-9772-4042-9972-df49732b8337
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1bf0b24d-4e34-4afa-a364-9ca66f18fb86
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ce9416a4-da89-4f60-a20d-fce652b59d82
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bfccba6b-c55a-48c3-bb91-f4af1d8e36f4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dccf4216-a966-47fb-be6c-e51b7c657e38
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c08a20ab-ac3b-4d6c-b459-fabd77d083a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9476e323-28e4-4494-80a8-7e715061ccfd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b98d48da-11fb-4240-bb0c-d38c1c9acc4e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 99c95c05-82f5-4d7a-a3ca-b6ee0eb47829
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 98bdcd9f-51fe-4b32-b61b-4867e95f71c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 20b92994-e44f-43d7-833e-22b4965d1d15
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1d64d91c-3083-4510-b319-89467584a998
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 55025387-4a1a-4b53-ab19-a102b8275eb3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cf70e6d8-3a94-4691-a73b-da4235e01806
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a0156ee3-051b-4d92-9f7b-150e75ca7d73
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a9c9a945-507d-417b-9808-daba5b7b8a2b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 24b669d8-3ec7-4f95-9fd0-647650a34292
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8bc93dcd-72e1-4e77-8741-9c402324b2ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 893a90d1-04a3-4eb8-8b9f-96d7036543bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 68e343ef-2d5d-46b9-87e4-f4b0e9953709
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 543c936f-6710-4f0d-953c-94463b84c0a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8e55c012-8bdf-4823-ab19-3cf3afb95917
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b7abaf49-9892-4202-b9d8-97bb6842225e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e2b69a61-199e-46e2-a3b3-273a58e306d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fccceb5e-cdb7-4ca4-992c-82ae5cd0ee3a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9d75250b-2414-4b99-934c-84dc2c551fe5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b9045849-8133-4200-8eb6-6a0ab2ceb8a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3986cf27-47bd-457e-a028-edb3fa6177b6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0c6edb5b-76bb-4f0d-9110-3976453a61a0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fb0300c8-d7c9-4934-abef-441da920e14c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a88bbd27-f8d6-4a27-944d-374f60988558
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5ab764e0-320b-49bd-9755-1a259881ac9a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 937fc696-a815-4b7f-93e9-1e778e80dc6e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 99187988-c943-475e-af2d-4a2dc5935295
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1d3fe454-4e46-46d3-ab9a-d9e9454ede68
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 27f5b2ac-a1b7-427e-87a3-75b786029e74
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6c50639c-49c3-460d-b44e-839394952744
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c03fd8f6-97c6-4dd6-8021-6db2b852e936
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 07eac111-5653-411d-9a6e-3cc3318d75a3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6d599e66-196c-48bc-bc7e-3b973e1255c3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dc40d3bd-88fa-4d14-982c-0671adaff118
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dc1931f0-c254-42f7-b09e-ffae4848091a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2283ad88-bb8d-485b-a2ee-78c90d52eed4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d450234a-3cba-49e4-8a2f-1d9f1063e343
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6bd3b65b-a4e7-447c-8a37-64f7a50eacad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 58f844c2-5663-4302-a7a0-c85dc3a3a679
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5d309c4d-9d77-47d6-a30d-8b1849d5f6a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 48df07e6-f800-4062-b342-3d90b67fe998
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4ad42e2a-15c1-4ab3-af19-d8800bc5a42d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 87513d35-072b-43e7-8383-b65678619108
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1feec958-cac0-4845-8812-770d9750b702
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 67611a11-468c-4049-b177-7e4046b85bff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 09ce3cfd-fda7-4e3b-a233-1d60890b8285
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 663d5217-20a3-47ce-a5f1-a7b2ed27cf7e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 73a438ce-e2ea-4ae0-9de8-228095d2a40a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e7c623db-848c-4796-b6df-e821af6b1376
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f7eabfef-1bb5-4ebb-9f1b-d5fce850d49c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a419b6bb-dff6-4c48-bf5b-5e8e4828baf2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 90466626-a37a-40c4-81e4-0e00c5f02afc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2ac33300-d677-45b7-a342-ef6b83a6bd2f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 473bac63-d001-45f4-b25b-090672e4c7ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b39bad3d-e4cd-4e63-a386-bca88b3bd926
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7bebc41c-a788-4a40-897e-f952af5f97ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c20bb222-9b4a-4dad-9658-dc5e1bbb3306
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e2e6468b-b4c5-4222-a9a3-bdbc415608d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aceb6ca1-a8de-42c5-be50-244faf700548
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5005bae7-d8db-4f1b-a493-3590c3698983
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ed5121a3-00d0-4944-ae19-c5d2f2089bfb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a776ebce-8691-4895-a422-06eccfc3c0ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 325ce200-0655-42b6-a3fb-fc6b92ae30e8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fa4c9955-78a3-4bc8-9778-cc3c1e4a80d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8f3c155f-5258-46a1-861f-b55c3dbe8ab7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4d1b88eb-5a0c-4154-a022-8d60fec8a7c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 937d9acf-496f-4f3e-8104-18a605db4024
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4fa197ec-fef5-4d88-b3f5-7bf320e6aa13
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 297231d5-652a-4ebb-9cd1-80313c681804
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 62e5d662-64d2-4851-b03b-789de6b33680
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 03c53859-a087-4bed-b597-0a436df84af4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d2a97981-7e99-42e9-a773-61fe4a264ec1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c14d1aaa-4fb1-4045-a97f-d975084d607e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 15a0ee84-57e9-4e2e-9e3a-d240149ac7c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message df329341-90d1-443c-bd59-50cf5a1ce609
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3e455481-6ccd-4266-aee4-f1cd19329d3d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 26f05ad9-f43d-4512-968c-126fcfe903f9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 23ea588e-cbdf-4c2b-af8d-414bc533c3fb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0b266b19-494d-46be-b29d-d8c52d2f0cc2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9dbeca5a-5249-4b0b-889e-082b0b43797f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4126eda1-efba-492a-bffd-fec8e4599416
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fe83f6fd-5e9e-4ecd-b6fe-a81b93407981
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message be39027f-3fad-4aaf-9ec1-3150c1d9cdc9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 407e6515-7cbd-4221-9c98-8a9a9dd27bdb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 538e1c05-39a5-44ff-b186-cee405d40115
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8687 {grpc_status:14, grpc_message:"Socket closed"}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_64
Server: localhost:8687
Algorithm: FEDAVG
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_64
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_64/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_64/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_64/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_64/test_labels.txt

📊 Raw data loaded:
   Train: X=(1040, 24), y=(1040,)
   Test:  X=(261, 24), y=(261,)

⚠️  Limiting training data: 1040 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  252 samples, 5 features
✅ Client client_64 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

📊 Round 0 Test Metrics:
   Loss: 0.0842, RMSE: 0.2902, MAE: 0.2520, R²: 0.0218

============================================================
🔄 Round 6 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0783 (↓), lr=0.001000
   • Epoch   2/100: train=0.0784, val=0.0801, patience=1/15, lr=0.001000
   • Epoch   3/100: train=0.0767, val=0.0780, patience=2/15, lr=0.001000
   • Epoch   4/100: train=0.0750, val=0.0779, patience=3/15, lr=0.001000
   ✓ Epoch   5/100: train=0.0736, val=0.0777 (↓), lr=0.001000
   • Epoch  11/100: train=0.0663, val=0.0765, patience=3/15, lr=0.001000
   📉 Epoch 15: LR reduced 0.001000 → 0.000500
   • Epoch  21/100: train=0.0580, val=0.0772, patience=5/15, lr=0.000500
   📉 Epoch 23: LR reduced 0.000500 → 0.000250
   📉 Epoch 31: LR reduced 0.000250 → 0.000125
   • Epoch  31/100: train=0.0536, val=0.0796, patience=15/15, lr=0.000125

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0757)

============================================================
📊 Round 6 Summary - Client client_64
   Epochs: 31/100 (early stopped)
   LR: 0.001000 → 0.000125 (3 reductions)
   Train: Loss=0.0597, RMSE=0.2442, R²=0.2692
   Val:   Loss=0.0757, RMSE=0.2752, R²=0.0127
============================================================


📊 Round 6 Test Metrics:
   Loss: 0.0837, RMSE: 0.2894, MAE: 0.2516, R²: 0.0273

============================================================
🔄 Round 7 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000125
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0780, val=0.0768 (↓), lr=0.000125
   • Epoch   2/100: train=0.0774, val=0.0766, patience=1/15, lr=0.000125
   • Epoch   3/100: train=0.0771, val=0.0767, patience=2/15, lr=0.000125
   • Epoch   4/100: train=0.0768, val=0.0767, patience=3/15, lr=0.000125
   • Epoch   5/100: train=0.0766, val=0.0767, patience=4/15, lr=0.000125
   📉 Epoch 8: LR reduced 0.000125 → 0.000063
   • Epoch  11/100: train=0.0756, val=0.0764, patience=10/15, lr=0.000063
   📉 Epoch 16: LR reduced 0.000063 → 0.000031
   • Epoch  21/100: train=0.0749, val=0.0761, patience=7/15, lr=0.000031
   📉 Epoch 24: LR reduced 0.000031 → 0.000016

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0763)

============================================================
📊 Round 7 Summary - Client client_64
   Epochs: 29/100 (early stopped)
   LR: 0.000125 → 0.000016 (3 reductions)
   Train: Loss=0.0752, RMSE=0.2743, R²=0.0703
   Val:   Loss=0.0763, RMSE=0.2761, R²=0.0489
============================================================


============================================================
🔄 Round 9 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000016
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0757, val=0.0829 (↓), lr=0.000016
   • Epoch   2/100: train=0.0756, val=0.0828, patience=1/15, lr=0.000016
   📉 Epoch 3: LR reduced 0.000016 → 0.000008
   • Epoch   3/100: train=0.0754, val=0.0826, patience=2/15, lr=0.000008
   • Epoch   4/100: train=0.0753, val=0.0826, patience=3/15, lr=0.000008
   • Epoch   5/100: train=0.0753, val=0.0825, patience=4/15, lr=0.000008
   📉 Epoch 11: LR reduced 0.000008 → 0.000004
   • Epoch  11/100: train=0.0750, val=0.0823, patience=2/15, lr=0.000004
   📉 Epoch 19: LR reduced 0.000004 → 0.000002
   • Epoch  21/100: train=0.0748, val=0.0822, patience=12/15, lr=0.000002

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 9 Summary - Client client_64
   Epochs: 24/100 (early stopped)
   LR: 0.000016 → 0.000002 (3 reductions)
   Train: Loss=0.0751, RMSE=0.2740, R²=0.0532
   Val:   Loss=0.0824, RMSE=0.2870, R²=0.0492
============================================================


============================================================
🔄 Round 10 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000002
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0747, val=0.0852 (↓), lr=0.000002
   • Epoch   2/100: train=0.0747, val=0.0851, patience=1/15, lr=0.000002
   📉 Epoch 3: LR reduced 0.000002 → 0.000001
   • Epoch   3/100: train=0.0747, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0746, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0746, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0746, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 10 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000002 → 0.000001 (1 reductions)
   Train: Loss=0.0749, RMSE=0.2736, R²=0.0367
   Val:   Loss=0.0852, RMSE=0.2918, R²=0.0851
============================================================


📊 Round 10 Test Metrics:
   Loss: 0.0830, RMSE: 0.2880, MAE: 0.2509, R²: 0.0362

📊 Round 10 Test Metrics:
   Loss: 0.0831, RMSE: 0.2883, MAE: 0.2512, R²: 0.0344

============================================================
🔄 Round 16 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0783, val=0.0678 (↓), lr=0.000001
   • Epoch   2/100: train=0.0783, val=0.0678, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0782, val=0.0678, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0782, val=0.0678, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0782, val=0.0678, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0782, val=0.0677, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0678)

============================================================
📊 Round 16 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0781, RMSE=0.2795, R²=0.0456
   Val:   Loss=0.0678, RMSE=0.2604, R²=0.1056
============================================================


📊 Round 16 Test Metrics:
   Loss: 0.0824, RMSE: 0.2870, MAE: 0.2498, R²: 0.0429

============================================================
🔄 Round 17 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0776, val=0.0697 (↓), lr=0.000001
   • Epoch   2/100: train=0.0776, val=0.0697, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0775, val=0.0697, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0775, val=0.0697, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0775, val=0.0697, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0774, val=0.0698, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0697)

============================================================
📊 Round 17 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0774, RMSE=0.2783, R²=0.0504
   Val:   Loss=0.0697, RMSE=0.2641, R²=0.0895
============================================================


============================================================
🔄 Round 19 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0749, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0749, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0749, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0749, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0749, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0748, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 19 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0749, RMSE=0.2736, R²=0.0540
   Val:   Loss=0.0797, RMSE=0.2823, R²=0.0869
============================================================


📊 Round 19 Test Metrics:
   Loss: 0.0823, RMSE: 0.2868, MAE: 0.2497, R²: 0.0445

============================================================
🔄 Round 21 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0772, val=0.0695 (↓), lr=0.000001
   • Epoch   2/100: train=0.0772, val=0.0695, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0771, val=0.0695, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0771, val=0.0695, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0771, val=0.0695, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0770, val=0.0694, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0695)

============================================================
📊 Round 21 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0771, RMSE=0.2777, R²=0.0676
   Val:   Loss=0.0695, RMSE=0.2637, R²=0.0472
============================================================


📊 Round 21 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2496, R²: 0.0454

============================================================
🔄 Round 23 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0754, val=0.0764 (↓), lr=0.000001
   • Epoch   2/100: train=0.0754, val=0.0764, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0754, val=0.0764, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0754, val=0.0764, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0753, val=0.0764, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0752, val=0.0764, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0764)

============================================================
📊 Round 23 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0754, RMSE=0.2746, R²=0.0517
   Val:   Loss=0.0764, RMSE=0.2763, R²=0.0948
============================================================


📊 Round 23 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2496, R²: 0.0453

📊 Round 23 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2496, R²: 0.0453

============================================================
🔄 Round 26 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0754, val=0.0767 (↓), lr=0.000001
   • Epoch   2/100: train=0.0754, val=0.0766, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0754, val=0.0766, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0754, val=0.0766, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0754, val=0.0766, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0754, val=0.0765, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0767)

============================================================
📊 Round 26 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0753, RMSE=0.2744, R²=0.0580
   Val:   Loss=0.0767, RMSE=0.2769, R²=0.0840
============================================================


📊 Round 26 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2496, R²: 0.0454

📊 Round 26 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2496, R²: 0.0454

============================================================
🔄 Round 28 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0745, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0745, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0745, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0745, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0745, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0744, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 28 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0742, RMSE=0.2724, R²=0.0643
   Val:   Loss=0.0811, RMSE=0.2847, R²=0.0638
============================================================


============================================================
🔄 Round 29 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0756, val=0.0768 (↓), lr=0.000001
   • Epoch   2/100: train=0.0756, val=0.0768, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0755, val=0.0768, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0755, val=0.0768, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0755, val=0.0768, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0754, val=0.0767, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0768)

============================================================
📊 Round 29 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0753, RMSE=0.2744, R²=0.0619
   Val:   Loss=0.0768, RMSE=0.2771, R²=0.0721
============================================================


📊 Round 29 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2496, R²: 0.0454

============================================================
🔄 Round 33 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0756, val=0.0750 (↓), lr=0.000001
   • Epoch   2/100: train=0.0756, val=0.0750, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0756, val=0.0750, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0756, val=0.0750, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0756, val=0.0750, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0754, val=0.0750, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0750)

============================================================
📊 Round 33 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0757, RMSE=0.2751, R²=0.0557
   Val:   Loss=0.0750, RMSE=0.2739, R²=0.0886
============================================================


📊 Round 33 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2496, R²: 0.0455

📊 Round 33 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2496, R²: 0.0455

============================================================
🔄 Round 36 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0779, val=0.0663 (↓), lr=0.000001
   • Epoch   2/100: train=0.0778, val=0.0663, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0778, val=0.0663, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0778, val=0.0663, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0778, val=0.0663, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0777, val=0.0662, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0663)

============================================================
📊 Round 36 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0779, RMSE=0.2790, R²=0.0718
   Val:   Loss=0.0663, RMSE=0.2575, R²=0.0273
============================================================


📊 Round 36 Test Metrics:
   Loss: 0.0822, RMSE: 0.2866, MAE: 0.2496, R²: 0.0455

============================================================
🔄 Round 38 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0767, val=0.0704 (↓), lr=0.000001
   • Epoch   2/100: train=0.0767, val=0.0704, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0766, val=0.0704, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0766, val=0.0704, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0766, val=0.0704, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0765, val=0.0704, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0704)

============================================================
📊 Round 38 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0768, RMSE=0.2772, R²=0.0662
   Val:   Loss=0.0704, RMSE=0.2653, R²=0.0552
============================================================


============================================================
🔄 Round 39 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0753, val=0.0762 (↓), lr=0.000001
   • Epoch   2/100: train=0.0753, val=0.0762, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0753, val=0.0762, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0753, val=0.0762, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0753, val=0.0761, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0752, val=0.0761, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0762)

============================================================
📊 Round 39 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0754, RMSE=0.2746, R²=0.0636
   Val:   Loss=0.0762, RMSE=0.2760, R²=0.0666
============================================================


📊 Round 39 Test Metrics:
   Loss: 0.0822, RMSE: 0.2866, MAE: 0.2496, R²: 0.0456

📊 Round 39 Test Metrics:
   Loss: 0.0822, RMSE: 0.2866, MAE: 0.2496, R²: 0.0456

============================================================
🔄 Round 43 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0765, val=0.0723 (↓), lr=0.000001
   • Epoch   2/100: train=0.0764, val=0.0723, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0764, val=0.0723, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0764, val=0.0723, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0764, val=0.0723, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0763, val=0.0722, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0723)

============================================================
📊 Round 43 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0764, RMSE=0.2763, R²=0.0611
   Val:   Loss=0.0723, RMSE=0.2689, R²=0.0794
============================================================


📊 Round 43 Test Metrics:
   Loss: 0.0822, RMSE: 0.2866, MAE: 0.2496, R²: 0.0456

============================================================
🔄 Round 46 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0754, val=0.0769 (↓), lr=0.000001
   • Epoch   2/100: train=0.0754, val=0.0769, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0754, val=0.0769, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0753, val=0.0769, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0753, val=0.0769, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0752, val=0.0769, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0769)

============================================================
📊 Round 46 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0752, RMSE=0.2742, R²=0.0557
   Val:   Loss=0.0769, RMSE=0.2774, R²=0.0973
============================================================


📊 Round 46 Test Metrics:
   Loss: 0.0822, RMSE: 0.2866, MAE: 0.2496, R²: 0.0457

📊 Round 46 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2495, R²: 0.0457

📊 Round 46 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2495, R²: 0.0457

============================================================
🔄 Round 51 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0754, val=0.0758 (↓), lr=0.000001
   • Epoch   2/100: train=0.0754, val=0.0757, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0754, val=0.0757, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0754, val=0.0757, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0754, val=0.0757, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0753, val=0.0757, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0758)

============================================================
📊 Round 51 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0755, RMSE=0.2748, R²=0.0754
   Val:   Loss=0.0758, RMSE=0.2752, R²=0.0199
============================================================


============================================================
🔄 Round 55 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0733, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0733, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0733, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0732, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0732, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0731, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 55 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0734, RMSE=0.2709, R²=0.0670
   Val:   Loss=0.0843, RMSE=0.2903, R²=0.0571
============================================================


============================================================
🔄 Round 56 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0729, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0729, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0729, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0729, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0729, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0728, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 56 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0730, RMSE=0.2701, R²=0.0654
   Val:   Loss=0.0858, RMSE=0.2930, R²=0.0574
============================================================


📊 Round 56 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2495, R²: 0.0460

============================================================
🔄 Round 59 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0742, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0742, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0742, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0742, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0741, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0740, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 59 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0743, RMSE=0.2726, R²=0.0693
   Val:   Loss=0.0806, RMSE=0.2839, R²=0.0479
============================================================


📊 Round 59 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2495, R²: 0.0460

📊 Round 59 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2495, R²: 0.0460

📊 Round 59 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2495, R²: 0.0460

============================================================
🔄 Round 62 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0750, val=0.0764 (↓), lr=0.000001
   • Epoch   2/100: train=0.0750, val=0.0764, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0750, val=0.0764, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0750, val=0.0764, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0750, val=0.0764, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0749, val=0.0763, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0764)

============================================================
📊 Round 62 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0753, RMSE=0.2744, R²=0.0637
   Val:   Loss=0.0764, RMSE=0.2765, R²=0.0693
============================================================


📊 Round 62 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2495, R²: 0.0460

============================================================
🔄 Round 63 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0749, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0749, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0749, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0748, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0748, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0747, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 63 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0749, RMSE=0.2736, R²=0.0676
   Val:   Loss=0.0781, RMSE=0.2795, R²=0.0532
============================================================


📊 Round 63 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2495, R²: 0.0460

============================================================
🔄 Round 64 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0768, val=0.0693 (↓), lr=0.000001
   • Epoch   2/100: train=0.0768, val=0.0693, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0768, val=0.0693, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0767, val=0.0693, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0767, val=0.0693, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0766, val=0.0693, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0693)

============================================================
📊 Round 64 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0771, RMSE=0.2777, R²=0.0650
   Val:   Loss=0.0693, RMSE=0.2632, R²=0.0530
============================================================


============================================================
🔄 Round 65 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0750, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0750, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0750, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0750, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0750, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0749, val=0.0774, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 65 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0750, RMSE=0.2739, R²=0.0635
   Val:   Loss=0.0775, RMSE=0.2784, R²=0.0445
============================================================


📊 Round 65 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2495, R²: 0.0460

============================================================
🔄 Round 66 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0642 (↓), lr=0.000001
   • Epoch   2/100: train=0.0785, val=0.0642, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0785, val=0.0642, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0785, val=0.0642, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0785, val=0.0642, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0641, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0642)

============================================================
📊 Round 66 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0783, RMSE=0.2799, R²=0.0575
   Val:   Loss=0.0642, RMSE=0.2534, R²=0.0990
============================================================


📊 Round 66 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2495, R²: 0.0460

============================================================
🔄 Round 67 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0741, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0740, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0740, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0740, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0740, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0739, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 67 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0739, RMSE=0.2718, R²=0.0573
   Val:   Loss=0.0821, RMSE=0.2865, R²=0.0912
============================================================


📊 Round 67 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2495, R²: 0.0461

============================================================
🔄 Round 69 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0764, val=0.0715 (↓), lr=0.000001
   • Epoch   2/100: train=0.0764, val=0.0715, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0764, val=0.0715, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0763, val=0.0715, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0763, val=0.0715, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0762, val=0.0715, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0715)

============================================================
📊 Round 69 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0765, RMSE=0.2766, R²=0.0620
   Val:   Loss=0.0715, RMSE=0.2673, R²=0.0605
============================================================


============================================================
🔄 Round 71 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0760, val=0.0739 (↓), lr=0.000001
   • Epoch   2/100: train=0.0759, val=0.0739, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0759, val=0.0739, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0759, val=0.0739, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0759, val=0.0739, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0758, val=0.0739, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0739)

============================================================
📊 Round 71 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0759, RMSE=0.2755, R²=0.0689
   Val:   Loss=0.0739, RMSE=0.2719, R²=0.0451
============================================================


📊 Round 71 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2495, R²: 0.0461

============================================================
🔄 Round 72 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0761, val=0.0734 (↓), lr=0.000001
   • Epoch   2/100: train=0.0761, val=0.0734, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0761, val=0.0734, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0760, val=0.0733, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0760, val=0.0733, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0759, val=0.0733, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0734)

============================================================
📊 Round 72 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0760, RMSE=0.2758, R²=0.0639
   Val:   Loss=0.0734, RMSE=0.2709, R²=0.0702
============================================================


📊 Round 72 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2495, R²: 0.0461

============================================================
🔄 Round 73 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0720, val=0.0910 (↓), lr=0.000001
   • Epoch   2/100: train=0.0719, val=0.0910, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0719, val=0.0909, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0719, val=0.0909, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0719, val=0.0909, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0718, val=0.0908, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0910)

============================================================
📊 Round 73 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0717, RMSE=0.2677, R²=0.0725
   Val:   Loss=0.0910, RMSE=0.3016, R²=0.0407
============================================================


============================================================
🔄 Round 75 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0765, val=0.0721 (↓), lr=0.000001
   • Epoch   2/100: train=0.0764, val=0.0721, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0764, val=0.0721, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0764, val=0.0721, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0764, val=0.0721, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0763, val=0.0720, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0721)

============================================================
📊 Round 75 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0764, RMSE=0.2763, R²=0.0735
   Val:   Loss=0.0721, RMSE=0.2685, R²=0.0285
============================================================


📊 Round 75 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2495, R²: 0.0461

============================================================
🔄 Round 76 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0737, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0737, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0737, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0737, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0737, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0736, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 76 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0736, RMSE=0.2714, R²=0.0761
   Val:   Loss=0.0830, RMSE=0.2881, R²=0.0159
============================================================


============================================================
🔄 Round 77 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0757, val=0.0746 (↓), lr=0.000001
   • Epoch   2/100: train=0.0756, val=0.0746, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0756, val=0.0746, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0756, val=0.0746, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0756, val=0.0746, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0755, val=0.0745, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0746)

============================================================
📊 Round 77 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0757, RMSE=0.2752, R²=0.0677
   Val:   Loss=0.0746, RMSE=0.2731, R²=0.0532
============================================================


============================================================
🔄 Round 78 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0766, val=0.0707 (↓), lr=0.000001
   • Epoch   2/100: train=0.0766, val=0.0707, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0766, val=0.0707, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0766, val=0.0707, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0766, val=0.0707, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0765, val=0.0706, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0707)

============================================================
📊 Round 78 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0767, RMSE=0.2769, R²=0.0613
   Val:   Loss=0.0707, RMSE=0.2660, R²=0.0826
============================================================


📊 Round 78 Test Metrics:
   Loss: 0.0821, RMSE: 0.2865, MAE: 0.2495, R²: 0.0462

============================================================
🔄 Round 83 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0737, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0737, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0737, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0737, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0737, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0736, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 83 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0734, RMSE=0.2709, R²=0.0701
   Val:   Loss=0.0839, RMSE=0.2897, R²=0.0487
============================================================


📊 Round 83 Test Metrics:
   Loss: 0.0821, RMSE: 0.2865, MAE: 0.2495, R²: 0.0463

============================================================
🔄 Round 85 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0743, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0743, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0743, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0743, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0743, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0742, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 85 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0744, RMSE=0.2727, R²=0.0727
   Val:   Loss=0.0800, RMSE=0.2828, R²=0.0368
============================================================


📊 Round 85 Test Metrics:
   Loss: 0.0821, RMSE: 0.2865, MAE: 0.2495, R²: 0.0463

============================================================
🔄 Round 86 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0736, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0736, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0736, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0735, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0735, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0734, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 86 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0737, RMSE=0.2714, R²=0.0700
   Val:   Loss=0.0828, RMSE=0.2877, R²=0.0324
============================================================


📊 Round 86 Test Metrics:
   Loss: 0.0821, RMSE: 0.2865, MAE: 0.2495, R²: 0.0463

============================================================
🔄 Round 88 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0753, val=0.0757 (↓), lr=0.000001
   • Epoch   2/100: train=0.0753, val=0.0757, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0753, val=0.0757, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0753, val=0.0757, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0752, val=0.0757, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0752, val=0.0756, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0757)

============================================================
📊 Round 88 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0754, RMSE=0.2747, R²=0.0627
   Val:   Loss=0.0757, RMSE=0.2751, R²=0.0751
============================================================


============================================================
🔄 Round 91 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0758, val=0.0736 (↓), lr=0.000001
   • Epoch   2/100: train=0.0758, val=0.0736, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0758, val=0.0736, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0757, val=0.0736, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0757, val=0.0736, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0756, val=0.0735, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0736)

============================================================
📊 Round 91 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0760, RMSE=0.2756, R²=0.0669
   Val:   Loss=0.0736, RMSE=0.2713, R²=0.0560
============================================================


📊 Round 91 Test Metrics:
   Loss: 0.0821, RMSE: 0.2865, MAE: 0.2495, R²: 0.0464

📊 Round 91 Test Metrics:
   Loss: 0.0821, RMSE: 0.2865, MAE: 0.2495, R²: 0.0464

============================================================
🔄 Round 94 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0738, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0738, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0738, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0738, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0738, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0737, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 94 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0741, RMSE=0.2723, R²=0.0637
   Val:   Loss=0.0810, RMSE=0.2845, R²=0.0723
============================================================


============================================================
🔄 Round 95 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0758, val=0.0743 (↓), lr=0.000001
   • Epoch   2/100: train=0.0758, val=0.0743, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0758, val=0.0743, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0758, val=0.0743, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0757, val=0.0743, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0756, val=0.0742, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0743)

============================================================
📊 Round 95 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0758, RMSE=0.2753, R²=0.0646
   Val:   Loss=0.0743, RMSE=0.2726, R²=0.0596
============================================================


📊 Round 95 Test Metrics:
   Loss: 0.0821, RMSE: 0.2865, MAE: 0.2495, R²: 0.0464

============================================================
🔄 Round 98 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0741, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0741, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0741, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0741, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0741, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0739, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 98 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0743, RMSE=0.2726, R²=0.0724
   Val:   Loss=0.0802, RMSE=0.2831, R²=0.0328
============================================================


📊 Round 98 Test Metrics:
   Loss: 0.0821, RMSE: 0.2865, MAE: 0.2494, R²: 0.0465

📊 Round 98 Test Metrics:
   Loss: 0.0821, RMSE: 0.2865, MAE: 0.2494, R²: 0.0465

============================================================
🔄 Round 101 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0768, val=0.0707 (↓), lr=0.000001
   • Epoch   2/100: train=0.0768, val=0.0707, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0768, val=0.0707, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0767, val=0.0707, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0767, val=0.0706, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0767, val=0.0706, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0707)

============================================================
📊 Round 101 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0767, RMSE=0.2769, R²=0.0586
   Val:   Loss=0.0707, RMSE=0.2659, R²=0.0692
============================================================


📊 Round 101 Test Metrics:
   Loss: 0.0821, RMSE: 0.2865, MAE: 0.2494, R²: 0.0465

📊 Round 101 Test Metrics:
   Loss: 0.0821, RMSE: 0.2865, MAE: 0.2494, R²: 0.0465

============================================================
🔄 Round 105 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0742, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0742, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0741, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0741, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0741, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0740, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 105 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0744, RMSE=0.2727, R²=0.0687
   Val:   Loss=0.0798, RMSE=0.2825, R²=0.0543
============================================================


📊 Round 105 Test Metrics:
   Loss: 0.0821, RMSE: 0.2865, MAE: 0.2494, R²: 0.0465

============================================================
🔄 Round 112 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0760, val=0.0737 (↓), lr=0.000001
   • Epoch   2/100: train=0.0760, val=0.0736, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0760, val=0.0736, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0760, val=0.0736, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0759, val=0.0736, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0759, val=0.0735, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0737)

============================================================
📊 Round 112 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0759, RMSE=0.2755, R²=0.0670
   Val:   Loss=0.0737, RMSE=0.2714, R²=0.0604
============================================================


============================================================
🔄 Round 113 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0732, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0732, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0731, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0731, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0731, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0730, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 113 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0729, RMSE=0.2700, R²=0.0641
   Val:   Loss=0.0857, RMSE=0.2927, R²=0.0700
============================================================


============================================================
🔄 Round 114 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0765, val=0.0717 (↓), lr=0.000001
   • Epoch   2/100: train=0.0765, val=0.0717, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0764, val=0.0717, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0764, val=0.0718, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0764, val=0.0718, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0763, val=0.0718, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0717)

============================================================
📊 Round 114 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0764, RMSE=0.2764, R²=0.0635
   Val:   Loss=0.0717, RMSE=0.2678, R²=0.0542
============================================================


============================================================
🔄 Round 116 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0752, val=0.0763 (↓), lr=0.000001
   • Epoch   2/100: train=0.0751, val=0.0763, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0751, val=0.0763, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0751, val=0.0763, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0751, val=0.0763, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0750, val=0.0762, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0763)

============================================================
📊 Round 116 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0752, RMSE=0.2743, R²=0.0690
   Val:   Loss=0.0763, RMSE=0.2763, R²=0.0537
============================================================


📊 Round 116 Test Metrics:
   Loss: 0.0821, RMSE: 0.2865, MAE: 0.2494, R²: 0.0466

============================================================
🔄 Round 117 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0759, val=0.0741 (↓), lr=0.000001
   • Epoch   2/100: train=0.0759, val=0.0741, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0759, val=0.0740, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0759, val=0.0740, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0758, val=0.0740, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0758, val=0.0739, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0741)

============================================================
📊 Round 117 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0758, RMSE=0.2753, R²=0.0696
   Val:   Loss=0.0741, RMSE=0.2722, R²=0.0451
============================================================


============================================================
🔄 Round 118 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0739, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0739, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0739, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0739, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0738, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0737, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 118 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0739, RMSE=0.2718, R²=0.0605
   Val:   Loss=0.0818, RMSE=0.2860, R²=0.0834
============================================================


============================================================
🔄 Round 120 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0757, val=0.0746 (↓), lr=0.000001
   • Epoch   2/100: train=0.0757, val=0.0746, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0757, val=0.0746, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0756, val=0.0746, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0756, val=0.0746, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0756, val=0.0745, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0746)

============================================================
📊 Round 120 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0757, RMSE=0.2751, R²=0.0669
   Val:   Loss=0.0746, RMSE=0.2731, R²=0.0600
============================================================


============================================================
🔄 Round 122 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0768, val=0.0712 (↓), lr=0.000001
   • Epoch   2/100: train=0.0768, val=0.0712, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0768, val=0.0712, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0768, val=0.0712, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0767, val=0.0712, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0767, val=0.0711, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0712)

============================================================
📊 Round 122 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0765, RMSE=0.2766, R²=0.0671
   Val:   Loss=0.0712, RMSE=0.2668, R²=0.0612
============================================================


============================================================
🔄 Round 123 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0758, val=0.0735 (↓), lr=0.000001
   • Epoch   2/100: train=0.0758, val=0.0735, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0758, val=0.0735, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0757, val=0.0735, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0757, val=0.0735, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0757, val=0.0735, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0735)

============================================================
📊 Round 123 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0759, RMSE=0.2755, R²=0.0577
   Val:   Loss=0.0735, RMSE=0.2712, R²=0.0844
============================================================


============================================================
🔄 Round 125 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0635 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0635, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0635, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0635, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0635, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0635, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0635)

============================================================
📊 Round 125 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2800, R²=0.0648
   Val:   Loss=0.0635, RMSE=0.2521, R²=0.0621
============================================================


📊 Round 125 Test Metrics:
   Loss: 0.0821, RMSE: 0.2865, MAE: 0.2494, R²: 0.0467

============================================================
🔄 Round 132 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0754, val=0.0764 (↓), lr=0.000001
   • Epoch   2/100: train=0.0753, val=0.0764, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0753, val=0.0764, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0753, val=0.0764, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0753, val=0.0765, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0751, val=0.0765, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0764)

============================================================
📊 Round 132 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0752, RMSE=0.2742, R²=0.0694
   Val:   Loss=0.0764, RMSE=0.2764, R²=0.0254
============================================================


📊 Round 132 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2494, R²: 0.0469

📊 Round 132 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2494, R²: 0.0469

📊 Round 132 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2494, R²: 0.0470

============================================================
🔄 Round 135 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0739, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0738, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0738, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0738, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0738, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0738, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 135 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0738, RMSE=0.2717, R²=0.0651
   Val:   Loss=0.0820, RMSE=0.2864, R²=0.0600
============================================================


============================================================
🔄 Round 136 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0764, val=0.0714 (↓), lr=0.000001
   • Epoch   2/100: train=0.0763, val=0.0714, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0763, val=0.0714, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0763, val=0.0714, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0763, val=0.0714, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0762, val=0.0713, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0714)

============================================================
📊 Round 136 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0765, RMSE=0.2765, R²=0.0652
   Val:   Loss=0.0714, RMSE=0.2672, R²=0.0689
============================================================


📊 Round 136 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2494, R²: 0.0470

============================================================
🔄 Round 137 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0757, val=0.0742 (↓), lr=0.000001
   • Epoch   2/100: train=0.0757, val=0.0742, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0757, val=0.0742, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0756, val=0.0742, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0756, val=0.0743, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0755, val=0.0744, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0742)

============================================================
📊 Round 137 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0758, RMSE=0.2752, R²=0.0655
   Val:   Loss=0.0742, RMSE=0.2724, R²=0.0373
============================================================


============================================================
🔄 Round 138 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0757, val=0.0744 (↓), lr=0.000001
   • Epoch   2/100: train=0.0757, val=0.0744, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0757, val=0.0744, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0757, val=0.0744, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0757, val=0.0744, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0756, val=0.0743, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0744)

============================================================
📊 Round 138 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0757, RMSE=0.2751, R²=0.0680
   Val:   Loss=0.0744, RMSE=0.2728, R²=0.0539
============================================================


📊 Round 138 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2494, R²: 0.0470

============================================================
🔄 Round 139 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0730, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0730, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0730, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0729, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0729, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0728, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 139 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0733, RMSE=0.2707, R²=0.0623
   Val:   Loss=0.0842, RMSE=0.2902, R²=0.0761
============================================================


📊 Round 139 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2494, R²: 0.0470

============================================================
🔄 Round 140 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0747, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0747, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0747, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0747, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0747, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0746, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 140 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0747, RMSE=0.2734, R²=0.0713
   Val:   Loss=0.0783, RMSE=0.2798, R²=0.0423
============================================================


📊 Round 140 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2494, R²: 0.0470

============================================================
🔄 Round 141 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0757, val=0.0746 (↓), lr=0.000001
   • Epoch   2/100: train=0.0757, val=0.0746, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0757, val=0.0746, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0757, val=0.0746, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0757, val=0.0746, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0756, val=0.0745, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0746)

============================================================
📊 Round 141 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0757, RMSE=0.2751, R²=0.0645
   Val:   Loss=0.0746, RMSE=0.2731, R²=0.0720
============================================================


📊 Round 141 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2494, R²: 0.0470

============================================================
🔄 Round 143 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0742, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0742, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0742, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0741, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0741, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0741, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 143 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0742, RMSE=0.2724, R²=0.0715
   Val:   Loss=0.0803, RMSE=0.2835, R²=0.0448
============================================================


============================================================
🔄 Round 145 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0759, val=0.0741 (↓), lr=0.000001
   • Epoch   2/100: train=0.0758, val=0.0741, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0758, val=0.0741, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0758, val=0.0741, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0758, val=0.0741, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0757, val=0.0741, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0741)

============================================================
📊 Round 145 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0758, RMSE=0.2752, R²=0.0677
   Val:   Loss=0.0741, RMSE=0.2723, R²=0.0597
============================================================


============================================================
🔄 Round 147 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0767, val=0.0706 (↓), lr=0.000001
   • Epoch   2/100: train=0.0767, val=0.0706, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0766, val=0.0705, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0766, val=0.0705, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0766, val=0.0705, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0765, val=0.0704, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0706)

============================================================
📊 Round 147 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0766, RMSE=0.2769, R²=0.0671
   Val:   Loss=0.0706, RMSE=0.2657, R²=0.0622
============================================================


📊 Round 147 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2494, R²: 0.0471

📊 Round 147 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2494, R²: 0.0471

============================================================
🔄 Round 150 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0749, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0749, val=0.0778, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0748, val=0.0778, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0748, val=0.0778, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0748, val=0.0778, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0747, val=0.0777, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 150 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0748, RMSE=0.2736, R²=0.0626
   Val:   Loss=0.0778, RMSE=0.2790, R²=0.0776
============================================================


============================================================
🔄 Round 152 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0762, val=0.0713 (↓), lr=0.000001
   • Epoch   2/100: train=0.0762, val=0.0713, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0762, val=0.0713, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0762, val=0.0713, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0762, val=0.0713, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0761, val=0.0713, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0713)

============================================================
📊 Round 152 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0764, RMSE=0.2765, R²=0.0664
   Val:   Loss=0.0713, RMSE=0.2671, R²=0.0616
============================================================


📊 Round 152 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2494, R²: 0.0471

============================================================
🔄 Round 154 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0762, val=0.0729 (↓), lr=0.000001
   • Epoch   2/100: train=0.0762, val=0.0729, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0762, val=0.0728, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0762, val=0.0728, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0762, val=0.0728, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0761, val=0.0728, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0729)

============================================================
📊 Round 154 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0761, RMSE=0.2758, R²=0.0717
   Val:   Loss=0.0729, RMSE=0.2699, R²=0.0424
============================================================


============================================================
🔄 Round 155 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0745, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0745, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0745, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0745, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0745, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0744, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 155 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0747, RMSE=0.2732, R²=0.0773
   Val:   Loss=0.0785, RMSE=0.2801, R²=0.0196
============================================================


============================================================
🔄 Round 157 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0741, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0740, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0740, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0740, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0740, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0739, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 157 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0742, RMSE=0.2724, R²=0.0617
   Val:   Loss=0.0804, RMSE=0.2835, R²=0.0774
============================================================


============================================================
🔄 Round 158 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0760, val=0.0733 (↓), lr=0.000001
   • Epoch   2/100: train=0.0760, val=0.0733, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0760, val=0.0732, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0760, val=0.0732, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0759, val=0.0732, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0758, val=0.0732, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0733)

============================================================
📊 Round 158 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0760, RMSE=0.2756, R²=0.0671
   Val:   Loss=0.0733, RMSE=0.2707, R²=0.0626
============================================================


📊 Round 158 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2493, R²: 0.0473

📊 Round 158 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2493, R²: 0.0473

============================================================
🔄 Round 163 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0742, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0742, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0742, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0742, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0742, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0741, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 163 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0740, RMSE=0.2720, R²=0.0768
   Val:   Loss=0.0811, RMSE=0.2848, R²=0.0242
============================================================


📊 Round 163 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2493, R²: 0.0473

============================================================
🔄 Round 166 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0713, val=0.0927 (↓), lr=0.000001
   • Epoch   2/100: train=0.0713, val=0.0927, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0712, val=0.0927, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0712, val=0.0927, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0712, val=0.0926, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0712, val=0.0925, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0927)

============================================================
📊 Round 166 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0711, RMSE=0.2667, R²=0.0623
   Val:   Loss=0.0927, RMSE=0.3045, R²=0.0684
============================================================


============================================================
🔄 Round 167 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0749, val=0.0780 (↓), lr=0.000001
   • Epoch   2/100: train=0.0749, val=0.0780, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0749, val=0.0779, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0749, val=0.0779, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0749, val=0.0779, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0748, val=0.0779, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 167 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0748, RMSE=0.2735, R²=0.0622
   Val:   Loss=0.0780, RMSE=0.2792, R²=0.0797
============================================================


📊 Round 167 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2493, R²: 0.0474

============================================================
🔄 Round 169 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0741, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0741, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0741, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0741, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0740, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0740, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 169 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0742, RMSE=0.2724, R²=0.0695
   Val:   Loss=0.0802, RMSE=0.2832, R²=0.0541
============================================================


📊 Round 169 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2493, R²: 0.0474

📊 Round 169 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2493, R²: 0.0474

============================================================
🔄 Round 172 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0754, val=0.0751 (↓), lr=0.000001
   • Epoch   2/100: train=0.0754, val=0.0751, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0753, val=0.0751, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0753, val=0.0751, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0753, val=0.0751, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0752, val=0.0750, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0751)

============================================================
📊 Round 172 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0755, RMSE=0.2748, R²=0.0761
   Val:   Loss=0.0751, RMSE=0.2741, R²=0.0171
============================================================


📊 Round 172 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2493, R²: 0.0475

📊 Round 172 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2493, R²: 0.0475

============================================================
🔄 Round 174 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0750, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0749, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0749, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0749, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0749, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0748, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 174 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0749, RMSE=0.2736, R²=0.0675
   Val:   Loss=0.0775, RMSE=0.2785, R²=0.0570
============================================================


📊 Round 174 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2493, R²: 0.0475

============================================================
🔄 Round 176 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0730, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0730, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0730, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0730, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0730, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0730, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 176 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0733, RMSE=0.2707, R²=0.0588
   Val:   Loss=0.0839, RMSE=0.2896, R²=0.0792
============================================================


📊 Round 176 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2493, R²: 0.0475

============================================================
🔄 Round 179 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0754, val=0.0753 (↓), lr=0.000001
   • Epoch   2/100: train=0.0754, val=0.0753, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0754, val=0.0753, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0753, val=0.0753, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0753, val=0.0753, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0753, val=0.0752, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0753)

============================================================
📊 Round 179 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0754, RMSE=0.2746, R²=0.0731
   Val:   Loss=0.0753, RMSE=0.2744, R²=0.0395
============================================================


📊 Round 179 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2493, R²: 0.0475

============================================================
🔄 Round 180 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0753, val=0.0757 (↓), lr=0.000001
   • Epoch   2/100: train=0.0752, val=0.0757, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0752, val=0.0757, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0752, val=0.0757, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0752, val=0.0757, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0751, val=0.0757, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0757)

============================================================
📊 Round 180 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0753, RMSE=0.2745, R²=0.0648
   Val:   Loss=0.0757, RMSE=0.2752, R²=0.0702
============================================================


============================================================
🔄 Round 181 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0767, val=0.0696 (↓), lr=0.000001
   • Epoch   2/100: train=0.0767, val=0.0696, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0767, val=0.0696, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0767, val=0.0696, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0767, val=0.0696, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0766, val=0.0695, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0696)

============================================================
📊 Round 181 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0769, RMSE=0.2772, R²=0.0601
   Val:   Loss=0.0696, RMSE=0.2638, R²=0.0924
============================================================


============================================================
🔄 Round 185 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0769, val=0.0700 (↓), lr=0.000001
   • Epoch   2/100: train=0.0769, val=0.0700, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0769, val=0.0700, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0768, val=0.0700, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0768, val=0.0700, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0768, val=0.0699, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0700)

============================================================
📊 Round 185 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0768, RMSE=0.2770, R²=0.0584
   Val:   Loss=0.0700, RMSE=0.2646, R²=0.0982
============================================================


📊 Round 185 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2493, R²: 0.0477

📊 Round 185 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2493, R²: 0.0478

📊 Round 185 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2493, R²: 0.0478

============================================================
🔄 Round 190 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0739, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0739, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0739, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0739, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0738, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0738, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 190 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0739, RMSE=0.2718, R²=0.0680
   Val:   Loss=0.0816, RMSE=0.2856, R²=0.0508
============================================================


📊 Round 190 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2493, R²: 0.0478

============================================================
🔄 Round 191 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0765, val=0.0716 (↓), lr=0.000001
   • Epoch   2/100: train=0.0765, val=0.0716, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0765, val=0.0716, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0765, val=0.0716, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0765, val=0.0716, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0764, val=0.0715, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0716)

============================================================
📊 Round 191 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0764, RMSE=0.2763, R²=0.0653
   Val:   Loss=0.0716, RMSE=0.2676, R²=0.0673
============================================================


📊 Round 191 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2493, R²: 0.0479

📊 Round 191 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2492, R²: 0.0479

============================================================
🔄 Round 195 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0734, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0734, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0734, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0734, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0734, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0732, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 195 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0734, RMSE=0.2709, R²=0.0696
   Val:   Loss=0.0835, RMSE=0.2889, R²=0.0485
============================================================


📊 Round 195 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2492, R²: 0.0479

📊 Round 195 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2492, R²: 0.0479

============================================================
🔄 Round 198 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0748, val=0.0779 (↓), lr=0.000001
   • Epoch   2/100: train=0.0748, val=0.0779, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0748, val=0.0779, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0748, val=0.0779, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0748, val=0.0779, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0747, val=0.0778, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0779)

============================================================
📊 Round 198 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0748, RMSE=0.2735, R²=0.0761
   Val:   Loss=0.0779, RMSE=0.2791, R²=0.0282
============================================================


📊 Round 198 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2492, R²: 0.0479

📊 Round 198 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2492, R²: 0.0480

📊 Round 198 Test Metrics:
   Loss: 0.0819, RMSE: 0.2863, MAE: 0.2492, R²: 0.0480

📊 Round 198 Test Metrics:
   Loss: 0.0819, RMSE: 0.2863, MAE: 0.2492, R²: 0.0480

============================================================
🔄 Round 208 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0752, val=0.0763 (↓), lr=0.000001
   • Epoch   2/100: train=0.0752, val=0.0763, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0752, val=0.0763, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0752, val=0.0763, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0751, val=0.0763, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0751, val=0.0762, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0763)

============================================================
📊 Round 208 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0752, RMSE=0.2742, R²=0.0693
   Val:   Loss=0.0763, RMSE=0.2763, R²=0.0559
============================================================


============================================================
🔄 Round 209 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0762, val=0.0714 (↓), lr=0.000001
   • Epoch   2/100: train=0.0762, val=0.0714, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0762, val=0.0714, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0762, val=0.0714, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0762, val=0.0714, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0761, val=0.0713, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0714)

============================================================
📊 Round 209 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0764, RMSE=0.2764, R²=0.0648
   Val:   Loss=0.0714, RMSE=0.2673, R²=0.0733
============================================================


============================================================
🔄 Round 210 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0762, val=0.0719 (↓), lr=0.000001
   • Epoch   2/100: train=0.0762, val=0.0719, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0762, val=0.0719, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0762, val=0.0719, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0762, val=0.0719, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0761, val=0.0718, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0719)

============================================================
📊 Round 210 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0763, RMSE=0.2761, R²=0.0637
   Val:   Loss=0.0719, RMSE=0.2682, R²=0.0598
============================================================


============================================================
🔄 Round 211 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0759, val=0.0732 (↓), lr=0.000001
   • Epoch   2/100: train=0.0759, val=0.0732, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0759, val=0.0732, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0758, val=0.0732, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0758, val=0.0732, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0757, val=0.0731, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0732)

============================================================
📊 Round 211 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0759, RMSE=0.2756, R²=0.0756
   Val:   Loss=0.0732, RMSE=0.2705, R²=0.0276
============================================================


📊 Round 211 Test Metrics:
   Loss: 0.0819, RMSE: 0.2863, MAE: 0.2492, R²: 0.0481

============================================================
🔄 Round 213 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0771, val=0.0694 (↓), lr=0.000001
   • Epoch   2/100: train=0.0771, val=0.0693, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0771, val=0.0693, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0771, val=0.0693, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0770, val=0.0693, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0770, val=0.0693, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0694)

============================================================
📊 Round 213 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0769, RMSE=0.2773, R²=0.0740
   Val:   Loss=0.0694, RMSE=0.2633, R²=0.0326
============================================================


============================================================
🔄 Round 214 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0747, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0747, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0747, val=0.0782, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0747, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0747, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0746, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 214 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0747, RMSE=0.2733, R²=0.0690
   Val:   Loss=0.0782, RMSE=0.2797, R²=0.0502
============================================================


============================================================
🔄 Round 215 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0759, val=0.0730 (↓), lr=0.000001
   • Epoch   2/100: train=0.0759, val=0.0730, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0759, val=0.0730, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0758, val=0.0730, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0758, val=0.0730, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0758, val=0.0729, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0730)

============================================================
📊 Round 215 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0760, RMSE=0.2757, R²=0.0659
   Val:   Loss=0.0730, RMSE=0.2702, R²=0.0701
============================================================


📊 Round 215 Test Metrics:
   Loss: 0.0819, RMSE: 0.2863, MAE: 0.2492, R²: 0.0481

============================================================
🔄 Round 216 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0740, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0739, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0739, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0739, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0739, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0738, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 216 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0737, RMSE=0.2714, R²=0.0687
   Val:   Loss=0.0823, RMSE=0.2868, R²=0.0522
============================================================


📊 Round 216 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2492, R²: 0.0482

============================================================
🔄 Round 217 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0757, val=0.0741 (↓), lr=0.000001
   • Epoch   2/100: train=0.0757, val=0.0741, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0756, val=0.0742, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0756, val=0.0742, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0756, val=0.0742, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0755, val=0.0742, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0741)

============================================================
📊 Round 217 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0757, RMSE=0.2751, R²=0.0653
   Val:   Loss=0.0741, RMSE=0.2723, R²=0.0549
============================================================


📊 Round 217 Test Metrics:
   Loss: 0.0819, RMSE: 0.2863, MAE: 0.2492, R²: 0.0482

============================================================
🔄 Round 222 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0774, val=0.0681 (↓), lr=0.000001
   • Epoch   2/100: train=0.0774, val=0.0680, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0774, val=0.0680, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0774, val=0.0680, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0774, val=0.0680, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0773, val=0.0679, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0681)

============================================================
📊 Round 222 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0772, RMSE=0.2779, R²=0.0643
   Val:   Loss=0.0681, RMSE=0.2609, R²=0.0741
============================================================


============================================================
🔄 Round 224 - Client client_64
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0757, val=0.0742 (↓), lr=0.000001
   • Epoch   2/100: train=0.0757, val=0.0742, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0757, val=0.0741, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0757, val=0.0741, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0757, val=0.0741, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0756, val=0.0741, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0742)

============================================================
📊 Round 224 Summary - Client client_64
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0757, RMSE=0.2751, R²=0.0457
   Val:   Loss=0.0742, RMSE=0.2723, R²=0.1442
============================================================


📊 Round 224 Test Metrics:
   Loss: 0.0819, RMSE: 0.2863, MAE: 0.2492, R²: 0.0481

❌ Client client_64 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8687 {grpc_status:14, grpc_message:"Socket closed"}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8687 {grpc_status:14, grpc_message:"Socket closed"}"
>
