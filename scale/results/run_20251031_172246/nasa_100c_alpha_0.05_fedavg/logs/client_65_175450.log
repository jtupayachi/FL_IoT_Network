[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 258474e2-87b3-4bf1-820c-dc1c2351569e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 73b3ba18-9a31-48d8-92fb-c598e5d27840
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6045ee5d-ea8b-48d6-9ce4-1d1630a6adc5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e5451478-5a06-4a9b-b1f9-3992bb429b5b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e30e967a-9519-4612-bcea-0404b517944c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b1906750-8b5e-4087-a0b8-493ddeb569f3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f9fc8a78-255b-4431-a645-de4203083e2c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8be24e92-a8b3-4acf-a0c8-b0d3b047f9ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ce910863-636c-4d2a-80d7-f7253edcf55c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1368aaf4-6c2e-4f38-a719-df1ca0fa84ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 345e101e-8b88-440b-b6e8-03a7c3a8ac62
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 33456431-34ca-4d94-bbd7-5d632e6699de
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e65f3552-8d6c-4931-9816-9eaa97b3cf50
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 602b7653-4715-4a1b-bc5c-f78001557a34
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3dd38d8e-01e9-4383-9475-1376d25af293
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 44162a82-50f9-46d5-b904-d0ed8ddb76a8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 72a4f73e-55de-47d8-8a15-de8c842afbcd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cfe72e9d-a789-4aa0-956b-8e39f37ef3d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 48c9f9aa-9953-4854-bd7a-bedbf62244c4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7ac25737-62d7-4e45-82c8-336fcc3c640f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b284dba4-2907-4f54-8af8-78c14bc3594f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fa71654a-9ba3-47f0-a77c-d0819459de67
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7263dc20-89d3-49b2-831f-ac917a25b77b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 521fb921-0ad2-4328-8567-b42a88240df9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5b0a5621-3cfa-4179-b033-19d00821008a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5cf02c3c-37ba-49f8-a5fa-9eb92bca3ce9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 219ebee4-2bbe-4cb7-a314-ddfda6efb840
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1635cfaa-35cc-47e6-b355-7528113fc923
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message edf25d34-f9f3-4bcd-8024-306481305853
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 44e5486b-5646-46af-b605-84f35329c3c7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 54252e5b-cc26-45d6-ae04-c2a4cede82e0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f9a303d9-3dd3-466c-8c90-1851037ec81f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a6af2bcb-6111-4cc6-a74a-c68a990fba83
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7ec52eaf-f073-4de2-bbc1-408c10ccdbbd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8b3cf022-bc52-4493-9939-582ed1636390
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 25250fd8-2908-4303-a75f-13d6a6a5daa5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 154137f6-230f-4998-89db-42718587f3d9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7b7d243a-d834-4feb-9303-9d439a2ee288
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4e5e3ab2-795e-472b-8166-3d2923a91e52
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8acac2a8-3d35-4841-8f08-92668a806529
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 45761487-bf41-49ad-a597-133ccaad7aeb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5d1f2f16-4500-4632-8023-525561b79f79
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 955b1ab6-5f0d-4626-b574-8151028bb7f3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c1e6eaf1-306e-4b0e-90d8-7401768acb9a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2eca10d5-54ac-4a50-8f23-0a18e745e387
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cc645ed5-f25f-4f86-9698-90e8ae14be63
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message df2724a3-826d-426d-b00b-04a02e048618
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 34e674a1-783d-46b9-b860-002670601ddc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 05c3bbc7-2305-4f7a-9fc6-413e402095a8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fccd226a-92c8-4d4f-ad60-41ee2145a2fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9051d1c6-f16e-43c7-b1f0-ef03d69ed5ce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4e25c75a-dd0f-4592-8deb-3144b40abbf6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bb56344e-11be-49bb-b0e3-a3873a42d6e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 77821633-5a20-4eba-a4cd-5dd078f3192a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 336dd18a-2c3f-456e-bb5f-db235e2ae9d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b0c85c24-2e2a-4e34-a993-1c7ac90f5ddf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f767b7f8-e850-40b2-b061-dc1fefd13257
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4b9164a8-f726-4f45-9af8-127cc9dd9ee0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ef182de6-a352-4393-a31a-26649986712b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5252a12a-db41-49f6-93db-6cd9dce08452
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 417a893b-5082-4339-9a0c-685598968f7e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f9526f59-5f6f-436e-8a2a-f8432b8ea138
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dc7ca935-eb0c-4c54-b411-c034b4fca3c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b982331c-bd19-4617-bbbc-e9fb9b65ab7f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 622350e1-7da8-4bcd-8196-ed7a833a16f2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 76d0cac8-3e3d-43dc-a006-65f4a5156a0d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b014c6e5-da3c-4657-acdc-99be2da04cd4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 41520e55-b137-4ad0-8f49-048b77d7a8f2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f6d19b21-2e3e-4d32-bb53-3960752234da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c74e2c32-75b4-447c-b58c-ffe36881029c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 28f42030-de58-4e90-a9d9-8fbcd3adaa05
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5dbdb4dc-7720-42be-9564-f7b8f54804f9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2b3d6dd4-99db-4670-a943-8d5b5af635f9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 90cbda23-552c-4f12-83a3-b9374c4b2fe7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ac81b790-f69e-4a8d-867e-c24cc432c2e9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8dc0d55f-ddf3-4891-9fde-6ed40d52fc8f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 82f60b27-0a09-4918-ad8a-0afcab34794b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 243af804-7002-49e3-8ffd-2b83d75067e8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0c490049-edd4-4f85-a4c8-7fbbaa78c1e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 75e17ea8-290e-44d0-b996-126d4b02beea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 372365be-9d17-460e-8179-08a8684f38c5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b2a423ab-c911-45c3-8b1b-2d1b67639034
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 57778d91-f2bf-44a9-bfe7-b78568aa216c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f95833e0-b495-425a-8237-fbb7e593b5a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 999724d7-3b51-4b6e-8eac-b56f97addb0e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f1da517f-ba31-47f8-9aac-662371564318
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message be935c6f-0241-44d7-9586-8e8d441b1173
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1355779b-bd6c-4cba-95b9-1282af783c34
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message df998510-0c72-4bf7-ab8d-07af40b50c48
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9934d7d9-8241-4427-a328-cb9096d1ffcd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b7b3b354-e6d8-4a81-901d-c7470d954b3c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 81f04579-ea58-44b1-9dbd-4c0e64d7487b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2176c4f8-dac8-42e8-8243-b6cf490e76c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message be88dfd1-e7ca-42ea-ba34-9a51755c9265
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7f3ebb04-119c-4936-b7b1-faf17cb905d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5f6a1e1e-ab97-4d57-8581-beed64c8bf66
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aefe4618-723a-4c7b-a375-6064dbcd4eea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 71cbe6f1-d4bf-43cf-b165-255149766e76
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cd279655-d5e3-418a-b24b-6f2af00be71f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6308b64d-d23f-4112-a97a-3844a1086a94
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fe9b95a5-598a-475a-a843-72e618954829
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 76bd251f-558f-4b25-967f-dc68c28492ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 67b55a5a-a75d-42ba-b61f-fb2880b7fa75
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 04bbb30a-5421-4205-ba21-09811d34c47c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e7818acb-3d50-45a8-9b1d-8b2e56ab2d98
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b58545e5-e476-4a17-b5cc-9f70130d5ec7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 08479ba1-93c3-49e0-b7a1-6ff79feb737b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b09e67a9-9e1a-4aa2-a58e-3a80728b4736
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 977bb6ab-37aa-410d-8ac8-d4da8a9f9ed8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c885d6ba-2986-49b6-a5b5-a2a9651af3a3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a258eae1-4561-4593-a497-ef0d9a7a7279
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e5a0156c-4d79-40ec-a4d7-bf64e83e2689
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a604b760-4d3a-4fcd-8a00-61cc3917e5c3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4de003dd-7173-40a7-b536-c68c951784ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b5cda35d-0084-4452-9fd8-c60b3be86dfc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 17e8c7e4-4ec0-478d-a368-f63d4fef9b1b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7ad20fff-c158-455a-b32f-50d851333365
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5aac3d3c-a8b2-4929-85b8-71aeddffa685
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1ca46d4e-757c-47c1-a263-c824698488b1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 12a134ef-c4e8-4c11-a7b9-0a11dbdc1c03
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 535b8820-a0d0-4e39-8091-6da51cc8e4ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3f261a1d-e781-4d2c-9767-fb3478579a7a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ed568f73-7083-4347-9ed0-8724d767f1a0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 19313c84-c360-42b5-856a-b838f48ea6c5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aceb4501-268d-4c3d-9cf6-28377027d6ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e102c6d4-3334-4276-85fe-3489a59bc907
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4772ccde-79ba-4925-89bc-1a35a22fd0e8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a0cfdf8e-5854-4612-aaa7-c5cf73ec5907
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2c3d9c91-1a18-4a8e-98cc-417743d11e0f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3775e53b-4a72-461d-aab2-4216981adff9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5eee7349-1b6b-4cfe-8212-51d42353a8de
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 51ff85cd-7f1b-410d-9e11-92af12bc16f6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eaa52d1a-bd1f-470a-8bc0-97b7e72d5b32
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c8ac058e-50da-497d-b455-3a06ac594b26
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2f38e05f-873a-4a70-ae44-a4e42ff112bd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6e88534c-f705-4e8a-8d3e-5977634e8f5f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3b8ba630-9951-4940-9422-1f700affc5d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2124f2a9-0997-40bf-af83-0a674f6dde5a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1d9fb27f-2e7a-49a1-95de-2f078333ce0a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b373a734-976c-4e99-800b-8401d3f3539d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6c353568-648a-473e-b27c-f850c817b039
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6702fe43-9020-4563-a166-da5aa19f4ab7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7ab2f0a6-59e1-4a16-aafa-67ab7c8927ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5ec2141f-d9b6-4d49-bc26-eee0951228dd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 30fc6990-0ecb-4c15-9ca1-b5a85859cab4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1e730b45-fc22-4261-bf6f-6d60c1267256
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a879d63c-f4d8-419e-83bc-b9c48b3f03cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dcc9d788-8508-4cd9-b420-50628bc71469
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5942aaba-42ac-4fcc-b0e8-fb3e3a8337cd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a67f5c48-f2f8-405d-b421-3b9225f070a3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f602dec8-517f-48e9-85f8-27d7e996fd06
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 98e05ad9-edd4-416b-8d24-265d0ac75192
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8da958d5-c23b-4688-8556-d24695186045
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5f8cfed9-614f-43b5-865f-dc2bb4150987
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ddb7b590-0bcd-4663-98e5-87effab6843f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aad8cfc2-339e-4830-a740-1703d3467f01
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 77a47dcb-6de2-4557-8457-809976f9d1a0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 226c549d-32f8-413e-8456-4d3418dedc59
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0745ccb1-6988-44c8-ae07-d3dc1abe7592
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f0a1d617-c5a2-4443-aa23-ccd41a47cebb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c57b0be5-e995-422e-8db8-3015c06ba054
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a33f1e9c-5552-4529-87d2-9a9b6a50f997
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1e90a178-c933-473d-9cca-5a68f74985fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4c3fa9df-6449-449b-b6ef-443e42d88f4c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a5b02172-4db0-45ed-b80c-c4c710aa1347
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a59b062c-8589-4e8b-b786-1434f1088c78
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e7b40831-4add-4d04-b55d-16ca590f9104
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d750ea66-4915-468e-9d0c-974c28268198
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 374197a4-9bd5-492d-8f25-bd4bcddb4cb4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ce2ce3cb-d236-48c1-a748-2702883177e6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 139fb41c-fdbe-4d9f-931f-380d55b3aeae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8171dfca-85ac-4abb-a6dd-1f72eb522ef6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 88386d80-99b6-4dca-b776-25f9514e811e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 245604cf-df7a-454e-8249-167eff2b86f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fcbfa88b-9a38-48e9-bc5e-83e919f12eef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0f86423b-7763-4881-b1fd-1f61bf1931e0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 992b2917-1219-4c7c-9308-e91fceab89e1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d7e9c137-e5bd-4745-8fb8-56710a39e429
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 44c7b721-78a8-4e98-bc9a-319fba26faf0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1a7e4fdf-aeed-4953-89fa-9fe8dc8c1dce
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "recvmsg:Connection reset by peer"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8687 {grpc_message:"recvmsg:Connection reset by peer", grpc_status:14}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_65
Server: localhost:8687
Algorithm: FEDAVG
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_65
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_65/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_65/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_65/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_65/test_labels.txt

📊 Raw data loaded:
   Train: X=(1919, 24), y=(1919,)
   Test:  X=(480, 24), y=(480,)

⚠️  Limiting training data: 1919 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  471 samples, 5 features
✅ Client client_65 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

============================================================
🔄 Round 6 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0852 (↓), lr=0.001000
   • Epoch   2/100: train=0.0848, val=0.0863, patience=1/15, lr=0.001000
   • Epoch   3/100: train=0.0835, val=0.0873, patience=2/15, lr=0.001000
   • Epoch   4/100: train=0.0819, val=0.0861, patience=3/15, lr=0.001000
   • Epoch   5/100: train=0.0816, val=0.0860, patience=4/15, lr=0.001000
   📉 Epoch 7: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0788, val=0.0861, patience=10/15, lr=0.000500
   📉 Epoch 15: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 6 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0843, RMSE=0.2904, R²=-0.0145
   Val:   Loss=0.0852, RMSE=0.2919, R²=0.0164
============================================================


📊 Round 6 Test Metrics:
   Loss: 0.0805, RMSE: 0.2838, MAE: 0.2440, R²: -0.0128

📊 Round 6 Test Metrics:
   Loss: 0.0800, RMSE: 0.2828, MAE: 0.2429, R²: -0.0058

📊 Round 6 Test Metrics:
   Loss: 0.0799, RMSE: 0.2826, MAE: 0.2428, R²: -0.0043

📊 Round 6 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2429, R²: -0.0049

📊 Round 6 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2427, R²: -0.0033

============================================================
🔄 Round 16 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0819 (↓), lr=0.000250
   • Epoch   2/100: train=0.0833, val=0.0823, patience=1/15, lr=0.000250
   • Epoch   3/100: train=0.0827, val=0.0830, patience=2/15, lr=0.000250
   • Epoch   4/100: train=0.0824, val=0.0833, patience=3/15, lr=0.000250
   • Epoch   5/100: train=0.0820, val=0.0837, patience=4/15, lr=0.000250
   📉 Epoch 7: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0808, val=0.0842, patience=10/15, lr=0.000125
   📉 Epoch 15: LR reduced 0.000125 → 0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 16 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000250 → 0.000063 (2 reductions)
   Train: Loss=0.0827, RMSE=0.2875, R²=0.0096
   Val:   Loss=0.0819, RMSE=0.2861, R²=0.0440
============================================================


📊 Round 16 Test Metrics:
   Loss: 0.0799, RMSE: 0.2826, MAE: 0.2428, R²: -0.0044

📊 Round 16 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2428, R²: -0.0047

============================================================
🔄 Round 19 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0780 (↓), lr=0.000063
   • Epoch   2/100: train=0.0841, val=0.0776, patience=1/15, lr=0.000063
   • Epoch   3/100: train=0.0840, val=0.0775, patience=2/15, lr=0.000063
   • Epoch   4/100: train=0.0839, val=0.0775, patience=3/15, lr=0.000063
   • Epoch   5/100: train=0.0838, val=0.0775, patience=4/15, lr=0.000063
   📉 Epoch 9: LR reduced 0.000063 → 0.000031
   • Epoch  11/100: train=0.0834, val=0.0775, patience=10/15, lr=0.000031

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 19 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000063 → 0.000031 (1 reductions)
   Train: Loss=0.0842, RMSE=0.2901, R²=0.0137
   Val:   Loss=0.0780, RMSE=0.2793, R²=0.0020
============================================================


📊 Round 19 Test Metrics:
   Loss: 0.0799, RMSE: 0.2827, MAE: 0.2429, R²: -0.0050

============================================================
🔄 Round 21 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000031
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   📉 Epoch 1: LR reduced 0.000031 → 0.000016
   ✓ Epoch   1/100: train=0.0847, val=0.0779 (↓), lr=0.000016
   • Epoch   2/100: train=0.0844, val=0.0776, patience=1/15, lr=0.000016
   ✓ Epoch   3/100: train=0.0843, val=0.0774 (↓), lr=0.000016
   • Epoch   4/100: train=0.0843, val=0.0772, patience=1/15, lr=0.000016
   • Epoch   5/100: train=0.0842, val=0.0771, patience=2/15, lr=0.000016
   • Epoch  11/100: train=0.0840, val=0.0770, patience=8/15, lr=0.000016
   📉 Epoch 15: LR reduced 0.000016 → 0.000008

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0774)

============================================================
📊 Round 21 Summary - Client client_65
   Epochs: 18/100 (early stopped)
   LR: 0.000031 → 0.000008 (2 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=0.0151
   Val:   Loss=0.0774, RMSE=0.2781, R²=-0.0013
============================================================


============================================================
🔄 Round 22 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000008
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0804 (↓), lr=0.000008
   • Epoch   2/100: train=0.0840, val=0.0803, patience=1/15, lr=0.000008
   • Epoch   3/100: train=0.0838, val=0.0802, patience=2/15, lr=0.000008
   • Epoch   4/100: train=0.0836, val=0.0802, patience=3/15, lr=0.000008
   📉 Epoch 5: LR reduced 0.000008 → 0.000004
   • Epoch   5/100: train=0.0835, val=0.0802, patience=4/15, lr=0.000004
   • Epoch  11/100: train=0.0833, val=0.0802, patience=10/15, lr=0.000004
   📉 Epoch 13: LR reduced 0.000004 → 0.000002

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 22 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000008 → 0.000002 (2 reductions)
   Train: Loss=0.0842, RMSE=0.2901, R²=0.0071
   Val:   Loss=0.0804, RMSE=0.2835, R²=0.0028
============================================================


📊 Round 22 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2432, R²: -0.0083

📊 Round 22 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2433, R²: -0.0085

📊 Round 22 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2432, R²: -0.0084

📊 Round 22 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2433, R²: -0.0085

📊 Round 22 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2432, R²: -0.0085

============================================================
🔄 Round 37 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000002
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0810 (↓), lr=0.000002
   • Epoch   2/100: train=0.0841, val=0.0810, patience=1/15, lr=0.000002
   • Epoch   3/100: train=0.0840, val=0.0809, patience=2/15, lr=0.000002
   • Epoch   4/100: train=0.0840, val=0.0809, patience=3/15, lr=0.000002
   📉 Epoch 5: LR reduced 0.000002 → 0.000001
   • Epoch   5/100: train=0.0840, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 37 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000002 → 0.000001 (1 reductions)
   Train: Loss=0.0842, RMSE=0.2901, R²=0.0029
   Val:   Loss=0.0810, RMSE=0.2846, R²=0.0151
============================================================


📊 Round 37 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2433, R²: -0.0085

============================================================
🔄 Round 44 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0872 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0872, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0871, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0871, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0871, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0869, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0872)

============================================================
📊 Round 44 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2875, R²=0.0114
   Val:   Loss=0.0872, RMSE=0.2953, R²=-0.0243
============================================================


============================================================
🔄 Round 46 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 46 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=-0.0057
   Val:   Loss=0.0797, RMSE=0.2823, R²=0.0410
============================================================


============================================================
🔄 Round 50 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 50 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=0.0084
   Val:   Loss=0.0842, RMSE=0.2902, R²=-0.0188
============================================================


📊 Round 50 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2433, R²: -0.0087

============================================================
🔄 Round 51 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0872 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0872, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0872, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0871, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0871, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0869, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0872)

============================================================
📊 Round 51 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2875, R²=0.0052
   Val:   Loss=0.0872, RMSE=0.2953, R²=-0.0001
============================================================


📊 Round 51 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2433, R²: -0.0087

============================================================
🔄 Round 52 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0896 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0895, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0895, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0895, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0894, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0893, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0896)

============================================================
📊 Round 52 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=0.0088
   Val:   Loss=0.0896, RMSE=0.2993, R²=-0.0098
============================================================


============================================================
🔄 Round 53 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 53 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2904, R²=0.0150
   Val:   Loss=0.0805, RMSE=0.2838, R²=-0.0414
============================================================


📊 Round 53 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2433, R²: -0.0087

============================================================
🔄 Round 55 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 55 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=0.0062
   Val:   Loss=0.0845, RMSE=0.2908, R²=0.0010
============================================================


📊 Round 55 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2433, R²: -0.0087

============================================================
🔄 Round 57 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0828, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 57 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2882, R²=0.0115
   Val:   Loss=0.0855, RMSE=0.2924, R²=-0.0227
============================================================


============================================================
🔄 Round 58 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 58 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2887, R²=0.0076
   Val:   Loss=0.0843, RMSE=0.2904, R²=-0.0108
============================================================


============================================================
🔄 Round 59 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 59 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2908, R²=0.0034
   Val:   Loss=0.0795, RMSE=0.2820, R²=-0.0063
============================================================


📊 Round 59 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2433, R²: -0.0087

============================================================
🔄 Round 63 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0883 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0883, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0882, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0882, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0882, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0880, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0883)

============================================================
📊 Round 63 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=0.0108
   Val:   Loss=0.0883, RMSE=0.2971, R²=-0.0200
============================================================


============================================================
🔄 Round 65 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 65 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=0.0096
   Val:   Loss=0.0836, RMSE=0.2892, R²=-0.0139
============================================================


📊 Round 65 Test Metrics:
   Loss: 0.0802, RMSE: 0.2833, MAE: 0.2433, R²: -0.0089

============================================================
🔄 Round 66 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0732 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0732, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0732, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0732, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0731, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0731, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0732)

============================================================
📊 Round 66 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2935, R²=0.0066
   Val:   Loss=0.0732, RMSE=0.2706, R²=-0.0027
============================================================


📊 Round 66 Test Metrics:
   Loss: 0.0802, RMSE: 0.2833, MAE: 0.2433, R²: -0.0089

============================================================
🔄 Round 68 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 68 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=0.0113
   Val:   Loss=0.0821, RMSE=0.2865, R²=-0.0220
============================================================


============================================================
🔄 Round 69 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 69 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2899, R²=0.0086
   Val:   Loss=0.0816, RMSE=0.2857, R²=-0.0213
============================================================


📊 Round 69 Test Metrics:
   Loss: 0.0802, RMSE: 0.2833, MAE: 0.2433, R²: -0.0090

============================================================
🔄 Round 70 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0930 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0929, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0929, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0929, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0928, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0926, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0930)

============================================================
📊 Round 70 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=0.0165
   Val:   Loss=0.0930, RMSE=0.3049, R²=-0.0565
============================================================


📊 Round 70 Test Metrics:
   Loss: 0.0802, RMSE: 0.2833, MAE: 0.2433, R²: -0.0090

📊 Round 70 Test Metrics:
   Loss: 0.0803, RMSE: 0.2833, MAE: 0.2433, R²: -0.0091

============================================================
🔄 Round 77 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0905 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0905, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0905, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0905, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0904, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0903, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0905)

============================================================
📊 Round 77 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2861, R²=0.0057
   Val:   Loss=0.0905, RMSE=0.3009, R²=0.0006
============================================================


📊 Round 77 Test Metrics:
   Loss: 0.0803, RMSE: 0.2833, MAE: 0.2433, R²: -0.0092

============================================================
🔄 Round 79 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 79 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2880, R²=-0.0109
   Val:   Loss=0.0862, RMSE=0.2936, R²=0.0493
============================================================


📊 Round 79 Test Metrics:
   Loss: 0.0803, RMSE: 0.2833, MAE: 0.2433, R²: -0.0092

============================================================
🔄 Round 82 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 82 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=0.0091
   Val:   Loss=0.0808, RMSE=0.2842, R²=-0.0150
============================================================


📊 Round 82 Test Metrics:
   Loss: 0.0803, RMSE: 0.2833, MAE: 0.2433, R²: -0.0091

============================================================
🔄 Round 84 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 84 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=-0.0091
   Val:   Loss=0.0784, RMSE=0.2799, R²=0.0539
============================================================


============================================================
🔄 Round 86 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0933 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0933, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0933, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0932, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0932, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0931, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0933)

============================================================
📊 Round 86 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=0.0136
   Val:   Loss=0.0933, RMSE=0.3055, R²=-0.0282
============================================================


============================================================
🔄 Round 87 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 87 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=0.0024
   Val:   Loss=0.0853, RMSE=0.2920, R²=0.0103
============================================================


📊 Round 87 Test Metrics:
   Loss: 0.0803, RMSE: 0.2833, MAE: 0.2433, R²: -0.0092

📊 Round 87 Test Metrics:
   Loss: 0.0803, RMSE: 0.2833, MAE: 0.2433, R²: -0.0092

============================================================
🔄 Round 93 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0888 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0888, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0888, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0888, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0887, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0887, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0888)

============================================================
📊 Round 93 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=0.0035
   Val:   Loss=0.0888, RMSE=0.2980, R²=0.0077
============================================================


============================================================
🔄 Round 96 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 96 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=0.0139
   Val:   Loss=0.0788, RMSE=0.2808, R²=-0.0414
============================================================


============================================================
🔄 Round 98 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0772 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0771, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0771, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0771, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0771, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0769, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 98 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2919, R²=0.0048
   Val:   Loss=0.0772, RMSE=0.2778, R²=0.0007
============================================================


📊 Round 98 Test Metrics:
   Loss: 0.0803, RMSE: 0.2833, MAE: 0.2433, R²: -0.0094

📊 Round 98 Test Metrics:
   Loss: 0.0803, RMSE: 0.2833, MAE: 0.2433, R²: -0.0094

============================================================
🔄 Round 102 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0858, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 102 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2882, R²=0.0017
   Val:   Loss=0.0859, RMSE=0.2930, R²=0.0131
============================================================


📊 Round 102 Test Metrics:
   Loss: 0.0803, RMSE: 0.2834, MAE: 0.2433, R²: -0.0095

============================================================
🔄 Round 106 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0881, val=0.0647 (↓), lr=0.000001
   • Epoch   2/100: train=0.0881, val=0.0647, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0880, val=0.0647, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0880, val=0.0647, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0880, val=0.0647, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0878, val=0.0647, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0647)

============================================================
📊 Round 106 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0883, RMSE=0.2972, R²=-0.0053
   Val:   Loss=0.0647, RMSE=0.2544, R²=0.0502
============================================================


📊 Round 106 Test Metrics:
   Loss: 0.0803, RMSE: 0.2834, MAE: 0.2434, R²: -0.0096

============================================================
🔄 Round 107 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0877 (↓), lr=0.000001
   • Epoch   2/100: train=0.0825, val=0.0877, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0877, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0877, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0877, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0876, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0877)

============================================================
📊 Round 107 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=0.0045
   Val:   Loss=0.0877, RMSE=0.2962, R²=0.0004
============================================================


============================================================
🔄 Round 109 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 109 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2891, R²=-0.0095
   Val:   Loss=0.0838, RMSE=0.2894, R²=0.0302
============================================================


============================================================
🔄 Round 110 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 110 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=0.0016
   Val:   Loss=0.0842, RMSE=0.2902, R²=-0.0126
============================================================


📊 Round 110 Test Metrics:
   Loss: 0.0803, RMSE: 0.2834, MAE: 0.2433, R²: -0.0095

============================================================
🔄 Round 111 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 111 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2906, R²=0.0024
   Val:   Loss=0.0802, RMSE=0.2832, R²=0.0062
============================================================


📊 Round 111 Test Metrics:
   Loss: 0.0803, RMSE: 0.2834, MAE: 0.2433, R²: -0.0095

============================================================
🔄 Round 112 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 112 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=-0.0086
   Val:   Loss=0.0790, RMSE=0.2810, R²=0.0433
============================================================


============================================================
🔄 Round 113 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 113 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2894, R²=0.0098
   Val:   Loss=0.0831, RMSE=0.2883, R²=-0.0202
============================================================


📊 Round 113 Test Metrics:
   Loss: 0.0803, RMSE: 0.2834, MAE: 0.2434, R²: -0.0096

============================================================
🔄 Round 114 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 114 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2913, R²=0.0024
   Val:   Loss=0.0788, RMSE=0.2807, R²=0.0118
============================================================


============================================================
🔄 Round 115 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 115 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=0.0058
   Val:   Loss=0.0857, RMSE=0.2928, R²=-0.0026
============================================================


📊 Round 115 Test Metrics:
   Loss: 0.0803, RMSE: 0.2834, MAE: 0.2434, R²: -0.0097

📊 Round 115 Test Metrics:
   Loss: 0.0803, RMSE: 0.2834, MAE: 0.2434, R²: -0.0097

============================================================
🔄 Round 118 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 118 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=0.0090
   Val:   Loss=0.0829, RMSE=0.2880, R²=-0.0511
============================================================


============================================================
🔄 Round 119 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 119 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=0.0045
   Val:   Loss=0.0807, RMSE=0.2840, R²=0.0010
============================================================


📊 Round 119 Test Metrics:
   Loss: 0.0803, RMSE: 0.2834, MAE: 0.2434, R²: -0.0098

============================================================
🔄 Round 123 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0801, patience=10/15, lr=0.000001
   • Epoch  21/100: train=0.0844, val=0.0798, patience=5/15, lr=0.000001
   • Epoch  31/100: train=0.0843, val=0.0796, patience=15/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 123 Summary - Client client_65
   Epochs: 31/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=0.0183
   Val:   Loss=0.0800, RMSE=0.2828, R²=-0.0493
============================================================


📊 Round 123 Test Metrics:
   Loss: 0.0803, RMSE: 0.2834, MAE: 0.2434, R²: -0.0098

📊 Round 123 Test Metrics:
   Loss: 0.0803, RMSE: 0.2834, MAE: 0.2434, R²: -0.0098

📊 Round 123 Test Metrics:
   Loss: 0.0803, RMSE: 0.2834, MAE: 0.2434, R²: -0.0098

============================================================
🔄 Round 128 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 128 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2896, R²=-0.0019
   Val:   Loss=0.0827, RMSE=0.2875, R²=0.0263
============================================================


📊 Round 128 Test Metrics:
   Loss: 0.0803, RMSE: 0.2834, MAE: 0.2434, R²: -0.0098

============================================================
🔄 Round 130 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0759 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0759, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0759, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0759, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0759, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0758, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0759)

============================================================
📊 Round 130 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2925, R²=-0.0077
   Val:   Loss=0.0759, RMSE=0.2756, R²=0.0544
============================================================


📊 Round 130 Test Metrics:
   Loss: 0.0803, RMSE: 0.2834, MAE: 0.2434, R²: -0.0097

============================================================
🔄 Round 132 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 132 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=0.0028
   Val:   Loss=0.0806, RMSE=0.2838, R²=0.0080
============================================================


📊 Round 132 Test Metrics:
   Loss: 0.0803, RMSE: 0.2834, MAE: 0.2434, R²: -0.0098

📊 Round 132 Test Metrics:
   Loss: 0.0803, RMSE: 0.2834, MAE: 0.2434, R²: -0.0098

📊 Round 132 Test Metrics:
   Loss: 0.0803, RMSE: 0.2834, MAE: 0.2434, R²: -0.0097

============================================================
🔄 Round 135 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0868 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0868, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0868, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0868, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0868, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0867, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0868)

============================================================
📊 Round 135 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=0.0017
   Val:   Loss=0.0868, RMSE=0.2946, R²=0.0075
============================================================


📊 Round 135 Test Metrics:
   Loss: 0.0803, RMSE: 0.2834, MAE: 0.2434, R²: -0.0097

📊 Round 135 Test Metrics:
   Loss: 0.0803, RMSE: 0.2834, MAE: 0.2434, R²: -0.0097

📊 Round 135 Test Metrics:
   Loss: 0.0803, RMSE: 0.2834, MAE: 0.2434, R²: -0.0097

============================================================
🔄 Round 140 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 140 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=0.0012
   Val:   Loss=0.0841, RMSE=0.2899, R²=0.0148
============================================================


============================================================
🔄 Round 141 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0897 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0897, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0897, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0897, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0896, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0895, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0897)

============================================================
📊 Round 141 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=-0.0025
   Val:   Loss=0.0897, RMSE=0.2995, R²=0.0273
============================================================


============================================================
🔄 Round 142 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0877 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0877, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0876, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0876, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0876, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0874, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0877)

============================================================
📊 Round 142 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=0.0115
   Val:   Loss=0.0877, RMSE=0.2961, R²=-0.0317
============================================================


============================================================
🔄 Round 144 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 144 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=0.0033
   Val:   Loss=0.0801, RMSE=0.2830, R²=0.0052
============================================================


📊 Round 144 Test Metrics:
   Loss: 0.0803, RMSE: 0.2834, MAE: 0.2434, R²: -0.0098

============================================================
🔄 Round 145 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 145 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=0.0008
   Val:   Loss=0.0835, RMSE=0.2890, R²=0.0058
============================================================


============================================================
🔄 Round 146 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0782, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 146 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2915, R²=0.0032
   Val:   Loss=0.0783, RMSE=0.2798, R²=0.0048
============================================================


============================================================
🔄 Round 147 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0780 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0779, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0779, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0779, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0779, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0777, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 147 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2916, R²=0.0037
   Val:   Loss=0.0780, RMSE=0.2792, R²=-0.0003
============================================================


📊 Round 147 Test Metrics:
   Loss: 0.0803, RMSE: 0.2834, MAE: 0.2434, R²: -0.0099

============================================================
🔄 Round 148 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0885 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0885, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0885, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0884, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0884, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0884, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0885)

============================================================
📊 Round 148 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=0.0040
   Val:   Loss=0.0885, RMSE=0.2974, R²=-0.0043
============================================================


============================================================
🔄 Round 149 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0782, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0779, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 149 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2915, R²=0.0149
   Val:   Loss=0.0782, RMSE=0.2797, R²=-0.0507
============================================================


📊 Round 149 Test Metrics:
   Loss: 0.0803, RMSE: 0.2834, MAE: 0.2434, R²: -0.0099

============================================================
🔄 Round 150 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0869 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0869, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0827, val=0.0869, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0868, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0868, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0826, val=0.0866, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 150 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=0.0125
   Val:   Loss=0.0869, RMSE=0.2948, R²=-0.0396
============================================================


============================================================
🔄 Round 151 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0747 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0747, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0746, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0746, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0746, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0745, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0747)

============================================================
📊 Round 151 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2930, R²=0.0025
   Val:   Loss=0.0747, RMSE=0.2733, R²=0.0101
============================================================


============================================================
🔄 Round 152 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0724 (↓), lr=0.000001
   • Epoch   2/100: train=0.0867, val=0.0724, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0867, val=0.0724, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0723, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0723, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0722, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0724)

============================================================
📊 Round 152 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2940, R²=0.0126
   Val:   Loss=0.0724, RMSE=0.2691, R²=-0.0402
============================================================


📊 Round 152 Test Metrics:
   Loss: 0.0803, RMSE: 0.2834, MAE: 0.2434, R²: -0.0099

============================================================
🔄 Round 155 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0885 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0885, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0885, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0885, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0885, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0883, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0885)

============================================================
📊 Round 155 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=0.0079
   Val:   Loss=0.0885, RMSE=0.2975, R²=-0.0108
============================================================


============================================================
🔄 Round 156 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 156 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0831, RMSE=0.2883, R²=0.0036
   Val:   Loss=0.0858, RMSE=0.2929, R²=0.0050
============================================================


📊 Round 156 Test Metrics:
   Loss: 0.0803, RMSE: 0.2834, MAE: 0.2434, R²: -0.0100

📊 Round 156 Test Metrics:
   Loss: 0.0803, RMSE: 0.2834, MAE: 0.2434, R²: -0.0100

============================================================
🔄 Round 160 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 160 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2887, R²=-0.0038
   Val:   Loss=0.0847, RMSE=0.2910, R²=0.0193
============================================================


📊 Round 160 Test Metrics:
   Loss: 0.0803, RMSE: 0.2834, MAE: 0.2434, R²: -0.0100

============================================================
🔄 Round 161 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 161 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=0.0047
   Val:   Loss=0.0842, RMSE=0.2902, R²=-0.0234
============================================================


📊 Round 161 Test Metrics:
   Loss: 0.0803, RMSE: 0.2834, MAE: 0.2434, R²: -0.0100

============================================================
🔄 Round 162 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 162 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=0.0134
   Val:   Loss=0.0810, RMSE=0.2847, R²=-0.0471
============================================================


📊 Round 162 Test Metrics:
   Loss: 0.0803, RMSE: 0.2834, MAE: 0.2434, R²: -0.0101

============================================================
🔄 Round 165 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0754 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0753, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0753, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0753, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0753, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0752, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0754)

============================================================
📊 Round 165 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2927, R²=-0.0020
   Val:   Loss=0.0754, RMSE=0.2745, R²=0.0281
============================================================


📊 Round 165 Test Metrics:
   Loss: 0.0803, RMSE: 0.2834, MAE: 0.2434, R²: -0.0100

============================================================
🔄 Round 166 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 166 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=0.0103
   Val:   Loss=0.0834, RMSE=0.2887, R²=-0.0254
============================================================


📊 Round 166 Test Metrics:
   Loss: 0.0803, RMSE: 0.2834, MAE: 0.2434, R²: -0.0101

============================================================
🔄 Round 167 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0899 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0899, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0898, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0898, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0898, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0898, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0899)

============================================================
📊 Round 167 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=0.0048
   Val:   Loss=0.0899, RMSE=0.2998, R²=-0.0006
============================================================


============================================================
🔄 Round 168 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 168 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2892, R²=-0.0027
   Val:   Loss=0.0836, RMSE=0.2891, R²=0.0302
============================================================


📊 Round 168 Test Metrics:
   Loss: 0.0803, RMSE: 0.2834, MAE: 0.2434, R²: -0.0100

📊 Round 168 Test Metrics:
   Loss: 0.0803, RMSE: 0.2834, MAE: 0.2434, R²: -0.0101

============================================================
🔄 Round 170 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 170 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2906, R²=0.0071
   Val:   Loss=0.0804, RMSE=0.2835, R²=-0.0144
============================================================


============================================================
🔄 Round 171 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 171 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=0.0134
   Val:   Loss=0.0801, RMSE=0.2831, R²=-0.0396
============================================================


📊 Round 171 Test Metrics:
   Loss: 0.0803, RMSE: 0.2834, MAE: 0.2434, R²: -0.0101

============================================================
🔄 Round 172 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 172 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=-0.0062
   Val:   Loss=0.0855, RMSE=0.2924, R²=0.0416
============================================================


📊 Round 172 Test Metrics:
   Loss: 0.0803, RMSE: 0.2834, MAE: 0.2434, R²: -0.0101

============================================================
🔄 Round 175 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 175 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2899, R²=0.0089
   Val:   Loss=0.0822, RMSE=0.2866, R²=-0.0170
============================================================


📊 Round 175 Test Metrics:
   Loss: 0.0803, RMSE: 0.2835, MAE: 0.2434, R²: -0.0102

============================================================
🔄 Round 177 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 177 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=0.0042
   Val:   Loss=0.0855, RMSE=0.2925, R²=-0.0027
============================================================


📊 Round 177 Test Metrics:
   Loss: 0.0803, RMSE: 0.2835, MAE: 0.2434, R²: -0.0102

📊 Round 177 Test Metrics:
   Loss: 0.0803, RMSE: 0.2835, MAE: 0.2434, R²: -0.0102

============================================================
🔄 Round 183 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0779 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0779, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0779, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0779, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0779, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0778, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0779)

============================================================
📊 Round 183 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2916, R²=-0.0001
   Val:   Loss=0.0779, RMSE=0.2792, R²=0.0211
============================================================


📊 Round 183 Test Metrics:
   Loss: 0.0803, RMSE: 0.2835, MAE: 0.2434, R²: -0.0102

============================================================
🔄 Round 184 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0725 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0724, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0724, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0724, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0723, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0722, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0725)

============================================================
📊 Round 184 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2940, R²=0.0072
   Val:   Loss=0.0725, RMSE=0.2692, R²=-0.0280
============================================================


📊 Round 184 Test Metrics:
   Loss: 0.0803, RMSE: 0.2834, MAE: 0.2434, R²: -0.0102

📊 Round 184 Test Metrics:
   Loss: 0.0803, RMSE: 0.2835, MAE: 0.2434, R²: -0.0102

============================================================
🔄 Round 188 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 188 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2892, R²=0.0081
   Val:   Loss=0.0837, RMSE=0.2893, R²=-0.0144
============================================================


📊 Round 188 Test Metrics:
   Loss: 0.0803, RMSE: 0.2835, MAE: 0.2434, R²: -0.0103

============================================================
🔄 Round 192 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 192 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=0.0089
   Val:   Loss=0.0809, RMSE=0.2844, R²=-0.0157
============================================================


📊 Round 192 Test Metrics:
   Loss: 0.0803, RMSE: 0.2835, MAE: 0.2434, R²: -0.0102

============================================================
🔄 Round 193 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0770 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0770, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0770, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0770, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0770, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0770, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0770)

============================================================
📊 Round 193 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2920, R²=-0.0018
   Val:   Loss=0.0770, RMSE=0.2774, R²=0.0232
============================================================


📊 Round 193 Test Metrics:
   Loss: 0.0803, RMSE: 0.2835, MAE: 0.2434, R²: -0.0102

============================================================
🔄 Round 195 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0882 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0882, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0882, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0881, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0881, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0879, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0882)

============================================================
📊 Round 195 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=0.0120
   Val:   Loss=0.0882, RMSE=0.2970, R²=-0.0281
============================================================


📊 Round 195 Test Metrics:
   Loss: 0.0803, RMSE: 0.2835, MAE: 0.2434, R²: -0.0102

📊 Round 195 Test Metrics:
   Loss: 0.0803, RMSE: 0.2835, MAE: 0.2434, R²: -0.0103

📊 Round 195 Test Metrics:
   Loss: 0.0804, RMSE: 0.2835, MAE: 0.2434, R²: -0.0103

============================================================
🔄 Round 199 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 199 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=0.0046
   Val:   Loss=0.0853, RMSE=0.2921, R²=0.0018
============================================================


📊 Round 199 Test Metrics:
   Loss: 0.0804, RMSE: 0.2835, MAE: 0.2434, R²: -0.0104

============================================================
🔄 Round 202 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 202 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=0.0045
   Val:   Loss=0.0824, RMSE=0.2870, R²=0.0025
============================================================


============================================================
🔄 Round 205 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 205 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2887, R²=0.0018
   Val:   Loss=0.0846, RMSE=0.2909, R²=0.0140
============================================================


============================================================
🔄 Round 207 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0828, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 207 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2884, R²=0.0094
   Val:   Loss=0.0855, RMSE=0.2923, R²=-0.0172
============================================================


📊 Round 207 Test Metrics:
   Loss: 0.0804, RMSE: 0.2835, MAE: 0.2434, R²: -0.0104

📊 Round 207 Test Metrics:
   Loss: 0.0804, RMSE: 0.2835, MAE: 0.2434, R²: -0.0104

📊 Round 207 Test Metrics:
   Loss: 0.0804, RMSE: 0.2835, MAE: 0.2434, R²: -0.0105

📊 Round 207 Test Metrics:
   Loss: 0.0804, RMSE: 0.2835, MAE: 0.2434, R²: -0.0105

============================================================
🔄 Round 211 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0978 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0977, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0977, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0977, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0977, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0976, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0978)

============================================================
📊 Round 211 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=0.0062
   Val:   Loss=0.0978, RMSE=0.3127, R²=-0.0028
============================================================


📊 Round 211 Test Metrics:
   Loss: 0.0804, RMSE: 0.2835, MAE: 0.2434, R²: -0.0105

============================================================
🔄 Round 215 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0892 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0892, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0892, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0892, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0891, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0890, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0892)

============================================================
📊 Round 215 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2868, R²=-0.0001
   Val:   Loss=0.0892, RMSE=0.2987, R²=0.0191
============================================================


📊 Round 215 Test Metrics:
   Loss: 0.0804, RMSE: 0.2835, MAE: 0.2434, R²: -0.0105

============================================================
🔄 Round 216 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0937 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0937, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0936, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0936, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0936, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0934, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0937)

============================================================
📊 Round 216 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=0.0192
   Val:   Loss=0.0937, RMSE=0.3061, R²=-0.0597
============================================================


📊 Round 216 Test Metrics:
   Loss: 0.0804, RMSE: 0.2835, MAE: 0.2434, R²: -0.0105

📊 Round 216 Test Metrics:
   Loss: 0.0804, RMSE: 0.2835, MAE: 0.2434, R²: -0.0105

============================================================
🔄 Round 218 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0939 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0939, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0939, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0939, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0938, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0937, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0939)

============================================================
📊 Round 218 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2847, R²=0.0154
   Val:   Loss=0.0939, RMSE=0.3065, R²=-0.0378
============================================================


============================================================
🔄 Round 219 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 219 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2908, R²=-0.0029
   Val:   Loss=0.0800, RMSE=0.2828, R²=0.0308
============================================================


============================================================
🔄 Round 220 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 220 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2887, R²=-0.0091
   Val:   Loss=0.0848, RMSE=0.2913, R²=0.0442
============================================================


============================================================
🔄 Round 222 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 222 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2913, R²=-0.0051
   Val:   Loss=0.0786, RMSE=0.2804, R²=0.0369
============================================================


============================================================
🔄 Round 223 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0867 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0867, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0867, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0866, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0866, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 223 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=0.0048
   Val:   Loss=0.0867, RMSE=0.2945, R²=-0.0035
============================================================


📊 Round 223 Test Metrics:
   Loss: 0.0804, RMSE: 0.2835, MAE: 0.2435, R²: -0.0107

============================================================
🔄 Round 225 - Client client_65
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 225 Summary - Client client_65
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2887, R²=0.0099
   Val:   Loss=0.0849, RMSE=0.2914, R²=-0.0307
============================================================


❌ Client client_65 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "recvmsg:Connection reset by peer"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8687 {grpc_message:"recvmsg:Connection reset by peer", grpc_status:14}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "recvmsg:Connection reset by peer"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8687 {grpc_message:"recvmsg:Connection reset by peer", grpc_status:14}"
>
