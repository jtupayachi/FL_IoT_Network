[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2c0012d8-69ac-4e06-81a2-5da8ad9aef18
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1fa7b006-ca4e-4f34-a4fb-76bd6f006c5e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a03fff91-b675-4e86-93d0-610ff70ee45c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b9682d6e-0fad-41b5-bc37-addd75854ea9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e7ae6a9c-ce58-4e8a-95b8-41568a53680d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2c8c9779-873b-45ab-8fe7-ef6a784fc7a7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 049a1b91-c4a9-4d60-8922-ecb9f1416d70
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3a07e026-f48b-443e-b857-76a82d291db3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8b7e7331-5f19-4461-a203-e7d0b4113260
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6151f63a-b64a-45dd-a330-ea25b25cf222
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0cdf6490-3851-414c-b096-3afb9571b500
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c938651f-13ab-4d27-9cb0-0547833feda6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d961f45c-4045-457f-ae14-644d43e3afc5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8b5c13a4-7acf-4f14-82c4-1c5bde843452
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2c4c8543-b790-4b04-97f8-941bfa7bfe19
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6f624fd5-593b-4568-a443-2e388b185677
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6e4e59c8-2e2b-4d8a-90f9-b4b279212ab1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9efc48e2-fd50-4ec3-8bf8-15014a67fdea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 35ac5008-fbf2-4508-939e-97113e77d518
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 04054146-09a1-4be3-9931-95f755ecd6c9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 50f6606f-55b5-4ac8-b413-923504cf1414
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b1537d3b-90d3-4624-98a7-fcdfd6e207a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 76e597c0-82c9-423e-9ab2-7c9d4a530230
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e8908848-93bc-4ce4-9024-d576bef713fb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 77cab6e9-0569-4202-b370-bbc2de5cb554
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fdc0a0d9-8f6b-45fd-9852-bf4e729ff98c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9312fc40-2273-453a-9aa3-654230a68cb5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 564dd0d0-4e38-479f-b6e4-0aa0958b0df9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8af90e3e-f8a4-4797-9a8b-cc8f7519c1d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 647da141-153a-4a63-a6ed-6d0ee0667f58
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 44df2bca-97a4-428f-9be6-7387dbdbd92f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6510a510-04e4-4ed8-ab85-d650dd608df9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0e12c64b-1dd7-4750-8ee9-f7992b591773
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7ddebd52-bf44-4348-812a-db4940aad583
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f85ed1ce-981d-4bd1-8031-bedbe3f52786
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eee2c4dd-43af-4408-97c6-5ede3922e37a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 12eb0ff8-eb9f-432d-8e21-3f795c873060
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b39894c4-30a5-4a16-a1b0-5faadda774fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dd01edb6-56d3-49a0-a0df-631cf5fba654
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 435bf4d4-7d42-4fcd-b9dd-7bb24d69dc7f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9bab1fd9-67a0-443c-9c74-c70a4e9a7035
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d33aaed0-4365-4b7d-9bc0-b21cfdaf7d4d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9903a3cf-c76d-4fbf-af4e-ecbc4a073f59
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9b14d29d-6f93-4ac3-b62a-c77ecffd8ff2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 31b4aeb9-7e72-4e16-a7bd-bba2e3743e7a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1432836b-40c4-4af0-ac7f-c7731664fd2a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bfc28ce0-a8f4-41fd-b968-e63cd3fa3801
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d372f395-56a6-4f65-8127-df3bb8b44441
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 02987d72-44d0-413b-8507-65bd0415e1da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 553e7498-c751-494e-9bab-51a9141942dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4c09532f-9e9a-45f8-b70b-28d6b858d066
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4dbd77b8-34c0-4299-b4fc-00bca94411e1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 919a0cba-0f5e-4cdc-af43-7e14e833b812
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b7209fc2-d82e-4c6b-b298-89c49fb01661
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 66c283bd-3942-4e84-980e-648ff4c70099
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ac2a648f-5e9b-4cf8-952a-0d2eed2540d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7afd2a1e-56b9-402b-b122-cb2748df52a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c5c7d966-fc2d-4984-b07e-d6700fc43c14
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6ba5b1c5-e5e2-4fc3-9c71-dda4e6a0bd25
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 44db4ae4-87af-41f1-bb82-c98574b0de80
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4af8bf85-cd5b-456c-877e-6b2bd06b7828
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d2d8db27-5081-4c7f-8614-98b9e8e279fb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d269878e-fdae-4c81-add0-5ec31339efd2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d5915779-133e-476e-9475-74472d82a993
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 05fd5c86-62d1-4481-af33-e9906f984a2d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e3ab6f57-ec68-4493-a50a-ad0f738619a9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 52eae270-9f54-42ef-a17b-42e2e606f334
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ba0a5c0d-266c-4bc4-acdf-40e0987bcf3d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b941a6da-dc54-4776-9f90-f296f99fb16c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 520ee99e-716d-45f3-9aef-5b8e3c0d0557
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 55bf74e1-7ff6-4d98-8e8a-a14e90e1ef56
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9fde1a75-da6a-44ef-9a50-a6f174103232
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c166c789-8dd2-468b-824d-a7aab23ef5fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a10e7eb4-4882-49d9-b9b3-d236237206ce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8b9856f2-41ad-4c9a-8be8-e3de10ef2891
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 84497267-49ee-4701-94bc-8f6b94217f82
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3fc36cdd-9dcf-40cc-bfff-43d6d69b780e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ab000433-bae2-47e8-826d-9aa75f9f069d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d9267834-00fb-47d7-8bf1-f786ac5bc82f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7623f5da-63eb-41fa-817e-699a3bf77759
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e7008d5a-04a9-459c-a83a-69bdc49be90c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b976808e-3a4d-40b0-ab07-6c1f501e1c4c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f7732ec4-a24e-47a6-9084-54be13e86ea0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c0ddccc3-becd-40cd-92ee-1a0da4fcb1e9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5a321368-f2a1-4725-9493-8edc923b2269
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 826ecb02-a3a6-4a64-ab1e-4e6f9252d540
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e8aa3dac-f5e8-4445-afaf-00de8b68791e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2fa8c706-432d-44dd-b0e2-1e0da0fc8e1e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 05ea1aea-6742-409d-b6fc-35d7f8863bd8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0954f648-673a-4629-a4d0-d56d0f848a88
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1863dd2a-05be-414b-be56-f73e0cfd71c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 708d7b48-17af-4a0e-8a16-a46a4a34565d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d8b01dc1-3440-4622-b8fc-af8c1217b071
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 18878dc5-566f-4808-867f-d9e631652b07
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6acc2f89-21c0-4152-b135-55e5a1638302
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0a970f90-f63a-4ecc-8dce-45b9c3748245
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 282cde28-2cf0-4d90-abc3-ffe221a56b7d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4b0ab68f-d7f9-4a59-a4df-84011efa1330
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4350ca53-c420-492b-9ed4-bddecc526465
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9ee655b7-af5c-49bb-8286-7ebf974397e6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 02a2ed1c-fae0-4056-9f22-22408dfb2eef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c4bee96f-8c4a-436a-bdf1-b97d776fb519
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c5f6e7ad-3339-485b-adc2-13902ca228f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 689daf87-e558-474b-9a0b-c07b69918a0b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 943b0a3e-11a6-4721-9e6a-b1f2e6f055cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 60bdeca9-d390-4976-bf49-5e46afb11409
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d2bde222-5ca6-47c5-81b4-69ab55e3f38f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7798dfb5-f523-4f1b-85bb-c8ec73f982ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c2a398a6-df65-4054-b2e0-5ab62854c655
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ab91a90f-4306-4f8e-9c05-db6b7316e6a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e3632585-4d5f-428c-9d14-d1b70332b289
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5fcd21dd-50b1-4329-9bfb-ba9ee338cfef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2fbda6a8-bcc9-49f3-98b7-510c5416ba4e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5c36a7df-408c-4506-a904-815eec9dd9e8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 552ad647-8526-4900-8cf4-348e3ad351ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 313cc7a7-5edd-456f-a5f3-63d1343c3ca4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 980a2494-f223-4b21-8b27-5ac73b7406a8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 98ef6f78-9530-454c-bda9-343e86d4c53a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eff29ded-cc63-42d1-99f7-a7cd6412a07c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1e4661c8-0f0b-4344-948f-5da14af77ec6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5cc6611e-a9f2-4ebd-aed6-28d249ec6cb1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b7c57933-26be-4c72-8f68-bdb67adcd1da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aac345fd-e8d7-4966-96bd-0e6b9136a8c5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a632f159-141e-4e93-a945-87e8a1ff66d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1ed52ec0-5dbe-4fc8-9fd8-ac0096ca38a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2e36cd72-5bea-4f9c-981b-2495b93b56a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message be5927d8-c864-4b38-8ead-5a45fba1a162
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5ebe8aa9-74ac-428d-9909-b12821d5b496
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2f3c3f78-30cb-41cc-99e9-e749a8dfb67a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 25bd8162-1218-46f0-b920-2b12de9f1269
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 47dcc567-6bfb-4677-b21b-21672406ee8f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 61e42470-c509-4c08-878d-357727bdd172
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ab355bc3-015b-43df-82a7-aa7962f12a87
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ccdaa384-921a-44ba-a56a-005c8d523d82
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d66f1637-41d5-494c-bf35-7b7c00243349
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2f29b8b1-e9e5-4e02-9e1d-c5dd6d36c5d9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message da69d2f4-16b1-485c-8844-da73b32c64c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message efced396-5d49-4a7e-ab8e-fef7e67bbcf0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 22ee3ffe-2342-4955-918b-6ab1af20855b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a3ae4845-05d0-4597-8bd6-3e6d00cd0003
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e0d770ea-7f47-4ee4-a8ec-b06eb08c4d34
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2c90c7d2-c190-4c60-8257-fecac7471328
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 045b9729-0432-4503-8457-0242ab7efb72
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e88ca6c8-574e-484e-b9c4-78a2f3fb92ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4626d4c0-a860-4c3a-867d-5746ec05df62
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a8d66678-0e31-4c2e-95d4-53a65bc1f84b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7142ed9a-6b1d-47d3-83b0-f35d1dd4bb58
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f341c42b-c9bb-4877-8ddf-2a07be344603
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ab5e58e5-f029-4f27-92e1-57b7b4215da4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 49c05d0e-04bc-4694-9e7a-315b8ae9dcf0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5d94b8fd-5d53-4e34-b0a7-097ab812f229
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 474b62e9-56fa-498a-a8e4-de54b30c0ed5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5374777a-b2cd-444f-a43c-c817b02783d5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 080db920-8764-4dce-8430-0bcc403341df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3a298d74-aea5-4cf2-9be9-c1cb91acba0f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4de856e8-4356-4261-a1b0-75568f7a00c4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cac38079-fb0c-4737-8a3f-7819046dc727
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b221b0c7-c878-4e16-9dc1-7add90322a90
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 92c58d8c-251a-4ade-bad8-e0ee241d5729
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7a349d63-86c9-429e-bb88-13ee24ee9956
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c340495e-9130-4f28-a203-f8a6c7641c28
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8676988a-74d1-4910-82d5-ce97899f7d46
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6a04d6a2-70b9-4ac4-a95a-fba99fcf114e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cf192359-13f4-4dec-9f5c-ed46c4a99faf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bb27c23e-49b2-440f-bbc0-7200b39d1288
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cb07b231-4815-4e4a-966f-4e7a92abeedf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0987dc06-32b5-4c55-8f8b-5a91ed8a5662
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 39e31ba2-80c5-44a5-99fd-41d2b827717e
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8687 {grpc_message:"Socket closed", grpc_status:14}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_66
Server: localhost:8687
Algorithm: FEDAVG
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_66
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_66/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_66/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_66/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_66/test_labels.txt

📊 Raw data loaded:
   Train: X=(1796, 24), y=(1796,)
   Test:  X=(450, 24), y=(450,)

⚠️  Limiting training data: 1796 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  441 samples, 5 features
✅ Client client_66 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

============================================================
🔄 Round 6 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0928 (↓), lr=0.001000
   • Epoch   2/100: train=0.0806, val=0.0925, patience=1/15, lr=0.001000
   • Epoch   3/100: train=0.0804, val=0.0926, patience=2/15, lr=0.001000
   • Epoch   4/100: train=0.0801, val=0.0928, patience=3/15, lr=0.001000
   • Epoch   5/100: train=0.0799, val=0.0928, patience=4/15, lr=0.001000
   📉 Epoch 8: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0785, val=0.0935, patience=10/15, lr=0.000500
   📉 Epoch 16: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0928)

============================================================
📊 Round 6 Summary - Client client_66
   Epochs: 16/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=-0.0070
   Val:   Loss=0.0928, RMSE=0.3046, R²=-0.0127
============================================================


📊 Round 6 Test Metrics:
   Loss: 0.0879, RMSE: 0.2964, MAE: 0.2552, R²: -0.0379

============================================================
🔄 Round 8 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0870, val=0.0779 (↓), lr=0.000250
   • Epoch   2/100: train=0.0867, val=0.0775, patience=1/15, lr=0.000250
   ✓ Epoch   3/100: train=0.0859, val=0.0773 (↓), lr=0.000250
   • Epoch   4/100: train=0.0854, val=0.0771, patience=1/15, lr=0.000250
   • Epoch   5/100: train=0.0851, val=0.0770, patience=2/15, lr=0.000250
   • Epoch  11/100: train=0.0843, val=0.0768, patience=8/15, lr=0.000250
   📉 Epoch 17: LR reduced 0.000250 → 0.000125

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 8 Summary - Client client_66
   Epochs: 18/100 (early stopped)
   LR: 0.000250 → 0.000125 (1 reductions)
   Train: Loss=0.0851, RMSE=0.2918, R²=-0.0102
   Val:   Loss=0.0773, RMSE=0.2780, R²=-0.0428
============================================================


📊 Round 8 Test Metrics:
   Loss: 0.0884, RMSE: 0.2974, MAE: 0.2557, R²: -0.0444

============================================================
🔄 Round 9 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000125
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0939 (↓), lr=0.000125
   • Epoch   2/100: train=0.0825, val=0.0934, patience=1/15, lr=0.000125
   ✓ Epoch   3/100: train=0.0821, val=0.0931 (↓), lr=0.000125
   • Epoch   4/100: train=0.0818, val=0.0928, patience=1/15, lr=0.000125
   • Epoch   5/100: train=0.0815, val=0.0926, patience=2/15, lr=0.000125
   📉 Epoch 7: LR reduced 0.000125 → 0.000063
   • Epoch  11/100: train=0.0808, val=0.0927, patience=8/15, lr=0.000063
   📉 Epoch 15: LR reduced 0.000063 → 0.000031

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0931)

============================================================
📊 Round 9 Summary - Client client_66
   Epochs: 18/100 (early stopped)
   LR: 0.000125 → 0.000031 (2 reductions)
   Train: Loss=0.0818, RMSE=0.2861, R²=-0.0152
   Val:   Loss=0.0931, RMSE=0.3051, R²=-0.0498
============================================================


📊 Round 9 Test Metrics:
   Loss: 0.0888, RMSE: 0.2980, MAE: 0.2564, R²: -0.0491

============================================================
🔄 Round 10 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000031
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0870, val=0.0800 (↓), lr=0.000031
   • Epoch   2/100: train=0.0866, val=0.0804, patience=1/15, lr=0.000031
   • Epoch   3/100: train=0.0864, val=0.0806, patience=2/15, lr=0.000031
   • Epoch   4/100: train=0.0862, val=0.0807, patience=3/15, lr=0.000031
   📉 Epoch 5: LR reduced 0.000031 → 0.000016
   • Epoch   5/100: train=0.0861, val=0.0806, patience=4/15, lr=0.000016
   • Epoch  11/100: train=0.0857, val=0.0804, patience=10/15, lr=0.000016
   📉 Epoch 13: LR reduced 0.000016 → 0.000008

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 10 Summary - Client client_66
   Epochs: 16/100 (early stopped)
   LR: 0.000031 → 0.000008 (2 reductions)
   Train: Loss=0.0867, RMSE=0.2945, R²=-0.0384
   Val:   Loss=0.0800, RMSE=0.2828, R²=-0.0636
============================================================


📊 Round 10 Test Metrics:
   Loss: 0.0890, RMSE: 0.2983, MAE: 0.2566, R²: -0.0508

============================================================
🔄 Round 12 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000008
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0828 (↓), lr=0.000008
   • Epoch   2/100: train=0.0864, val=0.0829, patience=1/15, lr=0.000008
   • Epoch   3/100: train=0.0863, val=0.0829, patience=2/15, lr=0.000008
   • Epoch   4/100: train=0.0862, val=0.0829, patience=3/15, lr=0.000008
   📉 Epoch 5: LR reduced 0.000008 → 0.000004
   • Epoch   5/100: train=0.0861, val=0.0830, patience=4/15, lr=0.000004
   • Epoch  11/100: train=0.0859, val=0.0830, patience=10/15, lr=0.000004
   📉 Epoch 13: LR reduced 0.000004 → 0.000002

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 12 Summary - Client client_66
   Epochs: 16/100 (early stopped)
   LR: 0.000008 → 0.000002 (2 reductions)
   Train: Loss=0.0862, RMSE=0.2936, R²=-0.0360
   Val:   Loss=0.0828, RMSE=0.2878, R²=-0.0679
============================================================


📊 Round 12 Test Metrics:
   Loss: 0.0888, RMSE: 0.2979, MAE: 0.2564, R²: -0.0485

============================================================
🔄 Round 13 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000002
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0888 (↓), lr=0.000002
   • Epoch   2/100: train=0.0848, val=0.0888, patience=1/15, lr=0.000002
   • Epoch   3/100: train=0.0847, val=0.0888, patience=2/15, lr=0.000002
   • Epoch   4/100: train=0.0847, val=0.0888, patience=3/15, lr=0.000002
   📉 Epoch 5: LR reduced 0.000002 → 0.000001
   • Epoch   5/100: train=0.0847, val=0.0888, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0888, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0888)

============================================================
📊 Round 13 Summary - Client client_66
   Epochs: 16/100 (early stopped)
   LR: 0.000002 → 0.000001 (1 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=-0.0451
   Val:   Loss=0.0888, RMSE=0.2980, R²=-0.0275
============================================================


============================================================
🔄 Round 15 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0954 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0954, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0954, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0954, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0954, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0953, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0954)

============================================================
📊 Round 15 Summary - Client client_66
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2896, R²=-0.0432
   Val:   Loss=0.0954, RMSE=0.3089, R²=-0.0720
============================================================


📊 Round 15 Test Metrics:
   Loss: 0.0897, RMSE: 0.2994, MAE: 0.2574, R²: -0.0589

📊 Round 15 Test Metrics:
   Loss: 0.0898, RMSE: 0.2996, MAE: 0.2576, R²: -0.0604

📊 Round 15 Test Metrics:
   Loss: 0.0898, RMSE: 0.2997, MAE: 0.2576, R²: -0.0606

============================================================
🔄 Round 20 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0901 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0900, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0900, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0900, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0900, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0900, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0901)

============================================================
📊 Round 20 Summary - Client client_66
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2924, R²=-0.0428
   Val:   Loss=0.0901, RMSE=0.3001, R²=-0.0926
============================================================


============================================================
🔄 Round 21 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0873, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0873, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0872, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0872, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0872, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0872, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 21 Summary - Client client_66
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0873, RMSE=0.2955, R²=-0.0522
   Val:   Loss=0.0841, RMSE=0.2899, R²=-0.0637
============================================================


============================================================
🔄 Round 23 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0876 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0876, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0876, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0876, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0876, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0875, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0876)

============================================================
📊 Round 23 Summary - Client client_66
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2941, R²=-0.0448
   Val:   Loss=0.0876, RMSE=0.2960, R²=-0.1042
============================================================


============================================================
🔄 Round 24 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0885, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0884, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0884, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0884, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0884, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0883, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 24 Summary - Client client_66
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0886, RMSE=0.2976, R²=-0.0628
   Val:   Loss=0.0793, RMSE=0.2817, R²=-0.0196
============================================================


============================================================
🔄 Round 25 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0937 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0937, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0937, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0937, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0937, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0936, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0937)

============================================================
📊 Round 25 Summary - Client client_66
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2915, R²=-0.0384
   Val:   Loss=0.0937, RMSE=0.3062, R²=-0.1276
============================================================


============================================================
🔄 Round 29 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0875, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0875, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0875, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0875, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0875, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0874, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 29 Summary - Client client_66
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0874, RMSE=0.2956, R²=-0.0545
   Val:   Loss=0.0840, RMSE=0.2899, R²=-0.0548
============================================================


📊 Round 29 Test Metrics:
   Loss: 0.0902, RMSE: 0.3004, MAE: 0.2582, R²: -0.0657

============================================================
🔄 Round 31 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0909 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0909, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0909, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0909, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0909, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0909, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0909)

============================================================
📊 Round 31 Summary - Client client_66
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2927, R²=-0.0419
   Val:   Loss=0.0909, RMSE=0.3015, R²=-0.1074
============================================================


============================================================
🔄 Round 32 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0888 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0888, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0888, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0888, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0888, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0887, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0888)

============================================================
📊 Round 32 Summary - Client client_66
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2936, R²=-0.0600
   Val:   Loss=0.0888, RMSE=0.2980, R²=-0.0360
============================================================


📊 Round 32 Test Metrics:
   Loss: 0.0902, RMSE: 0.3004, MAE: 0.2582, R²: -0.0658

📊 Round 32 Test Metrics:
   Loss: 0.0902, RMSE: 0.3004, MAE: 0.2582, R²: -0.0658

============================================================
🔄 Round 39 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0895 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0895, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0895, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0895, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0895, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0895, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0895)

============================================================
📊 Round 39 Summary - Client client_66
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2933, R²=-0.0580
   Val:   Loss=0.0895, RMSE=0.2992, R²=-0.0468
============================================================


============================================================
🔄 Round 40 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.1066 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.1066, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.1066, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.1066, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.1066, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.1065, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.1066)

============================================================
📊 Round 40 Summary - Client client_66
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2859, R²=-0.0416
   Val:   Loss=0.1066, RMSE=0.3265, R²=-0.0998
============================================================


📊 Round 40 Test Metrics:
   Loss: 0.0902, RMSE: 0.3004, MAE: 0.2582, R²: -0.0658

📊 Round 40 Test Metrics:
   Loss: 0.0902, RMSE: 0.3004, MAE: 0.2582, R²: -0.0658

============================================================
🔄 Round 42 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0885, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0885, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0885, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0885, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0885, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0884, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 42 Summary - Client client_66
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0885, RMSE=0.2975, R²=-0.0644
   Val:   Loss=0.0796, RMSE=0.2821, R²=-0.0280
============================================================


📊 Round 42 Test Metrics:
   Loss: 0.0902, RMSE: 0.3004, MAE: 0.2582, R²: -0.0658

============================================================
🔄 Round 43 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0867, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0867, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0867, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0867, val=0.0864, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0867, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 43 Summary - Client client_66
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2946, R²=-0.0445
   Val:   Loss=0.0864, RMSE=0.2940, R²=-0.0991
============================================================


📊 Round 43 Test Metrics:
   Loss: 0.0902, RMSE: 0.3004, MAE: 0.2582, R²: -0.0658

============================================================
🔄 Round 46 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0873, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0873, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0872, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0872, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0872, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0872, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 46 Summary - Client client_66
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0872, RMSE=0.2954, R²=-0.0568
   Val:   Loss=0.0847, RMSE=0.2910, R²=-0.0491
============================================================


============================================================
🔄 Round 47 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0986 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0986, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0986, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0986, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0986, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0985, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0986)

============================================================
📊 Round 47 Summary - Client client_66
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2894, R²=-0.0539
   Val:   Loss=0.0986, RMSE=0.3140, R²=-0.0579
============================================================


============================================================
🔄 Round 48 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0892, val=0.0760 (↓), lr=0.000001
   • Epoch   2/100: train=0.0892, val=0.0759, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0892, val=0.0759, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0892, val=0.0759, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0892, val=0.0759, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0891, val=0.0759, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0760)

============================================================
📊 Round 48 Summary - Client client_66
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0894, RMSE=0.2990, R²=-0.0571
   Val:   Loss=0.0760, RMSE=0.2756, R²=-0.0562
============================================================


📊 Round 48 Test Metrics:
   Loss: 0.0902, RMSE: 0.3004, MAE: 0.2582, R²: -0.0659

============================================================
🔄 Round 51 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0868 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0868, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0868, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0868, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0868, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0867, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0868)

============================================================
📊 Round 51 Summary - Client client_66
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0867, RMSE=0.2945, R²=-0.0579
   Val:   Loss=0.0868, RMSE=0.2946, R²=-0.0474
============================================================


============================================================
🔄 Round 52 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0884, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0883, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0883, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0883, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0883, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0882, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 52 Summary - Client client_66
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0882, RMSE=0.2970, R²=-0.0522
   Val:   Loss=0.0808, RMSE=0.2842, R²=-0.0728
============================================================


📊 Round 52 Test Metrics:
   Loss: 0.0902, RMSE: 0.3004, MAE: 0.2582, R²: -0.0658

📊 Round 52 Test Metrics:
   Loss: 0.0902, RMSE: 0.3004, MAE: 0.2582, R²: -0.0659

============================================================
🔄 Round 58 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0873, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0873, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0873, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0873, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0873, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0872, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 58 Summary - Client client_66
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0870, RMSE=0.2950, R²=-0.0534
   Val:   Loss=0.0855, RMSE=0.2924, R²=-0.0600
============================================================


📊 Round 58 Test Metrics:
   Loss: 0.0902, RMSE: 0.3004, MAE: 0.2582, R²: -0.0659

============================================================
🔄 Round 61 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.0871 (↓), lr=0.000001
   • Epoch   2/100: train=0.0868, val=0.0871, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0868, val=0.0871, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0868, val=0.0871, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0868, val=0.0871, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0867, val=0.0871, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0871)

============================================================
📊 Round 61 Summary - Client client_66
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2943, R²=-0.0517
   Val:   Loss=0.0871, RMSE=0.2952, R²=-0.0677
============================================================


============================================================
🔄 Round 63 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0871, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0871, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0871, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0871, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0871, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0870, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 63 Summary - Client client_66
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0871, RMSE=0.2951, R²=-0.0556
   Val:   Loss=0.0854, RMSE=0.2923, R²=-0.0569
============================================================


📊 Round 63 Test Metrics:
   Loss: 0.0902, RMSE: 0.3004, MAE: 0.2582, R²: -0.0659

============================================================
🔄 Round 67 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0888 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0888, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0888, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0888, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0888, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0887, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0888)

============================================================
📊 Round 67 Summary - Client client_66
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2936, R²=-0.0437
   Val:   Loss=0.0888, RMSE=0.2980, R²=-0.0996
============================================================


📊 Round 67 Test Metrics:
   Loss: 0.0903, RMSE: 0.3004, MAE: 0.2582, R²: -0.0660

============================================================
🔄 Round 69 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0875 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0875, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0875, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0875, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0875, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0866, val=0.0875, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0875)

============================================================
📊 Round 69 Summary - Client client_66
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2942, R²=-0.0509
   Val:   Loss=0.0875, RMSE=0.2959, R²=-0.0689
============================================================


============================================================
🔄 Round 70 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0891 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0891, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0891, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0891, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0891, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0891, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0891)

============================================================
📊 Round 70 Summary - Client client_66
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2935, R²=-0.0582
   Val:   Loss=0.0891, RMSE=0.2985, R²=-0.0411
============================================================


============================================================
🔄 Round 71 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0886 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0886, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0886, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0886, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0886, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0886, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0886)

============================================================
📊 Round 71 Summary - Client client_66
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2937, R²=-0.0630
   Val:   Loss=0.0886, RMSE=0.2977, R²=-0.0225
============================================================


📊 Round 71 Test Metrics:
   Loss: 0.0903, RMSE: 0.3004, MAE: 0.2582, R²: -0.0660

============================================================
🔄 Round 73 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0876, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0876, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0876, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0876, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0876, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0875, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 73 Summary - Client client_66
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0873, RMSE=0.2955, R²=-0.0606
   Val:   Loss=0.0843, RMSE=0.2904, R²=-0.0305
============================================================


📊 Round 73 Test Metrics:
   Loss: 0.0903, RMSE: 0.3004, MAE: 0.2582, R²: -0.0660

📊 Round 73 Test Metrics:
   Loss: 0.0903, RMSE: 0.3004, MAE: 0.2582, R²: -0.0660

📊 Round 73 Test Metrics:
   Loss: 0.0903, RMSE: 0.3004, MAE: 0.2582, R²: -0.0661

============================================================
🔄 Round 81 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0884, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0884, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0884, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0883, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0883, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0883, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 81 Summary - Client client_66
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0881, RMSE=0.2968, R²=-0.0538
   Val:   Loss=0.0813, RMSE=0.2852, R²=-0.0573
============================================================


📊 Round 81 Test Metrics:
   Loss: 0.0903, RMSE: 0.3004, MAE: 0.2582, R²: -0.0661

============================================================
🔄 Round 85 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0935 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0935, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0935, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0935, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0934, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0934, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0935)

============================================================
📊 Round 85 Summary - Client client_66
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2916, R²=-0.0486
   Val:   Loss=0.0935, RMSE=0.3057, R²=-0.0792
============================================================


📊 Round 85 Test Metrics:
   Loss: 0.0903, RMSE: 0.3004, MAE: 0.2582, R²: -0.0661

============================================================
🔄 Round 86 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0883, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0883, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0882, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0882, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0882, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0882, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 86 Summary - Client client_66
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0882, RMSE=0.2970, R²=-0.0537
   Val:   Loss=0.0809, RMSE=0.2844, R²=-0.0582
============================================================


============================================================
🔄 Round 87 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0924 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0924, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0924, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0924, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0924, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0923, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0924)

============================================================
📊 Round 87 Summary - Client client_66
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2921, R²=-0.0384
   Val:   Loss=0.0924, RMSE=0.3040, R²=-0.1197
============================================================


📊 Round 87 Test Metrics:
   Loss: 0.0903, RMSE: 0.3004, MAE: 0.2582, R²: -0.0661

============================================================
🔄 Round 88 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0903 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0903, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0903, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0903, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0903, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0903, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0903)

============================================================
📊 Round 88 Summary - Client client_66
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2930, R²=-0.0529
   Val:   Loss=0.0903, RMSE=0.3005, R²=-0.0708
============================================================


📊 Round 88 Test Metrics:
   Loss: 0.0903, RMSE: 0.3004, MAE: 0.2582, R²: -0.0661

📊 Round 88 Test Metrics:
   Loss: 0.0903, RMSE: 0.3004, MAE: 0.2582, R²: -0.0661

============================================================
🔄 Round 91 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.1088 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.1088, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.1088, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.1088, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.1088, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.1087, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.1088)

============================================================
📊 Round 91 Summary - Client client_66
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2850, R²=-0.0397
   Val:   Loss=0.1088, RMSE=0.3299, R²=-0.1016
============================================================


============================================================
🔄 Round 93 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0868, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0868, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0868, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0868, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0867, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 93 Summary - Client client_66
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0870, RMSE=0.2950, R²=-0.0410
   Val:   Loss=0.0856, RMSE=0.2925, R²=-0.1245
============================================================


📊 Round 93 Test Metrics:
   Loss: 0.0903, RMSE: 0.3004, MAE: 0.2582, R²: -0.0661

============================================================
🔄 Round 95 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0874, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0874, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0874, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0874, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0874, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0873, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 95 Summary - Client client_66
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0872, RMSE=0.2953, R²=-0.0585
   Val:   Loss=0.0848, RMSE=0.2912, R²=-0.0388
============================================================


============================================================
🔄 Round 96 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0890, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0890, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0890, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0890, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0889, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0889, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 96 Summary - Client client_66
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0888, RMSE=0.2979, R²=-0.0586
   Val:   Loss=0.0786, RMSE=0.2804, R²=-0.0374
============================================================


============================================================
🔄 Round 97 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0889 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0889, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0889, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0889, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0889, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0889, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0889)

============================================================
📊 Round 97 Summary - Client client_66
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2936, R²=-0.0435
   Val:   Loss=0.0889, RMSE=0.2981, R²=-0.1079
============================================================


📊 Round 97 Test Metrics:
   Loss: 0.0903, RMSE: 0.3004, MAE: 0.2582, R²: -0.0661

============================================================
🔄 Round 98 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0882 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0882, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0881, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0881, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0881, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0881, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0882)

============================================================
📊 Round 98 Summary - Client client_66
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2939, R²=-0.0645
   Val:   Loss=0.0882, RMSE=0.2969, R²=-0.0310
============================================================


📊 Round 98 Test Metrics:
   Loss: 0.0903, RMSE: 0.3004, MAE: 0.2582, R²: -0.0662

============================================================
🔄 Round 101 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0890 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0890, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0890, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0890, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0890, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0889, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0890)

============================================================
📊 Round 101 Summary - Client client_66
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2935, R²=-0.0491
   Val:   Loss=0.0890, RMSE=0.2983, R²=-0.0767
============================================================


📊 Round 101 Test Metrics:
   Loss: 0.0903, RMSE: 0.3005, MAE: 0.2582, R²: -0.0662

============================================================
🔄 Round 106 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0884 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0884, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0884, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0884, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0884, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0883, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0884)

============================================================
📊 Round 106 Summary - Client client_66
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2938, R²=-0.0549
   Val:   Loss=0.0884, RMSE=0.2973, R²=-0.0744
============================================================


============================================================
🔄 Round 108 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0881, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0881, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0881, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0881, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0881, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0880, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 108 Summary - Client client_66
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0881, RMSE=0.2968, R²=-0.0650
   Val:   Loss=0.0812, RMSE=0.2849, R²=-0.0126
============================================================


📊 Round 108 Test Metrics:
   Loss: 0.0903, RMSE: 0.3005, MAE: 0.2582, R²: -0.0663

============================================================
🔄 Round 110 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0914 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0914, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0914, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0914, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0914, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0913, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0914)

============================================================
📊 Round 110 Summary - Client client_66
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2925, R²=-0.0529
   Val:   Loss=0.0914, RMSE=0.3023, R²=-0.0684
============================================================


📊 Round 110 Test Metrics:
   Loss: 0.0903, RMSE: 0.3005, MAE: 0.2582, R²: -0.0662

============================================================
🔄 Round 111 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0876, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0876, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0876, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0876, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0876, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0875, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 111 Summary - Client client_66
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0879, RMSE=0.2964, R²=-0.0636
   Val:   Loss=0.0822, RMSE=0.2867, R²=-0.0178
============================================================


📊 Round 111 Test Metrics:
   Loss: 0.0903, RMSE: 0.3005, MAE: 0.2582, R²: -0.0662

============================================================
🔄 Round 112 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0949 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0949, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0948, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0948, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0948, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0948, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0949)

============================================================
📊 Round 112 Summary - Client client_66
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=-0.0525
   Val:   Loss=0.0949, RMSE=0.3080, R²=-0.0622
============================================================


============================================================
🔄 Round 113 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0942 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0942, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0942, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0942, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0941, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0941, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0942)

============================================================
📊 Round 113 Summary - Client client_66
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2913, R²=-0.0568
   Val:   Loss=0.0942, RMSE=0.3069, R²=-0.0524
============================================================


📊 Round 113 Test Metrics:
   Loss: 0.0903, RMSE: 0.3005, MAE: 0.2582, R²: -0.0663

📊 Round 113 Test Metrics:
   Loss: 0.0903, RMSE: 0.3005, MAE: 0.2582, R²: -0.0663

📊 Round 113 Test Metrics:
   Loss: 0.0903, RMSE: 0.3005, MAE: 0.2582, R²: -0.0663

📊 Round 113 Test Metrics:
   Loss: 0.0903, RMSE: 0.3005, MAE: 0.2582, R²: -0.0663

============================================================
🔄 Round 122 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0887, val=0.0777 (↓), lr=0.000001
   • Epoch   2/100: train=0.0886, val=0.0777, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0886, val=0.0777, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0886, val=0.0777, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0886, val=0.0777, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0885, val=0.0777, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 122 Summary - Client client_66
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0890, RMSE=0.2983, R²=-0.0554
   Val:   Loss=0.0777, RMSE=0.2788, R²=-0.0503
============================================================


📊 Round 122 Test Metrics:
   Loss: 0.0903, RMSE: 0.3005, MAE: 0.2582, R²: -0.0663

============================================================
🔄 Round 123 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0926 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0926, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0927, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0927, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0927, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0927, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0926)

============================================================
📊 Round 123 Summary - Client client_66
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2920, R²=-0.0559
   Val:   Loss=0.0926, RMSE=0.3044, R²=-0.0607
============================================================


📊 Round 123 Test Metrics:
   Loss: 0.0903, RMSE: 0.3005, MAE: 0.2582, R²: -0.0663

============================================================
🔄 Round 127 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0870, val=0.0868 (↓), lr=0.000001
   • Epoch   2/100: train=0.0870, val=0.0868, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0869, val=0.0868, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0869, val=0.0868, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0869, val=0.0868, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0869, val=0.0867, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0868)

============================================================
📊 Round 127 Summary - Client client_66
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0867, RMSE=0.2944, R²=-0.0536
   Val:   Loss=0.0868, RMSE=0.2947, R²=-0.0600
============================================================


============================================================
🔄 Round 128 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0889, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0889, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0889, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0888, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0888, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0888, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 128 Summary - Client client_66
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0889, RMSE=0.2981, R²=-0.0497
   Val:   Loss=0.0781, RMSE=0.2795, R²=-0.0768
============================================================


============================================================
🔄 Round 129 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0868, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0867, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0867, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0867, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0867, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 129 Summary - Client client_66
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0870, RMSE=0.2950, R²=-0.0646
   Val:   Loss=0.0856, RMSE=0.2926, R²=-0.0293
============================================================


============================================================
🔄 Round 130 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0881, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0881, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0881, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0881, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0880, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0880, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 130 Summary - Client client_66
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0879, RMSE=0.2966, R²=-0.0577
   Val:   Loss=0.0819, RMSE=0.2861, R²=-0.0519
============================================================


============================================================
🔄 Round 131 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0897 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0897, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0897, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0897, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0897, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0897, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0897)

============================================================
📊 Round 131 Summary - Client client_66
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2932, R²=-0.0567
   Val:   Loss=0.0897, RMSE=0.2995, R²=-0.0511
============================================================


📊 Round 131 Test Metrics:
   Loss: 0.0903, RMSE: 0.3005, MAE: 0.2582, R²: -0.0663

============================================================
🔄 Round 135 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0874, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0874, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0874, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0874, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0874, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0873, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 135 Summary - Client client_66
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0873, RMSE=0.2954, R²=-0.0580
   Val:   Loss=0.0847, RMSE=0.2910, R²=-0.0464
============================================================


📊 Round 135 Test Metrics:
   Loss: 0.0903, RMSE: 0.3005, MAE: 0.2582, R²: -0.0663

📊 Round 135 Test Metrics:
   Loss: 0.0903, RMSE: 0.3005, MAE: 0.2582, R²: -0.0663

============================================================
🔄 Round 138 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0877, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0877, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0877, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0877, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0876, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0876, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 138 Summary - Client client_66
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0875, RMSE=0.2958, R²=-0.0641
   Val:   Loss=0.0836, RMSE=0.2892, R²=-0.0169
============================================================


📊 Round 138 Test Metrics:
   Loss: 0.0903, RMSE: 0.3005, MAE: 0.2582, R²: -0.0663

============================================================
🔄 Round 139 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0900 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0900, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0901, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0901, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0901, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0902, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0900)

============================================================
📊 Round 139 Summary - Client client_66
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2931, R²=-0.0722
   Val:   Loss=0.0900, RMSE=0.3000, R²=-0.0183
============================================================


📊 Round 139 Test Metrics:
   Loss: 0.0903, RMSE: 0.3005, MAE: 0.2582, R²: -0.0663

============================================================
🔄 Round 140 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0872, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0872, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0872, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0872, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0872, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0871, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 140 Summary - Client client_66
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0872, RMSE=0.2953, R²=-0.0564
   Val:   Loss=0.0850, RMSE=0.2915, R²=-0.0475
============================================================


📊 Round 140 Test Metrics:
   Loss: 0.0903, RMSE: 0.3005, MAE: 0.2582, R²: -0.0663

📊 Round 140 Test Metrics:
   Loss: 0.0903, RMSE: 0.3005, MAE: 0.2582, R²: -0.0663

============================================================
🔄 Round 145 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0878 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0878, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0878, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0878, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0878, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0877, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0878)

============================================================
📊 Round 145 Summary - Client client_66
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2940, R²=-0.0545
   Val:   Loss=0.0878, RMSE=0.2963, R²=-0.0556
============================================================


📊 Round 145 Test Metrics:
   Loss: 0.0903, RMSE: 0.3005, MAE: 0.2582, R²: -0.0663

📊 Round 145 Test Metrics:
   Loss: 0.0903, RMSE: 0.3005, MAE: 0.2582, R²: -0.0663

============================================================
🔄 Round 149 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0874, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0874, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0874, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0874, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0874, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0873, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 149 Summary - Client client_66
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0876, RMSE=0.2960, R²=-0.0586
   Val:   Loss=0.0832, RMSE=0.2885, R²=-0.0458
============================================================


📊 Round 149 Test Metrics:
   Loss: 0.0903, RMSE: 0.3005, MAE: 0.2582, R²: -0.0664

============================================================
🔄 Round 151 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.1004 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.1004, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.1004, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.1004, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.1004, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.1003, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.1004)

============================================================
📊 Round 151 Summary - Client client_66
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2887, R²=-0.0620
   Val:   Loss=0.1004, RMSE=0.3168, R²=-0.0308
============================================================


📊 Round 151 Test Metrics:
   Loss: 0.0903, RMSE: 0.3005, MAE: 0.2582, R²: -0.0664

============================================================
🔄 Round 152 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0869, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0869, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0869, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0869, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0868, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0868, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 152 Summary - Client client_66
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0872, RMSE=0.2953, R²=-0.0543
   Val:   Loss=0.0848, RMSE=0.2912, R²=-0.0564
============================================================


📊 Round 152 Test Metrics:
   Loss: 0.0903, RMSE: 0.3005, MAE: 0.2582, R²: -0.0664

============================================================
🔄 Round 153 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0908 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0908, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0908, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0908, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0907, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0907, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0908)

============================================================
📊 Round 153 Summary - Client client_66
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2928, R²=-0.0490
   Val:   Loss=0.0908, RMSE=0.3013, R²=-0.0770
============================================================


📊 Round 153 Test Metrics:
   Loss: 0.0903, RMSE: 0.3005, MAE: 0.2583, R²: -0.0664

============================================================
🔄 Round 156 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0872 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0872, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0872, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0872, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0872, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0871, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0872)

============================================================
📊 Round 156 Summary - Client client_66
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2943, R²=-0.0507
   Val:   Loss=0.0872, RMSE=0.2954, R²=-0.0759
============================================================


📊 Round 156 Test Metrics:
   Loss: 0.0903, RMSE: 0.3005, MAE: 0.2583, R²: -0.0664

============================================================
🔄 Round 165 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0872, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0872, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0872, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0872, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0872, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0871, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 165 Summary - Client client_66
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0872, RMSE=0.2953, R²=-0.0590
   Val:   Loss=0.0849, RMSE=0.2914, R²=-0.0375
============================================================


============================================================
🔄 Round 166 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0878, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0878, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0878, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0878, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0878, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0877, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 166 Summary - Client client_66
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0877, RMSE=0.2962, R²=-0.0551
   Val:   Loss=0.0828, RMSE=0.2878, R²=-0.0524
============================================================


📊 Round 166 Test Metrics:
   Loss: 0.0903, RMSE: 0.3005, MAE: 0.2583, R²: -0.0664

============================================================
🔄 Round 167 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0932 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0932, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0932, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0932, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0932, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0932, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0932)

============================================================
📊 Round 167 Summary - Client client_66
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2917, R²=-0.0641
   Val:   Loss=0.0932, RMSE=0.3053, R²=-0.0216
============================================================


============================================================
🔄 Round 169 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0880, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0880, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0880, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0880, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0880, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0879, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 169 Summary - Client client_66
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0880, RMSE=0.2966, R²=-0.0534
   Val:   Loss=0.0818, RMSE=0.2860, R²=-0.0678
============================================================


📊 Round 169 Test Metrics:
   Loss: 0.0903, RMSE: 0.3005, MAE: 0.2583, R²: -0.0664

============================================================
🔄 Round 172 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0871 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0871, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0871, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0871, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0871, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0871, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0871)

============================================================
📊 Round 172 Summary - Client client_66
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2943, R²=-0.0678
   Val:   Loss=0.0871, RMSE=0.2952, R²=-0.0061
============================================================


============================================================
🔄 Round 173 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0877, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0877, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0877, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0877, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0877, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0877, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 173 Summary - Client client_66
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0877, RMSE=0.2962, R²=-0.0439
   Val:   Loss=0.0827, RMSE=0.2876, R²=-0.1155
============================================================


📊 Round 173 Test Metrics:
   Loss: 0.0903, RMSE: 0.3005, MAE: 0.2583, R²: -0.0664

📊 Round 173 Test Metrics:
   Loss: 0.0903, RMSE: 0.3005, MAE: 0.2583, R²: -0.0665

============================================================
🔄 Round 175 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0873, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0873, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0873, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0873, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0873, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0872, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 175 Summary - Client client_66
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0874, RMSE=0.2956, R²=-0.0565
   Val:   Loss=0.0842, RMSE=0.2901, R²=-0.0490
============================================================


📊 Round 175 Test Metrics:
   Loss: 0.0903, RMSE: 0.3005, MAE: 0.2583, R²: -0.0664

📊 Round 175 Test Metrics:
   Loss: 0.0903, RMSE: 0.3005, MAE: 0.2583, R²: -0.0664

============================================================
🔄 Round 178 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0873, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0873, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0873, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0872, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0872, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0872, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 178 Summary - Client client_66
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0873, RMSE=0.2954, R²=-0.0507
   Val:   Loss=0.0847, RMSE=0.2910, R²=-0.1209
============================================================


============================================================
🔄 Round 180 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0920 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0920, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0920, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0920, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0920, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0920, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0920)

============================================================
📊 Round 180 Summary - Client client_66
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2923, R²=-0.0577
   Val:   Loss=0.0920, RMSE=0.3033, R²=-0.0438
============================================================


============================================================
🔄 Round 181 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0910 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0910, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0910, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0910, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0910, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0909, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0910)

============================================================
📊 Round 181 Summary - Client client_66
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2927, R²=-0.0507
   Val:   Loss=0.0910, RMSE=0.3016, R²=-0.0697
============================================================


📊 Round 181 Test Metrics:
   Loss: 0.0903, RMSE: 0.3005, MAE: 0.2582, R²: -0.0664

============================================================
🔄 Round 185 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0893 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0893, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0893, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0893, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0893, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0893, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0893)

============================================================
📊 Round 185 Summary - Client client_66
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2934, R²=-0.0652
   Val:   Loss=0.0893, RMSE=0.2988, R²=-0.0238
============================================================


📊 Round 185 Test Metrics:
   Loss: 0.0903, RMSE: 0.3005, MAE: 0.2583, R²: -0.0664

============================================================
🔄 Round 187 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0873 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0873, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0873, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0873, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0873, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0873, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0873)

============================================================
📊 Round 187 Summary - Client client_66
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2943, R²=-0.0451
   Val:   Loss=0.0873, RMSE=0.2955, R²=-0.0950
============================================================


============================================================
🔄 Round 189 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0875, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0875, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0875, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0875, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0875, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0874, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 189 Summary - Client client_66
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0878, RMSE=0.2963, R²=-0.0518
   Val:   Loss=0.0826, RMSE=0.2873, R²=-0.0747
============================================================


📊 Round 189 Test Metrics:
   Loss: 0.0903, RMSE: 0.3005, MAE: 0.2582, R²: -0.0664

============================================================
🔄 Round 192 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0884, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0884, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0884, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0884, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0884, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0884, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 192 Summary - Client client_66
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0884, RMSE=0.2974, R²=-0.0565
   Val:   Loss=0.0800, RMSE=0.2828, R²=-0.0499
============================================================


============================================================
🔄 Round 193 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0939 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0939, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0939, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0939, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0939, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0940, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0939)

============================================================
📊 Round 193 Summary - Client client_66
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2915, R²=-0.0595
   Val:   Loss=0.0939, RMSE=0.3064, R²=-0.0546
============================================================


📊 Round 193 Test Metrics:
   Loss: 0.0903, RMSE: 0.3005, MAE: 0.2582, R²: -0.0664

============================================================
🔄 Round 195 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0873, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0873, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0873, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0873, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0873, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0872, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 195 Summary - Client client_66
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0874, RMSE=0.2956, R²=-0.0480
   Val:   Loss=0.0843, RMSE=0.2903, R²=-0.0835
============================================================


📊 Round 195 Test Metrics:
   Loss: 0.0903, RMSE: 0.3005, MAE: 0.2583, R²: -0.0665

📊 Round 195 Test Metrics:
   Loss: 0.0903, RMSE: 0.3005, MAE: 0.2582, R²: -0.0664

============================================================
🔄 Round 201 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0907 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0907, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0907, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0907, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0907, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0906, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0907)

============================================================
📊 Round 201 Summary - Client client_66
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2928, R²=-0.0505
   Val:   Loss=0.0907, RMSE=0.3012, R²=-0.0710
============================================================


============================================================
🔄 Round 202 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0996 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0996, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0996, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0996, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0996, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0995, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0996)

============================================================
📊 Round 202 Summary - Client client_66
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=-0.0489
   Val:   Loss=0.0996, RMSE=0.3156, R²=-0.0753
============================================================


📊 Round 202 Test Metrics:
   Loss: 0.0903, RMSE: 0.3005, MAE: 0.2583, R²: -0.0665

📊 Round 202 Test Metrics:
   Loss: 0.0903, RMSE: 0.3005, MAE: 0.2582, R²: -0.0664

============================================================
🔄 Round 206 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0911 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0911, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0911, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0911, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0911, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0911, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0911)

============================================================
📊 Round 206 Summary - Client client_66
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2927, R²=-0.0576
   Val:   Loss=0.0911, RMSE=0.3019, R²=-0.0446
============================================================


============================================================
🔄 Round 208 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0892 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0892, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0892, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0892, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0892, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0892, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0892)

============================================================
📊 Round 208 Summary - Client client_66
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2935, R²=-0.0619
   Val:   Loss=0.0892, RMSE=0.2986, R²=-0.0305
============================================================


============================================================
🔄 Round 209 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0885, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0885, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0885, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0884, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0884, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0884, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 209 Summary - Client client_66
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0885, RMSE=0.2974, R²=-0.0639
   Val:   Loss=0.0799, RMSE=0.2827, R²=-0.0161
============================================================


============================================================
🔄 Round 215 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0872, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0872, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0872, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0872, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0871, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0871, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 215 Summary - Client client_66
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0869, RMSE=0.2948, R²=-0.0549
   Val:   Loss=0.0862, RMSE=0.2936, R²=-0.0541
============================================================


============================================================
🔄 Round 216 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0887 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0886, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0886, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0886, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0886, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0886, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0887)

============================================================
📊 Round 216 Summary - Client client_66
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2937, R²=-0.0544
   Val:   Loss=0.0887, RMSE=0.2977, R²=-0.0560
============================================================


📊 Round 216 Test Metrics:
   Loss: 0.0903, RMSE: 0.3005, MAE: 0.2583, R²: -0.0665

📊 Round 216 Test Metrics:
   Loss: 0.0903, RMSE: 0.3005, MAE: 0.2583, R²: -0.0665

============================================================
🔄 Round 219 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0948 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0948, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0947, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0947, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0947, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0947, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0948)

============================================================
📊 Round 219 Summary - Client client_66
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2911, R²=-0.0552
   Val:   Loss=0.0948, RMSE=0.3078, R²=-0.0536
============================================================


📊 Round 219 Test Metrics:
   Loss: 0.0903, RMSE: 0.3005, MAE: 0.2583, R²: -0.0665

============================================================
🔄 Round 220 - Client client_66
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0872, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0872, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0872, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0872, val=0.0859, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0872, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0871, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 220 Summary - Client client_66
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0870, RMSE=0.2949, R²=-0.0559
   Val:   Loss=0.0859, RMSE=0.2931, R²=-0.0784
============================================================


📊 Round 220 Test Metrics:
   Loss: 0.0903, RMSE: 0.3005, MAE: 0.2583, R²: -0.0665

📊 Round 220 Test Metrics:
   Loss: 0.0903, RMSE: 0.3005, MAE: 0.2583, R²: -0.0665

❌ Client client_66 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8687 {grpc_message:"Socket closed", grpc_status:14}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8687 {grpc_message:"Socket closed", grpc_status:14}"
>
