[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 10ed5b73-b05f-4749-af7b-9c498036f040
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4aea10eb-74f5-46a4-b763-b525f6bcb712
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 86e8469b-a64e-4b3d-acf6-134c4c0518e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 29ac0bc9-f4d8-4b15-b82b-3d3ff075bdbd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 770f646c-aa37-4574-9ad7-45121302767b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 692e4baa-ea35-4d4a-8de2-ad396ef128ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 68d5ef75-1da3-4a8d-82ef-c96506aaf53b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cac129bf-c53b-40be-a096-fe3e15d869b8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2e9b2f0d-a802-49dd-80f7-ef91ad812362
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aed9925a-e448-4470-ac71-f869a1e50107
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9f423f70-4a7a-4107-9ab9-194f2990d547
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9172aabf-213c-498b-a80b-edd0af065819
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 20dbf562-b9a2-4ccc-af1e-ca867d788b61
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 80f9b6a5-b69f-4161-a1df-07e243521f3a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 293bb1cc-fb73-41e5-9a47-357598911f78
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fa7ada95-555e-4e34-bd5f-b61370ae9f0d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9f4e81e7-0567-4fcf-969c-97b820103db1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 260e18cb-18f6-45e1-9bb5-0983a241dc78
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0ee7f42a-6412-423d-93c6-09e30e3d7d78
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d7d9efd9-a85d-4ace-ab21-d3290452d0e9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3bb1f0c9-8ce4-4130-a6ab-dee80a10bede
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f1836db6-b8b4-4e46-92fe-d918a240ada8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ac58aced-2d12-4583-a4cb-235cc8585e98
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2025c6a4-a772-4c78-8c27-5c4fde9a8b07
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f0e31bb5-8a03-435b-9307-6dd28fe4d8b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 42aa86eb-c526-4dcb-a1b0-de67ecf58477
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6e1ae363-60a3-4879-84bc-898e358bb3a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8692b402-f7f5-45b1-a6c9-3bcde9f0bf5c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message db9b4047-7697-4e10-99a1-299ba6784950
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8f25403f-c626-4463-988e-c032470400eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3123aaa5-218f-4a39-899f-1e9c29892e35
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9dcfc785-f235-40f3-be29-b73551ef7aeb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 735616c1-b7fb-4c50-add7-eb2435f122a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 70d37c32-0637-4412-9e56-5c84b3cb92bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0b4f5f23-3a8b-4979-ac42-c7425292412c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 17b515c8-0843-4861-a6ab-0849165061da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 15fe990a-25cc-48f8-b365-a79b8292effc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7967b334-068c-42f7-ad63-cd19bb9bf80c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 977139a6-af12-44b0-a8f6-dd5364983bc8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 43087b1d-5a6b-4fea-a6c6-445f5ee0c662
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3cae722d-5379-4d09-ba69-6eb5326d23c5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 63b004d3-acde-4691-ad5a-4f91ab0b5e23
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c3b7c265-43ff-4062-8309-e472b07e9a6c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3b4760b5-a7f9-4964-b6be-fbd67b326c0d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2e1074a8-adc9-4248-9eea-7a3d290e5af8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d8b33c77-0c99-4581-8db6-6d6b067c2dc8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dd587be1-7fb3-46f0-9bd5-38701254da80
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 226d884d-cb48-4f84-b0af-bf2def49ae02
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d45b4571-5795-4468-97ca-d1d13a16c84e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a70da4d4-0b68-4716-b4a4-28eb6c911209
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2c4c4362-0397-43ed-9ac4-e72d71717365
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 91556ecc-bda3-40f7-90df-4c32df5d78a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8a14dcb6-59f6-4686-8c16-151a65b37109
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message effdd1a9-753b-4b92-85e1-6eb2a7ee8392
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 05251128-2e1f-49c7-8fc9-1206b7bb6681
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f85a97aa-d9c1-4ccc-8027-f7f88a1352d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c32b98ad-1580-42cd-89da-6ff6454f19a0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4c954a9a-dadf-4d9d-9040-a5ca72903741
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 594d253d-c3ba-4fe5-bf73-c9e00ac7fd04
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 89e1cb7d-994e-48c5-a90a-90ba2bb2bd4d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d3ef6fd4-8c14-402b-b710-0dc4c215373b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5cb9fb2a-a280-4ed4-8a99-c72d8ab4c287
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7adf9ae1-407f-45d0-82ac-0081fdf387fb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aff6e61d-e4fc-49b4-ac01-3eccca467ee3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cf1a8775-597d-40b9-9c1b-193340b6bd96
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 952e04cc-bf39-4310-bb2d-8a4eeea7f86a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 35d77a33-9178-41fa-943e-fc39f90a5527
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 792ce5fa-c668-4d29-9e7e-b8eee84b883b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 850f17ec-c606-449f-9bff-c7e02677f8e2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b1757bb2-0a4d-4b7f-be36-484317ad3aa9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fc0d12e1-0a89-4eae-bb2b-51ae12353e71
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4f1b43ea-7973-4d06-9818-621a09056e4a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 96fdbba6-a982-4eb9-a2d9-3773ea0de4a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d519976d-74d9-45eb-a13d-46ec05761cdd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 436bcccc-ca7f-4fcc-9af3-a4ea3fa0c6dd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1b6fd08e-f9e3-4ccf-8168-981949f69b1e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b224283b-6c56-4042-b03b-cf203caa2d9a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6df8d072-b6be-4659-a911-c510f9c006be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 38c00d9d-0419-4a29-b437-fd297be48435
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 01607caf-003b-444a-a915-82b28cf459d1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0e48f15a-485e-4ed2-9025-25fcb5f3e97b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 03cb4f3e-46f9-4a0c-be92-c34c18bd4892
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0c93bcef-f7ae-4711-a28b-0828ad7849d8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c7a9993a-2139-485e-b043-862f568f80e1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ffaaef60-94e9-4cd8-ab17-5dbeadb93ebc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0282eec0-1d8f-48d0-afcb-da51c99e1e8a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3cbeb42c-fdd2-44a9-a1f4-26ce65812a7f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 45ec9974-2900-45bc-b06e-594652157ab1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ffeccb1b-1ede-44c6-a7da-fa61efb5def6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1ad0941b-9529-46b3-9b86-c9f00bc0b938
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1aa47571-9317-4d51-b523-fe4d9d09a62d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d4af9322-7f1e-4a65-849f-ba88d52a03d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c1ebc76a-9f7a-4605-97a7-a273c8662b58
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 326ace44-c0e3-4231-a2a5-0e0226927bea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d37433ac-2f37-42cc-97c7-30fa32224f5d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 95c7be3b-d474-47b1-a461-777d44801c6f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3c1b5a7c-7b3f-473a-bb25-84f1305d38f2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 760d533c-d062-4e02-919c-6ebce85cfe28
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 19240f4f-0a62-4d99-8e05-e4d4adb9f067
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9b1d1234-7717-48e9-97eb-53892158e111
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0e4367ef-3685-44ec-bd48-275a397421e8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 99180aaa-bff4-418e-9488-59a862306b37
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a187a8af-e0ea-4e2b-a9f8-67acef243e75
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 39fd32bf-8afa-452d-95cc-2b282450eaa8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 909dd5e1-5ce3-49be-90db-1c10c3684afc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ea829c36-6b68-412a-84b2-9da4fed7e19d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c3a41ae4-b8ed-4a5a-96da-08ff4d909c30
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 03d0207d-3d55-4d53-a934-e433c7ac1ad7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1153e46e-9dcf-4dce-9907-dc60ae8d639b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4d7b10ce-0d49-4415-8f6f-c82e8dfa3218
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2c589fa5-3f23-4d2a-b58f-de3cd2d6449d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e3d22159-0a12-4d2e-9822-8037929f2f83
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bf232fa4-8d6e-4652-b585-eb1469f0a125
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 24bd8ed3-2cee-498b-b86b-ffa5b9a39e4e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6104744f-1b1a-4bd7-ab28-229a949eff35
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fd007435-2cce-4ef1-aa8b-73277114437f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9350a1a7-e7ee-4f8d-9021-8606a3a08f75
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 31d7ee42-0682-4481-b560-998865ed888b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 05ef86f1-d1bf-4d9d-aaa8-684b4eb524ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b8e59352-9dfc-4553-bffa-2905d4e59f2e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7ff050d2-92c6-4e4a-973d-d540e9bf6887
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 371e9e1a-cfbd-4ae0-bb0b-777cf94e8484
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 738bc836-c14a-4d20-afbd-8040e08b816c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a2a6cb2d-c331-4005-b279-47250bf8e911
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d4301232-ecac-4e0e-8417-9621c4938ea0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message affc145b-4e05-4441-ab34-2c5a7f2c1099
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5b00cac7-256b-44d9-80bf-146661d37025
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6714f65d-cf7a-48af-b058-8d6b142bffb7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bfcffa94-fd5f-44c0-8578-52b95499d8e9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 41aa3c32-bc5c-43cf-ac49-2794d1f0767c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 88d70e34-f35f-4d7e-8669-d56a93a1bfb3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 537689b1-6d28-48c3-9e83-3333338b6fe3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 33795ce5-b26f-425a-81bf-07ba2eacde0d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 710e109b-492e-4dad-b7fe-af1a9f247c8c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 07968338-65d2-41ff-9430-e0e02d98cf45
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 04d7689a-1874-42d2-88bb-a825241d92b8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 16df616e-49c3-40d6-a959-2ae1c5c20a0a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bb54ab28-6bda-4362-82d0-ec0e9e5605d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cb3e8bdb-582a-4d9c-9a01-3b76d512ea2d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cf8e8209-fc7d-4761-bd8a-c23c03faed5b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b1ff1d8a-eea4-49c8-9f2b-88e4f9002183
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3cfa484e-4757-4f94-90cf-7075a6f5673a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message df0caa83-3593-4e13-ad69-343baf506a50
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a6d952f3-6d03-4135-af10-fc42e3df6f63
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f8521d34-e070-4f93-92b0-77452577603d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2b5c2015-7fa7-4f72-9413-1c8bbc3d5953
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d369529b-d7a6-43aa-916a-5a0793d71683
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ba6daec3-4835-46f3-a250-d21325e5d6c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 617dc233-3003-460d-adad-c7d9caf8374a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 17591164-04e4-4db2-9aa6-0e74d3578cfd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2d60d13b-8412-4b3c-9d9d-f445deb176c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c9de7b1b-fed6-40b9-b099-3a44e2def3e0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cf52264e-df29-4adf-a528-e852671e9230
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 36ed3f80-8d27-4775-8cd2-d61b11e0ba05
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5f7309c6-4780-4fc0-8c1d-6e69973c5c69
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 453e4ea2-d4f2-4ebb-bfbb-7c44742745ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9e283ce1-ed8a-48d5-a81d-6d2ad1bfe53c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 444acc6b-0d89-4307-b71b-93d9a1340f01
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a7494b44-8853-4827-87b3-b1db6d814b1a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 51297af7-5c4f-468b-a69d-c237c009e97b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8ee65b79-3570-441e-9773-dc9d0a33a8c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 87103d3e-d8fa-4539-a4b0-dd8f2c8f125a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a62e85ec-684a-4ddf-898a-c40880d78a05
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8dc29139-da4e-4745-89de-1dd3c7763233
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a1de7b3b-f6c1-4009-9199-c41c4c786b00
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 573931f4-c35e-4285-a8a6-f70507798594
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8151512a-05c9-4fe3-8d0c-785a87c21f2c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 681398ae-727d-46ca-920a-118a8d5d84c5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5a1626b6-9442-4d85-9ec1-8cd41b355f75
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 20094371-da53-4ca5-b96e-01282958693f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 17504131-4c71-4f48-8e62-d4cc8f8f1be4
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8687 {grpc_status:14, grpc_message:"Socket closed"}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_67
Server: localhost:8687
Algorithm: FEDAVG
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_67
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_67/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_67/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_67/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_67/test_labels.txt

📊 Raw data loaded:
   Train: X=(1552, 24), y=(1552,)
   Test:  X=(389, 24), y=(389,)

⚠️  Limiting training data: 1552 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  380 samples, 5 features
✅ Client client_67 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

============================================================
🔄 Round 6 - Client client_67
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0806 (↓), lr=0.001000
   • Epoch   2/100: train=0.0879, val=0.0807, patience=1/15, lr=0.001000
   • Epoch   3/100: train=0.0875, val=0.0817, patience=2/15, lr=0.001000
   • Epoch   4/100: train=0.0849, val=0.0803, patience=3/15, lr=0.001000
   • Epoch   5/100: train=0.0846, val=0.0802, patience=4/15, lr=0.001000
   • Epoch  11/100: train=0.0837, val=0.0801, patience=1/15, lr=0.001000
   • Epoch  21/100: train=0.0812, val=0.0792, patience=6/15, lr=0.001000
   📉 Epoch 24: LR reduced 0.001000 → 0.000500

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 6 Summary - Client client_67
   Epochs: 30/100 (early stopped)
   LR: 0.001000 → 0.000500 (1 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=0.0223
   Val:   Loss=0.0795, RMSE=0.2820, R²=-0.0176
============================================================


============================================================
🔄 Round 7 - Client client_67
   Epochs: 100, Batch: 32, LR: 0.000500
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0834 (↓), lr=0.000500
   📉 Epoch 2: LR reduced 0.000500 → 0.000250
   • Epoch   2/100: train=0.0848, val=0.0835, patience=1/15, lr=0.000250
   • Epoch   3/100: train=0.0831, val=0.0834, patience=2/15, lr=0.000250
   • Epoch   4/100: train=0.0829, val=0.0835, patience=3/15, lr=0.000250
   • Epoch   5/100: train=0.0828, val=0.0835, patience=4/15, lr=0.000250
   📉 Epoch 10: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0820, val=0.0837, patience=10/15, lr=0.000125

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 7 Summary - Client client_67
   Epochs: 16/100 (early stopped)
   LR: 0.000500 → 0.000125 (2 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=-0.0196
   Val:   Loss=0.0834, RMSE=0.2888, R²=-0.0260
============================================================


📊 Round 7 Test Metrics:
   Loss: 0.0804, RMSE: 0.2835, MAE: 0.2450, R²: -0.0310

📊 Round 7 Test Metrics:
   Loss: 0.0802, RMSE: 0.2832, MAE: 0.2448, R²: -0.0287

📊 Round 7 Test Metrics:
   Loss: 0.0804, RMSE: 0.2835, MAE: 0.2449, R²: -0.0310

📊 Round 7 Test Metrics:
   Loss: 0.0804, RMSE: 0.2836, MAE: 0.2450, R²: -0.0318

📊 Round 7 Test Metrics:
   Loss: 0.0803, RMSE: 0.2834, MAE: 0.2448, R²: -0.0307

============================================================
🔄 Round 14 - Client client_67
   Epochs: 100, Batch: 32, LR: 0.000125
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0845 (↓), lr=0.000125
   📉 Epoch 2: LR reduced 0.000125 → 0.000063
   • Epoch   2/100: train=0.0844, val=0.0848, patience=1/15, lr=0.000063
   • Epoch   3/100: train=0.0839, val=0.0850, patience=2/15, lr=0.000063
   • Epoch   4/100: train=0.0837, val=0.0851, patience=3/15, lr=0.000063
   • Epoch   5/100: train=0.0835, val=0.0853, patience=4/15, lr=0.000063
   📉 Epoch 10: LR reduced 0.000063 → 0.000031
   • Epoch  11/100: train=0.0827, val=0.0860, patience=10/15, lr=0.000031

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 14 Summary - Client client_67
   Epochs: 16/100 (early stopped)
   LR: 0.000125 → 0.000031 (2 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=-0.0330
   Val:   Loss=0.0845, RMSE=0.2907, R²=-0.0198
============================================================


📊 Round 14 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2450, R²: -0.0338

📊 Round 14 Test Metrics:
   Loss: 0.0807, RMSE: 0.2840, MAE: 0.2451, R²: -0.0349

============================================================
🔄 Round 19 - Client client_67
   Epochs: 100, Batch: 32, LR: 0.000031
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0947 (↓), lr=0.000031
   📉 Epoch 2: LR reduced 0.000031 → 0.000016
   • Epoch   2/100: train=0.0840, val=0.0943, patience=1/15, lr=0.000016
   ✓ Epoch   3/100: train=0.0838, val=0.0940 (↓), lr=0.000016
   • Epoch   4/100: train=0.0836, val=0.0938, patience=1/15, lr=0.000016
   • Epoch   5/100: train=0.0835, val=0.0936, patience=2/15, lr=0.000016
   📉 Epoch 10: LR reduced 0.000016 → 0.000008
   • Epoch  11/100: train=0.0829, val=0.0927, patience=1/15, lr=0.000008
   📉 Epoch 18: LR reduced 0.000008 → 0.000004
   • Epoch  21/100: train=0.0826, val=0.0925, patience=11/15, lr=0.000004

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0928)

============================================================
📊 Round 19 Summary - Client client_67
   Epochs: 25/100 (early stopped)
   LR: 0.000031 → 0.000004 (3 reductions)
   Train: Loss=0.0826, RMSE=0.2873, R²=-0.0202
   Val:   Loss=0.0928, RMSE=0.3046, R²=-0.0640
============================================================


📊 Round 19 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2453, R²: -0.0369

📊 Round 19 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2453, R²: -0.0371

============================================================
🔄 Round 24 - Client client_67
   Epochs: 100, Batch: 32, LR: 0.000004
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0886, val=0.0776 (↓), lr=0.000004
   • Epoch   2/100: train=0.0885, val=0.0776, patience=1/15, lr=0.000004
   • Epoch   3/100: train=0.0885, val=0.0776, patience=2/15, lr=0.000004
   • Epoch   4/100: train=0.0884, val=0.0775, patience=3/15, lr=0.000004
   • Epoch   5/100: train=0.0883, val=0.0775, patience=4/15, lr=0.000004
   • Epoch  11/100: train=0.0879, val=0.0774, patience=10/15, lr=0.000004

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 24 Summary - Client client_67
   Epochs: 16/100 (early stopped)
   LR: 0.000004 → 0.000004 (0 reductions)
   Train: Loss=0.0887, RMSE=0.2979, R²=-0.0624
   Val:   Loss=0.0776, RMSE=0.2786, R²=-0.0127
============================================================


📊 Round 24 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2453, R²: -0.0371

📊 Round 24 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2453, R²: -0.0371

============================================================
🔄 Round 27 - Client client_67
   Epochs: 100, Batch: 32, LR: 0.000004
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0902 (↓), lr=0.000004
   • Epoch   2/100: train=0.0853, val=0.0902, patience=1/15, lr=0.000004
   • Epoch   3/100: train=0.0852, val=0.0901, patience=2/15, lr=0.000004
   • Epoch   4/100: train=0.0852, val=0.0901, patience=3/15, lr=0.000004
   • Epoch   5/100: train=0.0851, val=0.0901, patience=4/15, lr=0.000004
   📉 Epoch 6: LR reduced 0.000004 → 0.000002
   • Epoch  11/100: train=0.0850, val=0.0899, patience=10/15, lr=0.000002
   📉 Epoch 14: LR reduced 0.000002 → 0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0902)

============================================================
📊 Round 27 Summary - Client client_67
   Epochs: 16/100 (early stopped)
   LR: 0.000004 → 0.000001 (2 reductions)
   Train: Loss=0.0856, RMSE=0.2926, R²=-0.0503
   Val:   Loss=0.0902, RMSE=0.3004, R²=-0.0724
============================================================


📊 Round 27 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2452, R²: -0.0371

============================================================
🔄 Round 29 - Client client_67
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0871, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0871, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0871, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0871, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0871, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0870, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 29 Summary - Client client_67
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0871, RMSE=0.2951, R²=-0.0633
   Val:   Loss=0.0844, RMSE=0.2906, R²=-0.0140
============================================================


📊 Round 29 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2452, R²: -0.0371

📊 Round 29 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2453, R²: -0.0371

============================================================
🔄 Round 32 - Client client_67
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0883 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0883, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0883, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0883, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0883, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0883, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0883)

============================================================
📊 Round 32 Summary - Client client_67
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2935, R²=-0.0556
   Val:   Loss=0.0883, RMSE=0.2971, R²=-0.0529
============================================================


📊 Round 32 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2453, R²: -0.0371

============================================================
🔄 Round 34 - Client client_67
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0928 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0928, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0928, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0928, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0928, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0927, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0928)

============================================================
📊 Round 34 Summary - Client client_67
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2915, R²=-0.0448
   Val:   Loss=0.0928, RMSE=0.3047, R²=-0.0905
============================================================


📊 Round 34 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2453, R²: -0.0371

============================================================
🔄 Round 35 - Client client_67
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0975 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0975, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0975, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0975, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0975, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0974, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0975)

============================================================
📊 Round 35 Summary - Client client_67
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=-0.0485
   Val:   Loss=0.0975, RMSE=0.3123, R²=-0.0726
============================================================


📊 Round 35 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2453, R²: -0.0371

============================================================
🔄 Round 37 - Client client_67
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0891, val=0.0765 (↓), lr=0.000001
   • Epoch   2/100: train=0.0891, val=0.0765, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0891, val=0.0765, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0891, val=0.0765, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0891, val=0.0765, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0890, val=0.0764, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0765)

============================================================
📊 Round 37 Summary - Client client_67
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0891, RMSE=0.2985, R²=-0.0571
   Val:   Loss=0.0765, RMSE=0.2765, R²=-0.0497
============================================================


📊 Round 37 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2453, R²: -0.0371

============================================================
🔄 Round 40 - Client client_67
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0877, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0877, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0876, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0876, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0876, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0875, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 40 Summary - Client client_67
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0874, RMSE=0.2957, R²=-0.0499
   Val:   Loss=0.0831, RMSE=0.2883, R²=-0.0821
============================================================


============================================================
🔄 Round 41 - Client client_67
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0870 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0870, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0870, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0870, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0870, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0869, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 41 Summary - Client client_67
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2940, R²=-0.0538
   Val:   Loss=0.0870, RMSE=0.2950, R²=-0.0573
============================================================


============================================================
🔄 Round 43 - Client client_67
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0914 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0914, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0914, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0914, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0914, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0914, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0914)

============================================================
📊 Round 43 Summary - Client client_67
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2922, R²=-0.0394
   Val:   Loss=0.0914, RMSE=0.3024, R²=-0.1191
============================================================


============================================================
🔄 Round 44 - Client client_67
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0991 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0991, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0991, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0991, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0991, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0991, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0991)

============================================================
📊 Round 44 Summary - Client client_67
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2889, R²=-0.0472
   Val:   Loss=0.0991, RMSE=0.3148, R²=-0.0908
============================================================


📊 Round 44 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2453, R²: -0.0372

📊 Round 44 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2453, R²: -0.0372

============================================================
🔄 Round 47 - Client client_67
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0875, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0875, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0874, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0874, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0874, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0873, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 47 Summary - Client client_67
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0876, RMSE=0.2959, R²=-0.0559
   Val:   Loss=0.0825, RMSE=0.2872, R²=-0.0439
============================================================


📊 Round 47 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2453, R²: -0.0372

📊 Round 47 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2453, R²: -0.0372

============================================================
🔄 Round 51 - Client client_67
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0873, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0873, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0873, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0873, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0873, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0871, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 51 Summary - Client client_67
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0875, RMSE=0.2958, R²=-0.0505
   Val:   Loss=0.0829, RMSE=0.2879, R²=-0.1102
============================================================


📊 Round 51 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2453, R²: -0.0372

📊 Round 51 Test Metrics:
   Loss: 0.0808, RMSE: 0.2843, MAE: 0.2453, R²: -0.0372

============================================================
🔄 Round 54 - Client client_67
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0894 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0894, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0893, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0893, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0893, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0893, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0894)

============================================================
📊 Round 54 Summary - Client client_67
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2930, R²=-0.0504
   Val:   Loss=0.0894, RMSE=0.2989, R²=-0.0675
============================================================


============================================================
🔄 Round 57 - Client client_67
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0923 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0923, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0923, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0923, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0923, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0922, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0923)

============================================================
📊 Round 57 Summary - Client client_67
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2918, R²=-0.0453
   Val:   Loss=0.0923, RMSE=0.3038, R²=-0.0906
============================================================


📊 Round 57 Test Metrics:
   Loss: 0.0809, RMSE: 0.2843, MAE: 0.2453, R²: -0.0373

📊 Round 57 Test Metrics:
   Loss: 0.0809, RMSE: 0.2843, MAE: 0.2453, R²: -0.0373

============================================================
🔄 Round 62 - Client client_67
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0887, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0887, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0887, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0887, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0886, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0886, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 62 Summary - Client client_67
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0884, RMSE=0.2974, R²=-0.0597
   Val:   Loss=0.0791, RMSE=0.2813, R²=-0.0322
============================================================


📊 Round 62 Test Metrics:
   Loss: 0.0809, RMSE: 0.2843, MAE: 0.2453, R²: -0.0373

============================================================
🔄 Round 65 - Client client_67
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0877, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0877, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0877, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0877, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0877, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0876, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 65 Summary - Client client_67
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0877, RMSE=0.2961, R²=-0.0544
   Val:   Loss=0.0821, RMSE=0.2865, R²=-0.0499
============================================================


📊 Round 65 Test Metrics:
   Loss: 0.0809, RMSE: 0.2843, MAE: 0.2453, R²: -0.0373

📊 Round 65 Test Metrics:
   Loss: 0.0809, RMSE: 0.2843, MAE: 0.2453, R²: -0.0373

📊 Round 65 Test Metrics:
   Loss: 0.0809, RMSE: 0.2843, MAE: 0.2453, R²: -0.0373

📊 Round 65 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2453, R²: -0.0373

============================================================
🔄 Round 69 - Client client_67
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0908 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0908, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0908, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0908, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0908, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0907, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0908)

============================================================
📊 Round 69 Summary - Client client_67
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2925, R²=-0.0380
   Val:   Loss=0.0908, RMSE=0.3014, R²=-0.1189
============================================================


============================================================
🔄 Round 70 - Client client_67
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0868, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0868, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0868, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0867, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0867, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 70 Summary - Client client_67
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0867, RMSE=0.2945, R²=-0.0594
   Val:   Loss=0.0861, RMSE=0.2934, R²=-0.0322
============================================================


============================================================
🔄 Round 71 - Client client_67
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0903 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0902, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0902, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0902, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0902, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0902, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0903)

============================================================
📊 Round 71 Summary - Client client_67
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2927, R²=-0.0606
   Val:   Loss=0.0903, RMSE=0.3004, R²=-0.0306
============================================================


📊 Round 71 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2453, R²: -0.0373

============================================================
🔄 Round 72 - Client client_67
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0875, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0875, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0875, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0875, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0874, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0874, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 72 Summary - Client client_67
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0873, RMSE=0.2955, R²=-0.0522
   Val:   Loss=0.0837, RMSE=0.2894, R²=-0.0655
============================================================


📊 Round 72 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2453, R²: -0.0374

============================================================
🔄 Round 74 - Client client_67
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0888, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0888, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0888, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0888, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0888, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0887, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 74 Summary - Client client_67
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0886, RMSE=0.2976, R²=-0.0632
   Val:   Loss=0.0787, RMSE=0.2805, R²=-0.0231
============================================================


============================================================
🔄 Round 76 - Client client_67
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0869 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0869, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0869, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0869, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0869, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0868, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 76 Summary - Client client_67
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2941, R²=-0.0511
   Val:   Loss=0.0869, RMSE=0.2948, R²=-0.0667
============================================================


📊 Round 76 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2453, R²: -0.0374

📊 Round 76 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2453, R²: -0.0374

📊 Round 76 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2453, R²: -0.0374

📊 Round 76 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2453, R²: -0.0374

============================================================
🔄 Round 81 - Client client_67
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0888, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0888, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0887, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0887, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0887, val=0.0773, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0886, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 81 Summary - Client client_67
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0889, RMSE=0.2982, R²=-0.0595
   Val:   Loss=0.0773, RMSE=0.2780, R²=-0.0289
============================================================


📊 Round 81 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2453, R²: -0.0374

============================================================
🔄 Round 85 - Client client_67
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0871, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0871, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0870, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0870, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0870, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0869, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 85 Summary - Client client_67
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0872, RMSE=0.2952, R²=-0.0603
   Val:   Loss=0.0843, RMSE=0.2904, R²=-0.0303
============================================================


============================================================
🔄 Round 86 - Client client_67
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0873, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0873, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0872, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0872, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0872, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0871, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 86 Summary - Client client_67
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0869, RMSE=0.2948, R²=-0.0609
   Val:   Loss=0.0853, RMSE=0.2921, R²=-0.0751
============================================================


📊 Round 86 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2453, R²: -0.0374

============================================================
🔄 Round 89 - Client client_67
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0933 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0932, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0932, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0932, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0932, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0931, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0933)

============================================================
📊 Round 89 Summary - Client client_67
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=-0.0445
   Val:   Loss=0.0933, RMSE=0.3054, R²=-0.0951
============================================================


📊 Round 89 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2453, R²: -0.0374

📊 Round 89 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2453, R²: -0.0375

============================================================
🔄 Round 91 - Client client_67
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0881, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0880, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0880, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0880, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0880, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0878, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 91 Summary - Client client_67
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0879, RMSE=0.2965, R²=-0.0672
   Val:   Loss=0.0815, RMSE=0.2854, R²=-0.0171
============================================================


============================================================
🔄 Round 92 - Client client_67
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0884, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0884, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0884, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0884, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0884, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0883, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 92 Summary - Client client_67
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0883, RMSE=0.2972, R²=-0.0541
   Val:   Loss=0.0797, RMSE=0.2823, R²=-0.0533
============================================================


📊 Round 92 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2453, R²: -0.0375

📊 Round 92 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2453, R²: -0.0375

============================================================
🔄 Round 96 - Client client_67
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0870, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0870, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0870, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0870, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0870, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0869, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 96 Summary - Client client_67
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0872, RMSE=0.2954, R²=-0.0584
   Val:   Loss=0.0840, RMSE=0.2899, R²=-0.0370
============================================================


📊 Round 96 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2453, R²: -0.0375

============================================================
🔄 Round 100 - Client client_67
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 100 Summary - Client client_67
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0867, RMSE=0.2945, R²=-0.0551
   Val:   Loss=0.0861, RMSE=0.2935, R²=-0.0606
============================================================


============================================================
🔄 Round 101 - Client client_67
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0879, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0879, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0879, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0879, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0879, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0878, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 101 Summary - Client client_67
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0876, RMSE=0.2960, R²=-0.0583
   Val:   Loss=0.0825, RMSE=0.2872, R²=-0.0357
============================================================


============================================================
🔄 Round 103 - Client client_67
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0905 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0905, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0905, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0905, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0905, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0905, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0905)

============================================================
📊 Round 103 Summary - Client client_67
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2926, R²=-0.0590
   Val:   Loss=0.0905, RMSE=0.3009, R²=-0.0506
============================================================


📊 Round 103 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2453, R²: -0.0376

📊 Round 103 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2453, R²: -0.0376

📊 Round 103 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2453, R²: -0.0376

============================================================
🔄 Round 106 - Client client_67
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0879, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0879, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0878, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0878, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0878, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0877, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 106 Summary - Client client_67
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0881, RMSE=0.2968, R²=-0.0661
   Val:   Loss=0.0808, RMSE=0.2843, R²=-0.0055
============================================================


📊 Round 106 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2453, R²: -0.0376

============================================================
🔄 Round 110 - Client client_67
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0904, val=0.0713 (↓), lr=0.000001
   • Epoch   2/100: train=0.0904, val=0.0713, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0904, val=0.0713, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0904, val=0.0713, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0903, val=0.0713, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0902, val=0.0712, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0713)

============================================================
📊 Round 110 Summary - Client client_67
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0904, RMSE=0.3007, R²=-0.0612
   Val:   Loss=0.0713, RMSE=0.2670, R²=-0.0236
============================================================


============================================================
🔄 Round 111 - Client client_67
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0876 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0876, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0876, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0876, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0876, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0876, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0876)

============================================================
📊 Round 111 Summary - Client client_67
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2939, R²=-0.0562
   Val:   Loss=0.0876, RMSE=0.2960, R²=-0.0457
============================================================


📊 Round 111 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2453, R²: -0.0377

📊 Round 111 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2453, R²: -0.0377

📊 Round 111 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2453, R²: -0.0377

📊 Round 111 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2453, R²: -0.0377

📊 Round 111 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2453, R²: -0.0377

📊 Round 111 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2453, R²: -0.0377

============================================================
🔄 Round 120 - Client client_67
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0881, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0881, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0880, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0880, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0880, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0879, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 120 Summary - Client client_67
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0882, RMSE=0.2970, R²=-0.0576
   Val:   Loss=0.0804, RMSE=0.2835, R²=-0.0404
============================================================


============================================================
🔄 Round 121 - Client client_67
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0881, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0881, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0881, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0881, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0881, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0880, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 121 Summary - Client client_67
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0881, RMSE=0.2969, R²=-0.0446
   Val:   Loss=0.0806, RMSE=0.2840, R²=-0.1001
============================================================


📊 Round 121 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2453, R²: -0.0378

============================================================
🔄 Round 124 - Client client_67
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0918 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0918, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0918, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0918, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0918, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0919, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0918)

============================================================
📊 Round 124 Summary - Client client_67
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2921, R²=-0.0508
   Val:   Loss=0.0918, RMSE=0.3030, R²=-0.0878
============================================================


📊 Round 124 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2453, R²: -0.0378

============================================================
🔄 Round 125 - Client client_67
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0889, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0889, val=0.0778, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0889, val=0.0778, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0889, val=0.0778, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0889, val=0.0778, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0888, val=0.0778, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 125 Summary - Client client_67
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0888, RMSE=0.2980, R²=-0.0569
   Val:   Loss=0.0778, RMSE=0.2789, R²=-0.0500
============================================================


📊 Round 125 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2453, R²: -0.0378

============================================================
🔄 Round 126 - Client client_67
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0982 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0982, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0982, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0981, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0981, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0981, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0982)

============================================================
📊 Round 126 Summary - Client client_67
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2894, R²=-0.0501
   Val:   Loss=0.0982, RMSE=0.3133, R²=-0.0796
============================================================


============================================================
🔄 Round 128 - Client client_67
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0930 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0930, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0930, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0929, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0929, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0929, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0930)

============================================================
📊 Round 128 Summary - Client client_67
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2916, R²=-0.0569
   Val:   Loss=0.0930, RMSE=0.3049, R²=-0.0446
============================================================


📊 Round 128 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2453, R²: -0.0378

============================================================
🔄 Round 133 - Client client_67
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0876, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0876, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0876, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0876, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0875, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0874, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 133 Summary - Client client_67
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0879, RMSE=0.2964, R²=-0.0537
   Val:   Loss=0.0816, RMSE=0.2857, R²=-0.0578
============================================================


📊 Round 133 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2453, R²: -0.0379

📊 Round 133 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2453, R²: -0.0379

============================================================
🔄 Round 135 - Client client_67
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0895, val=0.0754 (↓), lr=0.000001
   • Epoch   2/100: train=0.0894, val=0.0754, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0894, val=0.0754, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0894, val=0.0754, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0894, val=0.0754, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0893, val=0.0753, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0754)

============================================================
📊 Round 135 Summary - Client client_67
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0894, RMSE=0.2990, R²=-0.0508
   Val:   Loss=0.0754, RMSE=0.2746, R²=-0.0703
============================================================


============================================================
🔄 Round 139 - Client client_67
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0873, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0873, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0873, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0873, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0873, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0872, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 139 Summary - Client client_67
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0872, RMSE=0.2952, R²=-0.0474
   Val:   Loss=0.0845, RMSE=0.2906, R²=-0.0879
============================================================


📊 Round 139 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2453, R²: -0.0379

============================================================
🔄 Round 143 - Client client_67
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0878, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0878, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0878, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0878, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0877, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0876, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 143 Summary - Client client_67
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0875, RMSE=0.2958, R²=-0.0521
   Val:   Loss=0.0831, RMSE=0.2883, R²=-0.0669
============================================================


📊 Round 143 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2453, R²: -0.0379

📊 Round 143 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2453, R²: -0.0379

============================================================
🔄 Round 146 - Client client_67
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0891, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0890, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0890, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0890, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0890, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0889, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 146 Summary - Client client_67
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0888, RMSE=0.2979, R²=-0.0590
   Val:   Loss=0.0781, RMSE=0.2795, R²=-0.0333
============================================================


📊 Round 146 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2453, R²: -0.0379

📊 Round 146 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2453, R²: -0.0379

============================================================
🔄 Round 151 - Client client_67
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0899 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0899, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0900, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0900, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0900, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0900, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0899)

============================================================
📊 Round 151 Summary - Client client_67
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2929, R²=-0.0625
   Val:   Loss=0.0899, RMSE=0.2999, R²=-0.0475
============================================================


📊 Round 151 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2453, R²: -0.0380

============================================================
🔄 Round 156 - Client client_67
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0868, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0868, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0868, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0867, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0867, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 156 Summary - Client client_67
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0869, RMSE=0.2947, R²=-0.0571
   Val:   Loss=0.0858, RMSE=0.2929, R²=-0.0449
============================================================


📊 Round 156 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2453, R²: -0.0380

📊 Round 156 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2453, R²: -0.0380

============================================================
🔄 Round 159 - Client client_67
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0872, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0872, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0872, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0872, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0871, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0870, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 159 Summary - Client client_67
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0874, RMSE=0.2956, R²=-0.0583
   Val:   Loss=0.0837, RMSE=0.2894, R²=-0.0592
============================================================


📊 Round 159 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2453, R²: -0.0380

📊 Round 159 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2453, R²: -0.0380

============================================================
🔄 Round 163 - Client client_67
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0893 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0892, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0892, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0892, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0892, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0892, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0893)

============================================================
📊 Round 163 Summary - Client client_67
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2932, R²=-0.0538
   Val:   Loss=0.0893, RMSE=0.2988, R²=-0.0578
============================================================


============================================================
🔄 Round 164 - Client client_67
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0889, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0889, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0889, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0889, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0889, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0888, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 164 Summary - Client client_67
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0887, RMSE=0.2978, R²=-0.0520
   Val:   Loss=0.0785, RMSE=0.2802, R²=-0.0658
============================================================


📊 Round 164 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2453, R²: -0.0380

============================================================
🔄 Round 165 - Client client_67
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0869, val=0.0853 (↓), lr=0.000001
   • Epoch   2/100: train=0.0869, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0869, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0869, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0869, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0869, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 165 Summary - Client client_67
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0870, RMSE=0.2949, R²=-0.0419
   Val:   Loss=0.0853, RMSE=0.2921, R²=-0.1196
============================================================


📊 Round 165 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2453, R²: -0.0380

📊 Round 165 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2453, R²: -0.0380

📊 Round 165 Test Metrics:
   Loss: 0.0809, RMSE: 0.2844, MAE: 0.2453, R²: -0.0380

============================================================
🔄 Round 173 - Client client_67
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0922 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0922, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0922, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0921, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0921, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0921, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0922)

============================================================
📊 Round 173 Summary - Client client_67
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2920, R²=-0.0541
   Val:   Loss=0.0922, RMSE=0.3036, R²=-0.0554
============================================================


============================================================
🔄 Round 175 - Client client_67
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0881, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0880, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0880, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0880, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0880, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0879, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 175 Summary - Client client_67
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0881, RMSE=0.2969, R²=-0.0533
   Val:   Loss=0.0807, RMSE=0.2840, R²=-0.0620
============================================================


📊 Round 175 Test Metrics:
   Loss: 0.0809, RMSE: 0.2845, MAE: 0.2454, R²: -0.0381

============================================================
🔄 Round 179 - Client client_67
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0909 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0909, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0909, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0909, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0909, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0908, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0909)

============================================================
📊 Round 179 Summary - Client client_67
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2925, R²=-0.0590
   Val:   Loss=0.0909, RMSE=0.3016, R²=-0.0401
============================================================


📊 Round 179 Test Metrics:
   Loss: 0.0809, RMSE: 0.2845, MAE: 0.2453, R²: -0.0381

============================================================
🔄 Round 183 - Client client_67
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0885, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0885, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0885, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0885, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0885, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0884, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 183 Summary - Client client_67
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0885, RMSE=0.2974, R²=-0.0583
   Val:   Loss=0.0794, RMSE=0.2818, R²=-0.0430
============================================================


📊 Round 183 Test Metrics:
   Loss: 0.0809, RMSE: 0.2845, MAE: 0.2454, R²: -0.0381

============================================================
🔄 Round 184 - Client client_67
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0905 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0905, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0905, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0905, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0905, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0905, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0905)

============================================================
📊 Round 184 Summary - Client client_67
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2927, R²=-0.0584
   Val:   Loss=0.0905, RMSE=0.3008, R²=-0.0473
============================================================


============================================================
🔄 Round 185 - Client client_67
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0950 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0950, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0950, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0950, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0950, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0950, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0950)

============================================================
📊 Round 185 Summary - Client client_67
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2908, R²=-0.0614
   Val:   Loss=0.0950, RMSE=0.3082, R²=-0.0320
============================================================


📊 Round 185 Test Metrics:
   Loss: 0.0809, RMSE: 0.2845, MAE: 0.2454, R²: -0.0382

📊 Round 185 Test Metrics:
   Loss: 0.0809, RMSE: 0.2845, MAE: 0.2453, R²: -0.0382

============================================================
🔄 Round 188 - Client client_67
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0920 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0920, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0920, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0920, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0920, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0920, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0920)

============================================================
📊 Round 188 Summary - Client client_67
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2921, R²=-0.0539
   Val:   Loss=0.0920, RMSE=0.3034, R²=-0.0564
============================================================


============================================================
🔄 Round 189 - Client client_67
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0878, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0878, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0878, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0878, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0877, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0877, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 189 Summary - Client client_67
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0880, RMSE=0.2967, R²=-0.0573
   Val:   Loss=0.0811, RMSE=0.2848, R²=-0.0680
============================================================


📊 Round 189 Test Metrics:
   Loss: 0.0809, RMSE: 0.2845, MAE: 0.2453, R²: -0.0382

📊 Round 189 Test Metrics:
   Loss: 0.0809, RMSE: 0.2845, MAE: 0.2453, R²: -0.0382

============================================================
🔄 Round 193 - Client client_67
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0888 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0888, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0888, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0888, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0888, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0887, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0888)

============================================================
📊 Round 193 Summary - Client client_67
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2935, R²=-0.0524
   Val:   Loss=0.0888, RMSE=0.2980, R²=-0.0840
============================================================


📊 Round 193 Test Metrics:
   Loss: 0.0809, RMSE: 0.2845, MAE: 0.2454, R²: -0.0382

📊 Round 193 Test Metrics:
   Loss: 0.0809, RMSE: 0.2845, MAE: 0.2454, R²: -0.0382

📊 Round 193 Test Metrics:
   Loss: 0.0809, RMSE: 0.2845, MAE: 0.2454, R²: -0.0382

============================================================
🔄 Round 203 - Client client_67
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0886 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0886, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0886, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0886, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0886, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0885, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0886)

============================================================
📊 Round 203 Summary - Client client_67
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2935, R²=-0.0514
   Val:   Loss=0.0886, RMSE=0.2977, R²=-0.0676
============================================================


📊 Round 203 Test Metrics:
   Loss: 0.0809, RMSE: 0.2845, MAE: 0.2454, R²: -0.0383

📊 Round 203 Test Metrics:
   Loss: 0.0809, RMSE: 0.2845, MAE: 0.2454, R²: -0.0382

============================================================
🔄 Round 205 - Client client_67
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0884 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0884, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0884, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0883, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0883, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0882, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0884)

============================================================
📊 Round 205 Summary - Client client_67
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2936, R²=-0.0486
   Val:   Loss=0.0884, RMSE=0.2973, R²=-0.0778
============================================================


============================================================
🔄 Round 206 - Client client_67
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0934 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0934, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0934, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0934, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0934, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0934, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0934)

============================================================
📊 Round 206 Summary - Client client_67
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2915, R²=-0.0507
   Val:   Loss=0.0934, RMSE=0.3057, R²=-0.0727
============================================================


📊 Round 206 Test Metrics:
   Loss: 0.0809, RMSE: 0.2845, MAE: 0.2454, R²: -0.0383

============================================================
🔄 Round 209 - Client client_67
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0873 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0873, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0873, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0873, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0873, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0872, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0873)

============================================================
📊 Round 209 Summary - Client client_67
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2941, R²=-0.0614
   Val:   Loss=0.0873, RMSE=0.2955, R²=-0.0282
============================================================


📊 Round 209 Test Metrics:
   Loss: 0.0809, RMSE: 0.2845, MAE: 0.2454, R²: -0.0383

============================================================
🔄 Round 211 - Client client_67
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0870, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0869, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0869, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0869, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0869, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0868, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 211 Summary - Client client_67
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0869, RMSE=0.2949, R²=-0.0547
   Val:   Loss=0.0855, RMSE=0.2924, R²=-0.0586
============================================================


📊 Round 211 Test Metrics:
   Loss: 0.0809, RMSE: 0.2845, MAE: 0.2454, R²: -0.0383

📊 Round 211 Test Metrics:
   Loss: 0.0809, RMSE: 0.2845, MAE: 0.2454, R²: -0.0383

📊 Round 211 Test Metrics:
   Loss: 0.0809, RMSE: 0.2845, MAE: 0.2454, R²: -0.0383

============================================================
🔄 Round 217 - Client client_67
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0883 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0883, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0883, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0883, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0883, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0883, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0883)

============================================================
📊 Round 217 Summary - Client client_67
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2937, R²=-0.0511
   Val:   Loss=0.0883, RMSE=0.2971, R²=-0.0732
============================================================


============================================================
🔄 Round 219 - Client client_67
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0870, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0870, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0870, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0870, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0870, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0869, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 219 Summary - Client client_67
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0870, RMSE=0.2949, R²=-0.0517
   Val:   Loss=0.0855, RMSE=0.2924, R²=-0.0679
============================================================


📊 Round 219 Test Metrics:
   Loss: 0.0809, RMSE: 0.2845, MAE: 0.2454, R²: -0.0384

📊 Round 219 Test Metrics:
   Loss: 0.0809, RMSE: 0.2845, MAE: 0.2454, R²: -0.0384

📊 Round 219 Test Metrics:
   Loss: 0.0809, RMSE: 0.2845, MAE: 0.2454, R²: -0.0384

============================================================
🔄 Round 222 - Client client_67
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0872, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0872, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0872, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0872, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0872, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0871, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 222 Summary - Client client_67
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0870, RMSE=0.2950, R²=-0.0468
   Val:   Loss=0.0852, RMSE=0.2918, R²=-0.0946
============================================================


📊 Round 222 Test Metrics:
   Loss: 0.0809, RMSE: 0.2845, MAE: 0.2454, R²: -0.0384

============================================================
🔄 Round 223 - Client client_67
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0874, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0874, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0874, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0874, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0874, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0872, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 223 Summary - Client client_67
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0875, RMSE=0.2958, R²=-0.0622
   Val:   Loss=0.0834, RMSE=0.2888, R²=-0.0252
============================================================


📊 Round 223 Test Metrics:
   Loss: 0.0809, RMSE: 0.2845, MAE: 0.2454, R²: -0.0384

❌ Client client_67 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8687 {grpc_status:14, grpc_message:"Socket closed"}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8687 {grpc_status:14, grpc_message:"Socket closed"}"
>
