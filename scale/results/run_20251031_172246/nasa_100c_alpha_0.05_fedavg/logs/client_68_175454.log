[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 16ec4483-50d9-433a-9dea-4a70ee2b628d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e5e7a9a2-45ca-4219-be7d-4bc7cdd154e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 63b403da-bcce-4d59-88e4-f13a3ac525e2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d8d0a4d6-2370-45e0-8916-648124b09a71
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2093befa-df3a-42f5-9941-775ced0dde1c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d39c6118-82fe-4b6c-b8ae-82932cace3fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8b981ceb-8c19-4ee8-aacf-245e9ddb4b16
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4a181a0d-d8b9-4fc7-9fee-0f2c4fcdddb6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message af0d4009-d01a-4dc3-b14c-13ae8d98c6d9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 46c07eee-ce7b-492f-9c1a-dd7a14b100b6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1cb24cd1-934b-44cf-ab3c-c4bce6f5d23d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f7e33052-4a77-4a1d-9e1b-339bed3c62c5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7a62d6da-69e2-471d-940c-9fa5262a77b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dccf9d95-b94c-483d-98a7-1d04722b1241
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eb6778a8-75e1-4e41-9f38-f58a5344bd17
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 18c317e3-7611-4820-8def-da6c6907f549
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3e062a89-bbfa-4a60-9a2d-c3cf82d6b17c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b67e9716-3d23-44a3-9024-1659e1a73ee4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b41985a1-8657-4496-8d83-63fd4290f212
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message baa5387c-99cf-4915-b280-9c1f765942de
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message af0c61cc-c0e4-4a57-9093-010f263ac600
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2982dead-26be-4356-9440-993fc5ecc617
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0835975f-cbfe-475f-b198-06908d33a4e8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 36f4ddb5-4825-406a-bfca-6775c2ecc1c6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 552883fb-5c83-4215-9ae5-4f9536d40e90
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d4c0d0e8-78fa-4a47-910a-52f80c865084
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5aea937a-4c33-484d-9e2b-0f2dcd302e1e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 913990d3-8f59-4891-a691-25df7acbcffd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 37f3d7c5-1b93-4f8f-9757-3ca85494396b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5331a745-302c-4d45-9b31-7260e28eb93f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bf873bea-3db7-4ac9-8342-4e9dbaedde80
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a83491d4-98c7-422f-a6c0-8594fbee400e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 73e8f2b6-8443-4667-9ef2-93f8b5eef1b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4257294d-3760-40cc-af8c-505f1d9bc371
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2a502e01-150d-4a64-b414-62795e291266
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aa1617fa-2345-47ec-bfae-b98e30cd96e5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 411b797a-d36a-45fc-98ba-4c211794a65b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e9271033-b964-4c9d-8c56-2413caf8aa93
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9af53ae7-927c-453a-b735-c21a24300bec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dd40e3b6-3761-4b4a-9485-16ab1fc7a3a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e7ebf546-7ff2-4cbb-840f-1a8d4eb102fb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f73fd3c6-e9df-4fa7-b88f-e13222b51cf7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 55f245f3-6819-4c74-965f-94f0aa80c105
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ff59f655-67f8-44d9-84df-a37709dc2993
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c7ac21b1-6402-47d3-9c4a-6abe4b35a85c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 03bb69b2-4828-4c61-a03f-f719310d3dd7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0d2410f5-ea6e-4a7a-b261-cb6a38161063
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a13ca2db-59d4-445e-9562-e45b3e6194aa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8157203e-d4a9-4811-b891-84619d205d7f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e62c0e47-4439-4082-b253-912639887b6e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 86624157-320f-4b93-8635-2788a578a0ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b1f4dea0-63a7-49bc-9de7-43a4664cf1e0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b379fd7b-e97e-4274-8fb1-807ee611eec0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9333daeb-0516-4019-b84e-70b211af8b63
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ffea939c-437c-4994-94d7-63a3235050b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fd274841-3cc6-4db7-96a1-93eccee3b05c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 43cefd9d-4b35-412d-b181-e537270e6b37
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e21749bd-f7b9-4781-9819-39f2a917d280
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7b85e566-7ed7-4cad-ae93-5461cd444d2d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a12e0bb2-3a1d-4cbf-a422-5c18836c33ec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 006c9305-f019-46d2-a264-e94c95886408
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6bc4d7f8-cc62-4edf-a719-31e8a180916f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a955635a-3fbb-4b36-bec8-9743888d41af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b8269d3c-5b6e-4a99-965c-7be790ca31d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f5a1ed6e-c849-402d-876c-c091e9186582
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c1d1a7e1-5c62-461b-8ce9-7d82720f5bf5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9e788156-28a1-4f50-8742-1a085761dce3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 53b30bc3-cede-46b8-8cd5-b9a53fd49944
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9a1924e3-8639-450e-915b-510f8e6ef7b7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dccf27a4-84c2-405a-ab4a-beadd1bc0d85
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6ecfbfe5-558b-4fdb-95d0-d0da237d1819
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6db2121f-b881-4863-89f0-7b8e34ade5a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6ee592f5-c013-431c-9641-de7b52d5b514
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3e232233-56a6-4017-949a-9073d8615e77
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1e05bfaf-5fc2-40e0-9c2a-0d7d1cc3ca02
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1a161d9b-c844-4164-9e6d-89b3f50ef677
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ff6922eb-efd1-4a48-952b-0021e898da7d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7b123db4-c9b8-4e30-9674-13e15c8dad9f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e8398ae1-27fb-472e-a308-fb3041ebfdf7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cc3f3a04-a647-41ee-926a-b3c6b2137caa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f34a9a09-b4ec-45b8-b5df-ab1ab57360b5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 112b34cc-122d-4376-9511-da76543bc003
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 09db2be9-bbe0-40f7-8a3f-522d9188245e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fbcd6f80-4781-44de-bff3-31c4b0dac515
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1bfe3602-8ce4-4c1a-b06c-791f8af4e303
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 107d825c-b021-4972-a28e-0ab9f1a1e0e9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bdab48e2-e912-411c-9750-88d85403873c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c0723757-2cc5-4a38-ba2f-b7a86c46135e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 56055a2f-3ef5-4efd-ad57-57d9137a93e6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b491c41f-de8e-4694-b432-9d82a4ab9f6f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c8acb04a-fb43-4cab-9441-33e6207f2577
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9ff93e09-2b43-46d0-83f3-e4872421ccdc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a0ccf29a-d0b3-4cf0-b7f2-cd5b353b285c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 10120614-9f8f-49da-939d-277a9bbab5ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8cfd55f8-d533-4bbf-8965-f82954c86dd3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4e64fa6b-221b-43b1-9eb6-a64e5e0327f4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1e75d175-4d80-4e87-8fa3-b5e736d65979
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3a595351-d144-44e8-8fc6-0e6cffdd6364
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ce33ce99-612b-45f7-bae8-3164e0aee238
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7b428e5a-950f-44f7-967e-24f1422313e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 11277c28-3b8d-4740-815d-82cf53ac6cd0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7984a6b2-42c7-48b0-a67c-f77a96af5f8c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e727060c-dc54-44c5-ac83-9d39357fc7d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 25f31f6c-cd9b-41a3-b577-aa5c33c21d1e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 812ec0e5-46dc-45a5-8800-c6b9caaa9adf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b3e58c9a-2995-4600-a5ba-a7a39a11c3a9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 70c3d906-28aa-4412-8169-4bf33d8cd8be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 48fbc4b8-ad16-4582-bc0a-2063090d0932
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9a53e4ad-d662-4d67-b893-16b6a890ff43
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 925f3b88-a6be-4b95-8b9e-b3357918815a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dfb19ff7-8ed0-4333-8fc7-6b2be3267db2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 311d8273-f9bb-4030-8bc0-08f94fa47f8b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c01247e2-089a-41a2-9476-84a1bd573632
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 17ae410d-2874-4d43-a548-f22a1e5291a8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c33894d3-f5f8-480f-827b-329132004355
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message acb3b4e1-e187-4c51-a962-533a347637f4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 784df346-d686-4dc8-88c2-f4eeb5432c42
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message de9161eb-419a-4c2f-81c1-582483eef1e9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4bb83518-d7cc-4eaa-9c91-7f77a2c14d8a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e4d80406-caa7-4290-801b-8d307df4942b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7fe8edb9-fa63-4c96-944f-68c51f590ce2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 41821d23-d7fb-4bb1-8ccf-a3a9f17ce17f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message da84a3ba-352f-4a7a-8e40-7211aadb5d52
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5bda85f1-d690-4ad2-a50b-3ae16c93df20
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 393e26e6-4024-4df6-bda6-a5627a9f18d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 74494e17-ac2e-40c3-bef2-3c68139c4db5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c0b41742-2a51-40ba-aa08-016b1bd63d40
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ac734d75-0927-465a-82e7-d3771e9046c6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e08a84e5-1284-4284-921a-3778a2261c2a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d917d1d5-ff7d-4e2b-9cb2-c242c993b2ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4101c25b-d461-4f15-8ceb-5edcdf24cc28
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 677af284-7215-4709-9fd3-e0d6ce303aab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3a8b7f14-0d7d-4273-ac42-3b85274b2cb3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 971a0bc6-4ee2-434e-b00d-54d82dd744c6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0608af78-4d98-48e9-b5bd-770d2e638ef4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e94109be-4a43-4fe5-9569-ab9c916e8959
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e4b3af01-efc0-46ce-b8d4-b2b5525c8efd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 71ce7787-55e7-42b9-b2ee-7cd5f149dec7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8a7416e7-f12b-469e-97bc-d606bc460292
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ac5d303d-edae-4325-94fd-1da074b39c2f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 96e16a97-8068-4ca6-b2be-bc98b3058da4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f8c6ccee-7ddb-4ba5-ad62-f5b7a2aee25b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2ab3fe3e-f771-4205-a253-c287f8f31aff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message de5274f8-2f45-44f2-b06a-598b454e1a1a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 31900e85-c7a9-43c3-82c2-7f522422886b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3388ca98-1323-4fc4-a7d3-fb060736861f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f17c750e-99c8-4f7e-a323-06801e86f221
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a13cd322-42b5-4d7c-bf03-39bd36f8c51a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0b7e44ea-5f8e-4c07-8356-3399b352d47d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message beea7a33-ec2d-40d1-a86e-75113f409365
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3cf78fcd-e652-40fb-8787-e4f6bdfc28bd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8aa3fe39-1a00-46f3-bdcd-b50a8775697c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cab04138-ceb2-47a6-923b-50b062b023a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 172a2643-2a5c-4877-83d7-0ec5919fc93d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 39d3270f-9696-46ad-83bb-eafe7aa94476
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9b0aecaa-9832-4b82-91e3-b8eedaa1b34b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b99a8368-af81-41eb-bedd-58d99384d637
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f77ebfb7-cb9f-46c0-90ce-07623b34c5f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cc77b1f9-7845-417b-91ca-051f173760b6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 97b77f26-721d-4fe1-bb34-6e004c0f9531
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 67daf5e1-c8a9-4b38-bf1f-441e4563610b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 489b4b63-82d7-409f-ba0a-eda11b4c7eee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aca2d296-b34b-46e9-bc8a-c186600a84fb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8b10fd2f-49a7-4e5d-9fb1-df11b98e29e6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 45448f7c-8792-4789-b2be-506f630131f8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4db3bf9d-9089-4aee-88ab-416e2a94fb61
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a699dd6a-6765-40e6-920a-cb0cf3feff75
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b52c56f0-d05a-41ca-82aa-621023f706bc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 72803319-2a8b-4805-8024-94f7528e4883
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4ebd47ca-5bea-4c80-af02-7bfcb2153f05
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1bea6ea3-1aee-40c9-98aa-0601df6c1364
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7140c742-16d2-49eb-9b5f-0baf869a099a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0dddd439-4be8-46d1-88ce-5fb5abccb306
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 59541752-912a-433a-977b-34cc1b8efd2c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ba368a61-ba06-4e88-a38b-72a4fe42843a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1bcce0ae-0cdc-4756-a333-4298aae4f82e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9a823082-24e5-450a-9e42-b4e654b6f5a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 52c45b10-191d-4615-bee1-136ace8f20b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0fbeb86e-2b5f-48ce-b068-f666503b0e2c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 970fe498-4562-42ad-ae8a-7c6d203cd0ec
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8687 {grpc_status:14, grpc_message:"Socket closed"}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_68
Server: localhost:8687
Algorithm: FEDAVG
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_68
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_68/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_68/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_68/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_68/test_labels.txt

📊 Raw data loaded:
   Train: X=(1040, 24), y=(1040,)
   Test:  X=(261, 24), y=(261,)

⚠️  Limiting training data: 1040 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  252 samples, 5 features
✅ Client client_68 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

📊 Round 0 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2499, R²: -0.0419

============================================================
🔄 Round 11 - Client client_68
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0878, val=0.0880 (↓), lr=0.001000
   ✓ Epoch   2/100: train=0.0848, val=0.0874 (↓), lr=0.001000
   • Epoch   3/100: train=0.0841, val=0.0869, patience=1/15, lr=0.001000
   ✓ Epoch   4/100: train=0.0836, val=0.0867 (↓), lr=0.001000
   • Epoch   5/100: train=0.0833, val=0.0863, patience=1/15, lr=0.001000
   • Epoch  11/100: train=0.0808, val=0.0846, patience=2/15, lr=0.001000
   📉 Epoch 21: LR reduced 0.001000 → 0.000500
   • Epoch  21/100: train=0.0731, val=0.0899, patience=8/15, lr=0.000500

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 11 Summary - Client client_68
   Epochs: 28/100 (early stopped)
   LR: 0.001000 → 0.000500 (1 reductions)
   Train: Loss=0.0782, RMSE=0.2796, R²=0.0650
   Val:   Loss=0.0844, RMSE=0.2905, R²=0.0278
============================================================


📊 Round 11 Test Metrics:
   Loss: 0.0831, RMSE: 0.2883, MAE: 0.2496, R²: -0.0365

============================================================
🔄 Round 14 - Client client_68
   Epochs: 100, Batch: 32, LR: 0.000500
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   📉 Epoch 1: LR reduced 0.000500 → 0.000250
   ✓ Epoch   1/100: train=0.0843, val=0.0912 (↓), lr=0.000250
   • Epoch   2/100: train=0.0834, val=0.0912, patience=1/15, lr=0.000250
   • Epoch   3/100: train=0.0831, val=0.0911, patience=2/15, lr=0.000250
   • Epoch   4/100: train=0.0829, val=0.0911, patience=3/15, lr=0.000250
   • Epoch   5/100: train=0.0826, val=0.0911, patience=4/15, lr=0.000250
   📉 Epoch 9: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0817, val=0.0911, patience=10/15, lr=0.000125

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0912)

============================================================
📊 Round 14 Summary - Client client_68
   Epochs: 16/100 (early stopped)
   LR: 0.000500 → 0.000125 (2 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=-0.0078
   Val:   Loss=0.0912, RMSE=0.3020, R²=-0.0185
============================================================


📊 Round 14 Test Metrics:
   Loss: 0.0834, RMSE: 0.2887, MAE: 0.2500, R²: -0.0395

============================================================
🔄 Round 15 - Client client_68
   Epochs: 100, Batch: 32, LR: 0.000125
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   📉 Epoch 1: LR reduced 0.000125 → 0.000063
   ✓ Epoch   1/100: train=0.0858, val=0.0853 (↓), lr=0.000063
   • Epoch   2/100: train=0.0854, val=0.0854, patience=1/15, lr=0.000063
   • Epoch   3/100: train=0.0853, val=0.0854, patience=2/15, lr=0.000063
   • Epoch   4/100: train=0.0852, val=0.0855, patience=3/15, lr=0.000063
   • Epoch   5/100: train=0.0851, val=0.0856, patience=4/15, lr=0.000063
   📉 Epoch 9: LR reduced 0.000063 → 0.000031
   • Epoch  11/100: train=0.0846, val=0.0860, patience=10/15, lr=0.000031

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0853)

============================================================
📊 Round 15 Summary - Client client_68
   Epochs: 16/100 (early stopped)
   LR: 0.000125 → 0.000031 (2 reductions)
   Train: Loss=0.0853, RMSE=0.2921, R²=-0.0167
   Val:   Loss=0.0853, RMSE=0.2921, R²=0.0035
============================================================


📊 Round 15 Test Metrics:
   Loss: 0.0834, RMSE: 0.2888, MAE: 0.2502, R²: -0.0403

============================================================
🔄 Round 17 - Client client_68
   Epochs: 100, Batch: 32, LR: 0.000031
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   📉 Epoch 1: LR reduced 0.000031 → 0.000016
   ✓ Epoch   1/100: train=0.0854, val=0.0861 (↓), lr=0.000016
   • Epoch   2/100: train=0.0852, val=0.0862, patience=1/15, lr=0.000016
   • Epoch   3/100: train=0.0852, val=0.0863, patience=2/15, lr=0.000016
   • Epoch   4/100: train=0.0851, val=0.0863, patience=3/15, lr=0.000016
   • Epoch   5/100: train=0.0851, val=0.0864, patience=4/15, lr=0.000016
   📉 Epoch 9: LR reduced 0.000016 → 0.000008
   • Epoch  11/100: train=0.0849, val=0.0865, patience=10/15, lr=0.000008

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 17 Summary - Client client_68
   Epochs: 16/100 (early stopped)
   LR: 0.000031 → 0.000008 (2 reductions)
   Train: Loss=0.0853, RMSE=0.2920, R²=-0.0156
   Val:   Loss=0.0861, RMSE=0.2935, R²=-0.0111
============================================================


📊 Round 17 Test Metrics:
   Loss: 0.0835, RMSE: 0.2889, MAE: 0.2503, R²: -0.0411

📊 Round 17 Test Metrics:
   Loss: 0.0835, RMSE: 0.2890, MAE: 0.2503, R²: -0.0413

============================================================
🔄 Round 19 - Client client_68
   Epochs: 100, Batch: 32, LR: 0.000008
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   📉 Epoch 1: LR reduced 0.000008 → 0.000004
   ✓ Epoch   1/100: train=0.0858, val=0.0866 (↓), lr=0.000004
   • Epoch   2/100: train=0.0857, val=0.0866, patience=1/15, lr=0.000004
   • Epoch   3/100: train=0.0857, val=0.0866, patience=2/15, lr=0.000004
   • Epoch   4/100: train=0.0856, val=0.0866, patience=3/15, lr=0.000004
   • Epoch   5/100: train=0.0856, val=0.0866, patience=4/15, lr=0.000004
   📉 Epoch 9: LR reduced 0.000004 → 0.000002
   • Epoch  11/100: train=0.0855, val=0.0867, patience=10/15, lr=0.000002

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0866)

============================================================
📊 Round 19 Summary - Client client_68
   Epochs: 16/100 (early stopped)
   LR: 0.000008 → 0.000002 (2 reductions)
   Train: Loss=0.0853, RMSE=0.2920, R²=-0.0198
   Val:   Loss=0.0866, RMSE=0.2943, R²=-0.0006
============================================================


============================================================
🔄 Round 20 - Client client_68
   Epochs: 100, Batch: 32, LR: 0.000002
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0833 (↓), lr=0.000002
   • Epoch   2/100: train=0.0860, val=0.0833, patience=1/15, lr=0.000002
   • Epoch   3/100: train=0.0860, val=0.0833, patience=2/15, lr=0.000002
   • Epoch   4/100: train=0.0860, val=0.0833, patience=3/15, lr=0.000002
   • Epoch   5/100: train=0.0860, val=0.0833, patience=4/15, lr=0.000002
   • Epoch  11/100: train=0.0859, val=0.0832, patience=10/15, lr=0.000002

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 20 Summary - Client client_68
   Epochs: 16/100 (early stopped)
   LR: 0.000002 → 0.000002 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2935, R²=-0.0149
   Val:   Loss=0.0833, RMSE=0.2886, R²=-0.0185
============================================================


📊 Round 20 Test Metrics:
   Loss: 0.0836, RMSE: 0.2891, MAE: 0.2505, R²: -0.0420

============================================================
🔄 Round 21 - Client client_68
   Epochs: 100, Batch: 32, LR: 0.000002
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0893 (↓), lr=0.000002
   • Epoch   2/100: train=0.0846, val=0.0893, patience=1/15, lr=0.000002
   • Epoch   3/100: train=0.0845, val=0.0893, patience=2/15, lr=0.000002
   • Epoch   4/100: train=0.0845, val=0.0892, patience=3/15, lr=0.000002
   📉 Epoch 5: LR reduced 0.000002 → 0.000001
   • Epoch   5/100: train=0.0845, val=0.0892, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0892, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0893)

============================================================
📊 Round 21 Summary - Client client_68
   Epochs: 16/100 (early stopped)
   LR: 0.000002 → 0.000001 (1 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=-0.0211
   Val:   Loss=0.0893, RMSE=0.2988, R²=-0.0043
============================================================


📊 Round 21 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2506, R²: -0.0426

============================================================
🔄 Round 22 - Client client_68
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0880, val=0.0757 (↓), lr=0.000001
   • Epoch   2/100: train=0.0880, val=0.0757, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0880, val=0.0757, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0880, val=0.0757, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0879, val=0.0758, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0879, val=0.0759, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0757)

============================================================
📊 Round 22 Summary - Client client_68
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0882, RMSE=0.2971, R²=-0.0187
   Val:   Loss=0.0757, RMSE=0.2751, R²=-0.0552
============================================================


📊 Round 22 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2506, R²: -0.0427

============================================================
🔄 Round 26 - Client client_68
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 26 Summary - Client client_68
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2933, R²=-0.0229
   Val:   Loss=0.0846, RMSE=0.2909, R²=-0.0271
============================================================


📊 Round 26 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2506, R²: -0.0426

============================================================
🔄 Round 30 - Client client_68
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 30 Summary - Client client_68
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2929, R²=-0.0123
   Val:   Loss=0.0857, RMSE=0.2927, R²=-0.0493
============================================================


📊 Round 30 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2506, R²: -0.0427

============================================================
🔄 Round 32 - Client client_68
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 32 Summary - Client client_68
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2935, R²=-0.0182
   Val:   Loss=0.0843, RMSE=0.2903, R²=-0.0148
============================================================


📊 Round 32 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2506, R²: -0.0428

============================================================
🔄 Round 35 - Client client_68
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 35 Summary - Client client_68
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2929, R²=-0.0157
   Val:   Loss=0.0856, RMSE=0.2926, R²=-0.0267
============================================================


📊 Round 35 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2506, R²: -0.0428

============================================================
🔄 Round 36 - Client client_68
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0891 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0891, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0891, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0891, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0891, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0890, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0891)

============================================================
📊 Round 36 Summary - Client client_68
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=-0.0115
   Val:   Loss=0.0891, RMSE=0.2985, R²=-0.0443
============================================================


📊 Round 36 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2506, R²: -0.0428

============================================================
🔄 Round 38 - Client client_68
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0878 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0878, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0878, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0878, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0878, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0877, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0878)

============================================================
📊 Round 38 Summary - Client client_68
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2920, R²=-0.0171
   Val:   Loss=0.0878, RMSE=0.2963, R²=-0.0197
============================================================


============================================================
🔄 Round 40 - Client client_68
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0908 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0908, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0908, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0908, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0908, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0908, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0908)

============================================================
📊 Round 40 Summary - Client client_68
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=-0.0119
   Val:   Loss=0.0908, RMSE=0.3014, R²=-0.0523
============================================================


📊 Round 40 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2506, R²: -0.0429

📊 Round 40 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2506, R²: -0.0429

📊 Round 40 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2506, R²: -0.0430

============================================================
🔄 Round 43 - Client client_68
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0873 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0873, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0873, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0873, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0873, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0872, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0873)

============================================================
📊 Round 43 Summary - Client client_68
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2922, R²=-0.0133
   Val:   Loss=0.0873, RMSE=0.2955, R²=-0.0452
============================================================


📊 Round 43 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2506, R²: -0.0430

============================================================
🔄 Round 44 - Client client_68
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 44 Summary - Client client_68
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2937, R²=-0.0190
   Val:   Loss=0.0838, RMSE=0.2895, R²=-0.0122
============================================================


📊 Round 44 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2506, R²: -0.0430

📊 Round 44 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2506, R²: -0.0430

============================================================
🔄 Round 46 - Client client_68
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0874, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0874, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0874, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0874, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0874, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0873, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 46 Summary - Client client_68
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0872, RMSE=0.2953, R²=-0.0176
   Val:   Loss=0.0800, RMSE=0.2828, R²=-0.0247
============================================================


============================================================
🔄 Round 47 - Client client_68
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 47 Summary - Client client_68
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2927, R²=-0.0116
   Val:   Loss=0.0862, RMSE=0.2936, R²=-0.0434
============================================================


📊 Round 47 Test Metrics:
   Loss: 0.0836, RMSE: 0.2892, MAE: 0.2507, R²: -0.0431

============================================================
🔄 Round 49 - Client client_68
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 49 Summary - Client client_68
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2934, R²=-0.0231
   Val:   Loss=0.0846, RMSE=0.2908, R²=-0.0018
============================================================


📊 Round 49 Test Metrics:
   Loss: 0.0837, RMSE: 0.2892, MAE: 0.2507, R²: -0.0432

============================================================
🔄 Round 53 - Client client_68
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0893 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0893, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0893, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0893, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0893, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0892, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0893)

============================================================
📊 Round 53 Summary - Client client_68
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=-0.0219
   Val:   Loss=0.0893, RMSE=0.2988, R²=-0.0079
============================================================


📊 Round 53 Test Metrics:
   Loss: 0.0837, RMSE: 0.2892, MAE: 0.2507, R²: -0.0432

============================================================
🔄 Round 54 - Client client_68
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0867, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0867, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0867, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0867, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0867, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 54 Summary - Client client_68
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0869, RMSE=0.2947, R²=-0.0196
   Val:   Loss=0.0815, RMSE=0.2854, R²=-0.0145
============================================================


📊 Round 54 Test Metrics:
   Loss: 0.0837, RMSE: 0.2892, MAE: 0.2507, R²: -0.0432

📊 Round 54 Test Metrics:
   Loss: 0.0837, RMSE: 0.2892, MAE: 0.2507, R²: -0.0432

📊 Round 54 Test Metrics:
   Loss: 0.0837, RMSE: 0.2892, MAE: 0.2507, R²: -0.0433

📊 Round 54 Test Metrics:
   Loss: 0.0837, RMSE: 0.2892, MAE: 0.2507, R²: -0.0433

============================================================
🔄 Round 59 - Client client_68
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0863 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 59 Summary - Client client_68
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2927, R²=-0.0161
   Val:   Loss=0.0863, RMSE=0.2938, R²=-0.0269
============================================================


📊 Round 59 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2507, R²: -0.0434

📊 Round 59 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2507, R²: -0.0434

============================================================
🔄 Round 63 - Client client_68
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0865 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0865, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0865, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0865, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0865, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0865)

============================================================
📊 Round 63 Summary - Client client_68
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2926, R²=-0.0216
   Val:   Loss=0.0865, RMSE=0.2941, R²=-0.0089
============================================================


📊 Round 63 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2507, R²: -0.0435

============================================================
🔄 Round 65 - Client client_68
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0868, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0868, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0868, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0868, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0867, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 65 Summary - Client client_68
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0867, RMSE=0.2944, R²=-0.0184
   Val:   Loss=0.0823, RMSE=0.2869, R²=-0.0164
============================================================


============================================================
🔄 Round 66 - Client client_68
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0871, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0871, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0870, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0870, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0870, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0870, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 66 Summary - Client client_68
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0872, RMSE=0.2954, R²=-0.0197
   Val:   Loss=0.0800, RMSE=0.2828, R²=-0.0171
============================================================


📊 Round 66 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2507, R²: -0.0435

============================================================
🔄 Round 68 - Client client_68
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 68 Summary - Client client_68
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2933, R²=-0.0197
   Val:   Loss=0.0848, RMSE=0.2912, R²=-0.0299
============================================================


============================================================
🔄 Round 71 - Client client_68
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0880, val=0.0769 (↓), lr=0.000001
   • Epoch   2/100: train=0.0880, val=0.0769, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0880, val=0.0769, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0880, val=0.0769, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0879, val=0.0769, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0879, val=0.0769, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0769)

============================================================
📊 Round 71 Summary - Client client_68
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0880, RMSE=0.2967, R²=-0.0257
   Val:   Loss=0.0769, RMSE=0.2773, R²=0.0149
============================================================


📊 Round 71 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2508, R²: -0.0438

📊 Round 71 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2508, R²: -0.0438

📊 Round 71 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2508, R²: -0.0439

============================================================
🔄 Round 76 - Client client_68
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 76 Summary - Client client_68
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2936, R²=-0.0168
   Val:   Loss=0.0842, RMSE=0.2901, R²=-0.0628
============================================================


📊 Round 76 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2508, R²: -0.0439

============================================================
🔄 Round 77 - Client client_68
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0925 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0925, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0925, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0925, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0925, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0925, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0925)

============================================================
📊 Round 77 Summary - Client client_68
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2901, R²=-0.0219
   Val:   Loss=0.0925, RMSE=0.3042, R²=-0.0055
============================================================


📊 Round 77 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2508, R²: -0.0440

📊 Round 77 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2508, R²: -0.0440

============================================================
🔄 Round 83 - Client client_68
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0870, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0870, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0870, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0870, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0870, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0869, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 83 Summary - Client client_68
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2946, R²=-0.0232
   Val:   Loss=0.0820, RMSE=0.2864, R²=0.0023
============================================================


📊 Round 83 Test Metrics:
   Loss: 0.0837, RMSE: 0.2893, MAE: 0.2508, R²: -0.0440

📊 Round 83 Test Metrics:
   Loss: 0.0837, RMSE: 0.2894, MAE: 0.2508, R²: -0.0441

📊 Round 83 Test Metrics:
   Loss: 0.0837, RMSE: 0.2894, MAE: 0.2508, R²: -0.0442

============================================================
🔄 Round 90 - Client client_68
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0870, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0870, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0870, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0870, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0870, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0869, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 90 Summary - Client client_68
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0873, RMSE=0.2955, R²=-0.0231
   Val:   Loss=0.0797, RMSE=0.2823, R²=-0.0171
============================================================


📊 Round 90 Test Metrics:
   Loss: 0.0837, RMSE: 0.2894, MAE: 0.2508, R²: -0.0442

📊 Round 90 Test Metrics:
   Loss: 0.0837, RMSE: 0.2894, MAE: 0.2509, R²: -0.0443

📊 Round 90 Test Metrics:
   Loss: 0.0837, RMSE: 0.2894, MAE: 0.2509, R²: -0.0443

============================================================
🔄 Round 93 - Client client_68
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0869, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0869, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0868, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0868, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0868, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0868, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 93 Summary - Client client_68
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0869, RMSE=0.2947, R²=-0.0162
   Val:   Loss=0.0817, RMSE=0.2858, R²=-0.0483
============================================================


📊 Round 93 Test Metrics:
   Loss: 0.0837, RMSE: 0.2894, MAE: 0.2509, R²: -0.0443

============================================================
🔄 Round 95 - Client client_68
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0876 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0876, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0876, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0876, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0876, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0854, val=0.0877, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0876)

============================================================
📊 Round 95 Summary - Client client_68
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2922, R²=-0.0200
   Val:   Loss=0.0876, RMSE=0.2959, R²=-0.0468
============================================================


📊 Round 95 Test Metrics:
   Loss: 0.0838, RMSE: 0.2894, MAE: 0.2509, R²: -0.0444

============================================================
🔄 Round 96 - Client client_68
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 96 Summary - Client client_68
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2939, R²=-0.0195
   Val:   Loss=0.0837, RMSE=0.2893, R²=-0.0162
============================================================


============================================================
🔄 Round 99 - Client client_68
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 99 Summary - Client client_68
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2939, R²=-0.0221
   Val:   Loss=0.0836, RMSE=0.2891, R²=-0.0040
============================================================


📊 Round 99 Test Metrics:
   Loss: 0.0838, RMSE: 0.2894, MAE: 0.2509, R²: -0.0445

📊 Round 99 Test Metrics:
   Loss: 0.0838, RMSE: 0.2894, MAE: 0.2509, R²: -0.0445

============================================================
🔄 Round 102 - Client client_68
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0913 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0912, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0912, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0912, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0912, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0912, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0913)

============================================================
📊 Round 102 Summary - Client client_68
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2906, R²=-0.0197
   Val:   Loss=0.0913, RMSE=0.3021, R²=-0.0140
============================================================


============================================================
🔄 Round 104 - Client client_68
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0943 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0943, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0943, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0943, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0943, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0943, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0943)

============================================================
📊 Round 104 Summary - Client client_68
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=-0.0165
   Val:   Loss=0.0943, RMSE=0.3071, R²=-0.0322
============================================================


============================================================
🔄 Round 105 - Client client_68
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0871 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0871, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0872, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0872, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0872, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0873, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0871)

============================================================
📊 Round 105 Summary - Client client_68
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2924, R²=-0.0212
   Val:   Loss=0.0871, RMSE=0.2952, R²=-0.0530
============================================================


============================================================
🔄 Round 107 - Client client_68
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0872, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0872, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0872, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0871, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0871, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0871, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 107 Summary - Client client_68
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0870, RMSE=0.2950, R²=-0.0186
   Val:   Loss=0.0810, RMSE=0.2845, R²=-0.0372
============================================================


============================================================
🔄 Round 108 - Client client_68
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0869, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0869, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0869, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0869, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0869, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0869, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 108 Summary - Client client_68
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0872, RMSE=0.2952, R²=-0.0208
   Val:   Loss=0.0805, RMSE=0.2837, R²=-0.0090
============================================================


============================================================
🔄 Round 110 - Client client_68
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0944 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0944, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0944, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0944, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0944, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0944, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0944)

============================================================
📊 Round 110 Summary - Client client_68
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=-0.0140
   Val:   Loss=0.0944, RMSE=0.3073, R²=-0.0361
============================================================


📊 Round 110 Test Metrics:
   Loss: 0.0838, RMSE: 0.2894, MAE: 0.2509, R²: -0.0447

============================================================
🔄 Round 112 - Client client_68
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0886 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0886, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0886, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0886, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0886, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0886, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0886)

============================================================
📊 Round 112 Summary - Client client_68
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2918, R²=-0.0133
   Val:   Loss=0.0886, RMSE=0.2976, R²=-0.0408
============================================================


📊 Round 112 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2509, R²: -0.0448

📊 Round 112 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2509, R²: -0.0449

============================================================
🔄 Round 114 - Client client_68
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 114 Summary - Client client_68
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2934, R²=-0.0172
   Val:   Loss=0.0847, RMSE=0.2911, R²=-0.0243
============================================================


📊 Round 114 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2510, R²: -0.0449

============================================================
🔄 Round 116 - Client client_68
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 116 Summary - Client client_68
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2936, R²=-0.0166
   Val:   Loss=0.0844, RMSE=0.2905, R²=-0.0294
============================================================


📊 Round 116 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2510, R²: -0.0450

============================================================
🔄 Round 118 - Client client_68
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0888 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0888, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0888, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0888, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0888, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0888, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0888)

============================================================
📊 Round 118 Summary - Client client_68
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2917, R²=-0.0159
   Val:   Loss=0.0888, RMSE=0.2980, R²=-0.0305
============================================================


📊 Round 118 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2510, R²: -0.0451

============================================================
🔄 Round 119 - Client client_68
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0876, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0876, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0876, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0876, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0876, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0875, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 119 Summary - Client client_68
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0876, RMSE=0.2960, R²=-0.0209
   Val:   Loss=0.0789, RMSE=0.2808, R²=-0.0099
============================================================


📊 Round 119 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2510, R²: -0.0451

============================================================
🔄 Round 120 - Client client_68
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0883 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0883, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0883, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0883, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0883, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0883, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0883)

============================================================
📊 Round 120 Summary - Client client_68
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2919, R²=-0.0236
   Val:   Loss=0.0883, RMSE=0.2972, R²=-0.0050
============================================================


============================================================
🔄 Round 121 - Client client_68
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0896 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0896, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0896, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0896, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0896, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0895, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0896)

============================================================
📊 Round 121 Summary - Client client_68
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=-0.0154
   Val:   Loss=0.0896, RMSE=0.2993, R²=-0.0313
============================================================


============================================================
🔄 Round 122 - Client client_68
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0879 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0879, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0879, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0879, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0879, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0879, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0879)

============================================================
📊 Round 122 Summary - Client client_68
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2921, R²=-0.0122
   Val:   Loss=0.0879, RMSE=0.2965, R²=-0.0512
============================================================


📊 Round 122 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2510, R²: -0.0452

============================================================
🔄 Round 124 - Client client_68
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0867, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0867, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0867, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0867, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0867, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 124 Summary - Client client_68
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0870, RMSE=0.2950, R²=-0.0122
   Val:   Loss=0.0813, RMSE=0.2851, R²=-0.0536
============================================================


📊 Round 124 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2510, R²: -0.0451

============================================================
🔄 Round 125 - Client client_68
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0875, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0875, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0875, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0875, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0875, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0874, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 125 Summary - Client client_68
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0875, RMSE=0.2958, R²=-0.0178
   Val:   Loss=0.0793, RMSE=0.2817, R²=-0.0230
============================================================


📊 Round 125 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2510, R²: -0.0453

📊 Round 125 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2510, R²: -0.0453

📊 Round 125 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2510, R²: -0.0453

📊 Round 125 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2510, R²: -0.0453

📊 Round 125 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2510, R²: -0.0454

📊 Round 125 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2510, R²: -0.0454

============================================================
🔄 Round 140 - Client client_68
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 140 Summary - Client client_68
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2937, R²=-0.0278
   Val:   Loss=0.0844, RMSE=0.2904, R²=0.0143
============================================================


📊 Round 140 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2510, R²: -0.0455

📊 Round 140 Test Metrics:
   Loss: 0.0838, RMSE: 0.2896, MAE: 0.2510, R²: -0.0455

============================================================
🔄 Round 144 - Client client_68
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0881 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0881, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0881, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0881, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0881, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0881, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0881)

============================================================
📊 Round 144 Summary - Client client_68
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2921, R²=-0.0210
   Val:   Loss=0.0881, RMSE=0.2969, R²=-0.0144
============================================================


📊 Round 144 Test Metrics:
   Loss: 0.0838, RMSE: 0.2896, MAE: 0.2510, R²: -0.0455

============================================================
🔄 Round 145 - Client client_68
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0904 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0904, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0904, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0904, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0904, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0904, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0904)

============================================================
📊 Round 145 Summary - Client client_68
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2911, R²=-0.0261
   Val:   Loss=0.0904, RMSE=0.3007, R²=0.0009
============================================================


📊 Round 145 Test Metrics:
   Loss: 0.0838, RMSE: 0.2896, MAE: 0.2511, R²: -0.0456

============================================================
🔄 Round 146 - Client client_68
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0903 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0903, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0903, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0903, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0903, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0902, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0903)

============================================================
📊 Round 146 Summary - Client client_68
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=-0.0231
   Val:   Loss=0.0903, RMSE=0.3005, R²=-0.0140
============================================================


📊 Round 146 Test Metrics:
   Loss: 0.0838, RMSE: 0.2896, MAE: 0.2511, R²: -0.0456

📊 Round 146 Test Metrics:
   Loss: 0.0838, RMSE: 0.2896, MAE: 0.2511, R²: -0.0456

📊 Round 146 Test Metrics:
   Loss: 0.0839, RMSE: 0.2896, MAE: 0.2511, R²: -0.0456

============================================================
🔄 Round 151 - Client client_68
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0904 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0904, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0904, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0903, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0903, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0903, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0904)

============================================================
📊 Round 151 Summary - Client client_68
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=-0.0192
   Val:   Loss=0.0904, RMSE=0.3006, R²=-0.0188
============================================================


📊 Round 151 Test Metrics:
   Loss: 0.0839, RMSE: 0.2896, MAE: 0.2511, R²: -0.0457

============================================================
🔄 Round 152 - Client client_68
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0867 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0867, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0867, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0867, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0867, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 152 Summary - Client client_68
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2927, R²=-0.0125
   Val:   Loss=0.0867, RMSE=0.2945, R²=-0.0503
============================================================


============================================================
🔄 Round 153 - Client client_68
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0882, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0882, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0882, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0881, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0881, val=0.0773, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0881, val=0.0773, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 153 Summary - Client client_68
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0880, RMSE=0.2967, R²=-0.0229
   Val:   Loss=0.0773, RMSE=0.2780, R²=-0.0034
============================================================


============================================================
🔄 Round 154 - Client client_68
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0872, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0872, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0872, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0872, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0872, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0871, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 154 Summary - Client client_68
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0871, RMSE=0.2951, R²=-0.0209
   Val:   Loss=0.0810, RMSE=0.2847, R²=-0.0281
============================================================


============================================================
🔄 Round 155 - Client client_68
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0957 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0956, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0956, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0956, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0956, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0956, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0957)

============================================================
📊 Round 155 Summary - Client client_68
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=-0.0225
   Val:   Loss=0.0957, RMSE=0.3093, R²=-0.0175
============================================================


📊 Round 155 Test Metrics:
   Loss: 0.0839, RMSE: 0.2896, MAE: 0.2511, R²: -0.0458

📊 Round 155 Test Metrics:
   Loss: 0.0839, RMSE: 0.2896, MAE: 0.2511, R²: -0.0458

📊 Round 155 Test Metrics:
   Loss: 0.0839, RMSE: 0.2896, MAE: 0.2511, R²: -0.0459

============================================================
🔄 Round 159 - Client client_68
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 159 Summary - Client client_68
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2941, R²=-0.0208
   Val:   Loss=0.0835, RMSE=0.2890, R²=-0.0127
============================================================


============================================================
🔄 Round 161 - Client client_68
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 161 Summary - Client client_68
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2939, R²=-0.0221
   Val:   Loss=0.0841, RMSE=0.2899, R²=-0.0091
============================================================


============================================================
🔄 Round 163 - Client client_68
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 163 Summary - Client client_68
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2931, R²=-0.0278
   Val:   Loss=0.0860, RMSE=0.2932, R²=-0.0237
============================================================


============================================================
🔄 Round 164 - Client client_68
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0916 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0916, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0916, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0915, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0915, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0915, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0916)

============================================================
📊 Round 164 Summary - Client client_68
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=-0.0183
   Val:   Loss=0.0916, RMSE=0.3026, R²=-0.0257
============================================================


📊 Round 164 Test Metrics:
   Loss: 0.0839, RMSE: 0.2896, MAE: 0.2511, R²: -0.0460

📊 Round 164 Test Metrics:
   Loss: 0.0839, RMSE: 0.2896, MAE: 0.2511, R²: -0.0460

📊 Round 164 Test Metrics:
   Loss: 0.0839, RMSE: 0.2896, MAE: 0.2511, R²: -0.0460

📊 Round 164 Test Metrics:
   Loss: 0.0839, RMSE: 0.2896, MAE: 0.2511, R²: -0.0461

============================================================
🔄 Round 172 - Client client_68
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0947 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0947, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0947, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0947, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0947, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0948, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0947)

============================================================
📊 Round 172 Summary - Client client_68
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2893, R²=-0.0230
   Val:   Loss=0.0947, RMSE=0.3078, R²=-0.0235
============================================================


📊 Round 172 Test Metrics:
   Loss: 0.0839, RMSE: 0.2896, MAE: 0.2511, R²: -0.0462

============================================================
🔄 Round 174 - Client client_68
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0941 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0941, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0941, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0942, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0942, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0942, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0941)

============================================================
📊 Round 174 Summary - Client client_68
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2896, R²=-0.0217
   Val:   Loss=0.0941, RMSE=0.3068, R²=-0.0269
============================================================


============================================================
🔄 Round 175 - Client client_68
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0878 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0878, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0878, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0878, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0878, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0878, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0878)

============================================================
📊 Round 175 Summary - Client client_68
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2923, R²=-0.0149
   Val:   Loss=0.0878, RMSE=0.2964, R²=-0.0397
============================================================


============================================================
🔄 Round 179 - Client client_68
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0922 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0922, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0922, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0922, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0921, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0921, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0922)

============================================================
📊 Round 179 Summary - Client client_68
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2904, R²=-0.0121
   Val:   Loss=0.0922, RMSE=0.3036, R²=-0.0484
============================================================


📊 Round 179 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2512, R²: -0.0463

📊 Round 179 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2512, R²: -0.0463

============================================================
🔄 Round 182 - Client client_68
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0956 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0956, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0956, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0956, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0956, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0956, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0956)

============================================================
📊 Round 182 Summary - Client client_68
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=-0.0158
   Val:   Loss=0.0956, RMSE=0.3092, R²=-0.0480
============================================================


============================================================
🔄 Round 188 - Client client_68
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0878 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0878, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0878, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0878, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0878, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0878, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0878)

============================================================
📊 Round 188 Summary - Client client_68
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2924, R²=-0.0276
   Val:   Loss=0.0878, RMSE=0.2963, R²=0.0087
============================================================


📊 Round 188 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2512, R²: -0.0465

📊 Round 188 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2512, R²: -0.0466

📊 Round 188 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2512, R²: -0.0466

============================================================
🔄 Round 198 - Client client_68
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0878 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0878, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0878, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0878, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0878, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0877, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0878)

============================================================
📊 Round 198 Summary - Client client_68
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2924, R²=-0.0189
   Val:   Loss=0.0878, RMSE=0.2963, R²=-0.0236
============================================================


📊 Round 198 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2512, R²: -0.0467

📊 Round 198 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2512, R²: -0.0467

============================================================
🔄 Round 200 - Client client_68
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0879, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0879, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0878, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0878, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0878, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0877, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 200 Summary - Client client_68
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0879, RMSE=0.2965, R²=-0.0219
   Val:   Loss=0.0781, RMSE=0.2795, R²=-0.0291
============================================================


📊 Round 200 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2512, R²: -0.0468

============================================================
🔄 Round 202 - Client client_68
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0867 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0867, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0867, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0867, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0866, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 202 Summary - Client client_68
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2929, R²=-0.0143
   Val:   Loss=0.0867, RMSE=0.2944, R²=-0.0512
============================================================


📊 Round 202 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2512, R²: -0.0468

============================================================
🔄 Round 205 - Client client_68
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0929 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0929, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0929, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0929, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0929, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0929, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0929)

============================================================
📊 Round 205 Summary - Client client_68
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=-0.0255
   Val:   Loss=0.0929, RMSE=0.3049, R²=-0.0110
============================================================


📊 Round 205 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2512, R²: -0.0468

📊 Round 205 Test Metrics:
   Loss: 0.0839, RMSE: 0.2897, MAE: 0.2512, R²: -0.0469

============================================================
🔄 Round 208 - Client client_68
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0957 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0957, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0957, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0957, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0957, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0958, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0957)

============================================================
📊 Round 208 Summary - Client client_68
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=-0.0243
   Val:   Loss=0.0957, RMSE=0.3094, R²=-0.0106
============================================================


📊 Round 208 Test Metrics:
   Loss: 0.0840, RMSE: 0.2897, MAE: 0.2512, R²: -0.0469

📊 Round 208 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2512, R²: -0.0469

📊 Round 208 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2512, R²: -0.0470

📊 Round 208 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2512, R²: -0.0470

============================================================
🔄 Round 212 - Client client_68
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0901 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0901, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0901, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0901, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0901, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0901, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0901)

============================================================
📊 Round 212 Summary - Client client_68
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=-0.0178
   Val:   Loss=0.0901, RMSE=0.3002, R²=-0.0411
============================================================


📊 Round 212 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2513, R²: -0.0470

📊 Round 212 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2513, R²: -0.0470

============================================================
🔄 Round 214 - Client client_68
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 214 Summary - Client client_68
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2932, R²=-0.0201
   Val:   Loss=0.0860, RMSE=0.2932, R²=-0.0206
============================================================


============================================================
🔄 Round 216 - Client client_68
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0929 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0929, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0929, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0929, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0929, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0928, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0929)

============================================================
📊 Round 216 Summary - Client client_68
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=-0.0190
   Val:   Loss=0.0929, RMSE=0.3048, R²=-0.0240
============================================================


📊 Round 216 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2513, R²: -0.0471

📊 Round 216 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2513, R²: -0.0471

📊 Round 216 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2513, R²: -0.0472

============================================================
🔄 Round 221 - Client client_68
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0837, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0837, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0837, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0863, val=0.0837, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 221 Summary - Client client_68
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2942, R²=-0.0156
   Val:   Loss=0.0837, RMSE=0.2893, R²=-0.0396
============================================================


📊 Round 221 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2513, R²: -0.0472

============================================================
🔄 Round 224 - Client client_68
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0886 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0886, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0886, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0886, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0886, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0886, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0886)

============================================================
📊 Round 224 Summary - Client client_68
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2921, R²=-0.0166
   Val:   Loss=0.0886, RMSE=0.2977, R²=-0.0443
============================================================


❌ Client client_68 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8687 {grpc_status:14, grpc_message:"Socket closed"}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8687 {grpc_status:14, grpc_message:"Socket closed"}"
>
