[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 88ecaba9-f4e8-4a45-af76-040ff4c041e1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fdb0bc47-5f3f-4338-85f7-710d6d9dc553
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 76577717-aea5-4166-9558-d993789849d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a42c279e-9fcf-4210-938f-97e4873314ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b1a82e95-44a4-4a3d-a330-d1e4a2152a53
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3552220f-b843-4581-84fe-df463af89cf7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b06ddf76-6bf8-425e-8e24-397e3e6849aa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0a355b87-91e5-4c8d-ab16-8897b0092c3d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b0877434-85e1-4968-b796-641283864cde
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 59bbf5b7-5081-4f0f-93e0-05bafc9e68fb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 79f3351b-5654-4866-ba22-ece2afe2a1ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a1957b09-2583-46af-924c-3686ea8ca40e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5dca64c7-6ee8-420f-96a2-aeb68f7dfe6b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4c7c0282-da56-431b-ab4c-e7cf50084032
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6144803b-be73-4345-9c7f-f5d3a44547da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 820814c5-5bdc-4f3a-87a2-96efc5c03210
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0301680b-0257-4e2e-b5b5-4fa206532f9d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 412b63d0-9079-4963-b368-bffafc5b9f00
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0b3b40fc-b6d0-4eaa-adac-88232c90fe8c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ddd47c3f-7272-44ba-9469-9218be612980
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0d6e115f-956a-48bb-a01a-3e1c1e0b76c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2f89383d-d5ca-4c0a-ad7c-4d6589f758da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c94c23b5-5fcb-4f8a-9d8d-242aad335958
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 34729843-b058-4135-9a65-045b3211cf4d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c52a8072-436b-4948-ad06-3180b8b40087
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1829884d-f176-4514-8a5d-7ff8a7d34cd0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cff21991-3ad0-4224-9a8c-3d1b8ee0d37d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 52a60e46-0b3f-4f0a-8892-76c939ac1a97
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f769c788-ba30-43ed-9ceb-450a165e98a9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 02717a09-000b-4d86-9e7a-7b85718955ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7ded6521-6db2-4d25-9745-c0c8425a509c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aec88a15-3810-47e2-b1fa-30da7734f651
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3dc89c14-0e94-4e3b-ab60-b55782d77b75
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2c0383ba-64d1-489c-8105-889d1f72665c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 33dc2805-4cf8-47f6-ad58-e4909e01f42e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 71629fca-6070-4d2b-8f50-83242b7c42e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1af984d5-e39c-4c2d-83b2-6cc140fa017e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d001d8c2-018e-4310-b0bc-6ea4013eb213
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f5050198-f9a0-4a5b-b174-60bb4e574cf5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cdbf9134-c0fb-4209-a23d-3f283988f6d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 68946a3c-5fc7-4cd0-9fae-f1fdc20c2835
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 430e9c6f-9631-4a4d-aab3-5ca3cccfbff1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 64dbcd28-6592-43be-84ce-c6170f9fa050
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5eaaa577-b33f-4ed3-a070-f457ded6a81f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9c41f58e-a609-408c-8822-1b75d69fafbf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 601dfbd0-5ce3-4e0b-88f1-4874dba90175
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 13e95467-3474-4ee4-a41a-8f06442f0273
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4a8c3969-8275-4146-87d9-0ad2be13bfc9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 055759ed-d24d-4149-bf03-1beecb7a25d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6afdc21d-e518-4620-b709-efa8e4bc0245
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cf413add-e873-49c2-84a3-20e8497c3993
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 642c28c0-28c0-49e8-85ce-aabd066eff58
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6cd4fb22-5597-49d3-a563-ae2be210d809
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 59890d12-1249-4cc9-b09e-9e2f29fc004c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 101292aa-3a2c-4eb4-adac-2d8922901a31
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cc891ce7-7676-4033-8c69-0fbd3d4ca160
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4265c900-29ca-4de8-ac78-b390caa74b80
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ab9db8f6-f8a1-48a8-a661-9727e6c48208
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7fb83af7-5b7e-4edc-aae4-ebea091a4a65
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d1f429fb-3f4c-48b1-af09-720758294e9a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 89f125c3-2cdf-482d-9453-5e86a8e315ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ff1e2d03-7f3b-4c2e-ab05-4450c93c88df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5cfc5d5d-5758-4cd4-af8f-ac3b1c6bdd9b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d44d0ac1-2a5d-45e7-92ff-7adf735f0f48
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 40f6e211-bc16-4c36-9f15-344d9a0b2e52
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4c7fce6a-8574-42bd-ade0-b40c900d13e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message df6b205d-761e-4655-a4ba-8317ca2bd9b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fdac5c4f-7bbb-49ff-8ca6-84a10fb9ddcc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0b645e00-0475-4652-b4d3-c4d9679a2c83
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 32ce1d98-87f0-4e9a-acc4-d25770bd5097
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7b153f63-a3dc-443f-aac3-c5cbba9d362e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c160d0ec-b559-4dbf-870f-03031f913a81
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 634288ba-58a2-4809-8dc9-acde1c9ce080
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ca1e6169-586e-407f-8b09-b28531d74003
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d2e22c3b-e08d-4dd5-9d71-4e1b39709e10
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 44a71c1a-963a-43ed-8b30-cc35aff2f034
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message afb5703a-fee8-442d-955a-3a54b39c3fc0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c6b7e518-b63b-4775-b11a-cd7594e4bb6f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 64155f5c-4674-4d78-b8a5-4e0c1ece0150
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 22b321ba-ad37-477f-b9fb-62c3a9ccbf39
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 52ecd189-e480-44b6-a015-06fdec089de6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 779b375e-6e08-45e9-9299-cb164cb64984
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7a95eb29-caec-499c-a695-a7b599ab0892
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5d2fc2a4-f469-4190-aa8b-3e4b1cd46b32
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 444a013b-94b5-4aad-ad89-171653b9d8ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d9f35d3b-a889-4d8c-b5a5-fc9f2df6f41e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message af245a24-bd26-4cbb-91c2-f930ecc371ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c83028f7-76ed-4351-9129-7a6860451348
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f1fdeb64-e0eb-4793-bd1e-14593a256053
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7122f6b3-2708-42d6-a7cc-de5d96c47223
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bacac8b6-4d18-4a45-bf63-5a169e40d30e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b8cd9b03-4434-4b10-a0c8-d0f140f9f2b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ce43437f-f146-49f2-8fb1-7b1a09880563
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 76bd07d6-08c7-4025-bda3-132bd450e206
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ce5bc119-928f-4677-800d-31ce1156a95d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 96fea657-d220-49d3-acca-1a2e181b37c6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4537bcb0-3a6f-4c01-9d65-546ac3b93f34
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 38d6a605-db1c-46b1-83d7-f645650eb950
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7f200c47-ba80-45e1-9fb6-5624221e9085
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bd4bf25f-cb8c-40c5-af4e-7d73a4ed73e0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 207363b1-db8e-4603-80a4-1a5417577513
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4b564faa-c261-4a7a-9ea5-498c136f1187
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 14ee36da-c53f-4b4c-ac03-ae03a6c86577
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5cfe9615-7396-4ac5-9aa1-2f3c27afbfc0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2b0ec948-900e-44b2-8caa-cb94cd20fc67
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a303ee63-b983-4d19-b10c-458b3391824a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 873b7042-4107-4708-a737-6edd04773b69
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8efc4de6-f721-4813-be4a-47146dfff1a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cd05ff1d-08ef-430b-ae9c-f98fffcedecf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fc9cc939-df5d-41a6-bee9-d6323d096600
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7af08bf7-91d7-4151-add9-584636e9b215
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 40327158-bdbc-4b9e-9591-456287eef61f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e0d39e3d-f8f7-4fc7-9c39-4393852dcf6c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d62ab883-c38d-4ddd-b0d5-ab39f9c7bdf3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8f190722-1e66-4743-a522-5df7a2aef709
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message deaf6d76-517a-45f6-a1a6-0d130298e5f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 48c02a72-18d8-42d9-b578-1988742e0c54
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f459f8d3-5a5b-41a8-b474-9e0251322417
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d48f1fcd-c3dd-4137-acf4-fddffc920320
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dcde0128-993b-43b1-b9af-4073eb019899
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 32b3c623-b36b-41ac-a2fa-a4b4eba1e7c6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fc9e1203-a1c6-4461-b147-dc38f807d6ef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4ea1ca55-c990-4af3-b80b-451fb9441c91
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ccac93fc-066c-4615-b462-9f31404558a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 75724e4c-8125-4f59-9dbe-e8931e2752a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 996c4246-fe67-4b0f-8db4-51e515ca7ccd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 60eee6ee-cdf4-42ec-9b0e-0418498a7e09
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 84f07069-b8f0-4e77-86ca-3b0da0cc2e04
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4ba4c418-b9c6-455f-a192-3e2b21e42a98
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9ac82aef-ed88-4b69-9699-d697da42abd6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4e92ed8a-fab4-4f28-98dd-5dd250a0385c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3bc003f7-7f2f-4b73-a1f0-653b337d57b5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cd959203-6603-4dd2-95fc-fe8fb91abfcc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f8b61ec4-09f5-4eb3-9ff8-3c0aaec470d5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 58c43bec-6578-430d-b4c8-a78d792879de
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e057116e-326b-4a4c-af78-16179a41f85d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eddff7fe-5de5-47c7-87d0-b8c6a3e91d6e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 21907e09-d167-4e1b-afc8-6f932c5f5386
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 460742e9-eb26-4316-b2fc-9f8f1bdf3028
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 865b2474-b7b2-41ca-bc7e-cb7817beb7d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 904cad13-f181-4b79-8bac-1dd05ece2067
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ebfa1dfc-1c25-4a4e-b603-f59767c7fc32
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 69978d96-6d6d-4ce7-b9d0-4b6c301d55c3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 161c52c8-2851-4f23-9002-0eebe9d46fd0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d92050d1-69a5-4af1-a831-eadad59d0f15
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e2f751b2-f9d5-400f-a7d6-aa6a44b0ef2e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a7f9fedd-995c-4d2b-a060-ec16d2567cc1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 90b65eac-25df-439f-9a83-8fb04a87be77
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f886a1db-3b1a-48d2-8513-95cb1908e6a7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cc3dae44-d998-458a-8ba5-ef9d9cca64bd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 317b19a7-4d8f-41f0-ba60-67eb5f3cdf82
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3dd7e3a6-3020-482a-9560-ea2c785b3981
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cb0aafc0-e507-4f1b-b0f0-e53a5e699a89
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7f27d9d9-e924-429a-b07c-82cb6653a244
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e0a4eff8-6798-4b01-979c-c8737d060a00
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7cf3d664-efad-44ef-8865-11b5d951d920
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ceb77ff6-0966-4d06-b8c2-9f01e3db8d67
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a38cb627-d40f-410c-8aaa-5609afe24c49
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0688d709-7652-4276-9ed5-ae0cba1f9e1c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 33976754-c198-4ba4-bc91-0d77a338a053
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 89e2df58-bf04-40f8-8618-88d95446a0ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 315a83d7-d948-4471-8f24-24a5c3afb1db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9e452e5a-ee69-4fa0-95cd-896726b5e5d8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f6f28948-f64a-4b40-9544-062e2120ce28
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7a5e9a46-15b7-41b8-95dd-1668f6bba09e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3eb10d2b-ca56-43a3-8859-e0232adb65b1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 771d8762-cf8a-43ed-a113-35aa4372b3db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8e5f6107-d52e-46ac-aff4-acb33c2aea15
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 047dc97d-2d93-4f9a-b89c-3ed0387ce62c
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8687 {grpc_status:14, grpc_message:"Socket closed"}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_69
Server: localhost:8687
Algorithm: FEDAVG
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_69
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_69/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_69/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_69/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_69/test_labels.txt

📊 Raw data loaded:
   Train: X=(824, 24), y=(824,)
   Test:  X=(207, 24), y=(207,)

⚠️  Limiting training data: 824 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  198 samples, 5 features
✅ Client client_69 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

📊 Round 0 Test Metrics:
   Loss: 0.0892, RMSE: 0.2986, MAE: 0.2596, R²: -0.0095

📊 Round 0 Test Metrics:
   Loss: 0.0898, RMSE: 0.2997, MAE: 0.2595, R²: -0.0168

============================================================
🔄 Round 10 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0895 (↓), lr=0.001000
   • Epoch   2/100: train=0.0821, val=0.0900, patience=1/15, lr=0.001000
   • Epoch   3/100: train=0.0822, val=0.0900, patience=2/15, lr=0.001000
   • Epoch   4/100: train=0.0815, val=0.0902, patience=3/15, lr=0.001000
   • Epoch   5/100: train=0.0808, val=0.0904, patience=4/15, lr=0.001000
   📉 Epoch 7: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0780, val=0.0919, patience=10/15, lr=0.000500
   📉 Epoch 15: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0895)

============================================================
📊 Round 10 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=-0.0257
   Val:   Loss=0.0895, RMSE=0.2991, R²=0.0041
============================================================


📊 Round 10 Test Metrics:
   Loss: 0.0899, RMSE: 0.2998, MAE: 0.2596, R²: -0.0176

============================================================
🔄 Round 11 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0840 (↓), lr=0.000250
   ✓ Epoch   2/100: train=0.0848, val=0.0833 (↓), lr=0.000250
   • Epoch   3/100: train=0.0842, val=0.0832, patience=1/15, lr=0.000250
   • Epoch   4/100: train=0.0839, val=0.0831, patience=2/15, lr=0.000250
   • Epoch   5/100: train=0.0837, val=0.0830, patience=3/15, lr=0.000250
   • Epoch  11/100: train=0.0829, val=0.0828, patience=1/15, lr=0.000250
   📉 Epoch 21: LR reduced 0.000250 → 0.000125
   • Epoch  21/100: train=0.0819, val=0.0828, patience=11/15, lr=0.000125

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 11 Summary - Client client_69
   Epochs: 25/100 (early stopped)
   LR: 0.000250 → 0.000125 (1 reductions)
   Train: Loss=0.0825, RMSE=0.2873, R²=0.0010
   Val:   Loss=0.0828, RMSE=0.2878, R²=-0.0316
============================================================


📊 Round 11 Test Metrics:
   Loss: 0.0898, RMSE: 0.2996, MAE: 0.2593, R²: -0.0163

📊 Round 11 Test Metrics:
   Loss: 0.0901, RMSE: 0.3001, MAE: 0.2595, R²: -0.0193

📊 Round 11 Test Metrics:
   Loss: 0.0900, RMSE: 0.3000, MAE: 0.2593, R²: -0.0188

📊 Round 11 Test Metrics:
   Loss: 0.0901, RMSE: 0.3001, MAE: 0.2593, R²: -0.0197

============================================================
🔄 Round 17 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000125
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0935 (↓), lr=0.000125
   ✓ Epoch   2/100: train=0.0833, val=0.0928 (↓), lr=0.000125
   • Epoch   3/100: train=0.0824, val=0.0925, patience=1/15, lr=0.000125
   📉 Epoch 4: LR reduced 0.000125 → 0.000063
   • Epoch   4/100: train=0.0819, val=0.0925, patience=2/15, lr=0.000063
   • Epoch   5/100: train=0.0816, val=0.0924, patience=3/15, lr=0.000063
   • Epoch  11/100: train=0.0810, val=0.0923, patience=9/15, lr=0.000063
   📉 Epoch 12: LR reduced 0.000063 → 0.000031

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0928)

============================================================
📊 Round 17 Summary - Client client_69
   Epochs: 17/100 (early stopped)
   LR: 0.000125 → 0.000031 (2 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=-0.0289
   Val:   Loss=0.0928, RMSE=0.3046, R²=-0.0347
============================================================


📊 Round 17 Test Metrics:
   Loss: 0.0901, RMSE: 0.3001, MAE: 0.2594, R²: -0.0194

📊 Round 17 Test Metrics:
   Loss: 0.0901, RMSE: 0.3002, MAE: 0.2594, R²: -0.0200

============================================================
🔄 Round 20 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000031
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0907 (↓), lr=0.000031
   ✓ Epoch   2/100: train=0.0859, val=0.0902 (↓), lr=0.000031
   📉 Epoch 3: LR reduced 0.000031 → 0.000016
   ✓ Epoch   3/100: train=0.0853, val=0.0897 (↓), lr=0.000016
   • Epoch   4/100: train=0.0849, val=0.0894, patience=1/15, lr=0.000016
   ✓ Epoch   5/100: train=0.0846, val=0.0891 (↓), lr=0.000016
   📉 Epoch 11: LR reduced 0.000016 → 0.000008
   • Epoch  11/100: train=0.0836, val=0.0884, patience=2/15, lr=0.000008
   📉 Epoch 19: LR reduced 0.000008 → 0.000004
   • Epoch  21/100: train=0.0833, val=0.0883, patience=12/15, lr=0.000004

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0886)

============================================================
📊 Round 20 Summary - Client client_69
   Epochs: 24/100 (early stopped)
   LR: 0.000031 → 0.000004 (3 reductions)
   Train: Loss=0.0835, RMSE=0.2889, R²=-0.0224
   Val:   Loss=0.0886, RMSE=0.2976, R²=-0.0365
============================================================


📊 Round 20 Test Metrics:
   Loss: 0.0903, RMSE: 0.3005, MAE: 0.2594, R²: -0.0221

📊 Round 20 Test Metrics:
   Loss: 0.0903, RMSE: 0.3005, MAE: 0.2594, R²: -0.0223

📊 Round 20 Test Metrics:
   Loss: 0.0903, RMSE: 0.3005, MAE: 0.2594, R²: -0.0223

📊 Round 20 Test Metrics:
   Loss: 0.0903, RMSE: 0.3005, MAE: 0.2594, R²: -0.0224

📊 Round 20 Test Metrics:
   Loss: 0.0903, RMSE: 0.3005, MAE: 0.2594, R²: -0.0224

============================================================
🔄 Round 25 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000004
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0958 (↓), lr=0.000004
   • Epoch   2/100: train=0.0854, val=0.0957, patience=1/15, lr=0.000004
   📉 Epoch 3: LR reduced 0.000004 → 0.000002
   • Epoch   3/100: train=0.0853, val=0.0956, patience=2/15, lr=0.000002
   • Epoch   4/100: train=0.0852, val=0.0956, patience=3/15, lr=0.000002
   • Epoch   5/100: train=0.0852, val=0.0956, patience=4/15, lr=0.000002
   📉 Epoch 11: LR reduced 0.000002 → 0.000001
   • Epoch  11/100: train=0.0850, val=0.0954, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0958)

============================================================
📊 Round 25 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.000004 → 0.000001 (2 reductions)
   Train: Loss=0.0853, RMSE=0.2920, R²=-0.0455
   Val:   Loss=0.0958, RMSE=0.3095, R²=-0.1352
============================================================


============================================================
🔄 Round 27 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0891, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0890, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0890, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0890, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0889, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0888, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 27 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0889, RMSE=0.2982, R²=-0.0775
   Val:   Loss=0.0814, RMSE=0.2853, R²=0.0012
============================================================


📊 Round 27 Test Metrics:
   Loss: 0.0903, RMSE: 0.3005, MAE: 0.2594, R²: -0.0224

============================================================
🔄 Round 28 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0873, val=0.0875 (↓), lr=0.000001
   • Epoch   2/100: train=0.0873, val=0.0875, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0873, val=0.0875, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0873, val=0.0875, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0872, val=0.0875, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0872, val=0.0874, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0875)

============================================================
📊 Round 28 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0874, RMSE=0.2956, R²=-0.0619
   Val:   Loss=0.0875, RMSE=0.2959, R²=-0.0559
============================================================


📊 Round 28 Test Metrics:
   Loss: 0.0903, RMSE: 0.3005, MAE: 0.2594, R²: -0.0224

📊 Round 28 Test Metrics:
   Loss: 0.0903, RMSE: 0.3005, MAE: 0.2594, R²: -0.0224

📊 Round 28 Test Metrics:
   Loss: 0.0903, RMSE: 0.3005, MAE: 0.2594, R²: -0.0224

============================================================
🔄 Round 36 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0879, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0879, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0878, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0878, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0878, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0877, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 36 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0878, RMSE=0.2963, R²=-0.0610
   Val:   Loss=0.0858, RMSE=0.2929, R²=-0.0608
============================================================


============================================================
🔄 Round 37 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0935 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0935, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0936, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0936, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0936, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0937, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0935)

============================================================
📊 Round 37 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2931, R²=-0.0621
   Val:   Loss=0.0935, RMSE=0.3058, R²=-0.0969
============================================================


📊 Round 37 Test Metrics:
   Loss: 0.0903, RMSE: 0.3005, MAE: 0.2594, R²: -0.0224

📊 Round 37 Test Metrics:
   Loss: 0.0903, RMSE: 0.3005, MAE: 0.2594, R²: -0.0224

📊 Round 37 Test Metrics:
   Loss: 0.0903, RMSE: 0.3005, MAE: 0.2594, R²: -0.0224

============================================================
🔄 Round 42 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0980 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0980, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0979, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0979, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0979, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0978, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0980)

============================================================
📊 Round 42 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=-0.0382
   Val:   Loss=0.0980, RMSE=0.3130, R²=-0.1500
============================================================


============================================================
🔄 Round 44 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0885, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0885, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0885, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0885, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0885, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0884, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 44 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0886, RMSE=0.2976, R²=-0.0570
   Val:   Loss=0.0828, RMSE=0.2877, R²=-0.0829
============================================================


📊 Round 44 Test Metrics:
   Loss: 0.0903, RMSE: 0.3005, MAE: 0.2594, R²: -0.0224

📊 Round 44 Test Metrics:
   Loss: 0.0903, RMSE: 0.3005, MAE: 0.2594, R²: -0.0224

============================================================
🔄 Round 48 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0879, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0879, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0878, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0878, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0878, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0877, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 48 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0881, RMSE=0.2968, R²=-0.0694
   Val:   Loss=0.0848, RMSE=0.2912, R²=-0.0269
============================================================


📊 Round 48 Test Metrics:
   Loss: 0.0903, RMSE: 0.3005, MAE: 0.2594, R²: -0.0224

============================================================
🔄 Round 49 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0870, val=0.0888 (↓), lr=0.000001
   • Epoch   2/100: train=0.0870, val=0.0888, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0870, val=0.0888, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0870, val=0.0888, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0869, val=0.0889, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0868, val=0.0889, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0888)

============================================================
📊 Round 49 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0871, RMSE=0.2951, R²=-0.0709
   Val:   Loss=0.0888, RMSE=0.2980, R²=-0.0455
============================================================


📊 Round 49 Test Metrics:
   Loss: 0.0903, RMSE: 0.3005, MAE: 0.2594, R²: -0.0224

📊 Round 49 Test Metrics:
   Loss: 0.0903, RMSE: 0.3005, MAE: 0.2594, R²: -0.0224

============================================================
🔄 Round 53 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.0894 (↓), lr=0.000001
   • Epoch   2/100: train=0.0868, val=0.0894, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0867, val=0.0894, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0867, val=0.0894, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0867, val=0.0894, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0866, val=0.0894, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0894)

============================================================
📊 Round 53 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0869, RMSE=0.2948, R²=-0.0765
   Val:   Loss=0.0894, RMSE=0.2991, R²=-0.0107
============================================================


📊 Round 53 Test Metrics:
   Loss: 0.0903, RMSE: 0.3005, MAE: 0.2594, R²: -0.0223

📊 Round 53 Test Metrics:
   Loss: 0.0903, RMSE: 0.3005, MAE: 0.2594, R²: -0.0223

============================================================
🔄 Round 57 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0890, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0890, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0890, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0890, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0890, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0888, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 57 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0886, RMSE=0.2977, R²=-0.0660
   Val:   Loss=0.0826, RMSE=0.2874, R²=-0.0388
============================================================


============================================================
🔄 Round 58 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0876, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0876, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0875, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0875, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0875, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0874, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 58 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0878, RMSE=0.2962, R²=-0.0524
   Val:   Loss=0.0861, RMSE=0.2934, R²=-0.1037
============================================================


📊 Round 58 Test Metrics:
   Loss: 0.0903, RMSE: 0.3005, MAE: 0.2594, R²: -0.0223

============================================================
🔄 Round 60 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0885, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0885, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0885, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0885, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0885, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0884, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 60 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0883, RMSE=0.2971, R²=-0.0733
   Val:   Loss=0.0841, RMSE=0.2899, R²=-0.0134
============================================================


============================================================
🔄 Round 61 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0894, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0894, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0893, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0893, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0893, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0892, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 61 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0895, RMSE=0.2991, R²=-0.0773
   Val:   Loss=0.0792, RMSE=0.2814, R²=-0.0034
============================================================


============================================================
🔄 Round 65 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0873, val=0.0888 (↓), lr=0.000001
   • Epoch   2/100: train=0.0873, val=0.0888, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0873, val=0.0888, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0872, val=0.0888, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0872, val=0.0888, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0871, val=0.0888, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0888)

============================================================
📊 Round 65 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0871, RMSE=0.2951, R²=-0.0629
   Val:   Loss=0.0888, RMSE=0.2980, R²=-0.0741
============================================================


📊 Round 65 Test Metrics:
   Loss: 0.0903, RMSE: 0.3005, MAE: 0.2594, R²: -0.0223

📊 Round 65 Test Metrics:
   Loss: 0.0903, RMSE: 0.3005, MAE: 0.2594, R²: -0.0223

============================================================
🔄 Round 69 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0884, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0884, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0883, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0883, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0883, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0882, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 69 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0883, RMSE=0.2972, R²=-0.0640
   Val:   Loss=0.0838, RMSE=0.2895, R²=-0.0566
============================================================


📊 Round 69 Test Metrics:
   Loss: 0.0903, RMSE: 0.3005, MAE: 0.2594, R²: -0.0223

📊 Round 69 Test Metrics:
   Loss: 0.0903, RMSE: 0.3005, MAE: 0.2594, R²: -0.0223

============================================================
🔄 Round 71 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0889, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0889, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0888, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0888, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0888, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0887, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 71 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0887, RMSE=0.2978, R²=-0.0593
   Val:   Loss=0.0825, RMSE=0.2872, R²=-0.0678
============================================================


============================================================
🔄 Round 75 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0892, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0892, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0892, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0891, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0891, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0890, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 75 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0891, RMSE=0.2985, R²=-0.0621
   Val:   Loss=0.0808, RMSE=0.2842, R²=-0.0559
============================================================


📊 Round 75 Test Metrics:
   Loss: 0.0903, RMSE: 0.3005, MAE: 0.2594, R²: -0.0223

============================================================
🔄 Round 76 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0951 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0951, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0951, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0951, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0951, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0950, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0951)

============================================================
📊 Round 76 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2924, R²=-0.0583
   Val:   Loss=0.0951, RMSE=0.3085, R²=-0.0699
============================================================


📊 Round 76 Test Metrics:
   Loss: 0.0903, RMSE: 0.3005, MAE: 0.2594, R²: -0.0223

============================================================
🔄 Round 77 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0872, val=0.0874 (↓), lr=0.000001
   • Epoch   2/100: train=0.0872, val=0.0874, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0872, val=0.0874, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0872, val=0.0874, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0872, val=0.0874, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0871, val=0.0873, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0874)

============================================================
📊 Round 77 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0874, RMSE=0.2957, R²=-0.0600
   Val:   Loss=0.0874, RMSE=0.2957, R²=-0.0646
============================================================


============================================================
🔄 Round 79 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0879, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0878, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0878, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0878, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0878, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0877, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 79 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0879, RMSE=0.2965, R²=-0.0560
   Val:   Loss=0.0855, RMSE=0.2924, R²=-0.0953
============================================================


============================================================
🔄 Round 80 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0870, val=0.0909 (↓), lr=0.000001
   • Epoch   2/100: train=0.0870, val=0.0909, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0869, val=0.0909, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0869, val=0.0909, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0869, val=0.0909, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0868, val=0.0908, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0909)

============================================================
📊 Round 80 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2942, R²=-0.0544
   Val:   Loss=0.0909, RMSE=0.3015, R²=-0.0879
============================================================


============================================================
🔄 Round 81 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0909 (↓), lr=0.000001
   • Epoch   2/100: train=0.0867, val=0.0908, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0908, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0908, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0908, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0907, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0909)

============================================================
📊 Round 81 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2942, R²=-0.0541
   Val:   Loss=0.0909, RMSE=0.3014, R²=-0.0881
============================================================


📊 Round 81 Test Metrics:
   Loss: 0.0903, RMSE: 0.3005, MAE: 0.2594, R²: -0.0223

============================================================
🔄 Round 83 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0882, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0881, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0881, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0881, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0881, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0880, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 83 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0884, RMSE=0.2974, R²=-0.0605
   Val:   Loss=0.0834, RMSE=0.2887, R²=-0.0622
============================================================


📊 Round 83 Test Metrics:
   Loss: 0.0903, RMSE: 0.3005, MAE: 0.2594, R²: -0.0223

📊 Round 83 Test Metrics:
   Loss: 0.0903, RMSE: 0.3005, MAE: 0.2594, R²: -0.0223

============================================================
🔄 Round 87 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0888, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0888, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0887, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0887, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0887, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0886, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 87 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0887, RMSE=0.2979, R²=-0.0600
   Val:   Loss=0.0822, RMSE=0.2867, R²=-0.0672
============================================================


============================================================
🔄 Round 88 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0881, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0881, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0881, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0880, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0880, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0879, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 88 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0878, RMSE=0.2964, R²=-0.0596
   Val:   Loss=0.0858, RMSE=0.2928, R²=-0.0670
============================================================


📊 Round 88 Test Metrics:
   Loss: 0.0903, RMSE: 0.3005, MAE: 0.2594, R²: -0.0223

📊 Round 88 Test Metrics:
   Loss: 0.0903, RMSE: 0.3005, MAE: 0.2594, R²: -0.0223

============================================================
🔄 Round 92 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0881, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0881, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0881, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0881, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0881, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0880, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 92 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0880, RMSE=0.2966, R²=-0.0559
   Val:   Loss=0.0852, RMSE=0.2919, R²=-0.0823
============================================================


============================================================
🔄 Round 93 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0963 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0963, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0963, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0962, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0962, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0962, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0963)

============================================================
📊 Round 93 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2919, R²=-0.0536
   Val:   Loss=0.0963, RMSE=0.3103, R²=-0.0897
============================================================


📊 Round 93 Test Metrics:
   Loss: 0.0903, RMSE: 0.3005, MAE: 0.2594, R²: -0.0223

📊 Round 93 Test Metrics:
   Loss: 0.0903, RMSE: 0.3005, MAE: 0.2593, R²: -0.0223

============================================================
🔄 Round 100 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0883, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0883, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0882, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0882, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0882, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0881, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 100 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0883, RMSE=0.2972, R²=-0.0558
   Val:   Loss=0.0840, RMSE=0.2897, R²=-0.0971
============================================================


📊 Round 100 Test Metrics:
   Loss: 0.0903, RMSE: 0.3005, MAE: 0.2593, R²: -0.0223

============================================================
🔄 Round 102 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0902, val=0.0757 (↓), lr=0.000001
   • Epoch   2/100: train=0.0902, val=0.0757, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0902, val=0.0757, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0902, val=0.0757, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0902, val=0.0757, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0901, val=0.0756, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0757)

============================================================
📊 Round 102 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0904, RMSE=0.3006, R²=-0.0659
   Val:   Loss=0.0757, RMSE=0.2751, R²=-0.0456
============================================================


============================================================
🔄 Round 103 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0897, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0896, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0896, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0896, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0896, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0895, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 103 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0896, RMSE=0.2994, R²=-0.0588
   Val:   Loss=0.0787, RMSE=0.2805, R²=-0.0715
============================================================


============================================================
🔄 Round 105 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0983 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0983, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0983, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0983, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0983, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0982, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0983)

============================================================
📊 Round 105 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2911, R²=-0.0664
   Val:   Loss=0.0983, RMSE=0.3136, R²=-0.0424
============================================================


============================================================
🔄 Round 106 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0883, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0883, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0883, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0883, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0883, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0882, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 106 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0882, RMSE=0.2970, R²=-0.0668
   Val:   Loss=0.0843, RMSE=0.2904, R²=-0.0400
============================================================


============================================================
🔄 Round 109 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0863, val=0.0910 (↓), lr=0.000001
   • Epoch   2/100: train=0.0863, val=0.0910, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0863, val=0.0910, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0910, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0910, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0909, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0910)

============================================================
📊 Round 109 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2942, R²=-0.0520
   Val:   Loss=0.0910, RMSE=0.3017, R²=-0.0988
============================================================


📊 Round 109 Test Metrics:
   Loss: 0.0903, RMSE: 0.3005, MAE: 0.2593, R²: -0.0222

📊 Round 109 Test Metrics:
   Loss: 0.0903, RMSE: 0.3005, MAE: 0.2593, R²: -0.0222

============================================================
🔄 Round 115 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.0907 (↓), lr=0.000001
   • Epoch   2/100: train=0.0868, val=0.0907, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0867, val=0.0907, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0867, val=0.0907, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0867, val=0.0907, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0866, val=0.0906, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0907)

============================================================
📊 Round 115 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2943, R²=-0.0511
   Val:   Loss=0.0907, RMSE=0.3012, R²=-0.1027
============================================================


📊 Round 115 Test Metrics:
   Loss: 0.0903, RMSE: 0.3005, MAE: 0.2593, R²: -0.0222

============================================================
🔄 Round 117 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0893, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0893, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0893, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0893, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0892, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0891, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 117 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0895, RMSE=0.2991, R²=-0.0701
   Val:   Loss=0.0794, RMSE=0.2818, R²=-0.0231
============================================================


============================================================
🔄 Round 118 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.1021 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.1021, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.1022, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.1023, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.1023, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.1027, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.1021)

============================================================
📊 Round 118 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=-0.0740
   Val:   Loss=0.1021, RMSE=0.3195, R²=-0.1242
============================================================


📊 Round 118 Test Metrics:
   Loss: 0.0903, RMSE: 0.3005, MAE: 0.2593, R²: -0.0222

============================================================
🔄 Round 122 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0890, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0890, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0890, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0890, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0889, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0889, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 122 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0890, RMSE=0.2984, R²=-0.0519
   Val:   Loss=0.0811, RMSE=0.2848, R²=-0.1233
============================================================


📊 Round 122 Test Metrics:
   Loss: 0.0903, RMSE: 0.3005, MAE: 0.2593, R²: -0.0222

============================================================
🔄 Round 125 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.0901 (↓), lr=0.000001
   • Epoch   2/100: train=0.0868, val=0.0901, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0868, val=0.0901, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0868, val=0.0901, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0867, val=0.0901, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0866, val=0.0901, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0901)

============================================================
📊 Round 125 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2946, R²=-0.0719
   Val:   Loss=0.0901, RMSE=0.3001, R²=-0.0295
============================================================


============================================================
🔄 Round 126 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.0884 (↓), lr=0.000001
   • Epoch   2/100: train=0.0868, val=0.0884, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0868, val=0.0884, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0868, val=0.0884, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0868, val=0.0884, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0867, val=0.0884, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0884)

============================================================
📊 Round 126 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0872, RMSE=0.2953, R²=-0.0737
   Val:   Loss=0.0884, RMSE=0.2974, R²=-0.0235
============================================================


📊 Round 126 Test Metrics:
   Loss: 0.0903, RMSE: 0.3005, MAE: 0.2593, R²: -0.0222

============================================================
🔄 Round 128 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0905 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0905, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0905, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0905, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0905, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0904, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0905)

============================================================
📊 Round 128 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0867, RMSE=0.2944, R²=-0.0566
   Val:   Loss=0.0905, RMSE=0.3009, R²=-0.0869
============================================================


============================================================
🔄 Round 129 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0882, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0882, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0882, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0882, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0882, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0881, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 129 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0880, RMSE=0.2967, R²=-0.0527
   Val:   Loss=0.0852, RMSE=0.2918, R²=-0.0974
============================================================


📊 Round 129 Test Metrics:
   Loss: 0.0903, RMSE: 0.3005, MAE: 0.2593, R²: -0.0222

============================================================
🔄 Round 130 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0913 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0913, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0913, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0863, val=0.0912, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0863, val=0.0912, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0912, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0913)

============================================================
📊 Round 130 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2941, R²=-0.0597
   Val:   Loss=0.0913, RMSE=0.3021, R²=-0.0662
============================================================


============================================================
🔄 Round 133 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0901, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0901, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0901, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0901, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0901, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0900, val=0.0774, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 133 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0899, RMSE=0.2999, R²=-0.0613
   Val:   Loss=0.0775, RMSE=0.2784, R²=-0.0619
============================================================


📊 Round 133 Test Metrics:
   Loss: 0.0903, RMSE: 0.3005, MAE: 0.2593, R²: -0.0222

📊 Round 133 Test Metrics:
   Loss: 0.0903, RMSE: 0.3005, MAE: 0.2593, R²: -0.0222

============================================================
🔄 Round 137 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0873, val=0.0872 (↓), lr=0.000001
   • Epoch   2/100: train=0.0873, val=0.0872, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0873, val=0.0872, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0873, val=0.0872, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0873, val=0.0872, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0872, val=0.0871, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0872)

============================================================
📊 Round 137 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0875, RMSE=0.2958, R²=-0.0560
   Val:   Loss=0.0872, RMSE=0.2954, R²=-0.0830
============================================================


📊 Round 137 Test Metrics:
   Loss: 0.0903, RMSE: 0.3005, MAE: 0.2593, R²: -0.0222

============================================================
🔄 Round 139 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0947 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0947, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0947, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0947, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0947, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0947, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0947)

============================================================
📊 Round 139 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2926, R²=-0.0601
   Val:   Loss=0.0947, RMSE=0.3077, R²=-0.0736
============================================================


============================================================
🔄 Round 145 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0888, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0888, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0888, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0888, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0888, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0887, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 145 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0886, RMSE=0.2977, R²=-0.0571
   Val:   Loss=0.0827, RMSE=0.2876, R²=-0.0993
============================================================


📊 Round 145 Test Metrics:
   Loss: 0.0903, RMSE: 0.3005, MAE: 0.2593, R²: -0.0221

📊 Round 145 Test Metrics:
   Loss: 0.0903, RMSE: 0.3005, MAE: 0.2593, R²: -0.0221

============================================================
🔄 Round 150 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0891, val=0.0824 (↓), lr=0.000001
   • Epoch   2/100: train=0.0891, val=0.0824, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0891, val=0.0824, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0891, val=0.0824, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0891, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0890, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0824)

============================================================
📊 Round 150 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0887, RMSE=0.2978, R²=-0.0594
   Val:   Loss=0.0824, RMSE=0.2871, R²=-0.0715
============================================================


============================================================
🔄 Round 151 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0873, val=0.0868 (↓), lr=0.000001
   • Epoch   2/100: train=0.0873, val=0.0868, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0872, val=0.0868, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0872, val=0.0868, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0872, val=0.0868, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0871, val=0.0867, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0868)

============================================================
📊 Round 151 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0876, RMSE=0.2960, R²=-0.0620
   Val:   Loss=0.0868, RMSE=0.2946, R²=-0.0576
============================================================


============================================================
🔄 Round 153 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0878, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0878, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0878, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0878, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0878, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0877, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 153 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0879, RMSE=0.2965, R²=-0.0641
   Val:   Loss=0.0857, RMSE=0.2927, R²=-0.0493
============================================================


📊 Round 153 Test Metrics:
   Loss: 0.0903, RMSE: 0.3005, MAE: 0.2593, R²: -0.0221

============================================================
🔄 Round 156 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0874, val=0.0873 (↓), lr=0.000001
   • Epoch   2/100: train=0.0874, val=0.0873, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0874, val=0.0873, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0874, val=0.0873, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0874, val=0.0873, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0873, val=0.0873, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0873)

============================================================
📊 Round 156 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0875, RMSE=0.2958, R²=-0.0704
   Val:   Loss=0.0873, RMSE=0.2955, R²=-0.0299
============================================================


============================================================
🔄 Round 158 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0869, val=0.0897 (↓), lr=0.000001
   • Epoch   2/100: train=0.0869, val=0.0897, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0869, val=0.0896, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0869, val=0.0896, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0868, val=0.0896, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0868, val=0.0896, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0897)

============================================================
📊 Round 158 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0869, RMSE=0.2948, R²=-0.0597
   Val:   Loss=0.0897, RMSE=0.2994, R²=-0.0667
============================================================


📊 Round 158 Test Metrics:
   Loss: 0.0903, RMSE: 0.3005, MAE: 0.2593, R²: -0.0221

============================================================
🔄 Round 159 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0953 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0952, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0952, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0952, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0952, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0952, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0953)

============================================================
📊 Round 159 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2924, R²=-0.0658
   Val:   Loss=0.0953, RMSE=0.3086, R²=-0.0448
============================================================


============================================================
🔄 Round 160 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0905 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0905, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0905, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0905, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0905, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0906, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0905)

============================================================
📊 Round 160 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0867, RMSE=0.2944, R²=-0.0582
   Val:   Loss=0.0905, RMSE=0.3009, R²=-0.0801
============================================================


============================================================
🔄 Round 163 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0931 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0931, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0931, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0931, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0931, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0931, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0931)

============================================================
📊 Round 163 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2933, R²=-0.0664
   Val:   Loss=0.0931, RMSE=0.3052, R²=-0.0502
============================================================


📊 Round 163 Test Metrics:
   Loss: 0.0903, RMSE: 0.3005, MAE: 0.2593, R²: -0.0221

============================================================
🔄 Round 164 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0874, val=0.0880 (↓), lr=0.000001
   • Epoch   2/100: train=0.0873, val=0.0880, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0873, val=0.0880, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0873, val=0.0880, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0873, val=0.0880, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0872, val=0.0879, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0880)

============================================================
📊 Round 164 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0873, RMSE=0.2955, R²=-0.0618
   Val:   Loss=0.0880, RMSE=0.2966, R²=-0.0627
============================================================


============================================================
🔄 Round 165 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0920 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0920, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0920, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0920, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0920, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0919, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0920)

============================================================
📊 Round 165 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2938, R²=-0.0609
   Val:   Loss=0.0920, RMSE=0.3033, R²=-0.0887
============================================================


📊 Round 165 Test Metrics:
   Loss: 0.0903, RMSE: 0.3005, MAE: 0.2593, R²: -0.0220

============================================================
🔄 Round 167 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0889, val=0.0837 (↓), lr=0.000001
   • Epoch   2/100: train=0.0888, val=0.0837, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0888, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0888, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0888, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0887, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0837)

============================================================
📊 Round 167 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0884, RMSE=0.2973, R²=-0.0719
   Val:   Loss=0.0837, RMSE=0.2892, R²=-0.0188
============================================================


============================================================
🔄 Round 168 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0881, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0881, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0880, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0880, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0880, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0879, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 168 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0878, RMSE=0.2964, R²=-0.0658
   Val:   Loss=0.0860, RMSE=0.2932, R²=-0.0463
============================================================


============================================================
🔄 Round 170 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0886, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0885, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0885, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0885, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0885, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0884, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 170 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0886, RMSE=0.2977, R²=-0.0737
   Val:   Loss=0.0829, RMSE=0.2879, R²=-0.0180
============================================================


📊 Round 170 Test Metrics:
   Loss: 0.0903, RMSE: 0.3005, MAE: 0.2592, R²: -0.0220

📊 Round 170 Test Metrics:
   Loss: 0.0903, RMSE: 0.3005, MAE: 0.2592, R²: -0.0220

============================================================
🔄 Round 174 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0877, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0877, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0877, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0876, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0876, val=0.0861, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0876, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 174 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0878, RMSE=0.2963, R²=-0.0557
   Val:   Loss=0.0861, RMSE=0.2935, R²=-0.0891
============================================================


============================================================
🔄 Round 175 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.1004 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.1003, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.1003, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.1003, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.1003, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.1002, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.1004)

============================================================
📊 Round 175 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2903, R²=-0.0454
   Val:   Loss=0.1004, RMSE=0.3168, R²=-0.1186
============================================================


📊 Round 175 Test Metrics:
   Loss: 0.0903, RMSE: 0.3005, MAE: 0.2592, R²: -0.0220

============================================================
🔄 Round 176 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0914 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0914, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0914, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0914, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0914, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0913, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0914)

============================================================
📊 Round 176 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2941, R²=-0.0511
   Val:   Loss=0.0914, RMSE=0.3024, R²=-0.1016
============================================================


📊 Round 176 Test Metrics:
   Loss: 0.0903, RMSE: 0.3005, MAE: 0.2592, R²: -0.0220

📊 Round 176 Test Metrics:
   Loss: 0.0903, RMSE: 0.3005, MAE: 0.2592, R²: -0.0220

============================================================
🔄 Round 178 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0873, val=0.0870 (↓), lr=0.000001
   • Epoch   2/100: train=0.0873, val=0.0869, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0873, val=0.0869, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0873, val=0.0869, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0873, val=0.0869, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0872, val=0.0869, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 178 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0876, RMSE=0.2960, R²=-0.0662
   Val:   Loss=0.0870, RMSE=0.2949, R²=-0.0484
============================================================


📊 Round 178 Test Metrics:
   Loss: 0.0903, RMSE: 0.3005, MAE: 0.2592, R²: -0.0220

📊 Round 178 Test Metrics:
   Loss: 0.0903, RMSE: 0.3005, MAE: 0.2592, R²: -0.0220

📊 Round 178 Test Metrics:
   Loss: 0.0903, RMSE: 0.3005, MAE: 0.2592, R²: -0.0220

============================================================
🔄 Round 182 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0907 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0907, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0907, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0907, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0907, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0906, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0907)

============================================================
📊 Round 182 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0867, RMSE=0.2944, R²=-0.0660
   Val:   Loss=0.0907, RMSE=0.3012, R²=-0.0434
============================================================


📊 Round 182 Test Metrics:
   Loss: 0.0903, RMSE: 0.3005, MAE: 0.2592, R²: -0.0220

📊 Round 182 Test Metrics:
   Loss: 0.0903, RMSE: 0.3005, MAE: 0.2592, R²: -0.0219

📊 Round 182 Test Metrics:
   Loss: 0.0903, RMSE: 0.3005, MAE: 0.2592, R²: -0.0219

============================================================
🔄 Round 188 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0896, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0896, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0896, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0896, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0895, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0895, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 188 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0897, RMSE=0.2995, R²=-0.0518
   Val:   Loss=0.0785, RMSE=0.2802, R²=-0.1192
============================================================


📊 Round 188 Test Metrics:
   Loss: 0.0903, RMSE: 0.3005, MAE: 0.2592, R²: -0.0219

============================================================
🔄 Round 190 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0875, val=0.0868 (↓), lr=0.000001
   • Epoch   2/100: train=0.0875, val=0.0868, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0874, val=0.0868, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0874, val=0.0868, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0874, val=0.0868, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0873, val=0.0868, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0868)

============================================================
📊 Round 190 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0876, RMSE=0.2960, R²=-0.0520
   Val:   Loss=0.0868, RMSE=0.2947, R²=-0.1248
============================================================


============================================================
🔄 Round 191 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0949 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0949, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0949, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0948, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0948, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0948, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0949)

============================================================
📊 Round 191 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2926, R²=-0.0508
   Val:   Loss=0.0949, RMSE=0.3080, R²=-0.1042
============================================================


📊 Round 191 Test Metrics:
   Loss: 0.0903, RMSE: 0.3005, MAE: 0.2592, R²: -0.0219

📊 Round 191 Test Metrics:
   Loss: 0.0903, RMSE: 0.3005, MAE: 0.2592, R²: -0.0219

============================================================
🔄 Round 194 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0883, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0883, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0883, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0883, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0882, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0882, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 194 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0881, RMSE=0.2968, R²=-0.0633
   Val:   Loss=0.0850, RMSE=0.2915, R²=-0.0596
============================================================


📊 Round 194 Test Metrics:
   Loss: 0.0903, RMSE: 0.3005, MAE: 0.2592, R²: -0.0219

📊 Round 194 Test Metrics:
   Loss: 0.0903, RMSE: 0.3005, MAE: 0.2592, R²: -0.0219

📊 Round 194 Test Metrics:
   Loss: 0.0903, RMSE: 0.3005, MAE: 0.2592, R²: -0.0219

📊 Round 194 Test Metrics:
   Loss: 0.0903, RMSE: 0.3005, MAE: 0.2592, R²: -0.0218

📊 Round 194 Test Metrics:
   Loss: 0.0903, RMSE: 0.3005, MAE: 0.2592, R²: -0.0218

============================================================
🔄 Round 204 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0954 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0954, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0954, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0954, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0954, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0954, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0954)

============================================================
📊 Round 204 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2924, R²=-0.0583
   Val:   Loss=0.0954, RMSE=0.3088, R²=-0.1294
============================================================


============================================================
🔄 Round 205 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0958 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0957, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0957, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0957, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0957, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0956, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0958)

============================================================
📊 Round 205 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2922, R²=-0.0580
   Val:   Loss=0.0958, RMSE=0.3094, R²=-0.0850
============================================================


============================================================
🔄 Round 206 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0991 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0991, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0991, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0845, val=0.0991, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0991, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0991, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0991)

============================================================
📊 Round 206 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2908, R²=-0.0435
   Val:   Loss=0.0991, RMSE=0.3148, R²=-0.1434
============================================================


📊 Round 206 Test Metrics:
   Loss: 0.0903, RMSE: 0.3005, MAE: 0.2592, R²: -0.0218

📊 Round 206 Test Metrics:
   Loss: 0.0903, RMSE: 0.3005, MAE: 0.2592, R²: -0.0218

============================================================
🔄 Round 208 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0968 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0968, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0968, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0968, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0968, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0968, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0968)

============================================================
📊 Round 208 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2918, R²=-0.0462
   Val:   Loss=0.0968, RMSE=0.3112, R²=-0.1189
============================================================


📊 Round 208 Test Metrics:
   Loss: 0.0903, RMSE: 0.3005, MAE: 0.2592, R²: -0.0218

============================================================
🔄 Round 211 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0891, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0890, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0890, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0890, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0890, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0889, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 211 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0894, RMSE=0.2989, R²=-0.0697
   Val:   Loss=0.0799, RMSE=0.2826, R²=-0.0273
============================================================


📊 Round 211 Test Metrics:
   Loss: 0.0903, RMSE: 0.3004, MAE: 0.2592, R²: -0.0218

📊 Round 211 Test Metrics:
   Loss: 0.0903, RMSE: 0.3004, MAE: 0.2592, R²: -0.0218

============================================================
🔄 Round 215 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0948 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0948, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0948, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0948, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0948, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0947, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0948)

============================================================
📊 Round 215 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2926, R²=-0.0576
   Val:   Loss=0.0948, RMSE=0.3080, R²=-0.0760
============================================================


📊 Round 215 Test Metrics:
   Loss: 0.0903, RMSE: 0.3004, MAE: 0.2592, R²: -0.0217

============================================================
🔄 Round 217 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0869, val=0.0903 (↓), lr=0.000001
   • Epoch   2/100: train=0.0869, val=0.0903, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0869, val=0.0903, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0869, val=0.0903, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0869, val=0.0903, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0868, val=0.0902, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0903)

============================================================
📊 Round 217 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2946, R²=-0.0570
   Val:   Loss=0.0903, RMSE=0.3005, R²=-0.0871
============================================================


============================================================
🔄 Round 221 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0891, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0890, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0890, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0890, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0890, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0889, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 221 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0892, RMSE=0.2986, R²=-0.0712
   Val:   Loss=0.0807, RMSE=0.2840, R²=-0.0359
============================================================


📊 Round 221 Test Metrics:
   Loss: 0.0903, RMSE: 0.3004, MAE: 0.2592, R²: -0.0217

============================================================
🔄 Round 222 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0886, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0886, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0885, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0885, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0885, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0884, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 222 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0888, RMSE=0.2980, R²=-0.0542
   Val:   Loss=0.0822, RMSE=0.2868, R²=-0.0944
============================================================


============================================================
🔄 Round 223 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0932 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0932, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0932, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0932, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0932, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0931, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0932)

============================================================
📊 Round 223 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2933, R²=-0.0760
   Val:   Loss=0.0932, RMSE=0.3053, R²=-0.0108
============================================================


============================================================
🔄 Round 224 - Client client_69
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0878, val=0.0874 (↓), lr=0.000001
   • Epoch   2/100: train=0.0878, val=0.0873, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0878, val=0.0873, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0878, val=0.0873, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0878, val=0.0873, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0877, val=0.0873, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0874)

============================================================
📊 Round 224 Summary - Client client_69
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0875, RMSE=0.2958, R²=-0.0615
   Val:   Loss=0.0874, RMSE=0.2956, R²=-0.0786
============================================================


❌ Client client_69 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8687 {grpc_status:14, grpc_message:"Socket closed"}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8687 {grpc_status:14, grpc_message:"Socket closed"}"
>
