[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 49f8c394-4091-4f74-9a15-cbc56a384785
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 317fe087-ca7a-4c46-9b35-cd67036f877c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 90a05f33-f70f-4b4f-b057-3fdaedb1ef0b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d29e1333-f408-46a1-a03d-78fa33f8d41a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 88aa8786-b49b-4fdf-8102-1ebafb90b51e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2c7b05fe-dd8e-4ef2-a3e1-3c2c5ffed495
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b0baedf0-34f8-4fa1-a29c-b6f22ee8d0ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bfe2e3fa-0e44-4550-87b5-67139c2fb85e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c6716153-3753-4c5a-a138-cf74f683bf63
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1edbb780-676f-4b29-a94c-00280e03f698
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 50fc0e91-c863-4c24-9d4a-62b8a1a95265
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 744977c1-8262-4b9b-bb0f-12400e105c77
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c59dd2a2-8c43-49c0-8c5b-a69d61f8d663
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ce101a99-4ce8-409a-bf30-46f84986da3b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 11e5531f-c8f8-481c-b313-a32177eb3a1c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ae861501-313b-42a5-acad-283a399f2c25
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3ec50efe-946f-4036-9d08-940998243703
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ce7705e9-09ab-4354-b1c4-c9e0ff0b091a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 54772183-4f28-48c7-9626-2cad8ac16456
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ab044086-68d0-4663-8633-0f62e4269d03
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7b6fda30-621f-4022-9fba-38bfa8129ec0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 001b2d88-965f-4103-9539-989311650e5b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a7b2e57e-2c7a-4ffe-8bb2-24469c8ea214
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ed54803f-fbc9-4886-9468-7516ee904d72
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b4b83c51-6909-4d34-a150-bd5e9b7e549c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ce027b0a-abb3-447b-b1d4-db259f7769b6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6594a50c-123c-4069-9b15-aa768b63292d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6f8ec8d5-e7d4-4d61-a5a6-e836c7b4ff4a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dfd3b50b-525d-4d18-9dbe-6e96cce7ad17
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 841a1cc5-aaa8-4455-81f5-8022b3b40db0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f9d92583-dce4-4116-992f-5e9ceedb3864
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c06d3c93-c4d5-40f3-adde-ddd99ebcad4b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2e980f92-e2f8-4fcb-8102-da6e650a6207
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3efad278-de5b-4836-8739-8035f60033a0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b3b03acb-ec3f-4eb8-8fd2-5de80487edf7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c11e5860-5e92-4bbb-89db-cfa255d112cd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 174b7b33-b037-4d87-a825-186045163e55
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1d07019a-b156-4cc7-a14d-c2adc396558a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 599b5c6e-3632-422f-baf4-63ef7dc07d0c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e5d5bc3d-409b-47e0-9b27-52cec02a2828
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d56c3506-89ba-4fb7-aa19-8898a078b886
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0857e3c6-2572-4897-a579-ba507b4c1c02
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3a85fb1e-88be-492d-8109-2f96791e70f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 38bb176c-2f42-498c-b08e-0f474e462d5a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 69c36639-4935-424b-b260-1df5f3728eac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 89866833-5fb1-4326-8f57-5d94452cda1e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2fcdf963-c47a-448b-b44a-3723330e6003
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 36eb4f3c-9c2b-45e9-8ce1-216ef6d01154
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2acee3e2-a742-4f5d-82d0-4182bda4a779
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f6844a23-7422-4094-b3ec-7f2dcb618c4d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7578cfcb-6b7f-4424-bc30-79e93aeadd64
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e7f60273-05da-4dfe-b682-f717cc4d9129
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6c8ec8be-af97-4a07-ad0f-ffeb6674b55d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6fe0dd87-93db-4656-a294-46717cb72b81
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c15c7191-5290-4eb0-8968-47e90f82c07f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9affc7fa-44b2-41da-9dc7-7143b680116a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f2d13131-4d57-4d9d-9a8d-6c285d53bb8f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 310c87a7-9bf7-431c-969b-fc54a22eef69
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b65573e9-74bd-4cc3-8a4a-d29788b12d26
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cd8fd464-6e90-40fb-ba58-1a582c30c11f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3a3b9b2c-0ad4-4536-9642-61c358b7ef26
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c18e5af1-fca7-44e7-a1ca-59698644926e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 45b3dad7-df50-46be-846e-30b9870e25b7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 957c7f51-16cd-47e7-b014-3cb236243085
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3a9dee35-1372-4807-9995-3ce28e2cfaf5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 44a0fe99-7abc-4907-ae4c-c8ea65dc9b36
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f2d7d21b-152b-4604-85c5-006563c10559
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cf1321a7-1c92-4bf3-a9ec-222607813168
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e247b0a3-fcd2-453b-b5c2-3ea69a0deb9e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 63b80003-9bb9-4989-8859-6ad787e77bfc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e92d7deb-8ebe-479a-b4ad-d1cbdf80041d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b2847008-12b8-4f21-859e-f14d53ad90d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1809a2c9-fdd9-445a-908e-0099c02f8e62
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2fdd18f3-a742-413e-95cc-fc57498f7c40
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5b893a64-3872-42c4-81f8-5d5a447d6391
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 031a11f4-4ce1-4f33-b639-275b66a136e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 296a4cf2-12af-44a7-84d8-ce2c46f721f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a8647497-9c75-4b16-843d-45dc0bf49739
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 48472ead-d9fd-493e-9072-889e0a39557e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7bcf8371-7e62-4e3a-8986-6e2addcd6511
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6a229f82-52ed-46c5-b9d2-87ab01cfdf7b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bb2f54a5-b1fa-4dcb-be09-d0018309ba28
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 00b75f58-275e-4e88-b1d0-e8d54f4bc4b6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1ee3a3cf-3d5b-462f-8d48-08df0829e5b5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fb7ab4c0-e7ba-484a-9ccc-b1124a5ae7ce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7b9e4e57-b567-4000-bae1-7cc464779dd3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 329b2b9d-4dbe-4fdd-9eca-3cad7de7bfb5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2fe91f7e-a924-4553-9e55-04e7be33849c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0c36d07a-a895-4f9d-88f7-f48a4be833d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e032b635-3e20-4d95-84c4-85d58c9eac71
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 880c44cd-07b2-4c01-b1f9-8d670a953b18
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3a398d26-5ed3-4cbe-bec3-147de99994e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 73b01026-f4c2-45fe-8075-01cfc83112a7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 32f8c79d-2847-4562-9154-55c1544506f6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2293346c-92f0-4e60-981a-23b7a70ac0df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a8a0a1d9-1e7f-49bd-8235-7a741ede9d13
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 31ce4b61-e7aa-407b-ba70-79260c2dcea3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message acee194b-819a-4a95-b1e1-292006ad739f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 461fc68f-261d-4fcf-bd2d-801985c720e9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ae743ae7-48e9-456c-8e68-bcb56eba67cd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b9593ddc-c231-463b-8435-b83585e5d5cb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0cdb53f5-8559-4b65-a356-239439b3e665
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 93a91c60-b317-4411-a2aa-2d6b8627b360
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dc8ab28a-fa2b-4c1c-9b76-d21a3bb3859e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6bda5fc4-bee2-43c6-9584-98bd20178d8c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 73954956-2545-4bb1-bf0a-acb1cb22c07d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5639a3dc-0f9c-4eed-8e29-3fce7a39f981
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fc2e8c12-1a0e-4f25-aff3-f1fd1fe2e4ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7d93f124-66ba-4a22-915c-36e099315ca7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6931b0c7-0cf7-4333-b68f-746b56579a5b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c38a3e41-72fc-4245-b110-4f4a37193245
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message abd24498-ce32-48e9-ac7a-abf4cd11244d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 921a5438-465e-4bcb-a435-c4d475238b56
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c7bda47a-399b-4a4f-bcca-9f88b2f976da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 367a1a05-ed1a-437c-8b7b-cbb1dbc4785b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 979328ca-6236-4367-b11f-c9793eff5f0f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e329aaa3-f2f9-4918-bd3c-293c2a00ba33
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8ea514e9-2b1f-48f4-b449-795b24436c0e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a5ca6d79-7c93-4dab-9e97-d874764293a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8f2ac6bb-679c-48e0-b9b8-a31fa05ac4c4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 340eec2c-9f1e-4410-a880-13ad42a18ca1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d82964f6-1a7c-44d8-8e16-92e1aa6f8927
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fdece495-a2af-43ec-b917-61339cebe4fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c8ef0781-4128-43cb-8c9f-49d7380003e2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2dfb176f-3bb6-4e7a-8c43-950010c792d8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d8132cc2-7c3c-4c69-8228-17523a5355ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8af58f2b-ae3e-478e-9d03-6fcd28e6a233
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 00f8d1ea-a3a7-4b61-ad6a-609b842397bb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f01f050a-bf8a-4a5b-9bff-7d9028f5a3c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f8ebce14-79bb-4f55-97bc-9c5def598c78
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 01164f59-0618-4fb8-8c54-c86e22ec9892
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 47a4018f-8b7a-4516-8d4e-e92609ac2af0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a1e7a313-b83a-407a-973a-fec053441006
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b5160b87-3a27-4a8e-a367-4f545d33a301
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eedb9933-f510-4c09-9d1b-791733f39f9e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4d988248-33aa-472e-90e3-baad33e7c451
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 720f64f8-b6f7-4d8c-b9e3-9056cffb054b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f493e35e-cf20-44fb-8786-6d5c6eeb5f16
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fc777dd0-e65b-4271-8b2f-16d80182bc2c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3528c7f3-2619-47a0-a84f-2ba275cb5795
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ef3caf4c-f829-4547-88fe-7d644a18c125
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cc0bf852-30fb-434b-b48b-529da5fab748
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3c9eca96-e2ba-4fb4-8f51-43e9918d57ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e8a0bda0-c3e4-4bb8-af8d-16a179694e66
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3d7b56a5-1b25-43a8-b725-8d5d59bb7377
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 254a5b76-ce30-4a87-a5d9-62c6d17b6011
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 26dbc4bf-7ad1-4ce4-ba6e-5b185340eef7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message df0b3bc2-ce62-41a9-a9b3-9538e57119e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a7c4df28-d65f-4f51-9606-ead06401e921
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eeb7315d-c140-4546-b647-27e4dcdb0e6e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 21bb1b81-ebed-432e-a598-dab4a459e91f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f6015ed0-dc37-4478-bce8-38e79550974c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fe3b3b2e-a7f5-487e-959c-8ca38aadfcf6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 28c8b50f-8070-4bd3-8f1a-e39b50316483
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d5f53cf9-52f7-4274-9e13-8d2c976a04b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cd842c3a-c35d-4eda-8833-868f76e69ea3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c44b6913-86a4-4dee-b10b-31f13431e428
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 606df4e9-bf72-4023-855b-10f8fc820ca0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1956c0ef-866e-415c-a669-45d6c7072364
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e228cf3e-65df-47ef-8139-9b1d8185479a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3b4b37d4-8308-4166-a744-48012c5e8f75
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3588d7f9-c8bb-448a-851b-c35916b4d04e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e54c5064-e586-4ded-8a35-e464f37a98d9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 56b05199-b007-4def-9678-a8cda3a02b2c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6f8ded18-093d-412e-95f2-d59682ecdc00
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f5164bca-27a7-4540-9b03-498c7a36efca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eb39ec95-3fbb-48a8-99d5-23d5285c23e1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a36db59b-9147-4d3d-a7a4-6843b7ba0086
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 88fc4bd7-1f4d-4f74-badf-b5d06b42a46d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a4f0077b-6092-4208-9b67-37146ab89675
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 095c794d-872e-4fdd-ab3b-923f74dde403
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f867d3c6-7388-4919-8606-0a77186a7551
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 699a6001-ffa0-4031-b0e4-3632330f6a33
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 016c19fc-da24-4199-b9ba-aa566cd527c7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bfef06f8-f240-4c60-ac8c-686e2d4f9b44
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dc5b6c29-b6a8-4f95-acf7-10890c367d26
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2dfb2900-45a7-4366-9e20-ec32899b577d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f8908ed5-4e3e-4c73-b657-c96a332cebd7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 109e87d6-167b-42ed-b520-19e7c31f80d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bd37f574-cf67-499d-9fa0-eb5b0654f45b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fce4e5e9-38c4-4dbe-883e-007ec445a49f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1673f505-1408-4dc1-9164-c4c3b688fd47
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 14d4c6b4-4ab5-42f8-a95a-b56ed28ee48e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d5d51acb-1baa-40d1-bc6b-b4f6c1266c2d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 17c89c65-988e-4469-a049-1bc6f5c05c5f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 94f8c6bf-7b9f-4320-82ff-d0ec3ed26908
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9f630317-17fd-4f33-afaf-ca5f87fae41f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 02ac4657-b702-4bf3-819c-59c6bc6a0718
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ecfd0030-a025-4940-bddd-32d3c023eb23
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e1f35e85-1ba0-47ba-883c-211dfd0fd819
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8687 {grpc_message:"Socket closed", grpc_status:14}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_6
Server: localhost:8687
Algorithm: FEDAVG
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_6
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_6/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_6/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_6/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_6/test_labels.txt

📊 Raw data loaded:
   Train: X=(1632, 24), y=(1632,)
   Test:  X=(409, 24), y=(409,)

⚠️  Limiting training data: 1632 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  400 samples, 5 features
✅ Client client_6 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

📊 Round 0 Test Metrics:
   Loss: 0.0803, RMSE: 0.2834, MAE: 0.2424, R²: -0.0238

📊 Round 0 Test Metrics:
   Loss: 0.0788, RMSE: 0.2807, MAE: 0.2407, R²: -0.0045

📊 Round 0 Test Metrics:
   Loss: 0.0790, RMSE: 0.2810, MAE: 0.2413, R²: -0.0065

📊 Round 0 Test Metrics:
   Loss: 0.0793, RMSE: 0.2817, MAE: 0.2420, R²: -0.0114

============================================================
🔄 Round 7 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0874 (↓), lr=0.001000
   • Epoch   2/100: train=0.0788, val=0.0875, patience=1/15, lr=0.001000
   • Epoch   3/100: train=0.0782, val=0.0878, patience=2/15, lr=0.001000
   • Epoch   4/100: train=0.0776, val=0.0881, patience=3/15, lr=0.001000
   • Epoch   5/100: train=0.0770, val=0.0887, patience=4/15, lr=0.001000
   📉 Epoch 7: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0737, val=0.0909, patience=10/15, lr=0.000500
   📉 Epoch 15: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0874)

============================================================
📊 Round 7 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0785, RMSE=0.2802, R²=0.0155
   Val:   Loss=0.0874, RMSE=0.2957, R²=-0.0335
============================================================


📊 Round 7 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2420, R²: -0.0142

============================================================
🔄 Round 9 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0776 (↓), lr=0.000250
   • Epoch   2/100: train=0.0821, val=0.0774, patience=1/15, lr=0.000250
   • Epoch   3/100: train=0.0818, val=0.0774, patience=2/15, lr=0.000250
   • Epoch   4/100: train=0.0816, val=0.0773, patience=3/15, lr=0.000250
   • Epoch   5/100: train=0.0814, val=0.0773, patience=4/15, lr=0.000250
   📉 Epoch 11: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0800, val=0.0778, patience=10/15, lr=0.000125

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 9 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000250 → 0.000125 (1 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=-0.0015
   Val:   Loss=0.0776, RMSE=0.2786, R²=-0.0109
============================================================


📊 Round 9 Test Metrics:
   Loss: 0.0798, RMSE: 0.2825, MAE: 0.2424, R²: -0.0172

============================================================
🔄 Round 11 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000125
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0869 (↓), lr=0.000125
   • Epoch   2/100: train=0.0802, val=0.0873, patience=1/15, lr=0.000125
   📉 Epoch 3: LR reduced 0.000125 → 0.000063
   • Epoch   3/100: train=0.0800, val=0.0874, patience=2/15, lr=0.000063
   • Epoch   4/100: train=0.0798, val=0.0874, patience=3/15, lr=0.000063
   • Epoch   5/100: train=0.0797, val=0.0874, patience=4/15, lr=0.000063
   📉 Epoch 11: LR reduced 0.000063 → 0.000031
   • Epoch  11/100: train=0.0792, val=0.0875, patience=10/15, lr=0.000031

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 11 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000125 → 0.000031 (2 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=-0.0059
   Val:   Loss=0.0869, RMSE=0.2949, R²=0.0015
============================================================


📊 Round 11 Test Metrics:
   Loss: 0.0796, RMSE: 0.2822, MAE: 0.2424, R²: -0.0149

📊 Round 11 Test Metrics:
   Loss: 0.0796, RMSE: 0.2822, MAE: 0.2425, R²: -0.0153

============================================================
🔄 Round 14 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000031
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0874 (↓), lr=0.000031
   • Epoch   2/100: train=0.0797, val=0.0877, patience=1/15, lr=0.000031
   📉 Epoch 3: LR reduced 0.000031 → 0.000016
   • Epoch   3/100: train=0.0795, val=0.0880, patience=2/15, lr=0.000016
   • Epoch   4/100: train=0.0795, val=0.0881, patience=3/15, lr=0.000016
   • Epoch   5/100: train=0.0794, val=0.0881, patience=4/15, lr=0.000016
   📉 Epoch 11: LR reduced 0.000016 → 0.000008
   • Epoch  11/100: train=0.0793, val=0.0883, patience=10/15, lr=0.000008

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0874)

============================================================
📊 Round 14 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000031 → 0.000008 (2 reductions)
   Train: Loss=0.0798, RMSE=0.2824, R²=0.0004
   Val:   Loss=0.0874, RMSE=0.2956, R²=-0.0395
============================================================


📊 Round 14 Test Metrics:
   Loss: 0.0797, RMSE: 0.2823, MAE: 0.2423, R²: -0.0158

📊 Round 14 Test Metrics:
   Loss: 0.0796, RMSE: 0.2822, MAE: 0.2423, R²: -0.0150

============================================================
🔄 Round 19 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000008
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0804 (↓), lr=0.000008
   • Epoch   2/100: train=0.0817, val=0.0804, patience=1/15, lr=0.000008
   📉 Epoch 3: LR reduced 0.000008 → 0.000004
   • Epoch   3/100: train=0.0817, val=0.0805, patience=2/15, lr=0.000004
   • Epoch   4/100: train=0.0816, val=0.0805, patience=3/15, lr=0.000004
   • Epoch   5/100: train=0.0816, val=0.0805, patience=4/15, lr=0.000004
   📉 Epoch 11: LR reduced 0.000004 → 0.000002
   • Epoch  11/100: train=0.0815, val=0.0806, patience=10/15, lr=0.000002

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 19 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000008 → 0.000002 (2 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=0.0045
   Val:   Loss=0.0804, RMSE=0.2836, R²=-0.0495
============================================================


📊 Round 19 Test Metrics:
   Loss: 0.0796, RMSE: 0.2822, MAE: 0.2422, R²: -0.0152

============================================================
🔄 Round 20 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000002
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0801 (↓), lr=0.000002
   • Epoch   2/100: train=0.0814, val=0.0801, patience=1/15, lr=0.000002
   📉 Epoch 3: LR reduced 0.000002 → 0.000001
   • Epoch   3/100: train=0.0814, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 20 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000002 → 0.000001 (1 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=-0.0039
   Val:   Loss=0.0801, RMSE=0.2831, R²=-0.0080
============================================================


📊 Round 20 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2421, R²: -0.0147

============================================================
🔄 Round 22 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 22 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=-0.0047
   Val:   Loss=0.0803, RMSE=0.2833, R²=-0.0117
============================================================


📊 Round 22 Test Metrics:
   Loss: 0.0796, RMSE: 0.2822, MAE: 0.2421, R²: -0.0149

📊 Round 22 Test Metrics:
   Loss: 0.0796, RMSE: 0.2822, MAE: 0.2421, R²: -0.0149

============================================================
🔄 Round 26 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 26 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2852, R²=-0.0051
   Val:   Loss=0.0813, RMSE=0.2851, R²=-0.0122
============================================================


============================================================
🔄 Round 28 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0765 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0765, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0765, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0765, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0765, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0765, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0765)

============================================================
📊 Round 28 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=-0.0076
   Val:   Loss=0.0765, RMSE=0.2766, R²=0.0061
============================================================


============================================================
🔄 Round 30 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 30 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2840, R²=-0.0058
   Val:   Loss=0.0840, RMSE=0.2898, R²=-0.0076
============================================================


============================================================
🔄 Round 32 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0765 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0765, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0765, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0765, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0765, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0765, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0765)

============================================================
📊 Round 32 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=-0.0088
   Val:   Loss=0.0765, RMSE=0.2766, R²=0.0112
============================================================


============================================================
🔄 Round 33 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0733 (↓), lr=0.000001
   • Epoch   2/100: train=0.0835, val=0.0733, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0733, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0733, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0733, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0733, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0733)

============================================================
📊 Round 33 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=-0.0049
   Val:   Loss=0.0733, RMSE=0.2707, R²=-0.0043
============================================================


============================================================
🔄 Round 36 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0761 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0761, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0761, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0761, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0761, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0761, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0761)

============================================================
📊 Round 36 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=-0.0038
   Val:   Loss=0.0761, RMSE=0.2759, R²=-0.0089
============================================================


📊 Round 36 Test Metrics:
   Loss: 0.0796, RMSE: 0.2822, MAE: 0.2421, R²: -0.0149

📊 Round 36 Test Metrics:
   Loss: 0.0796, RMSE: 0.2822, MAE: 0.2421, R²: -0.0149

============================================================
🔄 Round 44 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 44 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=0.0007
   Val:   Loss=0.0814, RMSE=0.2852, R²=-0.0325
============================================================


============================================================
🔄 Round 46 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0885 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0885, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0885, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0885, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0885, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0885, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0885)

============================================================
📊 Round 46 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2820, R²=-0.0025
   Val:   Loss=0.0885, RMSE=0.2974, R²=-0.0208
============================================================


📊 Round 46 Test Metrics:
   Loss: 0.0796, RMSE: 0.2822, MAE: 0.2421, R²: -0.0149

============================================================
🔄 Round 50 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 50 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=-0.0058
   Val:   Loss=0.0800, RMSE=0.2829, R²=0.0009
============================================================


📊 Round 50 Test Metrics:
   Loss: 0.0796, RMSE: 0.2822, MAE: 0.2421, R²: -0.0148

📊 Round 50 Test Metrics:
   Loss: 0.0796, RMSE: 0.2822, MAE: 0.2421, R²: -0.0148

📊 Round 50 Test Metrics:
   Loss: 0.0796, RMSE: 0.2822, MAE: 0.2421, R²: -0.0148

📊 Round 50 Test Metrics:
   Loss: 0.0796, RMSE: 0.2822, MAE: 0.2421, R²: -0.0148

============================================================
🔄 Round 56 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0868 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0868, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0868, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0868, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0868, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0868, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0868)

============================================================
📊 Round 56 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=-0.0038
   Val:   Loss=0.0868, RMSE=0.2946, R²=-0.0064
============================================================


============================================================
🔄 Round 58 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 58 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=-0.0069
   Val:   Loss=0.0831, RMSE=0.2883, R²=0.0002
============================================================


📊 Round 58 Test Metrics:
   Loss: 0.0796, RMSE: 0.2822, MAE: 0.2421, R²: -0.0148

============================================================
🔄 Round 59 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0839, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0839, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 59 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2840, R²=0.0022
   Val:   Loss=0.0839, RMSE=0.2896, R²=-0.0478
============================================================


📊 Round 59 Test Metrics:
   Loss: 0.0796, RMSE: 0.2822, MAE: 0.2421, R²: -0.0148

============================================================
🔄 Round 61 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 61 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=-0.0038
   Val:   Loss=0.0789, RMSE=0.2808, R²=-0.0070
============================================================


📊 Round 61 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2421, R²: -0.0148

📊 Round 61 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2421, R²: -0.0148

📊 Round 61 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2421, R²: -0.0148

============================================================
🔄 Round 65 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0767 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0767, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0767, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0767, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0767, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0767, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0767)

============================================================
📊 Round 65 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=-0.0062
   Val:   Loss=0.0767, RMSE=0.2770, R²=0.0040
============================================================


📊 Round 65 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2421, R²: -0.0148

📊 Round 65 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2421, R²: -0.0148

============================================================
🔄 Round 69 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 69 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2847, R²=-0.0014
   Val:   Loss=0.0821, RMSE=0.2866, R²=-0.0162
============================================================


📊 Round 69 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2421, R²: -0.0148

📊 Round 69 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2421, R²: -0.0148

📊 Round 69 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2421, R²: -0.0148

📊 Round 69 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2421, R²: -0.0148

📊 Round 69 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2421, R²: -0.0148

📊 Round 69 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2421, R²: -0.0148

📊 Round 69 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2421, R²: -0.0148

============================================================
🔄 Round 78 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0782, val=0.0939 (↓), lr=0.000001
   • Epoch   2/100: train=0.0782, val=0.0939, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0782, val=0.0939, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0782, val=0.0939, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0782, val=0.0939, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0782, val=0.0939, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0939)

============================================================
📊 Round 78 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0781, RMSE=0.2795, R²=-0.0023
   Val:   Loss=0.0939, RMSE=0.3064, R²=-0.0113
============================================================


============================================================
🔄 Round 79 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 79 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=-0.0096
   Val:   Loss=0.0823, RMSE=0.2869, R²=0.0123
============================================================


📊 Round 79 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2421, R²: -0.0148

============================================================
🔄 Round 81 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 81 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=0.0009
   Val:   Loss=0.0800, RMSE=0.2828, R²=-0.0259
============================================================


============================================================
🔄 Round 82 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0782, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 82 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0820, RMSE=0.2864, R²=-0.0067
   Val:   Loss=0.0782, RMSE=0.2797, R²=0.0063
============================================================


📊 Round 82 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2421, R²: -0.0148

============================================================
🔄 Round 86 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 86 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=-0.0114
   Val:   Loss=0.0850, RMSE=0.2915, R²=0.0178
============================================================


============================================================
🔄 Round 87 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 87 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=-0.0026
   Val:   Loss=0.0794, RMSE=0.2818, R²=-0.0145
============================================================


📊 Round 87 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2421, R²: -0.0148

============================================================
🔄 Round 88 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 88 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2859, R²=-0.0088
   Val:   Loss=0.0793, RMSE=0.2816, R²=0.0034
============================================================


============================================================
🔄 Round 89 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0777 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0777, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0777, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0777, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0777, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0777, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 89 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2866, R²=-0.0017
   Val:   Loss=0.0777, RMSE=0.2788, R²=-0.0173
============================================================


📊 Round 89 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2421, R²: -0.0148

============================================================
🔄 Round 91 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 91 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2847, R²=-0.0094
   Val:   Loss=0.0820, RMSE=0.2864, R²=0.0067
============================================================


============================================================
🔄 Round 94 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0780 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0780, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0780, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0780, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0780, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 94 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=-0.0023
   Val:   Loss=0.0780, RMSE=0.2793, R²=-0.0215
============================================================


📊 Round 94 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2421, R²: -0.0148

============================================================
🔄 Round 95 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0767 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0767, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0767, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0767, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0767, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0767, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0767)

============================================================
📊 Round 95 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2871, R²=-0.0044
   Val:   Loss=0.0767, RMSE=0.2769, R²=-0.0028
============================================================


📊 Round 95 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2421, R²: -0.0148

============================================================
🔄 Round 96 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 96 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2831, R²=-0.0053
   Val:   Loss=0.0856, RMSE=0.2927, R²=-0.0080
============================================================


📊 Round 96 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2421, R²: -0.0148

============================================================
🔄 Round 97 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0781, val=0.0930 (↓), lr=0.000001
   • Epoch   2/100: train=0.0781, val=0.0930, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0781, val=0.0930, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0781, val=0.0930, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0781, val=0.0930, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0781, val=0.0930, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0930)

============================================================
📊 Round 97 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0783, RMSE=0.2799, R²=-0.0042
   Val:   Loss=0.0930, RMSE=0.3050, R²=-0.0043
============================================================


============================================================
🔄 Round 98 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 98 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2856, R²=-0.0065
   Val:   Loss=0.0802, RMSE=0.2831, R²=0.0044
============================================================


📊 Round 98 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2421, R²: -0.0147

============================================================
🔄 Round 100 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0749 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0749, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0749, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0749, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0748, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0748, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0749)

============================================================
📊 Round 100 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=-0.0042
   Val:   Loss=0.0749, RMSE=0.2736, R²=-0.0049
============================================================


============================================================
🔄 Round 101 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0922 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0922, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0922, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0922, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0922, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0922, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0922)

============================================================
📊 Round 101 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2802, R²=-0.0079
   Val:   Loss=0.0922, RMSE=0.3036, R²=0.0077
============================================================


📊 Round 101 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2421, R²: -0.0147

📊 Round 101 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2421, R²: -0.0147

============================================================
🔄 Round 103 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0780, val=0.0942 (↓), lr=0.000001
   • Epoch   2/100: train=0.0780, val=0.0942, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0780, val=0.0942, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0780, val=0.0942, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0780, val=0.0942, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0779, val=0.0942, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0942)

============================================================
📊 Round 103 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0780, RMSE=0.2793, R²=-0.0022
   Val:   Loss=0.0942, RMSE=0.3070, R²=-0.0103
============================================================


📊 Round 103 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2421, R²: -0.0147

============================================================
🔄 Round 105 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 105 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=-0.0012
   Val:   Loss=0.0846, RMSE=0.2909, R²=-0.0153
============================================================


📊 Round 105 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2421, R²: -0.0147

📊 Round 105 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2421, R²: -0.0147

📊 Round 105 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2421, R²: -0.0147

============================================================
🔄 Round 111 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 111 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=-0.0030
   Val:   Loss=0.0860, RMSE=0.2933, R²=-0.0182
============================================================


📊 Round 111 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2421, R²: -0.0147

============================================================
🔄 Round 113 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 113 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=-0.0098
   Val:   Loss=0.0811, RMSE=0.2848, R²=0.0147
============================================================


📊 Round 113 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2421, R²: -0.0147

============================================================
🔄 Round 114 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 114 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2843, R²=0.0021
   Val:   Loss=0.0829, RMSE=0.2879, R²=-0.0306
============================================================


============================================================
🔄 Round 115 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 115 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2854, R²=-0.0026
   Val:   Loss=0.0805, RMSE=0.2837, R²=-0.0117
============================================================


📊 Round 115 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2421, R²: -0.0147

============================================================
🔄 Round 117 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0924 (↓), lr=0.000001
   • Epoch   2/100: train=0.0787, val=0.0924, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0924, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0924, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0924, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0924, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0924)

============================================================
📊 Round 117 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2801, R²=-0.0072
   Val:   Loss=0.0924, RMSE=0.3039, R²=-0.0028
============================================================


============================================================
🔄 Round 118 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0768 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0768, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0768, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0767, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0767, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0767, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0768)

============================================================
📊 Round 118 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0824, RMSE=0.2870, R²=-0.0060
   Val:   Loss=0.0768, RMSE=0.2771, R²=0.0034
============================================================


📊 Round 118 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2421, R²: -0.0147

============================================================
🔄 Round 121 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0850, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0850, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 121 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=-0.0039
   Val:   Loss=0.0850, RMSE=0.2916, R²=-0.0055
============================================================


📊 Round 121 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2421, R²: -0.0147

============================================================
🔄 Round 122 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 122 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=-0.0030
   Val:   Loss=0.0843, RMSE=0.2904, R²=-0.0516
============================================================


============================================================
🔄 Round 125 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 125 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=-0.0060
   Val:   Loss=0.0798, RMSE=0.2824, R²=-0.0106
============================================================


📊 Round 125 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2421, R²: -0.0147

📊 Round 125 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2421, R²: -0.0147

============================================================
🔄 Round 128 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0821, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0821, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0821, val=0.0773, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0821, val=0.0773, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 128 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2868, R²=-0.0010
   Val:   Loss=0.0773, RMSE=0.2780, R²=-0.0191
============================================================


📊 Round 128 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2421, R²: -0.0147

============================================================
🔄 Round 130 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0822, val=0.0770 (↓), lr=0.000001
   • Epoch   2/100: train=0.0822, val=0.0770, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0822, val=0.0770, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0770, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0770, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0770, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0770)

============================================================
📊 Round 130 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=-0.0002
   Val:   Loss=0.0770, RMSE=0.2775, R²=-0.0226
============================================================


============================================================
🔄 Round 131 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 131 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=-0.0073
   Val:   Loss=0.0823, RMSE=0.2868, R²=0.0077
============================================================


📊 Round 131 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2421, R²: -0.0146

============================================================
🔄 Round 133 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0774, val=0.0960 (↓), lr=0.000001
   • Epoch   2/100: train=0.0774, val=0.0960, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0774, val=0.0960, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0774, val=0.0960, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0774, val=0.0960, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0773, val=0.0961, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0960)

============================================================
📊 Round 133 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0776, RMSE=0.2785, R²=-0.0013
   Val:   Loss=0.0960, RMSE=0.3099, R²=-0.0122
============================================================


============================================================
🔄 Round 135 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0866 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0866, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0866, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0866, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0866, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0866)

============================================================
📊 Round 135 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=-0.0023
   Val:   Loss=0.0866, RMSE=0.2942, R²=-0.0096
============================================================


📊 Round 135 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2421, R²: -0.0146

============================================================
🔄 Round 136 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0874 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0874, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0874, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0874, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0874, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0874, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0874)

============================================================
📊 Round 136 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=0.0054
   Val:   Loss=0.0874, RMSE=0.2956, R²=-0.0390
============================================================


📊 Round 136 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2421, R²: -0.0146

============================================================
🔄 Round 137 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 137 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=-0.0057
   Val:   Loss=0.0827, RMSE=0.2876, R²=0.0006
============================================================


============================================================
🔄 Round 139 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 139 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=-0.0028
   Val:   Loss=0.0806, RMSE=0.2838, R²=-0.0089
============================================================


📊 Round 139 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2421, R²: -0.0146

📊 Round 139 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2421, R²: -0.0146

============================================================
🔄 Round 142 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0909 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0909, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0909, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0909, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0909, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0909, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0909)

============================================================
📊 Round 142 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2808, R²=-0.0092
   Val:   Loss=0.0909, RMSE=0.3015, R²=0.0123
============================================================


📊 Round 142 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2421, R²: -0.0146

📊 Round 142 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2421, R²: -0.0146

📊 Round 142 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2421, R²: -0.0146

============================================================
🔄 Round 147 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 147 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2829, R²=-0.0038
   Val:   Loss=0.0862, RMSE=0.2936, R²=-0.0074
============================================================


📊 Round 147 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2421, R²: -0.0146

============================================================
🔄 Round 148 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 148 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2861, R²=-0.0058
   Val:   Loss=0.0788, RMSE=0.2807, R²=-0.0006
============================================================


📊 Round 148 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2421, R²: -0.0145

============================================================
🔄 Round 149 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0789, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 149 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2861, R²=-0.0002
   Val:   Loss=0.0789, RMSE=0.2808, R²=-0.0221
============================================================


============================================================
🔄 Round 150 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0743 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0743, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0743, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0743, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0743, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0743, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0743)

============================================================
📊 Round 150 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2880, R²=-0.0021
   Val:   Loss=0.0743, RMSE=0.2726, R²=-0.0120
============================================================


📊 Round 150 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2421, R²: -0.0145

============================================================
🔄 Round 152 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 152 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=-0.0044
   Val:   Loss=0.0827, RMSE=0.2876, R²=-0.0024
============================================================


============================================================
🔄 Round 153 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 153 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2857, R²=-0.0102
   Val:   Loss=0.0797, RMSE=0.2823, R²=0.0215
============================================================


📊 Round 153 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2421, R²: -0.0145

============================================================
🔄 Round 154 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0729 (↓), lr=0.000001
   • Epoch   2/100: train=0.0833, val=0.0729, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0730, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0730, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0730, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0731, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0729)

============================================================
📊 Round 154 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=-0.0097
   Val:   Loss=0.0729, RMSE=0.2700, R²=-0.0082
============================================================


📊 Round 154 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2421, R²: -0.0145

📊 Round 154 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2421, R²: -0.0145

📊 Round 154 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2421, R²: -0.0145

📊 Round 154 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2421, R²: -0.0145

============================================================
🔄 Round 158 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 158 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=-0.0041
   Val:   Loss=0.0795, RMSE=0.2819, R²=-0.0195
============================================================


============================================================
🔄 Round 160 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0788 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0788, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0788)

============================================================
📊 Round 160 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2861, R²=-0.0018
   Val:   Loss=0.0788, RMSE=0.2807, R²=-0.0122
============================================================


📊 Round 160 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2421, R²: -0.0145

============================================================
🔄 Round 161 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 161 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=-0.0072
   Val:   Loss=0.0812, RMSE=0.2849, R²=-0.0036
============================================================


📊 Round 161 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2421, R²: -0.0145

============================================================
🔄 Round 162 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0845, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 162 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=-0.0016
   Val:   Loss=0.0845, RMSE=0.2906, R²=-0.0195
============================================================


============================================================
🔄 Round 163 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 163 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=-0.0001
   Val:   Loss=0.0796, RMSE=0.2821, R²=-0.0335
============================================================


📊 Round 163 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2421, R²: -0.0144

============================================================
🔄 Round 164 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0907 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0907, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0907, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0907, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0907, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0907, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0907)

============================================================
📊 Round 164 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2809, R²=-0.0089
   Val:   Loss=0.0907, RMSE=0.3011, R²=0.0104
============================================================


============================================================
🔄 Round 165 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 165 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=-0.0082
   Val:   Loss=0.0833, RMSE=0.2886, R²=-0.0003
============================================================


📊 Round 165 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2421, R²: -0.0144

============================================================
🔄 Round 169 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 169 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=-0.0072
   Val:   Loss=0.0795, RMSE=0.2819, R²=0.0105
============================================================


📊 Round 169 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2420, R²: -0.0144

📊 Round 169 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2420, R²: -0.0144

============================================================
🔄 Round 172 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 172 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=-0.0096
   Val:   Loss=0.0822, RMSE=0.2867, R²=0.0192
============================================================


📊 Round 172 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2420, R²: -0.0144

============================================================
🔄 Round 174 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0703 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0703, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0703, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0703, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0703, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0703, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0703)

============================================================
📊 Round 174 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=-0.0017
   Val:   Loss=0.0703, RMSE=0.2651, R²=-0.0129
============================================================


📊 Round 174 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2420, R²: -0.0144

📊 Round 174 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2420, R²: -0.0144

============================================================
🔄 Round 178 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 178 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2852, R²=-0.0037
   Val:   Loss=0.0808, RMSE=0.2842, R²=-0.0032
============================================================


📊 Round 178 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2420, R²: -0.0144

📊 Round 178 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2420, R²: -0.0144

============================================================
🔄 Round 183 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0861, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 183 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2829, R²=-0.0041
   Val:   Loss=0.0860, RMSE=0.2933, R²=-0.0026
============================================================


============================================================
🔄 Round 185 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 185 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2861, R²=-0.0071
   Val:   Loss=0.0787, RMSE=0.2805, R²=0.0110
============================================================


📊 Round 185 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2420, R²: -0.0144

📊 Round 185 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2420, R²: -0.0144

📊 Round 185 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2420, R²: -0.0143

============================================================
🔄 Round 192 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0921 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0921, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0920, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0920, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0920, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0920, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0921)

============================================================
📊 Round 192 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2802, R²=-0.0040
   Val:   Loss=0.0921, RMSE=0.3034, R²=-0.0055
============================================================


📊 Round 192 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2420, R²: -0.0143

📊 Round 192 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2420, R²: -0.0143

============================================================
🔄 Round 194 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 194 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=-0.0058
   Val:   Loss=0.0793, RMSE=0.2816, R²=-0.0039
============================================================


📊 Round 194 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2420, R²: -0.0143

============================================================
🔄 Round 195 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0805 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0805, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0805, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0805, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0805, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0805, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 195 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=-0.0068
   Val:   Loss=0.0805, RMSE=0.2837, R²=0.0027
============================================================


📊 Round 195 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2420, R²: -0.0143

============================================================
🔄 Round 198 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 198 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=-0.0030
   Val:   Loss=0.0848, RMSE=0.2912, R²=-0.0430
============================================================


📊 Round 198 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2420, R²: -0.0143

============================================================
🔄 Round 199 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0650 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0650, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0650, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0650, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0650, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0651, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0650)

============================================================
📊 Round 199 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2920, R²=-0.0041
   Val:   Loss=0.0650, RMSE=0.2550, R²=-0.0051
============================================================


📊 Round 199 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2420, R²: -0.0143

============================================================
🔄 Round 202 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 202 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2847, R²=-0.0074
   Val:   Loss=0.0820, RMSE=0.2863, R²=0.0115
============================================================


📊 Round 202 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2420, R²: -0.0143

============================================================
🔄 Round 208 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0825, val=0.0762 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0762, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0762, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0762, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0762, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0824, val=0.0762, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0762)

============================================================
📊 Round 208 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2872, R²=0.0002
   Val:   Loss=0.0762, RMSE=0.2760, R²=-0.0234
============================================================


============================================================
🔄 Round 209 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 209 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=-0.0050
   Val:   Loss=0.0801, RMSE=0.2830, R²=-0.0054
============================================================


📊 Round 209 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2420, R²: -0.0143

============================================================
🔄 Round 214 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 214 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=-0.0024
   Val:   Loss=0.0810, RMSE=0.2846, R²=-0.0179
============================================================


📊 Round 214 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2420, R²: -0.0143

============================================================
🔄 Round 215 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 215 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2830, R²=-0.0049
   Val:   Loss=0.0856, RMSE=0.2926, R²=0.0022
============================================================


============================================================
🔄 Round 216 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 216 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2854, R²=-0.0070
   Val:   Loss=0.0803, RMSE=0.2833, R²=-0.0027
============================================================


============================================================
🔄 Round 217 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 217 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=-0.0028
   Val:   Loss=0.0849, RMSE=0.2913, R²=-0.0155
============================================================


📊 Round 217 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2420, R²: -0.0143

============================================================
🔄 Round 220 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0813, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 220 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2850, R²=-0.0032
   Val:   Loss=0.0810, RMSE=0.2847, R²=-0.0054
============================================================


📊 Round 220 Test Metrics:
   Loss: 0.0796, RMSE: 0.2821, MAE: 0.2420, R²: -0.0143

============================================================
🔄 Round 223 - Client client_6
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0885 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0885, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0885, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0885, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0885, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0885, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0885)

============================================================
📊 Round 223 Summary - Client client_6
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2818, R²=-0.0036
   Val:   Loss=0.0885, RMSE=0.2975, R²=-0.0024
============================================================


❌ Client client_6 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8687 {grpc_message:"Socket closed", grpc_status:14}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8687 {grpc_message:"Socket closed", grpc_status:14}"
>
