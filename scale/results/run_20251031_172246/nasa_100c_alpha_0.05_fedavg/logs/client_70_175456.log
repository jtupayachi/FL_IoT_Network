[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a221407e-2f17-4abb-8307-1e66ac05d86d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e7bed6af-c994-41fc-a46c-a9e81e3738ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 521408db-39e4-4a7d-a160-b896bc193f07
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 41d62263-b583-41b8-b4d0-873291e12187
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2dd4ec7b-5e6d-4f8e-80d4-18252feba1e5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 879f7f15-be1b-4444-8f69-3551b717e00c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a4c9887e-4df1-492a-82bd-284f084e714b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d2ab330a-0467-4e25-a548-92ad5a9e0145
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9d99f263-2251-45e2-8cb7-12a31ec95be9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a15a3004-f7f3-432c-ba26-4da0d7594a07
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a8038092-f6c5-4fce-a89e-22a3f39d61d1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 21677441-3580-42c7-9454-055abc5a4a6a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a8f45364-367c-407d-ada1-aecb4d258e4e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6452a99a-ff27-47b2-8b0e-03ff78bab3a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 770422b6-ff0d-4cad-a208-f3554c8f9ee2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d2b1ce24-6737-40e8-82f9-edb59c878136
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9a193d00-d814-4d57-9c7c-8bde65fc9cf5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0b5bac84-b56a-46f0-8506-fff7d5f211ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message abe2c437-0b5e-4d0f-9286-77782527e359
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ff21e7dd-9ddf-45a7-93a6-03a4dc5caeb7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 69f654f5-7c5f-4bc6-8bd1-74a9f42e95af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 44339bf5-57cd-47a9-84a7-a1c9bbb1a28e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f3f6be38-e50a-44cf-8e04-7db132d1c98a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9703c7d4-368e-4afb-816b-efa3c57ea748
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ea7b4565-f09a-479e-a1ff-8bc272c7c839
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f4b89d41-4ded-41d9-8914-a96636288025
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4b522bb2-76e3-4a8d-b042-3f26c21a4f60
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2512a4eb-e754-4340-82e3-7a6d0eeee0e0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d2b04597-dca8-445f-ad93-849ce6fd8d8a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d26d31d7-6212-428c-b99b-36e759d40bc3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 399e1cf2-f589-485f-a448-0ab71d42028e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 184439a5-a0bc-4614-bb11-3b72e7efce6e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 555a5744-c3c9-4c1d-9143-da4e0f7b73df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 58fafc09-e345-4f2f-bc35-0343f7cf06f4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message db47bf8b-4e35-4d51-8aa2-032bf69a7f85
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a4bfe8a6-f4f2-4e83-af3b-4688a3fdcb63
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d10d67fe-59df-43cd-bf64-eee62c2800f4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b96d4781-da05-415b-a7b7-8a615caffa48
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8558b66f-124c-4f2a-9143-fdc30fa8e3e0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 535eb2d3-0cbe-4fc0-bb12-f6a7931b86b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message be3f8e85-9cd7-4a57-8ffb-51555f0757d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7bdb757e-718b-4256-822f-2ae109b61940
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ed1fa36f-b777-4e4a-b7cb-294e43a8bc78
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1b62facf-6322-4b49-b3d9-d8c41d23f6d8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0263f8c6-923e-4b8d-9652-727a2f7ae76d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 626163df-9329-4a23-aa82-58011b2d424f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c51dfa03-6437-4a0e-abba-3d9064bb1784
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7083ca27-d2b7-4cf2-9766-9292f7d14142
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 728bcd71-0cc0-4536-a20b-348fed5049e6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e2926ca3-fdda-4902-a6b3-b69c9f572b76
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d1bf4b87-2f4a-4341-84c1-4d846fc5a838
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c95b7c26-0188-4e40-9bdd-2b64e83d2ad6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 838cc31c-ed41-462f-b7ed-35c5d874bf98
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9a2066b6-4b3e-47f5-aa59-3436f21689c7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ca815ee6-2f9b-4588-988c-8833b8c2027a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 00339f3e-f37a-4519-9a58-a8c36628a425
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 89a292d7-d0b4-47df-9d23-d03b1a84c6f4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 95ed5972-511c-45da-8358-4a0b941222e8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ef868886-1cd2-4cdd-ab7a-a6cbbbffa81c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 17e5e6f7-e4c5-49b5-b094-c6090c968d33
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2c42f769-1a0f-4ea2-b95b-ecb6a66ebf92
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8961efe1-44a8-484a-abe4-1421447b8382
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d9fd5bc9-e491-4e69-a3c2-3e2e13368e0b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 59b60963-dcde-478d-880b-0d9849de82f4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 858880fe-e340-4e13-8113-9545412ef973
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 20fece93-7481-42c2-8f07-ebd1273be6b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a3e31b2d-a531-421c-9194-990ee9e5202e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ea756897-2529-4faf-9e6e-52ad533260af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c3c952bb-18a0-4134-aa77-c5aaee8f6f6c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8c01fdd6-ba79-4059-83d5-ccb09b638247
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 063ca068-06f6-469e-91db-684475d5a3f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 518ce6b6-4881-472d-bafd-7ff18649c204
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5d6529b7-02d7-4a52-9ebb-32106cc7b494
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bc385d79-daca-4d7b-92cc-6b1c4ea0758c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 821834f4-2f77-4aff-99cf-8f5aec49fd38
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6d613329-0c90-4380-8e3d-7e0422285192
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 05225aef-63f1-4ee5-8505-a8121ced42ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 168f9a85-6aca-48a1-83d3-9ec2696fd20f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e872433f-1609-4c37-8b9e-6828c6be834d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d3f1963b-487c-4291-8b3f-bb8e4b4b4ecf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ffd362e5-6d1b-48c5-a7c4-96e70c559f22
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dd476c97-9821-494f-9591-6e73c21b0e4e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eed1e37b-3477-4997-b2b5-2cc2997b8cd9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4b157dfb-31ce-4dd6-8bfd-09b520929cac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 75291af0-791c-4aec-bd2b-721878446450
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 83a69395-9d01-40f2-9e79-57dd6b9f5242
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0eb679b2-cbe3-47b0-a3c4-bd95b2cf6a2e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5dea498f-3598-4bbc-abdf-8629df25b94c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d7f11db1-78bc-4c1d-afd0-098537a9833e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f5368a66-6130-44f4-81de-d4e10ae53cdc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 724ebdde-eb92-46f8-96d9-f6b2be3455ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 39b53431-4334-44ea-bd26-c56653b8eed3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3bb12f8e-5539-4122-aec8-68133a380670
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 506fbea4-3fdb-4798-85cf-be7ff08a4f97
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 92a9f69f-e599-4f5a-a77c-870e26109e26
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 05c75ce3-33e2-485b-9c75-8d7d7f8563fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 93256c5b-2096-4015-aabb-f9091fc6c033
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 93fb1277-ef8c-4a69-badc-9f60a034c411
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e4447cd4-0737-4895-a601-4417f0cf40b7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 694787be-c86a-47c8-9af4-364e4f1bb43f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 43b306da-32ca-43d2-917b-c516a8999939
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4f7e4557-d7b5-445b-8836-28cf76be0992
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message decbe09c-7a67-4ebe-b1ad-c0abf07a3eef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5098f917-eff0-4295-8d20-890237ab5e60
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5ebe7a1a-d4f0-467d-b590-eea4c9615b91
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c8004533-afc2-433c-be64-7938eb31cd91
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c75ff104-0ba1-46da-a23e-917ca6e44630
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b2ac08cd-42e1-4fdd-838c-ce9d19c17010
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ebca2b2a-3596-407a-9382-6e4b12228634
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 376f2b76-6f18-4ee9-8e78-81907230f163
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 662f9acc-bd23-4fee-b36d-2a0c290419e6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d2bfde15-0887-4ca3-96b2-e8581f9c8a1a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 79d028be-b445-4f7a-842f-49f7197bbc21
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1a106d56-b2db-47fb-84b9-6996d1a7f31f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ebebe60d-0723-468e-be43-467e4cd9bf19
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6b47de4c-c3b8-452b-9c1d-3c7d27a4a49d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8aed990a-7a2a-4bfc-b0c7-f59ee78dc61e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7ee48ea4-1771-4277-b576-10229e275988
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7ab68576-eb89-47ed-a19f-f84ac1c669b4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0efeed47-f336-476e-ab4f-c49b451b77bc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8443f404-3bd8-49f3-bb55-80a74dbbb4ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7ce55b09-385e-4453-99d3-49bac6309064
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 03dedc62-7611-42d5-85f9-5ad4843ae686
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 87d00423-0adf-43ab-bd0d-e1506680fe1a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4e13ae81-84cd-4f42-895a-f1e94ae6acb3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 12a255d3-e770-4b3e-8bab-46035aa9a738
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8335d65c-b015-4574-b725-5df5a9d04081
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2accb654-8d2f-4ed7-89a6-cf4d456fdb86
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c986d5af-cd19-4e66-91db-82694e5a24b8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0e91aaba-b959-41e4-b272-0cc198802690
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message db860ea7-f61c-4a16-b9b8-b1682305fe71
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message db1c0115-b4c3-4a0a-b703-3ec9b69e7260
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9556b73e-0710-4884-ac8b-44be65a5c4be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 57b8c5a4-218d-4183-a134-34ac228eb4a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 26f09783-a86f-43c9-974e-d9eaf564c85a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ab833817-ed3f-48d3-9a34-5f112437b429
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4d775b25-5c74-4e55-80b5-eed215d37488
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4e57f92f-050b-4fd1-a3f2-da26d2d2e74b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f6505a46-0798-4851-b689-d33beed5b7e5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bc6ad29a-97ef-48c8-b93b-c362f0039cb5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 23c5b402-c22e-4cf3-b48b-4c7ee483711f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 05d681ec-81c7-4e39-89bc-8aed2b34afca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fae53265-4ba0-480d-ac89-421b693ced3b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8bee3dd2-39a7-4941-a0cf-fcce0433e559
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5b4b6ae1-5147-4b5a-a99e-92ae8b384809
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 034633d3-c9ff-4e9d-83b8-910fd19d495c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 98d662a4-3309-4a75-b049-b072cad40764
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c2823351-6894-44a2-9c72-a5c6419ca0d4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b120d70c-5cb1-438f-af34-47f195d68b1a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d0d58537-aadf-4ffe-81ce-a9072f093610
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0b9eb77e-5f4d-43af-ba00-fcd748346029
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7bf0e165-43fd-4283-ae34-296520962a56
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8b27340e-581b-4448-b935-6a1fbc41fcff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6689e979-509f-4b0a-b84d-e554ea99b6ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7f20c423-3fca-47db-a524-b1ae10ce6bc6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 76fd233d-9ccd-4544-93a4-303e90c69842
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3f9521ff-23f8-4e91-ab84-d9124eb6f881
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 49fcf58f-d893-4cf4-ac99-80119eed9ac7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 49cb9847-82e9-4328-8a63-c306526b31cd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1c1280f9-2bef-45ec-9553-92698f775734
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b3387dd1-105c-4c7c-a163-3bd8a798383a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d4d6cd52-f73e-4662-932c-dc0b0020e1f9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 646d0b83-88e9-48f5-9dac-82d4fdf462f2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 57710814-9502-459c-a572-f245d5c1349f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f4b04587-b8eb-4144-aef5-b1ddb867a1cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3d70b3da-cf0d-46b9-80b0-a73ee721181d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ea291740-a58a-4f13-b4e3-93830198c134
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f50ea7b4-2ac6-492e-ac27-4bec5899eb03
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 258cbf79-e356-4020-b734-ffa6cbd5b2ce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 68a254c9-2969-4245-b5e5-67a715c42041
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message aee5d322-ce31-4f4e-879b-badc069a3300
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ff7a5db1-6695-47b0-a62b-02b805e122de
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8687 {grpc_status:14, grpc_message:"Socket closed"}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_70
Server: localhost:8687
Algorithm: FEDAVG
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_70
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_70/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_70/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_70/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_70/test_labels.txt

📊 Raw data loaded:
   Train: X=(1108, 24), y=(1108,)
   Test:  X=(278, 24), y=(278,)

⚠️  Limiting training data: 1108 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  269 samples, 5 features
✅ Client client_70 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

📊 Round 0 Test Metrics:
   Loss: 0.0833, RMSE: 0.2886, MAE: 0.2483, R²: -0.0296

============================================================
🔄 Round 8 - Client client_70
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0873, val=0.0915 (↓), lr=0.001000
   ✓ Epoch   2/100: train=0.0841, val=0.0887 (↓), lr=0.001000
   • Epoch   3/100: train=0.0838, val=0.0882, patience=1/15, lr=0.001000
   ✓ Epoch   4/100: train=0.0835, val=0.0879 (↓), lr=0.001000
   • Epoch   5/100: train=0.0831, val=0.0878, patience=1/15, lr=0.001000
   • Epoch  11/100: train=0.0815, val=0.0887, patience=5/15, lr=0.001000
   📉 Epoch 12: LR reduced 0.001000 → 0.000500
   📉 Epoch 20: LR reduced 0.000500 → 0.000250
   • Epoch  21/100: train=0.0775, val=0.0905, patience=15/15, lr=0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0871)

============================================================
📊 Round 8 Summary - Client client_70
   Epochs: 21/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=0.0172
   Val:   Loss=0.0871, RMSE=0.2952, R²=0.0150
============================================================


📊 Round 8 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2482, R²: -0.0361

============================================================
🔄 Round 15 - Client client_70
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0893, val=0.0764 (↓), lr=0.000250
   • Epoch   2/100: train=0.0879, val=0.0764, patience=1/15, lr=0.000250
   • Epoch   3/100: train=0.0871, val=0.0764, patience=2/15, lr=0.000250
   • Epoch   4/100: train=0.0866, val=0.0765, patience=3/15, lr=0.000250
   • Epoch   5/100: train=0.0863, val=0.0767, patience=4/15, lr=0.000250
   📉 Epoch 8: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0850, val=0.0775, patience=10/15, lr=0.000125
   📉 Epoch 16: LR reduced 0.000125 → 0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0764)

============================================================
📊 Round 15 Summary - Client client_70
   Epochs: 16/100 (early stopped)
   LR: 0.000250 → 0.000063 (2 reductions)
   Train: Loss=0.0880, RMSE=0.2966, R²=-0.0166
   Val:   Loss=0.0764, RMSE=0.2765, R²=-0.0227
============================================================


📊 Round 15 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2481, R²: -0.0363

============================================================
🔄 Round 16 - Client client_70
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0909 (↓), lr=0.000063
   • Epoch   2/100: train=0.0851, val=0.0915, patience=1/15, lr=0.000063
   • Epoch   3/100: train=0.0847, val=0.0916, patience=2/15, lr=0.000063
   • Epoch   4/100: train=0.0843, val=0.0915, patience=3/15, lr=0.000063
   • Epoch   5/100: train=0.0840, val=0.0914, patience=4/15, lr=0.000063
   📉 Epoch 8: LR reduced 0.000063 → 0.000031
   • Epoch  11/100: train=0.0833, val=0.0916, patience=10/15, lr=0.000031
   📉 Epoch 16: LR reduced 0.000031 → 0.000016

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0909)

============================================================
📊 Round 16 Summary - Client client_70
   Epochs: 16/100 (early stopped)
   LR: 0.000063 → 0.000016 (2 reductions)
   Train: Loss=0.0852, RMSE=0.2919, R²=-0.0233
   Val:   Loss=0.0909, RMSE=0.3016, R²=-0.0619
============================================================


============================================================
🔄 Round 17 - Client client_70
   Epochs: 100, Batch: 32, LR: 0.000016
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0897 (↓), lr=0.000016
   • Epoch   2/100: train=0.0860, val=0.0896, patience=1/15, lr=0.000016
   • Epoch   3/100: train=0.0860, val=0.0895, patience=2/15, lr=0.000016
   • Epoch   4/100: train=0.0859, val=0.0894, patience=3/15, lr=0.000016
   • Epoch   5/100: train=0.0859, val=0.0893, patience=4/15, lr=0.000016
   📉 Epoch 8: LR reduced 0.000016 → 0.000008
   • Epoch  11/100: train=0.0856, val=0.0889, patience=4/15, lr=0.000008
   📉 Epoch 16: LR reduced 0.000008 → 0.000004
   • Epoch  21/100: train=0.0854, val=0.0886, patience=3/15, lr=0.000004
   📉 Epoch 24: LR reduced 0.000004 → 0.000002
   • Epoch  31/100: train=0.0853, val=0.0884, patience=13/15, lr=0.000002
   📉 Epoch 32: LR reduced 0.000002 → 0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0887)

============================================================
📊 Round 17 Summary - Client client_70
   Epochs: 33/100 (early stopped)
   LR: 0.000016 → 0.000001 (4 reductions)
   Train: Loss=0.0851, RMSE=0.2918, R²=-0.0154
   Val:   Loss=0.0887, RMSE=0.2978, R²=-0.0352
============================================================


📊 Round 17 Test Metrics:
   Loss: 0.0838, RMSE: 0.2895, MAE: 0.2482, R²: -0.0364

============================================================
🔄 Round 18 - Client client_70
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0880, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0880, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0880, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0880, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0880, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0879, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 18 Summary - Client client_70
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0875, RMSE=0.2959, R²=-0.0273
   Val:   Loss=0.0827, RMSE=0.2876, R²=-0.0326
============================================================


============================================================
🔄 Round 19 - Client client_70
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0872, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0872, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0872, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0872, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0872, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0871, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 19 Summary - Client client_70
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0874, RMSE=0.2956, R²=-0.0255
   Val:   Loss=0.0834, RMSE=0.2889, R²=-0.0428
============================================================


📊 Round 19 Test Metrics:
   Loss: 0.0838, RMSE: 0.2896, MAE: 0.2481, R²: -0.0366

============================================================
🔄 Round 22 - Client client_70
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0875 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0875, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0875, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0875, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0875, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0875, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0875)

============================================================
📊 Round 22 Summary - Client client_70
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2939, R²=-0.0253
   Val:   Loss=0.0875, RMSE=0.2958, R²=-0.0427
============================================================


============================================================
🔄 Round 23 - Client client_70
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0901, val=0.0728 (↓), lr=0.000001
   • Epoch   2/100: train=0.0901, val=0.0728, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0901, val=0.0728, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0901, val=0.0728, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0901, val=0.0728, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0901, val=0.0728, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0728)

============================================================
📊 Round 23 Summary - Client client_70
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0900, RMSE=0.3001, R²=-0.0318
   Val:   Loss=0.0728, RMSE=0.2698, R²=-0.0149
============================================================


📊 Round 23 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2481, R²: -0.0386

📊 Round 23 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2481, R²: -0.0387

============================================================
🔄 Round 26 - Client client_70
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0873, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0873, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0873, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0873, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0873, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0872, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 26 Summary - Client client_70
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0870, RMSE=0.2950, R²=-0.0282
   Val:   Loss=0.0849, RMSE=0.2913, R²=-0.0297
============================================================


📊 Round 26 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2481, R²: -0.0386

============================================================
🔄 Round 30 - Client client_70
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0878 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0878, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0878, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0878, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0878, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0878, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0878)

============================================================
📊 Round 30 Summary - Client client_70
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2937, R²=-0.0293
   Val:   Loss=0.0878, RMSE=0.2964, R²=-0.0281
============================================================


📊 Round 30 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2481, R²: -0.0386

============================================================
🔄 Round 31 - Client client_70
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0872, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0872, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0872, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0872, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0872, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0872, val=0.0849, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 31 Summary - Client client_70
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0870, RMSE=0.2950, R²=-0.0294
   Val:   Loss=0.0849, RMSE=0.2914, R²=-0.0291
============================================================


📊 Round 31 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2481, R²: -0.0386

============================================================
🔄 Round 32 - Client client_70
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0881, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0881, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0880, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0880, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0880, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0880, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 32 Summary - Client client_70
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0879, RMSE=0.2964, R²=-0.0312
   Val:   Loss=0.0815, RMSE=0.2854, R²=-0.0177
============================================================


📊 Round 32 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2481, R²: -0.0386

============================================================
🔄 Round 34 - Client client_70
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0874, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0874, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0874, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0874, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0874, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0873, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 34 Summary - Client client_70
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0877, RMSE=0.2961, R²=-0.0335
   Val:   Loss=0.0823, RMSE=0.2869, R²=-0.0087
============================================================


📊 Round 34 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2481, R²: -0.0386

📊 Round 34 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2481, R²: -0.0386

📊 Round 34 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2481, R²: -0.0386

📊 Round 34 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2481, R²: -0.0386

📊 Round 34 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2481, R²: -0.0386

============================================================
🔄 Round 40 - Client client_70
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0884 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0884, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0884, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0884, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0884, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0884, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0884)

============================================================
📊 Round 40 Summary - Client client_70
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2935, R²=-0.0269
   Val:   Loss=0.0884, RMSE=0.2974, R²=-0.0345
============================================================


📊 Round 40 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2481, R²: -0.0386

============================================================
🔄 Round 41 - Client client_70
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0923 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0923, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0923, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0923, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0923, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0923, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0923)

============================================================
📊 Round 41 Summary - Client client_70
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2918, R²=-0.0270
   Val:   Loss=0.0923, RMSE=0.3038, R²=-0.0406
============================================================


📊 Round 41 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2481, R²: -0.0386

============================================================
🔄 Round 42 - Client client_70
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0887, val=0.0777 (↓), lr=0.000001
   • Epoch   2/100: train=0.0887, val=0.0777, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0887, val=0.0777, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0887, val=0.0777, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0887, val=0.0777, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0886, val=0.0777, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 42 Summary - Client client_70
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0888, RMSE=0.2980, R²=-0.0352
   Val:   Loss=0.0777, RMSE=0.2788, R²=0.0001
============================================================


============================================================
🔄 Round 44 - Client client_70
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0864, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0864, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 44 Summary - Client client_70
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2944, R²=-0.0220
   Val:   Loss=0.0864, RMSE=0.2939, R²=-0.0573
============================================================


📊 Round 44 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2481, R²: -0.0386

📊 Round 44 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2481, R²: -0.0386

📊 Round 44 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2481, R²: -0.0386

📊 Round 44 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2481, R²: -0.0386

============================================================
🔄 Round 51 - Client client_70
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0895, val=0.0739 (↓), lr=0.000001
   • Epoch   2/100: train=0.0895, val=0.0739, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0895, val=0.0739, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0895, val=0.0739, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0895, val=0.0738, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0895, val=0.0738, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0739)

============================================================
📊 Round 51 Summary - Client client_70
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0898, RMSE=0.2996, R²=-0.0326
   Val:   Loss=0.0739, RMSE=0.2718, R²=-0.0084
============================================================


📊 Round 51 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2481, R²: -0.0386

============================================================
🔄 Round 56 - Client client_70
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.0870 (↓), lr=0.000001
   • Epoch   2/100: train=0.0868, val=0.0870, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0868, val=0.0870, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0868, val=0.0870, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0868, val=0.0870, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0868, val=0.0870, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0870)

============================================================
📊 Round 56 Summary - Client client_70
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2941, R²=-0.0261
   Val:   Loss=0.0870, RMSE=0.2950, R²=-0.0379
============================================================


📊 Round 56 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2481, R²: -0.0386

============================================================
🔄 Round 64 - Client client_70
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0888 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0888, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0888, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0888, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0888, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0888, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0888)

============================================================
📊 Round 64 Summary - Client client_70
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2933, R²=-0.0276
   Val:   Loss=0.0888, RMSE=0.2980, R²=-0.0325
============================================================


============================================================
🔄 Round 65 - Client client_70
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0866 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0866, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0866, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0865, val=0.0866, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0866, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0867, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0866)

============================================================
📊 Round 65 Summary - Client client_70
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2943, R²=-0.0321
   Val:   Loss=0.0866, RMSE=0.2942, R²=-0.0417
============================================================


📊 Round 65 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2481, R²: -0.0386

============================================================
🔄 Round 67 - Client client_70
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0893 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0893, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0893, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0893, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0893, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0893, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0893)

============================================================
📊 Round 67 Summary - Client client_70
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2931, R²=-0.0342
   Val:   Loss=0.0893, RMSE=0.2989, R²=-0.0061
============================================================


============================================================
🔄 Round 69 - Client client_70
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0908 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0908, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0908, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0908, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0908, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0908, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0908)

============================================================
📊 Round 69 Summary - Client client_70
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2925, R²=-0.0298
   Val:   Loss=0.0908, RMSE=0.3013, R²=-0.0237
============================================================


📊 Round 69 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2481, R²: -0.0386

📊 Round 69 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2481, R²: -0.0386

============================================================
🔄 Round 71 - Client client_70
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0871, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0870, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0870, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0870, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0870, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0870, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 71 Summary - Client client_70
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0871, RMSE=0.2951, R²=-0.0339
   Val:   Loss=0.0846, RMSE=0.2909, R²=-0.0105
============================================================


============================================================
🔄 Round 72 - Client client_70
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0921 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0921, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0921, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0921, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0921, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0921, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0921)

============================================================
📊 Round 72 Summary - Client client_70
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2919, R²=-0.0295
   Val:   Loss=0.0921, RMSE=0.3035, R²=-0.0346
============================================================


============================================================
🔄 Round 74 - Client client_70
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0881, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0881, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0881, val=0.0806, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0881, val=0.0806, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0881, val=0.0806, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0881, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 74 Summary - Client client_70
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0881, RMSE=0.2968, R²=-0.0333
   Val:   Loss=0.0806, RMSE=0.2839, R²=-0.0201
============================================================


📊 Round 74 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2481, R²: -0.0386

📊 Round 74 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2481, R²: -0.0386

============================================================
🔄 Round 76 - Client client_70
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0875, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0874, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0874, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0874, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0874, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0874, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 76 Summary - Client client_70
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0872, RMSE=0.2953, R²=-0.0288
   Val:   Loss=0.0840, RMSE=0.2898, R²=-0.0263
============================================================


📊 Round 76 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2481, R²: -0.0386

📊 Round 76 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2481, R²: -0.0386

============================================================
🔄 Round 81 - Client client_70
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0878, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0878, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0878, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0878, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0878, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0878, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 81 Summary - Client client_70
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0878, RMSE=0.2962, R²=-0.0312
   Val:   Loss=0.0819, RMSE=0.2862, R²=-0.0301
============================================================


📊 Round 81 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2481, R²: -0.0385

============================================================
🔄 Round 82 - Client client_70
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0868 (↓), lr=0.000001
   • Epoch   2/100: train=0.0867, val=0.0868, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0867, val=0.0868, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0868, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0868, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0866, val=0.0868, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0868)

============================================================
📊 Round 82 Summary - Client client_70
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0865, RMSE=0.2941, R²=-0.0300
   Val:   Loss=0.0868, RMSE=0.2947, R²=-0.0281
============================================================


📊 Round 82 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2481, R²: -0.0385

============================================================
🔄 Round 84 - Client client_70
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0873, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0873, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0873, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0872, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0872, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0872, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 84 Summary - Client client_70
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0869, RMSE=0.2949, R²=-0.0244
   Val:   Loss=0.0851, RMSE=0.2918, R²=-0.0603
============================================================


📊 Round 84 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2481, R²: -0.0385

============================================================
🔄 Round 86 - Client client_70
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0940 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0940, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0940, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0940, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0940, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0940, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0940)

============================================================
📊 Round 86 Summary - Client client_70
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2911, R²=-0.0276
   Val:   Loss=0.0940, RMSE=0.3066, R²=-0.0415
============================================================


📊 Round 86 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2481, R²: -0.0385

============================================================
🔄 Round 88 - Client client_70
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0882, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0882, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0882, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0882, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0882, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0882, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 88 Summary - Client client_70
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0884, RMSE=0.2973, R²=-0.0281
   Val:   Loss=0.0793, RMSE=0.2816, R²=-0.0327
============================================================


📊 Round 88 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2481, R²: -0.0385

============================================================
🔄 Round 93 - Client client_70
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0867, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0867, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0867, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0867, val=0.0864, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0867, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 93 Summary - Client client_70
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2943, R²=-0.0335
   Val:   Loss=0.0864, RMSE=0.2940, R²=-0.0091
============================================================


============================================================
🔄 Round 96 - Client client_70
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0881, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0881, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0881, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0881, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0881, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0880, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 96 Summary - Client client_70
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0882, RMSE=0.2969, R²=-0.0271
   Val:   Loss=0.0802, RMSE=0.2831, R²=-0.0333
============================================================


📊 Round 96 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2481, R²: -0.0384

============================================================
🔄 Round 99 - Client client_70
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0887 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0887, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0887, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0887, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0887, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0887, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0887)

============================================================
📊 Round 99 Summary - Client client_70
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2933, R²=-0.0318
   Val:   Loss=0.0887, RMSE=0.2978, R²=-0.0158
============================================================


============================================================
🔄 Round 101 - Client client_70
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0885, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0885, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0885, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0885, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0885, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0885, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 101 Summary - Client client_70
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0885, RMSE=0.2974, R²=-0.0336
   Val:   Loss=0.0790, RMSE=0.2811, R²=-0.0053
============================================================


📊 Round 101 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2481, R²: -0.0384

============================================================
🔄 Round 102 - Client client_70
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0880, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0880, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0880, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0880, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0880, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0880, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 102 Summary - Client client_70
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0880, RMSE=0.2966, R²=-0.0290
   Val:   Loss=0.0809, RMSE=0.2845, R²=-0.0262
============================================================


============================================================
🔄 Round 106 - Client client_70
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0869, val=0.0860 (↓), lr=0.000001
   • Epoch   2/100: train=0.0869, val=0.0860, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0869, val=0.0860, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0869, val=0.0860, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0869, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0868, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0860)

============================================================
📊 Round 106 Summary - Client client_70
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0867, RMSE=0.2945, R²=-0.0294
   Val:   Loss=0.0860, RMSE=0.2933, R²=-0.0238
============================================================


============================================================
🔄 Round 107 - Client client_70
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0864, val=0.0875 (↓), lr=0.000001
   • Epoch   2/100: train=0.0864, val=0.0875, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0864, val=0.0875, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0875, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0875, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0875, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0875)

============================================================
📊 Round 107 Summary - Client client_70
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2939, R²=-0.0278
   Val:   Loss=0.0875, RMSE=0.2957, R²=-0.0348
============================================================


📊 Round 107 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2481, R²: -0.0384

📊 Round 107 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2481, R²: -0.0384

📊 Round 107 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2481, R²: -0.0384

============================================================
🔄 Round 114 - Client client_70
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0879, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0879, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0879, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0879, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0879, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0879, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 114 Summary - Client client_70
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0878, RMSE=0.2962, R²=-0.0179
   Val:   Loss=0.0819, RMSE=0.2862, R²=-0.0757
============================================================


============================================================
🔄 Round 115 - Client client_70
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0901 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0901, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0855, val=0.0901, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0855, val=0.0901, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0855, val=0.0901, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0901, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0901)

============================================================
📊 Round 115 Summary - Client client_70
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2927, R²=-0.0299
   Val:   Loss=0.0901, RMSE=0.3002, R²=-0.0228
============================================================


📊 Round 115 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2481, R²: -0.0384

============================================================
🔄 Round 118 - Client client_70
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0898, val=0.0741 (↓), lr=0.000001
   • Epoch   2/100: train=0.0898, val=0.0741, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0897, val=0.0741, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0897, val=0.0741, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0897, val=0.0741, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0897, val=0.0741, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0741)

============================================================
📊 Round 118 Summary - Client client_70
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0897, RMSE=0.2995, R²=-0.0295
   Val:   Loss=0.0741, RMSE=0.2722, R²=-0.0246
============================================================


📊 Round 118 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2481, R²: -0.0384

📊 Round 118 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2481, R²: -0.0384

============================================================
🔄 Round 124 - Client client_70
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0873 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0873, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0873, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0873, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0873, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0866, val=0.0872, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0873)

============================================================
📊 Round 124 Summary - Client client_70
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2940, R²=-0.0229
   Val:   Loss=0.0873, RMSE=0.2954, R²=-0.0501
============================================================


📊 Round 124 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2481, R²: -0.0384

📊 Round 124 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2481, R²: -0.0384

📊 Round 124 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2481, R²: -0.0383

============================================================
🔄 Round 130 - Client client_70
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 130 Summary - Client client_70
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2947, R²=-0.0173
   Val:   Loss=0.0856, RMSE=0.2926, R²=-0.0754
============================================================


📊 Round 130 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2481, R²: -0.0383

📊 Round 130 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2481, R²: -0.0383

============================================================
🔄 Round 132 - Client client_70
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0933 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0933, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0933, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0934, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0934, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0935, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0933)

============================================================
📊 Round 132 Summary - Client client_70
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2914, R²=-0.0249
   Val:   Loss=0.0933, RMSE=0.3055, R²=-0.0787
============================================================


📊 Round 132 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2481, R²: -0.0383

============================================================
🔄 Round 134 - Client client_70
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0879, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0879, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0879, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0879, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0878, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0878, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 134 Summary - Client client_70
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0878, RMSE=0.2963, R²=-0.0372
   Val:   Loss=0.0817, RMSE=0.2859, R²=0.0043
============================================================


📊 Round 134 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2481, R²: -0.0383

📊 Round 134 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2481, R²: -0.0383

============================================================
🔄 Round 136 - Client client_70
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0872, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0872, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0872, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0872, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0872, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0871, val=0.0836, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 136 Summary - Client client_70
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0873, RMSE=0.2955, R²=-0.0249
   Val:   Loss=0.0836, RMSE=0.2891, R²=-0.0534
============================================================


📊 Round 136 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2481, R²: -0.0383

📊 Round 136 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2481, R²: -0.0383

============================================================
🔄 Round 139 - Client client_70
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0923 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0923, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0923, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0923, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0923, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0922, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0923)

============================================================
📊 Round 139 Summary - Client client_70
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2918, R²=-0.0225
   Val:   Loss=0.0923, RMSE=0.3037, R²=-0.0568
============================================================


📊 Round 139 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2481, R²: -0.0383

============================================================
🔄 Round 140 - Client client_70
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0879, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0879, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0879, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0879, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0879, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0878, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 140 Summary - Client client_70
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0879, RMSE=0.2964, R²=-0.0259
   Val:   Loss=0.0814, RMSE=0.2853, R²=-0.0580
============================================================


📊 Round 140 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2481, R²: -0.0383

📊 Round 140 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2481, R²: -0.0383

📊 Round 140 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2481, R²: -0.0383

============================================================
🔄 Round 146 - Client client_70
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0910 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0910, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0910, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0910, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0910, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0910, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0910)

============================================================
📊 Round 146 Summary - Client client_70
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2924, R²=-0.0277
   Val:   Loss=0.0910, RMSE=0.3016, R²=-0.0328
============================================================


============================================================
🔄 Round 147 - Client client_70
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0854 (↓), lr=0.000001
   • Epoch   2/100: train=0.0867, val=0.0854, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0867, val=0.0854, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0867, val=0.0854, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0867, val=0.0854, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0866, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0854)

============================================================
📊 Round 147 Summary - Client client_70
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0869, RMSE=0.2947, R²=-0.0360
   Val:   Loss=0.0854, RMSE=0.2923, R²=-0.0075
============================================================


📊 Round 147 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2481, R²: -0.0383

============================================================
🔄 Round 148 - Client client_70
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0930 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0930, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0930, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0930, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0930, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0930, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0930)

============================================================
📊 Round 148 Summary - Client client_70
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2915, R²=-0.0290
   Val:   Loss=0.0930, RMSE=0.3050, R²=-0.0290
============================================================


============================================================
🔄 Round 150 - Client client_70
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0877, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0877, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0877, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0877, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0877, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0876, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 150 Summary - Client client_70
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0876, RMSE=0.2960, R²=-0.0309
   Val:   Loss=0.0823, RMSE=0.2870, R²=-0.0203
============================================================


============================================================
🔄 Round 153 - Client client_70
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0886 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0886, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0886, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0886, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0886, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0886, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0886)

============================================================
📊 Round 153 Summary - Client client_70
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0861, RMSE=0.2934, R²=-0.0279
   Val:   Loss=0.0886, RMSE=0.2976, R²=-0.0447
============================================================


============================================================
🔄 Round 154 - Client client_70
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0922 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0922, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0922, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0922, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0922, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0922, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0922)

============================================================
📊 Round 154 Summary - Client client_70
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2918, R²=-0.0292
   Val:   Loss=0.0922, RMSE=0.3037, R²=-0.0244
============================================================


📊 Round 154 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2481, R²: -0.0383

============================================================
🔄 Round 157 - Client client_70
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0870, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0870, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0870, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0870, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0870, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0870, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 157 Summary - Client client_70
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0868, RMSE=0.2946, R²=-0.0282
   Val:   Loss=0.0856, RMSE=0.2926, R²=-0.0330
============================================================


============================================================
🔄 Round 158 - Client client_70
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0875 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0875, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0875, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0875, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0866, val=0.0875, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0875, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0875)

============================================================
📊 Round 158 Summary - Client client_70
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2938, R²=-0.0336
   Val:   Loss=0.0875, RMSE=0.2958, R²=-0.0075
============================================================


📊 Round 158 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2481, R²: -0.0382

============================================================
🔄 Round 159 - Client client_70
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0937 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0937, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0937, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0937, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0937, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0937, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0937)

============================================================
📊 Round 159 Summary - Client client_70
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=-0.0313
   Val:   Loss=0.0937, RMSE=0.3061, R²=-0.0248
============================================================


📊 Round 159 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2481, R²: -0.0382

============================================================
🔄 Round 160 - Client client_70
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0888 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0888, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0888, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0888, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0888, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0887, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0888)

============================================================
📊 Round 160 Summary - Client client_70
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2933, R²=-0.0273
   Val:   Loss=0.0888, RMSE=0.2979, R²=-0.0320
============================================================


============================================================
🔄 Round 161 - Client client_70
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0881 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0881, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0881, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0881, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0881, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0881, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0881)

============================================================
📊 Round 161 Summary - Client client_70
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2936, R²=-0.0249
   Val:   Loss=0.0881, RMSE=0.2969, R²=-0.0487
============================================================


📊 Round 161 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2481, R²: -0.0382

📊 Round 161 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2481, R²: -0.0382

============================================================
🔄 Round 163 - Client client_70
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0867, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0867, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0867, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0867, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0866, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 163 Summary - Client client_70
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0869, RMSE=0.2948, R²=-0.0278
   Val:   Loss=0.0852, RMSE=0.2919, R²=-0.0389
============================================================


📊 Round 163 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2481, R²: -0.0382

📊 Round 163 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2481, R²: -0.0382

📊 Round 163 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2481, R²: -0.0382

============================================================
🔄 Round 170 - Client client_70
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0877, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0877, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0877, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0877, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0877, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0877, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 170 Summary - Client client_70
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0874, RMSE=0.2956, R²=-0.0331
   Val:   Loss=0.0834, RMSE=0.2888, R²=-0.0168
============================================================


============================================================
🔄 Round 171 - Client client_70
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0872, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0872, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0872, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0872, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0872, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0871, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 171 Summary - Client client_70
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0870, RMSE=0.2950, R²=-0.0309
   Val:   Loss=0.0847, RMSE=0.2911, R²=-0.0191
============================================================


📊 Round 171 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2481, R²: -0.0382

============================================================
🔄 Round 172 - Client client_70
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0854, val=0.0915 (↓), lr=0.000001
   • Epoch   2/100: train=0.0854, val=0.0915, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0915, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0915, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0915, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0915, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0915)

============================================================
📊 Round 172 Summary - Client client_70
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0854, RMSE=0.2922, R²=-0.0327
   Val:   Loss=0.0915, RMSE=0.3024, R²=-0.0150
============================================================


📊 Round 172 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2481, R²: -0.0382

============================================================
🔄 Round 177 - Client client_70
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0865, val=0.0877 (↓), lr=0.000001
   • Epoch   2/100: train=0.0865, val=0.0877, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0865, val=0.0877, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0864, val=0.0878, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0864, val=0.0878, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0864, val=0.0878, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0877)

============================================================
📊 Round 177 Summary - Client client_70
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2937, R²=-0.0324
   Val:   Loss=0.0877, RMSE=0.2962, R²=-0.0320
============================================================


📊 Round 177 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2481, R²: -0.0382

============================================================
🔄 Round 179 - Client client_70
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0897 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0897, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0897, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0897, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0897, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0897, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0897)

============================================================
📊 Round 179 Summary - Client client_70
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2929, R²=-0.0319
   Val:   Loss=0.0897, RMSE=0.2994, R²=-0.0216
============================================================


============================================================
🔄 Round 181 - Client client_70
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0881, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0881, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0881, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0881, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0881, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0880, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 181 Summary - Client client_70
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0880, RMSE=0.2967, R²=-0.0309
   Val:   Loss=0.0808, RMSE=0.2842, R²=-0.0214
============================================================


📊 Round 181 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2480, R²: -0.0381

============================================================
🔄 Round 182 - Client client_70
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0879, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0879, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0878, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0878, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0878, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0878, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 182 Summary - Client client_70
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0878, RMSE=0.2963, R²=-0.0286
   Val:   Loss=0.0817, RMSE=0.2858, R²=-0.0381
============================================================


📊 Round 182 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2480, R²: -0.0381

📊 Round 182 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2480, R²: -0.0381

📊 Round 182 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2480, R²: -0.0381

============================================================
🔄 Round 186 - Client client_70
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0894, val=0.0770 (↓), lr=0.000001
   • Epoch   2/100: train=0.0894, val=0.0770, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0894, val=0.0770, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0894, val=0.0771, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0893, val=0.0771, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0893, val=0.0771, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0770)

============================================================
📊 Round 186 Summary - Client client_70
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0889, RMSE=0.2982, R²=-0.0292
   Val:   Loss=0.0770, RMSE=0.2776, R²=-0.0306
============================================================


📊 Round 186 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2480, R²: -0.0381

📊 Round 186 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2480, R²: -0.0381

📊 Round 186 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2480, R²: -0.0381

============================================================
🔄 Round 189 - Client client_70
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0867, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0867, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0867, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0867, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0867, val=0.0845, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0866, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 189 Summary - Client client_70
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0871, RMSE=0.2951, R²=-0.0244
   Val:   Loss=0.0845, RMSE=0.2907, R²=-0.0438
============================================================


📊 Round 189 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2480, R²: -0.0381

📊 Round 189 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2480, R²: -0.0381

📊 Round 189 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2480, R²: -0.0381

📊 Round 189 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2480, R²: -0.0381

📊 Round 189 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2480, R²: -0.0381

📊 Round 189 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2480, R²: -0.0381

============================================================
🔄 Round 196 - Client client_70
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0901, val=0.0731 (↓), lr=0.000001
   • Epoch   2/100: train=0.0901, val=0.0731, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0901, val=0.0731, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0900, val=0.0731, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0900, val=0.0731, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0900, val=0.0731, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0731)

============================================================
📊 Round 196 Summary - Client client_70
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0899, RMSE=0.2999, R²=-0.0363
   Val:   Loss=0.0731, RMSE=0.2703, R²=0.0028
============================================================


📊 Round 196 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2480, R²: -0.0381

============================================================
🔄 Round 201 - Client client_70
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0893 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0893, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0893, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0893, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0858, val=0.0893, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0892, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0893)

============================================================
📊 Round 201 Summary - Client client_70
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2931, R²=-0.0277
   Val:   Loss=0.0893, RMSE=0.2988, R²=-0.0344
============================================================


============================================================
🔄 Round 202 - Client client_70
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0925 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0925, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0925, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0925, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0925, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0926, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0925)

============================================================
📊 Round 202 Summary - Client client_70
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2917, R²=-0.0261
   Val:   Loss=0.0925, RMSE=0.3041, R²=-0.0661
============================================================


============================================================
🔄 Round 203 - Client client_70
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0907, val=0.0704 (↓), lr=0.000001
   • Epoch   2/100: train=0.0907, val=0.0704, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0907, val=0.0704, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0907, val=0.0704, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0907, val=0.0705, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0906, val=0.0705, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0704)

============================================================
📊 Round 203 Summary - Client client_70
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0906, RMSE=0.3010, R²=-0.0294
   Val:   Loss=0.0704, RMSE=0.2654, R²=-0.0427
============================================================


============================================================
🔄 Round 204 - Client client_70
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0859, val=0.0915 (↓), lr=0.000001
   • Epoch   2/100: train=0.0859, val=0.0915, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0915, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0915, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0915, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0914, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0915)

============================================================
📊 Round 204 Summary - Client client_70
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0853, RMSE=0.2921, R²=-0.0241
   Val:   Loss=0.0915, RMSE=0.3025, R²=-0.0436
============================================================


📊 Round 204 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2480, R²: -0.0380

📊 Round 204 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2480, R²: -0.0380

📊 Round 204 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2480, R²: -0.0380

============================================================
🔄 Round 208 - Client client_70
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0893 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0893, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0893, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0893, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0893, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0893, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0893)

============================================================
📊 Round 208 Summary - Client client_70
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2931, R²=-0.0295
   Val:   Loss=0.0893, RMSE=0.2988, R²=-0.0228
============================================================


============================================================
🔄 Round 209 - Client client_70
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0856, val=0.0893 (↓), lr=0.000001
   • Epoch   2/100: train=0.0856, val=0.0893, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0893, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0893, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0893, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0893, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0893)

============================================================
📊 Round 209 Summary - Client client_70
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2931, R²=-0.0170
   Val:   Loss=0.0893, RMSE=0.2989, R²=-0.0799
============================================================


📊 Round 209 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2480, R²: -0.0380

📊 Round 209 Test Metrics:
   Loss: 0.0840, RMSE: 0.2898, MAE: 0.2480, R²: -0.0380

============================================================
🔄 Round 213 - Client client_70
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0882, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0882, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0882, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0882, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0882, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0882, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 213 Summary - Client client_70
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0882, RMSE=0.2970, R²=-0.0294
   Val:   Loss=0.0800, RMSE=0.2828, R²=-0.0235
============================================================


============================================================
🔄 Round 215 - Client client_70
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0888 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0888, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0888, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0888, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0888, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0861, val=0.0887, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0888)

============================================================
📊 Round 215 Summary - Client client_70
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2933, R²=-0.0198
   Val:   Loss=0.0888, RMSE=0.2980, R²=-0.0623
============================================================


📊 Round 215 Test Metrics:
   Loss: 0.0840, RMSE: 0.2897, MAE: 0.2480, R²: -0.0380

============================================================
🔄 Round 221 - Client client_70
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0862, val=0.0875 (↓), lr=0.000001
   • Epoch   2/100: train=0.0862, val=0.0875, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0862, val=0.0875, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0862, val=0.0875, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0862, val=0.0875, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0862, val=0.0875, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0875)

============================================================
📊 Round 221 Summary - Client client_70
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2938, R²=-0.0327
   Val:   Loss=0.0875, RMSE=0.2958, R²=-0.0103
============================================================


📊 Round 221 Test Metrics:
   Loss: 0.0840, RMSE: 0.2897, MAE: 0.2480, R²: -0.0379

📊 Round 221 Test Metrics:
   Loss: 0.0840, RMSE: 0.2897, MAE: 0.2480, R²: -0.0379

❌ Client client_70 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8687 {grpc_status:14, grpc_message:"Socket closed"}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8687 {grpc_status:14, grpc_message:"Socket closed"}"
>
