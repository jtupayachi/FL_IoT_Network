[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fe40e4af-aef4-424c-a32e-104f44133867
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5148df89-aa33-4b47-ba0a-ed4c021e221c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5f5e1c09-d56e-4846-870a-54549f49d92e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fe4c16f6-de3c-474d-a34b-efa768812e7e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 04ca980e-d7ee-4bd5-baaa-2d751981472f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1b70d1a1-6050-4e1a-9e25-b815bd043c10
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6a009261-7ddb-400e-a28e-4b8fe9452648
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 739bbae9-3ea4-49e5-85f8-0fee2a947ce5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 822340da-830e-4cc3-bd10-3d5fff32e08f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6d4ed3d1-14b0-4faa-af19-171afcaabf93
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f6ce5a98-b5ae-41d7-b521-1050cf3dfa87
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 411e6f8e-740a-46cd-b79b-96bd22ffcebe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a674ed6b-f02d-4cd6-a964-cbf9ee43fc88
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6a45a635-85f8-469c-922e-0526e371fc83
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message df50ebc5-82f9-421a-bfae-1cb860785f53
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c66e2397-610d-4e26-905d-75f79ca8bf5d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 47456c4d-f8e4-4b6f-8b92-3f28c48f81a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bf478509-ca7c-421d-ba74-8b5c559799f2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1564a22c-3493-4be4-9a45-dfdac998ea06
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8c89875f-165f-43d8-9023-4907bc077f29
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f8788edd-c033-454c-bb62-328bb39fce51
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 29f99263-1d3c-4bf0-bd4b-31e3d715188e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4de0051f-c79d-4981-af7a-a636570c2f14
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 64fa2aeb-1724-47d8-b751-9ba57c5e551a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d305411b-4e81-4661-a539-c7175f635f39
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 66321e18-6191-43be-9cc0-3e56fd48b681
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fb7ee596-3ade-4bd6-9833-cb12390bc7af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 29e2f7fb-a4e0-408c-97f3-ef649801ded6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d753c6f8-eec2-414f-8e35-311cc20ac2ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d0a6ed17-a108-40b6-9f6a-f39df4e2eaf8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 946cf83d-34d6-4383-b1f1-928655b4b5cb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fd68d9a9-b5b8-48e3-a0fc-73cd91314d35
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 58632915-0089-4edc-ba8c-8f54eaaa006d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 40488afa-b6e3-43ae-b772-4414e0a3abe8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c50d07e9-eac7-4a75-9eed-4ea0b6e7c6a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ab5edbf9-c82a-433f-87e6-13e2a0c54b3b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 98fa22be-44bd-4c1b-9f13-bfaf09da9a51
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7c9b9f7c-fbf8-45dc-94f1-d73f1e858ab3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e80d63b0-9466-4f3c-8ae5-b5d918c9ddc9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message df564ac9-a5dc-4752-a6e4-aeab07c6b904
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4699810b-ec73-41b3-8e15-9445dffdade3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 00c7d762-aa32-4f7d-863e-1372481dfdd0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 027c9a16-76a2-420d-9986-3009ebb65e3d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 21290f0e-3dc1-40cf-9916-524bcd7e9425
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5d619159-132e-4722-85e0-8f07461834fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 54e50dbb-b97e-45cd-9987-db470135e71d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 58fb198c-7ec2-4ec3-b799-20200f5b7705
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7c62a37b-7613-4a10-8a2d-51dee6ef7fdf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0e059c38-2ba0-4d72-8f36-90ce1d89d099
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fed31b3f-5915-46a3-8f38-67c468711156
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0ef1b4e1-6769-470d-b3dc-b537ac2a2a0f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1971637c-4566-4cf4-a62a-7f0b96854502
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f4597f1b-f4a6-4c68-81e3-a76b194ee046
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 43ff8240-d478-4632-b59d-dd73a17d2e12
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 75de7512-a3cb-4af2-ad1d-641f66a6d4ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2221cc20-cca0-450e-958a-193855cd7af6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6ff97794-04ad-4055-8897-d02e35367faa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6cbd0b91-e113-4b33-bb7d-0eb958ac6098
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 24515525-ba3c-4bdb-843a-c7b418ac294e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 25ab4fa2-9322-4080-bf6b-87b141518bbd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4f7432f3-6576-47e0-917e-40c1812bc2de
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e05f22eb-4517-4fab-b97d-8d8ee66d360c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f05c60b6-c85b-48aa-b9c4-0218d4670e8e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d90a16dd-4f51-41c7-aac8-cd3a796e3aae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fc3965be-4ef1-4282-acbb-3f059d4921f4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3a0b214c-91d6-447f-b058-35b5b3f3e983
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 746adbb7-7f6e-4e0c-a003-66db6342f04a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3af962b1-8598-4d67-a156-5e9e22a92156
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ba55b423-a653-45e1-b8b3-8f0bfd890fd3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 74e558e8-a001-45b2-a6e2-f5f69708eb9f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 57725688-3181-43b9-ba9f-064a039184e6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e6725cc5-8aaa-433c-bd17-d4aeec3973d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0113c24c-cbd3-4b21-b675-d2e8e638a78f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 50413ff8-0214-4895-998e-09ee07246874
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bd61ec2a-cc40-4259-b8af-0fbea21ffa8f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 191464bc-fe76-4c5f-bca3-5f1948150e61
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5e8d9a17-c24f-4654-882c-13fa399fbe18
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6dba78ba-0f96-457c-9670-0ca07260de05
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6f44ff82-921c-490a-b974-130cb16ca01f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message af4e8f4f-e91a-43ab-8932-748ae17c6ca4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2728bb89-59a9-4775-989d-f697db42aa07
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f52de876-0460-47d6-ab8a-721133d524d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 22aa0207-309d-4a0c-b76c-2e7b34c7752d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 67666b83-741b-4ed0-a24b-81d0e238ec15
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b47853b9-1ec8-475d-8ac7-27077f0af406
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6862b566-fd2f-4fa1-96e5-687a184190ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5bcbbdad-411b-42ea-b83b-830c47e1656d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 29d7b110-1de1-485e-9d2b-a463b06a1ea4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 499e4fe1-fef7-4cb0-a416-20b949ce0d3f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 234850ef-9c43-4c7f-97fd-324228931ae3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f5d6bdd8-3eaa-4718-9e7b-91b236c374c8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1b588b09-959b-497f-b583-eb2e76a67d5b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7ba65269-c044-40ac-953b-186aaad7eec3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4c84fc67-7c55-4f50-911e-3e1e66f98e5a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c484514f-b140-43c1-b083-fe5e90fd6043
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e8312a04-d800-435d-bac0-40f322efa850
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f4b2c08a-729a-43ab-88f3-3abfaa521e14
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6bfcd63f-d9e1-42c8-b3b2-934082ad5072
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d5b97fa0-e61b-47f5-8c19-46d6b415b028
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 04f2da5a-1e56-4eb9-a593-5d7645a68098
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5734fb67-fac6-49c5-8060-e3a3e94c8e32
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 369e8454-7b0e-40d8-b3b8-4ea007980841
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a27dafc5-34a2-4c48-a4c8-09b17d950904
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9cbab220-fa62-49de-bf0a-f2bc5b59b62a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 94fc6e9c-6b30-446f-b4a9-a83fb1332899
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4a2dff29-295f-4ebf-b0e8-a51afe253053
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e1413381-cbc8-48f1-a75a-729224686e00
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ab3464ee-fbfc-4a00-a313-f58e3269779c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dfc7035b-e11f-47a5-a35c-51b8f61a199d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 24f24144-9e3b-4ef1-a0fa-f69d8af03696
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9fe1ca95-6a21-44e2-b9a1-edd6489c51e2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 748f5f61-e201-4290-b6c0-115ed87cecc6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9a14da03-f7a6-4228-a75e-055ccafce1e2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9a56190f-7867-4e97-bd7e-4bce1de9ccd1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7104ee07-f8ae-467a-a87b-a136b1138e13
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 592e2c78-2db4-4bc4-823a-1f86c9c2bbc7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b9fa5c80-f0f8-4df7-9878-1d56db854318
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 54961789-229a-49c8-bfb1-8a78ca5c0ed8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a023b6c2-88b1-402f-9961-8c7d9c44bd76
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f037de38-f0fc-42ab-ac44-ced6cf4fd75a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e9514229-1914-48f8-b478-c08921c35f4e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5249ea9a-c749-4fd4-9423-2b75f07c8b75
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 525d2759-8a41-4c24-b2c4-2790bf1f935d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 35f77e87-a8b0-4803-a530-822058636049
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 89c685dc-0869-4752-bdcd-cb21f3e63c63
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b3770d32-16c4-49ae-a7d4-d7480d133410
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9623ba2e-8afb-488f-9d78-c261c3d99f2f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0bbd6133-9789-407a-8ee4-506573987160
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3a0c3b6b-8621-4d0f-b3d6-883c98d0d5a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4bae22af-0674-4915-986f-340a5197a590
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b6a94ce3-40e8-47fe-b772-15ca2006db11
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9563a8cc-6ccc-41bd-9395-fd521a028417
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 60d28016-9986-4eb2-a63c-768dad47c45b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 457dd292-741e-4a1e-b3f5-1a4e65f6e24f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message acbe26c3-8f36-4cb3-8768-853da9711840
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e63c9b0a-2c6f-43ab-a2ad-63a0bc5b9645
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8d088fd1-67df-403f-8d7b-f194b9b512f3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 35480739-9fd7-46e7-92e7-94ee747402c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 404f4c48-7b1d-4720-9654-5d010738f569
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 41851c1d-41a9-43bb-8b64-aebd54ac2dd6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7617da88-bed6-4e4e-a876-aaac76e4b5e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ebfcb274-eacf-4e6e-836c-2b97749c7fc6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b0485b34-ed89-469b-a10f-c3c978472866
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d60bd798-839d-471b-8744-72be49dbce9d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6787211f-22e0-42c1-87d1-42195c21ea65
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 993194c2-c194-43c7-bcd3-03851db8f259
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e4d74ff8-6855-4922-ad49-038cbfdd3208
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c615d532-2876-4e7a-a79f-665f080254df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 45976ce8-1fe9-47cc-8087-e577bb6de85a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2734d787-f60f-4860-9bdb-76165476f50d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0e471698-cb84-4478-a453-82936b8c4c4a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0ebe4eee-d4e2-4bcc-9efb-4191b9605ccc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 60f25008-03e5-408f-a638-d0f96772e9b6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 480023cc-03b6-4bd0-b6df-b373b95aa215
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4eddfbca-53b5-4e39-89d3-9fd6b7c1397a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f34a6cde-4cd4-466a-b5e1-7a82d9896500
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 27a1f331-818a-40f3-a38a-85b66bbe274f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message af843c7a-6745-46ee-b761-4c5213f11e06
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3f9ccdfa-e870-44ab-a6f3-cbc7a55d9a8e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cdbc14f8-f735-45ac-b752-8192adaf5b43
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a4f22b1c-1b74-406a-9ee7-d48e8be78348
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b4b0d8e6-0655-4914-9422-fa81eea04879
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ee88b201-855c-4541-8fc6-e35259676b9d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a5a5a4a6-d9b1-476a-875d-e88922654967
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c7b89841-2f24-4ee3-9481-5dd9c6d75c72
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eb0e9f9e-4644-4425-8b84-3bfe100a42c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 663b6493-3c22-4c2b-a15c-0852f9d28be4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ae1621db-71b7-4408-a8f5-57658ad58f40
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fef5684c-291b-4de8-816a-03a2f2bea2ce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eb995ec6-5cdd-43a7-aa31-b27cef24cd47
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f8a89eeb-cd9e-4f4a-a471-77fb82c07b0c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 69cb24bd-ccf7-4c5c-914f-d35c3112145f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4e0062ce-360a-46b7-bf25-363f313d976c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0e6a431d-b47d-4a1f-9e25-6b736b5bb35d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a60936dc-5409-45bc-8436-49e3f6a16cb0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e31b1829-e500-4606-b739-46dcc15edbc1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7cf29242-11c4-476c-968a-1e5ff009ad86
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d804b327-e73c-441d-b166-cdd54d65a426
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fe0cb360-812e-4621-8d14-4d29b893b797
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5d919068-f11e-4e84-b637-db32e6d8f3a7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a5724cdd-6eeb-485d-b29c-e25812232bd4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 88410b2b-5b71-425b-905d-4fe4255dd142
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 638ba5f6-e63a-4073-a54b-a9e526c4fb86
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 22cbbec2-b45f-4cc1-bd91-27aafeed6fd0
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8687 {grpc_status:14, grpc_message:"Socket closed"}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_71
Server: localhost:8687
Algorithm: FEDAVG
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_71
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_71/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_71/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_71/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_71/test_labels.txt

📊 Raw data loaded:
   Train: X=(1127, 24), y=(1127,)
   Test:  X=(282, 24), y=(282,)

⚠️  Limiting training data: 1127 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  273 samples, 5 features
✅ Client client_71 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

============================================================
🔄 Round 6 - Client client_71
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0863 (↓), lr=0.001000
   ✓ Epoch   2/100: train=0.0797, val=0.0853 (↓), lr=0.001000
   ✓ Epoch   3/100: train=0.0782, val=0.0839 (↓), lr=0.001000
   ✓ Epoch   4/100: train=0.0764, val=0.0823 (↓), lr=0.001000
   ✓ Epoch   5/100: train=0.0746, val=0.0810 (↓), lr=0.001000
   • Epoch  11/100: train=0.0631, val=0.0800, patience=5/15, lr=0.001000
   📉 Epoch 13: LR reduced 0.001000 → 0.000500
   📉 Epoch 21: LR reduced 0.000500 → 0.000250
   • Epoch  21/100: train=0.0550, val=0.0806, patience=15/15, lr=0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 6 Summary - Client client_71
   Epochs: 21/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0703, RMSE=0.2651, R²=0.1509
   Val:   Loss=0.0796, RMSE=0.2821, R²=0.1253
============================================================


📊 Round 6 Test Metrics:
   Loss: 0.0831, RMSE: 0.2883, MAE: 0.2559, R²: 0.0364

📊 Round 6 Test Metrics:
   Loss: 0.0831, RMSE: 0.2883, MAE: 0.2561, R²: 0.0368

📊 Round 6 Test Metrics:
   Loss: 0.0831, RMSE: 0.2883, MAE: 0.2563, R²: 0.0366

============================================================
🔄 Round 10 - Client client_71
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0782 (↓), lr=0.000250
   • Epoch   2/100: train=0.0798, val=0.0780, patience=1/15, lr=0.000250
   ✓ Epoch   3/100: train=0.0793, val=0.0771 (↓), lr=0.000250
   • Epoch   4/100: train=0.0786, val=0.0772, patience=1/15, lr=0.000250
   • Epoch   5/100: train=0.0782, val=0.0769, patience=2/15, lr=0.000250
   • Epoch  11/100: train=0.0755, val=0.0752, patience=1/15, lr=0.000250
   • Epoch  21/100: train=0.0708, val=0.0728, patience=2/15, lr=0.000250
   • Epoch  31/100: train=0.0660, val=0.0719, patience=6/15, lr=0.000250
   📉 Epoch 33: LR reduced 0.000250 → 0.000125
   • Epoch  41/100: train=0.0629, val=0.0695, patience=7/15, lr=0.000125

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0697)

============================================================
📊 Round 10 Summary - Client client_71
   Epochs: 49/100 (early stopped)
   LR: 0.000250 → 0.000125 (1 reductions)
   Train: Loss=0.0640, RMSE=0.2530, R²=0.2486
   Val:   Loss=0.0697, RMSE=0.2640, R²=0.1285
============================================================


📊 Round 10 Test Metrics:
   Loss: 0.0831, RMSE: 0.2882, MAE: 0.2563, R²: 0.0373

============================================================
🔄 Round 11 - Client client_71
   Epochs: 100, Batch: 32, LR: 0.000125
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0828 (↓), lr=0.000125
   ✓ Epoch   2/100: train=0.0784, val=0.0822 (↓), lr=0.000125
   • Epoch   3/100: train=0.0780, val=0.0819, patience=1/15, lr=0.000125
   📉 Epoch 4: LR reduced 0.000125 → 0.000063
   ✓ Epoch   4/100: train=0.0778, val=0.0817 (↓), lr=0.000063
   • Epoch   5/100: train=0.0776, val=0.0816, patience=1/15, lr=0.000063
   • Epoch  11/100: train=0.0767, val=0.0809, patience=2/15, lr=0.000063
   📉 Epoch 12: LR reduced 0.000063 → 0.000031
   📉 Epoch 20: LR reduced 0.000031 → 0.000016
   • Epoch  21/100: train=0.0759, val=0.0805, patience=3/15, lr=0.000016
   📉 Epoch 28: LR reduced 0.000016 → 0.000008
   • Epoch  31/100: train=0.0757, val=0.0803, patience=13/15, lr=0.000008

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0805)

============================================================
📊 Round 11 Summary - Client client_71
   Epochs: 33/100 (early stopped)
   LR: 0.000125 → 0.000008 (4 reductions)
   Train: Loss=0.0762, RMSE=0.2761, R²=0.0983
   Val:   Loss=0.0805, RMSE=0.2838, R²=0.0394
============================================================


📊 Round 11 Test Metrics:
   Loss: 0.0831, RMSE: 0.2883, MAE: 0.2565, R²: 0.0365

============================================================
🔄 Round 15 - Client client_71
   Epochs: 100, Batch: 32, LR: 0.000008
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0783, val=0.0869 (↓), lr=0.000008
   • Epoch   2/100: train=0.0782, val=0.0868, patience=1/15, lr=0.000008
   📉 Epoch 3: LR reduced 0.000008 → 0.000004
   • Epoch   3/100: train=0.0781, val=0.0867, patience=2/15, lr=0.000004
   • Epoch   4/100: train=0.0781, val=0.0867, patience=3/15, lr=0.000004
   • Epoch   5/100: train=0.0780, val=0.0867, patience=4/15, lr=0.000004
   📉 Epoch 11: LR reduced 0.000004 → 0.000002
   • Epoch  11/100: train=0.0777, val=0.0864, patience=10/15, lr=0.000002
   📉 Epoch 19: LR reduced 0.000002 → 0.000001
   • Epoch  21/100: train=0.0774, val=0.0862, patience=8/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 15 Summary - Client client_71
   Epochs: 28/100 (early stopped)
   LR: 0.000008 → 0.000001 (3 reductions)
   Train: Loss=0.0775, RMSE=0.2784, R²=0.0599
   Val:   Loss=0.0863, RMSE=0.2938, R²=0.0636
============================================================


📊 Round 15 Test Metrics:
   Loss: 0.0826, RMSE: 0.2874, MAE: 0.2557, R²: 0.0424

📊 Round 15 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2554, R²: 0.0440

============================================================
🔄 Round 17 - Client client_71
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 17 Summary - Client client_71
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2814, R²=0.0603
   Val:   Loss=0.0810, RMSE=0.2846, R²=0.0508
============================================================


📊 Round 17 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2554, R²: 0.0441

============================================================
🔄 Round 18 - Client client_71
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0747 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0747, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0747, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0747, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0747, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0746, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0747)

============================================================
📊 Round 18 Summary - Client client_71
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=0.0571
   Val:   Loss=0.0747, RMSE=0.2733, R²=0.0547
============================================================


📊 Round 18 Test Metrics:
   Loss: 0.0824, RMSE: 0.2871, MAE: 0.2554, R²: 0.0443

📊 Round 18 Test Metrics:
   Loss: 0.0825, RMSE: 0.2872, MAE: 0.2554, R²: 0.0441

============================================================
🔄 Round 21 - Client client_71
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0746 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0746, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0746, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0746, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0746, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0745, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0746)

============================================================
📊 Round 21 Summary - Client client_71
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=0.0600
   Val:   Loss=0.0746, RMSE=0.2732, R²=0.0755
============================================================


📊 Round 21 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2550, R²: 0.0470

📊 Round 21 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2550, R²: 0.0470

============================================================
🔄 Round 24 - Client client_71
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0740 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0740, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0740, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0740, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0740, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0740, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0740)

============================================================
📊 Round 24 Summary - Client client_71
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=0.0715
   Val:   Loss=0.0740, RMSE=0.2721, R²=0.0198
============================================================


📊 Round 24 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2550, R²: 0.0470

============================================================
🔄 Round 29 - Client client_71
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0770 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0770, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0770, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0769, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0769, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0769, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0770)

============================================================
📊 Round 29 Summary - Client client_71
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2821, R²=0.0541
   Val:   Loss=0.0770, RMSE=0.2775, R²=0.1041
============================================================


============================================================
🔄 Round 30 - Client client_71
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 30 Summary - Client client_71
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2810, R²=0.0736
   Val:   Loss=0.0794, RMSE=0.2817, R²=0.0207
============================================================


📊 Round 30 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2550, R²: 0.0471

============================================================
🔄 Round 34 - Client client_71
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0780, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0780, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0780, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0779, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0779, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0778, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 34 Summary - Client client_71
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0782, RMSE=0.2797, R²=0.0697
   Val:   Loss=0.0823, RMSE=0.2868, R²=0.0312
============================================================


============================================================
🔄 Round 35 - Client client_71
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0760, val=0.0906 (↓), lr=0.000001
   • Epoch   2/100: train=0.0760, val=0.0906, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0760, val=0.0905, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0760, val=0.0905, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0760, val=0.0905, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0759, val=0.0904, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0906)

============================================================
📊 Round 35 Summary - Client client_71
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0762, RMSE=0.2760, R²=0.0646
   Val:   Loss=0.0906, RMSE=0.3009, R²=0.0629
============================================================


============================================================
🔄 Round 37 - Client client_71
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0771, val=0.0879 (↓), lr=0.000001
   • Epoch   2/100: train=0.0771, val=0.0879, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0770, val=0.0879, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0770, val=0.0879, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0770, val=0.0879, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0769, val=0.0878, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0879)

============================================================
📊 Round 37 Summary - Client client_71
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0768, RMSE=0.2772, R²=0.0713
   Val:   Loss=0.0879, RMSE=0.2965, R²=0.0302
============================================================


============================================================
🔄 Round 38 - Client client_71
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0700 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0700, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0700, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0700, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0700, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0699, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0700)

============================================================
📊 Round 38 Summary - Client client_71
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=0.0624
   Val:   Loss=0.0700, RMSE=0.2647, R²=0.0739
============================================================


============================================================
🔄 Round 39 - Client client_71
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0785, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 39 Summary - Client client_71
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2810, R²=0.0637
   Val:   Loss=0.0792, RMSE=0.2814, R²=0.0591
============================================================


📊 Round 39 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2550, R²: 0.0472

============================================================
🔄 Round 40 - Client client_71
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0753 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0753, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0753, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0753, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0753, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0753, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0753)

============================================================
📊 Round 40 Summary - Client client_71
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=0.0589
   Val:   Loss=0.0753, RMSE=0.2745, R²=0.0650
============================================================


============================================================
🔄 Round 41 - Client client_71
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0785 (↓), lr=0.000001
   • Epoch   2/100: train=0.0787, val=0.0785, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0785, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0785, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0785, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0785)

============================================================
📊 Round 41 Summary - Client client_71
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2813, R²=0.0613
   Val:   Loss=0.0785, RMSE=0.2803, R²=0.0520
============================================================


📊 Round 41 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2550, R²: 0.0472

============================================================
🔄 Round 42 - Client client_71
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 42 Summary - Client client_71
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2809, R²=0.0635
   Val:   Loss=0.0794, RMSE=0.2818, R²=0.0692
============================================================


============================================================
🔄 Round 44 - Client client_71
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0769, val=0.0872 (↓), lr=0.000001
   • Epoch   2/100: train=0.0769, val=0.0872, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0769, val=0.0871, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0769, val=0.0871, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0768, val=0.0871, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0767, val=0.0870, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0872)

============================================================
📊 Round 44 Summary - Client client_71
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0770, RMSE=0.2775, R²=0.0613
   Val:   Loss=0.0872, RMSE=0.2952, R²=0.0764
============================================================


📊 Round 44 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2550, R²: 0.0473

📊 Round 44 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2550, R²: 0.0473

📊 Round 44 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2550, R²: 0.0473

📊 Round 44 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2550, R²: 0.0473

📊 Round 44 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2550, R²: 0.0473

📊 Round 44 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2550, R²: 0.0473

============================================================
🔄 Round 51 - Client client_71
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0734 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0734, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0734, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0734, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0733, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0733, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0734)

============================================================
📊 Round 51 Summary - Client client_71
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=0.0632
   Val:   Loss=0.0734, RMSE=0.2709, R²=0.0608
============================================================


📊 Round 51 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2550, R²: 0.0474

============================================================
🔄 Round 52 - Client client_71
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0779, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0779, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0779, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0779, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0778, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0777, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 52 Summary - Client client_71
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0781, RMSE=0.2794, R²=0.0684
   Val:   Loss=0.0827, RMSE=0.2876, R²=0.0409
============================================================


📊 Round 52 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2549, R²: 0.0474

📊 Round 52 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2549, R²: 0.0474

📊 Round 52 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2549, R²: 0.0474

============================================================
🔄 Round 55 - Client client_71
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0774, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0774, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0774, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0774, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0773, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0772, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 55 Summary - Client client_71
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0774, RMSE=0.2781, R²=0.0716
   Val:   Loss=0.0856, RMSE=0.2925, R²=0.0400
============================================================


📊 Round 55 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2549, R²: 0.0474

📊 Round 55 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2549, R²: 0.0475

============================================================
🔄 Round 57 - Client client_71
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0785, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 57 Summary - Client client_71
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2801, R²=0.0606
   Val:   Loss=0.0811, RMSE=0.2847, R²=0.0758
============================================================


📊 Round 57 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2549, R²: 0.0475

============================================================
🔄 Round 58 - Client client_71
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0782, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0782, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0782, val=0.0831, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0782, val=0.0831, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0782, val=0.0831, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0781, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 58 Summary - Client client_71
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0780, RMSE=0.2792, R²=0.0622
   Val:   Loss=0.0831, RMSE=0.2883, R²=0.0734
============================================================


============================================================
🔄 Round 59 - Client client_71
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0808, val=0.0707 (↓), lr=0.000001
   • Epoch   2/100: train=0.0808, val=0.0707, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0707, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0707, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0707, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0706, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0707)

============================================================
📊 Round 59 Summary - Client client_71
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2847, R²=0.0614
   Val:   Loss=0.0707, RMSE=0.2659, R²=0.0811
============================================================


📊 Round 59 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2549, R²: 0.0475

📊 Round 59 Test Metrics:
   Loss: 0.0822, RMSE: 0.2867, MAE: 0.2549, R²: 0.0475

📊 Round 59 Test Metrics:
   Loss: 0.0822, RMSE: 0.2866, MAE: 0.2549, R²: 0.0476

📊 Round 59 Test Metrics:
   Loss: 0.0822, RMSE: 0.2866, MAE: 0.2549, R²: 0.0476

============================================================
🔄 Round 66 - Client client_71
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0754 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0754, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0754, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0754, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0754, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0753, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0754)

============================================================
📊 Round 66 Summary - Client client_71
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2826, R²=0.0583
   Val:   Loss=0.0754, RMSE=0.2746, R²=0.0852
============================================================


📊 Round 66 Test Metrics:
   Loss: 0.0822, RMSE: 0.2866, MAE: 0.2549, R²: 0.0476

============================================================
🔄 Round 67 - Client client_71
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0783, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0782, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 67 Summary - Client client_71
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2802, R²=0.0643
   Val:   Loss=0.0808, RMSE=0.2842, R²=0.0553
============================================================


📊 Round 67 Test Metrics:
   Loss: 0.0822, RMSE: 0.2866, MAE: 0.2549, R²: 0.0477

============================================================
🔄 Round 68 - Client client_71
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0774 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0773, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0774)

============================================================
📊 Round 68 Summary - Client client_71
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2817, R²=0.0616
   Val:   Loss=0.0774, RMSE=0.2781, R²=0.0796
============================================================


📊 Round 68 Test Metrics:
   Loss: 0.0822, RMSE: 0.2866, MAE: 0.2549, R²: 0.0477

============================================================
🔄 Round 70 - Client client_71
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0813, val=0.0697 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0697, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0697, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0697, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0697, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0696, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0697)

============================================================
📊 Round 70 Summary - Client client_71
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=0.0626
   Val:   Loss=0.0697, RMSE=0.2640, R²=0.0698
============================================================


📊 Round 70 Test Metrics:
   Loss: 0.0822, RMSE: 0.2866, MAE: 0.2549, R²: 0.0477

📊 Round 70 Test Metrics:
   Loss: 0.0822, RMSE: 0.2866, MAE: 0.2549, R²: 0.0478

============================================================
🔄 Round 73 - Client client_71
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0764 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0764, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0764, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0764, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0764, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0763, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0764)

============================================================
📊 Round 73 Summary - Client client_71
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2821, R²=0.0777
   Val:   Loss=0.0764, RMSE=0.2764, R²=0.0106
============================================================


============================================================
🔄 Round 75 - Client client_71
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0772, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0772, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0771, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0771, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0771, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0770, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 75 Summary - Client client_71
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0773, RMSE=0.2780, R²=0.0646
   Val:   Loss=0.0857, RMSE=0.2927, R²=0.0672
============================================================


📊 Round 75 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2549, R²: 0.0478

============================================================
🔄 Round 76 - Client client_71
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0778, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0778, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0778, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0778, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0777, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 76 Summary - Client client_71
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2815, R²=0.0639
   Val:   Loss=0.0778, RMSE=0.2789, R²=0.0710
============================================================


📊 Round 76 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2549, R²: 0.0479

📊 Round 76 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2549, R²: 0.0479

============================================================
🔄 Round 80 - Client client_71
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0723 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0723, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0808, val=0.0723, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0808, val=0.0723, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0723, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0723, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0723)

============================================================
📊 Round 80 Summary - Client client_71
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=0.0625
   Val:   Loss=0.0723, RMSE=0.2689, R²=0.0657
============================================================


============================================================
🔄 Round 81 - Client client_71
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0769, val=0.0876 (↓), lr=0.000001
   • Epoch   2/100: train=0.0769, val=0.0876, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0769, val=0.0877, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0768, val=0.0877, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0768, val=0.0877, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0767, val=0.0877, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0876)

============================================================
📊 Round 81 Summary - Client client_71
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0768, RMSE=0.2771, R²=0.0647
   Val:   Loss=0.0876, RMSE=0.2960, R²=0.0427
============================================================


============================================================
🔄 Round 84 - Client client_71
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0755 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0755, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0755, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0755, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0754, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0753, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0755)

============================================================
📊 Round 84 Summary - Client client_71
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=0.0625
   Val:   Loss=0.0755, RMSE=0.2748, R²=0.0790
============================================================


📊 Round 84 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2549, R²: 0.0480

📊 Round 84 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2549, R²: 0.0480

============================================================
🔄 Round 87 - Client client_71
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0703 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0702, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0702, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0702, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0702, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0701, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0703)

============================================================
📊 Round 87 Summary - Client client_71
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=0.0657
   Val:   Loss=0.0703, RMSE=0.2651, R²=0.0656
============================================================


============================================================
🔄 Round 88 - Client client_71
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0773, val=0.0861 (↓), lr=0.000001
   • Epoch   2/100: train=0.0773, val=0.0861, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0773, val=0.0861, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0773, val=0.0861, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0772, val=0.0860, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0771, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0861)

============================================================
📊 Round 88 Summary - Client client_71
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0771, RMSE=0.2777, R²=0.0682
   Val:   Loss=0.0861, RMSE=0.2935, R²=0.0563
============================================================


============================================================
🔄 Round 89 - Client client_71
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0758 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0758, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0758, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0758, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0758, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0758, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0758)

============================================================
📊 Round 89 Summary - Client client_71
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=0.0586
   Val:   Loss=0.0758, RMSE=0.2754, R²=0.0625
============================================================


📊 Round 89 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2549, R²: 0.0480

============================================================
🔄 Round 90 - Client client_71
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0719 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0719, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0719, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0719, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0718, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0718, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0719)

============================================================
📊 Round 90 Summary - Client client_71
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2840, R²=0.0642
   Val:   Loss=0.0719, RMSE=0.2681, R²=0.0697
============================================================


============================================================
🔄 Round 91 - Client client_71
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0779, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0778, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0778, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0778, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0778, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0776, val=0.0831, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 91 Summary - Client client_71
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0779, RMSE=0.2790, R²=0.0699
   Val:   Loss=0.0832, RMSE=0.2884, R²=0.0449
============================================================


📊 Round 91 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2549, R²: 0.0481

📊 Round 91 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2549, R²: 0.0481

============================================================
🔄 Round 94 - Client client_71
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0778, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0778, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0778, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0778, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0777, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0776, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 94 Summary - Client client_71
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0775, RMSE=0.2785, R²=0.0695
   Val:   Loss=0.0844, RMSE=0.2905, R²=0.0477
============================================================


============================================================
🔄 Round 95 - Client client_71
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0783, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0783, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0783, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0782, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 95 Summary - Client client_71
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2801, R²=0.0680
   Val:   Loss=0.0807, RMSE=0.2841, R²=0.0572
============================================================


============================================================
🔄 Round 96 - Client client_71
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0774, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0773, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0773, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0773, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0773, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0772, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 96 Summary - Client client_71
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0772, RMSE=0.2779, R²=0.0654
   Val:   Loss=0.0856, RMSE=0.2925, R²=0.0675
============================================================


============================================================
🔄 Round 97 - Client client_71
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0777 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0777, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0777, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0777, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0777, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 97 Summary - Client client_71
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2815, R²=0.0707
   Val:   Loss=0.0777, RMSE=0.2787, R²=0.0240
============================================================


📊 Round 97 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2548, R²: 0.0482

============================================================
🔄 Round 98 - Client client_71
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0783, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0782, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 98 Summary - Client client_71
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2812, R²=0.0721
   Val:   Loss=0.0783, RMSE=0.2798, R²=0.0371
============================================================


📊 Round 98 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2548, R²: 0.0482

============================================================
🔄 Round 99 - Client client_71
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 99 Summary - Client client_71
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2805, R²=0.0659
   Val:   Loss=0.0797, RMSE=0.2824, R²=0.0631
============================================================


📊 Round 99 Test Metrics:
   Loss: 0.0821, RMSE: 0.2866, MAE: 0.2548, R²: 0.0482

📊 Round 99 Test Metrics:
   Loss: 0.0821, RMSE: 0.2865, MAE: 0.2548, R²: 0.0482

📊 Round 99 Test Metrics:
   Loss: 0.0821, RMSE: 0.2865, MAE: 0.2548, R²: 0.0483

📊 Round 99 Test Metrics:
   Loss: 0.0821, RMSE: 0.2865, MAE: 0.2548, R²: 0.0483

============================================================
🔄 Round 111 - Client client_71
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0773, val=0.0850 (↓), lr=0.000001
   • Epoch   2/100: train=0.0773, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0772, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0772, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0772, val=0.0849, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0771, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 111 Summary - Client client_71
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0774, RMSE=0.2782, R²=0.0591
   Val:   Loss=0.0850, RMSE=0.2915, R²=0.0903
============================================================


============================================================
🔄 Round 114 - Client client_71
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0780, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0780, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0780, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0780, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0779, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 114 Summary - Client client_71
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2812, R²=0.0604
   Val:   Loss=0.0781, RMSE=0.2794, R²=0.0880
============================================================


============================================================
🔄 Round 117 - Client client_71
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0776, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0776, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0776, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0776, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0775, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0774, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 117 Summary - Client client_71
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0778, RMSE=0.2790, R²=0.0757
   Val:   Loss=0.0830, RMSE=0.2881, R²=0.0286
============================================================


📊 Round 117 Test Metrics:
   Loss: 0.0821, RMSE: 0.2865, MAE: 0.2548, R²: 0.0485

📊 Round 117 Test Metrics:
   Loss: 0.0821, RMSE: 0.2865, MAE: 0.2548, R²: 0.0485

============================================================
🔄 Round 119 - Client client_71
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0785, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 119 Summary - Client client_71
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2803, R²=0.0611
   Val:   Loss=0.0800, RMSE=0.2828, R²=0.0844
============================================================


📊 Round 119 Test Metrics:
   Loss: 0.0821, RMSE: 0.2865, MAE: 0.2548, R²: 0.0485

📊 Round 119 Test Metrics:
   Loss: 0.0821, RMSE: 0.2865, MAE: 0.2548, R²: 0.0486

📊 Round 119 Test Metrics:
   Loss: 0.0821, RMSE: 0.2865, MAE: 0.2548, R²: 0.0486

📊 Round 119 Test Metrics:
   Loss: 0.0821, RMSE: 0.2865, MAE: 0.2548, R²: 0.0486

============================================================
🔄 Round 127 - Client client_71
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0783, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0783, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0782, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0782, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0782, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0781, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 127 Summary - Client client_71
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0783, RMSE=0.2799, R²=0.0697
   Val:   Loss=0.0809, RMSE=0.2845, R²=0.0439
============================================================


============================================================
🔄 Round 128 - Client client_71
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0771, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0771, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0771, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0771, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0770, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0769, val=0.0852, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 128 Summary - Client client_71
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0773, RMSE=0.2779, R²=0.0759
   Val:   Loss=0.0852, RMSE=0.2919, R²=0.0259
============================================================


============================================================
🔄 Round 130 - Client client_71
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0776, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0776, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0775, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0775, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0775, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0774, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 130 Summary - Client client_71
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0775, RMSE=0.2784, R²=0.0701
   Val:   Loss=0.0842, RMSE=0.2901, R²=0.0460
============================================================


============================================================
🔄 Round 131 - Client client_71
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0734 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0734, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0734, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0734, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0733, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0733, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0734)

============================================================
📊 Round 131 Summary - Client client_71
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=0.0662
   Val:   Loss=0.0734, RMSE=0.2709, R²=0.0677
============================================================


============================================================
🔄 Round 132 - Client client_71
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0776, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0776, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0776, val=0.0842, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0776, val=0.0842, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0776, val=0.0842, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0774, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 132 Summary - Client client_71
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0775, RMSE=0.2784, R²=0.0700
   Val:   Loss=0.0842, RMSE=0.2902, R²=0.0528
============================================================


============================================================
🔄 Round 134 - Client client_71
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0777, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0777, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0777, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0777, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0777, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 134 Summary - Client client_71
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2813, R²=0.0673
   Val:   Loss=0.0778, RMSE=0.2788, R²=0.0434
============================================================


📊 Round 134 Test Metrics:
   Loss: 0.0821, RMSE: 0.2865, MAE: 0.2547, R²: 0.0488

============================================================
🔄 Round 136 - Client client_71
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0779, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0778, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0778, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0778, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0778, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0776, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 136 Summary - Client client_71
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0776, RMSE=0.2787, R²=0.0711
   Val:   Loss=0.0836, RMSE=0.2891, R²=0.0379
============================================================


📊 Round 136 Test Metrics:
   Loss: 0.0821, RMSE: 0.2865, MAE: 0.2547, R²: 0.0488

============================================================
🔄 Round 139 - Client client_71
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0780, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0779, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0779, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0779, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0779, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0778, val=0.0819, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 139 Summary - Client client_71
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0780, RMSE=0.2793, R²=0.0681
   Val:   Loss=0.0821, RMSE=0.2865, R²=0.0616
============================================================


============================================================
🔄 Round 140 - Client client_71
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0779, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0779, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0778, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0778, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0778, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0776, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 140 Summary - Client client_71
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0776, RMSE=0.2786, R²=0.0617
   Val:   Loss=0.0836, RMSE=0.2891, R²=0.0773
============================================================


📊 Round 140 Test Metrics:
   Loss: 0.0821, RMSE: 0.2865, MAE: 0.2547, R²: 0.0489

============================================================
🔄 Round 143 - Client client_71
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0785, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0785, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0785, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 143 Summary - Client client_71
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2802, R²=0.0652
   Val:   Loss=0.0801, RMSE=0.2830, R²=0.0723
============================================================


📊 Round 143 Test Metrics:
   Loss: 0.0821, RMSE: 0.2864, MAE: 0.2547, R²: 0.0489

============================================================
🔄 Round 144 - Client client_71
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0753 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0753, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0753, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0753, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0753, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0752, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0753)

============================================================
📊 Round 144 Summary - Client client_71
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=0.0715
   Val:   Loss=0.0753, RMSE=0.2745, R²=0.0401
============================================================


📊 Round 144 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2547, R²: 0.0489

📊 Round 144 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2547, R²: 0.0490

============================================================
🔄 Round 149 - Client client_71
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0787, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0785, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 149 Summary - Client client_71
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2806, R²=0.0622
   Val:   Loss=0.0791, RMSE=0.2813, R²=0.0866
============================================================


📊 Round 149 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2547, R²: 0.0490

============================================================
🔄 Round 150 - Client client_71
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0702 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0702, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0702, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0701, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0701, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0701, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0702)

============================================================
📊 Round 150 Summary - Client client_71
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2845, R²=0.0742
   Val:   Loss=0.0702, RMSE=0.2649, R²=0.0325
============================================================


============================================================
🔄 Round 151 - Client client_71
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 151 Summary - Client client_71
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2808, R²=0.0585
   Val:   Loss=0.0786, RMSE=0.2804, R²=0.0958
============================================================


📊 Round 151 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2547, R²: 0.0490

============================================================
🔄 Round 152 - Client client_71
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0785, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0785, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 152 Summary - Client client_71
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2801, R²=0.0699
   Val:   Loss=0.0801, RMSE=0.2830, R²=0.0437
============================================================


📊 Round 152 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2547, R²: 0.0490

📊 Round 152 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2547, R²: 0.0491

============================================================
🔄 Round 154 - Client client_71
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0772 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0772, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0772, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0772, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0772, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0771, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 154 Summary - Client client_71
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2814, R²=0.0683
   Val:   Loss=0.0772, RMSE=0.2778, R²=0.0546
============================================================


============================================================
🔄 Round 156 - Client client_71
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0779, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0778, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0778, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0778, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0778, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0777, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 156 Summary - Client client_71
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0782, RMSE=0.2797, R²=0.0737
   Val:   Loss=0.0811, RMSE=0.2848, R²=0.0369
============================================================


📊 Round 156 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2547, R²: 0.0491

============================================================
🔄 Round 157 - Client client_71
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0776, val=0.0825 (↓), lr=0.000001
   • Epoch   2/100: train=0.0776, val=0.0825, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0775, val=0.0825, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0775, val=0.0825, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0775, val=0.0824, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0774, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 157 Summary - Client client_71
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0779, RMSE=0.2791, R²=0.0629
   Val:   Loss=0.0825, RMSE=0.2872, R²=0.0814
============================================================


📊 Round 157 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2547, R²: 0.0491

📊 Round 157 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2547, R²: 0.0491

============================================================
🔄 Round 161 - Client client_71
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0755 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0755, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0755, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0755, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0755, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0755, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0755)

============================================================
📊 Round 161 Summary - Client client_71
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2821, R²=0.0758
   Val:   Loss=0.0755, RMSE=0.2748, R²=0.0302
============================================================


============================================================
🔄 Round 162 - Client client_71
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0777, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0777, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0776, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0776, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0776, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0775, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 162 Summary - Client client_71
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0777, RMSE=0.2788, R²=0.0719
   Val:   Loss=0.0830, RMSE=0.2881, R²=0.0504
============================================================


============================================================
🔄 Round 166 - Client client_71
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0785, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 166 Summary - Client client_71
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2803, R²=0.0734
   Val:   Loss=0.0796, RMSE=0.2821, R²=0.0216
============================================================


📊 Round 166 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2547, R²: 0.0493

📊 Round 166 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2547, R²: 0.0493

============================================================
🔄 Round 172 - Client client_71
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0783, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0783, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0783, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0782, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 172 Summary - Client client_71
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2804, R²=0.0704
   Val:   Loss=0.0793, RMSE=0.2815, R²=0.0529
============================================================


📊 Round 172 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2547, R²: 0.0494

📊 Round 172 Test Metrics:
   Loss: 0.0820, RMSE: 0.2864, MAE: 0.2546, R²: 0.0495

============================================================
🔄 Round 177 - Client client_71
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0778, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0778, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0778, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0778, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0777, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0776, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 177 Summary - Client client_71
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0780, RMSE=0.2793, R²=0.0664
   Val:   Loss=0.0818, RMSE=0.2861, R²=0.0730
============================================================


============================================================
🔄 Round 180 - Client client_71
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0708 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0708, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0708, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0708, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0708, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0807, val=0.0707, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0708)

============================================================
📊 Round 180 Summary - Client client_71
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=0.0667
   Val:   Loss=0.0708, RMSE=0.2661, R²=0.0690
============================================================


📊 Round 180 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2546, R²: 0.0496

============================================================
🔄 Round 186 - Client client_71
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0679 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0678, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0678, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0678, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0678, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0678, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0679)

============================================================
📊 Round 186 Summary - Client client_71
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2854, R²=0.0670
   Val:   Loss=0.0679, RMSE=0.2605, R²=0.0724
============================================================


📊 Round 186 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2546, R²: 0.0497

============================================================
🔄 Round 190 - Client client_71
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0773 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0773, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0773, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0773, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0774, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0773)

============================================================
📊 Round 190 Summary - Client client_71
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2812, R²=0.0673
   Val:   Loss=0.0773, RMSE=0.2780, R²=0.0285
============================================================


📊 Round 190 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2546, R²: 0.0498

============================================================
🔄 Round 191 - Client client_71
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0696 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0695, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0695, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0695, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0695, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0695, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0696)

============================================================
📊 Round 191 Summary - Client client_71
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=0.0676
   Val:   Loss=0.0696, RMSE=0.2637, R²=0.0675
============================================================


============================================================
🔄 Round 192 - Client client_71
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0747 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0747, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0747, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0747, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0747, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0747, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0747)

============================================================
📊 Round 192 Summary - Client client_71
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2824, R²=0.0715
   Val:   Loss=0.0747, RMSE=0.2734, R²=0.0511
============================================================


============================================================
🔄 Round 193 - Client client_71
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0757 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0757, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0757, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0757, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0756, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0756, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0757)

============================================================
📊 Round 193 Summary - Client client_71
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2819, R²=0.0596
   Val:   Loss=0.0757, RMSE=0.2751, R²=0.0896
============================================================


📊 Round 193 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2546, R²: 0.0498

============================================================
🔄 Round 194 - Client client_71
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0759 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0759, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0759, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0759, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0759, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0758, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0759)

============================================================
📊 Round 194 Summary - Client client_71
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2818, R²=0.0760
   Val:   Loss=0.0759, RMSE=0.2756, R²=0.0330
============================================================


📊 Round 194 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2546, R²: 0.0498

============================================================
🔄 Round 196 - Client client_71
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0779 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0779, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0779, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0779, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0778, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0777, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0779)

============================================================
📊 Round 196 Summary - Client client_71
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2809, R²=0.0582
   Val:   Loss=0.0779, RMSE=0.2791, R²=0.1031
============================================================


📊 Round 196 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2546, R²: 0.0498

============================================================
🔄 Round 198 - Client client_71
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0783 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0782, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0783)

============================================================
📊 Round 198 Summary - Client client_71
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2808, R²=0.0646
   Val:   Loss=0.0783, RMSE=0.2797, R²=0.0778
============================================================


📊 Round 198 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2546, R²: 0.0499

============================================================
🔄 Round 200 - Client client_71
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0777, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0777, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0776, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0776, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0776, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0775, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 200 Summary - Client client_71
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0777, RMSE=0.2787, R²=0.0673
   Val:   Loss=0.0828, RMSE=0.2878, R²=0.0581
============================================================


📊 Round 200 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2546, R²: 0.0500

============================================================
🔄 Round 203 - Client client_71
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0730 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0730, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0730, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0730, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0730, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0729, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0730)

============================================================
📊 Round 203 Summary - Client client_71
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2831, R²=0.0666
   Val:   Loss=0.0730, RMSE=0.2702, R²=0.0754
============================================================


📊 Round 203 Test Metrics:
   Loss: 0.0820, RMSE: 0.2863, MAE: 0.2546, R²: 0.0500

============================================================
🔄 Round 204 - Client client_71
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0781, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0781, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0781, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0781, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0780, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0779, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 204 Summary - Client client_71
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0781, RMSE=0.2795, R²=0.0733
   Val:   Loss=0.0810, RMSE=0.2845, R²=0.0473
============================================================


============================================================
🔄 Round 205 - Client client_71
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0726 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0726, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0726, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0726, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0726, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0725, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0726)

============================================================
📊 Round 205 Summary - Client client_71
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2832, R²=0.0684
   Val:   Loss=0.0726, RMSE=0.2695, R²=0.0676
============================================================


============================================================
🔄 Round 206 - Client client_71
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0756, val=0.0909 (↓), lr=0.000001
   • Epoch   2/100: train=0.0755, val=0.0909, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0755, val=0.0909, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0755, val=0.0909, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0755, val=0.0909, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0753, val=0.0909, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0909)

============================================================
📊 Round 206 Summary - Client client_71
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0757, RMSE=0.2750, R²=0.0762
   Val:   Loss=0.0909, RMSE=0.3016, R²=0.0359
============================================================


📊 Round 206 Test Metrics:
   Loss: 0.0819, RMSE: 0.2863, MAE: 0.2545, R²: 0.0502

============================================================
🔄 Round 214 - Client client_71
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0780, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0780, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0780, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0779, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0779, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0778, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 214 Summary - Client client_71
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0777, RMSE=0.2787, R²=0.0610
   Val:   Loss=0.0828, RMSE=0.2878, R²=0.0963
============================================================


📊 Round 214 Test Metrics:
   Loss: 0.0819, RMSE: 0.2863, MAE: 0.2545, R²: 0.0502

============================================================
🔄 Round 216 - Client client_71
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0774 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0774, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0774, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0774, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0773, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0772, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0774)

============================================================
📊 Round 216 Summary - Client client_71
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2811, R²=0.0665
   Val:   Loss=0.0774, RMSE=0.2782, R²=0.0748
============================================================


📊 Round 216 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2545, R²: 0.0502

============================================================
🔄 Round 217 - Client client_71
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0783, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0783, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0782, val=0.0785, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 217 Summary - Client client_71
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2805, R²=0.0740
   Val:   Loss=0.0786, RMSE=0.2804, R²=0.0451
============================================================


📊 Round 217 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2545, R²: 0.0503

📊 Round 217 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2545, R²: 0.0503

📊 Round 217 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2545, R²: 0.0503

============================================================
🔄 Round 221 - Client client_71
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0677 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0677, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0677, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0677, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0677, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0676, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0677)

============================================================
📊 Round 221 Summary - Client client_71
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2853, R²=0.0710
   Val:   Loss=0.0677, RMSE=0.2603, R²=0.0574
============================================================


============================================================
🔄 Round 222 - Client client_71
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0782, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 222 Summary - Client client_71
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2801, R²=0.0731
   Val:   Loss=0.0794, RMSE=0.2818, R²=0.0374
============================================================


📊 Round 222 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2545, R²: 0.0503

📊 Round 222 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2545, R²: 0.0504

❌ Client client_71 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8687 {grpc_status:14, grpc_message:"Socket closed"}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8687 {grpc_status:14, grpc_message:"Socket closed"}"
>
