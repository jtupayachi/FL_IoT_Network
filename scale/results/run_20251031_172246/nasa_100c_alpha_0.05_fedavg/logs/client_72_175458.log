[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bbd2d34d-23ea-48e5-83fb-87b410cd7c81
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c11b7336-42f3-4ed1-9865-4a50857c92ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2145a082-2c25-4e14-8783-4c913a9813d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b6036bbf-e65f-494e-a8fa-1d7eda194e89
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 242dd333-3c81-4851-a5ac-915f943c9e29
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9d870cbd-1287-4824-b425-0f080dbc2e94
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f6f683b3-9cda-458b-ad1e-c80c3e5dfadf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 12d5f479-b626-4a02-bf01-5a97e6563e50
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d52557ed-03a8-4adb-8dbe-ab9ad4f55901
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e68b8482-ae99-4158-8dd4-4a6d65ed9438
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a8d49554-c9ce-4b86-820b-c6cc1311e67d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3f262bb8-a1df-4689-8dc5-7a19051dff2f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1597793b-dcf2-47a2-bb51-e7876a19ce0b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f5af935e-ea51-4013-bf70-32100e63e0a7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f5af1bc3-a9be-4189-a1df-ade378ad08c6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4e30e18d-a34f-439a-8ace-8be06b774867
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 36204b20-78ba-40ea-8188-334fc959395b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 39e4e031-3f87-4b9d-ae68-235c908006a8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0d63c980-5cc2-4a78-9bfe-8255e09c3358
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 25292088-ed7c-439d-ab43-6cdb4ff6cdac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7a68bd53-c43a-41e1-8dc1-47046d7a2595
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e70e3c6b-1799-4a7a-900b-ba1bcade2710
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e749fdf1-1b04-4730-be6b-be23248f9270
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 917886e9-489a-4e54-87c7-4bceaa0fd0ea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cff5f050-e34f-4235-95f1-b171719332f7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b896d9ec-40f9-48d4-b5f9-eac3fde332eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 56825539-5726-444a-a35b-1239cf964442
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b25f0905-0663-4ac2-9088-7ecfcbdf7822
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d4b3bdd7-a9c4-48dd-ba9d-e5549f75980f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 704cad60-cd1f-4ecc-8e51-c21ebb8005fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 02bbbddd-e07f-496c-a805-5a4b94ff5a15
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 38aebb18-1db7-40bb-b2d9-763b290bb2ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1711c632-ef9c-45aa-b344-08cb6046a979
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 26482fba-c254-4059-b332-f481da99e4fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ac46674d-d11c-4b54-8eb1-a8c563fc9a7c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fdc5ac1d-b5dd-4461-8f02-f43da72c57b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cfdec9a5-302d-4d8a-99cf-640df617b185
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5a4f9817-972c-45d0-937c-57cc52d69b32
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3d421b5b-80e7-4c80-9bda-c816d29e8add
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 35933963-efab-4fb8-9747-d5e94a0f47b1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1fbaa998-d285-43fa-a23b-652aa2b2fa9f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a34c39bd-e14a-4fdb-9158-ac4d84d6b1f5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 54a7542b-a069-4a51-8198-278cf561afa9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2f04307d-89ef-49a2-bd84-fa25af71d562
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2a2ffebb-b08f-46d0-99a4-7061ed6eeead
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 83968a09-8285-4377-a269-b4047011f8ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 816a12e6-115b-4923-b45b-361cb0f88657
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6c9b72e6-e1b9-4b0d-9d25-8685cb822fc5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ff17c388-b858-4c37-b5ea-5c87ce3fffad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f3630208-2262-47d2-bf95-37246720af1c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dfb81c42-8c08-4434-b1d6-6b10cebb1587
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c70f0c69-769c-4454-a1f4-f55c899782e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9270dc33-8af3-44c1-a64b-faff8a88b715
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d327cdaf-f06f-4895-a939-e6297b7aaa25
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d2b1b574-9e7d-4e66-84ef-d4a3067d64b3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1f74a8cd-fa7a-4265-b24c-6429925c2f2f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 85664e6c-af66-4fa2-97a1-a9ade47a5867
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 13844045-860a-4ca0-82b5-e4ca22dab688
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ab3baf23-6816-4676-994d-367b2602a4fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a53345af-3eb4-4ce4-b1fc-8d6f32e1d5fe
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 135daf0f-78d7-4ca0-bdc6-46dfb2e056bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a323fcb4-f6ce-49f2-95d9-39d79acff385
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8994a0a0-59be-482c-b767-9e9541c73885
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f4cde82b-90b4-4055-a70f-5ecb8110cf56
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0c58d7af-82d3-401f-8327-1cfceb2bed10
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ea93dda4-5df1-4915-a598-1d1b78848c18
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 79df10e0-4528-4397-a6cf-c3021fce396e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 19aeafe4-ab0c-44c0-be4b-702c43ce1a8a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ef4eed18-45d2-44cb-94dc-4486e7883b59
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eeef56f4-9116-4a78-bb69-aef53eb2ea34
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7c533973-f515-4fb0-a1d7-5c79f9c9272c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a1cb4a58-5d99-427e-80cf-c673cb8fc4a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 64fc1a72-5ad5-454f-b97c-dd65115b3e94
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 33c7ccf9-3461-4b80-a70f-25afe8dd929c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d6429b88-8ea8-43df-9c8c-1b4803e4a22d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7fb895f6-3931-4587-a451-c87af8f06441
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fd3c757e-1e95-4303-ae42-d96388a55d1b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 62321eb8-c438-4547-9afb-d730c58775e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d70f1220-8425-4a27-897b-76d801b58eba
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9e898845-9149-4d9b-ae10-fb9d97e695a7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dbe8d995-cc6b-4477-88dd-8befa7ff8181
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4509ea42-b663-45c9-be30-da1f9b955727
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 442b5046-298f-47a3-888f-8868ce891f5d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fc40da24-5ca3-49cf-bbfe-ee13626c33a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 78cecb5a-4cb3-4775-bea0-703ffd37ee01
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8839133a-fb2c-4c04-8da8-82e94693f576
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3afa4cab-12ed-4111-a200-2e1e6a4590a7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 18af8aca-cecf-4a80-9bfb-e1685dba354f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 177e245b-22e1-4c25-a657-0204d86b0061
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 90b9b0ca-7cbc-46c3-b6c2-d92830b01502
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 12d0632a-494e-46c1-9d76-a0ec627611d9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7e63da09-9af0-46a9-8acb-4c4d334f0ae2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 691061ab-2db6-4978-ab54-920af7aa4849
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7890dbd4-157f-4b2f-ae06-ec237f00da58
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9ecdd928-3264-447d-a95c-0cee2f2b3bfc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 09723b35-db2d-4c9d-9de8-80f5e0d7bb00
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4dd418b8-8c1f-45ec-a1c4-351803663682
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d2bdcf98-f81d-451b-8300-f6203ed0827d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cf81361a-032a-4e41-9a83-683df3f7aa0d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aecfaa81-9fdc-42d9-a3a0-85403e41fa54
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 188a8870-dec8-4383-935c-242fe9c894d7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 504e6295-aa48-4b4a-be13-34f85fea1b42
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 022e9d51-be1e-46aa-836c-240a65873627
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7fde9187-968b-49e3-a37e-9f9f4369aaac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message faf74dcc-4af3-4ff0-b8f7-54d588352aab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 57e70db2-bd97-4000-9663-fa4ad45ee5d5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fc865c63-b9ac-409c-b03a-7c4b526f58db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 41cc8e52-1b3e-4503-b8fd-8e50ddfb264c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 039a83ab-6da9-4349-abbb-eb8e912294c4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eb68bcd7-52ce-4dcc-b1ec-4b669fc7695b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 05339d35-50bb-4f17-9faf-79814b1f63f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message adcedc79-4f30-4336-b7b1-ea9c9c401fc5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eb49850a-55b0-4018-8d90-521a6f91b3bc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5f44d050-25ea-48a4-8f61-4547463fd20a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 79804366-b339-4623-bf19-7e7a1b736f77
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b1fcbd07-58fc-43d8-b0ed-ea3fd3719837
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1b1a8057-357a-4c8a-bfea-e0a7da8cf2d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9369afe2-1de5-4637-b3bc-15dc39502f96
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ee2651e8-83db-42a1-b49b-c2d02dcf988f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 594d8ea6-d402-4057-99d1-b739e4ec245c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cf3fcb79-3793-4cc3-a4db-189ef8b87800
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dc66edf7-c0ec-49ff-8ef3-1cefacd84663
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b6b39b04-c35a-438c-b7f8-d66b9e1c192c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b547b784-d4fc-4353-a9e5-29a0bf03f2b6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b292a712-9445-4e35-b2dc-3d49e551c57f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8bf90555-86d0-4083-ba8c-974e8e9def2c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d9961063-e981-4dfa-af6a-4dc2ad8b1a87
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0a0b06a4-436a-4d0a-bc50-6bf858b4dd15
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ec7dced6-26fe-4e23-9afc-c826704c9523
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0754c40e-67af-416c-aefa-82bb481a6821
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ca0dd8c7-f74e-4a00-a11d-ff8af305eeb3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5c50d0fc-4fce-4e81-99e0-635d83965cec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d0be496f-988d-44ff-8927-35cf8961021d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 906a4e63-c893-4f9c-83f1-de78754e81db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9e10cac8-fc49-43d8-b755-e746bb43dbec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1b1843d9-e258-4e50-af8b-737c12785d2c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0dd35a0c-8afc-404d-be5d-d91f663608f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ce74b084-677e-4ed4-9e8c-08c4c6a15faa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 425a2000-328d-41ee-851c-325b8e1b0de1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0d106ba1-d61a-48f6-a556-0e0a121622e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 726fff95-2a03-485c-b765-1a48e74fb4c5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 06238432-4750-4684-a4d1-3f4fa5af5d7e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b354f8f5-a5da-414d-ac9b-690b57695614
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9f73a3ba-60ee-4af9-a592-a8b5cdbbe16f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 59da6934-b093-4402-a751-aafb8db6fc9b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 472dd2ee-ca4b-4763-b04d-20fd4868f554
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4b942343-2d85-4135-82c6-7c9673b35381
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 471ec23f-624b-4384-8ac5-b2a135d10fc0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4840fedb-95c7-4afa-91a3-907e4e9a01c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 707bc1eb-546a-44b4-96ed-8a1636d40147
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1bf342e7-8473-4ef9-a397-df2c23f8dae3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 922bf17d-ff99-4e91-86e3-5a519ed92159
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fdfdec20-342d-4205-80d2-afaa903745b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6a2dcff7-143d-4dcc-bcb2-5ddbcde4354d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e597ec83-275b-4441-9905-45b232df7bcb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 29cb4bb8-ebfe-4329-85c0-722e30a7ebd1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ef11d1c7-e5fa-4c34-8bad-97089d20aa95
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 70c52f68-b7bb-4086-babb-405b9d18d67e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 00733f19-e803-4f30-9411-daacc597f06a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d2fbd9fe-82e9-4305-b16c-c42580d0cceb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bcb12319-5998-4575-87ad-d429754b766a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4173ce6f-42bf-4152-bb83-c392cf9f5657
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 89b65153-4b6c-4b4b-a879-287651293191
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f0bb7e18-a34c-4d75-8247-d58bf195fabd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1f0a5f83-bda2-4eb2-b76d-e2cc83af29e0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2234aae0-f46a-4699-b812-b6858ec90080
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5d81758f-b677-4ea4-88b3-aa324d7c10d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4601f824-792d-4c10-8cca-a5e49d76c1b5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9e1ac808-18bb-42bf-af56-850fde3719ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c40c0acb-580c-4cbf-8d52-ae1f1e82a734
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 306c73ed-f9c2-457c-a1e1-1c7ecee04f09
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bedb9683-8d9b-41fe-8a3f-559c1d04d116
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 993bf9d5-abc3-4182-b9c3-18216928a353
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 75af49d6-4db9-4ecc-b5ea-1cc73ec856b6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 46020316-c16a-4386-aa57-ff5b3c5d385e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d68347c3-2898-403d-9507-387e17a946a3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message adaa4a27-977e-4027-be17-d1f6e2706a00
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c46c4127-bb84-427b-ab6e-d40f8adf99fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 58609c27-8220-4c0e-a450-b230fe1e9299
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 85999c5c-8b0e-450b-a9f9-84eb1dbcfbce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1f7017ed-8f31-4755-8e3e-19d5c11cebc9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0de1b1f5-0a84-49f5-a061-fd94e4cf3e38
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6ea4fc9a-461b-4262-b7b7-167500115ce0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 874834a4-d1af-429f-ad5a-5851a688f74c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4c5ec533-bc5d-4492-a180-8f0283da0d78
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6513c495-9851-45b5-a551-c174d8c61cfb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 68f03716-04cc-4e0c-9966-95f2da564ccf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8368e506-4f01-420c-b03f-3d8d67a28c85
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 38c0c1c6-7ea2-4e90-98df-d7faf60526b7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 29e3b3a5-32d1-4bd6-a2fa-de14bf137d10
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 02e4ca1d-0215-4788-aaeb-d66feb13b4fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 39079889-a3c7-448c-b4a4-db2f03e4110d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0d2828c3-f00c-4e9d-b2fa-1a94416c9929
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8687 {grpc_message:"Socket closed", grpc_status:14}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_72
Server: localhost:8687
Algorithm: FEDAVG
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_72
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_72/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_72/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_72/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_72/test_labels.txt

📊 Raw data loaded:
   Train: X=(2172, 24), y=(2172,)
   Test:  X=(543, 24), y=(543,)

⚠️  Limiting training data: 2172 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  534 samples, 5 features
✅ Client client_72 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

📊 Round 0 Test Metrics:
   Loss: 0.0810, RMSE: 0.2846, MAE: 0.2458, R²: 0.0081

============================================================
🔄 Round 7 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0833, val=0.0890 (↓), lr=0.001000
   • Epoch   2/100: train=0.0825, val=0.0914, patience=1/15, lr=0.001000
   • Epoch   3/100: train=0.0840, val=0.0908, patience=2/15, lr=0.001000
   • Epoch   4/100: train=0.0846, val=0.0892, patience=3/15, lr=0.001000
   ✓ Epoch   5/100: train=0.0837, val=0.0879 (↓), lr=0.001000
   • Epoch  11/100: train=0.0804, val=0.0886, patience=6/15, lr=0.001000
   📉 Epoch 12: LR reduced 0.001000 → 0.000500
   📉 Epoch 20: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0879)

============================================================
📊 Round 7 Summary - Client client_72
   Epochs: 20/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=0.0283
   Val:   Loss=0.0879, RMSE=0.2964, R²=0.0133
============================================================


📊 Round 7 Test Metrics:
   Loss: 0.0806, RMSE: 0.2839, MAE: 0.2454, R²: 0.0130

============================================================
🔄 Round 12 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0828 (↓), lr=0.000250
   • Epoch   2/100: train=0.0839, val=0.0830, patience=1/15, lr=0.000250
   • Epoch   3/100: train=0.0833, val=0.0831, patience=2/15, lr=0.000250
   • Epoch   4/100: train=0.0829, val=0.0830, patience=3/15, lr=0.000250
   • Epoch   5/100: train=0.0826, val=0.0831, patience=4/15, lr=0.000250
   📉 Epoch 8: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0813, val=0.0828, patience=10/15, lr=0.000125

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 12 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000250 → 0.000125 (1 reductions)
   Train: Loss=0.0836, RMSE=0.2892, R²=0.0099
   Val:   Loss=0.0828, RMSE=0.2878, R²=0.0359
============================================================


============================================================
🔄 Round 14 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000125
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0841 (↓), lr=0.000125
   • Epoch   2/100: train=0.0834, val=0.0840, patience=1/15, lr=0.000125
   • Epoch   3/100: train=0.0830, val=0.0838, patience=2/15, lr=0.000125
   • Epoch   4/100: train=0.0828, val=0.0837, patience=3/15, lr=0.000125
   • Epoch   5/100: train=0.0825, val=0.0836, patience=4/15, lr=0.000125
   📉 Epoch 6: LR reduced 0.000125 → 0.000063
   • Epoch  11/100: train=0.0816, val=0.0836, patience=4/15, lr=0.000063
   📉 Epoch 14: LR reduced 0.000063 → 0.000031
   • Epoch  21/100: train=0.0810, val=0.0836, patience=14/15, lr=0.000031
   📉 Epoch 22: LR reduced 0.000031 → 0.000016

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 14 Summary - Client client_72
   Epochs: 22/100 (early stopped)
   LR: 0.000125 → 0.000016 (3 reductions)
   Train: Loss=0.0818, RMSE=0.2861, R²=0.0378
   Val:   Loss=0.0836, RMSE=0.2891, R²=-0.0009
============================================================


📊 Round 14 Test Metrics:
   Loss: 0.0805, RMSE: 0.2837, MAE: 0.2453, R²: 0.0143

📊 Round 14 Test Metrics:
   Loss: 0.0805, RMSE: 0.2837, MAE: 0.2453, R²: 0.0140

============================================================
🔄 Round 18 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000016
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0844 (↓), lr=0.000016
   • Epoch   2/100: train=0.0838, val=0.0843, patience=1/15, lr=0.000016
   • Epoch   3/100: train=0.0837, val=0.0843, patience=2/15, lr=0.000016
   • Epoch   4/100: train=0.0837, val=0.0842, patience=3/15, lr=0.000016
   • Epoch   5/100: train=0.0836, val=0.0842, patience=4/15, lr=0.000016
   📉 Epoch 8: LR reduced 0.000016 → 0.000008
   • Epoch  11/100: train=0.0834, val=0.0841, patience=10/15, lr=0.000008
   📉 Epoch 16: LR reduced 0.000008 → 0.000004

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 18 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000016 → 0.000004 (2 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=0.0171
   Val:   Loss=0.0844, RMSE=0.2906, R²=-0.0100
============================================================


📊 Round 18 Test Metrics:
   Loss: 0.0805, RMSE: 0.2837, MAE: 0.2452, R²: 0.0141

📊 Round 18 Test Metrics:
   Loss: 0.0805, RMSE: 0.2837, MAE: 0.2452, R²: 0.0141

📊 Round 18 Test Metrics:
   Loss: 0.0805, RMSE: 0.2837, MAE: 0.2452, R²: 0.0141

============================================================
🔄 Round 26 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000004
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0802 (↓), lr=0.000004
   • Epoch   2/100: train=0.0844, val=0.0802, patience=1/15, lr=0.000004
   • Epoch   3/100: train=0.0843, val=0.0801, patience=2/15, lr=0.000004
   • Epoch   4/100: train=0.0843, val=0.0801, patience=3/15, lr=0.000004
   • Epoch   5/100: train=0.0843, val=0.0801, patience=4/15, lr=0.000004
   • Epoch  11/100: train=0.0841, val=0.0799, patience=10/15, lr=0.000004

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 26 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000004 → 0.000004 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=0.0044
   Val:   Loss=0.0802, RMSE=0.2832, R²=0.0383
============================================================


📊 Round 26 Test Metrics:
   Loss: 0.0805, RMSE: 0.2837, MAE: 0.2452, R²: 0.0141

============================================================
🔄 Round 27 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000004
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0775 (↓), lr=0.000004
   • Epoch   2/100: train=0.0855, val=0.0775, patience=1/15, lr=0.000004
   • Epoch   3/100: train=0.0854, val=0.0776, patience=2/15, lr=0.000004
   • Epoch   4/100: train=0.0854, val=0.0776, patience=3/15, lr=0.000004
   • Epoch   5/100: train=0.0853, val=0.0776, patience=4/15, lr=0.000004
   📉 Epoch 7: LR reduced 0.000004 → 0.000002
   • Epoch  11/100: train=0.0851, val=0.0778, patience=10/15, lr=0.000002
   📉 Epoch 15: LR reduced 0.000002 → 0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 27 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000004 → 0.000001 (2 reductions)
   Train: Loss=0.0854, RMSE=0.2922, R²=0.0064
   Val:   Loss=0.0775, RMSE=0.2783, R²=0.0034
============================================================


📊 Round 27 Test Metrics:
   Loss: 0.0805, RMSE: 0.2837, MAE: 0.2452, R²: 0.0142

============================================================
🔄 Round 29 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0845 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0845, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0845, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0845, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0845)

============================================================
📊 Round 29 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0837, RMSE=0.2892, R²=0.0064
   Val:   Loss=0.0845, RMSE=0.2907, R²=0.0281
============================================================


============================================================
🔄 Round 32 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 32 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2899, R²=0.0165
   Val:   Loss=0.0829, RMSE=0.2879, R²=-0.0160
============================================================


📊 Round 32 Test Metrics:
   Loss: 0.0805, RMSE: 0.2837, MAE: 0.2452, R²: 0.0142

📊 Round 32 Test Metrics:
   Loss: 0.0805, RMSE: 0.2837, MAE: 0.2452, R²: 0.0142

📊 Round 32 Test Metrics:
   Loss: 0.0805, RMSE: 0.2837, MAE: 0.2452, R²: 0.0142

============================================================
🔄 Round 40 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0871 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0872, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0872, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0872, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0872, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0832, val=0.0873, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0871)

============================================================
📊 Round 40 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=0.0012
   Val:   Loss=0.0871, RMSE=0.2952, R²=0.0395
============================================================


============================================================
🔄 Round 41 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0925 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0925, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0925, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0925, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0925, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0925, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0925)

============================================================
📊 Round 41 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2858, R²=0.0070
   Val:   Loss=0.0925, RMSE=0.3041, R²=0.0238
============================================================


📊 Round 41 Test Metrics:
   Loss: 0.0805, RMSE: 0.2837, MAE: 0.2452, R²: 0.0141

============================================================
🔄 Round 43 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0861, val=0.0741 (↓), lr=0.000001
   • Epoch   2/100: train=0.0861, val=0.0741, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0861, val=0.0741, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0861, val=0.0741, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0861, val=0.0741, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0860, val=0.0741, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0741)

============================================================
📊 Round 43 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2937, R²=0.0061
   Val:   Loss=0.0741, RMSE=0.2722, R²=0.0122
============================================================


📊 Round 43 Test Metrics:
   Loss: 0.0805, RMSE: 0.2837, MAE: 0.2452, R²: 0.0141

============================================================
🔄 Round 44 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0841, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 44 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=0.0101
   Val:   Loss=0.0839, RMSE=0.2897, R²=-0.0178
============================================================


============================================================
🔄 Round 45 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0868, val=0.0728 (↓), lr=0.000001
   • Epoch   2/100: train=0.0868, val=0.0728, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0868, val=0.0728, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0868, val=0.0728, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0868, val=0.0728, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0867, val=0.0728, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0728)

============================================================
📊 Round 45 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0866, RMSE=0.2942, R²=0.0067
   Val:   Loss=0.0728, RMSE=0.2699, R²=0.0260
============================================================


============================================================
🔄 Round 47 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 47 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2906, R²=0.0046
   Val:   Loss=0.0815, RMSE=0.2855, R²=0.0244
============================================================


📊 Round 47 Test Metrics:
   Loss: 0.0805, RMSE: 0.2837, MAE: 0.2452, R²: 0.0141

📊 Round 47 Test Metrics:
   Loss: 0.0805, RMSE: 0.2837, MAE: 0.2452, R²: 0.0141

============================================================
🔄 Round 51 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 51 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2906, R²=-0.0011
   Val:   Loss=0.0814, RMSE=0.2852, R²=0.0532
============================================================


============================================================
🔄 Round 52 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 52 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=0.0062
   Val:   Loss=0.0820, RMSE=0.2864, R²=0.0271
============================================================


📊 Round 52 Test Metrics:
   Loss: 0.0805, RMSE: 0.2837, MAE: 0.2452, R²: 0.0141

============================================================
🔄 Round 53 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0934 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0934, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0934, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0934, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0934, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0933, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0934)

============================================================
📊 Round 53 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2854, R²=0.0147
   Val:   Loss=0.0934, RMSE=0.3056, R²=-0.0050
============================================================


📊 Round 53 Test Metrics:
   Loss: 0.0805, RMSE: 0.2837, MAE: 0.2452, R²: 0.0141

============================================================
🔄 Round 54 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 54 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=0.0123
   Val:   Loss=0.0817, RMSE=0.2857, R²=-0.0027
============================================================


📊 Round 54 Test Metrics:
   Loss: 0.0805, RMSE: 0.2837, MAE: 0.2452, R²: 0.0141

============================================================
🔄 Round 55 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0916 (↓), lr=0.000001
   • Epoch   2/100: train=0.0819, val=0.0916, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0819, val=0.0916, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0916, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0916, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0916, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0916)

============================================================
📊 Round 55 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2862, R²=0.0140
   Val:   Loss=0.0916, RMSE=0.3027, R²=-0.0133
============================================================


📊 Round 55 Test Metrics:
   Loss: 0.0805, RMSE: 0.2837, MAE: 0.2452, R²: 0.0141

============================================================
🔄 Round 59 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 59 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0849, RMSE=0.2913, R²=0.0129
   Val:   Loss=0.0798, RMSE=0.2825, R²=-0.0002
============================================================


📊 Round 59 Test Metrics:
   Loss: 0.0805, RMSE: 0.2837, MAE: 0.2452, R²: 0.0141

============================================================
🔄 Round 61 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0847, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0847, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0847, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0846, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 61 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=0.0058
   Val:   Loss=0.0812, RMSE=0.2849, R²=0.0022
============================================================


📊 Round 61 Test Metrics:
   Loss: 0.0805, RMSE: 0.2837, MAE: 0.2452, R²: 0.0141

============================================================
🔄 Round 62 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0821, val=0.0909 (↓), lr=0.000001
   • Epoch   2/100: train=0.0821, val=0.0909, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0909, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0909, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0908, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0820, val=0.0908, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0909)

============================================================
📊 Round 62 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=0.0083
   Val:   Loss=0.0909, RMSE=0.3015, R²=0.0183
============================================================


============================================================
🔄 Round 64 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0744 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0744, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0744, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0745, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0745, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0745, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0744)

============================================================
📊 Round 64 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2936, R²=0.0046
   Val:   Loss=0.0744, RMSE=0.2728, R²=0.0200
============================================================


📊 Round 64 Test Metrics:
   Loss: 0.0805, RMSE: 0.2837, MAE: 0.2452, R²: 0.0141

============================================================
🔄 Round 66 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 66 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=0.0050
   Val:   Loss=0.0821, RMSE=0.2865, R²=0.0158
============================================================


============================================================
🔄 Round 67 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0834, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0833, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0833, val=0.0859, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0833, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0833, val=0.0858, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 67 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2887, R²=0.0088
   Val:   Loss=0.0859, RMSE=0.2931, R²=0.0125
============================================================


📊 Round 67 Test Metrics:
   Loss: 0.0805, RMSE: 0.2837, MAE: 0.2452, R²: 0.0141

📊 Round 67 Test Metrics:
   Loss: 0.0805, RMSE: 0.2837, MAE: 0.2452, R²: 0.0141

============================================================
🔄 Round 70 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0838, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 70 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2892, R²=0.0143
   Val:   Loss=0.0848, RMSE=0.2911, R²=-0.0062
============================================================


📊 Round 70 Test Metrics:
   Loss: 0.0805, RMSE: 0.2837, MAE: 0.2452, R²: 0.0141

============================================================
🔄 Round 72 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0829, val=0.0873 (↓), lr=0.000001
   • Epoch   2/100: train=0.0829, val=0.0873, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0829, val=0.0873, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0873, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0873, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0828, val=0.0873, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0873)

============================================================
📊 Round 72 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2881, R²=0.0046
   Val:   Loss=0.0873, RMSE=0.2955, R²=0.0217
============================================================


📊 Round 72 Test Metrics:
   Loss: 0.0805, RMSE: 0.2837, MAE: 0.2452, R²: 0.0141

============================================================
🔄 Round 73 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0892 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0892, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0892, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0892, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0892, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0892, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0892)

============================================================
📊 Round 73 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0825, RMSE=0.2873, R²=0.0166
   Val:   Loss=0.0892, RMSE=0.2987, R²=-0.0153
============================================================


============================================================
🔄 Round 74 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 74 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0847, RMSE=0.2910, R²=0.0098
   Val:   Loss=0.0807, RMSE=0.2840, R²=0.0043
============================================================


📊 Round 74 Test Metrics:
   Loss: 0.0805, RMSE: 0.2837, MAE: 0.2452, R²: 0.0141

============================================================
🔄 Round 78 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0830, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 78 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=0.0025
   Val:   Loss=0.0857, RMSE=0.2928, R²=0.0361
============================================================


📊 Round 78 Test Metrics:
   Loss: 0.0805, RMSE: 0.2837, MAE: 0.2452, R²: 0.0140

============================================================
🔄 Round 79 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0826, val=0.0889 (↓), lr=0.000001
   • Epoch   2/100: train=0.0826, val=0.0889, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0825, val=0.0889, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0825, val=0.0889, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0825, val=0.0889, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0889, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0889)

============================================================
📊 Round 79 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=0.0089
   Val:   Loss=0.0889, RMSE=0.2981, R²=0.0001
============================================================


📊 Round 79 Test Metrics:
   Loss: 0.0805, RMSE: 0.2837, MAE: 0.2452, R²: 0.0140

============================================================
🔄 Round 80 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0864, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0864, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 80 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=0.0064
   Val:   Loss=0.0864, RMSE=0.2940, R²=0.0249
============================================================


📊 Round 80 Test Metrics:
   Loss: 0.0805, RMSE: 0.2837, MAE: 0.2452, R²: 0.0140

============================================================
🔄 Round 81 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0753 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0753, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0753, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0753, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0753, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0752, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0753)

============================================================
📊 Round 81 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2933, R²=0.0121
   Val:   Loss=0.0753, RMSE=0.2745, R²=0.0018
============================================================


📊 Round 81 Test Metrics:
   Loss: 0.0805, RMSE: 0.2837, MAE: 0.2452, R²: 0.0140

📊 Round 81 Test Metrics:
   Loss: 0.0805, RMSE: 0.2837, MAE: 0.2452, R²: 0.0140

============================================================
🔄 Round 87 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0902 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0902, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0902, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0820, val=0.0902, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0820, val=0.0902, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0819, val=0.0901, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0902)

============================================================
📊 Round 87 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=0.0111
   Val:   Loss=0.0902, RMSE=0.3004, R²=0.0063
============================================================


============================================================
🔄 Round 89 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0835, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0834, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0834, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0834, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0834, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 89 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=0.0150
   Val:   Loss=0.0857, RMSE=0.2927, R²=-0.0091
============================================================


📊 Round 89 Test Metrics:
   Loss: 0.0805, RMSE: 0.2837, MAE: 0.2452, R²: 0.0140

============================================================
🔄 Round 94 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 94 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2901, R²=0.0117
   Val:   Loss=0.0829, RMSE=0.2879, R²=0.0037
============================================================


============================================================
🔄 Round 96 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0825, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 96 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2902, R²=0.0194
   Val:   Loss=0.0826, RMSE=0.2874, R²=-0.0463
============================================================


📊 Round 96 Test Metrics:
   Loss: 0.0805, RMSE: 0.2837, MAE: 0.2452, R²: 0.0140

📊 Round 96 Test Metrics:
   Loss: 0.0805, RMSE: 0.2837, MAE: 0.2452, R²: 0.0140

============================================================
🔄 Round 99 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0763 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0763, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0763, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0763, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0763, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0762, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0763)

============================================================
📊 Round 99 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2929, R²=0.0123
   Val:   Loss=0.0763, RMSE=0.2762, R²=-0.0043
============================================================


📊 Round 99 Test Metrics:
   Loss: 0.0805, RMSE: 0.2837, MAE: 0.2452, R²: 0.0140

============================================================
🔄 Round 100 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0876 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0876, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0876, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0876, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0832, val=0.0876, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0876, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0876)

============================================================
📊 Round 100 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0830, RMSE=0.2880, R²=0.0188
   Val:   Loss=0.0876, RMSE=0.2960, R²=-0.0252
============================================================


📊 Round 100 Test Metrics:
   Loss: 0.0805, RMSE: 0.2837, MAE: 0.2452, R²: 0.0140

📊 Round 100 Test Metrics:
   Loss: 0.0805, RMSE: 0.2837, MAE: 0.2452, R²: 0.0140

============================================================
🔄 Round 103 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0840, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 103 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=0.0066
   Val:   Loss=0.0836, RMSE=0.2891, R²=0.0181
============================================================


📊 Round 103 Test Metrics:
   Loss: 0.0805, RMSE: 0.2837, MAE: 0.2452, R²: 0.0140

============================================================
🔄 Round 104 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0829, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0829, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0829, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0829, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 104 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0841, RMSE=0.2901, R²=0.0153
   Val:   Loss=0.0830, RMSE=0.2880, R²=-0.0123
============================================================


============================================================
🔄 Round 106 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0866, val=0.0739 (↓), lr=0.000001
   • Epoch   2/100: train=0.0866, val=0.0739, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0866, val=0.0739, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0866, val=0.0739, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0865, val=0.0739, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0865, val=0.0738, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0739)

============================================================
📊 Round 106 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0864, RMSE=0.2939, R²=0.0107
   Val:   Loss=0.0739, RMSE=0.2719, R²=0.0066
============================================================


============================================================
🔄 Round 107 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 107 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=0.0132
   Val:   Loss=0.0838, RMSE=0.2896, R²=-0.0030
============================================================


📊 Round 107 Test Metrics:
   Loss: 0.0805, RMSE: 0.2837, MAE: 0.2452, R²: 0.0139

============================================================
🔄 Round 108 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0839, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 108 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0839, RMSE=0.2897, R²=0.0063
   Val:   Loss=0.0838, RMSE=0.2895, R²=0.0080
============================================================


📊 Round 108 Test Metrics:
   Loss: 0.0805, RMSE: 0.2838, MAE: 0.2452, R²: 0.0139

============================================================
🔄 Round 110 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 110 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2916, R²=0.0010
   Val:   Loss=0.0794, RMSE=0.2819, R²=0.0466
============================================================


============================================================
🔄 Round 111 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 111 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2915, R²=0.0206
   Val:   Loss=0.0796, RMSE=0.2822, R²=-0.0414
============================================================


📊 Round 111 Test Metrics:
   Loss: 0.0805, RMSE: 0.2837, MAE: 0.2452, R²: 0.0139

📊 Round 111 Test Metrics:
   Loss: 0.0805, RMSE: 0.2838, MAE: 0.2452, R²: 0.0139

============================================================
🔄 Round 115 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0795 (↓), lr=0.000001
   • Epoch   2/100: train=0.0852, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0852, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0852, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0851, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0795)

============================================================
📊 Round 115 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2916, R²=0.0081
   Val:   Loss=0.0795, RMSE=0.2820, R²=0.0176
============================================================


============================================================
🔄 Round 116 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0810 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0810, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0810, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0810, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0810, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 116 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2909, R²=0.0056
   Val:   Loss=0.0810, RMSE=0.2845, R²=0.0190
============================================================


📊 Round 116 Test Metrics:
   Loss: 0.0805, RMSE: 0.2838, MAE: 0.2452, R²: 0.0139

============================================================
🔄 Round 119 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0849, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0848, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 119 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0850, RMSE=0.2915, R²=0.0079
   Val:   Loss=0.0796, RMSE=0.2822, R²=0.0077
============================================================


📊 Round 119 Test Metrics:
   Loss: 0.0805, RMSE: 0.2838, MAE: 0.2452, R²: 0.0139

============================================================
🔄 Round 120 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0939 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0939, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0939, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0939, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0938, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0938, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0939)

============================================================
📊 Round 120 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2854, R²=0.0004
   Val:   Loss=0.0939, RMSE=0.3064, R²=0.0315
============================================================


============================================================
🔄 Round 122 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0841, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 122 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2901, R²=0.0028
   Val:   Loss=0.0828, RMSE=0.2878, R²=0.0319
============================================================


============================================================
🔄 Round 123 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0832, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0832, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0832, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0832, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0831, val=0.0855, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 123 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=0.0029
   Val:   Loss=0.0855, RMSE=0.2925, R²=0.0256
============================================================


📊 Round 123 Test Metrics:
   Loss: 0.0805, RMSE: 0.2838, MAE: 0.2452, R²: 0.0139

============================================================
🔄 Round 129 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0843, val=0.0821 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0821, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0821, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0842, val=0.0821, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0842, val=0.0821, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0821)

============================================================
📊 Round 129 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=0.0146
   Val:   Loss=0.0821, RMSE=0.2866, R²=-0.0122
============================================================


📊 Round 129 Test Metrics:
   Loss: 0.0805, RMSE: 0.2838, MAE: 0.2452, R²: 0.0139

📊 Round 129 Test Metrics:
   Loss: 0.0805, RMSE: 0.2838, MAE: 0.2452, R²: 0.0139

============================================================
🔄 Round 131 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 131 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2906, R²=0.0100
   Val:   Loss=0.0818, RMSE=0.2859, R²=0.0080
============================================================


============================================================
🔄 Round 132 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0838, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0838, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0838, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0837, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 132 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2899, R²=-0.0077
   Val:   Loss=0.0835, RMSE=0.2890, R²=0.0691
============================================================


📊 Round 132 Test Metrics:
   Loss: 0.0805, RMSE: 0.2838, MAE: 0.2452, R²: 0.0139

📊 Round 132 Test Metrics:
   Loss: 0.0805, RMSE: 0.2838, MAE: 0.2452, R²: 0.0139

============================================================
🔄 Round 135 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0776 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0776, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0776, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0776, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0776, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 135 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2924, R²=0.0124
   Val:   Loss=0.0776, RMSE=0.2786, R²=-0.0160
============================================================


📊 Round 135 Test Metrics:
   Loss: 0.0805, RMSE: 0.2838, MAE: 0.2452, R²: 0.0139

📊 Round 135 Test Metrics:
   Loss: 0.0805, RMSE: 0.2838, MAE: 0.2452, R²: 0.0139

============================================================
🔄 Round 137 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0822 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0822, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0822, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0822, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0822, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0821, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 137 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=0.0137
   Val:   Loss=0.0822, RMSE=0.2867, R²=-0.0082
============================================================


============================================================
🔄 Round 138 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0922 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0922, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0922, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0922, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0922, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0922, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0922)

============================================================
📊 Round 138 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2861, R²=0.0065
   Val:   Loss=0.0922, RMSE=0.3037, R²=0.0198
============================================================


============================================================
🔄 Round 140 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 140 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0842, RMSE=0.2903, R²=0.0148
   Val:   Loss=0.0827, RMSE=0.2876, R²=-0.0149
============================================================


📊 Round 140 Test Metrics:
   Loss: 0.0805, RMSE: 0.2838, MAE: 0.2452, R²: 0.0139

📊 Round 140 Test Metrics:
   Loss: 0.0805, RMSE: 0.2838, MAE: 0.2452, R²: 0.0139

============================================================
🔄 Round 142 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0848, val=0.0806 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0806, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0847, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0847, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0846, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0806)

============================================================
📊 Round 142 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2911, R²=0.0030
   Val:   Loss=0.0806, RMSE=0.2839, R²=-0.0130
============================================================


📊 Round 142 Test Metrics:
   Loss: 0.0805, RMSE: 0.2838, MAE: 0.2452, R²: 0.0139

============================================================
🔄 Round 143 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0908 (↓), lr=0.000001
   • Epoch   2/100: train=0.0824, val=0.0908, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0824, val=0.0908, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0824, val=0.0908, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0824, val=0.0908, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0823, val=0.0907, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0908)

============================================================
📊 Round 143 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0822, RMSE=0.2867, R²=0.0213
   Val:   Loss=0.0908, RMSE=0.3014, R²=-0.0396
============================================================


============================================================
🔄 Round 144 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0823, val=0.0904 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0904, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0903, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0822, val=0.0903, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0822, val=0.0903, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0903, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0904)

============================================================
📊 Round 144 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0823, RMSE=0.2869, R²=0.0200
   Val:   Loss=0.0904, RMSE=0.3006, R²=-0.0306
============================================================


============================================================
🔄 Round 146 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0766 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0766, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0766, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0766, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0766, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0765, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0766)

============================================================
📊 Round 146 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0858, RMSE=0.2929, R²=0.0091
   Val:   Loss=0.0766, RMSE=0.2768, R²=0.0105
============================================================


📊 Round 146 Test Metrics:
   Loss: 0.0805, RMSE: 0.2838, MAE: 0.2452, R²: 0.0139

📊 Round 146 Test Metrics:
   Loss: 0.0805, RMSE: 0.2838, MAE: 0.2452, R²: 0.0139

============================================================
🔄 Round 151 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0842, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0842, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0841, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 151 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=0.0090
   Val:   Loss=0.0827, RMSE=0.2875, R²=0.0106
============================================================


============================================================
🔄 Round 152 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0839 (↓), lr=0.000001
   • Epoch   2/100: train=0.0840, val=0.0839, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0840, val=0.0839, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0840, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0839)

============================================================
📊 Round 152 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2898, R²=0.0045
   Val:   Loss=0.0839, RMSE=0.2896, R²=0.0289
============================================================


📊 Round 152 Test Metrics:
   Loss: 0.0805, RMSE: 0.2838, MAE: 0.2452, R²: 0.0138

============================================================
🔄 Round 153 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0858, val=0.0761 (↓), lr=0.000001
   • Epoch   2/100: train=0.0858, val=0.0761, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0858, val=0.0761, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0858, val=0.0761, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0761, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0857, val=0.0761, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0761)

============================================================
📊 Round 153 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0859, RMSE=0.2931, R²=0.0119
   Val:   Loss=0.0761, RMSE=0.2759, R²=-0.0077
============================================================


============================================================
🔄 Round 154 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0770 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0769, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0857, val=0.0769, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0857, val=0.0769, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0857, val=0.0769, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0856, val=0.0768, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0770)

============================================================
📊 Round 154 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2927, R²=0.0072
   Val:   Loss=0.0770, RMSE=0.2774, R²=0.0191
============================================================


============================================================
🔄 Round 156 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 156 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=0.0074
   Val:   Loss=0.0826, RMSE=0.2874, R²=0.0085
============================================================


📊 Round 156 Test Metrics:
   Loss: 0.0805, RMSE: 0.2838, MAE: 0.2452, R²: 0.0138

📊 Round 156 Test Metrics:
   Loss: 0.0805, RMSE: 0.2838, MAE: 0.2452, R²: 0.0138

📊 Round 156 Test Metrics:
   Loss: 0.0805, RMSE: 0.2838, MAE: 0.2452, R²: 0.0138

📊 Round 156 Test Metrics:
   Loss: 0.0805, RMSE: 0.2838, MAE: 0.2452, R²: 0.0138

📊 Round 156 Test Metrics:
   Loss: 0.0805, RMSE: 0.2838, MAE: 0.2452, R²: 0.0138

============================================================
🔄 Round 162 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0778, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0778, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0778, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0853, val=0.0778, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0778, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 162 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0855, RMSE=0.2924, R²=0.0074
   Val:   Loss=0.0778, RMSE=0.2790, R²=0.0046
============================================================


============================================================
🔄 Round 163 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 163 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0845, RMSE=0.2907, R²=0.0118
   Val:   Loss=0.0817, RMSE=0.2859, R²=-0.0439
============================================================


============================================================
🔄 Round 164 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0844, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0844, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0843, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 164 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2908, R²=0.0029
   Val:   Loss=0.0816, RMSE=0.2857, R²=0.0342
============================================================


📊 Round 164 Test Metrics:
   Loss: 0.0805, RMSE: 0.2838, MAE: 0.2452, R²: 0.0138

============================================================
🔄 Round 165 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0835, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0835, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0834, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 165 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0835, RMSE=0.2890, R²=0.0046
   Val:   Loss=0.0856, RMSE=0.2926, R²=0.0212
============================================================


============================================================
🔄 Round 167 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0828, val=0.0891 (↓), lr=0.000001
   • Epoch   2/100: train=0.0828, val=0.0890, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0828, val=0.0890, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0827, val=0.0890, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0827, val=0.0890, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0827, val=0.0890, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0891)

============================================================
📊 Round 167 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0827, RMSE=0.2876, R²=0.0055
   Val:   Loss=0.0891, RMSE=0.2984, R²=0.0167
============================================================


📊 Round 167 Test Metrics:
   Loss: 0.0805, RMSE: 0.2838, MAE: 0.2452, R²: 0.0138

============================================================
🔄 Round 168 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0745 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0745, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0745, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0744, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0744, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0744, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0745)

============================================================
📊 Round 168 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0863, RMSE=0.2938, R²=0.0096
   Val:   Loss=0.0745, RMSE=0.2729, R²=0.0073
============================================================


============================================================
🔄 Round 169 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0831, val=0.0869 (↓), lr=0.000001
   • Epoch   2/100: train=0.0831, val=0.0869, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0831, val=0.0869, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0831, val=0.0869, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0831, val=0.0869, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0830, val=0.0869, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 169 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0832, RMSE=0.2885, R²=0.0124
   Val:   Loss=0.0869, RMSE=0.2949, R²=-0.0062
============================================================


📊 Round 169 Test Metrics:
   Loss: 0.0805, RMSE: 0.2838, MAE: 0.2452, R²: 0.0138

============================================================
🔄 Round 172 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0866 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0866, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0866, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0866, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0866, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0865, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0866)

============================================================
📊 Round 172 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2886, R²=0.0176
   Val:   Loss=0.0866, RMSE=0.2943, R²=-0.0255
============================================================


============================================================
🔄 Round 173 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0845, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0845, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0845, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0844, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0844, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0844, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 173 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=0.0133
   Val:   Loss=0.0828, RMSE=0.2877, R²=-0.0187
============================================================


============================================================
🔄 Round 174 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0878, val=0.0677 (↓), lr=0.000001
   • Epoch   2/100: train=0.0878, val=0.0677, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0878, val=0.0677, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0878, val=0.0676, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0878, val=0.0676, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0877, val=0.0676, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0677)

============================================================
📊 Round 174 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0880, RMSE=0.2967, R²=0.0092
   Val:   Loss=0.0677, RMSE=0.2601, R²=0.0060
============================================================


============================================================
🔄 Round 175 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0882 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0882, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0882, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0830, val=0.0882, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0882, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0882, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0882)

============================================================
📊 Round 175 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0829, RMSE=0.2879, R²=0.0104
   Val:   Loss=0.0882, RMSE=0.2970, R²=-0.0022
============================================================


📊 Round 175 Test Metrics:
   Loss: 0.0805, RMSE: 0.2838, MAE: 0.2452, R²: 0.0138

============================================================
🔄 Round 176 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0852, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0788, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0851, val=0.0788, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0851, val=0.0788, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0850, val=0.0788, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 176 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2920, R²=0.0021
   Val:   Loss=0.0789, RMSE=0.2808, R²=0.0375
============================================================


📊 Round 176 Test Metrics:
   Loss: 0.0805, RMSE: 0.2838, MAE: 0.2452, R²: 0.0138

============================================================
🔄 Round 177 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0835, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 177 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0834, RMSE=0.2888, R²=0.0149
   Val:   Loss=0.0864, RMSE=0.2939, R²=-0.0144
============================================================


📊 Round 177 Test Metrics:
   Loss: 0.0805, RMSE: 0.2838, MAE: 0.2452, R²: 0.0138

============================================================
🔄 Round 178 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0827, val=0.0894 (↓), lr=0.000001
   • Epoch   2/100: train=0.0827, val=0.0894, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0826, val=0.0894, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0826, val=0.0894, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0826, val=0.0894, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0825, val=0.0893, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0894)

============================================================
📊 Round 178 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0826, RMSE=0.2874, R²=0.0070
   Val:   Loss=0.0894, RMSE=0.2990, R²=0.0165
============================================================


============================================================
🔄 Round 179 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0851, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0851, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0851, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0850, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 179 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0851, RMSE=0.2917, R²=0.0027
   Val:   Loss=0.0796, RMSE=0.2821, R²=0.0335
============================================================


============================================================
🔄 Round 183 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0848, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 183 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0846, RMSE=0.2908, R²=0.0099
   Val:   Loss=0.0816, RMSE=0.2856, R²=0.0052
============================================================


📊 Round 183 Test Metrics:
   Loss: 0.0805, RMSE: 0.2838, MAE: 0.2452, R²: 0.0138

============================================================
🔄 Round 184 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0869, val=0.0724 (↓), lr=0.000001
   • Epoch   2/100: train=0.0869, val=0.0724, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0869, val=0.0724, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0869, val=0.0724, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0869, val=0.0724, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0868, val=0.0723, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0724)

============================================================
📊 Round 184 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0869, RMSE=0.2947, R²=0.0032
   Val:   Loss=0.0724, RMSE=0.2691, R²=0.0361
============================================================


📊 Round 184 Test Metrics:
   Loss: 0.0805, RMSE: 0.2838, MAE: 0.2452, R²: 0.0138

📊 Round 184 Test Metrics:
   Loss: 0.0805, RMSE: 0.2838, MAE: 0.2452, R²: 0.0137

📊 Round 184 Test Metrics:
   Loss: 0.0805, RMSE: 0.2838, MAE: 0.2452, R²: 0.0138

📊 Round 184 Test Metrics:
   Loss: 0.0805, RMSE: 0.2838, MAE: 0.2453, R²: 0.0138

============================================================
🔄 Round 189 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0848 (↓), lr=0.000001
   • Epoch   2/100: train=0.0838, val=0.0848, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0848, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0848, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0848, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0848)

============================================================
📊 Round 189 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0838, RMSE=0.2895, R²=0.0058
   Val:   Loss=0.0848, RMSE=0.2912, R²=-0.0242
============================================================


============================================================
🔄 Round 190 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0849, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0849, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0848, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0848, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0848, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0847, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 190 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=0.0056
   Val:   Loss=0.0808, RMSE=0.2843, R²=0.0123
============================================================


📊 Round 190 Test Metrics:
   Loss: 0.0805, RMSE: 0.2838, MAE: 0.2453, R²: 0.0137

============================================================
🔄 Round 194 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0830, val=0.0887 (↓), lr=0.000001
   • Epoch   2/100: train=0.0830, val=0.0887, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0830, val=0.0887, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0829, val=0.0886, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0829, val=0.0886, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0829, val=0.0886, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0887)

============================================================
📊 Round 194 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0828, RMSE=0.2878, R²=0.0031
   Val:   Loss=0.0887, RMSE=0.2978, R²=0.0283
============================================================


============================================================
🔄 Round 195 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0840, val=0.0855 (↓), lr=0.000001
   • Epoch   2/100: train=0.0839, val=0.0855, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0839, val=0.0855, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0839, val=0.0855, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0839, val=0.0855, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0839, val=0.0854, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0855)

============================================================
📊 Round 195 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0836, RMSE=0.2892, R²=0.0149
   Val:   Loss=0.0855, RMSE=0.2924, R²=-0.0164
============================================================


📊 Round 195 Test Metrics:
   Loss: 0.0805, RMSE: 0.2838, MAE: 0.2453, R²: 0.0137

============================================================
🔄 Round 196 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0857, val=0.0771 (↓), lr=0.000001
   • Epoch   2/100: train=0.0857, val=0.0771, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0856, val=0.0771, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0856, val=0.0771, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0856, val=0.0771, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0855, val=0.0771, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0771)

============================================================
📊 Round 196 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0857, RMSE=0.2928, R²=0.0075
   Val:   Loss=0.0771, RMSE=0.2777, R²=0.0107
============================================================


============================================================
🔄 Round 197 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0809 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0809, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0849, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0809)

============================================================
📊 Round 197 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0848, RMSE=0.2912, R²=0.0101
   Val:   Loss=0.0809, RMSE=0.2845, R²=0.0004
============================================================


📊 Round 197 Test Metrics:
   Loss: 0.0805, RMSE: 0.2838, MAE: 0.2453, R²: 0.0137

📊 Round 197 Test Metrics:
   Loss: 0.0805, RMSE: 0.2838, MAE: 0.2453, R²: 0.0137

📊 Round 197 Test Metrics:
   Loss: 0.0805, RMSE: 0.2838, MAE: 0.2453, R²: 0.0137

📊 Round 197 Test Metrics:
   Loss: 0.0805, RMSE: 0.2838, MAE: 0.2453, R²: 0.0137

📊 Round 197 Test Metrics:
   Loss: 0.0805, RMSE: 0.2838, MAE: 0.2453, R²: 0.0137

📊 Round 197 Test Metrics:
   Loss: 0.0805, RMSE: 0.2838, MAE: 0.2453, R²: 0.0137

📊 Round 197 Test Metrics:
   Loss: 0.0805, RMSE: 0.2838, MAE: 0.2453, R²: 0.0137

============================================================
🔄 Round 204 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0753 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0753, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0860, val=0.0753, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0860, val=0.0753, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0860, val=0.0753, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0859, val=0.0753, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0753)

============================================================
📊 Round 204 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0862, RMSE=0.2936, R²=0.0100
   Val:   Loss=0.0753, RMSE=0.2745, R²=-0.0142
============================================================


============================================================
🔄 Round 205 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0860, val=0.0759 (↓), lr=0.000001
   • Epoch   2/100: train=0.0860, val=0.0759, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0859, val=0.0759, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0859, val=0.0759, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0859, val=0.0759, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0858, val=0.0759, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0759)

============================================================
📊 Round 205 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0860, RMSE=0.2933, R²=0.0065
   Val:   Loss=0.0759, RMSE=0.2755, R²=0.0121
============================================================


============================================================
🔄 Round 206 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0842, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0841, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0841, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0841, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0841, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0840, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 206 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0843, RMSE=0.2903, R²=0.0077
   Val:   Loss=0.0830, RMSE=0.2882, R²=0.0111
============================================================


📊 Round 206 Test Metrics:
   Loss: 0.0805, RMSE: 0.2838, MAE: 0.2453, R²: 0.0137

📊 Round 206 Test Metrics:
   Loss: 0.0805, RMSE: 0.2838, MAE: 0.2453, R²: 0.0137

============================================================
🔄 Round 209 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0836, val=0.0867 (↓), lr=0.000001
   • Epoch   2/100: train=0.0836, val=0.0867, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0836, val=0.0867, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0836, val=0.0867, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0836, val=0.0867, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0835, val=0.0866, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0867)

============================================================
📊 Round 209 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0833, RMSE=0.2887, R²=0.0102
   Val:   Loss=0.0867, RMSE=0.2945, R²=0.0023
============================================================


============================================================
🔄 Round 210 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0837, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0837, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0837, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0837, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0837, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0836, val=0.0840, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 210 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0840, RMSE=0.2899, R²=0.0008
   Val:   Loss=0.0840, RMSE=0.2898, R²=0.0255
============================================================


============================================================
🔄 Round 211 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0824, val=0.0918 (↓), lr=0.000001
   • Epoch   2/100: train=0.0823, val=0.0918, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0823, val=0.0918, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0823, val=0.0918, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0823, val=0.0918, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0822, val=0.0918, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0918)

============================================================
📊 Round 211 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0821, RMSE=0.2865, R²=0.0133
   Val:   Loss=0.0918, RMSE=0.3030, R²=-0.0261
============================================================


📊 Round 211 Test Metrics:
   Loss: 0.0805, RMSE: 0.2838, MAE: 0.2453, R²: 0.0136

📊 Round 211 Test Metrics:
   Loss: 0.0805, RMSE: 0.2838, MAE: 0.2453, R²: 0.0136

📊 Round 211 Test Metrics:
   Loss: 0.0805, RMSE: 0.2838, MAE: 0.2453, R²: 0.0136

📊 Round 211 Test Metrics:
   Loss: 0.0805, RMSE: 0.2838, MAE: 0.2453, R²: 0.0136

============================================================
🔄 Round 217 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0850, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0850, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0850, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0850, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0849, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0849, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 217 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2919, R²=-0.0009
   Val:   Loss=0.0794, RMSE=0.2818, R²=0.0465
============================================================


📊 Round 217 Test Metrics:
   Loss: 0.0805, RMSE: 0.2838, MAE: 0.2453, R²: 0.0136

============================================================
🔄 Round 220 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0846, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0846, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0846, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0846, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0845, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0845, val=0.0826, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 220 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=0.0166
   Val:   Loss=0.0827, RMSE=0.2876, R²=-0.0275
============================================================


============================================================
🔄 Round 221 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0855, val=0.0779 (↓), lr=0.000001
   • Epoch   2/100: train=0.0855, val=0.0779, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0854, val=0.0779, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0854, val=0.0779, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0854, val=0.0779, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0853, val=0.0779, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0779)

============================================================
📊 Round 221 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0856, RMSE=0.2925, R²=0.0006
   Val:   Loss=0.0779, RMSE=0.2790, R²=0.0403
============================================================


============================================================
🔄 Round 222 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0844, val=0.0826 (↓), lr=0.000001
   • Epoch   2/100: train=0.0843, val=0.0826, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0843, val=0.0826, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0843, val=0.0826, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0843, val=0.0826, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0842, val=0.0825, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0826)

============================================================
📊 Round 222 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0844, RMSE=0.2905, R²=0.0023
   Val:   Loss=0.0826, RMSE=0.2875, R²=0.0309
============================================================


============================================================
🔄 Round 224 - Client client_72
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0853, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0853, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0853, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0853, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0852, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0852, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 224 Summary - Client client_72
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0852, RMSE=0.2918, R²=0.0123
   Val:   Loss=0.0796, RMSE=0.2821, R²=-0.0116
============================================================


❌ Client client_72 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8687 {grpc_message:"Socket closed", grpc_status:14}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8687 {grpc_message:"Socket closed", grpc_status:14}"
>
