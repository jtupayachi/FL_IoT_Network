[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0d702f18-bd4e-4811-a71c-e17bace4167e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1bbbb217-5cdc-45bd-99ee-6fb8476b154e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fd1ecdde-e4cd-4642-9298-4724a580a066
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1b02362a-d272-4578-8f7d-65cf843edd62
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 65c9f80f-d9c5-421a-94c7-a8fec2a43eb1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ab89a1a7-0f5a-4182-92ab-2105c78abec5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 08880e92-a4b6-4fdf-9fad-ab2fdaff46f6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4a795e64-7676-4178-b2e7-4db1b918f54f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 197b1257-c84b-42ea-b6d2-17a7fb81d8c7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6f7a5aae-6fc9-42b7-9bfe-240d8d8a6a89
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e68f188e-5f61-4d08-86ee-0117c313216c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2bc2308c-785c-4117-8d5a-43508186f9db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a9743ff8-4bbe-4b85-8542-e2313e458b2e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 06838ba3-25d4-42a9-bcde-0f9541a5a018
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message da6a77f9-e8b8-4dc8-b5f3-1114433169eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 61e76d94-6a96-4d7c-abcb-12f614c36c53
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8faab32a-dafb-4c72-9f56-8988c0f886fb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 85e2f919-016f-478b-b742-c41bbf8b6a3a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 590522fc-fe59-4913-b580-867f0521ab92
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a9fd29b7-5aee-4950-b327-40777caed8f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 62d260f5-d8de-47eb-b721-99aca94161c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5104c5d0-4a82-4968-85d7-d4a329cd96de
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3102b94a-df76-47f4-b80b-5de67f5559e2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a024faa6-5dac-4419-a0a9-58ac693a6e24
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 03e3404f-6e2e-4e50-96ec-67bf2b598de5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2365b05b-ed86-49cb-b823-92c83954cd33
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 493384c6-a0d4-4dc2-9ad7-ae2737290efd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d3c8d774-8187-445c-9374-a50c7bb6e427
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c6449116-220b-463a-a714-33058a1d290e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4fd13187-36ab-40c7-b5ee-98e2c04f8559
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f58640bb-f05d-441b-80fe-b7227396e011
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ba52d1f2-8978-416b-a7e3-7a6058fb427f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 37d0213d-a5a1-4243-9023-bf6b4d3db0be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 54ca2fcb-fd3b-46cb-aa4a-6a14e77be0ae
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 276bedcc-ee82-41dc-94bf-4a337dd7407a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 264fee2a-36e7-4d8c-a863-f91afc76e7a2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cb0f693b-b68f-49af-9fc8-5d62a403dbb9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9fb55ea6-76de-438e-ac85-51a60bc6fcaf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d7b7a548-e456-4d75-8ab7-70948eee6fed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 52b07b65-9376-42a4-8046-a94e8c0c444c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3ba0a0a3-46a3-4ed1-b7c5-de80cae1c1ad
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8c74bc20-e42c-467c-b7a4-32fe94868efc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 509c5323-320e-4b37-8cef-e36867ad7fac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9b38b14a-9d2a-47e0-84a0-5d1e05dda8f8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 795eca58-4dc3-4173-a6d9-0fa325c3c922
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ab32dfc4-7550-4ccd-97d4-448d17d08f8e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a98c8d56-ef89-42dd-aaee-c76cde5d88a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 77962b15-08e8-4958-b4ef-fc5220019928
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message dedd47e7-c58b-4ffc-a9b6-bdebb9dc46f4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a6673365-5365-443e-ae9e-ce4e35f779b1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d0830662-9ff6-4652-95d6-733654192894
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d8da5182-40fa-4601-a6ba-2b77eaacb14e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4f4554c1-ef28-4f5c-bdf9-4dc55f23a508
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message eba6162f-c149-4f9f-9ea5-6e0785da0e04
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4baef5dd-1116-403b-99f0-fc45a9571923
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ba11f7d3-5058-47dd-8e9a-cacd15a3ee76
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8b83bacb-6ae7-4e94-a558-a54f60e76163
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 55c0b8ef-62f3-4d3a-99b1-1a4eb95bb1db
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b6aec8fa-fb00-432d-a8cb-2cb1ea196499
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cf33ebc5-796c-4735-8d6e-183a25c549d5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c640d376-8b74-4612-abc9-44130bc9f53f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1d3baa22-ff5a-4690-8911-4c8a31c3b972
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 13c2be50-8b00-40d2-8c16-fbb735149904
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f90d44ea-616c-4f2e-a52a-2ada4cc24cc9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a57640dc-216d-43d9-b0e7-d067b4a34dea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4589c115-b017-4701-8b73-4ac3b11272f7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6cf4a45d-b53b-4704-9b59-52379414700a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4d39451a-7326-4e8a-bc93-6d5db8b8f8e0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message db919afb-35be-4fcc-867c-37ef43199447
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2650512d-8c2e-4d8f-a008-53167ebfcab6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f7a569d3-0af1-4e8c-97bf-bd6a2ef00be5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3c6b96ac-0a40-4ea9-beea-48f6b31d0a4f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1a36fa8e-eec8-436d-a80e-0bdd5f0418ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 375bf620-5334-413c-a0ea-161b93b5f2d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a948bb59-1ef6-4472-9287-d14898779ca2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6f9577de-9f78-4393-9dfb-b4e5729434e1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 77a0664f-6932-4b4f-b07e-ab7e87dfbf24
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 219b590b-eff7-43c1-9dff-35f56e448a2b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d162363a-3d3c-4f16-bfd7-65d59e6b6d80
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 240ca63d-d4cb-4242-b974-0dfb5d8b7b8a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e44668a0-3dad-4f29-8e8b-82adf8117b64
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0ffef5f3-6a41-484a-95a3-ed5e1b363bdc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7ec51ad0-5273-4909-aee7-a8eb43ba8f50
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 08b03f81-7cc0-4172-a128-68c88f7eced5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5c0b02eb-b3e0-4134-a40a-321abad5ba98
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4ac02ca9-c110-41b9-8f35-8877fbcd42ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 744ef8ab-ee1c-48af-9505-1c5d7ca14ba9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a4768033-75a6-4d37-8651-82ab6d3d1e21
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6ec02133-9999-4b01-8586-b2ae6f6733d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 29bbe0ea-578e-4eb6-929b-0f2c76d98f9a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bc8b38a2-fcae-440b-91b3-6e67e2bfa7b9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7952a175-0bd7-419b-b920-cf6ad1f1ea3f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 172bb073-a1d2-401e-9445-c14de0b4097a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0570d71c-e63c-402e-8fd5-0831170c49c9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message da83bdfa-f30f-4d1a-8cba-99072acc8795
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cce2ab6d-e429-41c6-a931-0adbb1cd876d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ae3100bd-f2f9-4f1a-ab17-cc1781f5bd54
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8204c90f-c6a3-4f05-ab0c-954537cd9091
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1d794173-f8de-4e59-89da-d048b5001723
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 069c939d-3c97-404f-b810-3675e9eb6de2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9dbda16e-5e0a-4cf1-8e82-e0c78c1805d3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 55af69a5-b6a3-439b-b333-7a336ccbf10b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8759f6cd-4c5c-4ec1-99ec-a597e4b66ec5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f08e832a-868f-4a64-8391-f54698a3cf78
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 63ce27fa-ecd1-48ba-910d-4969d75bead8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message df6e2a67-a7d2-469f-9828-b3d2ea8d3344
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f391d19e-8741-4f23-9337-ba38adb59502
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ea350ca4-dde3-4704-b29d-92e80075286c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 45daf725-656a-4838-ad4b-02927e1ed483
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1ed9a313-5f48-472e-a36c-8b2cb34fcc56
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2ba1b483-1b63-48e3-aef8-dcb17136d96b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 83337caf-6d9a-4161-8fcb-ba187c08848c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 16f86c08-5db1-4cc5-b041-f731daaba7da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 49d05916-259d-43b0-9c8e-8c0f206139e4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f97740c4-a392-44b7-909f-46bda046ccff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e0688642-6441-473e-b7d1-2641fa8ba54b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7afdeba0-c255-4798-a65e-ef97bd4a8841
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7fec15fa-8d52-4f22-ac45-6634c50fb936
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bb598d48-771e-4fff-b0d5-39935722f88a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4363e22c-7011-4444-9b13-c09de0359b09
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a4b23b68-2c58-403a-8d11-84c590be8dec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4681ad6f-0cc1-487d-ae6d-8d4e00738941
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 09d3f4da-9900-4bed-8978-67e1d3edf8dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 996ce338-0f78-4ad7-9ce4-dca1fb952c33
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e148e94d-e402-4135-9cb7-2a7c0f8b3fda
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 875dc9fa-48f1-4745-9f17-e47e300dd7b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d7d648f0-f726-40db-ab8c-6f09ab73c418
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 90cf1216-8544-4ba2-864d-d27900a91fc1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d4c7a4f8-ad35-4fda-86c7-d477885b3d75
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 97ddf2d9-db80-49e8-9b05-d54279c592fb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f3d53b95-b35e-4d51-b163-9fca4b99aac3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6cfc85ed-3ee9-4a8b-897f-9540b9d44448
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 73fbf841-444e-47e8-9da7-effb5da79a33
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d6aaf547-b762-4605-bb20-55431c8c8753
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ff0aa8df-0453-42b4-b9cb-31645a0b13f9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9d51e16f-9b26-471c-bd59-69b0e5ee42a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8584454f-92f5-4b25-8622-65b1f1a5395a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ee981297-4990-4191-9739-2a4f05779e9a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bb2883c9-39aa-4093-8c40-d42f18350ffd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e6b47d29-e34b-42b6-abd8-9e7e6facb4d1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 55c7da0e-f2d1-4384-8571-c5ec6a0209df
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 12f8d313-8022-41e8-9926-b542cf7af8dc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1383959e-9a7f-48e4-a030-41aee901d275
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 03146180-daad-4f8f-a707-5f2d0134db83
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e39c54fc-5fcc-4e1b-b809-6739e3a39d62
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 858d5ab5-7eb5-4103-a4c9-49fd4ea32281
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 84d92e04-326f-46e7-b8a5-969ce02a3861
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a86ae591-970f-4d6c-828b-a2dd6244f504
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2ad924e3-00a5-4871-a1bd-cce715fdb482
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ee9fadce-99ab-4965-80ea-f16310d0b37f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6540e133-24bd-47b7-8ef5-9f3c11633375
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 89b049e7-c0fc-4f81-885e-61ec4f8ade4b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8e323fa7-58b5-4646-86d2-019c4def8126
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d25ce7ec-27ea-423b-8721-af681091aace
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 565f84a5-3675-42b2-b7d0-494b807538a7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3704ab30-f24f-4c5b-98c6-940c56cd9f92
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0d05ae1e-7243-4669-9e40-0d0efcc3777e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3c5169a9-708c-414a-8dab-b1ba94948fb7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f732f121-a9de-46d5-bc42-06d3d5d52ca6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c7642ce4-6e73-4f11-afb1-0d678a867924
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fc9bccc3-aae3-40c5-a1f4-22e4231af011
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e3ceb09f-9a3c-4bef-bce5-fa3d3dae6b00
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 43813fc6-0341-4b52-aba5-a3cbcc6110b0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8864d0d6-80c8-4ed8-ae3d-eab430e7a50e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b974e640-ad7d-429f-bb90-ae8915cd2b88
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d49d843a-54c6-4122-ada4-66461ade33de
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 224bdf77-1ea6-451b-b7a4-566b41b85270
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2d16d51e-b994-46ca-86cd-5227e49c98be
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 377e6008-786e-4b95-a257-554636845132
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4aef25b9-bc38-4765-9dd7-5f553ab8e150
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 666f2952-dd97-4127-8eec-804617275faa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3d55c670-38bb-46a7-b0a4-807d6bf34ed2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8f869c58-cd82-4f89-b10f-85165c65684f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 86583dda-428b-413a-9774-32ca1ce57539
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8687 {grpc_status:14, grpc_message:"Socket closed"}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_73
Server: localhost:8687
Algorithm: FEDAVG
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_73
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_73/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_73/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_73/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_73/test_labels.txt

📊 Raw data loaded:
   Train: X=(1311, 24), y=(1311,)
   Test:  X=(328, 24), y=(328,)

⚠️  Limiting training data: 1311 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  319 samples, 5 features
✅ Client client_73 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

📊 Round 0 Test Metrics:
   Loss: 0.0750, RMSE: 0.2739, MAE: 0.2313, R²: 0.0947

============================================================
🔄 Round 9 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0810 (↓), lr=0.001000
   • Epoch   2/100: train=0.0770, val=0.0819, patience=1/15, lr=0.001000
   • Epoch   3/100: train=0.0764, val=0.0819, patience=2/15, lr=0.001000
   • Epoch   4/100: train=0.0761, val=0.0822, patience=3/15, lr=0.001000
   • Epoch   5/100: train=0.0758, val=0.0827, patience=4/15, lr=0.001000
   📉 Epoch 7: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0739, val=0.0835, patience=10/15, lr=0.000500
   📉 Epoch 15: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0810)

============================================================
📊 Round 9 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0765, RMSE=0.2765, R²=0.0724
   Val:   Loss=0.0810, RMSE=0.2847, R²=0.0214
============================================================


📊 Round 9 Test Metrics:
   Loss: 0.0749, RMSE: 0.2736, MAE: 0.2305, R²: 0.0967

📊 Round 9 Test Metrics:
   Loss: 0.0747, RMSE: 0.2732, MAE: 0.2286, R²: 0.0991

============================================================
🔄 Round 20 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0770, val=0.0822 (↓), lr=0.000250
   • Epoch   2/100: train=0.0764, val=0.0823, patience=1/15, lr=0.000250
   • Epoch   3/100: train=0.0760, val=0.0827, patience=2/15, lr=0.000250
   • Epoch   4/100: train=0.0757, val=0.0826, patience=3/15, lr=0.000250
   • Epoch   5/100: train=0.0756, val=0.0826, patience=4/15, lr=0.000250
   📉 Epoch 7: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0747, val=0.0824, patience=10/15, lr=0.000125
   📉 Epoch 15: LR reduced 0.000125 → 0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0822)

============================================================
📊 Round 20 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000250 → 0.000063 (2 reductions)
   Train: Loss=0.0766, RMSE=0.2767, R²=0.0614
   Val:   Loss=0.0822, RMSE=0.2867, R²=0.0440
============================================================


📊 Round 20 Test Metrics:
   Loss: 0.0745, RMSE: 0.2730, MAE: 0.2280, R²: 0.1008

📊 Round 20 Test Metrics:
   Loss: 0.0745, RMSE: 0.2729, MAE: 0.2279, R²: 0.1013

📊 Round 20 Test Metrics:
   Loss: 0.0745, RMSE: 0.2729, MAE: 0.2279, R²: 0.1013

============================================================
🔄 Round 24 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0782, val=0.0752 (↓), lr=0.000063
   • Epoch   2/100: train=0.0779, val=0.0752, patience=1/15, lr=0.000063
   • Epoch   3/100: train=0.0777, val=0.0753, patience=2/15, lr=0.000063
   • Epoch   4/100: train=0.0776, val=0.0754, patience=3/15, lr=0.000063
   • Epoch   5/100: train=0.0774, val=0.0755, patience=4/15, lr=0.000063
   📉 Epoch 7: LR reduced 0.000063 → 0.000031
   • Epoch  11/100: train=0.0769, val=0.0757, patience=10/15, lr=0.000031
   📉 Epoch 15: LR reduced 0.000031 → 0.000016

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0752)

============================================================
📊 Round 24 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000063 → 0.000016 (2 reductions)
   Train: Loss=0.0781, RMSE=0.2795, R²=0.0658
   Val:   Loss=0.0752, RMSE=0.2742, R²=0.0396
============================================================


============================================================
🔄 Round 25 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000016
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0694 (↓), lr=0.000016
   • Epoch   2/100: train=0.0797, val=0.0695, patience=1/15, lr=0.000016
   • Epoch   3/100: train=0.0796, val=0.0696, patience=2/15, lr=0.000016
   • Epoch   4/100: train=0.0795, val=0.0696, patience=3/15, lr=0.000016
   • Epoch   5/100: train=0.0795, val=0.0696, patience=4/15, lr=0.000016
   📉 Epoch 7: LR reduced 0.000016 → 0.000008
   • Epoch  11/100: train=0.0793, val=0.0696, patience=10/15, lr=0.000008
   📉 Epoch 15: LR reduced 0.000008 → 0.000004

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0694)

============================================================
📊 Round 25 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000016 → 0.000004 (2 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=0.0565
   Val:   Loss=0.0694, RMSE=0.2635, R²=0.0576
============================================================


📊 Round 25 Test Metrics:
   Loss: 0.0745, RMSE: 0.2729, MAE: 0.2279, R²: 0.1014

============================================================
🔄 Round 26 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000004
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0708 (↓), lr=0.000004
   • Epoch   2/100: train=0.0794, val=0.0708, patience=1/15, lr=0.000004
   • Epoch   3/100: train=0.0794, val=0.0708, patience=2/15, lr=0.000004
   • Epoch   4/100: train=0.0794, val=0.0708, patience=3/15, lr=0.000004
   • Epoch   5/100: train=0.0793, val=0.0708, patience=4/15, lr=0.000004
   📉 Epoch 7: LR reduced 0.000004 → 0.000002
   • Epoch  11/100: train=0.0793, val=0.0707, patience=10/15, lr=0.000002
   📉 Epoch 15: LR reduced 0.000002 → 0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0708)

============================================================
📊 Round 26 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000004 → 0.000001 (2 reductions)
   Train: Loss=0.0794, RMSE=0.2818, R²=0.0662
   Val:   Loss=0.0708, RMSE=0.2661, R²=0.0233
============================================================


============================================================
🔄 Round 27 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0765, val=0.0827 (↓), lr=0.000001
   • Epoch   2/100: train=0.0765, val=0.0827, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0765, val=0.0827, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0764, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0764, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0764, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0827)

============================================================
📊 Round 27 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0764, RMSE=0.2765, R²=0.0636
   Val:   Loss=0.0827, RMSE=0.2876, R²=0.0403
============================================================


============================================================
🔄 Round 28 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0774, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0774, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0774, val=0.0782, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0774, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0774, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0773, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 28 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0776, RMSE=0.2785, R²=0.0578
   Val:   Loss=0.0782, RMSE=0.2796, R²=0.0619
============================================================


📊 Round 28 Test Metrics:
   Loss: 0.0745, RMSE: 0.2729, MAE: 0.2279, R²: 0.1014

📊 Round 28 Test Metrics:
   Loss: 0.0745, RMSE: 0.2729, MAE: 0.2279, R²: 0.1014

============================================================
🔄 Round 31 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0770, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0769, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0769, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0769, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0769, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0769, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 31 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0768, RMSE=0.2771, R²=0.0634
   Val:   Loss=0.0814, RMSE=0.2853, R²=0.0297
============================================================


============================================================
🔄 Round 32 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0734 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0734, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0734, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0734, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0734, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0734, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0734)

============================================================
📊 Round 32 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2806, R²=0.0579
   Val:   Loss=0.0734, RMSE=0.2710, R²=0.0580
============================================================


📊 Round 32 Test Metrics:
   Loss: 0.0745, RMSE: 0.2729, MAE: 0.2279, R²: 0.1014

============================================================
🔄 Round 34 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0755, val=0.0858 (↓), lr=0.000001
   • Epoch   2/100: train=0.0755, val=0.0858, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0755, val=0.0858, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0755, val=0.0858, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0755, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0754, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0858)

============================================================
📊 Round 34 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0757, RMSE=0.2751, R²=0.0656
   Val:   Loss=0.0858, RMSE=0.2930, R²=0.0178
============================================================


============================================================
🔄 Round 35 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0782, val=0.0762 (↓), lr=0.000001
   • Epoch   2/100: train=0.0782, val=0.0762, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0782, val=0.0762, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0782, val=0.0762, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0782, val=0.0762, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0782, val=0.0762, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0762)

============================================================
📊 Round 35 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0781, RMSE=0.2794, R²=0.0657
   Val:   Loss=0.0762, RMSE=0.2761, R²=0.0256
============================================================


📊 Round 35 Test Metrics:
   Loss: 0.0745, RMSE: 0.2729, MAE: 0.2279, R²: 0.1015

📊 Round 35 Test Metrics:
   Loss: 0.0745, RMSE: 0.2729, MAE: 0.2279, R²: 0.1015

📊 Round 35 Test Metrics:
   Loss: 0.0745, RMSE: 0.2729, MAE: 0.2279, R²: 0.1015

📊 Round 35 Test Metrics:
   Loss: 0.0745, RMSE: 0.2729, MAE: 0.2279, R²: 0.1015

============================================================
🔄 Round 42 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0678 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0679, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0679, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0679, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0679, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0679, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0678)

============================================================
📊 Round 42 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2831, R²=0.0650
   Val:   Loss=0.0678, RMSE=0.2605, R²=0.0284
============================================================


============================================================
🔄 Round 43 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0771, val=0.0800 (↓), lr=0.000001
   • Epoch   2/100: train=0.0771, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0771, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0770, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0770, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0770, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0800)

============================================================
📊 Round 43 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0771, RMSE=0.2777, R²=0.0548
   Val:   Loss=0.0800, RMSE=0.2829, R²=0.0658
============================================================


============================================================
🔄 Round 44 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0783, val=0.0756 (↓), lr=0.000001
   • Epoch   2/100: train=0.0783, val=0.0756, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0783, val=0.0756, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0782, val=0.0756, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0782, val=0.0756, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0782, val=0.0755, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0756)

============================================================
📊 Round 44 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0782, RMSE=0.2797, R²=0.0532
   Val:   Loss=0.0756, RMSE=0.2749, R²=0.0815
============================================================


📊 Round 44 Test Metrics:
   Loss: 0.0745, RMSE: 0.2729, MAE: 0.2278, R²: 0.1015

============================================================
🔄 Round 45 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0757, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0757, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0757, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0757, val=0.0859, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0757, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0757, val=0.0859, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 45 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0757, RMSE=0.2750, R²=0.0581
   Val:   Loss=0.0859, RMSE=0.2930, R²=0.0566
============================================================


📊 Round 45 Test Metrics:
   Loss: 0.0745, RMSE: 0.2729, MAE: 0.2278, R²: 0.1015

============================================================
🔄 Round 47 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0783, val=0.0744 (↓), lr=0.000001
   • Epoch   2/100: train=0.0783, val=0.0744, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0783, val=0.0744, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0783, val=0.0744, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0783, val=0.0744, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0744, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0744)

============================================================
📊 Round 47 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2802, R²=0.0622
   Val:   Loss=0.0744, RMSE=0.2728, R²=0.0444
============================================================


============================================================
🔄 Round 48 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0746 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0746, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0746, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0746, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0746, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0746, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0746)

============================================================
📊 Round 48 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2801, R²=0.0544
   Val:   Loss=0.0746, RMSE=0.2731, R²=0.0686
============================================================


📊 Round 48 Test Metrics:
   Loss: 0.0745, RMSE: 0.2729, MAE: 0.2278, R²: 0.1016

============================================================
🔄 Round 56 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0780, val=0.0767 (↓), lr=0.000001
   • Epoch   2/100: train=0.0780, val=0.0766, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0780, val=0.0766, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0780, val=0.0766, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0780, val=0.0766, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0779, val=0.0766, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0767)

============================================================
📊 Round 56 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0779, RMSE=0.2792, R²=0.0456
   Val:   Loss=0.0767, RMSE=0.2769, R²=0.1095
============================================================


============================================================
🔄 Round 58 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0773, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0773, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0773, val=0.0781, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0773, val=0.0781, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0773, val=0.0781, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0773, val=0.0781, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 58 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0776, RMSE=0.2785, R²=0.0677
   Val:   Loss=0.0781, RMSE=0.2795, R²=0.0192
============================================================


============================================================
🔄 Round 59 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0775, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0775, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0775, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0774, val=0.0787, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0774, val=0.0787, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0774, val=0.0787, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 59 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0774, RMSE=0.2783, R²=0.0625
   Val:   Loss=0.0787, RMSE=0.2805, R²=0.0371
============================================================


📊 Round 59 Test Metrics:
   Loss: 0.0744, RMSE: 0.2728, MAE: 0.2278, R²: 0.1017

============================================================
🔄 Round 61 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0759, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0759, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0759, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0759, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0759, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0758, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 61 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0760, RMSE=0.2757, R²=0.0697
   Val:   Loss=0.0843, RMSE=0.2904, R²=0.0165
============================================================


============================================================
🔄 Round 62 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0761, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0761, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0761, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0761, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0761, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0760, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 62 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0763, RMSE=0.2762, R²=0.0634
   Val:   Loss=0.0832, RMSE=0.2884, R²=0.0297
============================================================


============================================================
🔄 Round 65 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0772, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0771, val=0.0795, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0771, val=0.0795, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0771, val=0.0795, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0771, val=0.0795, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0771, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 65 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0772, RMSE=0.2779, R²=0.0489
   Val:   Loss=0.0796, RMSE=0.2820, R²=0.0949
============================================================


📊 Round 65 Test Metrics:
   Loss: 0.0744, RMSE: 0.2728, MAE: 0.2278, R²: 0.1017

📊 Round 65 Test Metrics:
   Loss: 0.0744, RMSE: 0.2728, MAE: 0.2278, R²: 0.1017

============================================================
🔄 Round 68 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0773, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0773, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0773, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0773, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0773, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0772, val=0.0789, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 68 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0774, RMSE=0.2781, R²=0.0566
   Val:   Loss=0.0790, RMSE=0.2810, R²=0.0681
============================================================


📊 Round 68 Test Metrics:
   Loss: 0.0744, RMSE: 0.2728, MAE: 0.2278, R²: 0.1017

📊 Round 68 Test Metrics:
   Loss: 0.0744, RMSE: 0.2728, MAE: 0.2278, R²: 0.1017

📊 Round 68 Test Metrics:
   Loss: 0.0744, RMSE: 0.2728, MAE: 0.2278, R²: 0.1018

📊 Round 68 Test Metrics:
   Loss: 0.0744, RMSE: 0.2728, MAE: 0.2278, R²: 0.1018

📊 Round 68 Test Metrics:
   Loss: 0.0744, RMSE: 0.2728, MAE: 0.2278, R²: 0.1018

============================================================
🔄 Round 74 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0733 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0733, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0733, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0733, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0733, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0733, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0733)

============================================================
📊 Round 74 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2807, R²=0.0567
   Val:   Loss=0.0733, RMSE=0.2707, R²=0.0689
============================================================


============================================================
🔄 Round 76 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0744 (↓), lr=0.000001
   • Epoch   2/100: train=0.0785, val=0.0744, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0785, val=0.0744, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0785, val=0.0744, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0785, val=0.0744, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0785, val=0.0744, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0744)

============================================================
📊 Round 76 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2802, R²=0.0606
   Val:   Loss=0.0744, RMSE=0.2727, R²=0.0455
============================================================


📊 Round 76 Test Metrics:
   Loss: 0.0744, RMSE: 0.2728, MAE: 0.2278, R²: 0.1018

============================================================
🔄 Round 77 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0769, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0769, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0769, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0769, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0769, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0769, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 77 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0767, RMSE=0.2770, R²=0.0593
   Val:   Loss=0.0814, RMSE=0.2853, R²=0.0447
============================================================


📊 Round 77 Test Metrics:
   Loss: 0.0744, RMSE: 0.2728, MAE: 0.2278, R²: 0.1018

============================================================
🔄 Round 79 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0730 (↓), lr=0.000001
   • Epoch   2/100: train=0.0787, val=0.0730, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0730, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0730, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0730, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0730, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0730)

============================================================
📊 Round 79 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2808, R²=0.0647
   Val:   Loss=0.0730, RMSE=0.2702, R²=0.0239
============================================================


📊 Round 79 Test Metrics:
   Loss: 0.0744, RMSE: 0.2728, MAE: 0.2278, R²: 0.1018

📊 Round 79 Test Metrics:
   Loss: 0.0744, RMSE: 0.2728, MAE: 0.2278, R²: 0.1018

📊 Round 79 Test Metrics:
   Loss: 0.0744, RMSE: 0.2728, MAE: 0.2278, R²: 0.1019

📊 Round 79 Test Metrics:
   Loss: 0.0744, RMSE: 0.2728, MAE: 0.2278, R²: 0.1018

📊 Round 79 Test Metrics:
   Loss: 0.0744, RMSE: 0.2728, MAE: 0.2277, R²: 0.1019

📊 Round 79 Test Metrics:
   Loss: 0.0744, RMSE: 0.2728, MAE: 0.2277, R²: 0.1019

============================================================
🔄 Round 87 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0694 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0694, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0694, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0694, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0694, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0694, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0694)

============================================================
📊 Round 87 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2824, R²=0.0576
   Val:   Loss=0.0694, RMSE=0.2635, R²=0.0616
============================================================


============================================================
🔄 Round 89 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0736 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0736, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0736, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0736, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0736, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0736, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0736)

============================================================
📊 Round 89 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2805, R²=0.0509
   Val:   Loss=0.0736, RMSE=0.2712, R²=0.0839
============================================================


📊 Round 89 Test Metrics:
   Loss: 0.0744, RMSE: 0.2728, MAE: 0.2277, R²: 0.1019

📊 Round 89 Test Metrics:
   Loss: 0.0744, RMSE: 0.2728, MAE: 0.2277, R²: 0.1019

============================================================
🔄 Round 91 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0770, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0770, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0770, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0770, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0770, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0770, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 91 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0768, RMSE=0.2771, R²=0.0543
   Val:   Loss=0.0812, RMSE=0.2850, R²=0.0732
============================================================


============================================================
🔄 Round 92 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0767, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0767, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0767, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0767, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0767, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0766, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 92 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0768, RMSE=0.2771, R²=0.0613
   Val:   Loss=0.0813, RMSE=0.2851, R²=0.0406
============================================================


📊 Round 92 Test Metrics:
   Loss: 0.0744, RMSE: 0.2728, MAE: 0.2277, R²: 0.1019

📊 Round 92 Test Metrics:
   Loss: 0.0744, RMSE: 0.2728, MAE: 0.2277, R²: 0.1019

============================================================
🔄 Round 95 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0769, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0769, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0769, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0769, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0769, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0768, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 95 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0770, RMSE=0.2776, R²=0.0645
   Val:   Loss=0.0802, RMSE=0.2832, R²=0.0304
============================================================


📊 Round 95 Test Metrics:
   Loss: 0.0744, RMSE: 0.2728, MAE: 0.2277, R²: 0.1019

============================================================
🔄 Round 98 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0730 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0730, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0730, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0730, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0730, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0729, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0730)

============================================================
📊 Round 98 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2808, R²=0.0596
   Val:   Loss=0.0730, RMSE=0.2701, R²=0.0557
============================================================


📊 Round 98 Test Metrics:
   Loss: 0.0744, RMSE: 0.2728, MAE: 0.2277, R²: 0.1019

============================================================
🔄 Round 99 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0765, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0765, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0765, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0765, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0765, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0765, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 99 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0766, RMSE=0.2768, R²=0.0605
   Val:   Loss=0.0819, RMSE=0.2861, R²=0.0536
============================================================


📊 Round 99 Test Metrics:
   Loss: 0.0744, RMSE: 0.2728, MAE: 0.2277, R²: 0.1020

============================================================
🔄 Round 100 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0770, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0769, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0769, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0769, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0769, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0769, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 100 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0771, RMSE=0.2777, R²=0.0581
   Val:   Loss=0.0798, RMSE=0.2825, R²=0.0563
============================================================


============================================================
🔄 Round 101 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0777, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0777, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0777, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0777, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0777, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0776, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 101 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0775, RMSE=0.2784, R²=0.0581
   Val:   Loss=0.0784, RMSE=0.2800, R²=0.0632
============================================================


============================================================
🔄 Round 103 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0772, val=0.0799 (↓), lr=0.000001
   • Epoch   2/100: train=0.0772, val=0.0799, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0772, val=0.0799, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0772, val=0.0799, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0772, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0772, val=0.0799, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0799)

============================================================
📊 Round 103 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0771, RMSE=0.2777, R²=0.0691
   Val:   Loss=0.0799, RMSE=0.2826, R²=0.0178
============================================================


============================================================
🔄 Round 104 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0706 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0706, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0706, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0706, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0706, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0706, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0706)

============================================================
📊 Round 104 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2818, R²=0.0522
   Val:   Loss=0.0706, RMSE=0.2658, R²=0.0877
============================================================


📊 Round 104 Test Metrics:
   Loss: 0.0744, RMSE: 0.2728, MAE: 0.2277, R²: 0.1020

📊 Round 104 Test Metrics:
   Loss: 0.0744, RMSE: 0.2728, MAE: 0.2277, R²: 0.1020

📊 Round 104 Test Metrics:
   Loss: 0.0744, RMSE: 0.2728, MAE: 0.2277, R²: 0.1020

============================================================
🔄 Round 108 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0705 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0706, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0706, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0706, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0706, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0706, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0705)

============================================================
📊 Round 108 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2819, R²=0.0515
   Val:   Loss=0.0705, RMSE=0.2656, R²=0.0845
============================================================


============================================================
🔄 Round 110 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0762, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0762, val=0.0836, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0762, val=0.0836, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0762, val=0.0836, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0762, val=0.0836, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0762, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 110 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0762, RMSE=0.2760, R²=0.0626
   Val:   Loss=0.0836, RMSE=0.2891, R²=0.0446
============================================================


============================================================
🔄 Round 111 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0771, val=0.0794 (↓), lr=0.000001
   • Epoch   2/100: train=0.0771, val=0.0794, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0771, val=0.0794, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0771, val=0.0794, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0771, val=0.0794, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0771, val=0.0793, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0794)

============================================================
📊 Round 111 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0772, RMSE=0.2779, R²=0.0569
   Val:   Loss=0.0794, RMSE=0.2818, R²=0.0680
============================================================


============================================================
🔄 Round 112 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0775, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0775, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0775, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0775, val=0.0792, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0775, val=0.0792, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0775, val=0.0792, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 112 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0773, RMSE=0.2780, R²=0.0604
   Val:   Loss=0.0792, RMSE=0.2814, R²=0.0540
============================================================


============================================================
🔄 Round 114 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0713 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0713, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0713, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0713, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0713, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0713, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0713)

============================================================
📊 Round 114 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2815, R²=0.0510
   Val:   Loss=0.0713, RMSE=0.2671, R²=0.0934
============================================================


============================================================
🔄 Round 115 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0765, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0765, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0764, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0764, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0764, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0764, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 115 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0764, RMSE=0.2764, R²=0.0702
   Val:   Loss=0.0828, RMSE=0.2877, R²=0.0154
============================================================


============================================================
🔄 Round 116 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0713 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0713, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0713, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0713, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0713, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0713, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0713)

============================================================
📊 Round 116 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2815, R²=0.0591
   Val:   Loss=0.0713, RMSE=0.2670, R²=0.0336
============================================================


📊 Round 116 Test Metrics:
   Loss: 0.0744, RMSE: 0.2728, MAE: 0.2277, R²: 0.1021

============================================================
🔄 Round 117 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0768, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0768, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0767, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0767, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0767, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0767, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 117 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0769, RMSE=0.2773, R²=0.0650
   Val:   Loss=0.0807, RMSE=0.2841, R²=0.0308
============================================================


📊 Round 117 Test Metrics:
   Loss: 0.0744, RMSE: 0.2728, MAE: 0.2277, R²: 0.1021

============================================================
🔄 Round 121 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0773, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0773, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0773, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0773, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0773, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0772, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 121 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0772, RMSE=0.2778, R²=0.0523
   Val:   Loss=0.0796, RMSE=0.2821, R²=0.0842
============================================================


============================================================
🔄 Round 122 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0765, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0764, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0764, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0764, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0764, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0764, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 122 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0764, RMSE=0.2764, R²=0.0571
   Val:   Loss=0.0828, RMSE=0.2877, R²=0.0656
============================================================


============================================================
🔄 Round 124 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0766, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0766, val=0.0816, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0766, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0766, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0766, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0765, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 124 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0767, RMSE=0.2769, R²=0.0560
   Val:   Loss=0.0816, RMSE=0.2856, R²=0.0481
============================================================


📊 Round 124 Test Metrics:
   Loss: 0.0744, RMSE: 0.2728, MAE: 0.2277, R²: 0.1021

============================================================
🔄 Round 128 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0704 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0704, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0704, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0704, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0704, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0704, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0704)

============================================================
📊 Round 128 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2819, R²=0.0470
   Val:   Loss=0.0704, RMSE=0.2653, R²=0.1098
============================================================


============================================================
🔄 Round 130 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0718 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0718, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0718, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0718, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0718, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0718, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0718)

============================================================
📊 Round 130 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2813, R²=0.0485
   Val:   Loss=0.0718, RMSE=0.2679, R²=0.1028
============================================================


📊 Round 130 Test Metrics:
   Loss: 0.0744, RMSE: 0.2728, MAE: 0.2277, R²: 0.1021

============================================================
🔄 Round 131 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0689 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0689, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0689, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0689, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0689, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0690, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0689)

============================================================
📊 Round 131 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2826, R²=0.0563
   Val:   Loss=0.0689, RMSE=0.2625, R²=0.0724
============================================================


============================================================
🔄 Round 133 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0770, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0770, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0770, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0770, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0770, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0770, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 133 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0770, RMSE=0.2775, R²=0.0714
   Val:   Loss=0.0803, RMSE=0.2833, R²=0.0085
============================================================


============================================================
🔄 Round 134 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0758, val=0.0842 (↓), lr=0.000001
   • Epoch   2/100: train=0.0758, val=0.0842, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0758, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0758, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0758, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0758, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0842)

============================================================
📊 Round 134 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0760, RMSE=0.2757, R²=0.0706
   Val:   Loss=0.0842, RMSE=0.2902, R²=-0.0145
============================================================


📊 Round 134 Test Metrics:
   Loss: 0.0744, RMSE: 0.2728, MAE: 0.2276, R²: 0.1022

📊 Round 134 Test Metrics:
   Loss: 0.0744, RMSE: 0.2728, MAE: 0.2276, R²: 0.1022

============================================================
🔄 Round 136 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0702 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0702, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0702, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0702, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0702, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0702, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0702)

============================================================
📊 Round 136 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2820, R²=0.0510
   Val:   Loss=0.0702, RMSE=0.2650, R²=0.0933
============================================================


📊 Round 136 Test Metrics:
   Loss: 0.0744, RMSE: 0.2728, MAE: 0.2276, R²: 0.1022

📊 Round 136 Test Metrics:
   Loss: 0.0744, RMSE: 0.2728, MAE: 0.2276, R²: 0.1022

============================================================
🔄 Round 141 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0695 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0695, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0695, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0695, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0695, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0695, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0695)

============================================================
📊 Round 141 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=0.0532
   Val:   Loss=0.0695, RMSE=0.2636, R²=0.0863
============================================================


📊 Round 141 Test Metrics:
   Loss: 0.0744, RMSE: 0.2728, MAE: 0.2276, R²: 0.1022

📊 Round 141 Test Metrics:
   Loss: 0.0744, RMSE: 0.2728, MAE: 0.2276, R²: 0.1022

============================================================
🔄 Round 144 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0780, val=0.0760 (↓), lr=0.000001
   • Epoch   2/100: train=0.0780, val=0.0760, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0780, val=0.0760, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0780, val=0.0760, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0780, val=0.0760, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0780, val=0.0761, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0760)

============================================================
📊 Round 144 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0781, RMSE=0.2794, R²=0.0528
   Val:   Loss=0.0760, RMSE=0.2756, R²=0.0548
============================================================


📊 Round 144 Test Metrics:
   Loss: 0.0744, RMSE: 0.2728, MAE: 0.2276, R²: 0.1022

📊 Round 144 Test Metrics:
   Loss: 0.0744, RMSE: 0.2728, MAE: 0.2276, R²: 0.1022

============================================================
🔄 Round 147 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0725 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0725, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0725, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0725, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0725, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0726, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0725)

============================================================
📊 Round 147 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2810, R²=0.0510
   Val:   Loss=0.0725, RMSE=0.2692, R²=0.0629
============================================================


============================================================
🔄 Round 149 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0781, val=0.0756 (↓), lr=0.000001
   • Epoch   2/100: train=0.0781, val=0.0756, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0781, val=0.0756, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0780, val=0.0756, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0780, val=0.0756, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0780, val=0.0756, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0756)

============================================================
📊 Round 149 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0782, RMSE=0.2796, R²=0.0474
   Val:   Loss=0.0756, RMSE=0.2749, R²=0.0956
============================================================


============================================================
🔄 Round 150 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0701 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0701, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0701, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0701, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0701, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0701, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0701)

============================================================
📊 Round 150 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2820, R²=0.0564
   Val:   Loss=0.0701, RMSE=0.2648, R²=0.0708
============================================================


============================================================
🔄 Round 155 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0748, val=0.0896 (↓), lr=0.000001
   • Epoch   2/100: train=0.0747, val=0.0897, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0747, val=0.0897, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0747, val=0.0897, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0747, val=0.0897, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0747, val=0.0899, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0896)

============================================================
📊 Round 155 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0747, RMSE=0.2732, R²=0.0533
   Val:   Loss=0.0896, RMSE=0.2994, R²=0.0504
============================================================


📊 Round 155 Test Metrics:
   Loss: 0.0744, RMSE: 0.2728, MAE: 0.2276, R²: 0.1022

📊 Round 155 Test Metrics:
   Loss: 0.0744, RMSE: 0.2728, MAE: 0.2276, R²: 0.1022

============================================================
🔄 Round 157 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0717 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0717, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0717, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0717, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0717, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0717, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0717)

============================================================
📊 Round 157 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2813, R²=0.0544
   Val:   Loss=0.0717, RMSE=0.2678, R²=0.0791
============================================================


📊 Round 157 Test Metrics:
   Loss: 0.0744, RMSE: 0.2728, MAE: 0.2276, R²: 0.1023

📊 Round 157 Test Metrics:
   Loss: 0.0744, RMSE: 0.2728, MAE: 0.2276, R²: 0.1023

============================================================
🔄 Round 160 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0771, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0771, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0771, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0770, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0770, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0770, val=0.0807, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 160 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0769, RMSE=0.2773, R²=0.0511
   Val:   Loss=0.0807, RMSE=0.2840, R²=0.0862
============================================================


============================================================
🔄 Round 162 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0775, val=0.0774 (↓), lr=0.000001
   • Epoch   2/100: train=0.0775, val=0.0774, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0775, val=0.0774, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0775, val=0.0774, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0775, val=0.0774, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0774, val=0.0774, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0774)

============================================================
📊 Round 162 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0777, RMSE=0.2788, R²=0.0562
   Val:   Loss=0.0774, RMSE=0.2782, R²=0.0711
============================================================


============================================================
🔄 Round 166 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0732 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0732, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0732, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0732, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0732, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0732, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0732)

============================================================
📊 Round 166 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2806, R²=0.0560
   Val:   Loss=0.0732, RMSE=0.2705, R²=0.0721
============================================================


============================================================
🔄 Round 167 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0781, val=0.0757 (↓), lr=0.000001
   • Epoch   2/100: train=0.0781, val=0.0757, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0781, val=0.0757, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0781, val=0.0757, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0781, val=0.0757, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0780, val=0.0758, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0757)

============================================================
📊 Round 167 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0781, RMSE=0.2795, R²=0.0584
   Val:   Loss=0.0757, RMSE=0.2751, R²=0.0437
============================================================


============================================================
🔄 Round 168 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0779, val=0.0776 (↓), lr=0.000001
   • Epoch   2/100: train=0.0779, val=0.0776, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0779, val=0.0776, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0779, val=0.0776, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0779, val=0.0776, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0779, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 168 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0777, RMSE=0.2787, R²=0.0528
   Val:   Loss=0.0776, RMSE=0.2785, R²=0.0755
============================================================


📊 Round 168 Test Metrics:
   Loss: 0.0744, RMSE: 0.2728, MAE: 0.2276, R²: 0.1023

📊 Round 168 Test Metrics:
   Loss: 0.0744, RMSE: 0.2727, MAE: 0.2276, R²: 0.1023

============================================================
🔄 Round 171 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0779, val=0.0776 (↓), lr=0.000001
   • Epoch   2/100: train=0.0779, val=0.0776, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0778, val=0.0776, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0778, val=0.0776, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0778, val=0.0776, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0778, val=0.0776, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 171 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0776, RMSE=0.2787, R²=0.0590
   Val:   Loss=0.0776, RMSE=0.2786, R²=0.0607
============================================================


📊 Round 171 Test Metrics:
   Loss: 0.0744, RMSE: 0.2727, MAE: 0.2276, R²: 0.1023

📊 Round 171 Test Metrics:
   Loss: 0.0744, RMSE: 0.2727, MAE: 0.2276, R²: 0.1023

============================================================
🔄 Round 174 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0779, val=0.0771 (↓), lr=0.000001
   • Epoch   2/100: train=0.0779, val=0.0771, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0779, val=0.0771, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0779, val=0.0771, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0779, val=0.0771, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0778, val=0.0771, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0771)

============================================================
📊 Round 174 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0778, RMSE=0.2789, R²=0.0532
   Val:   Loss=0.0771, RMSE=0.2776, R²=0.0825
============================================================


📊 Round 174 Test Metrics:
   Loss: 0.0744, RMSE: 0.2727, MAE: 0.2276, R²: 0.1023

📊 Round 174 Test Metrics:
   Loss: 0.0744, RMSE: 0.2727, MAE: 0.2276, R²: 0.1023

============================================================
🔄 Round 177 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0770, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0770, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0770, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0770, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0770, val=0.0797, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0769, val=0.0797, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 177 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0771, RMSE=0.2777, R²=0.0629
   Val:   Loss=0.0797, RMSE=0.2823, R²=0.0356
============================================================


📊 Round 177 Test Metrics:
   Loss: 0.0744, RMSE: 0.2727, MAE: 0.2276, R²: 0.1023

============================================================
🔄 Round 179 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0762, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0762, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0762, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0762, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0762, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0762, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 179 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0763, RMSE=0.2763, R²=0.0537
   Val:   Loss=0.0830, RMSE=0.2880, R²=0.0747
============================================================


📊 Round 179 Test Metrics:
   Loss: 0.0744, RMSE: 0.2727, MAE: 0.2276, R²: 0.1023

📊 Round 179 Test Metrics:
   Loss: 0.0744, RMSE: 0.2727, MAE: 0.2276, R²: 0.1023

============================================================
🔄 Round 182 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0766, val=0.0819 (↓), lr=0.000001
   • Epoch   2/100: train=0.0766, val=0.0819, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0766, val=0.0819, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0766, val=0.0819, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0766, val=0.0819, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0765, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0819)

============================================================
📊 Round 182 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0766, RMSE=0.2767, R²=0.0542
   Val:   Loss=0.0819, RMSE=0.2862, R²=0.0584
============================================================


============================================================
🔄 Round 185 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0763, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0763, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0763, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0763, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0763, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0762, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 185 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0763, RMSE=0.2763, R²=0.0600
   Val:   Loss=0.0828, RMSE=0.2878, R²=0.0470
============================================================


📊 Round 185 Test Metrics:
   Loss: 0.0744, RMSE: 0.2727, MAE: 0.2276, R²: 0.1024

============================================================
🔄 Round 187 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0774, val=0.0780 (↓), lr=0.000001
   • Epoch   2/100: train=0.0774, val=0.0780, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0774, val=0.0780, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0774, val=0.0780, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0774, val=0.0780, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0774, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0780)

============================================================
📊 Round 187 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0775, RMSE=0.2785, R²=0.0561
   Val:   Loss=0.0780, RMSE=0.2794, R²=0.0724
============================================================


📊 Round 187 Test Metrics:
   Loss: 0.0744, RMSE: 0.2727, MAE: 0.2276, R²: 0.1024

📊 Round 187 Test Metrics:
   Loss: 0.0744, RMSE: 0.2727, MAE: 0.2276, R²: 0.1024

📊 Round 187 Test Metrics:
   Loss: 0.0744, RMSE: 0.2727, MAE: 0.2276, R²: 0.1024

============================================================
🔄 Round 191 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0779, val=0.0760 (↓), lr=0.000001
   • Epoch   2/100: train=0.0779, val=0.0760, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0779, val=0.0760, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0779, val=0.0760, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0779, val=0.0760, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0779, val=0.0760, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0760)

============================================================
📊 Round 191 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0781, RMSE=0.2794, R²=0.0581
   Val:   Loss=0.0760, RMSE=0.2756, R²=0.0646
============================================================


📊 Round 191 Test Metrics:
   Loss: 0.0744, RMSE: 0.2727, MAE: 0.2276, R²: 0.1024

📊 Round 191 Test Metrics:
   Loss: 0.0744, RMSE: 0.2727, MAE: 0.2276, R²: 0.1024

============================================================
🔄 Round 195 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0778, val=0.0762 (↓), lr=0.000001
   • Epoch   2/100: train=0.0778, val=0.0762, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0778, val=0.0762, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0778, val=0.0762, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0778, val=0.0762, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0777, val=0.0762, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0762)

============================================================
📊 Round 195 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0780, RMSE=0.2793, R²=0.0577
   Val:   Loss=0.0762, RMSE=0.2760, R²=0.0669
============================================================


============================================================
🔄 Round 197 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0780, val=0.0774 (↓), lr=0.000001
   • Epoch   2/100: train=0.0780, val=0.0774, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0780, val=0.0774, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0780, val=0.0774, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0780, val=0.0774, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0779, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0774)

============================================================
📊 Round 197 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0777, RMSE=0.2787, R²=0.0625
   Val:   Loss=0.0774, RMSE=0.2783, R²=0.0466
============================================================


📊 Round 197 Test Metrics:
   Loss: 0.0744, RMSE: 0.2727, MAE: 0.2276, R²: 0.1024

📊 Round 197 Test Metrics:
   Loss: 0.0744, RMSE: 0.2727, MAE: 0.2276, R²: 0.1024

============================================================
🔄 Round 202 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0782, val=0.0754 (↓), lr=0.000001
   • Epoch   2/100: train=0.0782, val=0.0754, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0782, val=0.0754, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0782, val=0.0754, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0782, val=0.0754, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0781, val=0.0754, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0754)

============================================================
📊 Round 202 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0782, RMSE=0.2796, R²=0.0612
   Val:   Loss=0.0754, RMSE=0.2746, R²=0.0487
============================================================


📊 Round 202 Test Metrics:
   Loss: 0.0744, RMSE: 0.2727, MAE: 0.2276, R²: 0.1024

📊 Round 202 Test Metrics:
   Loss: 0.0744, RMSE: 0.2727, MAE: 0.2276, R²: 0.1024

📊 Round 202 Test Metrics:
   Loss: 0.0744, RMSE: 0.2727, MAE: 0.2276, R²: 0.1024

📊 Round 202 Test Metrics:
   Loss: 0.0744, RMSE: 0.2727, MAE: 0.2275, R²: 0.1024

📊 Round 202 Test Metrics:
   Loss: 0.0744, RMSE: 0.2727, MAE: 0.2275, R²: 0.1024

📊 Round 202 Test Metrics:
   Loss: 0.0744, RMSE: 0.2727, MAE: 0.2275, R²: 0.1024

============================================================
🔄 Round 211 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0727 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0727, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0727, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0727, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0727, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0727, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0727)

============================================================
📊 Round 211 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2808, R²=0.0586
   Val:   Loss=0.0727, RMSE=0.2697, R²=0.0637
============================================================


============================================================
🔄 Round 212 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0735, val=0.0946 (↓), lr=0.000001
   • Epoch   2/100: train=0.0735, val=0.0947, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0735, val=0.0947, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0735, val=0.0947, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0735, val=0.0947, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0735, val=0.0947, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0946)

============================================================
📊 Round 212 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0734, RMSE=0.2709, R²=0.0623
   Val:   Loss=0.0946, RMSE=0.3076, R²=0.0416
============================================================


============================================================
🔄 Round 213 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0773, val=0.0798 (↓), lr=0.000001
   • Epoch   2/100: train=0.0773, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0773, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0773, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0773, val=0.0798, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0772, val=0.0798, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0798)

============================================================
📊 Round 213 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0771, RMSE=0.2777, R²=0.0517
   Val:   Loss=0.0798, RMSE=0.2824, R²=0.0749
============================================================


📊 Round 213 Test Metrics:
   Loss: 0.0744, RMSE: 0.2727, MAE: 0.2275, R²: 0.1024

📊 Round 213 Test Metrics:
   Loss: 0.0744, RMSE: 0.2727, MAE: 0.2275, R²: 0.1024

📊 Round 213 Test Metrics:
   Loss: 0.0744, RMSE: 0.2727, MAE: 0.2275, R²: 0.1024

============================================================
🔄 Round 217 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0765, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0765, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0765, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0765, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0765, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0765, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 217 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0767, RMSE=0.2770, R²=0.0491
   Val:   Loss=0.0813, RMSE=0.2852, R²=0.0974
============================================================


============================================================
🔄 Round 219 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0764, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0764, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0764, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0764, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0764, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0763, val=0.0818, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 219 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0766, RMSE=0.2767, R²=0.0634
   Val:   Loss=0.0818, RMSE=0.2860, R²=0.0405
============================================================


📊 Round 219 Test Metrics:
   Loss: 0.0744, RMSE: 0.2727, MAE: 0.2275, R²: 0.1025

📊 Round 219 Test Metrics:
   Loss: 0.0744, RMSE: 0.2727, MAE: 0.2275, R²: 0.1025

============================================================
🔄 Round 223 - Client client_73
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0662 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0662, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0662, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0662, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0662, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0662, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0662)

============================================================
📊 Round 223 Summary - Client client_73
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0805, RMSE=0.2837, R²=0.0606
   Val:   Loss=0.0662, RMSE=0.2573, R²=0.0536
============================================================


📊 Round 223 Test Metrics:
   Loss: 0.0744, RMSE: 0.2727, MAE: 0.2275, R²: 0.1025

📊 Round 223 Test Metrics:
   Loss: 0.0744, RMSE: 0.2727, MAE: 0.2275, R²: 0.1025

❌ Client client_73 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8687 {grpc_status:14, grpc_message:"Socket closed"}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8687 {grpc_status:14, grpc_message:"Socket closed"}"
>
