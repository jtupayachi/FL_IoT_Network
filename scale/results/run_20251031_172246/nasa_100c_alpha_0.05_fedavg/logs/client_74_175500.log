[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 456f12d2-0e4e-4d2e-82cb-2c8cb99e329c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1304e86e-70e1-4ed2-9437-96a51a818855
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5ccc9607-f9aa-4f34-87d2-d5ec00818a74
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cdd96b9c-166a-4924-8745-f7b0f333858e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b1ceb26e-4a3d-42f9-9c3c-6f4729aa45ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9803ab87-a1a8-4c55-8dcf-62806dde8f23
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 992d2bd4-4bad-4349-95a1-d5a9191d5913
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d540afc2-6876-44ae-9c5d-ee07d4092c90
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 37b31328-f7aa-4bae-a420-5e202036b353
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bfc57c7e-7515-4e72-bb87-228ae63ff560
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c5055ccb-6930-4014-ae9f-e6fba1a2ea29
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0244095a-07e1-4e7f-851f-df15924206d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 67c0e3c6-bbf8-46cd-9d25-39e5d049f801
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5eaf2106-2893-4b3f-860c-13b86c5d143a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 84001fa7-0ed0-4edb-b6b1-a8c086aba70f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1f9573a6-ada2-4f2c-8f41-eede08fed9f2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3f72da17-d771-42b0-af19-b04303445034
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 915a7a27-6baf-4385-92e0-4b0e2a6e24cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5752792d-4054-4c52-a70a-a771f795be7c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 03934324-5e5f-43b3-af79-0230a5e348b8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8d3aa397-60cd-473d-94da-526418f2adff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c7dfef3d-db6f-4b93-9cf7-66f4e1d666fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2c5a2b12-f02f-498b-974d-993eaf785181
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 57b48db7-7851-4a59-a9a3-46f4c720d0c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1efafaf3-e831-47cb-a712-08c2a36fffa0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a5ee0770-fb1a-4b3a-872a-8cb63e5d72c7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e083d3a1-44c7-43e7-8f5c-c332e577c46e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1abce96a-7c19-4862-bb7e-16c8c04d22fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4a6008fe-117e-4f74-8da7-843b756ca6d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 43adab0b-3fc0-4e0d-a298-24a56f665760
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3994bad1-4c81-4cb3-8dc5-b400f7e37b92
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 58e31f65-24d3-4f50-941d-84a6d07c7bf9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d975a642-8b65-4358-8937-1b6d1b35ff31
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7ac05680-52c2-4f9d-b06d-381083596548
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2292ce10-a6f6-487b-bd87-57c1eaaa223c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 80f84a8e-7c96-4687-9435-214d9ca9980d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9d438f08-ce20-414f-880d-5d7ae797b218
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8910d306-deaf-48f4-b996-84f279af9c03
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message faa90d82-1c2d-46d4-8451-add4f9615390
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d4716134-720f-4c7a-a084-61b97054fd3c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 01768a48-d3d0-4cde-b5eb-869b840e9b19
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f926fad1-2f27-4e30-bbb4-e47e84a3c9ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c5419fe8-2c45-429a-a51a-02ca34cffbe7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e5d2b39b-dc07-4e5d-88e5-a5efdf6263f1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 11898067-76c4-476b-902c-c3d7e6072371
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d5c71e2c-6f14-44c8-b3fe-69656d593ae9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ffbadd6d-eff9-426e-ab70-f6a8f0e60ccb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 570cdafa-9bed-478f-9923-cb5d117aebc0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1ce373e9-8cca-4c04-9615-7437fc8e406b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c8a4606f-388f-4fd0-9ded-31a54b4a7504
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fc0dd2fd-e76f-4fb2-bc99-43675a072e2a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0adbec27-a0b3-4c21-b3c6-cf2e2ccc2881
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b923bb1d-7ed3-4ac8-a6c6-a4d9dbcf18e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 08264914-69d6-496a-851b-b9ffa29997a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ea5dad7c-0bde-4dc9-8fe0-e183b3fa2388
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 09c59962-f510-484a-9824-4a8e2d12c620
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3b7eac90-6100-4821-9852-4f11bb3c7ae2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9f19f8f7-aff9-4f20-bd6f-ebfc8451c224
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a15b41e5-891d-4e40-bd69-22f317ba37b9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message afd9367b-881a-4690-a506-34701bce8ecb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1a15007f-e032-4680-9244-58b64a680f35
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d6f0f1b2-b57c-4277-af44-4f39cdd59318
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5665c269-9ac1-41a4-bf6a-b480724570c5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 44dcbf20-641c-408a-b6a1-1d4b30711d39
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message edc3a0f3-e424-46ec-88c8-ea053ef30535
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 85f39fbf-264b-452c-8b9b-03f8b83f8aca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2d23348f-aadc-4331-b824-c263dccc2d52
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 33107b1a-c9c0-4006-82c2-37fac187bab2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ed1314fe-7afe-4cc5-b131-68a5e138bc83
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 48350bbf-3726-4cf6-8029-48bb93000d73
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2af6ed25-4b69-40ae-b7bf-8ec435ef1863
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 940bc030-b487-49ed-b5e8-1ce666cd49e0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 47eee711-a487-424f-bd5e-7ed435ef9042
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 55c91daf-eb4a-4667-80b5-775879223db3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fcf7d7f9-dee8-4a01-b650-0d12fc8b3d67
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eb8174db-ec33-4519-8e72-4c0d54b31aaa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 328aaaac-818b-4517-a906-9f5abb3ef6bd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f215b947-092d-4418-ad06-d2cc58b5e905
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c6bd12fb-9307-48fd-824e-21f3c00d0008
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8a57dcde-af93-4b84-9884-3edfaec3261c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 49de6532-750c-4b2d-981b-e37233053ebf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f25b817c-d892-413b-8aca-b6decb8e0388
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0fffeb3c-4bb2-4b47-a31e-8f070c71618c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9c670c5b-2598-4478-9fe7-af8bf4424011
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f336a2dd-aa4b-45b4-be78-01671f73eed3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 45564012-a15f-4bb6-811b-fdd946840c98
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c6868bdc-7470-4a67-9250-50ffe27d03c2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a81d358b-37b4-4c24-b724-2fc65fd5574b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0b73eae0-769d-4f25-9205-72331fac9c76
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 82537ed8-54b7-4e9a-8f24-404bf2cbfb11
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7db51154-ec2b-4de3-8ad4-4bbccf04613e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6c29aa50-93b5-471d-8878-faf8cf88f1b5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 874903f6-a9f8-4442-a42f-0a0706e4da97
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 59168b2c-cbf6-46c5-a8f4-8c2df42175e3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 781d2caa-bfb1-4c5d-95f3-2eb1193d7d07
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message eeabf902-9333-40b6-9ba4-d69cbcd9ef5c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5efe4f4a-8275-4197-aee4-7c50b4994eb0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message df98c33d-092e-4254-bf60-d7cb83b786a0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 51ec3906-a756-4b4b-9e7a-6186e9ec20d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1722e722-1437-4fc7-a98a-40397f6a0489
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d228a4ce-348d-477b-ab21-746752132ea2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 922c465a-4866-40cb-82c2-bff588483075
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 70592569-5bc8-448e-a97a-f33d29f85337
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message bee9b952-1651-4da7-a0e5-fd6c1e0af643
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0a170095-81e1-445e-bfe2-dfeed6b5ca6e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3164fef3-67dd-4d90-a1c7-91327ae6bbfa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1b2704b3-63c9-4827-b893-e4e574c5790c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b1581e9c-57b9-44a9-8f87-a4b626b04974
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bf738b20-5b34-489c-87ac-9731f1f87d9e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 602957a0-3609-446b-a9af-895ca6667620
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fcfb46c5-fcda-4cfc-90ba-1bd41abf4b23
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 8e0e2610-c35a-435f-a41e-3bbdbd9985e8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e1fd277b-e2ec-4bc8-9221-f5d669f7db82
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 595d1ab1-739e-4ad7-9d21-39398390ec36
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3d961443-3dfc-4edb-bf6a-8d1fa7ff51cb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fafda860-e901-4846-a447-1bd9bdee9126
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c03007b3-5050-4ae9-b54f-1ac549133f18
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4b2dc5c8-a489-4ca4-af00-c40ddbdd8bd1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b2b75711-dc11-4103-af0b-f452377c832e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 52099f1f-82a8-4ead-8b3a-e71aa1521a38
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6a086124-94ea-46c8-bd4d-e0d9c5be342b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ebe4b9bd-ab43-436b-a96e-cb48e3897086
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d87feb3d-d408-45d6-b3ee-48ad80cd510c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1d1b78d7-5753-4265-bf9d-ff93f35207d0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 73160c9d-dba7-4b25-85d4-2ddb3faac070
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 697bdc27-780f-4e8e-980f-96a246be93b5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1037931e-d487-4cc8-9221-6def91d2f4fb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e9e9f3a8-835d-427c-a17f-f530bcf9acd6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fd6adc36-018b-4887-81f7-4ae24460172e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3a3aa41c-5a30-4b07-a8db-f703cf218e0a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 21b56790-4b31-4a2e-b2e5-29d2adf29c0b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fb51d450-a385-412a-9b32-cd52bb22d82d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a88abe30-8614-4cea-85b6-049069028b54
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2c092af6-32aa-463e-a9f2-2055bd7d8b3c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 95ec4323-a02c-417b-b8d4-0d65c3586b40
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 03edda65-c0ce-4d35-9327-27a9bd2678fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d3ca61f7-e171-4e42-8d3f-c47bbe194379
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 15bc44bd-3b58-4157-abb8-64edaf154309
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b69a5876-3518-44bf-98e6-382f0d32d85b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a9467c4b-d438-48e6-8c99-a3da11a19080
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c15ab181-19d8-4003-b916-691b484569ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a987ed82-b4d5-471d-b294-87985ff7d3af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a3cf537d-5187-43f5-92c0-5331aea27897
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 748f8f0b-305d-472f-8f3e-7bbc2956824d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c55bbb02-f216-43d7-9e0a-b3e0a95201ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e144d687-dfe2-43a7-a0d1-7eae4219dba7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 538517ae-e675-490f-b7f0-4284c4b16248
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c43b23c6-b2d2-4176-b39e-4ceb3ab34da7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3974f95f-4e8f-4337-a86a-e786a674af69
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 80325978-c7b1-4f15-899d-271ec7c8eda7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e7d8a8d3-30ad-4f63-b893-cd7b256a26f3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 4bd964c7-f499-4590-9fe0-6e4637d03bef
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 431731aa-cd34-4451-8380-6f34b74bb675
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f83080e8-8f47-46dd-8c4e-a7650231a3f7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7c3ddf74-c74d-4ab3-8a63-e6c694bbb89e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 25dc1dc4-6002-489c-886c-1a6f54a3162a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message cec96eda-3145-4cd9-9935-02540e66e152
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b3899afe-3be3-4efc-a411-978dc2ba82bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d1be9b1b-6fc7-4bac-9704-6fbe52282a6a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4645911c-cb89-4407-8851-74845487beca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message de5c9823-bf46-4115-a6ce-f5ea3a818f01
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2ddfcf9d-92d4-4267-958b-317af35e98fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3eca7d54-9f6b-4a3f-a184-af4b1fde5922
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 426c0c49-366b-494e-81d3-af0e5788fbbd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message e30aa276-adab-45de-9f46-181904ddd2fc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9a8497b9-0c21-4c4b-9886-008534e29bcf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d72ccdf5-9178-4572-aca3-90ae9e738764
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 47d5abb6-8d91-4a54-9925-7aa1bed5c1a0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 44103de7-9f04-4816-a4bb-a229d7771b9d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 32cbe042-0c3b-45ee-ac16-2328a9b938c3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 737e18a6-0dd9-404a-9014-dc6da2c1410f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 43c42069-b85d-4660-87e1-1031448122da
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9d985128-0b03-4ca4-8888-d0f180c29795
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 91c63f92-b161-4d2a-86b6-dd00b674976c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c7b7319f-8424-4fd8-aae0-d266206405d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7ec5c774-6893-449b-b43a-ece89c43f306
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6fbc50fc-d230-4a60-8f37-729452ab33cf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 411d0696-69ae-4dec-839d-af56ffde5a42
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b9e096d4-eaa5-47f6-9bd3-a57e31ded810
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 61ffa655-04f0-40b4-bd8f-6570c4e89d10
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 89a1e8d1-9d05-49b2-b300-48ab71165de0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8711c02a-ea78-4cd2-b43f-5677336b09af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c508e2bd-260d-4499-95eb-ae627c892e2c
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8687 {grpc_message:"Socket closed", grpc_status:14}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_74
Server: localhost:8687
Algorithm: FEDAVG
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_74
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_74/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_74/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_74/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_74/test_labels.txt

📊 Raw data loaded:
   Train: X=(1660, 24), y=(1660,)
   Test:  X=(416, 24), y=(416,)

⚠️  Limiting training data: 1660 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  407 samples, 5 features
✅ Client client_74 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

📊 Round 0 Test Metrics:
   Loss: 0.0823, RMSE: 0.2869, MAE: 0.2499, R²: -0.0098

============================================================
🔄 Round 7 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0856 (↓), lr=0.001000
   • Epoch   2/100: train=0.0779, val=0.0851, patience=1/15, lr=0.001000
   • Epoch   3/100: train=0.0782, val=0.0853, patience=2/15, lr=0.001000
   ✓ Epoch   4/100: train=0.0778, val=0.0850 (↓), lr=0.001000
   • Epoch   5/100: train=0.0771, val=0.0852, patience=1/15, lr=0.001000
   📉 Epoch 10: LR reduced 0.001000 → 0.000500
   • Epoch  11/100: train=0.0753, val=0.0860, patience=7/15, lr=0.000500
   📉 Epoch 18: LR reduced 0.000500 → 0.000250

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0850)

============================================================
📊 Round 7 Summary - Client client_74
   Epochs: 19/100 (early stopped)
   LR: 0.001000 → 0.000250 (2 reductions)
   Train: Loss=0.0763, RMSE=0.2761, R²=0.0121
   Val:   Loss=0.0850, RMSE=0.2916, R²=0.0025
============================================================


📊 Round 7 Test Metrics:
   Loss: 0.0819, RMSE: 0.2862, MAE: 0.2490, R²: -0.0045

============================================================
🔄 Round 8 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000250
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0787 (↓), lr=0.000250
   • Epoch   2/100: train=0.0787, val=0.0785, patience=1/15, lr=0.000250
   • Epoch   3/100: train=0.0784, val=0.0791, patience=2/15, lr=0.000250
   • Epoch   4/100: train=0.0782, val=0.0794, patience=3/15, lr=0.000250
   • Epoch   5/100: train=0.0781, val=0.0796, patience=4/15, lr=0.000250
   📉 Epoch 8: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0773, val=0.0801, patience=10/15, lr=0.000125
   📉 Epoch 16: LR reduced 0.000125 → 0.000063

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 8 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000250 → 0.000063 (2 reductions)
   Train: Loss=0.0785, RMSE=0.2802, R²=0.0067
   Val:   Loss=0.0787, RMSE=0.2806, R²=-0.0382
============================================================


============================================================
🔄 Round 9 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000063
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0782 (↓), lr=0.000063
   • Epoch   2/100: train=0.0786, val=0.0783, patience=1/15, lr=0.000063
   • Epoch   3/100: train=0.0786, val=0.0784, patience=2/15, lr=0.000063
   • Epoch   4/100: train=0.0785, val=0.0784, patience=3/15, lr=0.000063
   • Epoch   5/100: train=0.0785, val=0.0784, patience=4/15, lr=0.000063
   📉 Epoch 8: LR reduced 0.000063 → 0.000031
   • Epoch  11/100: train=0.0782, val=0.0784, patience=10/15, lr=0.000031
   📉 Epoch 16: LR reduced 0.000031 → 0.000016

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 9 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000063 → 0.000016 (2 reductions)
   Train: Loss=0.0784, RMSE=0.2800, R²=0.0094
   Val:   Loss=0.0782, RMSE=0.2796, R²=-0.0131
============================================================


📊 Round 9 Test Metrics:
   Loss: 0.0817, RMSE: 0.2859, MAE: 0.2485, R²: -0.0022

============================================================
🔄 Round 12 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000016
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0773, val=0.0833 (↓), lr=0.000016
   • Epoch   2/100: train=0.0772, val=0.0834, patience=1/15, lr=0.000016
   • Epoch   3/100: train=0.0772, val=0.0834, patience=2/15, lr=0.000016
   • Epoch   4/100: train=0.0772, val=0.0834, patience=3/15, lr=0.000016
   • Epoch   5/100: train=0.0771, val=0.0834, patience=4/15, lr=0.000016
   📉 Epoch 8: LR reduced 0.000016 → 0.000008
   • Epoch  11/100: train=0.0770, val=0.0836, patience=10/15, lr=0.000008
   📉 Epoch 16: LR reduced 0.000008 → 0.000004

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 12 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000016 → 0.000004 (2 reductions)
   Train: Loss=0.0773, RMSE=0.2779, R²=0.0082
   Val:   Loss=0.0833, RMSE=0.2887, R²=-0.0111
============================================================


📊 Round 12 Test Metrics:
   Loss: 0.0816, RMSE: 0.2857, MAE: 0.2482, R²: -0.0011

📊 Round 12 Test Metrics:
   Loss: 0.0815, RMSE: 0.2854, MAE: 0.2479, R²: 0.0008

============================================================
🔄 Round 19 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000004
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0754 (↓), lr=0.000004
   • Epoch   2/100: train=0.0794, val=0.0754, patience=1/15, lr=0.000004
   • Epoch   3/100: train=0.0793, val=0.0755, patience=2/15, lr=0.000004
   • Epoch   4/100: train=0.0793, val=0.0755, patience=3/15, lr=0.000004
   • Epoch   5/100: train=0.0793, val=0.0756, patience=4/15, lr=0.000004
   📉 Epoch 8: LR reduced 0.000004 → 0.000002
   • Epoch  11/100: train=0.0792, val=0.0757, patience=10/15, lr=0.000002
   📉 Epoch 16: LR reduced 0.000002 → 0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0754)

============================================================
📊 Round 19 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000004 → 0.000001 (2 reductions)
   Train: Loss=0.0792, RMSE=0.2814, R²=0.0050
   Val:   Loss=0.0754, RMSE=0.2746, R²=-0.0199
============================================================


============================================================
🔄 Round 20 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0777, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0777, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0777, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0777, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0777, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0777, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 20 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0778, RMSE=0.2789, R²=-0.0053
   Val:   Loss=0.0812, RMSE=0.2850, R²=0.0312
============================================================


============================================================
🔄 Round 22 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0768, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0768, val=0.0853, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0768, val=0.0853, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0768, val=0.0853, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0767, val=0.0853, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0767, val=0.0853, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 22 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0767, RMSE=0.2769, R²=0.0099
   Val:   Loss=0.0852, RMSE=0.2920, R²=-0.0140
============================================================


📊 Round 22 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2479, R²: 0.0015

============================================================
🔄 Round 23 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0790 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0790, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0790, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0790, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0790)

============================================================
📊 Round 23 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0783, RMSE=0.2797, R²=0.0074
   Val:   Loss=0.0790, RMSE=0.2811, R²=-0.0045
============================================================


📊 Round 23 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2478, R²: 0.0019

============================================================
🔄 Round 24 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0764 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0764, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0764, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0764, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0764, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0764, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0764)

============================================================
📊 Round 24 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2809, R²=0.0051
   Val:   Loss=0.0764, RMSE=0.2764, R²=0.0017
============================================================


📊 Round 24 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2479, R²: 0.0016

============================================================
🔄 Round 25 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0768, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0768, val=0.0846, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0768, val=0.0846, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0768, val=0.0846, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0768, val=0.0846, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0768, val=0.0846, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 25 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0769, RMSE=0.2772, R²=0.0025
   Val:   Loss=0.0846, RMSE=0.2909, R²=0.0137
============================================================


============================================================
🔄 Round 26 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0756 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0756, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0756, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0756, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0756, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0756, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0756)

============================================================
📊 Round 26 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0791, RMSE=0.2812, R²=0.0035
   Val:   Loss=0.0756, RMSE=0.2750, R²=0.0082
============================================================


📊 Round 26 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2479, R²: 0.0017

============================================================
🔄 Round 27 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0767, val=0.0847 (↓), lr=0.000001
   • Epoch   2/100: train=0.0767, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0767, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0767, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0767, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0767, val=0.0848, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0847)

============================================================
📊 Round 27 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0768, RMSE=0.2772, R²=0.0004
   Val:   Loss=0.0847, RMSE=0.2911, R²=0.0100
============================================================


📊 Round 27 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2479, R²: 0.0015

============================================================
🔄 Round 28 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0765 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0765, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0765, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0766, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0766, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0766, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0765)

============================================================
📊 Round 28 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2808, R²=0.0020
   Val:   Loss=0.0765, RMSE=0.2767, R²=0.0120
============================================================


📊 Round 28 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2479, R²: 0.0014

============================================================
🔄 Round 29 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0689 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0689, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0689, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0689, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0809, val=0.0689, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0689, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0689)

============================================================
📊 Round 29 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=0.0067
   Val:   Loss=0.0689, RMSE=0.2624, R²=-0.0072
============================================================


📊 Round 29 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2479, R²: 0.0015

============================================================
🔄 Round 31 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0772, val=0.0829 (↓), lr=0.000001
   • Epoch   2/100: train=0.0772, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0772, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0772, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0772, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0772, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0829)

============================================================
📊 Round 31 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0773, RMSE=0.2780, R²=0.0037
   Val:   Loss=0.0829, RMSE=0.2880, R²=0.0090
============================================================


============================================================
🔄 Round 32 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0767, val=0.0841 (↓), lr=0.000001
   • Epoch   2/100: train=0.0767, val=0.0841, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0767, val=0.0841, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0767, val=0.0841, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0767, val=0.0841, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0766, val=0.0842, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0841)

============================================================
📊 Round 32 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0770, RMSE=0.2774, R²=0.0078
   Val:   Loss=0.0841, RMSE=0.2901, R²=-0.0053
============================================================


============================================================
🔄 Round 33 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0720 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0720, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0720, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0720, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0720, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0720, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0720)

============================================================
📊 Round 33 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=0.0045
   Val:   Loss=0.0720, RMSE=0.2683, R²=0.0061
============================================================


📊 Round 33 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2479, R²: 0.0016

============================================================
🔄 Round 35 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0708 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0708, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0708, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0708, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0708, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0709, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0708)

============================================================
📊 Round 35 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=0.0092
   Val:   Loss=0.0708, RMSE=0.2660, R²=-0.0331
============================================================


📊 Round 35 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2479, R²: 0.0016

📊 Round 35 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2479, R²: 0.0016

============================================================
🔄 Round 43 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0753 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0753, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0753, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0753, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0753, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0753, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0753)

============================================================
📊 Round 43 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2814, R²=0.0081
   Val:   Loss=0.0753, RMSE=0.2744, R²=-0.0080
============================================================


📊 Round 43 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2478, R²: 0.0018

============================================================
🔄 Round 44 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0776, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0776, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0776, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0776, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0776, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0776, val=0.0823, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 44 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0774, RMSE=0.2782, R²=-0.0018
   Val:   Loss=0.0823, RMSE=0.2869, R²=0.0296
============================================================


📊 Round 44 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2479, R²: 0.0018

============================================================
🔄 Round 49 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0760, val=0.0886 (↓), lr=0.000001
   • Epoch   2/100: train=0.0760, val=0.0886, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0760, val=0.0886, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0760, val=0.0886, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0760, val=0.0886, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0759, val=0.0886, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0886)

============================================================
📊 Round 49 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0759, RMSE=0.2754, R²=0.0009
   Val:   Loss=0.0886, RMSE=0.2976, R²=0.0135
============================================================


============================================================
🔄 Round 51 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0746 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0746, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0746, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0746, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0746, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0746, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0746)

============================================================
📊 Round 51 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2817, R²=0.0016
   Val:   Loss=0.0746, RMSE=0.2731, R²=0.0171
============================================================


📊 Round 51 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2479, R²: 0.0016

📊 Round 51 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2479, R²: 0.0016

📊 Round 51 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2479, R²: 0.0015

📊 Round 51 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2479, R²: 0.0015

============================================================
🔄 Round 62 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0769 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0769, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0769, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0769, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0769, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0769, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0769)

============================================================
📊 Round 62 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2807, R²=0.0086
   Val:   Loss=0.0769, RMSE=0.2772, R²=-0.0119
============================================================


📊 Round 62 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2479, R²: 0.0016

============================================================
🔄 Round 63 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0779, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0779, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0779, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0778, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0778, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0778, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 63 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0776, RMSE=0.2785, R²=0.0053
   Val:   Loss=0.0817, RMSE=0.2858, R²=0.0019
============================================================


============================================================
🔄 Round 64 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0769 (↓), lr=0.000001
   • Epoch   2/100: train=0.0787, val=0.0769, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0769, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0769, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0769, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0769, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0769)

============================================================
📊 Round 64 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2807, R²=0.0009
   Val:   Loss=0.0769, RMSE=0.2772, R²=0.0218
============================================================


============================================================
🔄 Round 65 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0789 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0789, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0789, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0789, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0790, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0789)

============================================================
📊 Round 65 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0783, RMSE=0.2798, R²=0.0042
   Val:   Loss=0.0789, RMSE=0.2810, R²=0.0061
============================================================


📊 Round 65 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2479, R²: 0.0017

📊 Round 65 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2479, R²: 0.0018

============================================================
🔄 Round 70 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0745 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0745, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0745, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0745, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0746, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0790, val=0.0746, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0745)

============================================================
📊 Round 70 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2817, R²=0.0040
   Val:   Loss=0.0745, RMSE=0.2730, R²=-0.0097
============================================================


📊 Round 70 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2478, R²: 0.0019

============================================================
🔄 Round 71 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0761 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0761, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0762, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0762, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0762, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0763, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0761)

============================================================
📊 Round 71 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0790, RMSE=0.2810, R²=0.0011
   Val:   Loss=0.0761, RMSE=0.2759, R²=-0.0052
============================================================


============================================================
🔄 Round 72 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0748 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0748, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0748, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0748, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0748, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0748, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0748)

============================================================
📊 Round 72 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2816, R²=0.0090
   Val:   Loss=0.0748, RMSE=0.2734, R²=-0.0122
============================================================


📊 Round 72 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2478, R²: 0.0019

============================================================
🔄 Round 73 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0750 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0750, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0750, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0750, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0750, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0751, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0750)

============================================================
📊 Round 73 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2815, R²=-0.0007
   Val:   Loss=0.0750, RMSE=0.2738, R²=-0.0004
============================================================


📊 Round 73 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2479, R²: 0.0018

📊 Round 73 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2479, R²: 0.0018

📊 Round 73 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2478, R²: 0.0019

📊 Round 73 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2478, R²: 0.0020

📊 Round 73 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2478, R²: 0.0020

============================================================
🔄 Round 82 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0770, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0770, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0770, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0770, val=0.0850, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0770, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0770, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 82 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0768, RMSE=0.2771, R²=0.0031
   Val:   Loss=0.0849, RMSE=0.2914, R²=-0.0009
============================================================


============================================================
🔄 Round 83 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0778, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0778, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0778, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0778, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0778, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 83 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2803, R²=0.0046
   Val:   Loss=0.0778, RMSE=0.2788, R²=0.0000
============================================================


============================================================
🔄 Round 84 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0764, val=0.0863 (↓), lr=0.000001
   • Epoch   2/100: train=0.0764, val=0.0863, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0764, val=0.0863, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0764, val=0.0863, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0764, val=0.0863, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0764, val=0.0863, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0863)

============================================================
📊 Round 84 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0764, RMSE=0.2765, R²=0.0021
   Val:   Loss=0.0863, RMSE=0.2937, R²=0.0153
============================================================


============================================================
🔄 Round 85 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0724 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0724, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0724, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0724, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0724, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0724, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0724)

============================================================
📊 Round 85 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=0.0014
   Val:   Loss=0.0724, RMSE=0.2691, R²=0.0212
============================================================


============================================================
🔄 Round 87 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0776, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0776, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0776, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0776, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0776, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0776, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 87 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0777, RMSE=0.2788, R²=0.0052
   Val:   Loss=0.0811, RMSE=0.2847, R²=0.0052
============================================================


============================================================
🔄 Round 88 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0766, val=0.0849 (↓), lr=0.000001
   • Epoch   2/100: train=0.0766, val=0.0849, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0766, val=0.0849, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0766, val=0.0849, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0766, val=0.0850, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0766, val=0.0850, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0849)

============================================================
📊 Round 88 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0768, RMSE=0.2771, R²=0.0123
   Val:   Loss=0.0849, RMSE=0.2914, R²=-0.0453
============================================================


📊 Round 88 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2478, R²: 0.0019

============================================================
🔄 Round 89 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0772, val=0.0832 (↓), lr=0.000001
   • Epoch   2/100: train=0.0772, val=0.0832, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0772, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0772, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0772, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0772, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0832)

============================================================
📊 Round 89 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0772, RMSE=0.2779, R²=0.0109
   Val:   Loss=0.0832, RMSE=0.2884, R²=-0.0232
============================================================


============================================================
🔄 Round 90 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0737 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0737, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0737, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0737, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0737, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0737, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0737)

============================================================
📊 Round 90 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2821, R²=0.0076
   Val:   Loss=0.0737, RMSE=0.2714, R²=-0.0122
============================================================


============================================================
🔄 Round 91 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0771 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0771, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0771, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0771, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0771, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0771, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0771)

============================================================
📊 Round 91 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2806, R²=0.0040
   Val:   Loss=0.0771, RMSE=0.2777, R²=0.0099
============================================================


============================================================
🔄 Round 92 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0740 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0740, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0740, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0740, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0740, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0741, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0740)

============================================================
📊 Round 92 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2819, R²=0.0043
   Val:   Loss=0.0740, RMSE=0.2721, R²=0.0067
============================================================


📊 Round 92 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2478, R²: 0.0020

📊 Round 92 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2478, R²: 0.0019

============================================================
🔄 Round 94 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0719 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0719, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0719, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0719, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0719, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0720, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0719)

============================================================
📊 Round 94 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2829, R²=-0.0019
   Val:   Loss=0.0719, RMSE=0.2682, R²=0.0319
============================================================


============================================================
🔄 Round 96 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0774 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0774, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0774, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0774, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0774, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0774, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0774)

============================================================
📊 Round 96 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2804, R²=0.0007
   Val:   Loss=0.0774, RMSE=0.2782, R²=0.0176
============================================================


📊 Round 96 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2478, R²: 0.0020

============================================================
🔄 Round 100 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0739 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0739, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0739, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0739, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0739, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0739, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0739)

============================================================
📊 Round 100 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2820, R²=0.0056
   Val:   Loss=0.0739, RMSE=0.2719, R²=-0.0026
============================================================


📊 Round 100 Test Metrics:
   Loss: 0.0814, RMSE: 0.2852, MAE: 0.2478, R²: 0.0021

============================================================
🔄 Round 101 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0781, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0781, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0781, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0781, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0781, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0780, val=0.0804, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 101 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0779, RMSE=0.2791, R²=0.0003
   Val:   Loss=0.0804, RMSE=0.2835, R²=0.0235
============================================================


📊 Round 101 Test Metrics:
   Loss: 0.0814, RMSE: 0.2852, MAE: 0.2478, R²: 0.0021

📊 Round 101 Test Metrics:
   Loss: 0.0814, RMSE: 0.2852, MAE: 0.2478, R²: 0.0021

============================================================
🔄 Round 105 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0717 (↓), lr=0.000001
   • Epoch   2/100: train=0.0801, val=0.0717, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0801, val=0.0717, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0801, val=0.0717, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0801, val=0.0717, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0718, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0717)

============================================================
📊 Round 105 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0801, RMSE=0.2829, R²=0.0083
   Val:   Loss=0.0717, RMSE=0.2678, R²=-0.0091
============================================================


============================================================
🔄 Round 106 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0765, val=0.0851 (↓), lr=0.000001
   • Epoch   2/100: train=0.0765, val=0.0851, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0765, val=0.0851, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0765, val=0.0851, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0765, val=0.0851, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0765, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0851)

============================================================
📊 Round 106 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0767, RMSE=0.2770, R²=-0.0011
   Val:   Loss=0.0851, RMSE=0.2917, R²=0.0234
============================================================


============================================================
🔄 Round 107 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0772, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0772, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0772, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0772, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0772, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0772, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 107 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0772, RMSE=0.2778, R²=0.0095
   Val:   Loss=0.0833, RMSE=0.2887, R²=-0.0109
============================================================


============================================================
🔄 Round 108 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0743 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0743, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0743, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0743, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0744, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0744, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0743)

============================================================
📊 Round 108 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2818, R²=0.0068
   Val:   Loss=0.0743, RMSE=0.2726, R²=-0.0266
============================================================


📊 Round 108 Test Metrics:
   Loss: 0.0814, RMSE: 0.2852, MAE: 0.2478, R²: 0.0023

📊 Round 108 Test Metrics:
   Loss: 0.0814, RMSE: 0.2852, MAE: 0.2478, R²: 0.0022

📊 Round 108 Test Metrics:
   Loss: 0.0814, RMSE: 0.2852, MAE: 0.2478, R²: 0.0022

📊 Round 108 Test Metrics:
   Loss: 0.0814, RMSE: 0.2852, MAE: 0.2478, R²: 0.0022

📊 Round 108 Test Metrics:
   Loss: 0.0813, RMSE: 0.2852, MAE: 0.2478, R²: 0.0024

============================================================
🔄 Round 121 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0778, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0778, val=0.0801, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0778, val=0.0801, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0778, val=0.0801, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0778, val=0.0801, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0778, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 121 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0780, RMSE=0.2792, R²=0.0064
   Val:   Loss=0.0801, RMSE=0.2830, R²=-0.0028
============================================================


============================================================
🔄 Round 122 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0772, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0772, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0772, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0772, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0772, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0772, val=0.0833, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 122 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0772, RMSE=0.2778, R²=-0.0008
   Val:   Loss=0.0833, RMSE=0.2886, R²=0.0267
============================================================


📊 Round 122 Test Metrics:
   Loss: 0.0813, RMSE: 0.2852, MAE: 0.2478, R²: 0.0024

📊 Round 122 Test Metrics:
   Loss: 0.0813, RMSE: 0.2852, MAE: 0.2478, R²: 0.0023

============================================================
🔄 Round 124 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0735 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0735, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0735, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0735, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0735, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0735, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0735)

============================================================
📊 Round 124 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2822, R²=0.0017
   Val:   Loss=0.0735, RMSE=0.2711, R²=0.0145
============================================================


📊 Round 124 Test Metrics:
   Loss: 0.0813, RMSE: 0.2852, MAE: 0.2478, R²: 0.0024

============================================================
🔄 Round 126 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0774, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0774, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0774, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0774, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0774, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0774, val=0.0828, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 126 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0773, RMSE=0.2780, R²=0.0075
   Val:   Loss=0.0828, RMSE=0.2877, R²=-0.0033
============================================================


============================================================
🔄 Round 128 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0658 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0658, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0814, val=0.0658, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0814, val=0.0658, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0814, val=0.0658, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0658, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0658)

============================================================
📊 Round 128 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2856, R²=0.0063
   Val:   Loss=0.0658, RMSE=0.2564, R²=-0.0103
============================================================


============================================================
🔄 Round 129 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0723 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0723, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0723, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0723, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0723, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0800, val=0.0723, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0723)

============================================================
📊 Round 129 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=0.0068
   Val:   Loss=0.0723, RMSE=0.2689, R²=-0.0022
============================================================


📊 Round 129 Test Metrics:
   Loss: 0.0814, RMSE: 0.2852, MAE: 0.2478, R²: 0.0022

============================================================
🔄 Round 130 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0770 (↓), lr=0.000001
   • Epoch   2/100: train=0.0787, val=0.0770, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0770, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0770, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0770, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0770, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0770)

============================================================
📊 Round 130 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2806, R²=0.0034
   Val:   Loss=0.0770, RMSE=0.2775, R²=0.0078
============================================================


============================================================
🔄 Round 131 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0724 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0724, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0724, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0799, val=0.0724, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0724, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0725, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0724)

============================================================
📊 Round 131 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=-0.0016
   Val:   Loss=0.0724, RMSE=0.2691, R²=0.0228
============================================================


📊 Round 131 Test Metrics:
   Loss: 0.0814, RMSE: 0.2852, MAE: 0.2478, R²: 0.0021

📊 Round 131 Test Metrics:
   Loss: 0.0814, RMSE: 0.2852, MAE: 0.2478, R²: 0.0021

📊 Round 131 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2479, R²: 0.0019

============================================================
🔄 Round 139 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0807, val=0.0694 (↓), lr=0.000001
   • Epoch   2/100: train=0.0807, val=0.0694, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0807, val=0.0694, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0807, val=0.0695, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0807, val=0.0695, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0695, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0694)

============================================================
📊 Round 139 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0806, RMSE=0.2839, R²=0.0073
   Val:   Loss=0.0694, RMSE=0.2635, R²=-0.0050
============================================================


📊 Round 139 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2479, R²: 0.0020

============================================================
🔄 Round 140 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0735 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0735, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0735, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0735, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0735, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0735, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0735)

============================================================
📊 Round 140 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2822, R²=0.0065
   Val:   Loss=0.0735, RMSE=0.2710, R²=-0.0078
============================================================


============================================================
🔄 Round 142 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0762 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0762, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0762, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0762, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0762, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0762, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0762)

============================================================
📊 Round 142 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2809, R²=0.0054
   Val:   Loss=0.0762, RMSE=0.2761, R²=0.0041
============================================================


============================================================
🔄 Round 143 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0761, val=0.0866 (↓), lr=0.000001
   • Epoch   2/100: train=0.0761, val=0.0866, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0761, val=0.0866, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0761, val=0.0866, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0761, val=0.0866, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0761, val=0.0866, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0866)

============================================================
📊 Round 143 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0763, RMSE=0.2763, R²=0.0067
   Val:   Loss=0.0866, RMSE=0.2942, R²=-0.0037
============================================================


📊 Round 143 Test Metrics:
   Loss: 0.0814, RMSE: 0.2852, MAE: 0.2478, R²: 0.0021

============================================================
🔄 Round 146 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0737 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0737, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0737, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0737, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0737, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0738, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0737)

============================================================
📊 Round 146 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2821, R²=0.0034
   Val:   Loss=0.0737, RMSE=0.2715, R²=0.0027
============================================================


📊 Round 146 Test Metrics:
   Loss: 0.0814, RMSE: 0.2852, MAE: 0.2478, R²: 0.0021

📊 Round 146 Test Metrics:
   Loss: 0.0814, RMSE: 0.2852, MAE: 0.2478, R²: 0.0021

============================================================
🔄 Round 150 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0778, val=0.0803 (↓), lr=0.000001
   • Epoch   2/100: train=0.0778, val=0.0803, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0778, val=0.0803, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0778, val=0.0803, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0778, val=0.0803, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0777, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0803)

============================================================
📊 Round 150 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0779, RMSE=0.2791, R²=0.0099
   Val:   Loss=0.0803, RMSE=0.2833, R²=-0.0234
============================================================


📊 Round 150 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2479, R²: 0.0021

============================================================
🔄 Round 151 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0732 (↓), lr=0.000001
   • Epoch   2/100: train=0.0797, val=0.0732, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0797, val=0.0732, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0797, val=0.0733, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0797, val=0.0733, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0734, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0732)

============================================================
📊 Round 151 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=0.0032
   Val:   Loss=0.0732, RMSE=0.2706, R²=-0.0274
============================================================


============================================================
🔄 Round 152 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0779, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0779, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0779, val=0.0809, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0779, val=0.0809, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0778, val=0.0809, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0778, val=0.0809, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 152 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0778, RMSE=0.2789, R²=0.0073
   Val:   Loss=0.0808, RMSE=0.2843, R²=-0.0145
============================================================


📊 Round 152 Test Metrics:
   Loss: 0.0814, RMSE: 0.2852, MAE: 0.2479, R²: 0.0021

============================================================
🔄 Round 153 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0718 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0718, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0718, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0718, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0718, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0719, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0718)

============================================================
📊 Round 153 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2829, R²=0.0117
   Val:   Loss=0.0718, RMSE=0.2679, R²=-0.0595
============================================================


============================================================
🔄 Round 156 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0748 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0748, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0748, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0748, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0748, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0748, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0748)

============================================================
📊 Round 156 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2816, R²=0.0011
   Val:   Loss=0.0748, RMSE=0.2735, R²=0.0204
============================================================


📊 Round 156 Test Metrics:
   Loss: 0.0814, RMSE: 0.2852, MAE: 0.2479, R²: 0.0021

============================================================
🔄 Round 157 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0771, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0771, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0771, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0771, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0771, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0771, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 157 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0769, RMSE=0.2773, R²=0.0082
   Val:   Loss=0.0843, RMSE=0.2903, R²=-0.0267
============================================================


📊 Round 157 Test Metrics:
   Loss: 0.0814, RMSE: 0.2852, MAE: 0.2479, R²: 0.0021

📊 Round 157 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2479, R²: 0.0020

============================================================
🔄 Round 160 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0781, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0781, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0781, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0781, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0781, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0781, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 160 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0782, RMSE=0.2797, R²=-0.0044
   Val:   Loss=0.0791, RMSE=0.2813, R²=0.0414
============================================================


📊 Round 160 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2479, R²: 0.0020

============================================================
🔄 Round 161 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0762 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0762, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0762, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0762, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0762, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0763, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0762)

============================================================
📊 Round 161 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2809, R²=0.0002
   Val:   Loss=0.0762, RMSE=0.2761, R²=0.0022
============================================================


============================================================
🔄 Round 162 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0783, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0783, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0783, val=0.0782, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0783, val=0.0782, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0783, val=0.0782, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0782, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 162 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2801, R²=0.0095
   Val:   Loss=0.0782, RMSE=0.2797, R²=-0.0123
============================================================


📊 Round 162 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2479, R²: 0.0020

============================================================
🔄 Round 163 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0778, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0778, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0779, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0779, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0785, val=0.0779, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 163 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2802, R²=0.0005
   Val:   Loss=0.0778, RMSE=0.2790, R²=0.0132
============================================================


📊 Round 163 Test Metrics:
   Loss: 0.0814, RMSE: 0.2852, MAE: 0.2479, R²: 0.0021

📊 Round 163 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2479, R²: 0.0019

============================================================
🔄 Round 165 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0745 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0745, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0745, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0795, val=0.0745, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0795, val=0.0745, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0746, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0745)

============================================================
📊 Round 165 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2817, R²=0.0048
   Val:   Loss=0.0745, RMSE=0.2729, R²=-0.0106
============================================================


📊 Round 165 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2479, R²: 0.0020

============================================================
🔄 Round 166 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0648 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0648, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0648, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0648, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0648, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0648, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0648)

============================================================
📊 Round 166 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=0.0009
   Val:   Loss=0.0648, RMSE=0.2546, R²=0.0258
============================================================


📊 Round 166 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2479, R²: 0.0020

📊 Round 166 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2479, R²: 0.0019

============================================================
🔄 Round 170 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 170 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2800, R²=0.0093
   Val:   Loss=0.0784, RMSE=0.2800, R²=-0.0115
============================================================


📊 Round 170 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2479, R²: 0.0019

📊 Round 170 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2479, R²: 0.0019

============================================================
🔄 Round 172 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0766 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0766, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0785, val=0.0766, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0785, val=0.0766, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0785, val=0.0767, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0785, val=0.0768, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0766)

============================================================
📊 Round 172 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2808, R²=0.0038
   Val:   Loss=0.0766, RMSE=0.2767, R²=-0.0168
============================================================


📊 Round 172 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2479, R²: 0.0020

============================================================
🔄 Round 174 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0791, val=0.0746 (↓), lr=0.000001
   • Epoch   2/100: train=0.0791, val=0.0746, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0791, val=0.0746, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0746, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0746, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0746, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0746)

============================================================
📊 Round 174 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2817, R²=0.0093
   Val:   Loss=0.0746, RMSE=0.2731, R²=-0.0223
============================================================


📊 Round 174 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2479, R²: 0.0020

============================================================
🔄 Round 175 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0771 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0771, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0771, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0771, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0771, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0771, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0771)

============================================================
📊 Round 175 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2805, R²=0.0072
   Val:   Loss=0.0771, RMSE=0.2776, R²=-0.0027
============================================================


📊 Round 175 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2479, R²: 0.0020

============================================================
🔄 Round 176 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0771 (↓), lr=0.000001
   • Epoch   2/100: train=0.0787, val=0.0771, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0771, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0771, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0771, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0771, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0771)

============================================================
📊 Round 176 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2805, R²=0.0051
   Val:   Loss=0.0771, RMSE=0.2777, R²=0.0039
============================================================


============================================================
🔄 Round 177 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0731 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0731, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0732, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0732, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0732, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0732, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0731)

============================================================
📊 Round 177 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2823, R²=-0.0016
   Val:   Loss=0.0731, RMSE=0.2704, R²=0.0251
============================================================


============================================================
🔄 Round 178 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0778, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0778, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0777, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0777, val=0.0813, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0777, val=0.0813, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0777, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 178 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0777, RMSE=0.2787, R²=0.0043
   Val:   Loss=0.0812, RMSE=0.2850, R²=-0.0007
============================================================


📊 Round 178 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2479, R²: 0.0020

============================================================
🔄 Round 179 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0688 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0688, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0688, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0688, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0688, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0806, val=0.0688, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0688)

============================================================
📊 Round 179 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=0.0089
   Val:   Loss=0.0688, RMSE=0.2622, R²=-0.0274
============================================================


📊 Round 179 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2479, R²: 0.0019

============================================================
🔄 Round 182 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0769 (↓), lr=0.000001
   • Epoch   2/100: train=0.0787, val=0.0769, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0769, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0769, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0769, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0769, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0769)

============================================================
📊 Round 182 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2806, R²=0.0056
   Val:   Loss=0.0769, RMSE=0.2773, R²=0.0042
============================================================


============================================================
🔄 Round 183 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0766, val=0.0857 (↓), lr=0.000001
   • Epoch   2/100: train=0.0766, val=0.0857, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0766, val=0.0857, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0765, val=0.0857, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0765, val=0.0857, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0765, val=0.0857, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0857)

============================================================
📊 Round 183 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0766, RMSE=0.2767, R²=0.0077
   Val:   Loss=0.0857, RMSE=0.2928, R²=-0.0031
============================================================


📊 Round 183 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2479, R²: 0.0018

📊 Round 183 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2479, R²: 0.0017

📊 Round 183 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2479, R²: 0.0016

============================================================
🔄 Round 190 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0727 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0727, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0727, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0727, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0727, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0727, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0727)

============================================================
📊 Round 190 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2825, R²=0.0102
   Val:   Loss=0.0727, RMSE=0.2695, R²=-0.0268
============================================================


============================================================
🔄 Round 191 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0734 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0734, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0734, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0734, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0735, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0735, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0734)

============================================================
📊 Round 191 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2822, R²=0.0073
   Val:   Loss=0.0734, RMSE=0.2710, R²=-0.0064
============================================================


📊 Round 191 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2479, R²: 0.0015

📊 Round 191 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2479, R²: 0.0015

============================================================
🔄 Round 199 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0782, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0782, val=0.0798, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0781, val=0.0798, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0781, val=0.0798, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0781, val=0.0799, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0781, val=0.0801, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 199 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0780, RMSE=0.2794, R²=-0.0014
   Val:   Loss=0.0797, RMSE=0.2824, R²=-0.0337
============================================================


============================================================
🔄 Round 201 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0772 (↓), lr=0.000001
   • Epoch   2/100: train=0.0787, val=0.0772, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0787, val=0.0772, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0787, val=0.0772, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0787, val=0.0772, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0773, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 201 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2805, R²=-0.0034
   Val:   Loss=0.0772, RMSE=0.2778, R²=0.0125
============================================================


📊 Round 201 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2479, R²: 0.0015

============================================================
🔄 Round 203 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0775 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0775, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0775, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0775, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0775)

============================================================
📊 Round 203 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2803, R²=0.0085
   Val:   Loss=0.0775, RMSE=0.2785, R²=-0.0095
============================================================


============================================================
🔄 Round 205 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0739 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0739, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0739, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0739, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0739, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0739, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0739)

============================================================
📊 Round 205 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2820, R²=0.0101
   Val:   Loss=0.0739, RMSE=0.2719, R²=-0.0189
============================================================


============================================================
🔄 Round 206 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0764, val=0.0859 (↓), lr=0.000001
   • Epoch   2/100: train=0.0764, val=0.0859, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0764, val=0.0859, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0764, val=0.0859, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0764, val=0.0859, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0764, val=0.0860, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0859)

============================================================
📊 Round 206 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0765, RMSE=0.2766, R²=0.0050
   Val:   Loss=0.0859, RMSE=0.2930, R²=-0.0122
============================================================


============================================================
🔄 Round 208 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0778 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0778, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0778, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0778, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0778, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0785, val=0.0779, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0778)

============================================================
📊 Round 208 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2802, R²=0.0021
   Val:   Loss=0.0778, RMSE=0.2789, R²=0.0147
============================================================


============================================================
🔄 Round 209 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0766, val=0.0846 (↓), lr=0.000001
   • Epoch   2/100: train=0.0766, val=0.0847, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0766, val=0.0847, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0766, val=0.0847, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0766, val=0.0847, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0766, val=0.0847, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0846)

============================================================
📊 Round 209 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0768, RMSE=0.2772, R²=0.0021
   Val:   Loss=0.0846, RMSE=0.2909, R²=0.0095
============================================================


📊 Round 209 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2480, R²: 0.0014

📊 Round 209 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2480, R²: 0.0014

============================================================
🔄 Round 212 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0772, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0772, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0772, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0772, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0772, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0772, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 212 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0772, RMSE=0.2779, R²=0.0048
   Val:   Loss=0.0830, RMSE=0.2881, R²=0.0064
============================================================


============================================================
🔄 Round 214 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0812, val=0.0675 (↓), lr=0.000001
   • Epoch   2/100: train=0.0812, val=0.0675, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0812, val=0.0675, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0812, val=0.0675, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0812, val=0.0675, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0812, val=0.0675, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0675)

============================================================
📊 Round 214 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0811, RMSE=0.2848, R²=0.0059
   Val:   Loss=0.0675, RMSE=0.2597, R²=-0.0119
============================================================


============================================================
🔄 Round 215 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0758, val=0.0900 (↓), lr=0.000001
   • Epoch   2/100: train=0.0758, val=0.0900, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0758, val=0.0900, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0758, val=0.0900, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0757, val=0.0900, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0757, val=0.0900, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0900)

============================================================
📊 Round 215 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0755, RMSE=0.2747, R²=0.0129
   Val:   Loss=0.0900, RMSE=0.3000, R²=-0.0207
============================================================


============================================================
🔄 Round 217 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0776, val=0.0815 (↓), lr=0.000001
   • Epoch   2/100: train=0.0776, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0776, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0776, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0776, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0776, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0815)

============================================================
📊 Round 217 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0776, RMSE=0.2786, R²=0.0053
   Val:   Loss=0.0815, RMSE=0.2855, R²=0.0053
============================================================


📊 Round 217 Test Metrics:
   Loss: 0.0814, RMSE: 0.2854, MAE: 0.2480, R²: 0.0013

📊 Round 217 Test Metrics:
   Loss: 0.0814, RMSE: 0.2854, MAE: 0.2480, R²: 0.0013

============================================================
🔄 Round 219 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0777, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0776, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0776, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0776, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0776, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0776, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 219 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0777, RMSE=0.2788, R²=0.0046
   Val:   Loss=0.0811, RMSE=0.2847, R²=0.0043
============================================================


============================================================
🔄 Round 220 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0818, val=0.0647 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0647, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0647, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0648, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0648, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0649, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0647)

============================================================
📊 Round 220 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2860, R²=0.0056
   Val:   Loss=0.0647, RMSE=0.2544, R²=-0.0162
============================================================


============================================================
🔄 Round 221 - Client client_74
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0750 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0750, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0750, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0750, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0750, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0794, val=0.0750, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0750)

============================================================
📊 Round 221 Summary - Client client_74
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2815, R²=-0.0015
   Val:   Loss=0.0750, RMSE=0.2738, R²=0.0310
============================================================


📊 Round 221 Test Metrics:
   Loss: 0.0814, RMSE: 0.2853, MAE: 0.2480, R²: 0.0015

❌ Client client_74 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8687 {grpc_message:"Socket closed", grpc_status:14}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8687 {grpc_message:"Socket closed", grpc_status:14}"
>
