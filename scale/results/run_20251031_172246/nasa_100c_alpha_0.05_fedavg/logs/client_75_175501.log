[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_numpy_client() is deprecated. 
	Instead, use `flwr.client.start_client()` by ensuring you first call the `.to_client()` method as shown below: 
	flwr.client.start_client(
		server_address='<IP>:<PORT>',
		client=FlowerClient().to_client(), # <-- where FlowerClient is of type flwr.client.NumPyClient object
	)
	Using `start_numpy_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[93mWARNING [0m:   DEPRECATED FEATURE: flwr.client.start_client() is deprecated.
	Instead, use the `flower-supernode` CLI command to start a SuperNode as shown below:

		$ flower-supernode --insecure --superlink='<IP>:<PORT>'

	To view all available options, run:

		$ flower-supernode --help

	Using `start_client()` is deprecated.

            This is a deprecated feature. It will be removed
            entirely in future versions of Flower.
        
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2c37cf85-1259-423f-94e2-98656d47288b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 36adc3fb-3f7a-4e75-a3f2-490a2701ad2e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7b09e265-9b22-43a3-acf7-2d895eb393ed
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2b1c2c56-09aa-49df-9e71-1b1feb8be2ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f8b4a0d8-451a-49de-918b-022988158853
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 93bac3cd-ede3-4ae4-9113-2cd0293724d5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 35fdaa18-d686-49b5-8dc5-94955c46dee9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 73b9c4d3-b4c6-47df-95d4-1175f30c61a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 445c6455-812e-4e47-9ecb-7cb5dfe39760
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ae1971ba-bc09-4f02-8485-be4dd474f2a5
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 145b5222-925c-4660-8249-6fe797095e58
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message cc461724-174b-431a-987c-b6030c10f7ff
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 53696604-b92a-4b22-a7d9-4d2b17cce47c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f6955f6b-fde2-4000-aad3-0b3fae74a707
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0d1246be-15c8-49d9-b991-764d74789a6b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 45d3d6c7-5eb5-4dc1-b931-25867ac8f3d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 57b4c657-0fcd-4a94-ba87-708023e40dd4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 561e9f23-a8ce-48c7-9699-18217b62b6eb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e72a9219-a54c-4269-8355-2db49e07439d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 906f8bd5-8aa4-4da1-9838-9e1fef9091f2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e5115648-f355-4aca-a198-674c4dee94d9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 861c9a70-0bbe-43b0-9674-c98044f537f4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1f978a0e-9441-4402-a1a5-e4b7e73889c1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 16503c2d-62cb-47c5-a90b-de4532767c9e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f8f75a5d-fce2-426f-a901-f7c731ffaa20
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 77dfb86f-1f25-45b6-8f8e-3a156dd486a1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 95d54d2c-da19-4b29-861a-54576648273b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 205841a5-1af7-41e1-a9a1-9cbf24346e85
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7c8f2c65-dffd-47ab-80b7-4bec4604c898
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 61677f65-4bd5-408d-bbd3-551e2bd0a74f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1cb71548-40fe-4e41-b724-3b1e2e377e29
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a7b120ba-775f-45dd-88e7-7a7bce94cef8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0431ecba-c95f-4736-baba-db5e69536bdb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f95bedab-39e8-4203-9bfc-302748a7d050
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 554db85e-f68e-434d-838c-17fd44b35f03
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 4bb884a0-ba2a-4afc-923a-c716fa4d0f61
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b165df85-0f9b-4a86-a3b4-8b55cdaf4aaa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1cfc6ea4-37a2-4541-a474-a66aebd964c4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0145254b-eb0c-47e8-99eb-7b68771081a0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message faef43b0-b489-4f00-9157-4960aa172d53
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ea7bd204-f0f5-4d74-9537-2fd8585b2dd1
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3742b603-9cc9-40da-a164-e65041aed653
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bbe5054a-66bb-49bd-b52d-32ccecb5196e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 789370ec-b66a-486b-92e2-3e50d592f454
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5bff1391-d45a-4ee9-a70c-2c9bd934e199
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c740b2aa-ac60-432d-94e6-f66c13917a8f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 402ac72b-db9b-4a14-9d16-964f5a29ff1d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7d761d46-a308-48cc-a3ec-ca03993ba388
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 89f46067-5fdd-40dd-8a52-f35eb4de3667
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 8a98bf83-2a95-42a3-92c8-63ef336341cd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 63538eb6-bf9f-45e9-99bd-4e146b4e7a01
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ef21a215-6de4-4171-ac6d-68c57e1f9b4f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 31cb1988-11d6-43b3-95e2-76fba9490514
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f07c2b4a-6997-40a0-8146-d502a4bacbcf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2e0ac335-221b-42c4-b84b-fc80f0786834
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6f10e7fc-e675-413c-bd4a-4d7bb85d99fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9b9bcbb8-cbd4-4bae-a7f7-7dd30cf951ac
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c1c1deb2-a46d-48d4-be7c-7cd16a04e5ee
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ff540886-99ae-4da0-92f2-6d24d8664f61
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 47b5031d-f8f0-4091-95ac-d1a37b265d14
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b70376f9-074d-44b8-9127-7087005b2b4f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 764cb3c5-ce82-4b33-948a-45c755c18d64
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a21f497a-1aa6-40a0-bceb-3af6b4eb208a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a63a1620-5768-417f-8201-0b20a8068cdc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message db4adbbd-c461-4d5c-8cb9-1f2ab42878aa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ee38d1e5-bb78-4643-a753-c330eadd8d74
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1708c59f-a92d-45ce-9c90-2d28bcc73e4d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 64fbbde0-a369-450e-bbc3-088e1efc2ae4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f71aa18b-db2d-4000-a3e0-449d21e8fdce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fce20c38-d2da-4ab5-9ae0-dc7da98290a6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 299c566c-0956-4130-897c-c4445be4a355
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ca7de601-9ad7-4cae-9556-d38ea45bef97
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1a30ba9a-38e3-42a1-b063-1eef7c001ceb
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f79b7d1e-0c74-421d-adae-9dd7d61536b2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c22827ad-74d2-41b3-aa67-3bf60e6edcec
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a5c1997b-20fa-473a-a062-e76942428653
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message da9f019a-5762-4ffb-9831-afb16cc1d783
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9e768ddf-5745-4bbe-8d4a-0afd99e35917
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 04c96b8f-be6f-4e19-8308-d3bd91f451fd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a4730055-d5a9-4b3f-b970-13ecc46af3fa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c19f4e0a-2b69-4d78-9a97-e3222ab571ce
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2244741b-ce85-461f-b63c-a69f364615f0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ccca2d29-d93b-43d3-9dbb-525375522374
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 6ce36b9f-a35a-41a7-a757-792f50660543
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d94886c1-050e-42e7-9b40-fd8804251f97
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 60ff06c2-2ae0-4c43-baee-dca60a6267f4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d47f84a8-8964-44da-aeff-8bf4cd1cca2f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a7cf708f-f118-4930-9941-97e2dbda04ea
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 908b7758-ba4b-45dc-88e5-bff61e20da9f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3cba4776-348d-4ab1-8374-a800ccd0a221
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3f138fed-3eff-40bc-9e11-d2dae9835c33
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1a8bde13-1c00-438d-a21e-6ffc04046f1d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f4cf765e-d387-413b-b682-f038521b0436
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message fdbd7a57-d4be-4d4d-a14f-6798ac53de09
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message aad9e7ea-450a-404f-abeb-7f0883a59583
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a55c65f8-4b48-4ec4-b21a-f953ecc1303d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 3027dbf2-d9d4-4b20-9864-f54f064817cd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9c8d5fc1-a619-4f11-81e4-32a8bf86b979
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f9fd0904-b606-4619-a58e-fa6aaba03c2c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 047c2f5d-97e1-40b1-9c65-0998ac569c51
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c9438465-37e5-4464-b38f-df45b5126cc0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 311f9223-c3f7-4502-94ad-8f3be198385b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message f5c219d7-44be-48da-9838-5945e92458ca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 0b54d613-6d5f-4853-8ab7-437b159c35cc
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9f7cc80a-1023-48ff-929e-6e6162ca11a3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b439b68d-4aa4-4ac5-8ee7-b54187828816
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message bacd6ea8-06ef-4fc9-9c85-15db95c83779
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 575abe11-5eb8-417d-9688-e62db5dbcdf8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 20bed302-57e3-4d4c-941a-53dc01c98c0f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9682548d-bd7c-4092-a4a5-433792279706
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9b9c8e99-e92f-4c04-905b-c29fa75380ab
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 9aa0c4eb-0810-4b9b-9ccc-0d0e29d27a30
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 237004e1-ac10-4ee6-9ae4-4615a4a5c194
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 9feda470-83ec-4208-8bff-4b6ed8511513
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2b69e336-9ab1-4bee-b9e4-61352932351d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ea205ed3-55ea-482a-8b05-f2db18f12738
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 483fc10c-9005-4834-b68d-19243675fea6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 67bb6719-637b-4885-9c62-0ea7edcc57c3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 30538fcf-08e3-42bc-85a1-e44f4f493443
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 73bc5e3b-4a30-45bb-8e2e-13a511e88c94
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message e61757e7-5f8c-4434-9126-bfb352756c43
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message dc219cf0-9fb2-4ece-9a16-de2faa1da8c9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 74659193-74b0-461a-9af3-622ecf211b6e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 85d4c3f9-b8cf-4742-a82e-757fd75b93e7
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 075c2a6f-1413-4d69-b21d-8f044c7621af
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 2333a4db-a104-42b5-878a-d6a1d6fbdb99
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 06509f37-4498-495f-9843-0d1f53db833b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d51dfa3b-d348-434b-84f6-534a57635008
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 31faf191-5184-48ee-b263-c85bd6a156c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 127118a7-012b-492c-847c-4a41d235899f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 11865df2-47a3-4859-a54d-bb5566b78c68
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message a7770685-4168-443c-b45e-c02f38e9b90d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c3433773-0fdf-4326-86dd-ca60e1467cfa
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b718693d-e4c0-4586-b079-c997b70f09a4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 68aa78eb-de3b-4ea4-b7b3-6cd5b11edbd9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7be6ce93-12d8-454f-a911-e34512a32412
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 83020f1e-0ca3-4808-8cbc-cb6667dc42c9
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 76ae06be-abd5-4184-9428-65339d35912b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 7a2f2122-4003-46a7-8a27-6816a7ff664b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 48e522a3-bfed-4ae3-bdcd-b519bb814e28
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 1f24e62d-a3b8-47bc-9599-c134652c0a82
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 5e17f47f-fc02-4918-8380-62320d8f042f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 407bee8a-75fe-4dd4-a519-1b265e2450bf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 61320d15-7135-44d7-9f4f-6938af54a79c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a7e6aa61-bafe-41b1-9187-4daa7cb4be96
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2a34e19b-467d-423e-bb1c-539136e04481
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ff2f3e30-1f8f-4932-a7f0-314267eebd08
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7208c22f-3557-48ad-afb4-dd05138d343a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message c0693183-d05e-436d-98df-32e121293abf
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 36e04dbb-6fb7-444e-98f0-5763bd26f765
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 89deabbc-d934-4ec2-94d6-f5cd3e148a9e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 2c893f9d-68d2-4441-a36f-bed3197c3705
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 1f612a5d-c4d1-4bc0-b863-5a862c9e269d
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 902ccba5-9a31-4fe4-97da-df4e4176f86c
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b572c2ba-ddde-41af-8ce7-830e895a909f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 77e6ed8e-7680-43ad-bb90-ed9574a98a2f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3172b172-5f91-48aa-bf19-2a3da04933a8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b4e6e568-7ca7-43ee-9e6a-2765f6d9c24b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3ee3b8ea-a4f2-4a84-9b65-c1a87227c242
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c2018f46-3a93-4253-bd01-055cc146f4d6
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 6d263fca-b33b-4955-818e-fe9cb58869c3
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b511135c-61cc-4af9-8c6a-e71a32567882
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 3256b3d8-7bb9-44d5-b17d-4be8595f63bd
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message b49f3551-0f42-4226-9ee9-f30a6a7df63e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 0abcef46-42e0-40cd-a0f4-85d434cdf3c0
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 7b076dbf-e799-4593-91c2-0607366108d2
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 127d007f-ae36-4808-a9ae-2e0b37faebb4
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message d770fb1d-3e76-420d-86d0-49bb67bb6072
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message fcfb8953-da8b-45f7-bd96-9611c9052f2b
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message c9a26920-f46d-456d-b63d-8f2c24aef919
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message ab5ed493-ddbd-40c7-af52-b31161d10ee8
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a58dc30f-3ef5-45a3-a1e9-8ca332ff3332
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message f7cf3366-c34d-4942-b987-9a444aafc684
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 404e7ec8-2c92-412a-9ddf-8de5d78f027a
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 932b3bc0-9e90-4ead-9609-7892f349665f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message a23c13fd-2002-4d01-b149-31b63845659f
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 5d711b92-55c1-4f7d-bd62-1119b8784fca
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message 21b97ffa-75eb-47a8-aa56-128a1455ec65
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message d24d23b3-a49a-47da-b863-56ec6bcb1681
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message 81961656-b201-41ca-8b6d-f41fb741259e
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: evaluate message ab31e343-95bb-46e5-98d7-bdaffc9dc981
[92mINFO [0m:      Sent reply
[92mINFO [0m:      
[92mINFO [0m:      Received: train message b09b9d32-356e-4a9b-b236-7318b5da9a81
[92mINFO [0m:      Sent reply
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8687 {grpc_status:14, grpc_message:"Socket closed"}"
>

================================================================================
🚀 NASA C-MAPSS Federated Learning Client
================================================================================
Client ID: client_75
Server: localhost:8687
Algorithm: FEDAVG
================================================================================

   🔧 LSTM config: hidden_dim=64, num_layers=2
   ✅ Converted to hidden_dims=[64, 64]
🖥️  Using device: cuda
✅ Found client data directory with all required files

📊 NASADataLoader initialized:
   Data path: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_75
   RUL mode: linear
   RUL power: 1
   Reduction: kpca

📂 Loading data files:
   Train data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_75/train_data.txt
   Train labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_75/train_labels.txt
   Test data: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_75/test_data.txt
   Test labels: /mnt/ceph_drive/FL_IoT_Network/scale/data/nasa_cmaps/pre_split_data/100_clients/alpha_0.05/client_75/test_labels.txt

📊 Raw data loaded:
   Train: X=(883, 24), y=(883,)
   Test:  X=(221, 24), y=(221,)

⚠️  Limiting training data: 883 → 800 samples

🔧 Applying StandardScaler...

🔄 Creating LSTM sequences (length=10)...

✅ Data loading complete!
   Train: 791 samples, 5 features
   Test:  212 samples, 5 features
✅ Client client_75 initialized with ReduceLROnPlateau scheduler
   Initial LR: 0.001
   Scheduler patience: 5

📊 Round 0 Test Metrics:
   Loss: 0.0779, RMSE: 0.2791, MAE: 0.2397, R²: 0.0393

============================================================
🔄 Round 6 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.001000
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0838, val=0.0869 (↓), lr=0.001000
   ✓ Epoch   2/100: train=0.0822, val=0.0813 (↓), lr=0.001000
   ✓ Epoch   3/100: train=0.0812, val=0.0799 (↓), lr=0.001000
   ✓ Epoch   4/100: train=0.0799, val=0.0792 (↓), lr=0.001000
   • Epoch   5/100: train=0.0793, val=0.0792, patience=1/15, lr=0.001000
   ✓ Epoch  11/100: train=0.0757, val=0.0758 (↓), lr=0.001000
   📉 Epoch 20: LR reduced 0.001000 → 0.000500
   • Epoch  21/100: train=0.0698, val=0.0774, patience=10/15, lr=0.000500

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0758)

============================================================
📊 Round 6 Summary - Client client_75
   Epochs: 26/100 (early stopped)
   LR: 0.001000 → 0.000500 (1 reductions)
   Train: Loss=0.0736, RMSE=0.2713, R²=0.1201
   Val:   Loss=0.0758, RMSE=0.2754, R²=0.0982
============================================================


============================================================
🔄 Round 7 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000500
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0797, val=0.0825 (↓), lr=0.000500
   📉 Epoch 2: LR reduced 0.000500 → 0.000250
   • Epoch   2/100: train=0.0787, val=0.0835, patience=1/15, lr=0.000250
   • Epoch   3/100: train=0.0779, val=0.0833, patience=2/15, lr=0.000250
   • Epoch   4/100: train=0.0776, val=0.0835, patience=3/15, lr=0.000250
   • Epoch   5/100: train=0.0773, val=0.0834, patience=4/15, lr=0.000250
   📉 Epoch 10: LR reduced 0.000250 → 0.000125
   • Epoch  11/100: train=0.0752, val=0.0831, patience=10/15, lr=0.000125

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0825)

============================================================
📊 Round 7 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000500 → 0.000125 (2 reductions)
   Train: Loss=0.0788, RMSE=0.2807, R²=0.0528
   Val:   Loss=0.0825, RMSE=0.2873, R²=0.0349
============================================================


📊 Round 7 Test Metrics:
   Loss: 0.0768, RMSE: 0.2771, MAE: 0.2377, R²: 0.0532

============================================================
🔄 Round 8 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000125
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0764 (↓), lr=0.000125
   📉 Epoch 2: LR reduced 0.000125 → 0.000063
   • Epoch   2/100: train=0.0799, val=0.0766, patience=1/15, lr=0.000063
   • Epoch   3/100: train=0.0795, val=0.0768, patience=2/15, lr=0.000063
   • Epoch   4/100: train=0.0793, val=0.0769, patience=3/15, lr=0.000063
   • Epoch   5/100: train=0.0792, val=0.0769, patience=4/15, lr=0.000063
   📉 Epoch 10: LR reduced 0.000063 → 0.000031
   • Epoch  11/100: train=0.0784, val=0.0769, patience=10/15, lr=0.000031

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0764)

============================================================
📊 Round 8 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000125 → 0.000031 (2 reductions)
   Train: Loss=0.0801, RMSE=0.2829, R²=0.0603
   Val:   Loss=0.0764, RMSE=0.2765, R²=0.0256
============================================================


📊 Round 8 Test Metrics:
   Loss: 0.0768, RMSE: 0.2772, MAE: 0.2378, R²: 0.0528

📊 Round 8 Test Metrics:
   Loss: 0.0771, RMSE: 0.2777, MAE: 0.2384, R²: 0.0495

============================================================
🔄 Round 12 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000031
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0758 (↓), lr=0.000031
   📉 Epoch 2: LR reduced 0.000031 → 0.000016
   • Epoch   2/100: train=0.0802, val=0.0758, patience=1/15, lr=0.000016
   • Epoch   3/100: train=0.0800, val=0.0758, patience=2/15, lr=0.000016
   • Epoch   4/100: train=0.0799, val=0.0758, patience=3/15, lr=0.000016
   • Epoch   5/100: train=0.0798, val=0.0757, patience=4/15, lr=0.000016
   📉 Epoch 10: LR reduced 0.000016 → 0.000008
   • Epoch  11/100: train=0.0791, val=0.0756, patience=10/15, lr=0.000008

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0758)

============================================================
📊 Round 12 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000031 → 0.000008 (2 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=0.0435
   Val:   Loss=0.0758, RMSE=0.2753, R²=0.0653
============================================================


📊 Round 12 Test Metrics:
   Loss: 0.0771, RMSE: 0.2776, MAE: 0.2384, R²: 0.0499

============================================================
🔄 Round 13 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000008
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0726 (↓), lr=0.000008
   • Epoch   2/100: train=0.0814, val=0.0726, patience=1/15, lr=0.000008
   • Epoch   3/100: train=0.0813, val=0.0726, patience=2/15, lr=0.000008
   • Epoch   4/100: train=0.0813, val=0.0725, patience=3/15, lr=0.000008
   • Epoch   5/100: train=0.0812, val=0.0725, patience=4/15, lr=0.000008
   • Epoch  11/100: train=0.0809, val=0.0722, patience=10/15, lr=0.000008
   • Epoch  21/100: train=0.0804, val=0.0718, patience=7/15, lr=0.000008

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0721)

============================================================
📊 Round 13 Summary - Client client_75
   Epochs: 29/100 (early stopped)
   LR: 0.000008 → 0.000008 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2844, R²=0.0488
   Val:   Loss=0.0721, RMSE=0.2685, R²=0.0904
============================================================


📊 Round 13 Test Metrics:
   Loss: 0.0767, RMSE: 0.2770, MAE: 0.2379, R²: 0.0543

============================================================
🔄 Round 16 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000008
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0801, val=0.0772 (↓), lr=0.000008
   • Epoch   2/100: train=0.0801, val=0.0772, patience=1/15, lr=0.000008
   • Epoch   3/100: train=0.0800, val=0.0771, patience=2/15, lr=0.000008
   • Epoch   4/100: train=0.0800, val=0.0770, patience=3/15, lr=0.000008
   • Epoch   5/100: train=0.0799, val=0.0769, patience=4/15, lr=0.000008
   📉 Epoch 6: LR reduced 0.000008 → 0.000004
   • Epoch  11/100: train=0.0797, val=0.0766, patience=3/15, lr=0.000004
   📉 Epoch 14: LR reduced 0.000004 → 0.000002
   • Epoch  21/100: train=0.0795, val=0.0763, patience=13/15, lr=0.000002
   📉 Epoch 22: LR reduced 0.000002 → 0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0767)

============================================================
📊 Round 16 Summary - Client client_75
   Epochs: 23/100 (early stopped)
   LR: 0.000008 → 0.000001 (3 reductions)
   Train: Loss=0.0798, RMSE=0.2824, R²=0.0562
   Val:   Loss=0.0767, RMSE=0.2770, R²=0.0408
============================================================


📊 Round 16 Test Metrics:
   Loss: 0.0766, RMSE: 0.2768, MAE: 0.2378, R²: 0.0553

============================================================
🔄 Round 18 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0834 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0834, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0785, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0835, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0834)

============================================================
📊 Round 18 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2803, R²=0.0463
   Val:   Loss=0.0834, RMSE=0.2887, R²=0.0576
============================================================


📊 Round 18 Test Metrics:
   Loss: 0.0766, RMSE: 0.2768, MAE: 0.2379, R²: 0.0553

============================================================
🔄 Round 20 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0773, val=0.0882 (↓), lr=0.000001
   • Epoch   2/100: train=0.0773, val=0.0882, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0773, val=0.0882, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0773, val=0.0882, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0773, val=0.0881, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0772, val=0.0881, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0882)

============================================================
📊 Round 20 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0773, RMSE=0.2780, R²=0.0530
   Val:   Loss=0.0882, RMSE=0.2970, R²=0.0464
============================================================


============================================================
🔄 Round 21 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0785, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0784, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 21 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2801, R²=0.0589
   Val:   Loss=0.0828, RMSE=0.2877, R²=0.0349
============================================================


📊 Round 21 Test Metrics:
   Loss: 0.0764, RMSE: 0.2764, MAE: 0.2375, R²: 0.0580

📊 Round 21 Test Metrics:
   Loss: 0.0764, RMSE: 0.2764, MAE: 0.2375, R²: 0.0579

============================================================
🔄 Round 23 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0765 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0765, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0765, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0765, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0765, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0765, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0765)

============================================================
📊 Round 23 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2829, R²=0.0553
   Val:   Loss=0.0765, RMSE=0.2766, R²=0.0387
============================================================


📊 Round 23 Test Metrics:
   Loss: 0.0764, RMSE: 0.2764, MAE: 0.2375, R²: 0.0584

============================================================
🔄 Round 24 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0768 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0768, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0768, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0768, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0768, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0768, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0768)

============================================================
📊 Round 24 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=0.0523
   Val:   Loss=0.0768, RMSE=0.2772, R²=0.0164
============================================================


============================================================
🔄 Round 25 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0782, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0782, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0782, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0782, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0782, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0781, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 25 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2799, R²=0.0553
   Val:   Loss=0.0831, RMSE=0.2882, R²=0.0500
============================================================


============================================================
🔄 Round 26 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0832, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0783, val=0.0832, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0783, val=0.0832, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 26 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0783, RMSE=0.2799, R²=0.0614
   Val:   Loss=0.0833, RMSE=0.2886, R²=0.0149
============================================================


📊 Round 26 Test Metrics:
   Loss: 0.0764, RMSE: 0.2764, MAE: 0.2375, R²: 0.0583

============================================================
🔄 Round 29 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0808 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0808, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0808, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0808, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0808, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0808, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0808)

============================================================
📊 Round 29 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2810, R²=0.0532
   Val:   Loss=0.0808, RMSE=0.2842, R²=0.0531
============================================================


📊 Round 29 Test Metrics:
   Loss: 0.0764, RMSE: 0.2764, MAE: 0.2375, R²: 0.0583

📊 Round 29 Test Metrics:
   Loss: 0.0764, RMSE: 0.2764, MAE: 0.2375, R²: 0.0583

============================================================
🔄 Round 33 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0797 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0797, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0797, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0797, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0796, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0797)

============================================================
📊 Round 33 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2815, R²=0.0589
   Val:   Loss=0.0797, RMSE=0.2823, R²=0.0157
============================================================


📊 Round 33 Test Metrics:
   Loss: 0.0764, RMSE: 0.2764, MAE: 0.2375, R²: 0.0583

📊 Round 33 Test Metrics:
   Loss: 0.0764, RMSE: 0.2764, MAE: 0.2375, R²: 0.0583

============================================================
🔄 Round 39 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0783, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0783, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0783, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0783, val=0.0828, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0783, val=0.0828, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0782, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 39 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2800, R²=0.0605
   Val:   Loss=0.0828, RMSE=0.2878, R²=0.0298
============================================================


📊 Round 39 Test Metrics:
   Loss: 0.0764, RMSE: 0.2764, MAE: 0.2375, R²: 0.0583

📊 Round 39 Test Metrics:
   Loss: 0.0764, RMSE: 0.2764, MAE: 0.2375, R²: 0.0583

📊 Round 39 Test Metrics:
   Loss: 0.0764, RMSE: 0.2764, MAE: 0.2375, R²: 0.0583

============================================================
🔄 Round 45 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0705 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0705, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0705, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0705, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0704, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0704, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0705)

============================================================
📊 Round 45 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=0.0484
   Val:   Loss=0.0705, RMSE=0.2655, R²=0.0810
============================================================


============================================================
🔄 Round 46 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0812, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0812, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0812, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0786, val=0.0812, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 46 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2807, R²=0.0416
   Val:   Loss=0.0812, RMSE=0.2850, R²=0.0653
============================================================


📊 Round 46 Test Metrics:
   Loss: 0.0764, RMSE: 0.2764, MAE: 0.2375, R²: 0.0583

============================================================
🔄 Round 47 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0781, val=0.0836 (↓), lr=0.000001
   • Epoch   2/100: train=0.0781, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0781, val=0.0835, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0781, val=0.0835, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0781, val=0.0835, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0780, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0836)

============================================================
📊 Round 47 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0782, RMSE=0.2797, R²=0.0509
   Val:   Loss=0.0836, RMSE=0.2891, R²=0.0471
============================================================


📊 Round 47 Test Metrics:
   Loss: 0.0764, RMSE: 0.2764, MAE: 0.2375, R²: 0.0583

📊 Round 47 Test Metrics:
   Loss: 0.0764, RMSE: 0.2764, MAE: 0.2375, R²: 0.0583

📊 Round 47 Test Metrics:
   Loss: 0.0764, RMSE: 0.2764, MAE: 0.2375, R²: 0.0583

============================================================
🔄 Round 53 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0795, val=0.0782 (↓), lr=0.000001
   • Epoch   2/100: train=0.0795, val=0.0782, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0795, val=0.0783, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0783, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0794, val=0.0783, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0783, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0782)

============================================================
📊 Round 53 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2820, R²=0.0616
   Val:   Loss=0.0782, RMSE=0.2797, R²=0.0082
============================================================


📊 Round 53 Test Metrics:
   Loss: 0.0764, RMSE: 0.2764, MAE: 0.2375, R²: 0.0583

📊 Round 53 Test Metrics:
   Loss: 0.0764, RMSE: 0.2764, MAE: 0.2375, R²: 0.0583

============================================================
🔄 Round 56 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0812 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0812, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0810, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0812)

============================================================
📊 Round 56 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2807, R²=0.0421
   Val:   Loss=0.0812, RMSE=0.2849, R²=0.0986
============================================================


📊 Round 56 Test Metrics:
   Loss: 0.0764, RMSE: 0.2764, MAE: 0.2375, R²: 0.0582

📊 Round 56 Test Metrics:
   Loss: 0.0764, RMSE: 0.2764, MAE: 0.2375, R²: 0.0583

📊 Round 56 Test Metrics:
   Loss: 0.0764, RMSE: 0.2764, MAE: 0.2375, R²: 0.0583

============================================================
🔄 Round 62 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0780, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0780, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0780, val=0.0844, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0780, val=0.0844, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0780, val=0.0844, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0779, val=0.0844, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 62 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0780, RMSE=0.2793, R²=0.0538
   Val:   Loss=0.0844, RMSE=0.2904, R²=0.0541
============================================================


📊 Round 62 Test Metrics:
   Loss: 0.0764, RMSE: 0.2764, MAE: 0.2375, R²: 0.0583

============================================================
🔄 Round 65 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0793 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0793, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0793, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0793, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0793, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0794, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0793)

============================================================
📊 Round 65 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2816, R²=0.0382
   Val:   Loss=0.0793, RMSE=0.2815, R²=0.0976
============================================================


============================================================
🔄 Round 66 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0787, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0785, val=0.0824, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 66 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2802, R²=0.0488
   Val:   Loss=0.0823, RMSE=0.2869, R²=0.0681
============================================================


============================================================
🔄 Round 67 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0814, val=0.0711 (↓), lr=0.000001
   • Epoch   2/100: train=0.0814, val=0.0711, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0813, val=0.0711, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0813, val=0.0711, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0813, val=0.0711, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0813, val=0.0710, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0711)

============================================================
📊 Round 67 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0813, RMSE=0.2851, R²=0.0512
   Val:   Loss=0.0711, RMSE=0.2667, R²=0.0703
============================================================


📊 Round 67 Test Metrics:
   Loss: 0.0764, RMSE: 0.2764, MAE: 0.2375, R²: 0.0583

============================================================
🔄 Round 68 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0784 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0784, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0784, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0784, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0784, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0795, val=0.0784, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0784)

============================================================
📊 Round 68 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2819, R²=0.0492
   Val:   Loss=0.0784, RMSE=0.2800, R²=0.0745
============================================================


============================================================
🔄 Round 70 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0816, val=0.0701 (↓), lr=0.000001
   • Epoch   2/100: train=0.0816, val=0.0701, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0816, val=0.0701, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0816, val=0.0700, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0816, val=0.0700, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0815, val=0.0700, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0701)

============================================================
📊 Round 70 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0816, RMSE=0.2856, R²=0.0460
   Val:   Loss=0.0701, RMSE=0.2647, R²=0.0926
============================================================


📊 Round 70 Test Metrics:
   Loss: 0.0764, RMSE: 0.2764, MAE: 0.2375, R²: 0.0584

============================================================
🔄 Round 72 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0747 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0747, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0747, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0746, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0746, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0746, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0747)

============================================================
📊 Round 72 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=0.0484
   Val:   Loss=0.0747, RMSE=0.2733, R²=0.0761
============================================================


============================================================
🔄 Round 73 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0781 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0781, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0780, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0780, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0780, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0780, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0781)

============================================================
📊 Round 73 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2821, R²=0.0500
   Val:   Loss=0.0781, RMSE=0.2794, R²=0.0735
============================================================


📊 Round 73 Test Metrics:
   Loss: 0.0764, RMSE: 0.2764, MAE: 0.2375, R²: 0.0584

============================================================
🔄 Round 74 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 74 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2816, R²=0.0479
   Val:   Loss=0.0791, RMSE=0.2813, R²=0.0769
============================================================


📊 Round 74 Test Metrics:
   Loss: 0.0764, RMSE: 0.2764, MAE: 0.2375, R²: 0.0584

============================================================
🔄 Round 78 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0771, val=0.0864 (↓), lr=0.000001
   • Epoch   2/100: train=0.0771, val=0.0864, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0770, val=0.0864, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0770, val=0.0865, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0770, val=0.0865, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0769, val=0.0867, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0864)

============================================================
📊 Round 78 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0775, RMSE=0.2784, R²=0.0535
   Val:   Loss=0.0864, RMSE=0.2939, R²=0.0030
============================================================


============================================================
🔄 Round 80 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0811 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0811, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0811, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0811, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0811, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0811, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0811)

============================================================
📊 Round 80 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2807, R²=0.0485
   Val:   Loss=0.0811, RMSE=0.2847, R²=0.0664
============================================================


📊 Round 80 Test Metrics:
   Loss: 0.0764, RMSE: 0.2764, MAE: 0.2374, R²: 0.0585

📊 Round 80 Test Metrics:
   Loss: 0.0764, RMSE: 0.2764, MAE: 0.2375, R²: 0.0584

============================================================
🔄 Round 83 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 83 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0794, RMSE=0.2818, R²=0.0575
   Val:   Loss=0.0787, RMSE=0.2805, R²=0.0400
============================================================


📊 Round 83 Test Metrics:
   Loss: 0.0764, RMSE: 0.2764, MAE: 0.2375, R²: 0.0584

============================================================
🔄 Round 85 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0792, val=0.0796 (↓), lr=0.000001
   • Epoch   2/100: train=0.0792, val=0.0796, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0796, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0791, val=0.0796, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0791, val=0.0796, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0795, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0796)

============================================================
📊 Round 85 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2814, R²=0.0556
   Val:   Loss=0.0796, RMSE=0.2822, R²=0.0518
============================================================


============================================================
🔄 Round 86 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0783, val=0.0838 (↓), lr=0.000001
   • Epoch   2/100: train=0.0783, val=0.0838, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0782, val=0.0838, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0782, val=0.0838, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0782, val=0.0838, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0781, val=0.0838, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0838)

============================================================
📊 Round 86 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0781, RMSE=0.2795, R²=0.0636
   Val:   Loss=0.0838, RMSE=0.2895, R²=0.0173
============================================================


📊 Round 86 Test Metrics:
   Loss: 0.0764, RMSE: 0.2764, MAE: 0.2375, R²: 0.0584

============================================================
🔄 Round 88 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0767 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0767, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0767, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0767, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0767, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0767, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0767)

============================================================
📊 Round 88 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2826, R²=0.0509
   Val:   Loss=0.0767, RMSE=0.2769, R²=0.0632
============================================================


📊 Round 88 Test Metrics:
   Loss: 0.0764, RMSE: 0.2764, MAE: 0.2374, R²: 0.0584

📊 Round 88 Test Metrics:
   Loss: 0.0764, RMSE: 0.2764, MAE: 0.2374, R²: 0.0584

============================================================
🔄 Round 93 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0830 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0830, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0783, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0783, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0829, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0830)

============================================================
📊 Round 93 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0783, RMSE=0.2798, R²=0.0567
   Val:   Loss=0.0830, RMSE=0.2881, R²=0.0455
============================================================


============================================================
🔄 Round 96 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0779, val=0.0844 (↓), lr=0.000001
   • Epoch   2/100: train=0.0779, val=0.0844, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0779, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0779, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0779, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0778, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0844)

============================================================
📊 Round 96 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0780, RMSE=0.2792, R²=0.0587
   Val:   Loss=0.0844, RMSE=0.2904, R²=0.0343
============================================================


📊 Round 96 Test Metrics:
   Loss: 0.0764, RMSE: 0.2764, MAE: 0.2374, R²: 0.0584

============================================================
🔄 Round 100 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0805, val=0.0751 (↓), lr=0.000001
   • Epoch   2/100: train=0.0805, val=0.0750, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0750, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0750, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0804, val=0.0750, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0750, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0751)

============================================================
📊 Round 100 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2833, R²=0.0535
   Val:   Loss=0.0751, RMSE=0.2740, R²=0.0616
============================================================


📊 Round 100 Test Metrics:
   Loss: 0.0764, RMSE: 0.2764, MAE: 0.2374, R²: 0.0585

============================================================
🔄 Round 104 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0790, val=0.0804 (↓), lr=0.000001
   • Epoch   2/100: train=0.0790, val=0.0804, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0790, val=0.0804, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0790, val=0.0804, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0790, val=0.0804, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0789, val=0.0803, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0804)

============================================================
📊 Round 104 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2809, R²=0.0611
   Val:   Loss=0.0804, RMSE=0.2836, R²=0.0253
============================================================


📊 Round 104 Test Metrics:
   Loss: 0.0764, RMSE: 0.2763, MAE: 0.2374, R²: 0.0585

📊 Round 104 Test Metrics:
   Loss: 0.0764, RMSE: 0.2763, MAE: 0.2374, R²: 0.0585

============================================================
🔄 Round 106 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0820, val=0.0691 (↓), lr=0.000001
   • Epoch   2/100: train=0.0820, val=0.0691, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0820, val=0.0691, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0819, val=0.0691, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0819, val=0.0691, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0818, val=0.0691, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0691)

============================================================
📊 Round 106 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0818, RMSE=0.2859, R²=0.0540
   Val:   Loss=0.0691, RMSE=0.2628, R²=0.0533
============================================================


📊 Round 106 Test Metrics:
   Loss: 0.0764, RMSE: 0.2763, MAE: 0.2374, R²: 0.0585

============================================================
🔄 Round 107 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0764 (↓), lr=0.000001
   • Epoch   2/100: train=0.0799, val=0.0764, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0799, val=0.0764, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0764, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0764, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0798, val=0.0763, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0764)

============================================================
📊 Round 107 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=0.0568
   Val:   Loss=0.0764, RMSE=0.2765, R²=0.0476
============================================================


============================================================
🔄 Round 110 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0815, val=0.0692 (↓), lr=0.000001
   • Epoch   2/100: train=0.0815, val=0.0692, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0815, val=0.0692, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0815, val=0.0691, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0815, val=0.0691, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0814, val=0.0691, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0692)

============================================================
📊 Round 110 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0817, RMSE=0.2859, R²=0.0569
   Val:   Loss=0.0692, RMSE=0.2630, R²=0.0478
============================================================


📊 Round 110 Test Metrics:
   Loss: 0.0764, RMSE: 0.2763, MAE: 0.2374, R²: 0.0585

📊 Round 110 Test Metrics:
   Loss: 0.0764, RMSE: 0.2763, MAE: 0.2374, R²: 0.0585

📊 Round 110 Test Metrics:
   Loss: 0.0764, RMSE: 0.2763, MAE: 0.2374, R²: 0.0585

📊 Round 110 Test Metrics:
   Loss: 0.0764, RMSE: 0.2763, MAE: 0.2374, R²: 0.0586

============================================================
🔄 Round 116 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0772 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0772, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0772, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0771, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0771, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0771, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0772)

============================================================
📊 Round 116 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2824, R²=0.0636
   Val:   Loss=0.0772, RMSE=0.2778, R²=0.0017
============================================================


============================================================
🔄 Round 117 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0732 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0732, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0732, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0732, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0732, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0731, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0732)

============================================================
📊 Round 117 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0807, RMSE=0.2841, R²=0.0564
   Val:   Loss=0.0732, RMSE=0.2706, R²=0.0387
============================================================


📊 Round 117 Test Metrics:
   Loss: 0.0764, RMSE: 0.2763, MAE: 0.2374, R²: 0.0586

============================================================
🔄 Round 119 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0720 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0720, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0720, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0720, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0720, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0720, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0720)

============================================================
📊 Round 119 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=0.0606
   Val:   Loss=0.0720, RMSE=0.2684, R²=0.0227
============================================================


============================================================
🔄 Round 120 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0775, val=0.0862 (↓), lr=0.000001
   • Epoch   2/100: train=0.0775, val=0.0862, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0775, val=0.0862, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0775, val=0.0862, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0774, val=0.0862, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0773, val=0.0862, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0862)

============================================================
📊 Round 120 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0775, RMSE=0.2783, R²=0.0534
   Val:   Loss=0.0862, RMSE=0.2935, R²=0.0505
============================================================


📊 Round 120 Test Metrics:
   Loss: 0.0764, RMSE: 0.2763, MAE: 0.2374, R²: 0.0587

============================================================
🔄 Round 121 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0791 (↓), lr=0.000001
   • Epoch   2/100: train=0.0794, val=0.0791, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0794, val=0.0791, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0794, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0790, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0791)

============================================================
📊 Round 121 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2815, R²=0.0511
   Val:   Loss=0.0791, RMSE=0.2813, R²=0.0728
============================================================


============================================================
🔄 Round 125 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0760 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0760, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0760, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0760, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0799, val=0.0760, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0760, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0760)

============================================================
📊 Round 125 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=0.0502
   Val:   Loss=0.0760, RMSE=0.2758, R²=0.0743
============================================================


📊 Round 125 Test Metrics:
   Loss: 0.0764, RMSE: 0.2763, MAE: 0.2374, R²: 0.0587

============================================================
🔄 Round 126 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0785, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0785, val=0.0817, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0785, val=0.0817, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0785, val=0.0817, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 126 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2803, R²=0.0599
   Val:   Loss=0.0817, RMSE=0.2858, R²=0.0384
============================================================


📊 Round 126 Test Metrics:
   Loss: 0.0764, RMSE: 0.2763, MAE: 0.2374, R²: 0.0587

📊 Round 126 Test Metrics:
   Loss: 0.0764, RMSE: 0.2763, MAE: 0.2374, R²: 0.0586

============================================================
🔄 Round 128 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0745 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0745, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0806, val=0.0745, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0806, val=0.0745, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0806, val=0.0745, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0745, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0745)

============================================================
📊 Round 128 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=0.0549
   Val:   Loss=0.0745, RMSE=0.2730, R²=0.0570
============================================================


============================================================
🔄 Round 129 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0813 (↓), lr=0.000001
   • Epoch   2/100: train=0.0786, val=0.0813, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0786, val=0.0813, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0786, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0786, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0785, val=0.0814, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0813)

============================================================
📊 Round 129 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0787, RMSE=0.2805, R²=0.0470
   Val:   Loss=0.0813, RMSE=0.2852, R²=0.0660
============================================================


📊 Round 129 Test Metrics:
   Loss: 0.0764, RMSE: 0.2763, MAE: 0.2374, R²: 0.0586

============================================================
🔄 Round 132 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0798, val=0.0763 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0763, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0763, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0763, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0763, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0763, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0763)

============================================================
📊 Round 132 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0799, RMSE=0.2827, R²=0.0522
   Val:   Loss=0.0763, RMSE=0.2763, R²=0.0554
============================================================


📊 Round 132 Test Metrics:
   Loss: 0.0764, RMSE: 0.2763, MAE: 0.2374, R²: 0.0586

📊 Round 132 Test Metrics:
   Loss: 0.0764, RMSE: 0.2763, MAE: 0.2374, R²: 0.0585

📊 Round 132 Test Metrics:
   Loss: 0.0764, RMSE: 0.2763, MAE: 0.2374, R²: 0.0585

============================================================
🔄 Round 138 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0772, val=0.0868 (↓), lr=0.000001
   • Epoch   2/100: train=0.0772, val=0.0868, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0772, val=0.0868, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0772, val=0.0868, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0772, val=0.0868, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0771, val=0.0867, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0868)

============================================================
📊 Round 138 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0773, RMSE=0.2780, R²=0.0589
   Val:   Loss=0.0868, RMSE=0.2947, R²=0.0429
============================================================


============================================================
🔄 Round 141 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0720 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0720, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0720, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0720, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0720, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0719, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0720)

============================================================
📊 Round 141 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0810, RMSE=0.2846, R²=0.0533
   Val:   Loss=0.0720, RMSE=0.2683, R²=0.0507
============================================================


📊 Round 141 Test Metrics:
   Loss: 0.0764, RMSE: 0.2763, MAE: 0.2374, R²: 0.0586

📊 Round 141 Test Metrics:
   Loss: 0.0764, RMSE: 0.2763, MAE: 0.2374, R²: 0.0586

============================================================
🔄 Round 143 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0786, val=0.0817 (↓), lr=0.000001
   • Epoch   2/100: train=0.0785, val=0.0817, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0785, val=0.0816, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0785, val=0.0816, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0785, val=0.0816, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0816, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0817)

============================================================
📊 Round 143 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2803, R²=0.0550
   Val:   Loss=0.0817, RMSE=0.2858, R²=0.0573
============================================================


📊 Round 143 Test Metrics:
   Loss: 0.0764, RMSE: 0.2763, MAE: 0.2374, R²: 0.0586

📊 Round 143 Test Metrics:
   Loss: 0.0764, RMSE: 0.2763, MAE: 0.2374, R²: 0.0586

============================================================
🔄 Round 152 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0831 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0831, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0784, val=0.0830, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0783, val=0.0830, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0783, val=0.0830, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0830, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0831)

============================================================
📊 Round 152 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0782, RMSE=0.2797, R²=0.0556
   Val:   Loss=0.0831, RMSE=0.2882, R²=0.0557
============================================================


📊 Round 152 Test Metrics:
   Loss: 0.0764, RMSE: 0.2763, MAE: 0.2374, R²: 0.0586

============================================================
🔄 Round 153 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0777, val=0.0856 (↓), lr=0.000001
   • Epoch   2/100: train=0.0777, val=0.0856, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0777, val=0.0856, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0777, val=0.0856, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0777, val=0.0856, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0776, val=0.0856, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0856)

============================================================
📊 Round 153 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0776, RMSE=0.2785, R²=0.0606
   Val:   Loss=0.0856, RMSE=0.2926, R²=0.0291
============================================================


📊 Round 153 Test Metrics:
   Loss: 0.0764, RMSE: 0.2763, MAE: 0.2374, R²: 0.0586

============================================================
🔄 Round 155 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0705 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0705, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0705, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0705, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0705, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0810, val=0.0705, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0705)

============================================================
📊 Round 155 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0814, RMSE=0.2852, R²=0.0514
   Val:   Loss=0.0705, RMSE=0.2655, R²=0.0657
============================================================


📊 Round 155 Test Metrics:
   Loss: 0.0764, RMSE: 0.2763, MAE: 0.2374, R²: 0.0586

============================================================
🔄 Round 156 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0788, val=0.0807 (↓), lr=0.000001
   • Epoch   2/100: train=0.0788, val=0.0807, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0788, val=0.0807, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0788, val=0.0807, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0788, val=0.0807, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0787, val=0.0806, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0807)

============================================================
📊 Round 156 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0788, RMSE=0.2807, R²=0.0611
   Val:   Loss=0.0807, RMSE=0.2842, R²=0.0339
============================================================


============================================================
🔄 Round 158 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0802 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0802, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0802, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0802, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0802, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0802, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0802)

============================================================
📊 Round 158 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2809, R²=0.0537
   Val:   Loss=0.0802, RMSE=0.2833, R²=0.0632
============================================================


📊 Round 158 Test Metrics:
   Loss: 0.0764, RMSE: 0.2763, MAE: 0.2374, R²: 0.0586

📊 Round 158 Test Metrics:
   Loss: 0.0764, RMSE: 0.2763, MAE: 0.2374, R²: 0.0586

📊 Round 158 Test Metrics:
   Loss: 0.0764, RMSE: 0.2763, MAE: 0.2374, R²: 0.0585

============================================================
🔄 Round 165 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0784, val=0.0835 (↓), lr=0.000001
   • Epoch   2/100: train=0.0784, val=0.0835, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0783, val=0.0834, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0783, val=0.0834, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0783, val=0.0834, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0782, val=0.0834, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0835)

============================================================
📊 Round 165 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0781, RMSE=0.2795, R²=0.0574
   Val:   Loss=0.0835, RMSE=0.2889, R²=0.0492
============================================================


📊 Round 165 Test Metrics:
   Loss: 0.0764, RMSE: 0.2763, MAE: 0.2374, R²: 0.0585

============================================================
🔄 Round 167 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0773, val=0.0869 (↓), lr=0.000001
   • Epoch   2/100: train=0.0773, val=0.0869, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0773, val=0.0869, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0773, val=0.0869, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0773, val=0.0869, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0772, val=0.0869, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0869)

============================================================
📊 Round 167 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0772, RMSE=0.2779, R²=0.0680
   Val:   Loss=0.0869, RMSE=0.2948, R²=0.0095
============================================================


📊 Round 167 Test Metrics:
   Loss: 0.0764, RMSE: 0.2763, MAE: 0.2374, R²: 0.0585

============================================================
🔄 Round 168 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0794, val=0.0792 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0792, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0792, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0793, val=0.0791, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0793, val=0.0791, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0793, val=0.0791, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0792)

============================================================
📊 Round 168 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0792, RMSE=0.2814, R²=0.0491
   Val:   Loss=0.0792, RMSE=0.2814, R²=0.0714
============================================================


============================================================
🔄 Round 170 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0796, val=0.0776 (↓), lr=0.000001
   • Epoch   2/100: train=0.0796, val=0.0776, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0796, val=0.0776, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0796, val=0.0775, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0796, val=0.0775, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0796, val=0.0774, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0776)

============================================================
📊 Round 170 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0796, RMSE=0.2821, R²=0.0566
   Val:   Loss=0.0776, RMSE=0.2785, R²=0.0406
============================================================


📊 Round 170 Test Metrics:
   Loss: 0.0764, RMSE: 0.2763, MAE: 0.2374, R²: 0.0585

============================================================
🔄 Round 171 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0809, val=0.0721 (↓), lr=0.000001
   • Epoch   2/100: train=0.0809, val=0.0721, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0809, val=0.0721, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0809, val=0.0721, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0808, val=0.0721, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0808, val=0.0721, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0721)

============================================================
📊 Round 171 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2845, R²=0.0479
   Val:   Loss=0.0721, RMSE=0.2686, R²=0.0855
============================================================


📊 Round 171 Test Metrics:
   Loss: 0.0764, RMSE: 0.2763, MAE: 0.2374, R²: 0.0585

============================================================
🔄 Round 174 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0780, val=0.0840 (↓), lr=0.000001
   • Epoch   2/100: train=0.0779, val=0.0840, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0779, val=0.0840, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0779, val=0.0840, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0779, val=0.0840, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0778, val=0.0839, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0840)

============================================================
📊 Round 174 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0780, RMSE=0.2792, R²=0.0571
   Val:   Loss=0.0840, RMSE=0.2898, R²=0.0513
============================================================


📊 Round 174 Test Metrics:
   Loss: 0.0764, RMSE: 0.2763, MAE: 0.2374, R²: 0.0586

============================================================
🔄 Round 175 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0782, val=0.0828 (↓), lr=0.000001
   • Epoch   2/100: train=0.0782, val=0.0828, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0782, val=0.0828, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0782, val=0.0827, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0782, val=0.0827, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0781, val=0.0827, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0828)

============================================================
📊 Round 175 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0783, RMSE=0.2798, R²=0.0690
   Val:   Loss=0.0828, RMSE=0.2877, R²=-0.0094
============================================================


📊 Round 175 Test Metrics:
   Loss: 0.0764, RMSE: 0.2763, MAE: 0.2374, R²: 0.0586

============================================================
🔄 Round 180 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0783, val=0.0820 (↓), lr=0.000001
   • Epoch   2/100: train=0.0783, val=0.0820, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0783, val=0.0820, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0783, val=0.0820, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0783, val=0.0820, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0782, val=0.0820, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0820)

============================================================
📊 Round 180 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2801, R²=0.0554
   Val:   Loss=0.0820, RMSE=0.2864, R²=0.0502
============================================================


📊 Round 180 Test Metrics:
   Loss: 0.0764, RMSE: 0.2763, MAE: 0.2374, R²: 0.0585

============================================================
🔄 Round 181 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0817, val=0.0684 (↓), lr=0.000001
   • Epoch   2/100: train=0.0817, val=0.0683, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0817, val=0.0683, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0817, val=0.0683, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0817, val=0.0683, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0816, val=0.0682, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0684)

============================================================
📊 Round 181 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0819, RMSE=0.2861, R²=0.0312
   Val:   Loss=0.0684, RMSE=0.2615, R²=0.1448
============================================================


============================================================
🔄 Round 182 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0783, val=0.0833 (↓), lr=0.000001
   • Epoch   2/100: train=0.0783, val=0.0833, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0783, val=0.0833, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0783, val=0.0833, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0783, val=0.0833, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0783, val=0.0832, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0833)

============================================================
📊 Round 182 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0781, RMSE=0.2795, R²=0.0603
   Val:   Loss=0.0833, RMSE=0.2886, R²=0.0179
============================================================


============================================================
🔄 Round 185 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0804, val=0.0745 (↓), lr=0.000001
   • Epoch   2/100: train=0.0804, val=0.0745, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0804, val=0.0745, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0804, val=0.0745, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0745, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0803, val=0.0745, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0745)

============================================================
📊 Round 185 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0803, RMSE=0.2834, R²=0.0630
   Val:   Loss=0.0745, RMSE=0.2730, R²=0.0239
============================================================


============================================================
🔄 Round 189 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0819, val=0.0699 (↓), lr=0.000001
   • Epoch   2/100: train=0.0818, val=0.0699, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0818, val=0.0699, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0818, val=0.0699, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0818, val=0.0699, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0817, val=0.0698, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0699)

============================================================
📊 Round 189 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0815, RMSE=0.2855, R²=0.0551
   Val:   Loss=0.0699, RMSE=0.2644, R²=0.0503
============================================================


============================================================
🔄 Round 191 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0800, val=0.0765 (↓), lr=0.000001
   • Epoch   2/100: train=0.0800, val=0.0765, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0800, val=0.0764, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0800, val=0.0764, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0800, val=0.0764, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0799, val=0.0764, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0765)

============================================================
📊 Round 191 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0798, RMSE=0.2826, R²=0.0490
   Val:   Loss=0.0765, RMSE=0.2765, R²=0.0798
============================================================


============================================================
🔄 Round 192 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0779, val=0.0852 (↓), lr=0.000001
   • Epoch   2/100: train=0.0779, val=0.0852, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0779, val=0.0852, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0779, val=0.0852, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0778, val=0.0852, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0778, val=0.0851, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0852)

============================================================
📊 Round 192 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0776, RMSE=0.2787, R²=0.0578
   Val:   Loss=0.0852, RMSE=0.2920, R²=0.0431
============================================================


📊 Round 192 Test Metrics:
   Loss: 0.0764, RMSE: 0.2764, MAE: 0.2374, R²: 0.0584

============================================================
🔄 Round 194 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0727 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0728, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0728, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0728, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0728, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0804, val=0.0729, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0727)

============================================================
📊 Round 194 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0808, RMSE=0.2842, R²=0.0481
   Val:   Loss=0.0727, RMSE=0.2697, R²=0.0583
============================================================


============================================================
🔄 Round 195 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0789, val=0.0801 (↓), lr=0.000001
   • Epoch   2/100: train=0.0789, val=0.0800, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0789, val=0.0800, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0789, val=0.0800, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0789, val=0.0800, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0788, val=0.0800, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0801)

============================================================
📊 Round 195 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0789, RMSE=0.2810, R²=0.0599
   Val:   Loss=0.0801, RMSE=0.2829, R²=0.0391
============================================================


============================================================
🔄 Round 196 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0760 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0760, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0759, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0759, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0759, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0759, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0760)

============================================================
📊 Round 196 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0800, RMSE=0.2828, R²=0.0621
   Val:   Loss=0.0760, RMSE=0.2756, R²=0.0245
============================================================


📊 Round 196 Test Metrics:
   Loss: 0.0764, RMSE: 0.2764, MAE: 0.2374, R²: 0.0584

📊 Round 196 Test Metrics:
   Loss: 0.0764, RMSE: 0.2764, MAE: 0.2374, R²: 0.0584

📊 Round 196 Test Metrics:
   Loss: 0.0764, RMSE: 0.2764, MAE: 0.2374, R²: 0.0584

============================================================
🔄 Round 199 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0786 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0786, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0786, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0792, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0786)

============================================================
📊 Round 199 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2816, R²=0.0618
   Val:   Loss=0.0786, RMSE=0.2804, R²=0.0017
============================================================


============================================================
🔄 Round 201 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0802, val=0.0741 (↓), lr=0.000001
   • Epoch   2/100: train=0.0802, val=0.0741, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0802, val=0.0741, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0802, val=0.0741, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0802, val=0.0741, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0801, val=0.0740, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0741)

============================================================
📊 Round 201 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2836, R²=0.0467
   Val:   Loss=0.0741, RMSE=0.2722, R²=0.0940
============================================================


============================================================
🔄 Round 204 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0799, val=0.0768 (↓), lr=0.000001
   • Epoch   2/100: train=0.0798, val=0.0769, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0798, val=0.0769, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0798, val=0.0769, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0798, val=0.0769, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0797, val=0.0770, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0768)

============================================================
📊 Round 204 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0797, RMSE=0.2824, R²=0.0586
   Val:   Loss=0.0768, RMSE=0.2772, R²=0.0100
============================================================


📊 Round 204 Test Metrics:
   Loss: 0.0764, RMSE: 0.2764, MAE: 0.2374, R²: 0.0583

📊 Round 204 Test Metrics:
   Loss: 0.0764, RMSE: 0.2764, MAE: 0.2374, R²: 0.0583

📊 Round 204 Test Metrics:
   Loss: 0.0764, RMSE: 0.2764, MAE: 0.2374, R²: 0.0584

============================================================
🔄 Round 208 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0814 (↓), lr=0.000001
   • Epoch   2/100: train=0.0785, val=0.0814, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0785, val=0.0814, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0785, val=0.0814, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0814, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0813, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0814)

============================================================
📊 Round 208 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0786, RMSE=0.2803, R²=0.0528
   Val:   Loss=0.0814, RMSE=0.2854, R²=0.0666
============================================================


📊 Round 208 Test Metrics:
   Loss: 0.0764, RMSE: 0.2764, MAE: 0.2374, R²: 0.0584

📊 Round 208 Test Metrics:
   Loss: 0.0764, RMSE: 0.2764, MAE: 0.2374, R²: 0.0584

============================================================
🔄 Round 210 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0811, val=0.0711 (↓), lr=0.000001
   • Epoch   2/100: train=0.0811, val=0.0711, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0811, val=0.0711, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0811, val=0.0710, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0811, val=0.0710, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0811, val=0.0710, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0711)

============================================================
📊 Round 210 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0812, RMSE=0.2849, R²=0.0445
   Val:   Loss=0.0711, RMSE=0.2666, R²=0.0911
============================================================


📊 Round 210 Test Metrics:
   Loss: 0.0764, RMSE: 0.2764, MAE: 0.2374, R²: 0.0584

📊 Round 210 Test Metrics:
   Loss: 0.0764, RMSE: 0.2764, MAE: 0.2374, R²: 0.0584

============================================================
🔄 Round 212 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0823 (↓), lr=0.000001
   • Epoch   2/100: train=0.0785, val=0.0823, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0785, val=0.0823, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0785, val=0.0823, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0784, val=0.0823, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0822, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0823)

============================================================
📊 Round 212 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0784, RMSE=0.2799, R²=0.0604
   Val:   Loss=0.0823, RMSE=0.2869, R²=0.0221
============================================================


📊 Round 212 Test Metrics:
   Loss: 0.0764, RMSE: 0.2764, MAE: 0.2374, R²: 0.0584

============================================================
🔄 Round 213 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0787 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0787, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0793, val=0.0787, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0786, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0786, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0786, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0787)

============================================================
📊 Round 213 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0793, RMSE=0.2815, R²=0.0501
   Val:   Loss=0.0787, RMSE=0.2805, R²=0.0774
============================================================


============================================================
🔄 Round 214 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0810, val=0.0723 (↓), lr=0.000001
   • Epoch   2/100: train=0.0810, val=0.0723, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0810, val=0.0723, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0810, val=0.0723, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0810, val=0.0723, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0809, val=0.0723, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0723)

============================================================
📊 Round 214 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0809, RMSE=0.2843, R²=0.0548
   Val:   Loss=0.0723, RMSE=0.2689, R²=0.0604
============================================================


============================================================
🔄 Round 216 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0793, val=0.0777 (↓), lr=0.000001
   • Epoch   2/100: train=0.0793, val=0.0777, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0792, val=0.0777, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0792, val=0.0777, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0792, val=0.0777, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0791, val=0.0777, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0777)

============================================================
📊 Round 216 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0795, RMSE=0.2820, R²=0.0653
   Val:   Loss=0.0777, RMSE=0.2788, R²=0.0157
============================================================


============================================================
🔄 Round 217 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0781, val=0.0843 (↓), lr=0.000001
   • Epoch   2/100: train=0.0781, val=0.0843, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0781, val=0.0843, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0781, val=0.0843, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0781, val=0.0843, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0780, val=0.0843, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0843)

============================================================
📊 Round 217 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0779, RMSE=0.2790, R²=0.0695
   Val:   Loss=0.0843, RMSE=0.2904, R²=0.0027
============================================================


📊 Round 217 Test Metrics:
   Loss: 0.0764, RMSE: 0.2764, MAE: 0.2374, R²: 0.0584

============================================================
🔄 Round 218 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0818 (↓), lr=0.000001
   • Epoch   2/100: train=0.0785, val=0.0818, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0785, val=0.0818, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0785, val=0.0818, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0785, val=0.0818, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0817, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0818)

============================================================
📊 Round 218 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2802, R²=0.0617
   Val:   Loss=0.0818, RMSE=0.2860, R²=0.0342
============================================================


📊 Round 218 Test Metrics:
   Loss: 0.0764, RMSE: 0.2764, MAE: 0.2374, R²: 0.0584

📊 Round 218 Test Metrics:
   Loss: 0.0764, RMSE: 0.2764, MAE: 0.2374, R²: 0.0584

============================================================
🔄 Round 222 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0785, val=0.0816 (↓), lr=0.000001
   • Epoch   2/100: train=0.0785, val=0.0815, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0785, val=0.0815, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0785, val=0.0815, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0785, val=0.0815, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0784, val=0.0815, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0816)

============================================================
📊 Round 222 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0785, RMSE=0.2802, R²=0.0584
   Val:   Loss=0.0816, RMSE=0.2856, R²=0.0463
============================================================


============================================================
🔄 Round 223 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0806, val=0.0742 (↓), lr=0.000001
   • Epoch   2/100: train=0.0806, val=0.0742, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0805, val=0.0742, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0805, val=0.0741, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0805, val=0.0741, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0805, val=0.0740, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0742)

============================================================
📊 Round 223 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0804, RMSE=0.2835, R²=0.0462
   Val:   Loss=0.0742, RMSE=0.2724, R²=0.0951
============================================================


📊 Round 223 Test Metrics:
   Loss: 0.0764, RMSE: 0.2764, MAE: 0.2374, R²: 0.0585

============================================================
🔄 Round 224 - Client client_75
   Epochs: 100, Batch: 32, LR: 0.000001
   Early Stop Patience: 15, Min Delta: 0.0005
============================================================
   ✓ Epoch   1/100: train=0.0803, val=0.0748 (↓), lr=0.000001
   • Epoch   2/100: train=0.0803, val=0.0747, patience=1/15, lr=0.000001
   • Epoch   3/100: train=0.0803, val=0.0747, patience=2/15, lr=0.000001
   • Epoch   4/100: train=0.0803, val=0.0747, patience=3/15, lr=0.000001
   • Epoch   5/100: train=0.0803, val=0.0747, patience=4/15, lr=0.000001
   • Epoch  11/100: train=0.0802, val=0.0747, patience=10/15, lr=0.000001

   ⚠️  Early stopping: No improvement for 15 epochs
   ✅ Restored best model (val_loss=0.0748)

============================================================
📊 Round 224 Summary - Client client_75
   Epochs: 16/100 (early stopped)
   LR: 0.000001 → 0.000001 (0 reductions)
   Train: Loss=0.0802, RMSE=0.2833, R²=0.0527
   Val:   Loss=0.0748, RMSE=0.2734, R²=0.0444
============================================================


❌ Client client_75 error: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8687 {grpc_status:14, grpc_message:"Socket closed"}"
>
Traceback (most recent call last):
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1410, in <module>
    main()
  File "/mnt/ceph_drive/FL_IoT_Network/scale/client.py", line 1390, in main
    fl.client.start_numpy_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 624, in start_numpy_client
    start_client(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 183, in start_client
    start_client_internal(
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/app.py", line 394, in start_client_internal
    message = receive()
              ^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/flwr/compat/client/grpc_client/connection.py", line 142, in receive
    proto = next(server_message_iterator)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 538, in __next__
    return self._next()
           ^^^^^^^^^^^^
  File "/mnt/ceph_drive/FL_IoT_Network/flwr-nasa/lib/python3.11/site-packages/grpc/_channel.py", line 962, in _next
    raise self
grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:
	status = StatusCode.UNAVAILABLE
	details = "Socket closed"
	debug_error_string = "UNKNOWN:Error received from peer ipv6:%5B::1%5D:8687 {grpc_status:14, grpc_message:"Socket closed"}"
>
